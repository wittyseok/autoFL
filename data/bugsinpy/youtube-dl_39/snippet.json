[
    {
        "name": "youtube_dl.extractor.deezer.DeezerPlaylistIE._real_extract#28",
        "src_path": "youtube_dl/extractor/deezer.py",
        "class_name": "youtube_dl.extractor.deezer.DeezerPlaylistIE",
        "signature": "youtube_dl.extractor.deezer.DeezerPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        if 'test' not in self._downloader.params:\n            self._downloader.report_warning('For now, this extractor only supports the 30 second previews. Patches welcome!')\n\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, playlist_id)\n        geoblocking_msg = self._html_search_regex(\n            r'<p class=\"soon-txt\">(.*?)</p>', webpage, 'geoblocking message',\n            default=None)\n        if geoblocking_msg is not None:\n            raise ExtractorError(\n                'Deezer said: %s' % geoblocking_msg, expected=True)\n\n        data_json = self._search_regex(\n            r'naboo\\.display\\(\\'[^\\']+\\',\\s*(.*?)\\);\\n', webpage, 'data JSON')\n        data = json.loads(data_json)\n\n        playlist_title = data.get('DATA', {}).get('TITLE')\n        playlist_uploader = data.get('DATA', {}).get('PARENT_USERNAME')\n        playlist_thumbnail = self._search_regex(\n            r'<img id=\"naboo_playlist_image\".*?src=\"([^\"]+)\"', webpage,\n            'playlist thumbnail')\n\n        preview_pattern = self._search_regex(\n            r\"var SOUND_PREVIEW_GATEWAY\\s*=\\s*'([^']+)';\", webpage,\n            'preview URL pattern', fatal=False)\n        entries = []\n        for s in data['SONGS']['data']:\n            puid = s['MD5_ORIGIN']\n            preview_video_url = preview_pattern.\\\n                replace('{0}', puid[0]).\\\n                replace('{1}', puid).\\\n                replace('{2}', s['MEDIA_VERSION'])\n            formats = [{\n                'format_id': 'preview',\n                'url': preview_video_url,\n                'preference': -100,  # Only the first 30 seconds\n                'ext': 'mp3',\n            }]\n            self._sort_formats(formats)\n            artists = ', '.join(\n                orderedSet(a['ART_NAME'] for a in s['ARTISTS']))\n            entries.append({\n                'id': s['SNG_ID'],\n                'duration': int_or_none(s.get('DURATION')),\n                'title': '%s - %s' % (artists, s['SNG_TITLE']),\n                'uploader': s['ART_NAME'],\n                'uploader_id': s['ART_ID'],\n                'age_limit': 16 if s.get('EXPLICIT_LYRICS') == '1' else 0,\n                'formats': formats,\n            })\n\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'title': playlist_title,\n            'uploader': playlist_uploader,\n            'thumbnail': playlist_thumbnail,\n            'entries': entries,\n        }",
        "begin_line": 28,
        "end_line": 89,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.cbsnews.CBSNewsIE._real_extract#45",
        "src_path": "youtube_dl/extractor/cbsnews.py",
        "class_name": "youtube_dl.extractor.cbsnews.CBSNewsIE",
        "signature": "youtube_dl.extractor.cbsnews.CBSNewsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_info = json.loads(self._html_search_regex(\n            r'(?:<ul class=\"media-list items\" id=\"media-related-items\"><li data-video-info|<div id=\"cbsNewsVideoPlayer\" data-video-player-options)=\\'({.+?})\\'',\n            webpage, 'video JSON info'))\n\n        item = video_info['item'] if 'item' in video_info else video_info\n        title = item.get('articleTitle') or item.get('hed')\n        duration = item.get('duration')\n        thumbnail = item.get('mediaImage') or item.get('thumbnail')\n\n        formats = []\n        for format_id in ['RtmpMobileLow', 'RtmpMobileHigh', 'Hls', 'RtmpDesktop']:\n            uri = item.get('media' + format_id + 'URI')\n            if not uri:\n                continue\n            fmt = {\n                'url': uri,\n                'format_id': format_id,\n            }\n            if uri.startswith('rtmp'):\n                fmt.update({\n                    'app': 'ondemand?auth=cbs',\n                    'play_path': 'mp4:' + uri.split('<break>')[-1],\n                    'player_url': 'http://www.cbsnews.com/[[IMPORT]]/vidtech.cbsinteractive.com/player/3_3_0/CBSI_PLAYER_HD.swf',\n                    'page_url': 'http://www.cbsnews.com',\n                    'ext': 'flv',\n                })\n            elif uri.endswith('.m3u8'):\n                fmt['ext'] = 'mp4'\n            formats.append(fmt)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 45,
        "end_line": 87,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.cbs.CBSIE._real_extract#41",
        "src_path": "youtube_dl/extractor/cbs.py",
        "class_name": "youtube_dl.extractor.cbs.CBSIE",
        "signature": "youtube_dl.extractor.cbs.CBSIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        real_id = self._search_regex(\n            r\"video\\.settings\\.pid\\s*=\\s*'([^']+)';\",\n            webpage, 'real video ID')\n        return self.url_result(u'theplatform:%s' % real_id)",
        "begin_line": 41,
        "end_line": 48,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.veoh.VeohIE._extract_formats#56",
        "src_path": "youtube_dl/extractor/veoh.py",
        "class_name": "youtube_dl.extractor.veoh.VeohIE",
        "signature": "youtube_dl.extractor.veoh.VeohIE._extract_formats(self, source)",
        "snippet": "    def _extract_formats(self, source):\n        formats = []\n        link = source.get('aowPermalink')\n        if link:\n            formats.append({\n                'url': link,\n                'ext': 'mp4',\n                'format_id': 'aow',\n            })\n        link = source.get('fullPreviewHashLowPath')\n        if link:\n            formats.append({\n                'url': link,\n                'format_id': 'low',\n            })\n        link = source.get('fullPreviewHashHighPath')\n        if link:\n            formats.append({\n                'url': link,\n                'format_id': 'high',\n            })\n        return formats",
        "begin_line": 56,
        "end_line": 77,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.veoh.VeohIE._extract_video#79",
        "src_path": "youtube_dl/extractor/veoh.py",
        "class_name": "youtube_dl.extractor.veoh.VeohIE",
        "signature": "youtube_dl.extractor.veoh.VeohIE._extract_video(self, source)",
        "snippet": "    def _extract_video(self, source):\n        return {\n            'id': source.get('videoId'),\n            'title': source.get('title'),\n            'description': source.get('description'),\n            'thumbnail': source.get('highResImage') or source.get('medResImage'),\n            'uploader': source.get('username'),\n            'duration': int_or_none(source.get('length')),\n            'view_count': int_or_none(source.get('views')),\n            'age_limit': 18 if source.get('isMature') == 'true' or source.get('isSexy') == 'true' else 0,\n            'formats': self._extract_formats(source),\n        }",
        "begin_line": 79,
        "end_line": 90,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.veoh.VeohIE._real_extract#92",
        "src_path": "youtube_dl/extractor/veoh.py",
        "class_name": "youtube_dl.extractor.veoh.VeohIE",
        "signature": "youtube_dl.extractor.veoh.VeohIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        if video_id.startswith('v'):\n            rsp = self._download_xml(\n                r'http://www.veoh.com/api/findByPermalink?permalink=%s' % video_id, video_id, 'Downloading video XML')\n            stat = rsp.get('stat')\n            if stat == 'ok':\n                return self._extract_video(rsp.find('./videoList/video'))\n            elif stat == 'fail':\n                raise ExtractorError(\n                    '%s said: %s' % (self.IE_NAME, rsp.find('./errorList/error').get('errorMessage')), expected=True)\n\n        webpage = self._download_webpage(url, video_id)\n        age_limit = 0\n        if 'class=\"adultwarning-container\"' in webpage:\n            self.report_age_confirmation()\n            age_limit = 18\n            request = compat_urllib_request.Request(url)\n            request.add_header('Cookie', 'confirmedAdult=true')\n            webpage = self._download_webpage(request, video_id)\n\n        m_youtube = re.search(r'http://www\\.youtube\\.com/v/(.*?)(\\&|\"|\\?)', webpage)\n        if m_youtube is not None:\n            youtube_id = m_youtube.group(1)\n            self.to_screen('%s: detected Youtube video.' % video_id)\n            return self.url_result(youtube_id, 'Youtube')\n\n        info = json.loads(\n            self._search_regex(r'videoDetailsJSON = \\'({.*?})\\';', webpage, 'info').replace('\\\\\\'', '\\''))\n\n        video = self._extract_video(info)\n        video['age_limit'] = age_limit\n\n        return video",
        "begin_line": 92,
        "end_line": 127,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.howcast.HowcastIE._real_extract#21",
        "src_path": "youtube_dl/extractor/howcast.py",
        "class_name": "youtube_dl.extractor.howcast.HowcastIE",
        "signature": "youtube_dl.extractor.howcast.HowcastIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n\n        self.report_extraction(video_id)\n\n        video_url = self._search_regex(r'\\'?file\\'?: \"(http://mobile-media\\.howcast\\.com/[0-9]+\\.mp4)',\n            webpage, 'video URL')\n\n        video_description = self._html_search_regex(r'<meta content=(?:\"([^\"]+)\"|\\'([^\\']+)\\') name=\\'description\\'',\n            webpage, 'description', fatal=False)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': self._og_search_title(webpage),\n            'description': video_description,\n            'thumbnail': self._og_search_thumbnail(webpage),\n        }",
        "begin_line": 21,
        "end_line": 41,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.nowness.NownessIE._real_extract#41",
        "src_path": "youtube_dl/extractor/nowness.py",
        "class_name": "youtube_dl.extractor.nowness.NownessIE",
        "signature": "youtube_dl.extractor.nowness.NownessIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('slug')\n\n        webpage = self._download_webpage(url, video_id)\n        player_url = self._search_regex(\n            r'\"([^\"]+/content/issue-[0-9.]+.js)\"', webpage, 'player URL')\n        real_id = self._search_regex(\n            r'\\sdata-videoId=\"([0-9]+)\"', webpage, 'internal video ID')\n\n        player_code = self._download_webpage(\n            player_url, video_id,\n            note='Downloading player JavaScript',\n            errnote='Player download failed')\n        player_code = player_code.replace(\"'+d+'\", real_id)\n\n        bc_url = BrightcoveIE._extract_brightcove_url(player_code)\n        if bc_url is None:\n            raise ExtractorError('Could not find player definition')\n        return {\n            '_type': 'url',\n            'url': bc_url,\n            'ie_key': 'Brightcove',\n        }",
        "begin_line": 41,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.gamekings.GamekingsIE._real_extract#22",
        "src_path": "youtube_dl/extractor/gamekings.py",
        "class_name": "youtube_dl.extractor.gamekings.GamekingsIE",
        "signature": "youtube_dl.extractor.gamekings.GamekingsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n\n        mobj = re.match(self._VALID_URL, url)\n        name = mobj.group('name')\n        webpage = self._download_webpage(url, name)\n        video_url = self._og_search_video_url(webpage)\n\n        video = re.search(r'[0-9]+', video_url)\n        video_id = video.group(0)\n\n        # Todo: add medium format\n        video_url = video_url.replace(video_id, 'large/' + video_id)\n\n        return {\n            'id': video_id,\n            'ext': 'mp4',\n            'url': video_url,\n            'title': self._og_search_title(webpage),\n            'description': self._og_search_description(webpage),\n        }",
        "begin_line": 22,
        "end_line": 41,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.rutube.RutubeIE._real_extract#38",
        "src_path": "youtube_dl/extractor/rutube.py",
        "class_name": "youtube_dl.extractor.rutube.RutubeIE",
        "signature": "youtube_dl.extractor.rutube.RutubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        video = self._download_json(\n            'http://rutube.ru/api/video/%s/?format=json' % video_id,\n            video_id, 'Downloading video JSON')\n\n        # Some videos don't have the author field\n        author = video.get('author') or {}\n\n        options = self._download_json(\n            'http://rutube.ru/api/play/options/%s/?format=json' % video_id,\n            video_id, 'Downloading options JSON')\n\n        m3u8_url = options['video_balancer'].get('m3u8')\n        if m3u8_url is None:\n            raise ExtractorError('Couldn\\'t find m3u8 manifest url')\n\n        return {\n            'id': video['id'],\n            'title': video['title'],\n            'description': video['description'],\n            'duration': video['duration'],\n            'view_count': video['hits'],\n            'url': m3u8_url,\n            'ext': 'mp4',\n            'thumbnail': video['thumbnail_url'],\n            'uploader': author.get('name'),\n            'uploader_id': compat_str(author['id']) if author else None,\n            'upload_date': unified_strdate(video['created_ts']),\n            'age_limit': 18 if video['is_adult'] else 0,\n        }",
        "begin_line": 38,
        "end_line": 70,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.rutube.RutubeChannelIE._extract_videos#87",
        "src_path": "youtube_dl/extractor/rutube.py",
        "class_name": "youtube_dl.extractor.rutube.RutubeChannelIE",
        "signature": "youtube_dl.extractor.rutube.RutubeChannelIE._extract_videos(self, channel_id, channel_title=None)",
        "snippet": "    def _extract_videos(self, channel_id, channel_title=None):\n        entries = []\n        for pagenum in itertools.count(1):\n            page = self._download_json(\n                self._PAGE_TEMPLATE % (channel_id, pagenum),\n                channel_id, 'Downloading page %s' % pagenum)\n            results = page['results']\n            if not results:\n                break\n            entries.extend(self.url_result(result['video_url'], 'Rutube') for result in results)\n            if not page['has_next']:\n                break\n        return self.playlist_result(entries, channel_id, channel_title)",
        "begin_line": 87,
        "end_line": 99,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.0004462293618920125,
            "pseudo_tarantula_susp": 0.0002772387025228722,
            "pseudo_op2_susp": 0.0004462293618920125,
            "pseudo_barinel_susp": 0.00027631942525559546
        }
    },
    {
        "name": "youtube_dl.extractor.rutube.RutubeChannelIE._real_extract#101",
        "src_path": "youtube_dl/extractor/rutube.py",
        "class_name": "youtube_dl.extractor.rutube.RutubeChannelIE",
        "signature": "youtube_dl.extractor.rutube.RutubeChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        channel_id = mobj.group('id')\n        return self._extract_videos(channel_id)",
        "begin_line": 101,
        "end_line": 104,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00023618327822390176,
            "pseudo_dstar_susp": 0.000233590282644242,
            "pseudo_tarantula_susp": 0.0002772387025228722,
            "pseudo_op2_susp": 0.000233590282644242,
            "pseudo_barinel_susp": 0.00027631942525559546
        }
    },
    {
        "name": "youtube_dl.extractor.rutube.RutubeMovieIE._real_extract#116",
        "src_path": "youtube_dl/extractor/rutube.py",
        "class_name": "youtube_dl.extractor.rutube.RutubeMovieIE",
        "signature": "youtube_dl.extractor.rutube.RutubeMovieIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        movie_id = mobj.group('id')\n        movie = self._download_json(\n            self._MOVIE_TEMPLATE % movie_id, movie_id,\n            'Downloading movie JSON')\n        movie_name = movie['name']\n        return self._extract_videos(movie_id, movie_name)",
        "begin_line": 116,
        "end_line": 123,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.dbtv.DBTVIE._real_extract#34",
        "src_path": "youtube_dl/extractor/dbtv.py",
        "class_name": "youtube_dl.extractor.dbtv.DBTVIE",
        "signature": "youtube_dl.extractor.dbtv.DBTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        data = self._download_json(\n            'http://api.dbtv.no/discovery/%s' % video_id, display_id)\n\n        video = data['playlist'][0]\n\n        formats = [{\n            'url': f['URL'],\n            'vcodec': f.get('container'),\n            'width': int_or_none(f.get('width')),\n            'height': int_or_none(f.get('height')),\n            'vbr': float_or_none(f.get('rate'), 1000),\n            'filesize': int_or_none(f.get('size')),\n        } for f in video['renditions'] if 'URL' in f]\n\n        if not formats:\n            for url_key, format_id in [('URL', 'mp4'), ('HLSURL', 'hls')]:\n                if url_key in video:\n                    formats.append({\n                        'url': video[url_key],\n                        'format_id': format_id,\n                    })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video['id'],\n            'display_id': display_id,\n            'title': video['title'],\n            'description': clean_html(video['desc']),\n            'thumbnail': video.get('splash') or video.get('thumb'),\n            'timestamp': float_or_none(video.get('publishedAt'), 1000),\n            'duration': float_or_none(video.get('length'), 1000),\n            'view_count': int_or_none(video.get('views')),\n            'categories': video.get('tags'),\n            'formats': formats,\n        }",
        "begin_line": 34,
        "end_line": 74,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.livestream.LivestreamIE._parse_smil#42",
        "src_path": "youtube_dl/extractor/livestream.py",
        "class_name": "youtube_dl.extractor.livestream.LivestreamIE",
        "signature": "youtube_dl.extractor.livestream.LivestreamIE._parse_smil(self, video_id, smil_url)",
        "snippet": "    def _parse_smil(self, video_id, smil_url):\n        formats = []\n        _SWITCH_XPATH = (\n            './/{http://www.w3.org/2001/SMIL20/Language}body/'\n            '{http://www.w3.org/2001/SMIL20/Language}switch')\n        smil_doc = self._download_xml(\n            smil_url, video_id,\n            note='Downloading SMIL information',\n            errnote='Unable to download SMIL information',\n            fatal=False)\n        if smil_doc is False:  # Download failed\n            return formats\n        title_node = find_xpath_attr(\n            smil_doc, './/{http://www.w3.org/2001/SMIL20/Language}meta',\n            'name', 'title')\n        if title_node is None:\n            self.report_warning('Cannot find SMIL id')\n            switch_node = smil_doc.find(_SWITCH_XPATH)\n        else:\n            title_id = title_node.attrib['content']\n            switch_node = find_xpath_attr(\n                smil_doc, _SWITCH_XPATH, 'id', title_id)\n        if switch_node is None:\n            raise ExtractorError('Cannot find switch node')\n        video_nodes = switch_node.findall(\n            '{http://www.w3.org/2001/SMIL20/Language}video')\n\n        for vn in video_nodes:\n            tbr = int_or_none(vn.attrib.get('system-bitrate'))\n            furl = (\n                'http://livestream-f.akamaihd.net/%s?v=3.0.3&fp=WIN%%2014,0,0,145' %\n                (vn.attrib['src']))\n            if 'clipBegin' in vn.attrib:\n                furl += '&ssek=' + vn.attrib['clipBegin']\n            formats.append({\n                'url': furl,\n                'format_id': 'smil_%d' % tbr,\n                'ext': 'flv',\n                'tbr': tbr,\n                'preference': -1000,\n            })\n        return formats",
        "begin_line": 42,
        "end_line": 83,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.livestream.LivestreamIE._extract_video_info#85",
        "src_path": "youtube_dl/extractor/livestream.py",
        "class_name": "youtube_dl.extractor.livestream.LivestreamIE",
        "signature": "youtube_dl.extractor.livestream.LivestreamIE._extract_video_info(self, video_data)",
        "snippet": "    def _extract_video_info(self, video_data):\n        video_id = compat_str(video_data['id'])\n\n        FORMAT_KEYS = (\n            ('sd', 'progressive_url'),\n            ('hd', 'progressive_url_hd'),\n        )\n        formats = [{\n            'format_id': format_id,\n            'url': video_data[key],\n            'quality': i + 1,\n        } for i, (format_id, key) in enumerate(FORMAT_KEYS)\n            if video_data.get(key)]\n\n        smil_url = video_data.get('smil_url')\n        if smil_url:\n            formats.extend(self._parse_smil(video_id, smil_url))\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': video_data['caption'],\n            'thumbnail': video_data.get('thumbnail_url'),\n            'upload_date': video_data['updated_at'].replace('-', '')[:8],\n            'like_count': video_data.get('likes', {}).get('total'),\n            'view_count': video_data.get('views'),\n        }",
        "begin_line": 85,
        "end_line": 112,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.livestream.LivestreamIE._real_extract#114",
        "src_path": "youtube_dl/extractor/livestream.py",
        "class_name": "youtube_dl.extractor.livestream.LivestreamIE",
        "signature": "youtube_dl.extractor.livestream.LivestreamIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        event_name = mobj.group('event_name')\n        webpage = self._download_webpage(url, video_id or event_name)\n\n        og_video = self._og_search_video_url(\n            webpage, 'player url', fatal=False, default=None)\n        if og_video is not None:\n            query_str = compat_urllib_parse_urlparse(og_video).query\n            query = compat_urlparse.parse_qs(query_str)\n            if 'play_url' in query:\n                api_url = query['play_url'][0].replace('.smil', '')\n                info = json.loads(self._download_webpage(\n                    api_url, video_id, 'Downloading video info'))\n                return self._extract_video_info(info)\n\n        config_json = self._search_regex(\n            r'window.config = ({.*?});', webpage, 'window config')\n        info = json.loads(config_json)['event']\n\n        def is_relevant(vdata, vid):\n            result = vdata['type'] == 'video'\n            if video_id is not None:\n                result = result and compat_str(vdata['data']['id']) == vid\n            return result\n\n        videos = [self._extract_video_info(video_data['data'])\n                  for video_data in info['feed']['data']\n                  if is_relevant(video_data, video_id)]\n        if video_id is None:\n            # This is an event page:\n            return self.playlist_result(videos, info['id'], info['full_name'])\n        else:\n            if not videos:\n                raise ExtractorError('Cannot find video %s' % video_id)\n            return videos[0]",
        "begin_line": 114,
        "end_line": 150,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00023618327822390176,
            "pseudo_dstar_susp": 0.000233590282644242,
            "pseudo_tarantula_susp": 0.0002772387025228722,
            "pseudo_op2_susp": 0.000233590282644242,
            "pseudo_barinel_susp": 0.00027631942525559546
        }
    },
    {
        "name": "youtube_dl.extractor.livestream.LivestreamIE.is_relevant#135",
        "src_path": "youtube_dl/extractor/livestream.py",
        "class_name": "youtube_dl.extractor.livestream.LivestreamIE",
        "signature": "youtube_dl.extractor.livestream.LivestreamIE.is_relevant(vdata, vid)",
        "snippet": "        def is_relevant(vdata, vid):\n            result = vdata['type'] == 'video'\n            if video_id is not None:\n                result = result and compat_str(vdata['data']['id']) == vid\n            return result",
        "begin_line": 135,
        "end_line": 139,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.livestream.LivestreamOriginalIE._extract_video#179",
        "src_path": "youtube_dl/extractor/livestream.py",
        "class_name": "youtube_dl.extractor.livestream.LivestreamOriginalIE",
        "signature": "youtube_dl.extractor.livestream.LivestreamOriginalIE._extract_video(self, user, video_id)",
        "snippet": "    def _extract_video(self, user, video_id):\n        api_url = 'http://x{0}x.api.channel.livestream.com/2.0/clipdetails?extendedInfo=true&id={1}'.format(user, video_id)\n\n        info = self._download_xml(api_url, video_id)\n        item = info.find('channel').find('item')\n        ns = {'media': 'http://search.yahoo.com/mrss'}\n        thumbnail_url = item.find(xpath_with_ns('media:thumbnail', ns)).attrib['url']\n        # Remove the extension and number from the path (like 1.jpg)\n        path = self._search_regex(r'(user-files/.+)_.*?\\.jpg$', thumbnail_url, 'path')\n\n        return {\n            'id': video_id,\n            'title': item.find('title').text,\n            'url': 'rtmp://extondemand.livestream.com/ondemand',\n            'play_path': 'mp4:trans/dv15/mogulus-{0}.mp4'.format(path),\n            'ext': 'flv',\n            'thumbnail': thumbnail_url,\n        }",
        "begin_line": 179,
        "end_line": 196,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.livestream.LivestreamOriginalIE._extract_folder#198",
        "src_path": "youtube_dl/extractor/livestream.py",
        "class_name": "youtube_dl.extractor.livestream.LivestreamOriginalIE",
        "signature": "youtube_dl.extractor.livestream.LivestreamOriginalIE._extract_folder(self, url, folder_id)",
        "snippet": "    def _extract_folder(self, url, folder_id):\n        webpage = self._download_webpage(url, folder_id)\n        paths = orderedSet(re.findall(\n            r'''(?x)(?:\n                <li\\s+class=\"folder\">\\s*<a\\s+href=\"|\n                <a\\s+href=\"(?=https?://livestre\\.am/)\n            )([^\"]+)\"''', webpage))\n\n        return {\n            '_type': 'playlist',\n            'id': folder_id,\n            'entries': [{\n                '_type': 'url',\n                'url': compat_urlparse.urljoin(url, p),\n            } for p in paths],\n        }",
        "begin_line": 198,
        "end_line": 213,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.livestream.LivestreamOriginalIE._real_extract#215",
        "src_path": "youtube_dl/extractor/livestream.py",
        "class_name": "youtube_dl.extractor.livestream.LivestreamOriginalIE",
        "signature": "youtube_dl.extractor.livestream.LivestreamOriginalIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        id = mobj.group('id')\n        user = mobj.group('user')\n        url_type = mobj.group('type')\n        if url_type == 'folder':\n            return self._extract_folder(url, id)\n        else:\n            return self._extract_video(user, id)",
        "begin_line": 215,
        "end_line": 223,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.livestream.LivestreamShortenerIE._real_extract#233",
        "src_path": "youtube_dl/extractor/livestream.py",
        "class_name": "youtube_dl.extractor.livestream.LivestreamShortenerIE",
        "signature": "youtube_dl.extractor.livestream.LivestreamShortenerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        id = mobj.group('id')\n        webpage = self._download_webpage(url, id)\n\n        return {\n            '_type': 'url',\n            'url': self._og_search_url(webpage),\n        }",
        "begin_line": 233,
        "end_line": 241,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.escapist.EscapistIE._real_extract#27",
        "src_path": "youtube_dl/extractor/escapist.py",
        "class_name": "youtube_dl.extractor.escapist.EscapistIE",
        "signature": "youtube_dl.extractor.escapist.EscapistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        showName = mobj.group('showname')\n        video_id = mobj.group('id')\n\n        self.report_extraction(video_id)\n        webpage = self._download_webpage(url, video_id)\n\n        videoDesc = self._html_search_regex(\n            r'<meta name=\"description\" content=\"([^\"]*)\"',\n            webpage, 'description', fatal=False)\n\n        playerUrl = self._og_search_video_url(webpage, name='player URL')\n\n        title = self._html_search_regex(\n            r'<meta name=\"title\" content=\"([^\"]*)\"',\n            webpage, 'title').split(' : ')[-1]\n\n        configUrl = self._search_regex('config=(.*)$', playerUrl, 'config URL')\n        configUrl = compat_urllib_parse.unquote(configUrl)\n\n        formats = []\n\n        def _add_format(name, cfgurl, quality):\n            config = self._download_json(\n                cfgurl, video_id,\n                'Downloading ' + name + ' configuration',\n                'Unable to download ' + name + ' configuration',\n                transform_source=lambda s: s.replace(\"'\", '\"'))\n\n            playlist = config['playlist']\n            formats.append({\n                'url': playlist[1]['url'],\n                'format_id': name,\n                'quality': quality,\n            })\n\n        _add_format('normal', configUrl, quality=0)\n        hq_url = (configUrl +\n                  ('&hq=1' if '?' in configUrl else configUrl + '?hq=1'))\n        try:\n            _add_format('hq', hq_url, quality=1)\n        except ExtractorError:\n            pass  # That's fine, we'll just use normal quality\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'uploader': showName,\n            'title': title,\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'description': videoDesc,\n            'player_url': playerUrl,\n        }",
        "begin_line": 27,
        "end_line": 82,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.zdf.ZDFIE._real_extract#31",
        "src_path": "youtube_dl/extractor/zdf.py",
        "class_name": "youtube_dl.extractor.zdf.ZDFIE",
        "signature": "youtube_dl.extractor.zdf.ZDFIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('video_id')\n\n        xml_url = 'http://www.zdf.de/ZDFmediathek/xmlservice/web/beitragsDetails?ak=web&id=%s' % video_id\n        doc = self._download_xml(\n            xml_url, video_id,\n            note='Downloading video info',\n            errnote='Failed to download video info')\n\n        title = doc.find('.//information/title').text\n        description = doc.find('.//information/detail').text\n        duration = int(doc.find('.//details/lengthSec').text)\n        uploader_node = doc.find('.//details/originChannelTitle')\n        uploader = None if uploader_node is None else uploader_node.text\n        uploader_id_node = doc.find('.//details/originChannelId')\n        uploader_id = None if uploader_id_node is None else uploader_id_node.text\n        upload_date = unified_strdate(doc.find('.//details/airtime').text)\n\n        def xml_to_format(fnode):\n            video_url = fnode.find('url').text\n            is_available = 'http://www.metafilegenerator' not in video_url\n\n            format_id = fnode.attrib['basetype']\n            format_m = re.match(r'''(?x)\n                (?P<vcodec>[^_]+)_(?P<acodec>[^_]+)_(?P<container>[^_]+)_\n                (?P<proto>[^_]+)_(?P<index>[^_]+)_(?P<indexproto>[^_]+)\n            ''', format_id)\n\n            ext = format_m.group('container')\n            proto = format_m.group('proto').lower()\n\n            quality = fnode.find('./quality').text\n            abr = int(fnode.find('./audioBitrate').text) // 1000\n            vbr_node = fnode.find('./videoBitrate')\n            vbr = None if vbr_node is None else int(vbr_node.text) // 1000\n\n            width_node = fnode.find('./width')\n            width = None if width_node is None else int_or_none(width_node.text)\n            height_node = fnode.find('./height')\n            height = None if height_node is None else int_or_none(height_node.text)\n\n            format_note = ''\n            if not format_note:\n                format_note = None\n\n            return {\n                'format_id': format_id + '-' + quality,\n                'url': video_url,\n                'ext': ext,\n                'acodec': format_m.group('acodec'),\n                'vcodec': format_m.group('vcodec'),\n                'abr': abr,\n                'vbr': vbr,\n                'width': width,\n                'height': height,\n                'filesize': int_or_none(fnode.find('./filesize').text),\n                'format_note': format_note,\n                'protocol': proto,\n                '_available': is_available,\n            }\n\n        format_nodes = doc.findall('.//formitaeten/formitaet')\n        formats = list(filter(\n            lambda f: f['_available'],\n            map(xml_to_format, format_nodes)))\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'upload_date': upload_date,\n            'formats': formats,\n        }",
        "begin_line": 31,
        "end_line": 109,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.ebaumsworld.EbaumsWorldIE._real_extract#22",
        "src_path": "youtube_dl/extractor/ebaumsworld.py",
        "class_name": "youtube_dl.extractor.ebaumsworld.EbaumsWorldIE",
        "signature": "youtube_dl.extractor.ebaumsworld.EbaumsWorldIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        config = self._download_xml(\n            'http://www.ebaumsworld.com/video/player/%s' % video_id, video_id)\n        video_url = config.find('file').text\n\n        return {\n            'id': video_id,\n            'title': config.find('title').text,\n            'url': video_url,\n            'description': config.find('description').text,\n            'thumbnail': config.find('image').text,\n            'uploader': config.find('username').text,\n        }",
        "begin_line": 22,
        "end_line": 36,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.sockshare.SockshareIE._real_extract#29",
        "src_path": "youtube_dl/extractor/sockshare.py",
        "class_name": "youtube_dl.extractor.sockshare.SockshareIE",
        "signature": "youtube_dl.extractor.sockshare.SockshareIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        url = 'http://sockshare.com/file/%s' % video_id\n        webpage = self._download_webpage(url, video_id)\n\n        if re.search(self._FILE_DELETED_REGEX, webpage) is not None:\n            raise ExtractorError('Video %s does not exist' % video_id,\n                                 expected=True)\n\n        confirm_hash = self._html_search_regex(r'''(?x)<input\\s+\n            type=\"hidden\"\\s+\n            value=\"([^\"]*)\"\\s+\n            name=\"hash\"\n            ''', webpage, 'hash')\n\n        fields = {\n            \"hash\": confirm_hash,\n            \"confirm\": \"Continue as Free User\"\n        }\n\n        post = compat_urllib_parse.urlencode(fields)\n        req = compat_urllib_request.Request(url, post)\n        # Apparently, this header is required for confirmation to work.\n        req.add_header('Host', 'www.sockshare.com')\n        req.add_header('Content-type', 'application/x-www-form-urlencoded')\n\n        webpage = self._download_webpage(\n            req, video_id, 'Downloading video page')\n\n        video_url = self._html_search_regex(\n            r'<a href=\"([^\"]*)\".+class=\"download_file_link\"',\n            webpage, 'file url')\n        video_url = \"http://www.sockshare.com\" + video_url\n        title = self._html_search_regex((\n            r'<h1>(.+)<strong>',\n            r'var name = \"([^\"]+)\";'),\n            webpage, 'title', default=None)\n        thumbnail = self._html_search_regex(\n            r'<img\\s+src=\"([^\"]*)\".+?name=\"bg\"',\n            webpage, 'thumbnail')\n\n        formats = [{\n            'format_id': 'sd',\n            'url': video_url,\n            'ext': determine_ext(title),\n        }]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 29,
        "end_line": 83,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.ehow.EHowIE._real_extract#26",
        "src_path": "youtube_dl/extractor/ehow.py",
        "class_name": "youtube_dl.extractor.ehow.EHowIE",
        "signature": "youtube_dl.extractor.ehow.EHowIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        video_url = self._search_regex(r'(?:file|source)=(http[^\\'\"&]*)',\n            webpage, 'video URL')\n        final_url = compat_urllib_parse.unquote(video_url)\n        uploader = self._html_search_meta('uploader', webpage)\n        title = self._og_search_title(webpage).replace(' | eHow', '')\n\n        return {\n            'id': video_id,\n            'url': final_url,\n            'title': title,\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'description': self._og_search_description(webpage),\n            'uploader': uploader,\n        }",
        "begin_line": 26,
        "end_line": 43,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.steam.SteamIE._real_extract#62",
        "src_path": "youtube_dl/extractor/steam.py",
        "class_name": "youtube_dl.extractor.steam.SteamIE",
        "signature": "youtube_dl.extractor.steam.SteamIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        fileID = m.group('fileID')\n        if fileID:\n            videourl = url\n            playlist_id = fileID\n        else:\n            gameID = m.group('gameID')\n            playlist_id = gameID\n            videourl = self._VIDEO_PAGE_TEMPLATE % playlist_id\n        webpage = self._download_webpage(videourl, playlist_id)\n\n        if re.search('<h2>Please enter your birth date to continue:</h2>', webpage) is not None:\n            videourl = self._AGECHECK_TEMPLATE % playlist_id\n            self.report_age_confirmation()\n            webpage = self._download_webpage(videourl, playlist_id)\n\n        if fileID:\n            playlist_title = self._html_search_regex(\n                r'<div class=\"workshopItemTitle\">(.+)</div>', webpage, 'title')\n            mweb = re.finditer(r'''(?x)\n                'movie_(?P<videoID>[0-9]+)':\\s*\\{\\s*\n                YOUTUBE_VIDEO_ID:\\s*\"(?P<youtube_id>[^\"]+)\",\n                ''', webpage)\n            videos = [{\n                '_type': 'url',\n                'url': vid.group('youtube_id'),\n                'ie_key': 'Youtube',\n            } for vid in mweb]\n        else:\n            playlist_title = self._html_search_regex(\n                r'<h2 class=\"pageheader\">(.*?)</h2>', webpage, 'game title')\n\n            mweb = re.finditer(r'''(?x)\n                'movie_(?P<videoID>[0-9]+)':\\s*\\{\\s*\n                FILENAME:\\s*\"(?P<videoURL>[\\w:/\\.\\?=]+)\"\n                (,\\s*MOVIE_NAME:\\s*\\\"(?P<videoName>[\\w:/\\.\\?=\\+-]+)\\\")?\\s*\\},\n                ''', webpage)\n            titles = re.finditer(\n                r'<span class=\"title\">(?P<videoName>.+?)</span>', webpage)\n            thumbs = re.finditer(\n                r'<img class=\"movie_thumb\" src=\"(?P<thumbnail>.+?)\">', webpage)\n            videos = []\n\n            for vid, vtitle, thumb in zip(mweb, titles, thumbs):\n                video_id = vid.group('videoID')\n                title = vtitle.group('videoName')\n                video_url = vid.group('videoURL')\n                video_thumb = thumb.group('thumbnail')\n                if not video_url:\n                    raise ExtractorError('Cannot find video url for %s' % video_id)\n                videos.append({\n                    'id': video_id,\n                    'url': video_url,\n                    'ext': 'flv',\n                    'title': unescapeHTML(title),\n                    'thumbnail': video_thumb\n                })\n        if not videos:\n            raise ExtractorError('Could not find any videos')\n\n        return self.playlist_result(videos, playlist_id, playlist_title)",
        "begin_line": 62,
        "end_line": 123,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.auengine.AUEngineIE._real_extract#26",
        "src_path": "youtube_dl/extractor/auengine.py",
        "class_name": "youtube_dl.extractor.auengine.AUEngineIE",
        "signature": "youtube_dl.extractor.auengine.AUEngineIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        title = self._html_search_regex(r'<title>(?P<title>.+?)</title>', webpage, 'title')\n        title = title.strip()\n        links = re.findall(r'\\s(?:file|url):\\s*[\"\\']([^\\'\"]+)[\"\\']', webpage)\n        links = map(compat_urllib_parse.unquote, links)\n\n        thumbnail = None\n        video_url = None\n        for link in links:\n            if link.endswith('.png'):\n                thumbnail = link\n            elif '/videos/' in link:\n                video_url = link\n        if not video_url:\n            raise ExtractorError('Could not find video URL')\n        ext = '.' + determine_ext(video_url)\n        if ext == title[-len(ext):]:\n            title = title[:-len(ext)]\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'thumbnail': thumbnail,\n            'http_referer': 'http://www.auengine.com/flowplayer/flowplayer.commercial-3.2.14.swf',\n        }",
        "begin_line": 26,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.noco.NocoIE._real_initialize#38",
        "src_path": "youtube_dl/extractor/noco.py",
        "class_name": "youtube_dl.extractor.noco.NocoIE",
        "signature": "youtube_dl.extractor.noco.NocoIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 38,
        "end_line": 39,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.noco.NocoIE._login#41",
        "src_path": "youtube_dl/extractor/noco.py",
        "class_name": "youtube_dl.extractor.noco.NocoIE",
        "signature": "youtube_dl.extractor.noco.NocoIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n\n        login_form = {\n            'a': 'login',\n            'cookie': '1',\n            'username': username,\n            'password': password,\n        }\n        request = compat_urllib_request.Request(self._LOGIN_URL, compat_urllib_parse.urlencode(login_form))\n        request.add_header('Content-Type', 'application/x-www-form-urlencoded; charset=UTF-8')\n\n        login = self._download_json(request, None, 'Logging in as %s' % username)\n\n        if 'erreur' in login:\n            raise  ExtractorError('Unable to login: %s' % clean_html(login['erreur']), expected=True)",
        "begin_line": 41,
        "end_line": 58,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.noco.NocoIE._real_extract#60",
        "src_path": "youtube_dl/extractor/noco.py",
        "class_name": "youtube_dl.extractor.noco.NocoIE",
        "signature": "youtube_dl.extractor.noco.NocoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        medias = self._download_json(\n            'https://api.noco.tv/1.0/video/medias/%s' % video_id, video_id, 'Downloading video JSON')\n\n        formats = []\n\n        for fmt in medias['fr']['video_list']['default']['quality_list']:\n            format_id = fmt['quality_key']\n\n            file = self._download_json(\n                'https://api.noco.tv/1.0/video/file/%s/fr/%s' % (format_id.lower(), video_id),\n                video_id, 'Downloading %s video JSON' % format_id)\n\n            file_url = file['file']\n            if not file_url:\n                continue\n\n            if file_url == 'forbidden':\n                raise ExtractorError(\n                    '%s returned error: %s - %s' % (\n                        self.IE_NAME, file['popmessage']['title'], file['popmessage']['message']),\n                    expected=True)\n\n            formats.append({\n                'url': file_url,\n                'format_id': format_id,\n                'width': fmt['res_width'],\n                'height': fmt['res_lines'],\n                'abr': fmt['audiobitrate'],\n                'vbr': fmt['videobitrate'],\n                'filesize': fmt['filesize'],\n                'format_note': fmt['quality_name'],\n                'preference': fmt['priority'],\n            })\n\n        self._sort_formats(formats)\n\n        show = self._download_json(\n            'https://api.noco.tv/1.0/shows/show/%s' % video_id, video_id, 'Downloading show JSON')[0]\n\n        upload_date = unified_strdate(show['indexed'])\n        uploader = show['partner_name']\n        uploader_id = show['partner_key']\n        duration = show['duration_ms'] / 1000.0\n        thumbnail = show['screenshot']\n\n        episode = show.get('show_TT') or show.get('show_OT')\n        family = show.get('family_TT') or show.get('family_OT')\n        episode_number = show.get('episode_number')\n\n        title = ''\n        if family:\n            title += family\n        if episode_number:\n            title += ' #' + compat_str(episode_number)\n        if episode:\n            title += ' - ' + episode\n\n        description = show.get('show_resume') or show.get('family_resume')\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 60,
        "end_line": 133,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.cloudy.CloudyIE._extract_video#48",
        "src_path": "youtube_dl/extractor/cloudy.py",
        "class_name": "youtube_dl.extractor.cloudy.CloudyIE",
        "signature": "youtube_dl.extractor.cloudy.CloudyIE._extract_video(self, video_host, video_id, file_key, error_url=None, try_num=0)",
        "snippet": "    def _extract_video(self, video_host, video_id, file_key, error_url=None, try_num=0):\n\n        if try_num > self._MAX_TRIES - 1:\n            raise ExtractorError('Unable to extract video URL', expected=True)\n\n        form = {\n            'file': video_id,\n            'key': file_key,\n        }\n\n        if error_url:\n            form.update({\n                'numOfErrors': try_num,\n                'errorCode': '404',\n                'errorUrl': error_url,\n            })\n\n        data_url = self._API_URL % (video_host, compat_urllib_parse.urlencode(form))\n        player_data = self._download_webpage(\n            data_url, video_id, 'Downloading player data')\n        data = compat_parse_qs(player_data)\n\n        try_num += 1\n\n        if 'error' in data:\n            raise ExtractorError(\n                '%s error: %s' % (self.IE_NAME, ' '.join(data['error_msg'])),\n                expected=True)\n\n        title = data.get('title', [None])[0]\n        if title:\n            title = remove_end(title, '&asdasdas').strip()\n\n        video_url = data.get('url', [None])[0]\n\n        if video_url:\n            try:\n                self._request_webpage(HEADRequest(video_url), video_id, 'Checking video URL')\n            except ExtractorError as e:\n                if isinstance(e.cause, compat_HTTPError) and e.cause.code in [404, 410]:\n                    self.report_warning('Invalid video URL, requesting another', video_id)\n                    return self._extract_video(video_host, video_id, file_key, video_url, try_num)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n        }",
        "begin_line": 48,
        "end_line": 95,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.cloudy.CloudyIE._real_extract#97",
        "src_path": "youtube_dl/extractor/cloudy.py",
        "class_name": "youtube_dl.extractor.cloudy.CloudyIE",
        "signature": "youtube_dl.extractor.cloudy.CloudyIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_host = mobj.group('host')\n        video_id = mobj.group('id')\n\n        url = self._EMBED_URL % (video_host, video_id)\n        webpage = self._download_webpage(url, video_id)\n\n        file_key = self._search_regex(\n            r'filekey\\s*=\\s*\"([^\"]+)\"', webpage, 'file_key')\n\n        return self._extract_video(video_host, video_id, file_key)",
        "begin_line": 97,
        "end_line": 108,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.ooyala.OoyalaIE._extract_result#48",
        "src_path": "youtube_dl/extractor/ooyala.py",
        "class_name": "youtube_dl.extractor.ooyala.OoyalaIE",
        "signature": "youtube_dl.extractor.ooyala.OoyalaIE._extract_result(self, info, more_info)",
        "snippet": "    def _extract_result(self, info, more_info):\n        return {\n            'id': info['embedCode'],\n            'ext': 'mp4',\n            'title': unescapeHTML(info['title']),\n            'url': info.get('ipad_url') or info['url'],\n            'description': unescapeHTML(more_info['description']),\n            'thumbnail': more_info['promo'],\n        }",
        "begin_line": 48,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.ooyala.OoyalaIE._real_extract#58",
        "src_path": "youtube_dl/extractor/ooyala.py",
        "class_name": "youtube_dl.extractor.ooyala.OoyalaIE",
        "signature": "youtube_dl.extractor.ooyala.OoyalaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        embedCode = mobj.group('id')\n        player_url = 'http://player.ooyala.com/player.js?embedCode=%s' % embedCode\n        player = self._download_webpage(player_url, embedCode)\n        mobile_url = self._search_regex(r'mobile_player_url=\"(.+?)&device=\"',\n                                        player, 'mobile player url')\n        # Looks like some videos are only available for particular devices\n        # (e.g. http://player.ooyala.com/player.js?embedCode=x1b3lqZDq9y_7kMyC2Op5qo-p077tXD0\n        # is only available for ipad)\n        # Working around with fetching URLs for all the devices found starting with 'unknown'\n        # until we succeed or eventually fail for each device.\n        devices = re.findall(r'device\\s*=\\s*\"([^\"]+)\";', player)\n        devices.remove('unknown')\n        devices.insert(0, 'unknown')\n        for device in devices:\n            mobile_player = self._download_webpage(\n                '%s&device=%s' % (mobile_url, device), embedCode,\n                'Downloading mobile player JS for %s device' % device)\n            videos_info = self._search_regex(\n                r'var streams=window.oo_testEnv\\?\\[\\]:eval\\(\"\\((\\[{.*?}\\])\\)\"\\);',\n                mobile_player, 'info', fatal=False, default=None)\n            if videos_info:\n                break\n        if not videos_info:\n            raise ExtractorError('Unable to extract info')\n        videos_info = videos_info.replace('\\\\\"', '\"')\n        videos_more_info = self._search_regex(\n            r'eval\\(\"\\(({.*?\\\\\"promo\\\\\".*?})\\)\"', mobile_player, 'more info').replace('\\\\\"', '\"')\n        videos_info = json.loads(videos_info)\n        videos_more_info = json.loads(videos_more_info)\n\n        if videos_more_info.get('lineup'):\n            videos = [self._extract_result(info, more_info) for (info, more_info) in zip(videos_info, videos_more_info['lineup'])]\n            return {\n                '_type': 'playlist',\n                'id': embedCode,\n                'title': unescapeHTML(videos_more_info['title']),\n                'entries': videos,\n            }\n        else:\n            return self._extract_result(videos_info[0], videos_more_info)",
        "begin_line": 58,
        "end_line": 99,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.condenast.CondeNastIE._extract_series#48",
        "src_path": "youtube_dl/extractor/condenast.py",
        "class_name": "youtube_dl.extractor.condenast.CondeNastIE",
        "signature": "youtube_dl.extractor.condenast.CondeNastIE._extract_series(self, url, webpage)",
        "snippet": "    def _extract_series(self, url, webpage):\n        title = self._html_search_regex(r'<div class=\"cne-series-info\">.*?<h1>(.+?)</h1>',\n                                        webpage, 'series title', flags=re.DOTALL)\n        url_object = compat_urllib_parse_urlparse(url)\n        base_url = '%s://%s' % (url_object.scheme, url_object.netloc)\n        m_paths = re.finditer(r'<p class=\"cne-thumb-title\">.*?<a href=\"(/watch/.+?)[\"\\?]',\n                              webpage, flags=re.DOTALL)\n        paths = orderedSet(m.group(1) for m in m_paths)\n        build_url = lambda path: compat_urlparse.urljoin(base_url, path)\n        entries = [self.url_result(build_url(path), 'CondeNast') for path in paths]\n        return self.playlist_result(entries, playlist_title=title)",
        "begin_line": 48,
        "end_line": 58,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.condenast.CondeNastIE._extract_video#60",
        "src_path": "youtube_dl/extractor/condenast.py",
        "class_name": "youtube_dl.extractor.condenast.CondeNastIE",
        "signature": "youtube_dl.extractor.condenast.CondeNastIE._extract_video(self, webpage, url_type)",
        "snippet": "    def _extract_video(self, webpage, url_type):\n        if url_type != 'embed':\n            description = self._html_search_regex(\n                [\n                    r'<div class=\"cne-video-description\">(.+?)</div>',\n                    r'<div class=\"video-post-content\">(.+?)</div>',\n                ],\n                webpage, 'description', fatal=False, flags=re.DOTALL)\n        else:\n            description = None\n        params = self._search_regex(r'var params = {(.+?)}[;,]', webpage,\n                                    'player params', flags=re.DOTALL)\n        video_id = self._search_regex(r'videoId: [\\'\"](.+?)[\\'\"]', params, 'video id')\n        player_id = self._search_regex(r'playerId: [\\'\"](.+?)[\\'\"]', params, 'player id')\n        target = self._search_regex(r'target: [\\'\"](.+?)[\\'\"]', params, 'target')\n        data = compat_urllib_parse.urlencode({'videoId': video_id,\n                                              'playerId': player_id,\n                                              'target': target,\n                                              })\n        base_info_url = self._search_regex(r'url = [\\'\"](.+?)[\\'\"][,;]',\n                                           webpage, 'base info url',\n                                           default='http://player.cnevids.com/player/loader.js?')\n        info_url = base_info_url + data\n        info_page = self._download_webpage(info_url, video_id,\n                                           'Downloading video info')\n        video_info = self._search_regex(r'var video = ({.+?});', info_page, 'video info')\n        video_info = json.loads(video_info)\n\n        formats = [{\n            'format_id': '%s-%s' % (fdata['type'].split('/')[-1], fdata['quality']),\n            'url': fdata['src'],\n            'ext': fdata['type'].split('/')[-1],\n            'quality': 1 if fdata['quality'] == 'high' else 0,\n        } for fdata in video_info['sources'][0]]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': video_info['title'],\n            'thumbnail': video_info['poster_frame'],\n            'description': description,\n        }",
        "begin_line": 60,
        "end_line": 102,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.condenast.CondeNastIE._real_extract#104",
        "src_path": "youtube_dl/extractor/condenast.py",
        "class_name": "youtube_dl.extractor.condenast.CondeNastIE",
        "signature": "youtube_dl.extractor.condenast.CondeNastIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        site = mobj.group('site')\n        url_type = mobj.group('type')\n        item_id = mobj.group('id')\n\n        self.to_screen('Extracting from %s with the Cond\u00e9 Nast extractor' % self._SITES[site])\n        webpage = self._download_webpage(url, item_id)\n\n        if url_type == 'series':\n            return self._extract_series(url, webpage)\n        else:\n            return self._extract_video(webpage, url_type)",
        "begin_line": 104,
        "end_line": 116,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.vimple.VimpleIE._real_extract#41",
        "src_path": "youtube_dl/extractor/vimple.py",
        "class_name": "youtube_dl.extractor.vimple.VimpleIE",
        "signature": "youtube_dl.extractor.vimple.VimpleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        iframe_url = 'http://player.vimple.ru/iframe/%s' % video_id\n\n        iframe = self._download_webpage(\n            iframe_url, video_id,\n            note='Downloading iframe', errnote='unable to fetch iframe')\n        player_url = self._html_search_regex(\n            r'\"(http://player.vimple.ru/flash/.+?)\"', iframe, 'player url')\n\n        player = self._request_webpage(\n            player_url, video_id, note='Downloading swf player').read()\n\n        player = zlib.decompress(player[8:])\n\n        xml_pieces = re.findall(b'([a-zA-Z0-9 =+/]{500})', player)\n        xml_pieces = [piece[1:-1] for piece in xml_pieces]\n\n        xml_data = b''.join(xml_pieces)\n        xml_data = base64.b64decode(xml_data)\n\n        xml_data = xml.etree.ElementTree.fromstring(xml_data)\n\n        video = xml_data.find('Video')\n        quality = video.get('quality')\n        q_tag = video.find(quality.capitalize())\n\n        formats = [\n            {\n                'url': q_tag.get('url'),\n                'tbr': int(q_tag.get('bitrate')),\n                'filesize': int(q_tag.get('filesize')),\n                'format_id': quality,\n            },\n        ]\n\n        return {\n            'id': video_id,\n            'title': video.find('Title').text,\n            'formats': formats,\n            'thumbnail': video.find('Poster').get('url'),\n            'duration': int_or_none(video.get('duration')),\n            'webpage_url': video.find('Share').get('videoPageUrl'),\n        }",
        "begin_line": 41,
        "end_line": 86,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.vbox7.Vbox7IE._real_extract#27",
        "src_path": "youtube_dl/extractor/vbox7.py",
        "class_name": "youtube_dl.extractor.vbox7.Vbox7IE",
        "signature": "youtube_dl.extractor.vbox7.Vbox7IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        redirect_page, urlh = self._download_webpage_handle(url, video_id)\n        new_location = self._search_regex(r'window\\.location = \\'(.*)\\';',\n            redirect_page, 'redirect location')\n        redirect_url = urlh.geturl() + new_location\n        webpage = self._download_webpage(redirect_url, video_id,\n            'Downloading redirect page')\n\n        title = self._html_search_regex(r'<title>(.*)</title>',\n            webpage, 'title').split('/')[0].strip()\n\n        info_url = \"http://vbox7.com/play/magare.do\"\n        data = compat_urllib_parse.urlencode({'as3': '1', 'vid': video_id})\n        info_request = compat_urllib_request.Request(info_url, data)\n        info_request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        info_response = self._download_webpage(info_request, video_id, 'Downloading info webpage')\n        if info_response is None:\n            raise ExtractorError('Unable to extract the media url')\n        (final_url, thumbnail_url) = map(lambda x: x.split('=')[1], info_response.split('&'))\n\n        return {\n            'id': video_id,\n            'url': final_url,\n            'ext': 'flv',\n            'title': title,\n            'thumbnail': thumbnail_url,\n        }",
        "begin_line": 27,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.__init__#148",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.__init__(self, downloader=None)",
        "snippet": "    def __init__(self, downloader=None):\n        \"\"\"Constructor. Receives an optional downloader.\"\"\"\n        self._ready = False\n        self.set_downloader(downloader)",
        "begin_line": 148,
        "end_line": 151,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.010752688172043012,
            "pseudo_dstar_susp": 0.16666666666666666,
            "pseudo_tarantula_susp": 0.0002994011976047904,
            "pseudo_op2_susp": 0.16666666666666666,
            "pseudo_barinel_susp": 0.0002994011976047904
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.suitable#154",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        \"\"\"Receives a URL and returns True if suitable for this IE.\"\"\"\n\n        # This does not use has/getattr intentionally - we want to know whether\n        # we have cached the regexp for *this* class, whereas getattr would also\n        # match the superclass\n        if '_VALID_URL_RE' not in cls.__dict__:\n            cls._VALID_URL_RE = re.compile(cls._VALID_URL)\n        return cls._VALID_URL_RE.match(url) is not None",
        "begin_line": 154,
        "end_line": 162,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.006369426751592357,
            "pseudo_dstar_susp": 0.007142857142857143,
            "pseudo_tarantula_susp": 0.0003003003003003003,
            "pseudo_op2_susp": 0.007142857142857143,
            "pseudo_barinel_susp": 0.0003003003003003003
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.working#165",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.working(cls)",
        "snippet": "    def working(cls):\n        \"\"\"Getter method for _WORKING.\"\"\"\n        return cls._WORKING",
        "begin_line": 165,
        "end_line": 167,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0053475935828877,
            "pseudo_dstar_susp": 0.010101010101010102,
            "pseudo_tarantula_susp": 0.0002937720329024677,
            "pseudo_op2_susp": 0.010101010101010102,
            "pseudo_barinel_susp": 0.0002937720329024677
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.initialize#169",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.initialize(self)",
        "snippet": "    def initialize(self):\n        \"\"\"Initializes an instance (authentication, etc).\"\"\"\n        if not self._ready:\n            self._real_initialize()\n            self._ready = True",
        "begin_line": 169,
        "end_line": 173,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.045454545454545456,
            "pseudo_dstar_susp": 0.015384615384615385,
            "pseudo_tarantula_susp": 0.0003181673560292714,
            "pseudo_op2_susp": 0.015384615384615385,
            "pseudo_barinel_susp": 0.0003181673560292714
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.extract#175",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.extract(self, url)",
        "snippet": "    def extract(self, url):\n        \"\"\"Extracts URL information and returns it in list of dicts.\"\"\"\n        self.initialize()\n        return self._real_extract(url)",
        "begin_line": 175,
        "end_line": 178,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.045454545454545456,
            "pseudo_dstar_susp": 0.015384615384615385,
            "pseudo_tarantula_susp": 0.0003181673560292714,
            "pseudo_op2_susp": 0.015384615384615385,
            "pseudo_barinel_susp": 0.0003181673560292714
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.set_downloader#180",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.set_downloader(self, downloader)",
        "snippet": "    def set_downloader(self, downloader):\n        \"\"\"Sets the downloader for this IE.\"\"\"\n        self._downloader = downloader",
        "begin_line": 180,
        "end_line": 182,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.010752688172043012,
            "pseudo_dstar_susp": 0.16666666666666666,
            "pseudo_tarantula_susp": 0.0002994011976047904,
            "pseudo_op2_susp": 0.16666666666666666,
            "pseudo_barinel_susp": 0.0002994011976047904
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._real_initialize#184",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        \"\"\"Real initialization process. Redefine in subclasses.\"\"\"\n        pass",
        "begin_line": 184,
        "end_line": 186,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00641025641025641,
            "pseudo_dstar_susp": 0.006172839506172839,
            "pseudo_tarantula_susp": 0.00031289111389236547,
            "pseudo_op2_susp": 0.006172839506172839,
            "pseudo_barinel_susp": 0.00031289111389236547
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._real_extract#188",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        \"\"\"Real extraction process. Redefine in subclasses.\"\"\"\n        pass",
        "begin_line": 188,
        "end_line": 190,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.ie_key#193",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.ie_key(cls)",
        "snippet": "    def ie_key(cls):\n        \"\"\"A string for getting the InfoExtractor with get_info_extractor\"\"\"\n        return cls.__name__[:-2]",
        "begin_line": 193,
        "end_line": 195,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00909090909090909,
            "pseudo_dstar_susp": 0.009615384615384616,
            "pseudo_tarantula_susp": 0.00031298904538341156,
            "pseudo_op2_susp": 0.009615384615384616,
            "pseudo_barinel_susp": 0.00031298904538341156
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.IE_NAME#198",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.IE_NAME(self)",
        "snippet": "    def IE_NAME(self):\n        return type(self).__name__[:-2]",
        "begin_line": 198,
        "end_line": 199,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.003703703703703704,
            "pseudo_dstar_susp": 0.0038314176245210726,
            "pseudo_tarantula_susp": 0.00030184123151222455,
            "pseudo_op2_susp": 0.0038314176245210726,
            "pseudo_barinel_susp": 0.00030184123151222455
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._request_webpage#201",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._request_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True)",
        "snippet": "    def _request_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True):\n        \"\"\" Returns the response handle \"\"\"\n        if note is None:\n            self.report_download_webpage(video_id)\n        elif note is not False:\n            if video_id is None:\n                self.to_screen('%s' % (note,))\n            else:\n                self.to_screen('%s: %s' % (video_id, note))\n        try:\n            return self._downloader.urlopen(url_or_request)\n        except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:\n            if errnote is False:\n                return False\n            if errnote is None:\n                errnote = 'Unable to download webpage'\n            errmsg = '%s: %s' % (errnote, compat_str(err))\n            if fatal:\n                raise ExtractorError(errmsg, sys.exc_info()[2], cause=err)\n            else:\n                self._downloader.report_warning(errmsg)\n                return False",
        "begin_line": 201,
        "end_line": 222,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.05263157894736842,
            "pseudo_dstar_susp": 0.013888888888888888,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.013888888888888888,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._download_webpage_handle#224",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._download_webpage_handle(self, url_or_request, video_id, note=None, errnote=None, fatal=True)",
        "snippet": "    def _download_webpage_handle(self, url_or_request, video_id, note=None, errnote=None, fatal=True):\n        \"\"\" Returns a tuple (page content as string, URL handle) \"\"\"\n\n        # Strip hashes from the URL (#1038)\n        if isinstance(url_or_request, (compat_str, str)):\n            url_or_request = url_or_request.partition('#')[0]\n\n        urlh = self._request_webpage(url_or_request, video_id, note, errnote, fatal)\n        if urlh is False:\n            assert not fatal\n            return False\n        content_type = urlh.headers.get('Content-Type', '')\n        webpage_bytes = urlh.read()\n        m = re.match(r'[a-zA-Z0-9_.-]+/[a-zA-Z0-9_.-]+\\s*;\\s*charset=(.+)', content_type)\n        if m:\n            encoding = m.group(1)\n        else:\n            m = re.search(br'<meta[^>]+charset=[\\'\"]?([^\\'\")]+)[ /\\'\">]',\n                          webpage_bytes[:1024])\n            if m:\n                encoding = m.group(1).decode('ascii')\n            elif webpage_bytes.startswith(b'\\xff\\xfe'):\n                encoding = 'utf-16'\n            else:\n                encoding = 'utf-8'\n        if self._downloader.params.get('dump_intermediate_pages', False):\n            try:\n                url = url_or_request.get_full_url()\n            except AttributeError:\n                url = url_or_request\n            self.to_screen('Dumping request to ' + url)\n            dump = base64.b64encode(webpage_bytes).decode('ascii')\n            self._downloader.to_screen(dump)\n        if self._downloader.params.get('write_pages', False):\n            try:\n                url = url_or_request.get_full_url()\n            except AttributeError:\n                url = url_or_request\n            basen = '%s_%s' % (video_id, url)\n            if len(basen) > 240:\n                h = '___' + hashlib.md5(basen.encode('utf-8')).hexdigest()\n                basen = basen[:240 - len(h)] + h\n            raw_filename = basen + '.dump'\n            filename = sanitize_filename(raw_filename, restricted=True)\n            self.to_screen('Saving request to ' + filename)\n            with open(filename, 'wb') as outf:\n                outf.write(webpage_bytes)\n\n        try:\n            content = webpage_bytes.decode(encoding, 'replace')\n        except LookupError:\n            content = webpage_bytes.decode('utf-8', 'replace')\n\n        if ('<title>Access to this site is blocked</title>' in content and\n                'Websense' in content[:512]):\n            msg = 'Access to this webpage has been blocked by Websense filtering software in your network.'\n            blocked_iframe = self._html_search_regex(\n                r'<iframe src=\"([^\"]+)\"', content,\n                'Websense information URL', default=None)\n            if blocked_iframe:\n                msg += ' Visit %s for more details' % blocked_iframe\n            raise ExtractorError(msg, expected=True)\n\n        return (content, urlh)",
        "begin_line": 224,
        "end_line": 287,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.03225806451612903,
            "pseudo_dstar_susp": 0.011235955056179775,
            "pseudo_tarantula_susp": 0.00033344448149383126,
            "pseudo_op2_susp": 0.011235955056179775,
            "pseudo_barinel_susp": 0.00033344448149383126
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._download_webpage#289",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._download_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True)",
        "snippet": "    def _download_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True):\n        \"\"\" Returns the data of the page as a string \"\"\"\n        res = self._download_webpage_handle(url_or_request, video_id, note, errnote, fatal)\n        if res is False:\n            return res\n        else:\n            content, _ = res\n            return content",
        "begin_line": 289,
        "end_line": 296,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.012345679012345678,
            "pseudo_dstar_susp": 0.010869565217391304,
            "pseudo_tarantula_susp": 0.00032829940906106366,
            "pseudo_op2_susp": 0.010869565217391304,
            "pseudo_barinel_susp": 0.00032829940906106366
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._download_xml#298",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._download_xml(self, url_or_request, video_id, note='Downloading XML', errnote='Unable to download XML', transform_source=None, fatal=True)",
        "snippet": "    def _download_xml(self, url_or_request, video_id,\n                      note='Downloading XML', errnote='Unable to download XML',\n                      transform_source=None, fatal=True):\n        \"\"\"Return the xml as an xml.etree.ElementTree.Element\"\"\"\n        xml_string = self._download_webpage(\n            url_or_request, video_id, note, errnote, fatal=fatal)\n        if xml_string is False:\n            return xml_string\n        if transform_source:\n            xml_string = transform_source(xml_string)\n        return xml.etree.ElementTree.fromstring(xml_string.encode('utf-8'))",
        "begin_line": 298,
        "end_line": 308,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0021929824561403508,
            "pseudo_dstar_susp": 0.002564102564102564,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.002564102564102564,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._download_json#310",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._download_json(self, url_or_request, video_id, note='Downloading JSON metadata', errnote='Unable to download JSON metadata', transform_source=None, fatal=True)",
        "snippet": "    def _download_json(self, url_or_request, video_id,\n                       note='Downloading JSON metadata',\n                       errnote='Unable to download JSON metadata',\n                       transform_source=None,\n                       fatal=True):\n        json_string = self._download_webpage(\n            url_or_request, video_id, note, errnote, fatal=fatal)\n        if (not fatal) and json_string is False:\n            return None\n        if transform_source:\n            json_string = transform_source(json_string)\n        try:\n            return json.loads(json_string)\n        except ValueError as ve:\n            raise ExtractorError('Failed to download JSON', cause=ve)",
        "begin_line": 310,
        "end_line": 324,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0031545741324921135,
            "pseudo_dstar_susp": 0.0031847133757961785,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0031847133757961785,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.report_warning#326",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.report_warning(self, msg, video_id=None)",
        "snippet": "    def report_warning(self, msg, video_id=None):\n        idstr = '' if video_id is None else '%s: ' % video_id\n        self._downloader.report_warning(\n            '[%s] %s%s' % (self.IE_NAME, idstr, msg))",
        "begin_line": 326,
        "end_line": 329,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007692307692307692,
            "pseudo_dstar_susp": 0.0006273525721455458,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006273525721455458,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.to_screen#331",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.to_screen(self, msg)",
        "snippet": "    def to_screen(self, msg):\n        \"\"\"Print msg to screen, prefixing it with '[ie_name]'\"\"\"\n        self._downloader.to_screen('[%s] %s' % (self.IE_NAME, msg))",
        "begin_line": 331,
        "end_line": 333,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.041666666666666664,
            "pseudo_dstar_susp": 0.013513513513513514,
            "pseudo_tarantula_susp": 0.0003183699458771092,
            "pseudo_op2_susp": 0.013513513513513514,
            "pseudo_barinel_susp": 0.00031857279388340236
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.report_extraction#335",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.report_extraction(self, id_or_name)",
        "snippet": "    def report_extraction(self, id_or_name):\n        \"\"\"Report information extraction.\"\"\"\n        self.to_screen('%s: Extracting information' % id_or_name)",
        "begin_line": 335,
        "end_line": 337,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.003194888178913738,
            "pseudo_dstar_susp": 0.003115264797507788,
            "pseudo_tarantula_susp": 0.0003355704697986577,
            "pseudo_op2_susp": 0.003115264797507788,
            "pseudo_barinel_susp": 0.0003355704697986577
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.report_download_webpage#339",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.report_download_webpage(self, video_id)",
        "snippet": "    def report_download_webpage(self, video_id):\n        \"\"\"Report webpage download.\"\"\"\n        self.to_screen('%s: Downloading webpage' % video_id)",
        "begin_line": 339,
        "end_line": 341,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.003952569169960474,
            "pseudo_dstar_susp": 0.0038910505836575876,
            "pseudo_tarantula_susp": 0.0003274394237066143,
            "pseudo_op2_susp": 0.0038910505836575876,
            "pseudo_barinel_susp": 0.0003274394237066143
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.report_age_confirmation#343",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.report_age_confirmation(self)",
        "snippet": "    def report_age_confirmation(self):\n        \"\"\"Report attempt to confirm age.\"\"\"\n        self.to_screen('Confirming age')",
        "begin_line": 343,
        "end_line": 345,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009541984732824427,
            "pseudo_dstar_susp": 0.000757002271006813,
            "pseudo_tarantula_susp": 0.00030102347983142685,
            "pseudo_op2_susp": 0.000757002271006813,
            "pseudo_barinel_susp": 0.00030102347983142685
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.report_login#347",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.report_login(self)",
        "snippet": "    def report_login(self):\n        \"\"\"Report attempt to log in.\"\"\"\n        self.to_screen('Logging in')",
        "begin_line": 347,
        "end_line": 349,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.url_result#353",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.url_result(url, ie=None, video_id=None)",
        "snippet": "    def url_result(url, ie=None, video_id=None):\n        \"\"\"Returns a url that points to a page that should be processed\"\"\"\n        #TODO: ie should be the class used for getting the info\n        video_info = {'_type': 'url',\n                      'url': url,\n                      'ie_key': ie}\n        if video_id is not None:\n            video_info['id'] = video_id\n        return video_info",
        "begin_line": 353,
        "end_line": 361,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0022123893805309734,
            "pseudo_dstar_susp": 0.0022026431718061676,
            "pseudo_tarantula_susp": 0.00029761904761904765,
            "pseudo_op2_susp": 0.0022026431718061676,
            "pseudo_barinel_susp": 0.00029761904761904765
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.playlist_result#363",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.playlist_result(entries, playlist_id=None, playlist_title=None)",
        "snippet": "    def playlist_result(entries, playlist_id=None, playlist_title=None):\n        \"\"\"Returns a playlist\"\"\"\n        video_info = {'_type': 'playlist',\n                      'entries': entries}\n        if playlist_id:\n            video_info['id'] = playlist_id\n        if playlist_title:\n            video_info['title'] = playlist_title\n        return video_info",
        "begin_line": 363,
        "end_line": 371,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008424599831508003,
            "pseudo_dstar_susp": 0.0006743088334457181,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006743088334457181,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._search_regex#373",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._search_regex(self, pattern, string, name, default=_NO_DEFAULT, fatal=True, flags=0)",
        "snippet": "    def _search_regex(self, pattern, string, name, default=_NO_DEFAULT, fatal=True, flags=0):\n        \"\"\"\n        Perform a regex search on the given string, using a single or a list of\n        patterns returning the first matching group.\n        In case of failure return a default value or raise a WARNING or a\n        RegexNotFoundError, depending on fatal, specifying the field name.\n        \"\"\"\n        if isinstance(pattern, (str, compat_str, compiled_regex_type)):\n            mobj = re.search(pattern, string, flags)\n        else:\n            for p in pattern:\n                mobj = re.search(p, string, flags)\n                if mobj:\n                    break\n\n        if os.name != 'nt' and sys.stderr.isatty():\n            _name = '\\033[0;34m%s\\033[0m' % name\n        else:\n            _name = name\n\n        if mobj:\n            # return the first matching group\n            return next(g for g in mobj.groups() if g is not None)\n        elif default is not _NO_DEFAULT:\n            return default\n        elif fatal:\n            raise RegexNotFoundError('Unable to extract %s' % _name)\n        else:\n            self._downloader.report_warning('unable to extract %s; '\n                'please report this issue on http://yt-dl.org/bug' % _name)\n            return None",
        "begin_line": 373,
        "end_line": 403,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.003745318352059925,
            "pseudo_dstar_susp": 0.0037593984962406013,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0037593984962406013,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._html_search_regex#405",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._html_search_regex(self, pattern, string, name, default=_NO_DEFAULT, fatal=True, flags=0)",
        "snippet": "    def _html_search_regex(self, pattern, string, name, default=_NO_DEFAULT, fatal=True, flags=0):\n        \"\"\"\n        Like _search_regex, but strips HTML tags and unescapes entities.\n        \"\"\"\n        res = self._search_regex(pattern, string, name, default, fatal, flags)\n        if res:\n            return clean_html(res).strip()\n        else:\n            return res",
        "begin_line": 405,
        "end_line": 413,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.003472222222222222,
            "pseudo_dstar_susp": 0.003436426116838488,
            "pseudo_tarantula_susp": 0.00033523298692591353,
            "pseudo_op2_susp": 0.003436426116838488,
            "pseudo_barinel_susp": 0.00033523298692591353
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._get_login_info#415",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._get_login_info(self)",
        "snippet": "    def _get_login_info(self):\n        \"\"\"\n        Get the the login info as (username, password)\n        It will look in the netrc file using the _NETRC_MACHINE value\n        If there's no info available, return (None, None)\n        \"\"\"\n        if self._downloader is None:\n            return (None, None)\n\n        username = None\n        password = None\n        downloader_params = self._downloader.params\n\n        # Attempt to use provided username and password or .netrc data\n        if downloader_params.get('username', None) is not None:\n            username = downloader_params['username']\n            password = downloader_params['password']\n        elif downloader_params.get('usenetrc', False):\n            try:\n                info = netrc.netrc().authenticators(self._NETRC_MACHINE)\n                if info is not None:\n                    username = info[0]\n                    password = info[2]\n                else:\n                    raise netrc.NetrcParseError('No authenticators for %s' % self._NETRC_MACHINE)\n            except (IOError, netrc.NetrcParseError) as err:\n                self._downloader.report_warning('parsing .netrc: %s' % compat_str(err))\n        \n        return (username, password)",
        "begin_line": 415,
        "end_line": 443,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.003257328990228013,
            "pseudo_dstar_susp": 0.003246753246753247,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.003246753246753247,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._get_tfa_info#445",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._get_tfa_info(self)",
        "snippet": "    def _get_tfa_info(self):\n        \"\"\"\n        Get the two-factor authentication info\n        TODO - asking the user will be required for sms/phone verify\n        currently just uses the command line option\n        If there's no info available, return None\n        \"\"\"\n        if self._downloader is None:\n            return None\n        downloader_params = self._downloader.params\n\n        if downloader_params.get('twofactor', None) is not None:\n            return downloader_params['twofactor']\n\n        return None",
        "begin_line": 445,
        "end_line": 459,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._og_regexes#463",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._og_regexes(prop)",
        "snippet": "    def _og_regexes(prop):\n        content_re = r'content=(?:\"([^>]+?)\"|\\'([^>]+?)\\')'\n        property_re = r'(?:name|property)=[\\'\"]og:%s[\\'\"]' % re.escape(prop)\n        template = r'<meta[^>]+?%s[^>]+?%s'\n        return [\n            template % (property_re, content_re),\n            template % (content_re, property_re),\n        ]",
        "begin_line": 463,
        "end_line": 470,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002785515320334262,
            "pseudo_dstar_susp": 0.002638522427440633,
            "pseudo_tarantula_susp": 0.0003224766204450177,
            "pseudo_op2_susp": 0.002638522427440633,
            "pseudo_barinel_susp": 0.0003224766204450177
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._og_search_property#472",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._og_search_property(self, prop, html, name=None, **kargs)",
        "snippet": "    def _og_search_property(self, prop, html, name=None, **kargs):\n        if name is None:\n            name = 'OpenGraph %s' % prop\n        escaped = self._search_regex(self._og_regexes(prop), html, name, flags=re.DOTALL, **kargs)\n        if escaped is None:\n            return None\n        return unescapeHTML(escaped)",
        "begin_line": 472,
        "end_line": 478,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0024096385542168677,
            "pseudo_dstar_susp": 0.0024096385542168677,
            "pseudo_tarantula_susp": 0.0003224766204450177,
            "pseudo_op2_susp": 0.0024096385542168677,
            "pseudo_barinel_susp": 0.0003224766204450177
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._og_search_thumbnail#480",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._og_search_thumbnail(self, html, **kargs)",
        "snippet": "    def _og_search_thumbnail(self, html, **kargs):\n        return self._og_search_property('image', html, 'thumbnail url', fatal=False, **kargs)",
        "begin_line": 480,
        "end_line": 481,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007194244604316547,
            "pseudo_dstar_susp": 0.0006729475100942127,
            "pseudo_tarantula_susp": 0.0002880184331797235,
            "pseudo_op2_susp": 0.0006729475100942127,
            "pseudo_barinel_susp": 0.0002880184331797235
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._og_search_description#483",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._og_search_description(self, html, **kargs)",
        "snippet": "    def _og_search_description(self, html, **kargs):\n        return self._og_search_property('description', html, fatal=False, **kargs)",
        "begin_line": 483,
        "end_line": 484,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0015772870662460567,
            "pseudo_dstar_susp": 0.0012903225806451613,
            "pseudo_tarantula_susp": 0.00031486146095717883,
            "pseudo_op2_susp": 0.0012903225806451613,
            "pseudo_barinel_susp": 0.00031496062992125983
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._og_search_title#486",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._og_search_title(self, html, **kargs)",
        "snippet": "    def _og_search_title(self, html, **kargs):\n        return self._og_search_property('title', html, **kargs)",
        "begin_line": 486,
        "end_line": 487,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002347417840375587,
            "pseudo_dstar_susp": 0.0023148148148148147,
            "pseudo_tarantula_susp": 0.00033145508783559825,
            "pseudo_op2_susp": 0.0023148148148148147,
            "pseudo_barinel_susp": 0.00033145508783559825
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._og_search_video_url#489",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._og_search_video_url(self, html, name='video url', secure=True, **kargs)",
        "snippet": "    def _og_search_video_url(self, html, name='video url', secure=True, **kargs):\n        regexes = self._og_regexes('video') + self._og_regexes('video:url')\n        if secure:\n            regexes = self._og_regexes('video:secure_url') + regexes\n        return self._html_search_regex(regexes, html, name, **kargs)",
        "begin_line": 489,
        "end_line": 493,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0012919896640826874,
            "pseudo_dstar_susp": 0.000998003992015968,
            "pseudo_tarantula_susp": 0.0003224766204450177,
            "pseudo_op2_susp": 0.000998003992015968,
            "pseudo_barinel_susp": 0.0003224766204450177
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._og_search_url#495",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._og_search_url(self, html, **kargs)",
        "snippet": "    def _og_search_url(self, html, **kargs):\n        return self._og_search_property('url', html, **kargs)",
        "begin_line": 495,
        "end_line": 496,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._html_search_meta#498",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._html_search_meta(self, name, html, display_name=None, fatal=False, **kwargs)",
        "snippet": "    def _html_search_meta(self, name, html, display_name=None, fatal=False, **kwargs):\n        if display_name is None:\n            display_name = name\n        return self._html_search_regex(\n            r'''(?ix)<meta\n                    (?=[^>]+(?:itemprop|name|property)=[\"\\']?%s[\"\\']?)\n                    [^>]+content=[\"\\']([^\"\\']+)[\"\\']''' % re.escape(name),\n            html, display_name, fatal=fatal, **kwargs)",
        "begin_line": 498,
        "end_line": 505,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0022371364653243847,
            "pseudo_dstar_susp": 0.0020964360587002098,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0020964360587002098,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._dc_search_uploader#507",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._dc_search_uploader(self, html)",
        "snippet": "    def _dc_search_uploader(self, html):\n        return self._html_search_meta('dc.creator', html, 'uploader')",
        "begin_line": 507,
        "end_line": 508,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._rta_search#510",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._rta_search(self, html)",
        "snippet": "    def _rta_search(self, html):\n        # See http://www.rtalabel.org/index.php?content=howtofaq#single\n        if re.search(r'(?ix)<meta\\s+name=\"rating\"\\s+'\n                     r'     content=\"RTA-5042-1996-1400-1577-RTA\"',\n                     html):\n            return 18\n        return 0",
        "begin_line": 510,
        "end_line": 516,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0024390243902439024,
            "pseudo_dstar_susp": 0.002369668246445498,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.002369668246445498,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._media_rating_search#518",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._media_rating_search(self, html)",
        "snippet": "    def _media_rating_search(self, html):\n        # See http://www.tjg-designs.com/WP/metadata-code-examples-adding-metadata-to-your-web-pages/\n        rating = self._html_search_meta('rating', html)\n\n        if not rating:\n            return None\n\n        RATING_TABLE = {\n            'safe for kids': 0,\n            'general': 8,\n            '14 years': 14,\n            'mature': 17,\n            'restricted': 19,\n        }\n        return RATING_TABLE.get(rating.lower(), None)",
        "begin_line": 518,
        "end_line": 532,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._twitter_search_player#534",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._twitter_search_player(self, html)",
        "snippet": "    def _twitter_search_player(self, html):\n        return self._html_search_meta('twitter:player', html,\n            'twitter card player')",
        "begin_line": 534,
        "end_line": 536,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._sort_formats#538",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._sort_formats(self, formats)",
        "snippet": "    def _sort_formats(self, formats):\n        if not formats:\n            raise ExtractorError('No video formats found')\n\n        def _formats_key(f):\n            # TODO remove the following workaround\n            from ..utils import determine_ext\n            if not f.get('ext') and 'url' in f:\n                f['ext'] = determine_ext(f['url'])\n\n            preference = f.get('preference')\n            if preference is None:\n                proto = f.get('protocol')\n                if proto is None:\n                    proto = compat_urllib_parse_urlparse(f.get('url', '')).scheme\n\n                preference = 0 if proto in ['http', 'https'] else -0.1\n                if f.get('ext') in ['f4f', 'f4m']:  # Not yet supported\n                    preference -= 0.5\n\n            if f.get('vcodec') == 'none':  # audio only\n                if self._downloader.params.get('prefer_free_formats'):\n                    ORDER = ['aac', 'mp3', 'm4a', 'webm', 'ogg', 'opus']\n                else:\n                    ORDER = ['webm', 'opus', 'ogg', 'mp3', 'aac', 'm4a']\n                ext_preference = 0\n                try:\n                    audio_ext_preference = ORDER.index(f['ext'])\n                except ValueError:\n                    audio_ext_preference = -1\n            else:\n                if self._downloader.params.get('prefer_free_formats'):\n                    ORDER = ['flv', 'mp4', 'webm']\n                else:\n                    ORDER = ['webm', 'flv', 'mp4']\n                try:\n                    ext_preference = ORDER.index(f['ext'])\n                except ValueError:\n                    ext_preference = -1\n                audio_ext_preference = 0\n\n            return (\n                preference,\n                f.get('quality') if f.get('quality') is not None else -1,\n                f.get('height') if f.get('height') is not None else -1,\n                f.get('width') if f.get('width') is not None else -1,\n                ext_preference,\n                f.get('tbr') if f.get('tbr') is not None else -1,\n                f.get('vbr') if f.get('vbr') is not None else -1,\n                f.get('abr') if f.get('abr') is not None else -1,\n                audio_ext_preference,\n                f.get('filesize') if f.get('filesize') is not None else -1,\n                f.get('filesize_approx') if f.get('filesize_approx') is not None else -1,\n                f.get('format_id'),\n            )\n        formats.sort(key=_formats_key)",
        "begin_line": 538,
        "end_line": 593,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007692307692307692,
            "pseudo_dstar_susp": 0.0010193679918450561,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0010193679918450561,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._formats_key#542",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._formats_key(f)",
        "snippet": "        def _formats_key(f):\n            # TODO remove the following workaround\n            from ..utils import determine_ext\n            if not f.get('ext') and 'url' in f:\n                f['ext'] = determine_ext(f['url'])\n\n            preference = f.get('preference')\n            if preference is None:\n                proto = f.get('protocol')\n                if proto is None:\n                    proto = compat_urllib_parse_urlparse(f.get('url', '')).scheme\n\n                preference = 0 if proto in ['http', 'https'] else -0.1\n                if f.get('ext') in ['f4f', 'f4m']:  # Not yet supported\n                    preference -= 0.5\n\n            if f.get('vcodec') == 'none':  # audio only\n                if self._downloader.params.get('prefer_free_formats'):\n                    ORDER = ['aac', 'mp3', 'm4a', 'webm', 'ogg', 'opus']\n                else:\n                    ORDER = ['webm', 'opus', 'ogg', 'mp3', 'aac', 'm4a']\n                ext_preference = 0\n                try:\n                    audio_ext_preference = ORDER.index(f['ext'])\n                except ValueError:\n                    audio_ext_preference = -1\n            else:\n                if self._downloader.params.get('prefer_free_formats'):\n                    ORDER = ['flv', 'mp4', 'webm']\n                else:\n                    ORDER = ['webm', 'flv', 'mp4']\n                try:\n                    ext_preference = ORDER.index(f['ext'])\n                except ValueError:\n                    ext_preference = -1\n                audio_ext_preference = 0\n\n            return (\n                preference,\n                f.get('quality') if f.get('quality') is not None else -1,\n                f.get('height') if f.get('height') is not None else -1,\n                f.get('width') if f.get('width') is not None else -1,\n                ext_preference,\n                f.get('tbr') if f.get('tbr') is not None else -1,\n                f.get('vbr') if f.get('vbr') is not None else -1,\n                f.get('abr') if f.get('abr') is not None else -1,\n                audio_ext_preference,\n                f.get('filesize') if f.get('filesize') is not None else -1,\n                f.get('filesize_approx') if f.get('filesize_approx') is not None else -1,\n                f.get('format_id'),\n            )",
        "begin_line": 542,
        "end_line": 592,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007199424046076314,
            "pseudo_dstar_susp": 0.001282051282051282,
            "pseudo_tarantula_susp": 0.00022336385972749609,
            "pseudo_op2_susp": 0.001282051282051282,
            "pseudo_barinel_susp": 0.00022341376228775692
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.http_scheme#595",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.http_scheme(self)",
        "snippet": "    def http_scheme(self):\n        \"\"\" Either \"https:\" or \"https:\", depending on the user's preferences \"\"\"\n        return (\n            'http:'\n            if self._downloader.params.get('prefer_insecure', False)\n            else 'https:')",
        "begin_line": 595,
        "end_line": 600,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._proto_relative_url#602",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._proto_relative_url(self, url, scheme=None)",
        "snippet": "    def _proto_relative_url(self, url, scheme=None):\n        if url is None:\n            return url\n        if url.startswith('//'):\n            if scheme is None:\n                scheme = self.http_scheme()\n            return scheme + url\n        else:\n            return url",
        "begin_line": 602,
        "end_line": 610,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._sleep#612",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._sleep(self, timeout, video_id, msg_template=None)",
        "snippet": "    def _sleep(self, timeout, video_id, msg_template=None):\n        if msg_template is None:\n            msg_template = '%(video_id)s: Waiting for %(timeout)s seconds'\n        msg = msg_template % {'video_id': video_id, 'timeout': timeout}\n        self.to_screen(msg)\n        time.sleep(timeout)",
        "begin_line": 612,
        "end_line": 617,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._extract_f4m_formats#619",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._extract_f4m_formats(self, manifest_url, video_id)",
        "snippet": "    def _extract_f4m_formats(self, manifest_url, video_id):\n        manifest = self._download_xml(\n            manifest_url, video_id, 'Downloading f4m manifest',\n            'Unable to download f4m manifest')\n\n        formats = []\n        media_nodes = manifest.findall('{http://ns.adobe.com/f4m/1.0}media')\n        for i, media_el in enumerate(media_nodes):\n            tbr = int_or_none(media_el.attrib.get('bitrate'))\n            format_id = 'f4m-%d' % (i if tbr is None else tbr)\n            formats.append({\n                'format_id': format_id,\n                'url': manifest_url,\n                'ext': 'flv',\n                'tbr': tbr,\n                'width': int_or_none(media_el.attrib.get('width')),\n                'height': int_or_none(media_el.attrib.get('height')),\n            })\n        self._sort_formats(formats)\n\n        return formats",
        "begin_line": 619,
        "end_line": 639,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._extract_m3u8_formats#641",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._extract_m3u8_formats(self, m3u8_url, video_id, ext=None)",
        "snippet": "    def _extract_m3u8_formats(self, m3u8_url, video_id, ext=None):\n        formats = [{\n            'format_id': 'm3u8-meta',\n            'url': m3u8_url,\n            'ext': ext,\n            'protocol': 'm3u8',\n            'preference': -1,\n            'resolution': 'multiple',\n            'format_note': 'Quality selection URL',\n        }]\n\n        m3u8_doc = self._download_webpage(m3u8_url, video_id)\n        last_info = None\n        kv_rex = re.compile(\n            r'(?P<key>[a-zA-Z_-]+)=(?P<val>\"[^\"]+\"|[^\",]+)(?:,|$)')\n        for line in m3u8_doc.splitlines():\n            if line.startswith('#EXT-X-STREAM-INF:'):\n                last_info = {}\n                for m in kv_rex.finditer(line):\n                    v = m.group('val')\n                    if v.startswith('\"'):\n                        v = v[1:-1]\n                    last_info[m.group('key')] = v\n            elif line.startswith('#') or not line.strip():\n                continue\n            else:\n                if last_info is None:\n                    formats.append({'url': line})\n                    continue\n                tbr = int_or_none(last_info.get('BANDWIDTH'), scale=1000)\n\n                f = {\n                    'format_id': 'm3u8-%d' % (tbr if tbr else len(formats)),\n                    'url': line.strip(),\n                    'tbr': tbr,\n                    'ext': ext,\n                }\n                codecs = last_info.get('CODECS')\n                if codecs:\n                    # TODO: looks like video codec is not always necessarily goes first\n                    va_codecs = codecs.split(',')\n                    if va_codecs[0]:\n                        f['vcodec'] = va_codecs[0].partition('.')[0]\n                    if len(va_codecs) > 1 and va_codecs[1]:\n                        f['acodec'] = va_codecs[1].partition('.')[0]\n                resolution = last_info.get('RESOLUTION')\n                if resolution:\n                    width_str, height_str = resolution.split('x')\n                    f['width'] = int(width_str)\n                    f['height'] = int(height_str)\n                formats.append(f)\n                last_info = {}\n        self._sort_formats(formats)\n        return formats",
        "begin_line": 641,
        "end_line": 694,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.common.SearchInfoExtractor._make_valid_url#705",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.SearchInfoExtractor",
        "signature": "youtube_dl.extractor.common.SearchInfoExtractor._make_valid_url(cls)",
        "snippet": "    def _make_valid_url(cls):\n        return r'%s(?P<prefix>|[1-9][0-9]*|all):(?P<query>[\\s\\S]+)' % cls._SEARCH_KEY",
        "begin_line": 705,
        "end_line": 706,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0038910505836575876,
            "pseudo_dstar_susp": 0.004,
            "pseudo_tarantula_susp": 0.0002991325157044571,
            "pseudo_op2_susp": 0.004,
            "pseudo_barinel_susp": 0.0002991325157044571
        }
    },
    {
        "name": "youtube_dl.extractor.common.SearchInfoExtractor.suitable#709",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.SearchInfoExtractor",
        "signature": "youtube_dl.extractor.common.SearchInfoExtractor.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return re.match(cls._make_valid_url(), url) is not None",
        "begin_line": 709,
        "end_line": 710,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0038910505836575876,
            "pseudo_dstar_susp": 0.004,
            "pseudo_tarantula_susp": 0.0002991325157044571,
            "pseudo_op2_susp": 0.004,
            "pseudo_barinel_susp": 0.0002991325157044571
        }
    },
    {
        "name": "youtube_dl.extractor.common.SearchInfoExtractor._real_extract#712",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.SearchInfoExtractor",
        "signature": "youtube_dl.extractor.common.SearchInfoExtractor._real_extract(self, query)",
        "snippet": "    def _real_extract(self, query):\n        mobj = re.match(self._make_valid_url(), query)\n        if mobj is None:\n            raise ExtractorError('Invalid search query \"%s\"' % query)\n\n        prefix = mobj.group('prefix')\n        query = mobj.group('query')\n        if prefix == '':\n            return self._get_n_results(query, 1)\n        elif prefix == 'all':\n            return self._get_n_results(query, self._MAX_RESULTS)\n        else:\n            n = int(prefix)\n            if n <= 0:\n                raise ExtractorError('invalid download number %s for query \"%s\"' % (n, query))\n            elif n > self._MAX_RESULTS:\n                self._downloader.report_warning('%s returns max %i results (you requested %i)' % (self._SEARCH_KEY, self._MAX_RESULTS, n))\n                n = self._MAX_RESULTS\n            return self._get_n_results(query, n)",
        "begin_line": 712,
        "end_line": 730,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.common.SearchInfoExtractor._get_n_results#732",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.SearchInfoExtractor",
        "signature": "youtube_dl.extractor.common.SearchInfoExtractor._get_n_results(self, query, n)",
        "snippet": "    def _get_n_results(self, query, n):\n        \"\"\"Get a specified number of results for a query\"\"\"\n        raise NotImplementedError(\"This method must be implemented by subclasses\")",
        "begin_line": 732,
        "end_line": 734,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.mixcloud.MixcloudIE.check_urls#36",
        "src_path": "youtube_dl/extractor/mixcloud.py",
        "class_name": "youtube_dl.extractor.mixcloud.MixcloudIE",
        "signature": "youtube_dl.extractor.mixcloud.MixcloudIE.check_urls(self, url_list)",
        "snippet": "    def check_urls(self, url_list):\n        \"\"\"Returns 1st active url from list\"\"\"\n        for url in url_list:\n            try:\n                # We only want to know if the request succeed\n                # don't download the whole file\n                self._request_webpage(HEADRequest(url), None, False)\n                return url\n            except ExtractorError:\n                url = None\n\n        return None",
        "begin_line": 36,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.mixcloud.MixcloudIE._get_url#49",
        "src_path": "youtube_dl/extractor/mixcloud.py",
        "class_name": "youtube_dl.extractor.mixcloud.MixcloudIE",
        "signature": "youtube_dl.extractor.mixcloud.MixcloudIE._get_url(self, template_url)",
        "snippet": "    def _get_url(self, template_url):\n        return self.check_urls(template_url % i for i in range(30))",
        "begin_line": 49,
        "end_line": 50,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.mixcloud.MixcloudIE._real_extract#52",
        "src_path": "youtube_dl/extractor/mixcloud.py",
        "class_name": "youtube_dl.extractor.mixcloud.MixcloudIE",
        "signature": "youtube_dl.extractor.mixcloud.MixcloudIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        uploader = mobj.group(1)\n        cloudcast_name = mobj.group(2)\n        track_id = compat_urllib_parse.unquote('-'.join((uploader, cloudcast_name)))\n\n        webpage = self._download_webpage(url, track_id)\n\n        preview_url = self._search_regex(\n            r'\\s(?:data-preview-url|m-preview)=\"(.+?)\"', webpage, 'preview url')\n        song_url = preview_url.replace('/previews/', '/c/originals/')\n        template_url = re.sub(r'(stream\\d*)', 'stream%d', song_url)\n        final_song_url = self._get_url(template_url)\n        if final_song_url is None:\n            self.to_screen('Trying with m4a extension')\n            template_url = template_url.replace('.mp3', '.m4a').replace('originals/', 'm4a/64/')\n            final_song_url = self._get_url(template_url)\n        if final_song_url is None:\n            raise ExtractorError('Unable to extract track url')\n\n        PREFIX = (\n            r'<div class=\"cloudcast-play-button-container\"'\n            r'(?:\\s+[a-zA-Z0-9-]+(?:=\"[^\"]+\")?)*?\\s+')\n        title = self._html_search_regex(\n            PREFIX + r'm-title=\"([^\"]+)\"', webpage, 'title')\n        thumbnail = self._proto_relative_url(self._html_search_regex(\n            PREFIX + r'm-thumbnail-url=\"([^\"]+)\"', webpage, 'thumbnail',\n            fatal=False))\n        uploader = self._html_search_regex(\n            PREFIX + r'm-owner-name=\"([^\"]+)\"',\n            webpage, 'uploader', fatal=False)\n        uploader_id = self._search_regex(\n            r'\\s+\"profile\": \"([^\"]+)\",', webpage, 'uploader id', fatal=False)\n        description = self._og_search_description(webpage)\n        like_count = int_or_none(self._search_regex(\n            r'<meta itemprop=\"interactionCount\" content=\"UserLikes:([0-9]+)\"',\n            webpage, 'like count', fatal=False))\n        view_count = int_or_none(self._search_regex(\n            r'<meta itemprop=\"interactionCount\" content=\"UserPlays:([0-9]+)\"',\n            webpage, 'play count', fatal=False))\n        timestamp = parse_iso8601(self._search_regex(\n            r'<time itemprop=\"dateCreated\" datetime=\"([^\"]+)\">',\n            webpage, 'upload date'))\n\n        return {\n            'id': track_id,\n            'title': title,\n            'url': final_song_url,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'timestamp': timestamp,\n            'view_count': view_count,\n            'like_count': like_count,\n        }",
        "begin_line": 52,
        "end_line": 107,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.normalboots.NormalbootsIE._real_extract#28",
        "src_path": "youtube_dl/extractor/normalboots.py",
        "class_name": "youtube_dl.extractor.normalboots.NormalbootsIE",
        "signature": "youtube_dl.extractor.normalboots.NormalbootsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n\n        webpage = self._download_webpage(url, video_id)\n        video_uploader = self._html_search_regex(r'Posted\\sby\\s<a\\shref=\"[A-Za-z0-9/]*\">(?P<uploader>[A-Za-z]*)\\s</a>',\n            webpage, 'uploader')\n        raw_upload_date = self._html_search_regex('<span style=\"text-transform:uppercase; font-size:inherit;\">[A-Za-z]+, (?P<date>.*)</span>',\n            webpage, 'date')\n        video_upload_date = unified_strdate(raw_upload_date)\n\n        player_url = self._html_search_regex(r'<iframe\\swidth=\"[0-9]+\"\\sheight=\"[0-9]+\"\\ssrc=\"(?P<url>[\\S]+)\"', webpage, 'url')\n        player_page = self._download_webpage(player_url, video_id)\n        video_url = self._html_search_regex(r\"file:\\s'(?P<file>[^']+\\.mp4)'\", player_page, 'file')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': self._og_search_title(webpage),\n            'description': self._og_search_description(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'uploader': video_uploader,\n            'upload_date': video_upload_date,\n        }",
        "begin_line": 28,
        "end_line": 51,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.keezmovies.KeezMoviesIE._real_extract#29",
        "src_path": "youtube_dl/extractor/keezmovies.py",
        "class_name": "youtube_dl.extractor.keezmovies.KeezMoviesIE",
        "signature": "youtube_dl.extractor.keezmovies.KeezMoviesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n\n        req = compat_urllib_request.Request(url)\n        req.add_header('Cookie', 'age_verified=1')\n        webpage = self._download_webpage(req, video_id)\n\n        # embedded video\n        mobj = re.search(r'href=\"([^\"]+)\"></iframe>', webpage)\n        if mobj:\n            embedded_url = mobj.group(1)\n            return self.url_result(embedded_url)\n\n        video_title = self._html_search_regex(r'<h1 [^>]*>([^<]+)', webpage, 'title')\n        video_url = compat_urllib_parse.unquote(self._html_search_regex(r'video_url=(.+?)&amp;', webpage, 'video_url'))\n        if 'encrypted=true' in webpage:\n            password = self._html_search_regex(r'video_title=(.+?)&amp;', webpage, 'password')\n            video_url = aes_decrypt_text(video_url, password, 32).decode('utf-8')\n        path = compat_urllib_parse_urlparse(video_url).path\n        extension = os.path.splitext(path)[1][1:]\n        format = path.split('/')[4].split('_')[:2]\n        format = \"-\".join(format)\n\n        age_limit = self._rta_search(webpage)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'url': video_url,\n            'ext': extension,\n            'format': format,\n            'format_id': format,\n            'age_limit': age_limit,\n        }",
        "begin_line": 29,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.flickr.FlickrIE._real_extract#26",
        "src_path": "youtube_dl/extractor/flickr.py",
        "class_name": "youtube_dl.extractor.flickr.FlickrIE",
        "signature": "youtube_dl.extractor.flickr.FlickrIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n        video_uploader_id = mobj.group('uploader_id')\n        webpage_url = 'http://www.flickr.com/photos/' + video_uploader_id + '/' + video_id\n        webpage = self._download_webpage(webpage_url, video_id)\n\n        secret = self._search_regex(r\"photo_secret: '(\\w+)'\", webpage, 'secret')\n\n        first_url = 'https://secure.flickr.com/apps/video/video_mtl_xml.gne?v=x&photo_id=' + video_id + '&secret=' + secret + '&bitrate=700&target=_self'\n        first_xml = self._download_webpage(first_url, video_id, 'Downloading first data webpage')\n\n        node_id = self._html_search_regex(r'<Item id=\"id\">(\\d+-\\d+)</Item>',\n            first_xml, 'node_id')\n\n        second_url = 'https://secure.flickr.com/video_playlist.gne?node_id=' + node_id + '&tech=flash&mode=playlist&bitrate=700&secret=' + secret + '&rd=video.yahoo.com&noad=1'\n        second_xml = self._download_webpage(second_url, video_id, 'Downloading second data webpage')\n\n        self.report_extraction(video_id)\n\n        mobj = re.search(r'<STREAM APP=\"(.+?)\" FULLPATH=\"(.+?)\"', second_xml)\n        if mobj is None:\n            raise ExtractorError('Unable to extract video url')\n        video_url = mobj.group(1) + unescapeHTML(mobj.group(2))\n\n        return [{\n            'id':          video_id,\n            'url':         video_url,\n            'ext':         'mp4',\n            'title':       self._og_search_title(webpage),\n            'description': self._og_search_description(webpage),\n            'thumbnail':   self._og_search_thumbnail(webpage),\n            'uploader_id': video_uploader_id,\n        }]",
        "begin_line": 26,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.internetvideoarchive.InternetVideoArchiveIE._build_url#25",
        "src_path": "youtube_dl/extractor/internetvideoarchive.py",
        "class_name": "youtube_dl.extractor.internetvideoarchive.InternetVideoArchiveIE",
        "signature": "youtube_dl.extractor.internetvideoarchive.InternetVideoArchiveIE._build_url(query)",
        "snippet": "    def _build_url(query):\n        return 'http://video.internetvideoarchive.net/flash/players/flashconfiguration.aspx?' + query",
        "begin_line": 25,
        "end_line": 26,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.internetvideoarchive.InternetVideoArchiveIE._real_extract#38",
        "src_path": "youtube_dl/extractor/internetvideoarchive.py",
        "class_name": "youtube_dl.extractor.internetvideoarchive.InternetVideoArchiveIE",
        "signature": "youtube_dl.extractor.internetvideoarchive.InternetVideoArchiveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        query = compat_urlparse.urlparse(url).query\n        query_dic = compat_urlparse.parse_qs(query)\n        video_id = query_dic['publishedid'][0]\n        url = self._build_url(query)\n\n        flashconfiguration = self._download_xml(url, video_id,\n            u'Downloading flash configuration')\n        file_url = flashconfiguration.find('file').text\n        file_url = file_url.replace('/playlist.aspx', '/mrssplaylist.aspx')\n        # Replace some of the parameters in the query to get the best quality\n        # and http links (no m3u8 manifests)\n        file_url = re.sub(r'(?<=\\?)(.+)$',\n            lambda m: self._clean_query(m.group()),\n            file_url)\n        info = self._download_xml(file_url, video_id,\n            u'Downloading video info')\n        item = info.find('channel/item')\n\n        def _bp(p):\n            return xpath_with_ns(p,\n                {'media': 'http://search.yahoo.com/mrss/',\n                'jwplayer': 'http://developer.longtailvideo.com/trac/wiki/FlashFormats'})\n        formats = []\n        for content in item.findall(_bp('media:group/media:content')):\n            attr = content.attrib\n            f_url = attr['url']\n            width = int(attr['width'])\n            bitrate = int(attr['bitrate'])\n            format_id = '%d-%dk' % (width, bitrate)\n            formats.append({\n                'format_id': format_id,\n                'url': f_url,\n                'width': width,\n                'tbr': bitrate,\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': item.find('title').text,\n            'formats': formats,\n            'thumbnail': item.find(_bp('media:thumbnail')).attrib['url'],\n            'description': item.find('description').text,\n            'duration': int(attr['duration']),\n        }",
        "begin_line": 38,
        "end_line": 84,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.huffpost.HuffPostIE._real_extract#35",
        "src_path": "youtube_dl/extractor/huffpost.py",
        "class_name": "youtube_dl.extractor.huffpost.HuffPostIE",
        "signature": "youtube_dl.extractor.huffpost.HuffPostIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        api_url = 'http://embed.live.huffingtonpost.com/api/segments/%s.json' % video_id\n        data = self._download_json(api_url, video_id)['data']\n\n        video_title = data['title']\n        duration = parse_duration(data['running_time'])\n        upload_date = unified_strdate(data['schedule']['starts_at'])\n        description = data.get('description')\n\n        thumbnails = []\n        for url in data['images'].values():\n            m = re.match('.*-([0-9]+x[0-9]+)\\.', url)\n            if not m:\n                continue\n            thumbnails.append({\n                'url': url,\n                'resolution': m.group(1),\n            })\n\n        formats = [{\n            'format': key,\n            'format_id': key.replace('/', '.'),\n            'ext': 'mp4',\n            'url': url,\n            'vcodec': 'none' if key.startswith('audio/') else None,\n        } for key, url in data['sources']['live'].items()]\n        if data.get('fivemin_id'):\n            fid = data['fivemin_id']\n            fcat = str(int(fid) // 100 + 1)\n            furl = 'http://avideos.5min.com/2/' + fcat[-3:] + '/' + fcat + '/' + fid + '.mp4'\n            formats.append({\n                'format': 'fivemin',\n                'url': furl,\n                'preference': 1,\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'description': description,\n            'formats': formats,\n            'duration': duration,\n            'upload_date': upload_date,\n            'thumbnails': thumbnails,\n        }",
        "begin_line": 35,
        "end_line": 83,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.keek.KeekIE._real_extract#21",
        "src_path": "youtube_dl/extractor/keek.py",
        "class_name": "youtube_dl.extractor.keek.KeekIE",
        "signature": "youtube_dl.extractor.keek.KeekIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('videoID')\n\n        video_url = 'http://cdn.keek.com/keek/video/%s' % video_id\n        thumbnail = 'http://cdn.keek.com/keek/thumbnail/%s/w100/h75' % video_id\n        webpage = self._download_webpage(url, video_id)\n\n        uploader = self._html_search_regex(\n            r'<div class=\"user-name-and-bio\">[\\S\\s]+?<h2>(?P<uploader>.+?)</h2>',\n            webpage, 'uploader', fatal=False)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'ext': 'mp4',\n            'title': self._og_search_title(webpage),\n            'thumbnail': thumbnail,\n            'uploader': uploader\n        }",
        "begin_line": 21,
        "end_line": 40,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.mojvideo.MojvideoIE._real_extract#28",
        "src_path": "youtube_dl/extractor/mojvideo.py",
        "class_name": "youtube_dl.extractor.mojvideo.MojvideoIE",
        "signature": "youtube_dl.extractor.mojvideo.MojvideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        # XML is malformed\n        playerapi = self._download_webpage(\n            'http://www.mojvideo.com/playerapi.php?v=%s&t=1' % video_id, display_id)\n\n        if '<error>true</error>' in playerapi:\n            error_desc = self._html_search_regex(\n                r'<errordesc>([^<]*)</errordesc>', playerapi, 'error description', fatal=False)\n            raise ExtractorError('%s said: %s' % (self.IE_NAME, error_desc), expected=True)\n\n        title = self._html_search_regex(\n            r'<title>([^<]+)</title>', playerapi, 'title')\n        video_url = self._html_search_regex(\n            r'<file>([^<]+)</file>', playerapi, 'video URL')\n        thumbnail = self._html_search_regex(\n            r'<preview>([^<]+)</preview>', playerapi, 'thumbnail', fatal=False)\n        duration = parse_duration(self._html_search_regex(\n            r'<duration>([^<]+)</duration>', playerapi, 'duration', fatal=False))\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'url': video_url,\n            'title': title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n        }",
        "begin_line": 28,
        "end_line": 58,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.bliptv.BlipTVIE._real_extract#70",
        "src_path": "youtube_dl/extractor/bliptv.py",
        "class_name": "youtube_dl.extractor.bliptv.BlipTVIE",
        "signature": "youtube_dl.extractor.bliptv.BlipTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        lookup_id = mobj.group('lookup_id')\n\n        # See https://github.com/rg3/youtube-dl/issues/857\n        if lookup_id:\n            info_page = self._download_webpage(\n                'http://blip.tv/play/%s.x?p=1' % lookup_id, lookup_id, 'Resolving lookup id')\n            video_id = self._search_regex(r'data-episode-id=\"([0-9]+)', info_page, 'video_id')\n        else:\n            video_id = mobj.group('id')\n\n        rss = self._download_xml('http://blip.tv/rss/flash/%s' % video_id, video_id, 'Downloading video RSS')\n\n        def blip(s):\n            return '{http://blip.tv/dtd/blip/1.0}%s' % s\n\n        def media(s):\n            return '{http://search.yahoo.com/mrss/}%s' % s\n\n        def itunes(s):\n            return '{http://www.itunes.com/dtds/podcast-1.0.dtd}%s' % s\n\n        item = rss.find('channel/item')\n\n        video_id = item.find(blip('item_id')).text\n        title = item.find('./title').text\n        description = clean_html(compat_str(item.find(blip('puredescription')).text))\n        timestamp = parse_iso8601(item.find(blip('datestamp')).text)\n        uploader = item.find(blip('user')).text\n        uploader_id = item.find(blip('userid')).text\n        duration = int(item.find(blip('runtime')).text)\n        media_thumbnail = item.find(media('thumbnail'))\n        thumbnail = media_thumbnail.get('url') if media_thumbnail is not None else item.find(itunes('image')).text\n        categories = [category.text for category in item.findall('category')]\n\n        formats = []\n        subtitles = {}\n\n        media_group = item.find(media('group'))\n        for media_content in media_group.findall(media('content')):\n            url = media_content.get('url')\n            role = media_content.get(blip('role'))\n            msg = self._download_webpage(\n                url + '?showplayer=20140425131715&referrer=http://blip.tv&mask=7&skin=flashvars&view=url',\n                video_id, 'Resolving URL for %s' % role)\n            real_url = compat_urlparse.parse_qs(msg)['message'][0]\n\n            media_type = media_content.get('type')\n            if media_type == 'text/srt' or url.endswith('.srt'):\n                LANGS = {\n                    'english': 'en',\n                }\n                lang = role.rpartition('-')[-1].strip().lower()\n                langcode = LANGS.get(lang, lang)\n                subtitles[langcode] = url\n            elif media_type.startswith('video/'):\n                formats.append({\n                    'url': real_url,\n                    'format_id': role,\n                    'format_note': media_type,\n                    'vcodec': media_content.get(blip('vcodec')),\n                    'acodec': media_content.get(blip('acodec')),\n                    'filesize': media_content.get('filesize'),\n                    'width': int(media_content.get('width')),\n                    'height': int(media_content.get('height')),\n                })\n        self._sort_formats(formats)\n\n        # subtitles\n        video_subtitles = self.extract_subtitles(video_id, subtitles)\n        if self._downloader.params.get('listsubtitles', False):\n            self._list_available_subtitles(video_id, subtitles)\n            return\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'duration': duration,\n            'thumbnail': thumbnail,\n            'categories': categories,\n            'formats': formats,\n            'subtitles': video_subtitles,\n        }",
        "begin_line": 70,
        "end_line": 157,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0010030090270812437,
            "pseudo_dstar_susp": 0.0007739938080495357,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0007739938080495357,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.bliptv.BlipTVIE._download_subtitle_url#159",
        "src_path": "youtube_dl/extractor/bliptv.py",
        "class_name": "youtube_dl.extractor.bliptv.BlipTVIE",
        "signature": "youtube_dl.extractor.bliptv.BlipTVIE._download_subtitle_url(self, sub_lang, url)",
        "snippet": "    def _download_subtitle_url(self, sub_lang, url):\n        # For some weird reason, blip.tv serves a video instead of subtitles\n        # when we request with a common UA\n        req = compat_urllib_request.Request(url)\n        req.add_header('Youtubedl-user-agent', 'youtube-dl')\n        return self._download_webpage(req, None, note=False)",
        "begin_line": 159,
        "end_line": 164,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.bliptv.BlipTVUserIE._real_extract#172",
        "src_path": "youtube_dl/extractor/bliptv.py",
        "class_name": "youtube_dl.extractor.bliptv.BlipTVUserIE",
        "signature": "youtube_dl.extractor.bliptv.BlipTVUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        username = mobj.group(1)\n\n        page_base = 'http://m.blip.tv/pr/show_get_full_episode_list?users_id=%s&lite=0&esi=1'\n\n        page = self._download_webpage(url, username, 'Downloading user page')\n        mobj = re.search(r'data-users-id=\"([^\"]+)\"', page)\n        page_base = page_base % mobj.group(1)\n\n        # Download video ids using BlipTV Ajax calls. Result size per\n        # query is limited (currently to 12 videos) so we need to query\n        # page by page until there are no video ids - it means we got\n        # all of them.\n\n        video_ids = []\n        pagenum = 1\n\n        while True:\n            url = page_base + \"&page=\" + str(pagenum)\n            page = self._download_webpage(\n                url, username, 'Downloading video ids from page %d' % pagenum)\n\n            # Extract video identifiers\n            ids_in_page = []\n\n            for mobj in re.finditer(r'href=\"/([^\"]+)\"', page):\n                if mobj.group(1) not in ids_in_page:\n                    ids_in_page.append(unescapeHTML(mobj.group(1)))\n\n            video_ids.extend(ids_in_page)\n\n            # A little optimization - if current page is not\n            # \"full\", ie. does not contain PAGE_SIZE video ids then\n            # we can assume that this page is the last one - there\n            # are no more ids on further pages - no need to query\n            # again.\n\n            if len(ids_in_page) < self._PAGE_SIZE:\n                break\n\n            pagenum += 1\n\n        urls = ['http://blip.tv/%s' % video_id for video_id in video_ids]\n        url_entries = [self.url_result(vurl, 'BlipTV') for vurl in urls]\n        return [self.playlist_result(url_entries, playlist_title=username)]",
        "begin_line": 172,
        "end_line": 217,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.jsinterp.JSInterpreter.__init__#12",
        "src_path": "youtube_dl/jsinterp.py",
        "class_name": "youtube_dl.jsinterp.JSInterpreter",
        "signature": "youtube_dl.jsinterp.JSInterpreter.__init__(self, code)",
        "snippet": "    def __init__(self, code):\n        self.code = code\n        self._functions = {}\n        self._objects = {}",
        "begin_line": 12,
        "end_line": 15,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 6.729927989770509e-05,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.jsinterp.JSInterpreter.interpret_statement#17",
        "src_path": "youtube_dl/jsinterp.py",
        "class_name": "youtube_dl.jsinterp.JSInterpreter",
        "signature": "youtube_dl.jsinterp.JSInterpreter.interpret_statement(self, stmt, local_vars, allow_recursion=20)",
        "snippet": "    def interpret_statement(self, stmt, local_vars, allow_recursion=20):\n        if allow_recursion < 0:\n            raise ExtractorError('Recursion limit reached')\n\n        if stmt.startswith('var '):\n            stmt = stmt[len('var '):]\n        ass_m = re.match(r'^(?P<out>[a-z]+)(?:\\[(?P<index>[^\\]]+)\\])?' +\n                         r'=(?P<expr>.*)$', stmt)\n        if ass_m:\n            if ass_m.groupdict().get('index'):\n                def assign(val):\n                    lvar = local_vars[ass_m.group('out')]\n                    idx = self.interpret_expression(\n                        ass_m.group('index'), local_vars, allow_recursion)\n                    assert isinstance(idx, int)\n                    lvar[idx] = val\n                    return val\n                expr = ass_m.group('expr')\n            else:\n                def assign(val):\n                    local_vars[ass_m.group('out')] = val\n                    return val\n                expr = ass_m.group('expr')\n        elif stmt.startswith('return '):\n            assign = lambda v: v\n            expr = stmt[len('return '):]\n        else:\n            # Try interpreting it as an expression\n            expr = stmt\n            assign = lambda v: v\n\n        v = self.interpret_expression(expr, local_vars, allow_recursion)\n        return assign(v)",
        "begin_line": 17,
        "end_line": 49,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.0001840942562592047,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.jsinterp.JSInterpreter.assign#27",
        "src_path": "youtube_dl/jsinterp.py",
        "class_name": "youtube_dl.jsinterp.JSInterpreter",
        "signature": "youtube_dl.jsinterp.JSInterpreter.assign(val)",
        "snippet": "                def assign(val):\n                    lvar = local_vars[ass_m.group('out')]\n                    idx = self.interpret_expression(\n                        ass_m.group('index'), local_vars, allow_recursion)\n                    assert isinstance(idx, int)\n                    lvar[idx] = val\n                    return val",
        "begin_line": 27,
        "end_line": 33,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 6.729927989770509e-05,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.jsinterp.JSInterpreter.assign#36",
        "src_path": "youtube_dl/jsinterp.py",
        "class_name": "youtube_dl.jsinterp.JSInterpreter",
        "signature": "youtube_dl.jsinterp.JSInterpreter.assign(val)",
        "snippet": "                def assign(val):\n                    local_vars[ass_m.group('out')] = val\n                    return val",
        "begin_line": 36,
        "end_line": 38,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 6.729927989770509e-05,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.jsinterp.JSInterpreter.interpret_expression#51",
        "src_path": "youtube_dl/jsinterp.py",
        "class_name": "youtube_dl.jsinterp.JSInterpreter",
        "signature": "youtube_dl.jsinterp.JSInterpreter.interpret_expression(self, expr, local_vars, allow_recursion)",
        "snippet": "    def interpret_expression(self, expr, local_vars, allow_recursion):\n        if expr.isdigit():\n            return int(expr)\n\n        if expr.isalpha():\n            return local_vars[expr]\n\n        try:\n            return json.loads(expr)\n        except ValueError:\n            pass\n\n        m = re.match(\n            r'^(?P<var>[a-zA-Z0-9_]+)\\.(?P<member>[^(]+)(?:\\(+(?P<args>[^()]*)\\))?$',\n            expr)\n        if m:\n            variable = m.group('var')\n            member = m.group('member')\n            arg_str = m.group('args')\n\n            if variable in local_vars:\n                obj = local_vars[variable]\n            else:\n                if variable not in self._objects:\n                    self._objects[variable] = self.extract_object(variable)\n                obj = self._objects[variable]\n\n            if arg_str is None:\n                # Member access\n                if member == 'length':\n                    return len(obj)\n                return obj[member]\n\n            assert expr.endswith(')')\n            # Function call\n            if arg_str == '':\n                argvals = tuple()\n            else:\n                argvals = tuple([\n                    self.interpret_expression(v, local_vars, allow_recursion)\n                    for v in arg_str.split(',')])\n\n            if member == 'split':\n                assert argvals == ('',)\n                return list(obj)\n            if member == 'join':\n                assert len(argvals) == 1\n                return argvals[0].join(obj)\n            if member == 'reverse':\n                assert len(argvals) == 0\n                obj.reverse()\n                return obj\n            if member == 'slice':\n                assert len(argvals) == 1\n                return obj[argvals[0]:]\n            if member == 'splice':\n                assert isinstance(obj, list)\n                index, howMany = argvals\n                res = []\n                for i in range(index, min(index + howMany, len(obj))):\n                    res.append(obj.pop(index))\n                return res\n\n            return obj[member](argvals)\n\n        m = re.match(\n            r'^(?P<in>[a-z]+)\\[(?P<idx>.+)\\]$', expr)\n        if m:\n            val = local_vars[m.group('in')]\n            idx = self.interpret_expression(\n                m.group('idx'), local_vars, allow_recursion - 1)\n            return val[idx]\n\n        m = re.match(r'^(?P<a>.+?)(?P<op>[%])(?P<b>.+?)$', expr)\n        if m:\n            a = self.interpret_expression(\n                m.group('a'), local_vars, allow_recursion)\n            b = self.interpret_expression(\n                m.group('b'), local_vars, allow_recursion)\n            return a % b\n\n        m = re.match(\n            r'^(?P<func>[a-zA-Z$]+)\\((?P<args>[a-z0-9,]+)\\)$', expr)\n        if m:\n            fname = m.group('func')\n            argvals = tuple([\n                int(v) if v.isdigit() else local_vars[v]\n                for v in m.group('args').split(',')])\n            if fname not in self._functions:\n                self._functions[fname] = self.extract_function(fname)\n            return self._functions[fname](argvals)\n        raise ExtractorError('Unsupported JS expression %r' % expr)",
        "begin_line": 51,
        "end_line": 142,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.0001840942562592047,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.jsinterp.JSInterpreter.extract_object#144",
        "src_path": "youtube_dl/jsinterp.py",
        "class_name": "youtube_dl.jsinterp.JSInterpreter",
        "signature": "youtube_dl.jsinterp.JSInterpreter.extract_object(self, objname)",
        "snippet": "    def extract_object(self, objname):\n        obj = {}\n        obj_m = re.search(\n            (r'(?:var\\s+)?%s\\s*=\\s*\\{' % re.escape(objname)) +\n            r'\\s*(?P<fields>([a-zA-Z$0-9]+\\s*:\\s*function\\(.*?\\)\\s*\\{.*?\\})*)' +\n            r'\\}\\s*;',\n            self.code)\n        fields = obj_m.group('fields')\n        # Currently, it only supports function definitions\n        fields_m = re.finditer(\n            r'(?P<key>[a-zA-Z$0-9]+)\\s*:\\s*function'\n            r'\\((?P<args>[a-z,]+)\\){(?P<code>[^}]+)}',\n            fields)\n        for f in fields_m:\n            argnames = f.group('args').split(',')\n            obj[f.group('key')] = self.build_function(argnames, f.group('code'))\n\n        return obj",
        "begin_line": 144,
        "end_line": 161,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 7.217090069284065e-05,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.jsinterp.JSInterpreter.extract_function#163",
        "src_path": "youtube_dl/jsinterp.py",
        "class_name": "youtube_dl.jsinterp.JSInterpreter",
        "signature": "youtube_dl.jsinterp.JSInterpreter.extract_function(self, funcname)",
        "snippet": "    def extract_function(self, funcname):\n        func_m = re.search(\n            (r'(?:function %s|[{;]%s\\s*=\\s*function)' % (\n                re.escape(funcname), re.escape(funcname))) +\n            r'\\((?P<args>[a-z,]+)\\){(?P<code>[^}]+)}',\n            self.code)\n        if func_m is None:\n            raise ExtractorError('Could not find JS function %r' % funcname)\n        argnames = func_m.group('args').split(',')\n\n        return self.build_function(argnames, func_m.group('code'))",
        "begin_line": 163,
        "end_line": 173,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 6.729927989770509e-05,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.jsinterp.JSInterpreter.build_function#175",
        "src_path": "youtube_dl/jsinterp.py",
        "class_name": "youtube_dl.jsinterp.JSInterpreter",
        "signature": "youtube_dl.jsinterp.JSInterpreter.build_function(self, argnames, code)",
        "snippet": "    def build_function(self, argnames, code):\n        def resf(args):\n            local_vars = dict(zip(argnames, args))\n            for stmt in code.split(';'):\n                res = self.interpret_statement(stmt, local_vars)\n            return res\n        return resf",
        "begin_line": 175,
        "end_line": 181,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 6.729927989770509e-05,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.jsinterp.JSInterpreter.resf#176",
        "src_path": "youtube_dl/jsinterp.py",
        "class_name": "youtube_dl.jsinterp.JSInterpreter",
        "signature": "youtube_dl.jsinterp.JSInterpreter.resf(args)",
        "snippet": "        def resf(args):\n            local_vars = dict(zip(argnames, args))\n            for stmt in code.split(';'):\n                res = self.interpret_statement(stmt, local_vars)\n            return res",
        "begin_line": 176,
        "end_line": 180,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 6.729927989770509e-05,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.mooshare.MooshareIE._real_extract#45",
        "src_path": "youtube_dl/extractor/mooshare.py",
        "class_name": "youtube_dl.extractor.mooshare.MooshareIE",
        "signature": "youtube_dl.extractor.mooshare.MooshareIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        page = self._download_webpage(url, video_id, 'Downloading page')\n\n        if re.search(r'>Video Not Found or Deleted<', page) is not None:\n            raise ExtractorError(u'Video %s does not exist' % video_id, expected=True)\n\n        hash_key = self._html_search_regex(r'<input type=\"hidden\" name=\"hash\" value=\"([^\"]+)\">', page, 'hash')\n        title = self._html_search_regex(r'(?m)<div class=\"blockTitle\">\\s*<h2>Watch ([^<]+)</h2>', page, 'title')\n\n        download_form = {\n            'op': 'download1',\n            'id': video_id,\n            'hash': hash_key,\n        }\n\n        request = compat_urllib_request.Request(\n            'http://mooshare.biz/%s' % video_id, compat_urllib_parse.urlencode(download_form))\n        request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n\n        self.to_screen('%s: Waiting for timeout' % video_id)\n        time.sleep(5)\n\n        video_page = self._download_webpage(request, video_id, 'Downloading video page')\n\n        thumbnail = self._html_search_regex(r'image:\\s*\"([^\"]+)\",', video_page, 'thumbnail', fatal=False)\n        duration_str = self._html_search_regex(r'duration:\\s*\"(\\d+)\",', video_page, 'duration', fatal=False)\n        duration = int(duration_str) if duration_str is not None else None\n\n        formats = []\n\n        # SD video\n        mobj = re.search(r'(?m)file:\\s*\"(?P<url>[^\"]+)\",\\s*provider:', video_page)\n        if mobj is not None:\n            formats.append({\n                'url': mobj.group('url'),\n                'format_id': 'sd',\n                'format': 'SD',\n            })\n\n        # HD video\n        mobj = re.search(r'\\'hd-2\\': { file: \\'(?P<url>[^\\']+)\\' },', video_page)\n        if mobj is not None:\n            formats.append({\n                'url': mobj.group('url'),\n                'format_id': 'hd',\n                'format': 'HD',\n            })\n\n        # rtmp video\n        mobj = re.search(r'(?m)file: \"(?P<playpath>[^\"]+)\",\\s*streamer: \"(?P<rtmpurl>rtmp://[^\"]+)\",', video_page)\n        if mobj is not None:\n            formats.append({\n                'url': mobj.group('rtmpurl'),\n                'play_path': mobj.group('playpath'),\n                'rtmp_live': False,\n                'ext': 'mp4',\n                'format_id': 'rtmp',\n                'format': 'HD',\n            })\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 45,
        "end_line": 114,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.kontrtube.KontrTubeIE._real_extract#28",
        "src_path": "youtube_dl/extractor/kontrtube.py",
        "class_name": "youtube_dl.extractor.kontrtube.KontrTubeIE",
        "signature": "youtube_dl.extractor.kontrtube.KontrTubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id, 'Downloading page')\n\n        video_url = self._html_search_regex(r\"video_url: '(.+?)/?',\", webpage, 'video URL')\n        thumbnail = self._html_search_regex(r\"preview_url: '(.+?)/?',\", webpage, 'video thumbnail', fatal=False)\n        title = self._html_search_regex(\n            r'<title>(.+?) - \u0422\u0440\u0443\u0431\u0430 \u0437\u043e\u0432\u0451\u0442 - \u0418\u043d\u0442\u0435\u0440\u0435\u0441\u043d\u044b\u0439 \u0432\u0438\u0434\u0435\u043e\u0445\u043e\u0441\u0442\u0438\u043d\u0433</title>', webpage, 'video title')\n        description = self._html_search_meta('description', webpage, 'video description')\n\n        mobj = re.search(\n            r'<div class=\"col_2\">\u0414\u043b\u0438\u0442\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u044c: <span>(?P<minutes>\\d+)\u043c:(?P<seconds>\\d+)\u0441</span></div>', webpage)\n        duration = int(mobj.group('minutes')) * 60 + int(mobj.group('seconds')) if mobj else None\n\n        view_count = self._html_search_regex(\n            r'<div class=\"col_2\">\u041f\u0440\u043e\u0441\u043c\u043e\u0442\u0440\u043e\u0432: <span>(\\d+)</span></div>', webpage, 'view count', fatal=False)\n\n        comment_count = None\n        comment_str = self._html_search_regex(\n            r'\u041a\u043e\u043c\u043c\u0435\u043d\u0442\u0430\u0440\u0438\u0438: <span>([^<]+)</span>', webpage, 'comment count', fatal=False)\n        if comment_str.startswith('\u043a\u043e\u043c\u043c\u0435\u043d\u0442\u0430\u0440\u0438\u0435\u0432 \u043d\u0435\u0442'):\n            comment_count = 0\n        else:\n            mobj = re.search(r'\\d+ \u0438\u0437 (?P<total>\\d+) \u043a\u043e\u043c\u043c\u0435\u043d\u0442\u0430\u0440\u0438\u0435\u0432', comment_str)\n            if mobj:\n                comment_count = mobj.group('total')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'thumbnail': thumbnail,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'view_count': int_or_none(view_count),\n            'comment_count': int_or_none(comment_count),\n        }",
        "begin_line": 28,
        "end_line": 66,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.m6.M6IE._real_extract#25",
        "src_path": "youtube_dl/extractor/m6.py",
        "class_name": "youtube_dl.extractor.m6.M6IE",
        "signature": "youtube_dl.extractor.m6.M6IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        rss = self._download_xml('http://ws.m6.fr/v1/video/info/m6/bonus/%s' % video_id, video_id,\n            'Downloading video RSS')\n\n        title = rss.find('./channel/item/title').text\n        description = rss.find('./channel/item/description').text\n        thumbnail = rss.find('./channel/item/visuel_clip_big').text\n        duration = int(rss.find('./channel/item/duration').text)\n        view_count = int(rss.find('./channel/item/nombre_vues').text)\n\n        formats = []\n        for format_id in ['lq', 'sd', 'hq', 'hd']:\n            video_url = rss.find('./channel/item/url_video_%s' % format_id)\n            if video_url is None:\n                continue\n            formats.append({\n                'url': video_url.text,\n                'format_id': format_id,\n            })\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'view_count': view_count,\n            'formats': formats,\n        }",
        "begin_line": 25,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.blinkx.BlinkxIE._real_extract#35",
        "src_path": "youtube_dl/extractor/blinkx.py",
        "class_name": "youtube_dl.extractor.blinkx.BlinkxIE",
        "signature": "youtube_dl.extractor.blinkx.BlinkxIE._real_extract(self, rl)",
        "snippet": "    def _real_extract(self, rl):\n        m = re.match(self._VALID_URL, rl)\n        video_id = m.group('id')\n        display_id = video_id[:8]\n\n        api_url = ('https://apib4.blinkx.com/api.php?action=play_video&' +\n                   'video=%s' % video_id)\n        data_json = self._download_webpage(api_url, display_id)\n        data = json.loads(data_json)['api']['results'][0]\n        duration = None\n        thumbnails = []\n        formats = []\n        for m in data['media']:\n            if m['type'] == 'jpg':\n                thumbnails.append({\n                    'url': m['link'],\n                    'width': int(m['w']),\n                    'height': int(m['h']),\n                })\n            elif m['type'] == 'original':\n                duration = float(m['d'])\n            elif m['type'] == 'youtube':\n                yt_id = m['link']\n                self.to_screen('Youtube video detected: %s' % yt_id)\n                return self.url_result(yt_id, 'Youtube', video_id=yt_id)\n            elif m['type'] in ('flv', 'mp4'):\n                vcodec = remove_start(m['vcodec'], 'ff')\n                acodec = remove_start(m['acodec'], 'ff')\n                tbr = (int(m['vbr']) + int(m['abr'])) // 1000\n                format_id = '%s-%sk-%s' % (vcodec, tbr, m['w'])\n                formats.append({\n                    'format_id': format_id,\n                    'url': m['link'],\n                    'vcodec': vcodec,\n                    'acodec': acodec,\n                    'abr': int(m['abr']) // 1000,\n                    'vbr': int(m['vbr']) // 1000,\n                    'tbr': tbr,\n                    'width': int(m['w']),\n                    'height': int(m['h']),\n                })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': display_id,\n            'fullid': video_id,\n            'title': data['title'],\n            'formats': formats,\n            'uploader': data['channel_name'],\n            'timestamp': data['pubdate_epoch'],\n            'description': data.get('description'),\n            'thumbnails': thumbnails,\n            'duration': duration,\n        }",
        "begin_line": 35,
        "end_line": 89,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.__init__#26",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.__init__(self, downloader=None, deletetempfiles=False)",
        "snippet": "    def __init__(self, downloader=None, deletetempfiles=False):\n        PostProcessor.__init__(self, downloader)\n        self._exes = self.detect_executables()\n        self._deletetempfiles = deletetempfiles",
        "begin_line": 26,
        "end_line": 29,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor._get_executable#36",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor._get_executable(self)",
        "snippet": "    def _get_executable(self):\n        if self._downloader.params.get('prefer_ffmpeg', False):\n            return self._exes['ffmpeg'] or self._exes['avconv']\n        else:\n            return self._exes['avconv'] or self._exes['ffmpeg']",
        "begin_line": 36,
        "end_line": 40,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor._uses_avconv#42",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor._uses_avconv(self)",
        "snippet": "    def _uses_avconv(self):\n        return self._get_executable() == self._exes['avconv']",
        "begin_line": 42,
        "end_line": 43,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.run_ffmpeg_multiple_files#45",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.run_ffmpeg_multiple_files(self, input_paths, out_path, opts)",
        "snippet": "    def run_ffmpeg_multiple_files(self, input_paths, out_path, opts):\n        if not self._get_executable():\n            raise FFmpegPostProcessorError(u'ffmpeg or avconv not found. Please install one.')\n\n        files_cmd = []\n        for path in input_paths:\n            files_cmd.extend(['-i', encodeFilename(path, True)])\n        cmd = ([self._get_executable(), '-y'] + files_cmd\n               + [encodeArgument(o) for o in opts] +\n               [encodeFilename(self._ffmpeg_filename_argument(out_path), True)])\n\n        if self._downloader.params.get('verbose', False):\n            self._downloader.to_screen(u'[debug] ffmpeg command line: %s' % shell_quote(cmd))\n        p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        stdout, stderr = p.communicate()\n        if p.returncode != 0:\n            stderr = stderr.decode('utf-8', 'replace')\n            msg = stderr.strip().split('\\n')[-1]\n            raise FFmpegPostProcessorError(msg)\n        if self._deletetempfiles:\n            for ipath in input_paths:\n                os.remove(ipath)",
        "begin_line": 45,
        "end_line": 66,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.run_ffmpeg#68",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.run_ffmpeg(self, path, out_path, opts)",
        "snippet": "    def run_ffmpeg(self, path, out_path, opts):\n        self.run_ffmpeg_multiple_files([path], out_path, opts)",
        "begin_line": 68,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor._ffmpeg_filename_argument#71",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor._ffmpeg_filename_argument(self, fn)",
        "snippet": "    def _ffmpeg_filename_argument(self, fn):\n        # ffmpeg broke --, see https://ffmpeg.org/trac/ffmpeg/ticket/2127 for details\n        if fn.startswith(u'-'):\n            return u'./' + fn\n        return fn",
        "begin_line": 71,
        "end_line": 75,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.__init__#79",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.__init__(self, downloader=None, preferredcodec=None, preferredquality=None, nopostoverwrites=False)",
        "snippet": "    def __init__(self, downloader=None, preferredcodec=None, preferredquality=None, nopostoverwrites=False):\n        FFmpegPostProcessor.__init__(self, downloader)\n        if preferredcodec is None:\n            preferredcodec = 'best'\n        self._preferredcodec = preferredcodec\n        self._preferredquality = preferredquality\n        self._nopostoverwrites = nopostoverwrites",
        "begin_line": 79,
        "end_line": 85,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.get_audio_codec#87",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.get_audio_codec(self, path)",
        "snippet": "    def get_audio_codec(self, path):\n        if not self._exes['ffprobe'] and not self._exes['avprobe']:\n            raise PostProcessingError(u'ffprobe or avprobe not found. Please install one.')\n        try:\n            cmd = [\n                self._exes['avprobe'] or self._exes['ffprobe'],\n                '-show_streams',\n                encodeFilename(self._ffmpeg_filename_argument(path), True)]\n            handle = subprocess.Popen(cmd, stderr=compat_subprocess_get_DEVNULL(), stdout=subprocess.PIPE)\n            output = handle.communicate()[0]\n            if handle.wait() != 0:\n                return None\n        except (IOError, OSError):\n            return None\n        audio_codec = None\n        for line in output.decode('ascii', 'ignore').split('\\n'):\n            if line.startswith('codec_name='):\n                audio_codec = line.split('=')[1].strip()\n            elif line.strip() == 'codec_type=audio' and audio_codec is not None:\n                return audio_codec\n        return None",
        "begin_line": 87,
        "end_line": 107,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.run_ffmpeg#109",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.run_ffmpeg(self, path, out_path, codec, more_opts)",
        "snippet": "    def run_ffmpeg(self, path, out_path, codec, more_opts):\n        if codec is None:\n            acodec_opts = []\n        else:\n            acodec_opts = ['-acodec', codec]\n        opts = ['-vn'] + acodec_opts + more_opts\n        try:\n            FFmpegPostProcessor.run_ffmpeg(self, path, out_path, opts)\n        except FFmpegPostProcessorError as err:\n            raise AudioConversionError(err.msg)",
        "begin_line": 109,
        "end_line": 118,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.run#120",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.run(self, information)",
        "snippet": "    def run(self, information):\n        path = information['filepath']\n\n        filecodec = self.get_audio_codec(path)\n        if filecodec is None:\n            raise PostProcessingError(u'WARNING: unable to obtain file audio codec with ffprobe')\n\n        uses_avconv = self._uses_avconv()\n        more_opts = []\n        if self._preferredcodec == 'best' or self._preferredcodec == filecodec or (self._preferredcodec == 'm4a' and filecodec == 'aac'):\n            if filecodec == 'aac' and self._preferredcodec in ['m4a', 'best']:\n                # Lossless, but in another container\n                acodec = 'copy'\n                extension = 'm4a'\n                more_opts = ['-bsf:a' if uses_avconv else '-absf', 'aac_adtstoasc']\n            elif filecodec in ['aac', 'mp3', 'vorbis', 'opus']:\n                # Lossless if possible\n                acodec = 'copy'\n                extension = filecodec\n                if filecodec == 'aac':\n                    more_opts = ['-f', 'adts']\n                if filecodec == 'vorbis':\n                    extension = 'ogg'\n            else:\n                # MP3 otherwise.\n                acodec = 'libmp3lame'\n                extension = 'mp3'\n                more_opts = []\n                if self._preferredquality is not None:\n                    if int(self._preferredquality) < 10:\n                        more_opts += ['-q:a' if uses_avconv else '-aq', self._preferredquality]\n                    else:\n                        more_opts += ['-b:a' if uses_avconv else '-ab', self._preferredquality + 'k']\n        else:\n            # We convert the audio (lossy)\n            acodec = {'mp3': 'libmp3lame', 'aac': 'aac', 'm4a': 'aac', 'opus': 'opus', 'vorbis': 'libvorbis', 'wav': None}[self._preferredcodec]\n            extension = self._preferredcodec\n            more_opts = []\n            if self._preferredquality is not None:\n                # The opus codec doesn't support the -aq option\n                if int(self._preferredquality) < 10 and extension != 'opus':\n                    more_opts += ['-q:a' if uses_avconv else '-aq', self._preferredquality]\n                else:\n                    more_opts += ['-b:a' if uses_avconv else '-ab', self._preferredquality + 'k']\n            if self._preferredcodec == 'aac':\n                more_opts += ['-f', 'adts']\n            if self._preferredcodec == 'm4a':\n                more_opts += ['-bsf:a' if uses_avconv else '-absf', 'aac_adtstoasc']\n            if self._preferredcodec == 'vorbis':\n                extension = 'ogg'\n            if self._preferredcodec == 'wav':\n                extension = 'wav'\n                more_opts += ['-f', 'wav']\n\n        prefix, sep, ext = path.rpartition(u'.') # not os.path.splitext, since the latter does not work on unicode in all setups\n        new_path = prefix + sep + extension\n\n        # If we download foo.mp3 and convert it to... foo.mp3, then don't delete foo.mp3, silly.\n        if new_path == path:\n            self._nopostoverwrites = True\n\n        try:\n            if self._nopostoverwrites and os.path.exists(encodeFilename(new_path)):\n                self._downloader.to_screen(u'[youtube] Post-process file %s exists, skipping' % new_path)\n            else:\n                self._downloader.to_screen(u'[' + self._get_executable() + '] Destination: ' + new_path)\n                self.run_ffmpeg(path, new_path, acodec, more_opts)\n        except:\n            etype,e,tb = sys.exc_info()\n            if isinstance(e, AudioConversionError):\n                msg = u'audio conversion failed: ' + e.msg\n            else:\n                msg = u'error running ' + self._get_executable()\n            raise PostProcessingError(msg)\n\n        # Try to update the date time for extracted audio file.\n        if information.get('filetime') is not None:\n            try:\n                os.utime(encodeFilename(new_path), (time.time(), information['filetime']))\n            except:\n                self._downloader.report_warning(u'Cannot update utime of audio file')\n\n        information['filepath'] = new_path\n        return self._nopostoverwrites,information",
        "begin_line": 120,
        "end_line": 203,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegVideoConvertor.__init__#207",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegVideoConvertor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegVideoConvertor.__init__(self, downloader=None, preferedformat=None)",
        "snippet": "    def __init__(self, downloader=None,preferedformat=None):\n        super(FFmpegVideoConvertor, self).__init__(downloader)\n        self._preferedformat=preferedformat",
        "begin_line": 207,
        "end_line": 209,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegVideoConvertor.run#211",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegVideoConvertor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegVideoConvertor.run(self, information)",
        "snippet": "    def run(self, information):\n        path = information['filepath']\n        prefix, sep, ext = path.rpartition(u'.')\n        outpath = prefix + sep + self._preferedformat\n        if information['ext'] == self._preferedformat:\n            self._downloader.to_screen(u'[ffmpeg] Not converting video file %s - already is in target format %s' % (path, self._preferedformat))\n            return True,information\n        self._downloader.to_screen(u'['+'ffmpeg'+'] Converting video from %s to %s, Destination: ' % (information['ext'], self._preferedformat) +outpath)\n        self.run_ffmpeg(path, outpath, [])\n        information['filepath'] = outpath\n        information['format'] = self._preferedformat\n        information['ext'] = self._preferedformat\n        return False,information",
        "begin_line": 211,
        "end_line": 223,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegEmbedSubtitlePP.__init__#415",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegEmbedSubtitlePP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegEmbedSubtitlePP.__init__(self, downloader=None, subtitlesformat='srt')",
        "snippet": "    def __init__(self, downloader=None, subtitlesformat='srt'):\n        super(FFmpegEmbedSubtitlePP, self).__init__(downloader)\n        self._subformat = subtitlesformat",
        "begin_line": 415,
        "end_line": 417,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegEmbedSubtitlePP.run#424",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegEmbedSubtitlePP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegEmbedSubtitlePP.run(self, information)",
        "snippet": "    def run(self, information):\n        if information['ext'] != u'mp4':\n            self._downloader.to_screen(u'[ffmpeg] Subtitles can only be embedded in mp4 files')\n            return True, information\n        if not information.get('subtitles'):\n            self._downloader.to_screen(u'[ffmpeg] There aren\\'t any subtitles to embed') \n            return True, information\n\n        sub_langs = [key for key in information['subtitles']]\n        filename = information['filepath']\n        input_files = [filename] + [subtitles_filename(filename, lang, self._subformat) for lang in sub_langs]\n\n        opts = ['-map', '0:0', '-map', '0:1', '-c:v', 'copy', '-c:a', 'copy']\n        for (i, lang) in enumerate(sub_langs):\n            opts.extend(['-map', '%d:0' % (i+1), '-c:s:%d' % i, 'mov_text'])\n            lang_code = self._conver_lang_code(lang)\n            if lang_code is not None:\n                opts.extend(['-metadata:s:s:%d' % i, 'language=%s' % lang_code])\n        opts.extend(['-f', 'mp4'])\n\n        temp_filename = filename + u'.temp'\n        self._downloader.to_screen(u'[ffmpeg] Embedding subtitles in \\'%s\\'' % filename)\n        self.run_ffmpeg_multiple_files(input_files, temp_filename, opts)\n        os.remove(encodeFilename(filename))\n        os.rename(encodeFilename(temp_filename), encodeFilename(filename))\n\n        return True, information",
        "begin_line": 424,
        "end_line": 450,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegMetadataPP.run#454",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegMetadataPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegMetadataPP.run(self, info)",
        "snippet": "    def run(self, info):\n        metadata = {}\n        if info.get('title') is not None:\n            metadata['title'] = info['title']\n        if info.get('upload_date') is not None:\n            metadata['date'] = info['upload_date']\n        if info.get('uploader') is not None:\n            metadata['artist'] = info['uploader']\n        elif info.get('uploader_id') is not None:\n            metadata['artist'] = info['uploader_id']\n\n        if not metadata:\n            self._downloader.to_screen(u'[ffmpeg] There isn\\'t any metadata to add')\n            return True, info\n\n        filename = info['filepath']\n        temp_filename = prepend_extension(filename, 'temp')\n\n        if info['ext'] == u'm4a':\n            options = ['-vn', '-acodec', 'copy']\n        else:\n            options = ['-c', 'copy']\n\n        for (name, value) in metadata.items():\n            options.extend(['-metadata', '%s=%s' % (name, value)])\n\n        self._downloader.to_screen(u'[ffmpeg] Adding metadata to \\'%s\\'' % filename)\n        self.run_ffmpeg(filename, temp_filename, options)\n        os.remove(encodeFilename(filename))\n        os.rename(encodeFilename(temp_filename), encodeFilename(filename))\n        return True, info",
        "begin_line": 454,
        "end_line": 484,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegMergerPP.run#488",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegMergerPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegMergerPP.run(self, info)",
        "snippet": "    def run(self, info):\n        filename = info['filepath']\n        args = ['-c', 'copy']\n        self._downloader.to_screen(u'[ffmpeg] Merging formats into \"%s\"' % filename)\n        self.run_ffmpeg_multiple_files(info['__files_to_merge'], filename, args)\n        return True, info",
        "begin_line": 488,
        "end_line": 493,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegAudioFixPP.run#497",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegAudioFixPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegAudioFixPP.run(self, info)",
        "snippet": "    def run(self, info):\n        filename = info['filepath']\n        temp_filename = prepend_extension(filename, 'temp')\n\n        options = ['-vn', '-acodec', 'copy']\n        self._downloader.to_screen(u'[ffmpeg] Fixing audio file \"%s\"' % filename)\n        self.run_ffmpeg(filename, temp_filename, options)\n\n        os.remove(encodeFilename(filename))\n        os.rename(encodeFilename(temp_filename), encodeFilename(filename))\n\n        return True, info",
        "begin_line": 497,
        "end_line": 508,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.soundgasm.SoundgasmIE._real_extract#22",
        "src_path": "youtube_dl/extractor/soundgasm.py",
        "class_name": "youtube_dl.extractor.soundgasm.SoundgasmIE",
        "signature": "youtube_dl.extractor.soundgasm.SoundgasmIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('title')\n        audio_title = mobj.group('user') + '_' + mobj.group('title')\n        webpage = self._download_webpage(url, display_id)\n        audio_url = self._html_search_regex(\n            r'(?s)m4a\\:\\s\"([^\"]+)\"', webpage, 'audio URL')\n        audio_id = re.split('\\/|\\.', audio_url)[-2]\n        description = self._html_search_regex(\n            r'(?s)<li>Description:\\s(.*?)<\\/li>', webpage, 'description',\n            fatal=False)\n\n        return {\n            'id': audio_id,\n            'display_id': display_id,\n            'url': audio_url,\n            'title': audio_title,\n            'description': description\n        }",
        "begin_line": 22,
        "end_line": 40,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.ivi.IviIE._extract_description#55",
        "src_path": "youtube_dl/extractor/ivi.py",
        "class_name": "youtube_dl.extractor.ivi.IviIE",
        "signature": "youtube_dl.extractor.ivi.IviIE._extract_description(self, html)",
        "snippet": "    def _extract_description(self, html):\n        m = re.search(r'<meta name=\"description\" content=\"(?P<description>[^\"]+)\"/>', html)\n        return m.group('description') if m is not None else None",
        "begin_line": 55,
        "end_line": 57,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.ivi.IviIE._extract_comment_count#59",
        "src_path": "youtube_dl/extractor/ivi.py",
        "class_name": "youtube_dl.extractor.ivi.IviIE",
        "signature": "youtube_dl.extractor.ivi.IviIE._extract_comment_count(self, html)",
        "snippet": "    def _extract_comment_count(self, html):\n        m = re.search('(?s)<a href=\"#\" id=\"view-comments\" class=\"action-button dim gradient\">\\s*\u041a\u043e\u043c\u043c\u0435\u043d\u0442\u0430\u0440\u0438\u0438:\\s*(?P<commentcount>\\d+)\\s*</a>', html)\n        return int(m.group('commentcount')) if m is not None else 0",
        "begin_line": 59,
        "end_line": 61,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.ivi.IviIE._real_extract#63",
        "src_path": "youtube_dl/extractor/ivi.py",
        "class_name": "youtube_dl.extractor.ivi.IviIE",
        "signature": "youtube_dl.extractor.ivi.IviIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n\n        api_url = 'http://api.digitalaccess.ru/api/json/'\n\n        data = {'method': 'da.content.get',\n                'params': [video_id, {'site': 's183',\n                                      'referrer': 'http://www.ivi.ru/watch/%s' % video_id,\n                                      'contentid': video_id\n                                      }\n                           ]\n                }\n\n        request = compat_urllib_request.Request(api_url, json.dumps(data))\n\n        video_json_page = self._download_webpage(request, video_id, 'Downloading video JSON')\n        video_json = json.loads(video_json_page)\n\n        if 'error' in video_json:\n            error = video_json['error']\n            if error['origin'] == 'NoRedisValidData':\n                raise ExtractorError('Video %s does not exist' % video_id, expected=True)\n            raise ExtractorError('Unable to download video %s: %s' % (video_id, error['message']), expected=True)\n\n        result = video_json['result']\n\n        formats = [{\n            'url': x['url'],\n            'format_id': x['content_format'],\n            'preference': self._known_formats.index(x['content_format']),\n        } for x in result['files'] if x['content_format'] in self._known_formats]\n\n        self._sort_formats(formats)\n\n        if not formats:\n            raise ExtractorError('No media links available for %s' % video_id)\n\n        duration = result['duration']\n        compilation = result['compilation']\n        title = result['title']\n\n        title = '%s - %s' % (compilation, title) if compilation is not None else title  \n\n        previews = result['preview']\n        previews.sort(key=lambda fmt: self._known_thumbnails.index(fmt['content_format']))\n        thumbnail = previews[-1]['url'] if len(previews) > 0 else None\n\n        video_page = self._download_webpage(url, video_id, 'Downloading video page')\n        description = self._extract_description(video_page)\n        comment_count = self._extract_comment_count(video_page)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'description': description,\n            'duration': duration,\n            'comment_count': comment_count,\n            'formats': formats,\n        }",
        "begin_line": 63,
        "end_line": 123,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.ivi.IviCompilationIE._extract_entries#146",
        "src_path": "youtube_dl/extractor/ivi.py",
        "class_name": "youtube_dl.extractor.ivi.IviCompilationIE",
        "signature": "youtube_dl.extractor.ivi.IviCompilationIE._extract_entries(self, html, compilation_id)",
        "snippet": "    def _extract_entries(self, html, compilation_id):\n        return [self.url_result('http://www.ivi.ru/watch/%s/%s' % (compilation_id, serie), 'Ivi')\n                for serie in re.findall(r'<strong><a href=\"/watch/%s/(\\d+)\">(?:[^<]+)</a></strong>' % compilation_id, html)]",
        "begin_line": 146,
        "end_line": 148,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.ivi.IviCompilationIE._real_extract#150",
        "src_path": "youtube_dl/extractor/ivi.py",
        "class_name": "youtube_dl.extractor.ivi.IviCompilationIE",
        "signature": "youtube_dl.extractor.ivi.IviCompilationIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        compilation_id = mobj.group('compilationid')\n        season_id = mobj.group('seasonid')\n\n        if season_id is not None: # Season link\n            season_page = self._download_webpage(url, compilation_id, 'Downloading season %s web page' % season_id)\n            playlist_id = '%s/season%s' % (compilation_id, season_id)\n            playlist_title = self._html_search_meta('title', season_page, 'title')\n            entries = self._extract_entries(season_page, compilation_id)\n        else: # Compilation link            \n            compilation_page = self._download_webpage(url, compilation_id, 'Downloading compilation web page')\n            playlist_id = compilation_id\n            playlist_title = self._html_search_meta('title', compilation_page, 'title')\n            seasons = re.findall(r'<a href=\"/watch/%s/season(\\d+)\">[^<]+</a>' % compilation_id, compilation_page)\n            if len(seasons) == 0: # No seasons in this compilation\n                entries = self._extract_entries(compilation_page, compilation_id)\n            else:\n                entries = []\n                for season_id in seasons:\n                    season_page = self._download_webpage(\n                        'http://www.ivi.ru/watch/%s/season%s' % (compilation_id, season_id),\n                        compilation_id, 'Downloading season %s web page' % season_id)\n                    entries.extend(self._extract_entries(season_page, compilation_id))\n\n        return self.playlist_result(entries, playlist_id, playlist_title)",
        "begin_line": 150,
        "end_line": 175,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.firedrive.FiredriveIE._real_extract#30",
        "src_path": "youtube_dl/extractor/firedrive.py",
        "class_name": "youtube_dl.extractor.firedrive.FiredriveIE",
        "signature": "youtube_dl.extractor.firedrive.FiredriveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        url = 'http://firedrive.com/file/%s' % video_id\n\n        webpage = self._download_webpage(url, video_id)\n\n        if re.search(self._FILE_DELETED_REGEX, webpage) is not None:\n            raise ExtractorError('Video %s does not exist' % video_id,\n                                 expected=True)\n\n        fields = dict(re.findall(r'''(?x)<input\\s+\n            type=\"hidden\"\\s+\n            name=\"([^\"]+)\"\\s+\n            value=\"([^\"]*)\"\n            ''', webpage))\n\n        post = compat_urllib_parse.urlencode(fields)\n        req = compat_urllib_request.Request(url, post)\n        req.add_header('Content-type', 'application/x-www-form-urlencoded')\n\n        # Apparently, this header is required for confirmation to work.\n        req.add_header('Host', 'www.firedrive.com')\n\n        webpage = self._download_webpage(req, video_id,\n                                         'Downloading video page')\n\n        title = self._search_regex(r'class=\"external_title_left\">(.+)</div>',\n                                   webpage, 'title')\n        thumbnail = self._search_regex(r'image:\\s?\"(//[^\\\"]+)', webpage,\n                                       'thumbnail', fatal=False)\n        if thumbnail is not None:\n            thumbnail = 'http:' + thumbnail\n\n        ext = self._search_regex(r'type:\\s?\\'([^\\']+)\\',',\n                                 webpage, 'extension', fatal=False)\n        video_url = self._search_regex(\n            r'file:\\s?loadURL\\(\\'(http[^\\']+)\\'\\),', webpage, 'file url')\n\n        formats = [{\n            'format_id': 'sd',\n            'url': video_url,\n            'ext': ext,\n        }]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 30,
        "end_line": 81,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.howstuffworks.HowStuffWorksIE._real_extract#62",
        "src_path": "youtube_dl/extractor/howstuffworks.py",
        "class_name": "youtube_dl.extractor.howstuffworks.HowStuffWorksIE",
        "signature": "youtube_dl.extractor.howstuffworks.HowStuffWorksIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('id')\n        webpage = self._download_webpage(url, display_id)\n\n        content_id = self._search_regex(r'var siteSectionId=\"(\\d+)\";', webpage, 'content id')\n\n        mp4 = self._search_regex(\n            r'''(?xs)var\\s+clip\\s*=\\s*{\\s*\n                .+?\\s*\n                content_id\\s*:\\s*%s\\s*,\\s*\n                .+?\\s*\n                mp4\\s*:\\s*\\[(.*?),?\\]\\s*\n                };\\s*\n                videoData\\.push\\(clip\\);''' % content_id,\n            webpage, 'mp4', fatal=False, default=None)\n\n        smil = self._download_xml(\n            'http://services.media.howstuffworks.com/videos/%s/smil-service.smil' % content_id,\n            content_id, 'Downloading video SMIL')\n\n        http_base = find_xpath_attr(\n            smil,\n            './{0}head/{0}meta'.format('{http://www.w3.org/2001/SMIL20/Language}'),\n            'name',\n            'httpBase').get('content')\n\n        def random_string(str_len=0):\n            return ''.join([random.choice(string.ascii_uppercase) for _ in range(str_len)])\n\n        URL_SUFFIX = '?v=2.11.3&fp=LNX 11,2,202,356&r=%s&g=%s' % (random_string(5), random_string(12))\n\n        formats = []\n\n        if mp4:\n            for video in json.loads('[%s]' % mp4):\n                bitrate = video['bitrate']\n                fmt = {\n                    'url': video['src'].replace('http://pmd.video.howstuffworks.com', http_base) + URL_SUFFIX,\n                    'format_id': bitrate,\n                }\n                m = re.search(r'(?P<vbr>\\d+)[Kk]', bitrate)\n                if m:\n                    fmt['vbr'] = int(m.group('vbr'))\n                formats.append(fmt)\n        else:\n            for video in smil.findall(\n                    './/{0}body/{0}switch/{0}video'.format('{http://www.w3.org/2001/SMIL20/Language}')):\n                vbr = int(video.attrib['system-bitrate']) / 1000\n                formats.append({\n                    'url': '%s/%s%s' % (http_base, video.attrib['src'], URL_SUFFIX),\n                    'format_id': '%dk' % vbr,\n                    'vbr': vbr,\n                })\n\n        self._sort_formats(formats)\n\n        title = self._og_search_title(webpage)\n        TITLE_SUFFIX = ' : HowStuffWorks'\n        if title.endswith(TITLE_SUFFIX):\n            title = title[:-len(TITLE_SUFFIX)]\n\n        description = self._og_search_description(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        return {\n            'id': content_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 62,
        "end_line": 134,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007692307692307692,
            "pseudo_dstar_susp": 0.0006273525721455458,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006273525721455458,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.nba.NBAIE._real_extract#26",
        "src_path": "youtube_dl/extractor/nba.py",
        "class_name": "youtube_dl.extractor.nba.NBAIE",
        "signature": "youtube_dl.extractor.nba.NBAIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = 'http://ht-mobile.cdn.turner.com/nba/big' + video_id + '_nba_1280x720.mp4'\n\n        shortened_video_id = video_id.rpartition('/')[2]\n        title = remove_end(\n            self._og_search_title(webpage, default=shortened_video_id), ' : NBA.com')\n\n        description = self._og_search_description(webpage)\n        duration = parse_duration(\n            self._html_search_meta('duration', webpage, 'duration', fatal=False))\n\n\n        return {\n            'id': shortened_video_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'duration': duration,\n        }",
        "begin_line": 26,
        "end_line": 49,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.sztvhu.SztvHuIE._real_extract#22",
        "src_path": "youtube_dl/extractor/sztvhu.py",
        "class_name": "youtube_dl.extractor.sztvhu.SztvHuIE",
        "signature": "youtube_dl.extractor.sztvhu.SztvHuIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        video_file = self._search_regex(\n            r'file: \"...:(.*?)\",', webpage, 'video file')\n        title = self._html_search_regex(\n            r'<meta name=\"title\" content=\"([^\"]*?) - [^-]*? - [^-]*?\"',\n            webpage, 'video title')\n        description = self._html_search_regex(\n            r'<meta name=\"description\" content=\"([^\"]*)\"/>',\n            webpage, 'video description', fatal=False)\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        video_url = 'http://media.sztv.hu/vod/' + video_file\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'ext': determine_ext(video_url),\n            'description': description,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 22,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.abc.ABCIE._real_extract#24",
        "src_path": "youtube_dl/extractor/abc.py",
        "class_name": "youtube_dl.extractor.abc.ABCIE",
        "signature": "youtube_dl.extractor.abc.ABCIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n\n        urls_info_json = self._search_regex(\n            r'inlineVideoData\\.push\\((.*?)\\);', webpage, 'video urls',\n            flags=re.DOTALL)\n        urls_info = json.loads(urls_info_json.replace('\\'', '\"'))\n        formats = [{\n            'url': url_info['url'],\n            'width': int(url_info['width']),\n            'height': int(url_info['height']),\n            'tbr': int(url_info['bitrate']),\n            'filesize': int(url_info['filesize']),\n        } for url_info in urls_info]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n            'formats': formats,\n            'description': self._og_search_description(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n        }",
        "begin_line": 24,
        "end_line": 48,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.mofosex.MofosexIE._real_extract#27",
        "src_path": "youtube_dl/extractor/mofosex.py",
        "class_name": "youtube_dl.extractor.mofosex.MofosexIE",
        "signature": "youtube_dl.extractor.mofosex.MofosexIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n        url = 'http://www.' + mobj.group('url')\n\n        req = compat_urllib_request.Request(url)\n        req.add_header('Cookie', 'age_verified=1')\n        webpage = self._download_webpage(req, video_id)\n\n        video_title = self._html_search_regex(r'<h1>(.+?)<', webpage, 'title')\n        video_url = compat_urllib_parse.unquote(self._html_search_regex(r'flashvars.video_url = \\'([^\\']+)', webpage, 'video_url'))\n        path = compat_urllib_parse_urlparse(video_url).path\n        extension = os.path.splitext(path)[1][1:]\n        format = path.split('/')[5].split('_')[:2]\n        format = \"-\".join(format)\n\n        age_limit = self._rta_search(webpage)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'url': video_url,\n            'ext': extension,\n            'format': format,\n            'format_id': format,\n            'age_limit': age_limit,\n        }",
        "begin_line": 27,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.newgrounds.NewgroundsIE._real_extract#22",
        "src_path": "youtube_dl/extractor/newgrounds.py",
        "class_name": "youtube_dl.extractor.newgrounds.NewgroundsIE",
        "signature": "youtube_dl.extractor.newgrounds.NewgroundsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        music_id = mobj.group('id')\n        webpage = self._download_webpage(url, music_id)\n        \n        title = self._html_search_regex(\n            r',\"name\":\"([^\"]+)\",', webpage, 'music title')\n        uploader = self._html_search_regex(\n            r',\"artist\":\"([^\"]+)\",', webpage, 'music uploader')\n        \n        music_url_json_string = self._html_search_regex(\n            r'({\"url\":\"[^\"]+\"),', webpage, 'music url') + '}'\n        music_url_json = json.loads(music_url_json_string)\n        music_url = music_url_json['url']\n\n        return {\n            'id': music_id,\n            'title': title,\n            'url': music_url,\n            'uploader': uploader,\n        }",
        "begin_line": 22,
        "end_line": 42,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.ted.TEDIE._extract_info#76",
        "src_path": "youtube_dl/extractor/ted.py",
        "class_name": "youtube_dl.extractor.ted.TEDIE",
        "signature": "youtube_dl.extractor.ted.TEDIE._extract_info(self, webpage)",
        "snippet": "    def _extract_info(self, webpage):\n        info_json = self._search_regex(r'q\\(\"\\w+.init\",({.+})\\)</script>',\n            webpage, 'info json')\n        return json.loads(info_json)",
        "begin_line": 76,
        "end_line": 79,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0015015015015015015,
            "pseudo_dstar_susp": 0.0011235955056179776,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0011235955056179776,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.ted.TEDIE._real_extract#81",
        "src_path": "youtube_dl/extractor/ted.py",
        "class_name": "youtube_dl.extractor.ted.TEDIE",
        "signature": "youtube_dl.extractor.ted.TEDIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url, re.VERBOSE)\n        if m.group('type') == 'embed':\n            desktop_url = m.group('proto') + 'www' + m.group('urlmain')\n            return self.url_result(desktop_url, 'TED')\n        name = m.group('name')\n        if m.group('type_talk'):\n            return self._talk_info(url, name)\n        elif m.group('type_watch'):\n            return self._watch_info(url, name)\n        else:\n            return self._playlist_videos_info(url, name)",
        "begin_line": 81,
        "end_line": 92,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001644736842105263,
            "pseudo_dstar_susp": 0.0012453300124533001,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0012453300124533001,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.ted.TEDIE._playlist_videos_info#94",
        "src_path": "youtube_dl/extractor/ted.py",
        "class_name": "youtube_dl.extractor.ted.TEDIE",
        "signature": "youtube_dl.extractor.ted.TEDIE._playlist_videos_info(self, url, name)",
        "snippet": "    def _playlist_videos_info(self, url, name):\n        '''Returns the videos of the playlist'''\n\n        webpage = self._download_webpage(url, name,\n            'Downloading playlist webpage')\n        info = self._extract_info(webpage)\n        playlist_info = info['playlist']\n\n        playlist_entries = [\n            self.url_result('http://www.ted.com/talks/' + talk['slug'], self.ie_key())\n            for talk in info['talks']\n        ]\n        return self.playlist_result(\n            playlist_entries,\n            playlist_id=compat_str(playlist_info['id']),\n            playlist_title=playlist_info['title'])",
        "begin_line": 94,
        "end_line": 109,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.ted.TEDIE._talk_info#111",
        "src_path": "youtube_dl/extractor/ted.py",
        "class_name": "youtube_dl.extractor.ted.TEDIE",
        "signature": "youtube_dl.extractor.ted.TEDIE._talk_info(self, url, video_name)",
        "snippet": "    def _talk_info(self, url, video_name):\n        webpage = self._download_webpage(url, video_name)\n        self.report_extraction(video_name)\n\n        talk_info = self._extract_info(webpage)['talks'][0]\n\n        formats = [{\n            'url': format_url,\n            'format_id': format_id,\n            'format': format_id,\n        } for (format_id, format_url) in talk_info['nativeDownloads'].items() if format_url is not None]\n        if formats:\n            for f in formats:\n                finfo = self._NATIVE_FORMATS.get(f['format_id'])\n                if finfo:\n                    f.update(finfo)\n        else:\n            # Use rtmp downloads\n            formats = [{\n                'format_id': f['name'],\n                'url': talk_info['streamer'],\n                'play_path': f['file'],\n                'ext': 'flv',\n                'width': f['width'],\n                'height': f['height'],\n                'tbr': f['bitrate'],\n            } for f in talk_info['resources']['rtmp']]\n        self._sort_formats(formats)\n\n        video_id = compat_str(talk_info['id'])\n        # subtitles\n        video_subtitles = self.extract_subtitles(video_id, talk_info)\n        if self._downloader.params.get('listsubtitles', False):\n            self._list_available_subtitles(video_id, talk_info)\n            return\n\n        thumbnail = talk_info['thumb']\n        if not thumbnail.startswith('http'):\n            thumbnail = 'http://' + thumbnail\n        return {\n            'id': video_id,\n            'title': talk_info['title'],\n            'uploader': talk_info['speaker'],\n            'thumbnail': thumbnail,\n            'description': self._og_search_description(webpage),\n            'subtitles': video_subtitles,\n            'formats': formats,\n        }",
        "begin_line": 111,
        "end_line": 158,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0013986013986013986,
            "pseudo_dstar_susp": 0.0010482180293501049,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0010482180293501049,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.ted.TEDIE._get_available_subtitles#160",
        "src_path": "youtube_dl/extractor/ted.py",
        "class_name": "youtube_dl.extractor.ted.TEDIE",
        "signature": "youtube_dl.extractor.ted.TEDIE._get_available_subtitles(self, video_id, talk_info)",
        "snippet": "    def _get_available_subtitles(self, video_id, talk_info):\n        languages = [lang['languageCode'] for lang in talk_info.get('languages', [])]\n        if languages:\n            sub_lang_list = {}\n            for l in languages:\n                url = 'http://www.ted.com/talks/subtitles/id/%s/lang/%s/format/srt' % (video_id, l)\n                sub_lang_list[l] = url\n            return sub_lang_list\n        else:\n            self._downloader.report_warning('video doesn\\'t have subtitles')\n            return {}",
        "begin_line": 160,
        "end_line": 170,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.ted.TEDIE._watch_info#172",
        "src_path": "youtube_dl/extractor/ted.py",
        "class_name": "youtube_dl.extractor.ted.TEDIE",
        "signature": "youtube_dl.extractor.ted.TEDIE._watch_info(self, url, name)",
        "snippet": "    def _watch_info(self, url, name):\n        webpage = self._download_webpage(url, name)\n\n        config_json = self._html_search_regex(\n            r\"data-config='([^']+)\", webpage, 'config')\n        config = json.loads(config_json)\n        video_url = config['video']['url']\n        thumbnail = config.get('image', {}).get('url')\n\n        title = self._html_search_regex(\n            r\"(?s)<h1(?:\\s+class='[^']+')?>(.+?)</h1>\", webpage, 'title')\n        description = self._html_search_regex(\n            [\n                r'(?s)<h4 class=\"[^\"]+\" id=\"h3--about-this-talk\">.*?</h4>(.*?)</div>',\n                r'(?s)<p><strong>About this talk:</strong>\\s+(.*?)</p>',\n            ],\n            webpage, 'description', fatal=False)\n\n        return {\n            'id': name,\n            'url': video_url,\n            'title': title,\n            'thumbnail': thumbnail,\n            'description': description,\n        }",
        "begin_line": 172,
        "end_line": 196,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.pornhd.PornHdIE._real_extract#24",
        "src_path": "youtube_dl/extractor/pornhd.py",
        "class_name": "youtube_dl.extractor.pornhd.PornHdIE",
        "signature": "youtube_dl.extractor.pornhd.PornHdIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(\n            r'<title>(.+) porn HD.+?</title>', webpage, 'title')\n        description = self._html_search_regex(\n            r'<div class=\"description\">([^<]+)</div>', webpage, 'description', fatal=False)\n        view_count = int_or_none(self._html_search_regex(\n            r'(\\d+) views\\s*</span>', webpage, 'view count', fatal=False))\n\n        videos = re.findall(\n            r'var __video([\\da-zA-Z]+?)(Low|High)StreamUrl = \\'(http://.+?)\\?noProxy=1\\'', webpage)\n\n        mobj = re.search(r'flashVars = (?P<flashvars>{.+?});', webpage)\n        if mobj:\n            flashvars = json.loads(mobj.group('flashvars'))\n            for key, quality in [('hashlink', 'low'), ('hd', 'high')]:\n                redirect_url = flashvars.get(key)\n                if redirect_url:\n                    videos.append(('flv', quality, redirect_url))\n            thumbnail = flashvars['urlWallpaper']\n        else:\n            thumbnail = self._og_search_thumbnail(webpage)\n\n        formats = []\n        for format_, quality, redirect_url in videos:\n            format_id = '%s-%s' % (format_.lower(), quality.lower())\n            video_url = self._download_webpage(\n                redirect_url, video_id, 'Downloading %s video link' % format_id, fatal=False)\n            if not video_url:\n                continue\n            formats.append({\n                'url': video_url,\n                'ext': format_.lower(),\n                'format_id': format_id,\n                'quality': 1 if quality.lower() == 'high' else 0,\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'view_count': view_count,\n            'formats': formats,\n            'age_limit': 18,\n        }",
        "begin_line": 24,
        "end_line": 74,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.ntv.NTVIE._real_extract#94",
        "src_path": "youtube_dl/extractor/ntv.py",
        "class_name": "youtube_dl.extractor.ntv.NTVIE",
        "signature": "youtube_dl.extractor.ntv.NTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        page = self._download_webpage(url, video_id)\n\n        video_id = self._html_search_regex(self._VIDEO_ID_REGEXES, page, 'video id')\n\n        player = self._download_xml('http://www.ntv.ru/vi%s/' % video_id, video_id, 'Downloading video XML')\n        title = unescapeHTML(player.find('./data/title').text)\n        description = unescapeHTML(player.find('./data/description').text)\n\n        video = player.find('./data/video')\n        video_id = video.find('./id').text\n        thumbnail = video.find('./splash').text\n        duration = int(video.find('./totaltime').text)\n        view_count = int(video.find('./views').text)\n        puid22 = video.find('./puid22').text\n\n        apps = {\n            '4': 'video1',\n            '7': 'video2',\n        }\n\n        app = apps.get(puid22, apps['4'])\n\n        formats = []\n        for format_id in ['', 'hi', 'webm']:\n            file = video.find('./%sfile' % format_id)\n            if file is None:\n                continue\n            size = video.find('./%ssize' % format_id)\n            formats.append({\n                'url': 'rtmp://media.ntv.ru/%s' % app,\n                'app': app,\n                'play_path': file.text,\n                'rtmp_conn': 'B:1',\n                'player_url': 'http://www.ntv.ru/swf/vps1.swf?update=20131128',\n                'page_url': 'http://www.ntv.ru',\n                'flash_ver': 'LNX 11,2,202,341',\n                'rtmp_live': True,\n                'ext': 'flv',\n                'filesize': int(size.text),\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'view_count': view_count,\n            'formats': formats,\n        }",
        "begin_line": 94,
        "end_line": 148,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00047596382674916705,
            "pseudo_dstar_susp": 0.0005931198102016608,
            "pseudo_tarantula_susp": 0.00028538812785388126,
            "pseudo_op2_susp": 0.0005931198102016608,
            "pseudo_barinel_susp": 0.00028538812785388126
        }
    },
    {
        "name": "youtube_dl.extractor.pbs.PBSIE._extract_ids#71",
        "src_path": "youtube_dl/extractor/pbs.py",
        "class_name": "youtube_dl.extractor.pbs.PBSIE",
        "signature": "youtube_dl.extractor.pbs.PBSIE._extract_ids(self, url)",
        "snippet": "    def _extract_ids(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        presumptive_id = mobj.group('presumptive_id')\n        display_id = presumptive_id\n        if presumptive_id:\n            webpage = self._download_webpage(url, display_id)\n\n            MEDIA_ID_REGEXES = [\n                r\"div\\s*:\\s*'videoembed'\\s*,\\s*mediaid\\s*:\\s*'(\\d+)'\",  # frontline video embed\n                r'class=\"coveplayerid\">([^<]+)<',                       # coveplayer\n            ]\n\n            media_id = self._search_regex(\n                MEDIA_ID_REGEXES, webpage, 'media ID', fatal=False, default=None)\n            if media_id:\n                return media_id, presumptive_id\n\n            url = self._search_regex(\n                r'<iframe\\s+(?:class|id)=[\"\\']partnerPlayer[\"\\'].*?\\s+src=[\"\\'](.*?)[\"\\']>',\n                webpage, 'player URL')\n            mobj = re.match(self._VALID_URL, url)\n\n        player_id = mobj.group('player_id')\n        if not display_id:\n            display_id = player_id\n        if player_id:\n            player_page = self._download_webpage(\n                url, display_id, note='Downloading player page',\n                errnote='Could not download player page')\n            video_id = self._search_regex(\n                r'<div\\s+id=\"video_([0-9]+)\"', player_page, 'video ID')\n        else:\n            video_id = mobj.group('id')\n            display_id = video_id\n\n        return video_id, display_id",
        "begin_line": 71,
        "end_line": 107,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009000900090009,
            "pseudo_dstar_susp": 0.0006983240223463687,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006983240223463687,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.pbs.PBSIE._real_extract#109",
        "src_path": "youtube_dl/extractor/pbs.py",
        "class_name": "youtube_dl.extractor.pbs.PBSIE",
        "signature": "youtube_dl.extractor.pbs.PBSIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id, display_id = self._extract_ids(url)\n\n        info_url = 'http://video.pbs.org/videoInfo/%s?format=json' % video_id\n        info = self._download_json(info_url, display_id)\n\n        rating_str = info.get('rating')\n        if rating_str is not None:\n            rating_str = rating_str.rpartition('-')[2]\n        age_limit = US_RATINGS.get(rating_str)\n\n        return {\n            'id': video_id,\n            'title': info['title'],\n            'url': info['alternate_encoding']['url'],\n            'ext': 'mp4',\n            'description': info['program'].get('description'),\n            'thumbnail': info.get('image_url'),\n            'duration': info.get('duration'),\n            'age_limit': age_limit,\n        }",
        "begin_line": 109,
        "end_line": 129,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009000900090009,
            "pseudo_dstar_susp": 0.0006983240223463687,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006983240223463687,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.eporner.EpornerIE._real_extract#29",
        "src_path": "youtube_dl/extractor/eporner.py",
        "class_name": "youtube_dl.extractor.eporner.EpornerIE",
        "signature": "youtube_dl.extractor.eporner.EpornerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id)\n        title = self._html_search_regex(\n            r'<title>(.*?) - EPORNER', webpage, 'title')\n\n        redirect_code = self._html_search_regex(\n            r'<script type=\"text/javascript\" src=\"/config5/%s/([a-f\\d]+)/\">' % video_id,\n            webpage, 'redirect_code')\n        redirect_url = 'http://www.eporner.com/config5/%s/%s' % (video_id, redirect_code)\n        player_code = self._download_webpage(\n            redirect_url, display_id, note='Downloading player config')\n\n        sources = self._search_regex(\n            r'(?s)sources\\s*:\\s*\\[\\s*({.+?})\\s*\\]', player_code, 'sources')\n\n        formats = []\n        for video_url, format_id in re.findall(r'file\\s*:\\s*\"([^\"]+)\",\\s*label\\s*:\\s*\"([^\"]+)\"', sources):\n            fmt = {\n                'url': video_url,\n                'format_id': format_id,\n            }\n            m = re.search(r'^(\\d+)', format_id)\n            if m:\n                fmt['height'] = int(m.group(1))\n            formats.append(fmt)\n        self._sort_formats(formats)\n\n        duration = parse_duration(self._search_regex(\n            r'class=\"mbtim\">([0-9:]+)</div>', webpage, 'duration',\n            fatal=False))\n        view_count = str_to_int(self._search_regex(\n            r'id=\"cinemaviews\">\\s*([0-9,]+)\\s*<small>views',\n            webpage, 'view count', fatal=False))\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'duration': duration,\n            'view_count': view_count,\n            'formats': formats,\n            'age_limit': self._rta_search(webpage),\n        }",
        "begin_line": 29,
        "end_line": 75,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.spankwire.SpankwireIE._real_extract#34",
        "src_path": "youtube_dl/extractor/spankwire.py",
        "class_name": "youtube_dl.extractor.spankwire.SpankwireIE",
        "signature": "youtube_dl.extractor.spankwire.SpankwireIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n        url = 'http://www.' + mobj.group('url')\n\n        req = compat_urllib_request.Request(url)\n        req.add_header('Cookie', 'age_verified=1')\n        webpage = self._download_webpage(req, video_id)\n\n        title = self._html_search_regex(r'<h1>([^<]+)', webpage, 'title')\n        description = self._html_search_regex(\n            r'<div\\s+id=\"descriptionContent\">([^<]+)<', webpage, 'description', fatal=False)\n        thumbnail = self._html_search_regex(\n            r'flashvars\\.image_url = \"([^\"]+)', webpage, 'thumbnail', fatal=False)\n\n        uploader = self._html_search_regex(\n            r'by:\\s*<a [^>]*>(.+?)</a>', webpage, 'uploader', fatal=False)\n        uploader_id = self._html_search_regex(\n            r'by:\\s*<a href=\"/Profile\\.aspx\\?.*?UserId=(\\d+).*?\"', webpage, 'uploader id', fatal=False)\n        upload_date = self._html_search_regex(r'</a> on (.+?) at \\d+:\\d+', webpage, 'upload date', fatal=False)\n        if upload_date:\n            upload_date = unified_strdate(upload_date)\n        \n        view_count = self._html_search_regex(\n            r'<div id=\"viewsCounter\"><span>([^<]+)</span> views</div>', webpage, 'view count', fatal=False)\n        if view_count:\n            view_count = str_to_int(view_count)\n        comment_count = int_or_none(self._html_search_regex(\n            r'<span id=\"spCommentCount\">\\s*(\\d+)</span> Comments</div>', webpage, 'comment count', fatal=False))\n\n        video_urls = list(map(compat_urllib_parse.unquote , re.findall(r'flashvars\\.quality_[0-9]{3}p = \"([^\"]+)', webpage)))\n        if webpage.find('flashvars\\.encrypted = \"true\"') != -1:\n            password = self._html_search_regex(r'flashvars\\.video_title = \"([^\"]+)', webpage, 'password').replace('+', ' ')\n            video_urls = list(map(lambda s: aes_decrypt_text(s, password, 32).decode('utf-8'), video_urls))\n\n        formats = []\n        for video_url in video_urls:\n            path = compat_urllib_parse_urlparse(video_url).path\n            format = path.split('/')[4].split('_')[:2]\n            resolution, bitrate_str = format\n            format = \"-\".join(format)\n            height = int(resolution.rstrip('Pp'))\n            tbr = int(bitrate_str.rstrip('Kk'))\n            formats.append({\n                'url': video_url,\n                'resolution': resolution,\n                'format': format,\n                'tbr': tbr,\n                'height': height,\n                'format_id': format,\n            })\n        self._sort_formats(formats)\n\n        age_limit = self._rta_search(webpage)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'upload_date': upload_date,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'formats': formats,\n            'age_limit': age_limit,\n        }",
        "begin_line": 34,
        "end_line": 101,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.cspan.CSpanIE._real_extract#46",
        "src_path": "youtube_dl/extractor/cspan.py",
        "class_name": "youtube_dl.extractor.cspan.CSpanIE",
        "signature": "youtube_dl.extractor.cspan.CSpanIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        page_id = mobj.group('id')\n        webpage = self._download_webpage(url, page_id)\n        video_id = self._search_regex(r'progid=\\'?([0-9]+)\\'?>', webpage, 'video id')\n\n        description = self._html_search_regex(\n            [\n                # The full description\n                r'<div class=\\'expandable\\'>(.*?)<a href=\\'#\\'',\n                # If the description is small enough the other div is not\n                # present, otherwise this is a stripped version\n                r'<p class=\\'initial\\'>(.*?)</p>'\n            ],\n            webpage, 'description', flags=re.DOTALL)\n\n        info_url = 'http://c-spanvideo.org/videoLibrary/assets/player/ajax-player.php?os=android&html5=program&id=' + video_id\n        data = self._download_json(info_url, video_id)\n\n        doc = self._download_xml(\n            'http://www.c-span.org/common/services/flashXml.php?programid=' + video_id,\n            video_id)\n\n        title = find_xpath_attr(doc, './/string', 'name', 'title').text\n        thumbnail = find_xpath_attr(doc, './/string', 'name', 'poster').text\n\n        files = data['video']['files']\n\n        entries = [{\n            'id': '%s_%d' % (video_id, partnum + 1),\n            'title': (\n                title if len(files) == 1 else\n                '%s part %d' % (title, partnum + 1)),\n            'url': unescapeHTML(f['path']['#text']),\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': int_or_none(f.get('length', {}).get('#text')),\n        } for partnum, f in enumerate(files)]\n\n        return {\n            '_type': 'playlist',\n            'entries': entries,\n            'title': title,\n            'id': video_id,\n        }",
        "begin_line": 46,
        "end_line": 90,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.rtlnl.RtlXlIE._real_extract#27",
        "src_path": "youtube_dl/extractor/rtlnl.py",
        "class_name": "youtube_dl.extractor.rtlnl.RtlXlIE",
        "signature": "youtube_dl.extractor.rtlnl.RtlXlIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        uuid = mobj.group('uuid')\n\n        info = self._download_json(\n            'http://www.rtl.nl/system/s4m/vfd/version=2/uuid=%s/fmt=flash/' % uuid,\n            uuid)\n\n        material = info['material'][0]\n        episode_info = info['episodes'][0]\n\n        progname = info['abstracts'][0]['name']\n        subtitle = material['title'] or info['episodes'][0]['name']\n\n        videopath = material['videopath']\n        f4m_url = 'http://manifest.us.rtl.nl' + videopath\n\n        formats = self._extract_f4m_formats(f4m_url, uuid)\n\n        video_urlpart = videopath.split('/flash/')[1][:-4]\n        PG_URL_TEMPLATE = 'http://pg.us.rtl.nl/rtlxl/network/%s/progressive/%s.mp4'\n\n        formats.extend([\n            {\n                'url': PG_URL_TEMPLATE % ('a2m', video_urlpart),\n                'format_id': 'pg-sd',\n            },\n            {\n                'url': PG_URL_TEMPLATE % ('a3m', video_urlpart),\n                'format_id': 'pg-hd',\n            }\n        ])\n\n        return {\n            'id': uuid,\n            'title': '%s - %s' % (progname, subtitle),\n            'formats': formats,\n            'timestamp': material['original_date'],\n            'description': episode_info['synopsis'],\n            'duration': parse_duration(material.get('duration')),\n        }",
        "begin_line": 27,
        "end_line": 67,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._login#56",
        "src_path": "youtube_dl/extractor/crunchyroll.py",
        "class_name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE",
        "signature": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n        self.report_login()\n        login_url = 'https://www.crunchyroll.com/?a=formhandler'\n        data = urlencode_postdata({\n            'formname': 'RpcApiUser_Login',\n            'name': username,\n            'password': password,\n        })\n        login_request = compat_urllib_request.Request(login_url, data)\n        login_request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        self._download_webpage(login_request, None, False, 'Wrong login info')",
        "begin_line": 56,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._real_initialize#72",
        "src_path": "youtube_dl/extractor/crunchyroll.py",
        "class_name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE",
        "signature": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 72,
        "end_line": 73,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._decrypt_subtitles#76",
        "src_path": "youtube_dl/extractor/crunchyroll.py",
        "class_name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE",
        "signature": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._decrypt_subtitles(self, data, iv, id)",
        "snippet": "    def _decrypt_subtitles(self, data, iv, id):\n        data = bytes_to_intlist(data)\n        iv = bytes_to_intlist(iv)\n        id = int(id)\n\n        def obfuscate_key_aux(count, modulo, start):\n            output = list(start)\n            for _ in range(count):\n                output.append(output[-1] + output[-2])\n            # cut off start values\n            output = output[2:]\n            output = list(map(lambda x: x % modulo + 33, output))\n            return output\n\n        def obfuscate_key(key):\n            num1 = int(floor(pow(2, 25) * sqrt(6.9)))\n            num2 = (num1 ^ key) << 5\n            num3 = key ^ num1\n            num4 = num3 ^ (num3 >> 3) ^ num2\n            prefix = intlist_to_bytes(obfuscate_key_aux(20, 97, (1, 2)))\n            shaHash = bytes_to_intlist(sha1(prefix + str(num4).encode('ascii')).digest())\n            # Extend 160 Bit hash to 256 Bit\n            return shaHash + [0] * 12\n\n        key = obfuscate_key(id)\n        class Counter:\n            __value = iv\n            def next_value(self):\n                temp = self.__value\n                self.__value = inc(self.__value)\n                return temp\n        decrypted_data = intlist_to_bytes(aes_cbc_decrypt(data, key, iv))\n        return zlib.decompress(decrypted_data)",
        "begin_line": 76,
        "end_line": 108,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._convert_subtitles_to_srt#110",
        "src_path": "youtube_dl/extractor/crunchyroll.py",
        "class_name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE",
        "signature": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._convert_subtitles_to_srt(self, subtitles)",
        "snippet": "    def _convert_subtitles_to_srt(self, subtitles):\n        output = ''\n        for i, (start, end, text) in enumerate(re.findall(r'<event [^>]*?start=\"([^\"]+)\" [^>]*?end=\"([^\"]+)\" [^>]*?text=\"([^\"]+)\"[^>]*?>', subtitles), 1):\n            start = start.replace('.', ',')\n            end = end.replace('.', ',')\n            text = clean_html(text)\n            text = text.replace('\\\\N', '\\n')\n            if not text:\n                continue\n            output += '%d\\n%s --> %s\\n%s\\n\\n' % (i, start, end, text)\n        return output",
        "begin_line": 110,
        "end_line": 120,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._convert_subtitles_to_ass#122",
        "src_path": "youtube_dl/extractor/crunchyroll.py",
        "class_name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE",
        "signature": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._convert_subtitles_to_ass(self, subtitles)",
        "snippet": "    def _convert_subtitles_to_ass(self, subtitles):\n        output = ''\n\n        def ass_bool(strvalue):\n            assvalue = '0'\n            if strvalue == '1':\n                assvalue = '-1'\n            return assvalue\n\n        sub_root = xml.etree.ElementTree.fromstring(subtitles)\n        if not sub_root:\n            return output\n\n        output = '[Script Info]\\n'\n        output += 'Title: %s\\n' % sub_root.attrib[\"title\"]\n        output += 'ScriptType: v4.00+\\n'\n        output += 'WrapStyle: %s\\n' % sub_root.attrib[\"wrap_style\"]\n        output += 'PlayResX: %s\\n' % sub_root.attrib[\"play_res_x\"]\n        output += 'PlayResY: %s\\n' % sub_root.attrib[\"play_res_y\"]\n        output += \"\"\"ScaledBorderAndShadow: yes\n\n[V4+ Styles]\nFormat: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\n\"\"\"\n        for style in sub_root.findall('./styles/style'):\n            output += 'Style: ' + style.attrib[\"name\"]\n            output += ',' + style.attrib[\"font_name\"]\n            output += ',' + style.attrib[\"font_size\"]\n            output += ',' + style.attrib[\"primary_colour\"]\n            output += ',' + style.attrib[\"secondary_colour\"]\n            output += ',' + style.attrib[\"outline_colour\"]\n            output += ',' + style.attrib[\"back_colour\"]\n            output += ',' + ass_bool(style.attrib[\"bold\"])\n            output += ',' + ass_bool(style.attrib[\"italic\"])\n            output += ',' + ass_bool(style.attrib[\"underline\"])\n            output += ',' + ass_bool(style.attrib[\"strikeout\"])\n            output += ',' + style.attrib[\"scale_x\"]\n            output += ',' + style.attrib[\"scale_y\"]\n            output += ',' + style.attrib[\"spacing\"]\n            output += ',' + style.attrib[\"angle\"]\n            output += ',' + style.attrib[\"border_style\"]\n            output += ',' + style.attrib[\"outline\"]\n            output += ',' + style.attrib[\"shadow\"]\n            output += ',' + style.attrib[\"alignment\"]\n            output += ',' + style.attrib[\"margin_l\"]\n            output += ',' + style.attrib[\"margin_r\"]\n            output += ',' + style.attrib[\"margin_v\"]\n            output += ',' + style.attrib[\"encoding\"]\n            output += '\\n'\n\n        output += \"\"\"\n[Events]\nFormat: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\n\"\"\"\n        for event in sub_root.findall('./events/event'):\n            output += 'Dialogue: 0'\n            output += ',' + event.attrib[\"start\"]\n            output += ',' + event.attrib[\"end\"]\n            output += ',' + event.attrib[\"style\"]\n            output += ',' + event.attrib[\"name\"]\n            output += ',' + event.attrib[\"margin_l\"]\n            output += ',' + event.attrib[\"margin_r\"]\n            output += ',' + event.attrib[\"margin_v\"]\n            output += ',' + event.attrib[\"effect\"]\n            output += ',' + event.attrib[\"text\"]\n            output += '\\n'\n\n        return output",
        "begin_line": 122,
        "end_line": 189,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._real_extract#191",
        "src_path": "youtube_dl/extractor/crunchyroll.py",
        "class_name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE",
        "signature": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self,url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('video_id')\n\n        if mobj.group('prefix') == 'm':\n            mobile_webpage = self._download_webpage(url, video_id, 'Downloading mobile webpage')\n            webpage_url = self._search_regex(r'<link rel=\"canonical\" href=\"([^\"]+)\" />', mobile_webpage, 'webpage_url')\n        else:\n            webpage_url = 'http://www.' + mobj.group('url')\n\n        webpage = self._download_webpage(webpage_url, video_id, 'Downloading webpage')\n        note_m = self._html_search_regex(r'<div class=\"showmedia-trailer-notice\">(.+?)</div>', webpage, 'trailer-notice', default='')\n        if note_m:\n            raise ExtractorError(note_m)\n\n        mobj = re.search(r'Page\\.messaging_box_controller\\.addItems\\(\\[(?P<msg>{.+?})\\]\\)', webpage)\n        if mobj:\n            msg = json.loads(mobj.group('msg'))\n            if msg.get('type') == 'error':\n                raise ExtractorError('crunchyroll returned error: %s' % msg['message_body'], expected=True)\n\n        video_title = self._html_search_regex(r'<h1[^>]*>(.+?)</h1>', webpage, 'video_title', flags=re.DOTALL)\n        video_title = re.sub(r' {2,}', ' ', video_title)\n        video_description = self._html_search_regex(r'\"description\":\"([^\"]+)', webpage, 'video_description', default='')\n        if not video_description:\n            video_description = None\n        video_upload_date = self._html_search_regex(r'<div>Availability for free users:(.+?)</div>', webpage, 'video_upload_date', fatal=False, flags=re.DOTALL)\n        if video_upload_date:\n            video_upload_date = unified_strdate(video_upload_date)\n        video_uploader = self._html_search_regex(r'<div>\\s*Publisher:(.+?)</div>', webpage, 'video_uploader', fatal=False, flags=re.DOTALL)\n\n        playerdata_url = compat_urllib_parse.unquote(self._html_search_regex(r'\"config_url\":\"([^\"]+)', webpage, 'playerdata_url'))\n        playerdata_req = compat_urllib_request.Request(playerdata_url)\n        playerdata_req.data = compat_urllib_parse.urlencode({'current_page': webpage_url})\n        playerdata_req.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        playerdata = self._download_webpage(playerdata_req, video_id, note='Downloading media info')\n\n        stream_id = self._search_regex(r'<media_id>([^<]+)', playerdata, 'stream_id')\n        video_thumbnail = self._search_regex(r'<episode_image_url>([^<]+)', playerdata, 'thumbnail', fatal=False)\n\n        formats = []\n        for fmt in re.findall(r'\\?p([0-9]{3,4})=1', webpage):\n            stream_quality, stream_format = self._FORMAT_IDS[fmt]\n            video_format = fmt+'p'\n            streamdata_req = compat_urllib_request.Request('http://www.crunchyroll.com/xml/')\n            # urlencode doesn't work!\n            streamdata_req.data = 'req=RpcApiVideoEncode%5FGetStreamInfo&video%5Fencode%5Fquality='+stream_quality+'&media%5Fid='+stream_id+'&video%5Fformat='+stream_format\n            streamdata_req.add_header('Content-Type', 'application/x-www-form-urlencoded')\n            streamdata_req.add_header('Content-Length', str(len(streamdata_req.data)))\n            streamdata = self._download_webpage(streamdata_req, video_id, note='Downloading media info for '+video_format)\n            video_url = self._search_regex(r'<host>([^<]+)', streamdata, 'video_url')\n            video_play_path = self._search_regex(r'<file>([^<]+)', streamdata, 'video_play_path')\n            formats.append({\n                'url': video_url,\n                'play_path':   video_play_path,\n                'ext': 'flv',\n                'format': video_format,\n                'format_id': video_format,\n            })\n\n        subtitles = {}\n        sub_format = self._downloader.params.get('subtitlesformat', 'srt')\n        for sub_id, sub_name in re.findall(r'\\?ssid=([0-9]+)\" title=\"([^\"]+)', webpage):\n            sub_page = self._download_webpage('http://www.crunchyroll.com/xml/?req=RpcApiSubtitle_GetXml&subtitle_script_id='+sub_id,\\\n                                              video_id, note='Downloading subtitles for '+sub_name)\n            id = self._search_regex(r'id=\\'([0-9]+)', sub_page, 'subtitle_id', fatal=False)\n            iv = self._search_regex(r'<iv>([^<]+)', sub_page, 'subtitle_iv', fatal=False)\n            data = self._search_regex(r'<data>([^<]+)', sub_page, 'subtitle_data', fatal=False)\n            if not id or not iv or not data:\n                continue\n            id = int(id)\n            iv = base64.b64decode(iv)\n            data = base64.b64decode(data)\n\n            subtitle = self._decrypt_subtitles(data, iv, id).decode('utf-8')\n            lang_code = self._search_regex(r'lang_code=[\"\\']([^\"\\']+)', subtitle, 'subtitle_lang_code', fatal=False)\n            if not lang_code:\n                continue\n            if sub_format == 'ass':\n                subtitles[lang_code] = self._convert_subtitles_to_ass(subtitle)\n            else:\n                subtitles[lang_code] = self._convert_subtitles_to_srt(subtitle)\n\n        return {\n            'id':          video_id,\n            'title':       video_title,\n            'description': video_description,\n            'thumbnail':   video_thumbnail,\n            'uploader':    video_uploader,\n            'upload_date': video_upload_date,\n            'subtitles':   subtitles,\n            'formats':     formats,\n        }",
        "begin_line": 191,
        "end_line": 283,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.motorsport.MotorsportIE._real_extract#34",
        "src_path": "youtube_dl/extractor/motorsport.py",
        "class_name": "youtube_dl.extractor.motorsport.MotorsportIE",
        "signature": "youtube_dl.extractor.motorsport.MotorsportIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, display_id)\n        flashvars_code = self._html_search_regex(\n            r'<embed id=\"player\".*?flashvars=\"([^\"]+)\"', webpage, 'flashvars')\n        flashvars = compat_parse_qs(flashvars_code)\n        params = json.loads(flashvars['parameters'][0])\n\n        e = compat_str(int(time.time()) + 24 * 60 * 60)\n        base_video_url = params['location'] + '?e=' + e\n        s = 'h3hg713fh32'\n        h = hashlib.md5((s + base_video_url).encode('utf-8')).hexdigest()\n        video_url = base_video_url + '&h=' + h\n\n        uploader = self._html_search_regex(\n            r'(?s)<span class=\"label\">Video by: </span>(.*?)</a>', webpage,\n            'uploader', fatal=False)\n\n        return {\n            'id': params['video_id'],\n            'display_id': display_id,\n            'title': params['title'],\n            'url': video_url,\n            'description': params.get('description'),\n            'thumbnail': params.get('main_thumb'),\n            'duration': int_or_none(params.get('duration')),\n            'uploader': uploader,\n        }",
        "begin_line": 34,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.vesti.VestiIE._real_extract#103",
        "src_path": "youtube_dl/extractor/vesti.py",
        "class_name": "youtube_dl.extractor.vesti.VestiIE",
        "signature": "youtube_dl.extractor.vesti.VestiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        page = self._download_webpage(url, video_id, 'Downloading page')\n\n        mobj = re.search(\n            r'<meta[^>]+?property=\"og:video\"[^>]+?content=\"http://www\\.vesti\\.ru/i/flvplayer_videoHost\\.swf\\?vid=(?P<id>\\d+)',\n            page)\n        if mobj:\n            video_id = mobj.group('id')\n            page = self._download_webpage('http://www.vesti.ru/only_video.html?vid=%s' % video_id, video_id,\n                'Downloading video page')\n\n        rutv_url = RUTVIE._extract_url(page)\n        if rutv_url:\n            return self.url_result(rutv_url, 'RUTV')\n\n        raise ExtractorError('No video found', expected=True)",
        "begin_line": 103,
        "end_line": 121,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009000900090009,
            "pseudo_dstar_susp": 0.0006983240223463687,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006983240223463687,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.hark.HarkIE._real_extract#22",
        "src_path": "youtube_dl/extractor/hark.py",
        "class_name": "youtube_dl.extractor.hark.HarkIE",
        "signature": "youtube_dl.extractor.hark.HarkIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group(1)\n        json_url = \"http://www.hark.com/clips/%s.json\" %(video_id)\n        info_json = self._download_webpage(json_url, video_id)\n        info = json.loads(info_json)\n        final_url = info['url']\n\n        return {'id': video_id,\n                'url' : final_url,\n                'title': info['name'],\n                'ext': determine_ext(final_url),\n                'description': info['description'],\n                'thumbnail': info['image_original'],\n                'duration': info['duration'],\n                }",
        "begin_line": 22,
        "end_line": 37,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.videodetective.VideoDetectiveIE._real_extract#24",
        "src_path": "youtube_dl/extractor/videodetective.py",
        "class_name": "youtube_dl.extractor.videodetective.VideoDetectiveIE",
        "signature": "youtube_dl.extractor.videodetective.VideoDetectiveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        og_video = self._og_search_video_url(webpage)\n        query = compat_urlparse.urlparse(og_video).query\n        return self.url_result(InternetVideoArchiveIE._build_url(query), ie=InternetVideoArchiveIE.ie_key())",
        "begin_line": 24,
        "end_line": 30,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.cracked.CrackedIE._real_extract#27",
        "src_path": "youtube_dl/extractor/cracked.py",
        "class_name": "youtube_dl.extractor.cracked.CrackedIE",
        "signature": "youtube_dl.extractor.cracked.CrackedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = self._html_search_regex(\n            [r'var\\s+CK_vidSrc\\s*=\\s*\"([^\"]+)\"', r'<video\\s+src=\"([^\"]+)\"'], webpage, 'video URL')\n\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage)\n\n        timestamp = self._html_search_regex(r'<time datetime=\"([^\"]+)\"', webpage, 'upload date', fatal=False)\n        if timestamp:\n            timestamp = parse_iso8601(timestamp[:-6])\n\n        view_count = str_to_int(self._html_search_regex(\n            r'<span class=\"views\" id=\"viewCounts\">([\\d,\\.]+) Views</span>', webpage, 'view count', fatal=False))\n        comment_count = str_to_int(self._html_search_regex(\n            r'<span id=\"commentCounts\">([\\d,\\.]+)</span>', webpage, 'comment count', fatal=False))\n\n        m = re.search(r'_(?P<width>\\d+)X(?P<height>\\d+)\\.mp4$', video_url)\n        if m:\n            width = int(m.group('width'))\n            height = int(m.group('height'))\n        else:\n            width = height = None\n\n        return {\n            'id': video_id,\n            'url':video_url,\n            'title': title,\n            'description': description,\n            'timestamp': timestamp,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'height': height,\n            'width': width,\n        }",
        "begin_line": 27,
        "end_line": 65,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.npo.NPOIE._real_extract#28",
        "src_path": "youtube_dl/extractor/npo.py",
        "class_name": "youtube_dl.extractor.npo.NPOIE",
        "signature": "youtube_dl.extractor.npo.NPOIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        metadata = self._download_json(\n            'http://e.omroep.nl/metadata/aflevering/%s' % video_id,\n            video_id,\n            # We have to remove the javascript callback\n            transform_source=lambda j: re.sub(r'parseMetadata\\((.*?)\\);\\n//.*$', r'\\1', j)\n        )\n        token_page = self._download_webpage(\n            'http://ida.omroep.nl/npoplayer/i.js',\n            video_id,\n            note='Downloading token'\n        )\n        token = self._search_regex(r'npoplayer\\.token = \"(.+?)\"', token_page, 'token')\n\n        formats = []\n        quality = qualities(['adaptive', 'h264_sb', 'h264_bb', 'h264_std'])\n        for format_id in metadata['pubopties']:\n            streams_info = self._download_json(\n                'http://ida.omroep.nl/odi/?prid=%s&puboptions=%s&adaptive=yes&token=%s' % (video_id, format_id, token),\n                video_id, 'Downloading %s streams info' % format_id)\n            stream_info = self._download_json(\n                streams_info['streams'][0] + '&type=json',\n                video_id, 'Downloading %s stream info' % format_id)\n            if format_id == 'adaptive':\n                formats.extend(self._extract_m3u8_formats(stream_info['url'], video_id))\n            else:\n                formats.append({\n                    'url': stream_info['url'],\n                    'format_id': format_id,\n                    'quality': quality(format_id),\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': metadata['titel'],\n            'description': metadata['info'],\n            'thumbnail': metadata['images'][-1]['url'],\n            'upload_date': unified_strdate(metadata['gidsdatum']),\n            'formats': formats,\n        }",
        "begin_line": 28,
        "end_line": 71,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.weibo.WeiboIE._real_extract#33",
        "src_path": "youtube_dl/extractor/weibo.py",
        "class_name": "youtube_dl.extractor.weibo.WeiboIE",
        "signature": "youtube_dl.extractor.weibo.WeiboIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url, flags=re.VERBOSE)\n        video_id = mobj.group('id')\n        info_url = 'http://video.weibo.com/?s=v&a=play_list&format=json&mix_video_id=t_%s' % video_id\n        info = self._download_json(info_url, video_id)\n\n        videos_urls = map(lambda v: v['play_page_url'], info['result']['data'])\n        # Prefer sina video since they have thumbnails\n        videos_urls = sorted(videos_urls, key=lambda u: 'video.sina.com' in u)\n        player_url = videos_urls[-1]\n        m_sina = re.match(r'https?://video\\.sina\\.com\\.cn/v/b/(\\d+)-\\d+\\.html',\n            player_url)\n        if m_sina is not None:\n            self.to_screen('Sina video detected')\n            sina_id = m_sina.group(1)\n            player_url = 'http://you.video.sina.com.cn/swf/quotePlayer.swf?vid=%s' % sina_id\n        return self.url_result(player_url)",
        "begin_line": 33,
        "end_line": 49,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.nhl.NHLBaseInfoExtractor._extract_video#20",
        "src_path": "youtube_dl/extractor/nhl.py",
        "class_name": "youtube_dl.extractor.nhl.NHLBaseInfoExtractor",
        "signature": "youtube_dl.extractor.nhl.NHLBaseInfoExtractor._extract_video(self, info)",
        "snippet": "    def _extract_video(self, info):\n        video_id = info['id']\n        self.report_extraction(video_id)\n\n        initial_video_url = info['publishPoint']\n        data = compat_urllib_parse.urlencode({\n            'type': 'fvod',\n            'path': initial_video_url.replace('.mp4', '_sd.mp4'),\n        })\n        path_url = 'http://video.nhl.com/videocenter/servlets/encryptvideopath?' + data\n        path_doc = self._download_xml(\n            path_url, video_id, 'Downloading final video url')\n        video_url = path_doc.find('path').text\n\n        join = compat_urlparse.urljoin\n        return {\n            'id': video_id,\n            'title': info['name'],\n            'url': video_url,\n            'ext': determine_ext(video_url),\n            'description': info['description'],\n            'duration': int(info['duration']),\n            'thumbnail': join(join(video_url, '/u/'), info['bigImage']),\n            'upload_date': unified_strdate(info['releaseDate'].split('.')[0]),\n        }",
        "begin_line": 20,
        "end_line": 44,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.nhl.NHLIE._real_extract#63",
        "src_path": "youtube_dl/extractor/nhl.py",
        "class_name": "youtube_dl.extractor.nhl.NHLIE",
        "signature": "youtube_dl.extractor.nhl.NHLIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        json_url = 'http://video.nhl.com/videocenter/servlets/playlist?ids=%s&format=json' % video_id\n        data = self._download_json(\n            json_url, video_id, transform_source=self._fix_json)\n        return self._extract_video(data[0])",
        "begin_line": 63,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.nhl.NHLVideocenterIE._real_extract#85",
        "src_path": "youtube_dl/extractor/nhl.py",
        "class_name": "youtube_dl.extractor.nhl.NHLVideocenterIE",
        "signature": "youtube_dl.extractor.nhl.NHLVideocenterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        team = mobj.group('team')\n        webpage = self._download_webpage(url, team)\n        cat_id = self._search_regex(\n            [r'var defaultCatId = \"(.+?)\";',\n             r'{statusIndex:0,index:0,.*?id:(.*?),'],\n            webpage, 'category id')\n        playlist_title = self._html_search_regex(\n            r'tab0\"[^>]*?>(.*?)</td>',\n            webpage, 'playlist title', flags=re.DOTALL).lower().capitalize()\n\n        data = compat_urllib_parse.urlencode({\n            'cid': cat_id,\n            # This is the default value\n            'count': 12,\n            'ptrs': 3,\n            'format': 'json',\n        })\n        path = '/videocenter/servlets/browse?' + data\n        request_url = compat_urlparse.urljoin(url, path)\n        response = self._download_webpage(request_url, playlist_title)\n        response = self._fix_json(response)\n        if not response.strip():\n            self._downloader.report_warning(u'Got an empty reponse, trying '\n                                            'adding the \"newvideos\" parameter')\n            response = self._download_webpage(request_url + '&newvideos=true',\n                playlist_title)\n            response = self._fix_json(response)\n        videos = json.loads(response)\n\n        return {\n            '_type': 'playlist',\n            'title': playlist_title,\n            'id': cat_id,\n            'entries': [self._extract_video(v) for v in videos],\n        }",
        "begin_line": 85,
        "end_line": 121,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.nbc.NBCIE._real_extract#28",
        "src_path": "youtube_dl/extractor/nbc.py",
        "class_name": "youtube_dl.extractor.nbc.NBCIE",
        "signature": "youtube_dl.extractor.nbc.NBCIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        theplatform_url = self._search_regex('class=\"video-player video-player-full\" data-mpx-url=\"(.*?)\"', webpage, 'theplatform url')\n        if theplatform_url.startswith('//'):\n            theplatform_url = 'http:' + theplatform_url\n        return self.url_result(theplatform_url)",
        "begin_line": 28,
        "end_line": 35,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.nbc.NBCNewsIE._real_extract#68",
        "src_path": "youtube_dl/extractor/nbc.py",
        "class_name": "youtube_dl.extractor.nbc.NBCNewsIE",
        "signature": "youtube_dl.extractor.nbc.NBCNewsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        if video_id is not None:\n            all_info = self._download_xml('http://www.nbcnews.com/id/%s/displaymode/1219' % video_id, video_id)\n            info = all_info.find('video')\n\n            return {\n                'id': video_id,\n                'title': info.find('headline').text,\n                'ext': 'flv',\n                'url': find_xpath_attr(info, 'media', 'type', 'flashVideo').text,\n                'description': compat_str(info.find('caption').text),\n                'thumbnail': find_xpath_attr(info, 'media', 'type', 'thumbnail').text,\n            }\n        else:\n            # \"feature\" pages use theplatform.com\n            title = mobj.group('title')\n            webpage = self._download_webpage(url, title)\n            bootstrap_json = self._search_regex(\n                r'var bootstrapJson = ({.+})\\s*$', webpage, 'bootstrap json',\n                flags=re.MULTILINE)\n            bootstrap = json.loads(bootstrap_json)\n            info = bootstrap['results'][0]['video']\n            mpxid = info['mpxId']\n\n            base_urls = [\n                info['fallbackPlaylistUrl'],\n                info['associatedPlaylistUrl'],\n            ]\n\n            for base_url in base_urls:\n                playlist_url = base_url + '?form=MPXNBCNewsAPI'\n                all_videos = self._download_json(playlist_url, title)['videos']\n\n                try:\n                    info = next(v for v in all_videos if v['mpxId'] == mpxid)\n                    break\n                except StopIteration:\n                    continue\n\n            if info is None:\n                raise ExtractorError('Could not find video in playlists')\n\n            return {\n                '_type': 'url',\n                # We get the best quality video\n                'url': info['videoAssets'][-1]['publicUrl'],\n                'ie_key': 'ThePlatform',\n            }",
        "begin_line": 68,
        "end_line": 117,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTvIE._real_extract#26",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTvIE",
        "signature": "youtube_dl.extractor.arte.ArteTvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        lang = mobj.group('lang')\n        video_id = mobj.group('id')\n\n        ref_xml_url = url.replace('/videos/', '/do_delegate/videos/')\n        ref_xml_url = ref_xml_url.replace('.html', ',view,asPlayerXml.xml')\n        ref_xml_doc = self._download_xml(\n            ref_xml_url, video_id, note='Downloading metadata')\n        config_node = find_xpath_attr(ref_xml_doc, './/video', 'lang', lang)\n        config_xml_url = config_node.attrib['ref']\n        config = self._download_xml(\n            config_xml_url, video_id, note='Downloading configuration')\n\n        formats = [{\n            'forma_id': q.attrib['quality'],\n            # The playpath starts at 'mp4:', if we don't manually\n            # split the url, rtmpdump will incorrectly parse them\n            'url': q.text.split('mp4:', 1)[0],\n            'play_path': 'mp4:' + q.text.split('mp4:', 1)[1],\n            'ext': 'flv',\n            'quality': 2 if q.attrib['quality'] == 'hd' else 1,\n        } for q in config.findall('./urls/url')]\n        self._sort_formats(formats)\n\n        title = config.find('.//name').text\n        thumbnail = config.find('.//firstThumbnailUrl').text\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 26,
        "end_line": 58,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTVPlus7IE._extract_url_info#66",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTVPlus7IE",
        "signature": "youtube_dl.extractor.arte.ArteTVPlus7IE._extract_url_info(cls, url)",
        "snippet": "    def _extract_url_info(cls, url):\n        mobj = re.match(cls._VALID_URL, url)\n        lang = mobj.group('lang')\n        # This is not a real id, it can be for example AJT for the news\n        # http://www.arte.tv/guide/fr/emissions/AJT/arte-journal\n        video_id = mobj.group('id')\n        return video_id, lang",
        "begin_line": 66,
        "end_line": 72,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009000900090009,
            "pseudo_dstar_susp": 0.0006983240223463687,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006983240223463687,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTVPlus7IE._real_extract#74",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTVPlus7IE",
        "signature": "youtube_dl.extractor.arte.ArteTVPlus7IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id, lang = self._extract_url_info(url)\n        webpage = self._download_webpage(url, video_id)\n        return self._extract_from_webpage(webpage, video_id, lang)",
        "begin_line": 74,
        "end_line": 77,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007692307692307692,
            "pseudo_dstar_susp": 0.0006273525721455458,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006273525721455458,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTVPlus7IE._extract_from_webpage#79",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTVPlus7IE",
        "signature": "youtube_dl.extractor.arte.ArteTVPlus7IE._extract_from_webpage(self, webpage, video_id, lang)",
        "snippet": "    def _extract_from_webpage(self, webpage, video_id, lang):\n        json_url = self._html_search_regex(\n            [r'arte_vp_url=[\"\\'](.*?)[\"\\']', r'data-url=[\"\\']([^\"]+)[\"\\']'],\n            webpage, 'json vp url')\n        return self._extract_from_json_url(json_url, video_id, lang)",
        "begin_line": 79,
        "end_line": 83,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTVPlus7IE._extract_from_json_url#85",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTVPlus7IE",
        "signature": "youtube_dl.extractor.arte.ArteTVPlus7IE._extract_from_json_url(self, json_url, video_id, lang)",
        "snippet": "    def _extract_from_json_url(self, json_url, video_id, lang):\n        info = self._download_json(json_url, video_id)\n        player_info = info['videoJsonPlayer']\n\n        info_dict = {\n            'id': player_info['VID'],\n            'title': player_info['VTI'],\n            'description': player_info.get('VDE'),\n            'upload_date': unified_strdate(player_info.get('VDA', '').split(' ')[0]),\n            'thumbnail': player_info.get('programImage') or player_info.get('VTU', {}).get('IUR'),\n        }\n\n        all_formats = player_info['VSR'].values()\n        # Some formats use the m3u8 protocol\n        all_formats = list(filter(lambda f: f.get('videoFormat') != 'M3U8', all_formats))\n        def _match_lang(f):\n            if f.get('versionCode') is None:\n                return True\n            # Return true if that format is in the language of the url\n            if lang == 'fr':\n                l = 'F'\n            elif lang == 'de':\n                l = 'A'\n            else:\n                l = lang\n            regexes = [r'VO?%s' % l, r'VO?.-ST%s' % l]\n            return any(re.match(r, f['versionCode']) for r in regexes)\n        # Some formats may not be in the same language as the url\n        # TODO: Might want not to drop videos that does not match requested language\n        # but to process those formats with lower precedence\n        formats = filter(_match_lang, all_formats)\n        formats = list(formats)  # in python3 filter returns an iterator\n        if not formats:\n            # Some videos are only available in the 'Originalversion'\n            # they aren't tagged as being in French or German\n            # Sometimes there are neither videos of requested lang code\n            # nor original version videos available\n            # For such cases we just take all_formats as is\n            formats = all_formats\n            if not formats:\n                raise ExtractorError('The formats list is empty')\n\n        if re.match(r'[A-Z]Q', formats[0]['quality']) is not None:\n            def sort_key(f):\n                return ['HQ', 'MQ', 'EQ', 'SQ'].index(f['quality'])\n        else:\n            def sort_key(f):\n                versionCode = f.get('versionCode')\n                if versionCode is None:\n                    versionCode = ''\n                return (\n                    # Sort first by quality\n                    int(f.get('height', -1)),\n                    int(f.get('bitrate', -1)),\n                    # The original version with subtitles has lower relevance\n                    re.match(r'VO-ST(F|A)', versionCode) is None,\n                    # The version with sourds/mal subtitles has also lower relevance\n                    re.match(r'VO?(F|A)-STM\\1', versionCode) is None,\n                    # Prefer http downloads over m3u8\n                    0 if f['url'].endswith('m3u8') else 1,\n                )\n        formats = sorted(formats, key=sort_key)\n        def _format(format_info):\n            quality = ''\n            height = format_info.get('height')\n            if height is not None:\n                quality = compat_str(height)\n            bitrate = format_info.get('bitrate')\n            if bitrate is not None:\n                quality += '-%d' % bitrate\n            if format_info.get('versionCode') is not None:\n                format_id = '%s-%s' % (quality, format_info['versionCode'])\n            else:\n                format_id = quality\n            info = {\n                'format_id': format_id,\n                'format_note': format_info.get('versionLibelle'),\n                'width': format_info.get('width'),\n                'height': height,\n            }\n            if format_info['mediaType'] == 'rtmp':\n                info['url'] = format_info['streamer']\n                info['play_path'] = 'mp4:' + format_info['url']\n                info['ext'] = 'flv'\n            else:\n                info['url'] = format_info['url']\n                info['ext'] = determine_ext(info['url'])\n            return info\n        info_dict['formats'] = [_format(f) for f in formats]\n\n        return info_dict",
        "begin_line": 85,
        "end_line": 175,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTVFutureIE._real_extract#217",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTVFutureIE",
        "signature": "youtube_dl.extractor.arte.ArteTVFutureIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        anchor_id, lang = self._extract_url_info(url)\n        webpage = self._download_webpage(url, anchor_id)\n        row = get_element_by_id(anchor_id, webpage)\n        return self._extract_from_webpage(row, anchor_id, lang)",
        "begin_line": 217,
        "end_line": 221,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTVDDCIE._real_extract#228",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTVDDCIE",
        "signature": "youtube_dl.extractor.arte.ArteTVDDCIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id, lang = self._extract_url_info(url)\n        if lang == 'folge':\n            lang = 'de'\n        elif lang == 'emission':\n            lang = 'fr'\n        webpage = self._download_webpage(url, video_id)\n        scriptElement = get_element_by_attribute('class', 'visu_video_block', webpage)\n        script_url = self._html_search_regex(r'src=\"(.*?)\"', scriptElement, 'script url')\n        javascriptPlayerGenerator = self._download_webpage(script_url, video_id, 'Download javascript player generator')\n        json_url = self._search_regex(r\"json_url=(.*)&rendering_place.*\", javascriptPlayerGenerator, 'json url')\n        return self._extract_from_json_url(json_url, video_id, lang)",
        "begin_line": 228,
        "end_line": 239,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTVEmbedIE._real_extract#270",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTVEmbedIE",
        "signature": "youtube_dl.extractor.arte.ArteTVEmbedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        lang = mobj.group('lang')\n        json_url = mobj.group('json_url')\n        return self._extract_from_json_url(json_url, video_id, lang)",
        "begin_line": 270,
        "end_line": 275,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.funnyordie.FunnyOrDieIE._real_extract#34",
        "src_path": "youtube_dl/extractor/funnyordie.py",
        "class_name": "youtube_dl.extractor.funnyordie.FunnyOrDieIE",
        "signature": "youtube_dl.extractor.funnyordie.FunnyOrDieIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n\n        links = re.findall(r'<source src=\"([^\"]+/v)\\d+\\.([^\"]+)\" type=\\'video', webpage)\n        if not links:\n            raise ExtractorError('No media links available for %s' % video_id)\n\n        links.sort(key=lambda link: 1 if link[1] == 'mp4' else 0)\n\n        bitrates = self._html_search_regex(r'<source src=\"[^\"]+/v,((?:\\d+,)+)\\.mp4\\.csmil', webpage, 'video bitrates')\n        bitrates = [int(b) for b in bitrates.rstrip(',').split(',')]\n        bitrates.sort()\n\n        formats = []\n\n        for bitrate in bitrates:\n            for link in links:\n                formats.append({\n                    'url': '%s%d.%s' % (link[0], bitrate, link[1]),\n                    'format_id': '%s-%d' % (link[1], bitrate),\n                    'vbr': bitrate,\n                })\n\n        post_json = self._search_regex(\n            r'fb_post\\s*=\\s*(\\{.*?\\});', webpage, 'post details')\n        post = json.loads(post_json)\n\n        return {\n            'id': video_id,\n            'title': post['name'],\n            'description': post.get('description'),\n            'thumbnail': post.get('picture'),\n            'formats': formats,\n        }",
        "begin_line": 34,
        "end_line": 70,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.academicearth.AcademicEarthCourseIE._real_extract#20",
        "src_path": "youtube_dl/extractor/academicearth.py",
        "class_name": "youtube_dl.extractor.academicearth.AcademicEarthCourseIE",
        "signature": "youtube_dl.extractor.academicearth.AcademicEarthCourseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        playlist_id = m.group('id')\n\n        webpage = self._download_webpage(url, playlist_id)\n        title = self._html_search_regex(\n            r'<h1 class=\"playlist-name\"[^>]*?>(.*?)</h1>', webpage, u'title')\n        description = self._html_search_regex(\n            r'<p class=\"excerpt\"[^>]*?>(.*?)</p>',\n            webpage, u'description', fatal=False)\n        urls = re.findall(\n            r'<li class=\"lecture-preview\">\\s*?<a target=\"_blank\" href=\"([^\"]+)\">',\n            webpage)\n        entries = [self.url_result(u) for u in urls]\n\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'title': title,\n            'description': description,\n            'entries': entries,\n        }",
        "begin_line": 20,
        "end_line": 41,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.appletrailers.AppleTrailersIE._real_extract#67",
        "src_path": "youtube_dl/extractor/appletrailers.py",
        "class_name": "youtube_dl.extractor.appletrailers.AppleTrailersIE",
        "signature": "youtube_dl.extractor.appletrailers.AppleTrailersIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        movie = mobj.group('movie')\n        uploader_id = mobj.group('company')\n\n        playlist_url = compat_urlparse.urljoin(url, 'includes/playlists/itunes.inc')\n        def fix_html(s):\n            s = re.sub(r'(?s)<script[^<]*?>.*?</script>', '', s)\n            s = re.sub(r'<img ([^<]*?)>', r'<img \\1/>', s)\n            # The ' in the onClick attributes are not escaped, it couldn't be parsed\n            # like: http://trailers.apple.com/trailers/wb/gravity/\n            def _clean_json(m):\n                return 'iTunes.playURL(%s);' % m.group(1).replace('\\'', '&#39;')\n            s = re.sub(self._JSON_RE, _clean_json, s)\n            s = '<html>' + s + u'</html>'\n            return s\n        doc = self._download_xml(playlist_url, movie, transform_source=fix_html)\n\n        playlist = []\n        for li in doc.findall('./div/ul/li'):\n            on_click = li.find('.//a').attrib['onClick']\n            trailer_info_json = self._search_regex(self._JSON_RE,\n                on_click, 'trailer info')\n            trailer_info = json.loads(trailer_info_json)\n            title = trailer_info['title']\n            video_id = movie + '-' + re.sub(r'[^a-zA-Z0-9]', '', title).lower()\n            thumbnail = li.find('.//img').attrib['src']\n            upload_date = trailer_info['posted'].replace('-', '')\n\n            runtime = trailer_info['runtime']\n            m = re.search(r'(?P<minutes>[0-9]+):(?P<seconds>[0-9]{1,2})', runtime)\n            duration = None\n            if m:\n                duration = 60 * int(m.group('minutes')) + int(m.group('seconds'))\n\n            first_url = trailer_info['url']\n            trailer_id = first_url.split('/')[-1].rpartition('_')[0].lower()\n            settings_json_url = compat_urlparse.urljoin(url, 'includes/settings/%s.json' % trailer_id)\n            settings = self._download_json(settings_json_url, trailer_id, 'Downloading settings json')\n\n            formats = []\n            for format in settings['metadata']['sizes']:\n                # The src is a file pointing to the real video file\n                format_url = re.sub(r'_(\\d*p.mov)', r'_h\\1', format['src'])\n                formats.append({\n                    'url': format_url,\n                    'format': format['type'],\n                    'width': int_or_none(format['width']),\n                    'height': int_or_none(format['height']),\n                })\n\n            self._sort_formats(formats)\n\n            playlist.append({\n                '_type': 'video',\n                'id': video_id,\n                'title': title,\n                'formats': formats,\n                'title': title,\n                'duration': duration,\n                'thumbnail': thumbnail,\n                'upload_date': upload_date,\n                'uploader_id': uploader_id,\n                'user_agent': 'QuickTime compatible (youtube-dl)',\n            })\n\n        return {\n            '_type': 'playlist',\n            'id': movie,\n            'entries': playlist,\n        }",
        "begin_line": 67,
        "end_line": 137,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.appletrailers.AppleTrailersIE.fix_html#73",
        "src_path": "youtube_dl/extractor/appletrailers.py",
        "class_name": "youtube_dl.extractor.appletrailers.AppleTrailersIE",
        "signature": "youtube_dl.extractor.appletrailers.AppleTrailersIE.fix_html(s)",
        "snippet": "        def fix_html(s):\n            s = re.sub(r'(?s)<script[^<]*?>.*?</script>', '', s)\n            s = re.sub(r'<img ([^<]*?)>', r'<img \\1/>', s)\n            # The ' in the onClick attributes are not escaped, it couldn't be parsed\n            # like: http://trailers.apple.com/trailers/wb/gravity/\n            def _clean_json(m):\n                return 'iTunes.playURL(%s);' % m.group(1).replace('\\'', '&#39;')\n            s = re.sub(self._JSON_RE, _clean_json, s)\n            s = '<html>' + s + u'</html>'\n            return s",
        "begin_line": 73,
        "end_line": 82,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.appletrailers.AppleTrailersIE._clean_json#78",
        "src_path": "youtube_dl/extractor/appletrailers.py",
        "class_name": "youtube_dl.extractor.appletrailers.AppleTrailersIE",
        "signature": "youtube_dl.extractor.appletrailers.AppleTrailersIE._clean_json(m)",
        "snippet": "            def _clean_json(m):\n                return 'iTunes.playURL(%s);' % m.group(1).replace('\\'', '&#39;')",
        "begin_line": 78,
        "end_line": 79,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.postprocessor.common.PostProcessor.__init__#23",
        "src_path": "youtube_dl/postprocessor/common.py",
        "class_name": "youtube_dl.postprocessor.common.PostProcessor",
        "signature": "youtube_dl.postprocessor.common.PostProcessor.__init__(self, downloader=None)",
        "snippet": "    def __init__(self, downloader=None):\n        self._downloader = downloader",
        "begin_line": 23,
        "end_line": 24,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.postprocessor.common.PostProcessor.set_downloader#26",
        "src_path": "youtube_dl/postprocessor/common.py",
        "class_name": "youtube_dl.postprocessor.common.PostProcessor",
        "signature": "youtube_dl.postprocessor.common.PostProcessor.set_downloader(self, downloader)",
        "snippet": "    def set_downloader(self, downloader):\n        \"\"\"Sets the downloader for this PP.\"\"\"\n        self._downloader = downloader",
        "begin_line": 26,
        "end_line": 28,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.postprocessor.common.PostProcessor.run#30",
        "src_path": "youtube_dl/postprocessor/common.py",
        "class_name": "youtube_dl.postprocessor.common.PostProcessor",
        "signature": "youtube_dl.postprocessor.common.PostProcessor.run(self, information)",
        "snippet": "    def run(self, information):\n        \"\"\"Run the PostProcessor.\n\n        The \"information\" argument is a dictionary like the ones\n        composed by InfoExtractors. The only difference is that this\n        one has an extra field called \"filepath\" that points to the\n        downloaded file.\n\n        This method returns a tuple, the first element of which describes\n        whether the original file should be kept (i.e. not deleted - None for\n        no preference), and the second of which is the updated information.\n\n        In addition, this method may raise a PostProcessingError\n        exception if post processing fails.\n        \"\"\"\n        return None, information  # by default, keep file and do nothing",
        "begin_line": 30,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.space.SpaceIE._real_extract#24",
        "src_path": "youtube_dl/extractor/space.py",
        "class_name": "youtube_dl.extractor.space.SpaceIE",
        "signature": "youtube_dl.extractor.space.SpaceIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        title = mobj.group('title')\n        webpage = self._download_webpage(url, title)\n        try:\n            # Some videos require the playerKey field, which isn't define in\n            # the BrightcoveExperience object\n            brightcove_url = self._og_search_video_url(webpage)\n        except RegexNotFoundError:\n            # Other videos works fine with the info from the object\n            brightcove_url = BrightcoveIE._extract_brightcove_url(webpage)\n        if brightcove_url is None:\n            raise ExtractorError(u'The webpage does not contain a video', expected=True)\n        return self.url_result(brightcove_url, BrightcoveIE.ie_key())",
        "begin_line": 24,
        "end_line": 37,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.postprocessor.execafterdownload.ExecAfterDownloadPP.__init__#13",
        "src_path": "youtube_dl/postprocessor/execafterdownload.py",
        "class_name": "youtube_dl.postprocessor.execafterdownload.ExecAfterDownloadPP",
        "signature": "youtube_dl.postprocessor.execafterdownload.ExecAfterDownloadPP.__init__(self, downloader=None, verboseOutput=None, exec_cmd=None)",
        "snippet": "    def __init__(self, downloader=None, verboseOutput=None, exec_cmd=None):\n        self.verboseOutput = verboseOutput\n        self.exec_cmd = exec_cmd",
        "begin_line": 13,
        "end_line": 15,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.postprocessor.execafterdownload.ExecAfterDownloadPP.run#17",
        "src_path": "youtube_dl/postprocessor/execafterdownload.py",
        "class_name": "youtube_dl.postprocessor.execafterdownload.ExecAfterDownloadPP",
        "signature": "youtube_dl.postprocessor.execafterdownload.ExecAfterDownloadPP.run(self, information)",
        "snippet": "    def run(self, information):\n        cmd = self.exec_cmd\n        if not '{}' in cmd:\n            cmd += ' {}'\n\n        cmd = cmd.replace('{}', shlex_quote(information['filepath']))\n\n        self._downloader.to_screen(\"[exec] Executing command: %s\" % cmd)\n        retCode = subprocess.call(cmd, shell=True)\n        if retCode != 0:\n            raise PostProcessingError(\n                'Command returned error code %d' % retCode)\n\n        return None, information  # by default, keep file and do nothing",
        "begin_line": 17,
        "end_line": 30,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.c56.C56IE._real_extract#23",
        "src_path": "youtube_dl/extractor/c56.py",
        "class_name": "youtube_dl.extractor.c56.C56IE",
        "signature": "youtube_dl.extractor.c56.C56IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url, flags=re.VERBOSE)\n        text_id = mobj.group('textid')\n\n        page = self._download_json(\n            'http://vxml.56.com/json/%s/' % text_id, text_id, 'Downloading video info')\n\n        info = page['info']\n\n        formats = [\n            {\n                'format_id': f['type'],\n                'filesize': int(f['filesize']),\n                'url': f['url']\n            } for f in info['rfiles']\n        ]\n        self._sort_formats(formats)\n\n        return {\n            'id': info['vid'],\n            'title': info['Subject'],\n            'duration': int(info['duration']) / 1000.0,\n            'formats': formats,\n            'thumbnail': info.get('bimg') or info.get('img'),\n        }",
        "begin_line": 23,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudIE.report_resolve#102",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudIE.report_resolve(self, video_id)",
        "snippet": "    def report_resolve(self, video_id):\n        \"\"\"Report information extraction.\"\"\"\n        self.to_screen('%s: Resolving id' % video_id)",
        "begin_line": 102,
        "end_line": 104,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0010030090270812437,
            "pseudo_dstar_susp": 0.0007739938080495357,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0007739938080495357,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudIE._resolv_url#107",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudIE._resolv_url(cls, url)",
        "snippet": "    def _resolv_url(cls, url):\n        return 'http://api.soundcloud.com/resolve.json?url=' + url + '&client_id=' + cls._CLIENT_ID",
        "begin_line": 107,
        "end_line": 108,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0012578616352201257,
            "pseudo_dstar_susp": 0.0008285004142502071,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0008285004142502071,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudIE._extract_info_dict#110",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudIE._extract_info_dict(self, info, full_title=None, quiet=False, secret_token=None)",
        "snippet": "    def _extract_info_dict(self, info, full_title=None, quiet=False, secret_token=None):\n        track_id = compat_str(info['id'])\n        name = full_title or track_id\n        if quiet:\n            self.report_extraction(name)\n\n        thumbnail = info['artwork_url']\n        if thumbnail is not None:\n            thumbnail = thumbnail.replace('-large', '-t500x500')\n        ext = 'mp3'\n        result = {\n            'id': track_id,\n            'uploader': info['user']['username'],\n            'upload_date': unified_strdate(info['created_at']),\n            'title': info['title'],\n            'description': info['description'],\n            'thumbnail': thumbnail,\n            'duration': int_or_none(info.get('duration'), 1000),\n        }\n        formats = []\n        if info.get('downloadable', False):\n            # We can build a direct link to the song\n            format_url = (\n                'https://api.soundcloud.com/tracks/{0}/download?client_id={1}'.format(\n                    track_id, self._CLIENT_ID))\n            formats.append({\n                'format_id': 'download',\n                'ext': info.get('original_format', 'mp3'),\n                'url': format_url,\n                'vcodec': 'none',\n                'preference': 10,\n            })\n\n        # We have to retrieve the url\n        streams_url = ('http://api.soundcloud.com/i1/tracks/{0}/streams?'\n            'client_id={1}&secret_token={2}'.format(track_id, self._IPHONE_CLIENT_ID, secret_token))\n        format_dict = self._download_json(\n            streams_url,\n            track_id, 'Downloading track url')\n\n        for key, stream_url in format_dict.items():\n            if key.startswith('http'):\n                formats.append({\n                    'format_id': key,\n                    'ext': ext,\n                    'url': stream_url,\n                    'vcodec': 'none',\n                })\n            elif key.startswith('rtmp'):\n                # The url doesn't have an rtmp app, we have to extract the playpath\n                url, path = stream_url.split('mp3:', 1)\n                formats.append({\n                    'format_id': key,\n                    'url': url,\n                    'play_path': 'mp3:' + path,\n                    'ext': ext,\n                    'vcodec': 'none',\n                })\n\n            if not formats:\n                # We fallback to the stream_url in the original info, this\n                # cannot be always used, sometimes it can give an HTTP 404 error\n                formats.append({\n                    'format_id': 'fallback',\n                    'url': info['stream_url'] + '?client_id=' + self._CLIENT_ID,\n                    'ext': ext,\n                    'vcodec': 'none',\n                })\n\n            for f in formats:\n                if f['format_id'].startswith('http'):\n                    f['protocol'] = 'http'\n                if f['format_id'].startswith('rtmp'):\n                    f['protocol'] = 'rtmp'\n\n            self._sort_formats(formats)\n            result['formats'] = formats\n\n        return result",
        "begin_line": 110,
        "end_line": 188,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudIE._real_extract#190",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url, flags=re.VERBOSE)\n        if mobj is None:\n            raise ExtractorError('Invalid URL: %s' % url)\n\n        track_id = mobj.group('track_id')\n        token = None\n        if track_id is not None:\n            info_json_url = 'http://api.soundcloud.com/tracks/' + track_id + '.json?client_id=' + self._CLIENT_ID\n            full_title = track_id\n        elif mobj.group('player'):\n            query = compat_urlparse.parse_qs(compat_urlparse.urlparse(url).query)\n            return self.url_result(query['url'][0])\n        else:\n            # extract uploader (which is in the url)\n            uploader = mobj.group('uploader')\n            # extract simple title (uploader + slug of song title)\n            slug_title =  mobj.group('title')\n            token = mobj.group('token')\n            full_title = resolve_title = '%s/%s' % (uploader, slug_title)\n            if token:\n                resolve_title += '/%s' % token\n    \n            self.report_resolve(full_title)\n    \n            url = 'http://soundcloud.com/%s' % resolve_title\n            info_json_url = self._resolv_url(url)\n        info = self._download_json(info_json_url, full_title, 'Downloading info JSON')\n\n        return self._extract_info_dict(info, full_title, secret_token=token)",
        "begin_line": 190,
        "end_line": 219,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009000900090009,
            "pseudo_dstar_susp": 0.0006983240223463687,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006983240223463687,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudSetIE._real_extract#233",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudSetIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudSetIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        # extract uploader (which is in the url)\n        uploader = mobj.group(1)\n        # extract simple title (uploader + slug of song title)\n        slug_title = mobj.group(2)\n        full_title = '%s/sets/%s' % (uploader, slug_title)\n\n        self.report_resolve(full_title)\n\n        url = 'http://soundcloud.com/%s/sets/%s' % (uploader, slug_title)\n        resolv_url = self._resolv_url(url)\n        info = self._download_json(resolv_url, full_title)\n\n        if 'errors' in info:\n            for err in info['errors']:\n                self._downloader.report_error('unable to download video webpage: %s' % compat_str(err['error_message']))\n            return\n\n        return {\n            '_type': 'playlist',\n            'entries': [self._extract_info_dict(track) for track in info['tracks']],\n            'id': info['id'],\n            'title': info['title'],\n        }",
        "begin_line": 233,
        "end_line": 258,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudUserIE._real_extract#280",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudUserIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        uploader = mobj.group('user')\n        resource = mobj.group('rsrc')\n        if resource is None:\n            resource = 'tracks'\n        elif resource == 'likes':\n            resource = 'favorites'\n\n        url = 'http://soundcloud.com/%s/' % uploader\n        resolv_url = self._resolv_url(url)\n        user = self._download_json(\n            resolv_url, uploader, 'Downloading user info')\n        base_url = 'http://api.soundcloud.com/users/%s/%s.json?' % (uploader, resource)\n\n        entries = []\n        for i in itertools.count():\n            data = compat_urllib_parse.urlencode({\n                'offset': i * 50,\n                'limit': 50,\n                'client_id': self._CLIENT_ID,\n            })\n            new_entries = self._download_json(\n                base_url + data, uploader, 'Downloading track page %s' % (i + 1))\n            if len(new_entries) == 0:\n                self.to_screen('%s: End page received' % uploader)\n                break\n            entries.extend(self._extract_info_dict(e, quiet=True) for e in new_entries)\n\n        return {\n            '_type': 'playlist',\n            'id': compat_str(user['id']),\n            'title': user['username'],\n            'entries': entries,\n        }",
        "begin_line": 280,
        "end_line": 314,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudPlaylistIE._real_extract#333",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudPlaylistIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('id')\n        base_url = '%s//api.soundcloud.com/playlists/%s.json?' % (self.http_scheme(), playlist_id)\n\n        data = compat_urllib_parse.urlencode({\n            'client_id': self._CLIENT_ID,\n        })\n        data = self._download_json(\n            base_url + data, playlist_id, 'Downloading playlist')\n\n        entries = [\n            self._extract_info_dict(t, quiet=True) for t in data['tracks']]\n\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'title': data.get('title'),\n            'description': data.get('description'),\n            'entries': entries,\n        }",
        "begin_line": 333,
        "end_line": 353,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.xvideos.XVideosIE._real_extract#26",
        "src_path": "youtube_dl/extractor/xvideos.py",
        "class_name": "youtube_dl.extractor.xvideos.XVideosIE",
        "signature": "youtube_dl.extractor.xvideos.XVideosIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group(1)\n\n        webpage = self._download_webpage(url, video_id)\n\n        self.report_extraction(video_id)\n\n        mobj = re.search(r'<h1 class=\"inlineError\">(.+?)</h1>', webpage)\n        if mobj:\n            raise ExtractorError('%s said: %s' % (self.IE_NAME, clean_html(mobj.group(1))), expected=True)\n\n        # Extract video URL\n        video_url = compat_urllib_parse.unquote(\n            self._search_regex(r'flv_url=(.+?)&', webpage, 'video URL'))\n\n        # Extract title\n        video_title = self._html_search_regex(\n            r'<title>(.*?)\\s+-\\s+XVID', webpage, 'title')\n\n        # Extract video thumbnail\n        video_thumbnail = self._search_regex(\n            r'url_bigthumb=(.+?)&amp', webpage, 'thumbnail', fatal=False)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'uploader': None,\n            'upload_date': None,\n            'title': video_title,\n            'ext': 'flv',\n            'thumbnail': video_thumbnail,\n            'description': None,\n            'age_limit': 18,\n        }",
        "begin_line": 26,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.roxwel.RoxwelIE._real_extract#29",
        "src_path": "youtube_dl/extractor/roxwel.py",
        "class_name": "youtube_dl.extractor.roxwel.RoxwelIE",
        "signature": "youtube_dl.extractor.roxwel.RoxwelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        filename = mobj.group('filename')\n        info_url = 'http://www.roxwel.com/api/videos/%s' % filename\n        info = self._download_json(info_url, filename)\n\n        rtmp_rates = sorted([int(r.replace('flv_', '')) for r in info['media_rates'] if r.startswith('flv_')])\n        best_rate = rtmp_rates[-1]\n        url_page_url = 'http://roxwel.com/pl_one_time.php?filename=%s&quality=%s' % (filename, best_rate)\n        rtmp_url = self._download_webpage(url_page_url, filename, 'Downloading video url')\n        ext = determine_ext(rtmp_url)\n        if ext == 'f4v':\n            rtmp_url = rtmp_url.replace(filename, 'mp4:%s' % filename)\n\n        return {\n            'id': filename,\n            'title': info['title'],\n            'url': rtmp_url,\n            'ext': 'flv',\n            'description': info['description'],\n            'thumbnail': info.get('player_image_url') or info.get('image_url_large'),\n            'uploader': info['artist'],\n            'uploader_id': info['artistname'],\n            'upload_date': unified_strdate(info['dbdate']),\n        }",
        "begin_line": 29,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.wdr.WDRIE._real_extract#70",
        "src_path": "youtube_dl/extractor/wdr.py",
        "class_name": "youtube_dl.extractor.wdr.WDRIE",
        "signature": "youtube_dl.extractor.wdr.WDRIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        page_url = mobj.group('url')\n        page_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, page_id)\n\n        if mobj.group('player') is None:\n            entries = [\n                self.url_result(page_url + href, 'WDR')\n                for href in re.findall(r'<a href=\"/?(.+?%s\\.html)\" rel=\"nofollow\"' % self._PLAYER_REGEX, webpage)\n            ]\n            return self.playlist_result(entries, page_id)\n\n        flashvars = compat_parse_qs(\n            self._html_search_regex(r'<param name=\"flashvars\" value=\"([^\"]+)\"', webpage, 'flashvars'))\n\n        page_id = flashvars['trackerClipId'][0]\n        video_url = flashvars['dslSrc'][0]\n        title = flashvars['trackerClipTitle'][0]\n        thumbnail = flashvars['startPicture'][0] if 'startPicture' in flashvars else None\n\n        if 'trackerClipAirTime' in flashvars:\n            upload_date = flashvars['trackerClipAirTime'][0]\n        else:\n            upload_date = self._html_search_meta('DC.Date', webpage, 'upload date')\n\n        if upload_date:\n            upload_date = unified_strdate(upload_date)\n\n        if video_url.endswith('.f4m'):\n            video_url += '?hdcore=3.2.0&plugin=aasp-3.2.0.77.18'\n            ext = 'flv'\n        else:\n            ext = determine_ext(video_url)\n\n        description = self._html_search_meta('Description', webpage, 'description')\n\n        return {\n            'id': page_id,\n            'url': video_url,\n            'ext': ext,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n        }",
        "begin_line": 70,
        "end_line": 116,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009000900090009,
            "pseudo_dstar_susp": 0.0006983240223463687,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006983240223463687,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.wdr.WDRMobileIE._real_extract#137",
        "src_path": "youtube_dl/extractor/wdr.py",
        "class_name": "youtube_dl.extractor.wdr.WDRMobileIE",
        "signature": "youtube_dl.extractor.wdr.WDRMobileIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        return {\n            'id': mobj.group('id'),\n            'title': mobj.group('title'),\n            'age_limit': int(mobj.group('age_limit')),\n            'url': url,\n            'ext': determine_ext(url),\n            'user_agent': 'mobile',\n        }",
        "begin_line": 137,
        "end_line": 146,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.wdr.WDRMausIE._real_extract#173",
        "src_path": "youtube_dl/extractor/wdr.py",
        "class_name": "youtube_dl.extractor.wdr.WDRMausIE",
        "signature": "youtube_dl.extractor.wdr.WDRMausIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        param_code = self._html_search_regex(\n            r'<a href=\"\\?startVideo=1&amp;([^\"]+)\"', webpage, 'parameters')\n\n        title_date = self._search_regex(\n            r'<div class=\"sendedatum\"><p>Sendedatum:\\s*([0-9\\.]+)</p>',\n            webpage, 'air date')\n        title_str = self._html_search_regex(\n            r'<h1>(.*?)</h1>', webpage, 'title')\n        title = '%s - %s' % (title_date, title_str)\n        upload_date = unified_strdate(\n            self._html_search_meta('dc.date', webpage))\n\n        fields = compat_parse_qs(param_code)\n        video_url = fields['firstVideo'][0]\n        thumbnail = compat_urlparse.urljoin(url, fields['startPicture'][0])\n\n        formats = [{\n            'format_id': 'rtmp',\n            'url': video_url,\n        }]\n\n        jscode = self._download_webpage(\n            'http://www.wdrmaus.de/codebase/js/extended-medien.min.js',\n            video_id, fatal=False,\n            note='Downloading URL translation table',\n            errnote='Could not download URL translation table')\n        if jscode:\n            for m in re.finditer(\n                    r\"stream:\\s*'dslSrc=(?P<stream>[^']+)',\\s*download:\\s*'(?P<dl>[^']+)'\\s*\\}\",\n                    jscode):\n                if video_url.startswith(m.group('stream')):\n                    http_url = video_url.replace(\n                        m.group('stream'), m.group('dl'))\n                    formats.append({\n                        'format_id': 'http',\n                        'url': http_url,\n                    })\n                    break\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n        }",
        "begin_line": 173,
        "end_line": 225,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.ubu.UbuIE._real_extract#22",
        "src_path": "youtube_dl/extractor/ubu.py",
        "class_name": "youtube_dl.extractor.ubu.UbuIE",
        "signature": "youtube_dl.extractor.ubu.UbuIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(\n            r'<title>.+?Film &amp; Video: ([^<]+)</title>', webpage, 'title')\n\n        duration = int_or_none(self._html_search_regex(\n            r'Duration: (\\d+) minutes', webpage, 'duration', fatal=False, default=None))\n        if duration:\n            duration *= 60\n\n        formats = []\n\n        FORMAT_REGEXES = [\n            ['sq', r\"'flashvars'\\s*,\\s*'file=([^']+)'\"],\n            ['hq', r'href=\"(http://ubumexico\\.centro\\.org\\.mx/video/[^\"]+)\"']\n        ]\n\n        for format_id, format_regex in FORMAT_REGEXES:\n            m = re.search(format_regex, webpage)\n            if m:\n                formats.append({\n                    'url': m.group(1),\n                    'format_id': format_id,\n                })\n\n        return {\n            'id': video_id,\n            'title': title,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 22,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.viki.VikiIE._real_extract#33",
        "src_path": "youtube_dl/extractor/viki.py",
        "class_name": "youtube_dl.extractor.viki.VikiIE",
        "signature": "youtube_dl.extractor.viki.VikiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group(1)\n\n        webpage = self._download_webpage(url, video_id)\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        uploader_m = re.search(\n            r'<strong>Broadcast Network: </strong>\\s*([^<]*)<', webpage)\n        if uploader_m is None:\n            uploader = None\n        else:\n            uploader = uploader_m.group(1).strip()\n\n        rating_str = self._html_search_regex(\n            r'<strong>Rating: </strong>\\s*([^<]*)<', webpage,\n            'rating information', default='').strip()\n        age_limit = US_RATINGS.get(rating_str)\n\n        info_url = 'http://www.viki.com/player5_fragment/%s?action=show&controller=videos' % video_id\n        info_webpage = self._download_webpage(\n            info_url, video_id, note='Downloading info page')\n        if re.match(r'\\s*<div\\s+class=\"video-error', info_webpage):\n            raise ExtractorError(\n                'Video %s is blocked from your location.' % video_id,\n                expected=True)\n        video_url = self._html_search_regex(\n            r'<source[^>]+src=\"([^\"]+)\"', info_webpage, 'video URL')\n\n        upload_date_str = self._html_search_regex(\n            r'\"created_at\":\"([^\"]+)\"', info_webpage, 'upload date')\n        upload_date = (\n            unified_strdate(upload_date_str)\n            if upload_date_str is not None\n            else None\n        )\n\n        # subtitles\n        video_subtitles = self.extract_subtitles(video_id, info_webpage)\n        if self._downloader.params.get('listsubtitles', False):\n            self._list_available_subtitles(video_id, info_webpage)\n            return\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'description': description,\n            'thumbnail': thumbnail,\n            'age_limit': age_limit,\n            'uploader': uploader,\n            'subtitles': video_subtitles,\n            'upload_date': upload_date,\n        }",
        "begin_line": 33,
        "end_line": 88,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.viki.VikiIE._get_available_subtitles#90",
        "src_path": "youtube_dl/extractor/viki.py",
        "class_name": "youtube_dl.extractor.viki.VikiIE",
        "signature": "youtube_dl.extractor.viki.VikiIE._get_available_subtitles(self, video_id, info_webpage)",
        "snippet": "    def _get_available_subtitles(self, video_id, info_webpage):\n        res = {}\n        for sturl_html in re.findall(r'<track src=\"([^\"]+)\"/>', info_webpage):\n            sturl = unescapeHTML(sturl_html)\n            m = re.search(r'/(?P<lang>[a-z]+)\\.vtt', sturl)\n            if not m:\n                continue\n            res[m.group('lang')] = sturl\n        return res",
        "begin_line": 90,
        "end_line": 98,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.update.rsa_verify#16",
        "src_path": "youtube_dl/update.py",
        "class_name": "youtube_dl.update",
        "signature": "youtube_dl.update.rsa_verify(message, signature, key)",
        "snippet": "def rsa_verify(message, signature, key):\n    from struct import pack\n    from hashlib import sha256\n    from sys import version_info\n    def b(x):\n        if version_info[0] == 2: return x\n        else: return x.encode('latin1')\n    assert(type(message) == type(b('')))\n    block_size = 0\n    n = key[0]\n    while n:\n        block_size += 1\n        n >>= 8\n    signature = pow(int(signature, 16), key[1], key[0])\n    raw_bytes = []\n    while signature:\n        raw_bytes.insert(0, pack(\"B\", signature & 0xFF))\n        signature >>= 8\n    signature = (block_size - len(raw_bytes)) * b('\\x00') + b('').join(raw_bytes)\n    if signature[0:2] != b('\\x00\\x01'): return False\n    signature = signature[2:]\n    if not b('\\x00') in signature: return False\n    signature = signature[signature.index(b('\\x00'))+1:]\n    if not signature.startswith(b('\\x30\\x31\\x30\\x0D\\x06\\x09\\x60\\x86\\x48\\x01\\x65\\x03\\x04\\x02\\x01\\x05\\x00\\x04\\x20')): return False\n    signature = signature[19:]\n    if signature != sha256(message).digest(): return False\n    return True",
        "begin_line": 16,
        "end_line": 42,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.update.update_self#45",
        "src_path": "youtube_dl/update.py",
        "class_name": "youtube_dl.update",
        "signature": "youtube_dl.update.update_self(to_screen, verbose)",
        "snippet": "def update_self(to_screen, verbose):\n    \"\"\"Update the program file with the latest version from the repository\"\"\"\n\n    UPDATE_URL = \"http://rg3.github.io/youtube-dl/update/\"\n    VERSION_URL = UPDATE_URL + 'LATEST_VERSION'\n    JSON_URL = UPDATE_URL + 'versions.json'\n    UPDATES_RSA_KEY = (0x9d60ee4d8f805312fdb15a62f87b95bd66177b91df176765d13514a0f1754bcd2057295c5b6f1d35daa6742c3ffc9a82d3e118861c207995a8031e151d863c9927e304576bc80692bc8e094896fcf11b66f3e29e04e3a71e9a11558558acea1840aec37fc396fb6b65dc81a1c4144e03bd1c011de62e3f1357b327d08426fe93, 65537)\n\n    if not isinstance(globals().get('__loader__'), zipimporter) and not hasattr(sys, \"frozen\"):\n        to_screen(u'It looks like you installed youtube-dl with a package manager, pip, setup.py or a tarball. Please use that to update.')\n        return\n\n    # Check if there is a new version\n    try:\n        newversion = compat_urllib_request.urlopen(VERSION_URL).read().decode('utf-8').strip()\n    except:\n        if verbose: to_screen(compat_str(traceback.format_exc()))\n        to_screen(u'ERROR: can\\'t find the current version. Please try again later.')\n        return\n    if newversion == __version__:\n        to_screen(u'youtube-dl is up-to-date (' + __version__ + ')')\n        return\n\n    # Download and check versions info\n    try:\n        versions_info = compat_urllib_request.urlopen(JSON_URL).read().decode('utf-8')\n        versions_info = json.loads(versions_info)\n    except:\n        if verbose: to_screen(compat_str(traceback.format_exc()))\n        to_screen(u'ERROR: can\\'t obtain versions info. Please try again later.')\n        return\n    if not 'signature' in versions_info:\n        to_screen(u'ERROR: the versions file is not signed or corrupted. Aborting.')\n        return\n    signature = versions_info['signature']\n    del versions_info['signature']\n    if not rsa_verify(json.dumps(versions_info, sort_keys=True).encode('utf-8'), signature, UPDATES_RSA_KEY):\n        to_screen(u'ERROR: the versions file signature is invalid. Aborting.')\n        return\n\n    version_id = versions_info['latest']\n\n    def version_tuple(version_str):\n        return tuple(map(int, version_str.split('.')))\n    if version_tuple(__version__) >= version_tuple(version_id):\n        to_screen(u'youtube-dl is up to date (%s)' % __version__)\n        return\n\n    to_screen(u'Updating to version ' + version_id + ' ...')\n    version = versions_info['versions'][version_id]\n\n    print_notes(to_screen, versions_info['versions'])\n\n    filename = sys.argv[0]\n    # Py2EXE: Filename could be different\n    if hasattr(sys, \"frozen\") and not os.path.isfile(filename):\n        if os.path.isfile(filename + u'.exe'):\n            filename += u'.exe'\n\n    if not os.access(filename, os.W_OK):\n        to_screen(u'ERROR: no write permissions on %s' % filename)\n        return\n\n    # Py2EXE\n    if hasattr(sys, \"frozen\"):\n        exe = os.path.abspath(filename)\n        directory = os.path.dirname(exe)\n        if not os.access(directory, os.W_OK):\n            to_screen(u'ERROR: no write permissions on %s' % directory)\n            return\n\n        try:\n            urlh = compat_urllib_request.urlopen(version['exe'][0])\n            newcontent = urlh.read()\n            urlh.close()\n        except (IOError, OSError):\n            if verbose: to_screen(compat_str(traceback.format_exc()))\n            to_screen(u'ERROR: unable to download latest version')\n            return\n\n        newcontent_hash = hashlib.sha256(newcontent).hexdigest()\n        if newcontent_hash != version['exe'][1]:\n            to_screen(u'ERROR: the downloaded file hash does not match. Aborting.')\n            return\n\n        try:\n            with open(exe + '.new', 'wb') as outf:\n                outf.write(newcontent)\n        except (IOError, OSError):\n            if verbose: to_screen(compat_str(traceback.format_exc()))\n            to_screen(u'ERROR: unable to write the new version')\n            return\n\n        try:\n            bat = os.path.join(directory, 'youtube-dl-updater.bat')\n            with io.open(bat, 'w') as batfile:\n                batfile.write(u\"\"\"\n@echo off\necho Waiting for file handle to be closed ...\nping 127.0.0.1 -n 5 -w 1000 > NUL\nmove /Y \"%s.new\" \"%s\" > NUL\necho Updated youtube-dl to version %s.\nstart /b \"\" cmd /c del \"%%~f0\"&exit /b\"\n                \\n\"\"\" % (exe, exe, version_id))\n\n            subprocess.Popen([bat])  # Continues to run in the background\n            return  # Do not show premature success messages\n        except (IOError, OSError):\n            if verbose: to_screen(compat_str(traceback.format_exc()))\n            to_screen(u'ERROR: unable to overwrite current version')\n            return\n\n    # Zip unix package\n    elif isinstance(globals().get('__loader__'), zipimporter):\n        try:\n            urlh = compat_urllib_request.urlopen(version['bin'][0])\n            newcontent = urlh.read()\n            urlh.close()\n        except (IOError, OSError):\n            if verbose: to_screen(compat_str(traceback.format_exc()))\n            to_screen(u'ERROR: unable to download latest version')\n            return\n\n        newcontent_hash = hashlib.sha256(newcontent).hexdigest()\n        if newcontent_hash != version['bin'][1]:\n            to_screen(u'ERROR: the downloaded file hash does not match. Aborting.')\n            return\n\n        try:\n            with open(filename, 'wb') as outf:\n                outf.write(newcontent)\n        except (IOError, OSError):\n            if verbose: to_screen(compat_str(traceback.format_exc()))\n            to_screen(u'ERROR: unable to overwrite current version')\n            return\n\n    to_screen(u'Updated youtube-dl. Restart youtube-dl to use the new version.')",
        "begin_line": 45,
        "end_line": 181,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.update.get_notes#183",
        "src_path": "youtube_dl/update.py",
        "class_name": "youtube_dl.update",
        "signature": "youtube_dl.update.get_notes(versions, fromVersion)",
        "snippet": "def get_notes(versions, fromVersion):\n    notes = []\n    for v,vdata in sorted(versions.items()):\n        if v > fromVersion:\n            notes.extend(vdata.get('notes', []))\n    return notes",
        "begin_line": 183,
        "end_line": 188,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.update.print_notes#190",
        "src_path": "youtube_dl/update.py",
        "class_name": "youtube_dl.update",
        "signature": "youtube_dl.update.print_notes(to_screen, versions, fromVersion=__version__)",
        "snippet": "def print_notes(to_screen, versions, fromVersion=__version__):\n    notes = get_notes(versions, fromVersion)\n    if notes:\n        to_screen(u'PLEASE NOTE:')\n        for note in notes:\n            to_screen(note)",
        "begin_line": 190,
        "end_line": 195,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.clipfish.ClipfishIE._real_extract#30",
        "src_path": "youtube_dl/extractor/clipfish.py",
        "class_name": "youtube_dl.extractor.clipfish.ClipfishIE",
        "signature": "youtube_dl.extractor.clipfish.ClipfishIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group(1)\n\n        info_url = ('http://www.clipfish.de/devxml/videoinfo/%s?ts=%d' %\n                    (video_id, int(time.time())))\n        doc = self._download_xml(\n            info_url, video_id, note=u'Downloading info page')\n        title = doc.find('title').text\n        video_url = doc.find('filename').text\n        if video_url is None:\n            xml_bytes = xml.etree.ElementTree.tostring(doc)\n            raise ExtractorError('Cannot find video URL in document %r' %\n                                 xml_bytes)\n        thumbnail = doc.find('imageurl').text\n        duration = parse_duration(doc.find('duration').text)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'thumbnail': thumbnail,\n            'duration': duration,\n        }",
        "begin_line": 30,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.exfm.ExfmIE._real_extract#41",
        "src_path": "youtube_dl/extractor/exfm.py",
        "class_name": "youtube_dl.extractor.exfm.ExfmIE",
        "signature": "youtube_dl.extractor.exfm.ExfmIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        song_id = mobj.group('id')\n        info_url = \"http://ex.fm/api/v3/song/%s\" % song_id\n        info = self._download_json(info_url, song_id)['song']\n        song_url = info['url']\n        if re.match(self._SOUNDCLOUD_URL, song_url) is not None:\n            self.to_screen('Soundcloud song detected')\n            return self.url_result(song_url.replace('/stream', ''), 'Soundcloud')\n        return {\n            'id': song_id,\n            'url': song_url,\n            'ext': 'mp3',\n            'title': info['title'],\n            'thumbnail': info['image']['large'],\n            'uploader': info['artist'],\n            'view_count': info['loved_count'],\n        }",
        "begin_line": 41,
        "end_line": 58,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.freesound.FreesoundIE._real_extract#22",
        "src_path": "youtube_dl/extractor/freesound.py",
        "class_name": "youtube_dl.extractor.freesound.FreesoundIE",
        "signature": "youtube_dl.extractor.freesound.FreesoundIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        music_id = mobj.group('id')\n        webpage = self._download_webpage(url, music_id)\n        title = self._html_search_regex(\n            r'<div id=\"single_sample_header\">.*?<a href=\"#\">(.+?)</a>',\n            webpage, 'music title', flags=re.DOTALL)\n        description = self._html_search_regex(\n            r'<div id=\"sound_description\">(.*?)</div>', webpage, 'description',\n            fatal=False, flags=re.DOTALL)\n\n        return {\n            'id': music_id,\n            'title': title,\n            'url': self._og_search_property('audio', webpage, 'music url'),\n            'uploader': self._og_search_property('audio:artist', webpage, 'music uploader'),\n            'description': description,\n        }",
        "begin_line": 22,
        "end_line": 39,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.jpopsukitv.JpopsukiIE._real_extract#32",
        "src_path": "youtube_dl/extractor/jpopsukitv.py",
        "class_name": "youtube_dl.extractor.jpopsukitv.JpopsukiIE",
        "signature": "youtube_dl.extractor.jpopsukitv.JpopsukiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = 'http://www.jpopsuki.tv' + self._html_search_regex(\n            r'<source src=\"(.*?)\" type', webpage, 'video url')\n\n        video_title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n        uploader = self._html_search_regex(\n            r'<li>from: <a href=\"/user/view/user/(.*?)/uid/',\n            webpage, 'video uploader', fatal=False)\n        uploader_id = self._html_search_regex(\n            r'<li>from: <a href=\"/user/view/user/\\S*?/uid/(\\d*)',\n            webpage, 'video uploader_id', fatal=False)\n        upload_date = self._html_search_regex(\n            r'<li>uploaded: (.*?)</li>', webpage, 'video upload_date',\n            fatal=False)\n        if upload_date is not None:\n            upload_date = unified_strdate(upload_date)\n        view_count_str = self._html_search_regex(\n            r'<li>Hits: ([0-9]+?)</li>', webpage, 'video view_count',\n            fatal=False)\n        comment_count_str = self._html_search_regex(\n            r'<h2>([0-9]+?) comments</h2>', webpage, 'video comment_count',\n            fatal=False)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': video_title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'upload_date': upload_date,\n            'view_count': int_or_none(view_count_str),\n            'comment_count': int_or_none(comment_count_str),\n        }",
        "begin_line": 32,
        "end_line": 73,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.toutv.TouTvIE._real_extract#35",
        "src_path": "youtube_dl/extractor/toutv.py",
        "class_name": "youtube_dl.extractor.toutv.TouTvIE",
        "signature": "youtube_dl.extractor.toutv.TouTvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n\n        mediaId = self._search_regex(\n            r'\"idMedia\":\\s*\"([^\"]+)\"', webpage, 'media ID')\n\n        streams_url = 'http://release.theplatform.com/content.select?pid=' + mediaId\n        streams_doc = self._download_xml(\n            streams_url, video_id, note='Downloading stream list')\n\n        video_url = next(n.text\n                         for n in streams_doc.findall('.//choice/url')\n                         if '//ad.doubleclick' not in n.text)\n        if video_url.endswith('/Unavailable.flv'):\n            raise ExtractorError(\n                'Access to this video is blocked from outside of Canada',\n                expected=True)\n\n        duration_str = self._html_search_meta(\n            'video:duration', webpage, 'duration')\n        duration = int(duration_str) if duration_str else None\n        upload_date_str = self._html_search_meta(\n            'video:release_date', webpage, 'upload date')\n        upload_date = unified_strdate(upload_date_str) if upload_date_str else None\n\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n            'url': video_url,\n            'description': self._og_search_description(webpage),\n            'uploader': self._dc_search_uploader(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'age_limit': self._media_rating_search(webpage),\n            'duration': duration,\n            'upload_date': upload_date,\n            'ext': 'mp4',\n        }",
        "begin_line": 35,
        "end_line": 73,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.justintv.JustinTVIE._parse_page#47",
        "src_path": "youtube_dl/extractor/justintv.py",
        "class_name": "youtube_dl.extractor.justintv.JustinTVIE",
        "signature": "youtube_dl.extractor.justintv.JustinTVIE._parse_page(self, url, video_id, counter)",
        "snippet": "    def _parse_page(self, url, video_id, counter):\n        info_json = self._download_webpage(\n            url, video_id,\n            'Downloading video info JSON on page %d' % counter,\n            'Unable to download video info JSON %d' % counter)\n\n        response = json.loads(info_json)\n        if type(response) != list:\n            error_text = response.get('error', 'unknown error')\n            raise ExtractorError('Justin.tv API: %s' % error_text)\n        info = []\n        for clip in response:\n            video_url = clip['video_file_url']\n            if video_url:\n                video_extension = os.path.splitext(video_url)[1][1:]\n                video_date = re.sub('-', '', clip['start_time'][:10])\n                video_uploader_id = clip.get('user_id', clip.get('channel_id'))\n                video_id = clip['id']\n                video_title = clip.get('title', video_id)\n                info.append({\n                    'id': compat_str(video_id),\n                    'url': video_url,\n                    'title': video_title,\n                    'uploader': clip.get('channel_name', video_uploader_id),\n                    'uploader_id': video_uploader_id,\n                    'upload_date': video_date,\n                    'ext': video_extension,\n                })\n        return (len(response), info)",
        "begin_line": 47,
        "end_line": 75,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.justintv.JustinTVIE._real_extract#77",
        "src_path": "youtube_dl/extractor/justintv.py",
        "class_name": "youtube_dl.extractor.justintv.JustinTVIE",
        "signature": "youtube_dl.extractor.justintv.JustinTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        api_base = 'http://api.justin.tv'\n        paged = False\n        if mobj.group('channelid'):\n            paged = True\n            video_id = mobj.group('channelid')\n            api = api_base + '/channel/archives/%s.json' % video_id\n        elif mobj.group('chapterid'):\n            chapter_id = mobj.group('chapterid')\n\n            webpage = self._download_webpage(url, chapter_id)\n            m = re.search(r'PP\\.archive_id = \"([0-9]+)\";', webpage)\n            if not m:\n                raise ExtractorError('Cannot find archive of a chapter')\n            archive_id = m.group(1)\n\n            api = api_base + '/broadcast/by_chapter/%s.xml' % chapter_id\n            doc = self._download_xml(\n                api, chapter_id,\n                note='Downloading chapter information',\n                errnote='Chapter information download failed')\n            for a in doc.findall('.//archive'):\n                if archive_id == a.find('./id').text:\n                    break\n            else:\n                raise ExtractorError('Could not find chapter in chapter information')\n\n            video_url = a.find('./video_file_url').text\n            video_ext = video_url.rpartition('.')[2] or 'flv'\n\n            chapter_api_url = 'https://api.twitch.tv/kraken/videos/c' + chapter_id\n            chapter_info = self._download_json(\n                chapter_api_url, 'c' + chapter_id,\n                note='Downloading chapter metadata',\n                errnote='Download of chapter metadata failed')\n\n            bracket_start = int(doc.find('.//bracket_start').text)\n            bracket_end = int(doc.find('.//bracket_end').text)\n\n            # TODO determine start (and probably fix up file)\n            #  youtube-dl -v http://www.twitch.tv/firmbelief/c/1757457\n            #video_url += '?start=' + TODO:start_timestamp\n            # bracket_start is 13290, but we want 51670615\n            self._downloader.report_warning('Chapter detected, but we can just download the whole file. '\n                                            'Chapter starts at %s and ends at %s' % (formatSeconds(bracket_start), formatSeconds(bracket_end)))\n\n            info = {\n                'id': 'c' + chapter_id,\n                'url': video_url,\n                'ext': video_ext,\n                'title': chapter_info['title'],\n                'thumbnail': chapter_info['preview'],\n                'description': chapter_info['description'],\n                'uploader': chapter_info['channel']['display_name'],\n                'uploader_id': chapter_info['channel']['name'],\n            }\n            return info\n        else:\n            video_id = mobj.group('videoid')\n            api = api_base + '/broadcast/by_archive/%s.json' % video_id\n\n        entries = []\n        offset = 0\n        limit = self._JUSTIN_PAGE_LIMIT\n        for counter in itertools.count(1):\n            page_url = api + ('?offset=%d&limit=%d' % (offset, limit))\n            page_count, page_info = self._parse_page(\n                page_url, video_id, counter)\n            entries.extend(page_info)\n            if not paged or page_count != limit:\n                break\n            offset += limit\n        return {\n            '_type': 'playlist',\n            'id': video_id,\n            'entries': entries,\n        }",
        "begin_line": 77,
        "end_line": 155,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.gameone.GameOneIE._real_extract#40",
        "src_path": "youtube_dl/extractor/gameone.py",
        "class_name": "youtube_dl.extractor.gameone.GameOneIE",
        "signature": "youtube_dl.extractor.gameone.GameOneIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        og_video = self._og_search_video_url(webpage, secure=False)\n        description = self._html_search_meta('description', webpage)\n        age_limit = int(\n            self._search_regex(\n                r'age=(\\d+)',\n                self._html_search_meta(\n                    'age-de-meta-label',\n                    webpage),\n                'age_limit',\n                '0'))\n        mrss_url = self._search_regex(r'mrss=([^&]+)', og_video, 'mrss')\n\n        mrss = self._download_xml(mrss_url, video_id, 'Downloading mrss')\n        title = mrss.find('.//item/title').text\n        thumbnail = mrss.find('.//item/image').get('url')\n        timestamp = parse_iso8601(mrss.find('.//pubDate').text, delimiter=' ')\n        content = mrss.find(xpath_with_ns('.//media:content', NAMESPACE_MAP))\n        content_url = content.get('url')\n\n        content = self._download_xml(\n            content_url,\n            video_id,\n            'Downloading media:content')\n        rendition_items = content.findall('.//rendition')\n        duration = int(rendition_items[0].get('duration'))\n        formats = [\n            {\n                'url': re.sub(r'.*/(r2)', RAW_MP4_URL + r'\\1', r.find('./src').text),\n                'width': int(r.get('width')),\n                'height': int(r.get('height')),\n                'tbr': int(r.get('bitrate')),\n            }\n            for r in rendition_items\n        ]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n            'description': description,\n            'age_limit': age_limit,\n            'timestamp': timestamp,\n        }",
        "begin_line": 40,
        "end_line": 90,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.gameone.GameOnePlaylistIE._real_extract#104",
        "src_path": "youtube_dl/extractor/gameone.py",
        "class_name": "youtube_dl.extractor.gameone.GameOnePlaylistIE",
        "signature": "youtube_dl.extractor.gameone.GameOnePlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        webpage = self._download_webpage('http://www.gameone.de/tv', 'TV')\n        max_id = max(map(int, re.findall(r'<a href=\"/tv/(\\d+)\"', webpage)))\n        entries = [\n            self.url_result('http://www.gameone.de/tv/%d' % video_id, 'GameOne')\n            for video_id in range(max_id, 0, -1)]\n\n        return {\n            '_type': 'playlist',\n            'title': 'GameOne',\n            'entries': entries,\n        }",
        "begin_line": 104,
        "end_line": 115,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.tvplay.TVPlayIE._real_extract#178",
        "src_path": "youtube_dl/extractor/tvplay.py",
        "class_name": "youtube_dl.extractor.tvplay.TVPlayIE",
        "signature": "youtube_dl.extractor.tvplay.TVPlayIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        video = self._download_json(\n            'http://playapi.mtgx.tv/v1/videos/%s' % video_id, video_id, 'Downloading video JSON')\n\n        if video['is_geo_blocked']:\n            raise ExtractorError(\n                'This content is not available in your country due to copyright reasons', expected=True)\n\n        streams = self._download_json(\n            'http://playapi.mtgx.tv/v1/videos/stream/%s' % video_id, video_id, 'Downloading streams JSON')\n\n        quality = qualities(['hls', 'medium', 'high'])\n        formats = []\n        for format_id, video_url in streams['streams'].items():\n            if not video_url or not isinstance(video_url, compat_str):\n                continue\n            fmt = {\n                'format_id': format_id,\n                'preference': quality(format_id),\n            }\n            if video_url.startswith('rtmp'):\n                m = re.search(r'^(?P<url>rtmp://[^/]+/(?P<app>[^/]+))/(?P<playpath>.+)$', video_url)\n                if not m:\n                    continue\n                fmt.update({\n                    'ext': 'flv',\n                    'url': m.group('url'),\n                    'app': m.group('app'),\n                    'play_path': m.group('playpath'),\n                })\n            else:\n                fmt.update({\n                    'url': video_url,\n                })\n            formats.append(fmt)\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video['title'],\n            'description': video['description'],\n            'duration': video['duration'],\n            'timestamp': parse_iso8601(video['created_at']),\n            'view_count': video['views']['total'],\n            'age_limit': video.get('age_limit', 0),\n            'formats': formats,\n        }",
        "begin_line": 178,
        "end_line": 228,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0013986013986013986,
            "pseudo_dstar_susp": 0.0010482180293501049,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0010482180293501049,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.teachingchannel.TeachingChannelIE._real_extract#26",
        "src_path": "youtube_dl/extractor/teachingchannel.py",
        "class_name": "youtube_dl.extractor.teachingchannel.TeachingChannelIE",
        "signature": "youtube_dl.extractor.teachingchannel.TeachingChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        title = mobj.group('title')\n        webpage = self._download_webpage(url, title)\n        ooyala_code = self._search_regex(\n            r'data-embed-code=\\'(.+?)\\'', webpage, 'ooyala code')\n\n        return OoyalaIE._build_url_result(ooyala_code)",
        "begin_line": 26,
        "end_line": 33,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.drtuber.DrTuberIE._real_extract#28",
        "src_path": "youtube_dl/extractor/drtuber.py",
        "class_name": "youtube_dl.extractor.drtuber.DrTuberIE",
        "signature": "youtube_dl.extractor.drtuber.DrTuberIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        video_url = self._html_search_regex(\n            r'<source src=\"([^\"]+)\"', webpage, 'video URL')\n\n        title = self._html_search_regex(\n            r'<title>([^<]+)\\s*-\\s*Free', webpage, 'title')\n\n        thumbnail = self._html_search_regex(\n            r'poster=\"([^\"]+)\"',\n            webpage, 'thumbnail', fatal=False)\n\n        like_count = str_to_int(self._html_search_regex(\n            r'<span id=\"rate_likes\">\\s*<img[^>]+>\\s*<span>([\\d,\\.]+)</span>',\n            webpage, 'like count', fatal=False))\n        dislike_count = str_to_int(self._html_search_regex(\n            r'<span id=\"rate_dislikes\">\\s*<img[^>]+>\\s*<span>([\\d,\\.]+)</span>',\n            webpage, 'like count', fatal=False))\n        comment_count = str_to_int(self._html_search_regex(\n            r'<span class=\"comments_count\">([\\d,\\.]+)</span>',\n            webpage, 'comment count', fatal=False))\n\n        cats_str = self._html_search_regex(\n            r'<meta name=\"keywords\" content=\"([^\"]+)\"', webpage, 'categories', fatal=False)\n        categories = None if cats_str is None else cats_str.split(' ')\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'url': video_url,\n            'title': title,\n            'thumbnail': thumbnail,\n            'like_count': like_count,\n            'dislike_count': dislike_count,\n            'comment_count': comment_count,\n            'categories': categories,\n            'age_limit': self._rta_search(webpage),\n        }",
        "begin_line": 28,
        "end_line": 70,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.comedycentral.ComedyCentralShowsIE._real_extract#120",
        "src_path": "youtube_dl/extractor/comedycentral.py",
        "class_name": "youtube_dl.extractor.comedycentral.ComedyCentralShowsIE",
        "signature": "youtube_dl.extractor.comedycentral.ComedyCentralShowsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url, re.VERBOSE)\n        if mobj is None:\n            raise ExtractorError('Invalid URL: %s' % url)\n\n        if mobj.group('shortname'):\n            if mobj.group('shortname') in ('tds', 'thedailyshow'):\n                url = 'http://thedailyshow.cc.com/full-episodes/'\n            else:\n                url = 'http://thecolbertreport.cc.com/full-episodes/'\n            mobj = re.match(self._VALID_URL, url, re.VERBOSE)\n            assert mobj is not None\n\n        if mobj.group('clip'):\n            if mobj.group('videotitle'):\n                epTitle = mobj.group('videotitle')\n            elif mobj.group('showname') == 'thedailyshow':\n                epTitle = mobj.group('tdstitle')\n            else:\n                epTitle = mobj.group('cntitle')\n            dlNewest = False\n        elif mobj.group('interview'):\n            epTitle = mobj.group('interview_title')\n            dlNewest = False\n        else:\n            dlNewest = not mobj.group('episode')\n            if dlNewest:\n                epTitle = mobj.group('showname')\n            else:\n                epTitle = mobj.group('episode')\n        show_name = mobj.group('showname')\n\n        webpage, htmlHandle = self._download_webpage_handle(url, epTitle)\n        if dlNewest:\n            url = htmlHandle.geturl()\n            mobj = re.match(self._VALID_URL, url, re.VERBOSE)\n            if mobj is None:\n                raise ExtractorError('Invalid redirected URL: ' + url)\n            if mobj.group('episode') == '':\n                raise ExtractorError('Redirected URL is still not specific: ' + url)\n            epTitle = (mobj.group('episode') or mobj.group('videotitle')).rpartition('/')[-1]\n\n        mMovieParams = re.findall('(?:<param name=\"movie\" value=\"|var url = \")(http://media.mtvnservices.com/([^\"]*(?:episode|video).*?:.*?))\"', webpage)\n        if len(mMovieParams) == 0:\n            # The Colbert Report embeds the information in a without\n            # a URL prefix; so extract the alternate reference\n            # and then add the URL prefix manually.\n\n            altMovieParams = re.findall('data-mgid=\"([^\"]*(?:episode|video|playlist).*?:.*?)\"', webpage)\n            if len(altMovieParams) == 0:\n                raise ExtractorError('unable to find Flash URL in webpage ' + url)\n            else:\n                mMovieParams = [(\"http://media.mtvnservices.com/\" + altMovieParams[0], altMovieParams[0])]\n\n        uri = mMovieParams[0][1]\n        # Correct cc.com in uri\n        uri = re.sub(r'(episode:[^.]+)(\\.cc)?\\.com', r'\\1.cc.com', uri)\n\n        index_url = 'http://%s.cc.com/feeds/mrss?%s' % (show_name, compat_urllib_parse.urlencode({'uri': uri}))\n        idoc = self._download_xml(\n            index_url, epTitle,\n            'Downloading show index', 'Unable to download episode index')\n\n        title = idoc.find('./channel/title').text\n        description = idoc.find('./channel/description').text\n\n        entries = []\n        item_els = idoc.findall('.//item')\n        for part_num, itemEl in enumerate(item_els):\n            upload_date = unified_strdate(itemEl.findall('./pubDate')[0].text)\n            thumbnail = itemEl.find('.//{http://search.yahoo.com/mrss/}thumbnail').attrib.get('url')\n\n            content = itemEl.find('.//{http://search.yahoo.com/mrss/}content')\n            duration = float_or_none(content.attrib.get('duration'))\n            mediagen_url = content.attrib['url']\n            guid = itemEl.find('./guid').text.rpartition(':')[-1]\n\n            cdoc = self._download_xml(\n                mediagen_url, epTitle,\n                'Downloading configuration for segment %d / %d' % (part_num + 1, len(item_els)))\n\n            turls = []\n            for rendition in cdoc.findall('.//rendition'):\n                finfo = (rendition.attrib['bitrate'], rendition.findall('./src')[0].text)\n                turls.append(finfo)\n\n            formats = []\n            for format, rtmp_video_url in turls:\n                w, h = self._video_dimensions.get(format, (None, None))\n                formats.append({\n                    'format_id': 'vhttp-%s' % format,\n                    'url': self._transform_rtmp_url(rtmp_video_url),\n                    'ext': self._video_extensions.get(format, 'mp4'),\n                    'height': h,\n                    'width': w,\n\n                    'format_note': 'HTTP 400 at the moment (patches welcome!)',\n                    'preference': -100,\n                })\n                formats.append({\n                    'format_id': 'rtmp-%s' % format,\n                    'url': rtmp_video_url.replace('viacomccstrm', 'viacommtvstrm'),\n                    'ext': self._video_extensions.get(format, 'mp4'),\n                    'height': h,\n                    'width': w,\n                })\n                self._sort_formats(formats)\n\n            virtual_id = show_name + ' ' + epTitle + ' part ' + compat_str(part_num + 1)\n            entries.append({\n                'id': guid,\n                'title': virtual_id,\n                'formats': formats,\n                'uploader': show_name,\n                'upload_date': upload_date,\n                'duration': duration,\n                'thumbnail': thumbnail,\n                'description': description,\n            })\n\n        return {\n            '_type': 'playlist',\n            'entries': entries,\n            'title': show_name + ' ' + title,\n            'description': description,\n        }",
        "begin_line": 120,
        "end_line": 245,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.traileraddict.TrailerAddictIE._real_extract#22",
        "src_path": "youtube_dl/extractor/traileraddict.py",
        "class_name": "youtube_dl.extractor.traileraddict.TrailerAddictIE",
        "signature": "youtube_dl.extractor.traileraddict.TrailerAddictIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        name = mobj.group('movie') + '/' + mobj.group('trailer_name')\n        webpage = self._download_webpage(url, name)\n\n        title = self._search_regex(r'<title>(.+?)</title>',\n                webpage, 'video title').replace(' - Trailer Addict','')\n        view_count_str = self._search_regex(\n            r'<span class=\"views_n\">([0-9,.]+)</span>',\n            webpage, 'view count', fatal=False)\n        view_count = (\n            None if view_count_str is None\n            else int(view_count_str.replace(',', '')))\n        video_id = self._search_regex(\n            r'<param\\s+name=\"movie\"\\s+value=\"/emb/([0-9]+)\"\\s*/>',\n            webpage, 'video id')\n\n        # Presence of (no)watchplus function indicates HD quality is available\n        if re.search(r'function (no)?watchplus()', webpage):\n            fvar = \"fvarhd\"\n        else:\n            fvar = \"fvar\"\n\n        info_url = \"http://www.traileraddict.com/%s.php?tid=%s\" % (fvar, str(video_id))\n        info_webpage = self._download_webpage(info_url, video_id , \"Downloading the info webpage\")\n\n        final_url = self._search_regex(r'&fileurl=(.+)',\n                info_webpage, 'Download url').replace('%3F','?')\n        thumbnail_url = self._search_regex(r'&image=(.+?)&',\n                info_webpage, 'thumbnail url')\n\n        description = self._html_search_regex(\n            r'(?s)<div class=\"synopsis\">.*?<div class=\"movie_label_info\"[^>]*>(.*?)</div>',\n            webpage, 'description', fatal=False)\n\n        return {\n            'id': video_id,\n            'url': final_url,\n            'title': title,\n            'thumbnail': thumbnail_url,\n            'description': description,\n            'view_count': view_count,\n        }",
        "begin_line": 22,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.downloader.rtmp.RtmpFD.real_download#19",
        "src_path": "youtube_dl/downloader/rtmp.py",
        "class_name": "youtube_dl.downloader.rtmp.RtmpFD",
        "signature": "youtube_dl.downloader.rtmp.RtmpFD.real_download(self, filename, info_dict)",
        "snippet": "    def real_download(self, filename, info_dict):\n        def run_rtmpdump(args):\n            start = time.time()\n            resume_percent = None\n            resume_downloaded_data_len = None\n            proc = subprocess.Popen(args, stderr=subprocess.PIPE)\n            cursor_in_new_line = True\n            proc_stderr_closed = False\n            while not proc_stderr_closed:\n                # read line from stderr\n                line = ''\n                while True:\n                    char = proc.stderr.read(1)\n                    if not char:\n                        proc_stderr_closed = True\n                        break\n                    if char in [b'\\r', b'\\n']:\n                        break\n                    line += char.decode('ascii', 'replace')\n                if not line:\n                    # proc_stderr_closed is True\n                    continue\n                mobj = re.search(r'([0-9]+\\.[0-9]{3}) kB / [0-9]+\\.[0-9]{2} sec \\(([0-9]{1,2}\\.[0-9])%\\)', line)\n                if mobj:\n                    downloaded_data_len = int(float(mobj.group(1))*1024)\n                    percent = float(mobj.group(2))\n                    if not resume_percent:\n                        resume_percent = percent\n                        resume_downloaded_data_len = downloaded_data_len\n                    eta = self.calc_eta(start, time.time(), 100-resume_percent, percent-resume_percent)\n                    speed = self.calc_speed(start, time.time(), downloaded_data_len-resume_downloaded_data_len)\n                    data_len = None\n                    if percent > 0:\n                        data_len = int(downloaded_data_len * 100 / percent)\n                    data_len_str = '~' + format_bytes(data_len)\n                    self.report_progress(percent, data_len_str, speed, eta)\n                    cursor_in_new_line = False\n                    self._hook_progress({\n                        'downloaded_bytes': downloaded_data_len,\n                        'total_bytes': data_len,\n                        'tmpfilename': tmpfilename,\n                        'filename': filename,\n                        'status': 'downloading',\n                        'eta': eta,\n                        'speed': speed,\n                    })\n                else:\n                    # no percent for live streams\n                    mobj = re.search(r'([0-9]+\\.[0-9]{3}) kB / [0-9]+\\.[0-9]{2} sec', line)\n                    if mobj:\n                        downloaded_data_len = int(float(mobj.group(1))*1024)\n                        time_now = time.time()\n                        speed = self.calc_speed(start, time_now, downloaded_data_len)\n                        self.report_progress_live_stream(downloaded_data_len, speed, time_now - start)\n                        cursor_in_new_line = False\n                        self._hook_progress({\n                            'downloaded_bytes': downloaded_data_len,\n                            'tmpfilename': tmpfilename,\n                            'filename': filename,\n                            'status': 'downloading',\n                            'speed': speed,\n                        })\n                    elif self.params.get('verbose', False):\n                        if not cursor_in_new_line:\n                            self.to_screen('')\n                        cursor_in_new_line = True\n                        self.to_screen('[rtmpdump] '+line)\n            proc.wait()\n            if not cursor_in_new_line:\n                self.to_screen('')\n            return proc.returncode\n\n        url = info_dict['url']\n        player_url = info_dict.get('player_url', None)\n        page_url = info_dict.get('page_url', None)\n        app = info_dict.get('app', None)\n        play_path = info_dict.get('play_path', None)\n        tc_url = info_dict.get('tc_url', None)\n        flash_version = info_dict.get('flash_version', None)\n        live = info_dict.get('rtmp_live', False)\n        conn = info_dict.get('rtmp_conn', None)\n        protocol = info_dict.get('rtmp_protocol', None)\n\n        self.report_destination(filename)\n        tmpfilename = self.temp_name(filename)\n        test = self.params.get('test', False)\n\n        # Check for rtmpdump first\n        if not check_executable('rtmpdump', ['-h']):\n            self.report_error('RTMP download detected but \"rtmpdump\" could not be run. Please install it.')\n            return False\n\n        # Download using rtmpdump. rtmpdump returns exit code 2 when\n        # the connection was interrumpted and resuming appears to be\n        # possible. This is part of rtmpdump's normal usage, AFAIK.\n        basic_args = ['rtmpdump', '--verbose', '-r', url, '-o', tmpfilename]\n        if player_url is not None:\n            basic_args += ['--swfVfy', player_url]\n        if page_url is not None:\n            basic_args += ['--pageUrl', page_url]\n        if app is not None:\n            basic_args += ['--app', app]\n        if play_path is not None:\n            basic_args += ['--playpath', play_path]\n        if tc_url is not None:\n            basic_args += ['--tcUrl', url]\n        if test:\n            basic_args += ['--stop', '1']\n        if flash_version is not None:\n            basic_args += ['--flashVer', flash_version]\n        if live:\n            basic_args += ['--live']\n        if isinstance(conn, list):\n            for entry in conn:\n                basic_args += ['--conn', entry]\n        elif isinstance(conn, compat_str):\n            basic_args += ['--conn', conn]\n        if protocol is not None:\n            basic_args += ['--protocol', protocol]\n        args = basic_args + [[], ['--resume', '--skip', '1']][not live and self.params.get('continuedl', False)]\n\n        if sys.platform == 'win32' and sys.version_info < (3, 0):\n            # Windows subprocess module does not actually support Unicode\n            # on Python 2.x\n            # See http://stackoverflow.com/a/9951851/35070\n            subprocess_encoding = sys.getfilesystemencoding()\n            args = [a.encode(subprocess_encoding, 'ignore') for a in args]\n        else:\n            subprocess_encoding = None\n\n        if self.params.get('verbose', False):\n            if subprocess_encoding:\n                str_args = [\n                    a.decode(subprocess_encoding) if isinstance(a, bytes) else a\n                    for a in args]\n            else:\n                str_args = args\n            try:\n                import pipes\n                shell_quote = lambda args: ' '.join(map(pipes.quote, str_args))\n            except ImportError:\n                shell_quote = repr\n            self.to_screen('[debug] rtmpdump command line: ' + shell_quote(str_args))\n\n        RD_SUCCESS = 0\n        RD_FAILED = 1\n        RD_INCOMPLETE = 2\n        RD_NO_CONNECT = 3\n\n        retval = run_rtmpdump(args)\n\n        if retval == RD_NO_CONNECT:\n            self.report_error('[rtmpdump] Could not connect to RTMP server.')\n            return False\n\n        while (retval == RD_INCOMPLETE or retval == RD_FAILED) and not test and not live:\n            prevsize = os.path.getsize(encodeFilename(tmpfilename))\n            self.to_screen('[rtmpdump] %s bytes' % prevsize)\n            time.sleep(5.0) # This seems to be needed\n            retval = run_rtmpdump(basic_args + ['-e'] + [[], ['-k', '1']][retval == RD_FAILED])\n            cursize = os.path.getsize(encodeFilename(tmpfilename))\n            if prevsize == cursize and retval == RD_FAILED:\n                break\n             # Some rtmp streams seem abort after ~ 99.8%. Don't complain for those\n            if prevsize == cursize and retval == RD_INCOMPLETE and cursize > 1024:\n                self.to_screen('[rtmpdump] Could not download the whole video. This can happen for some advertisements.')\n                retval = RD_SUCCESS\n                break\n        if retval == RD_SUCCESS or (test and retval == RD_INCOMPLETE):\n            fsize = os.path.getsize(encodeFilename(tmpfilename))\n            self.to_screen('[rtmpdump] %s bytes' % fsize)\n            self.try_rename(tmpfilename, filename)\n            self._hook_progress({\n                'downloaded_bytes': fsize,\n                'total_bytes': fsize,\n                'filename': filename,\n                'status': 'finished',\n            })\n            return True\n        else:\n            self.to_stderr('\\n')\n            self.report_error('rtmpdump exited with code %d' % retval)\n            return False",
        "begin_line": 19,
        "end_line": 201,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.archiveorg.ArchiveOrgIE._real_extract#28",
        "src_path": "youtube_dl/extractor/archiveorg.py",
        "class_name": "youtube_dl.extractor.archiveorg.ArchiveOrgIE",
        "signature": "youtube_dl.extractor.archiveorg.ArchiveOrgIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        json_url = url + ('?' if '?' in url else '&') + 'output=json'\n        json_data = self._download_webpage(json_url, video_id)\n        data = json.loads(json_data)\n\n        title = data['metadata']['title'][0]\n        description = data['metadata']['description'][0]\n        uploader = data['metadata']['creator'][0]\n        upload_date = unified_strdate(data['metadata']['date'][0])\n\n        formats = [\n            {\n                'format': fdata['format'],\n                'url': 'http://' + data['server'] + data['dir'] + fn,\n                'file_size': int(fdata['size']),\n            }\n            for fn, fdata in data['files'].items()\n            if 'Video' in fdata['format']]\n\n        self._sort_formats(formats)\n\n        return {\n            '_type': 'video',\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'description': description,\n            'uploader': uploader,\n            'upload_date': upload_date,\n            'thumbnail': data.get('misc', {}).get('image'),\n        }",
        "begin_line": 28,
        "end_line": 61,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.metacafe.MetacafeIE.report_disclaimer#104",
        "src_path": "youtube_dl/extractor/metacafe.py",
        "class_name": "youtube_dl.extractor.metacafe.MetacafeIE",
        "signature": "youtube_dl.extractor.metacafe.MetacafeIE.report_disclaimer(self)",
        "snippet": "    def report_disclaimer(self):\n        self.to_screen('Retrieving disclaimer')",
        "begin_line": 104,
        "end_line": 105,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009541984732824427,
            "pseudo_dstar_susp": 0.000757002271006813,
            "pseudo_tarantula_susp": 0.00030102347983142685,
            "pseudo_op2_susp": 0.000757002271006813,
            "pseudo_barinel_susp": 0.00030102347983142685
        }
    },
    {
        "name": "youtube_dl.extractor.metacafe.MetacafeIE._real_initialize#107",
        "src_path": "youtube_dl/extractor/metacafe.py",
        "class_name": "youtube_dl.extractor.metacafe.MetacafeIE",
        "signature": "youtube_dl.extractor.metacafe.MetacafeIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        # Retrieve disclaimer\n        self.report_disclaimer()\n        self._download_webpage(self._DISCLAIMER, None, False, 'Unable to retrieve disclaimer')\n\n        # Confirm age\n        disclaimer_form = {\n            'filters': '0',\n            'submit': \"Continue - I'm over 18\",\n        }\n        request = compat_urllib_request.Request(self._FILTER_POST, compat_urllib_parse.urlencode(disclaimer_form))\n        request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        self.report_age_confirmation()\n        self._download_webpage(request, None, False, 'Unable to confirm age')",
        "begin_line": 107,
        "end_line": 120,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009541984732824427,
            "pseudo_dstar_susp": 0.000757002271006813,
            "pseudo_tarantula_susp": 0.00030102347983142685,
            "pseudo_op2_susp": 0.000757002271006813,
            "pseudo_barinel_susp": 0.00030102347983142685
        }
    },
    {
        "name": "youtube_dl.extractor.metacafe.MetacafeIE._real_extract#122",
        "src_path": "youtube_dl/extractor/metacafe.py",
        "class_name": "youtube_dl.extractor.metacafe.MetacafeIE",
        "signature": "youtube_dl.extractor.metacafe.MetacafeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        # Extract id and simplified title from URL\n        mobj = re.match(self._VALID_URL, url)\n        if mobj is None:\n            raise ExtractorError('Invalid URL: %s' % url)\n\n        video_id = mobj.group(1)\n\n        # the video may come from an external site\n        m_external = re.match('^(\\w{2})-(.*)$', video_id)\n        if m_external is not None:\n            prefix, ext_id = m_external.groups()\n            # Check if video comes from YouTube\n            if prefix == 'yt':\n                return self.url_result('http://www.youtube.com/watch?v=%s' % ext_id, 'Youtube')\n            # CBS videos use theplatform.com\n            if prefix == 'cb':\n                return self.url_result('theplatform:%s' % ext_id, 'ThePlatform')\n\n        # Retrieve video webpage to extract further information\n        req = compat_urllib_request.Request('http://www.metacafe.com/watch/%s/' % video_id)\n\n        # AnyClip videos require the flashversion cookie so that we get the link\n        # to the mp4 file\n        mobj_an = re.match(r'^an-(.*?)$', video_id)\n        if mobj_an:\n            req.headers['Cookie'] = 'flashVersion=0;'\n        webpage = self._download_webpage(req, video_id)\n\n        # Extract URL, uploader and title from webpage\n        self.report_extraction(video_id)\n        video_url = None\n        mobj = re.search(r'(?m)&mediaURL=([^&]+)', webpage)\n        if mobj is not None:\n            mediaURL = compat_urllib_parse.unquote(mobj.group(1))\n            video_ext = mediaURL[-3:]\n\n            # Extract gdaKey if available\n            mobj = re.search(r'(?m)&gdaKey=(.*?)&', webpage)\n            if mobj is None:\n                video_url = mediaURL\n            else:\n                gdaKey = mobj.group(1)\n                video_url = '%s?__gda__=%s' % (mediaURL, gdaKey)\n        if video_url is None:\n            mobj = re.search(r'<video src=\"([^\"]+)\"', webpage)\n            if mobj:\n                video_url = mobj.group(1)\n                video_ext = 'mp4'\n        if video_url is None:\n            flashvars = self._search_regex(\n                r' name=\"flashvars\" value=\"(.*?)\"', webpage, 'flashvars',\n                default=None)\n            if flashvars:\n                vardict = compat_parse_qs(flashvars)\n                if 'mediaData' not in vardict:\n                    raise ExtractorError('Unable to extract media URL')\n                mobj = re.search(\n                    r'\"mediaURL\":\"(?P<mediaURL>http.*?)\",(.*?)\"key\":\"(?P<key>.*?)\"', vardict['mediaData'][0])\n                if mobj is None:\n                    raise ExtractorError('Unable to extract media URL')\n                mediaURL = mobj.group('mediaURL').replace('\\\\/', '/')\n                video_url = '%s?__gda__=%s' % (mediaURL, mobj.group('key'))\n                video_ext = determine_ext(video_url)\n        if video_url is None:\n            player_url = self._search_regex(\n                r\"swfobject\\.embedSWF\\('([^']+)'\",\n                webpage, 'config URL', default=None)\n            if player_url:\n                config_url = self._search_regex(\n                    r'config=(.+)$', player_url, 'config URL')\n                config_doc = self._download_xml(\n                    config_url, video_id,\n                    note='Downloading video config')\n                smil_url = config_doc.find('.//properties').attrib['smil_file']\n                smil_doc = self._download_xml(\n                    smil_url, video_id,\n                    note='Downloading SMIL document')\n                base_url = smil_doc.find('./head/meta').attrib['base']\n                video_url = []\n                for vn in smil_doc.findall('.//video'):\n                    br = int(vn.attrib['system-bitrate'])\n                    play_path = vn.attrib['src']\n                    video_url.append({\n                        'format_id': 'smil-%d' % br,\n                        'url': base_url,\n                        'play_path': play_path,\n                        'page_url': url,\n                        'player_url': player_url,\n                        'ext': play_path.partition(':')[0],\n                    })\n\n        if video_url is None:\n            raise ExtractorError('Unsupported video type')\n\n        video_title = self._html_search_regex(\n            r'(?im)<title>(.*) - Video</title>', webpage, 'title')\n        description = self._og_search_description(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n        video_uploader = self._html_search_regex(\n                r'submitter=(.*?);|googletag\\.pubads\\(\\)\\.setTargeting\\(\"(?:channel|submiter)\",\"([^\"]+)\"\\);',\n                webpage, 'uploader nickname', fatal=False)\n        duration = int_or_none(\n            self._html_search_meta('video:duration', webpage))\n\n        age_limit = (\n            18\n            if re.search(r'\"contentRating\":\"restricted\"', webpage)\n            else 0)\n\n        if isinstance(video_url, list):\n            formats = video_url\n        else:\n            formats = [{\n                'url': video_url,\n                'ext': video_ext,\n            }]\n\n        self._sort_formats(formats)\n        return {\n            'id': video_id,\n            'description': description,\n            'uploader': video_uploader,\n            'title': video_title,\n            'thumbnail': thumbnail,\n            'age_limit': age_limit,\n            'formats': formats,\n            'duration': duration,\n        }",
        "begin_line": 122,
        "end_line": 250,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009541984732824427,
            "pseudo_dstar_susp": 0.000757002271006813,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.000757002271006813,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.gorillavid.GorillaVidIE._real_extract#51",
        "src_path": "youtube_dl/extractor/gorillavid.py",
        "class_name": "youtube_dl.extractor.gorillavid.GorillaVidIE",
        "signature": "youtube_dl.extractor.gorillavid.GorillaVidIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage('http://%s/%s' % (mobj.group('host'), video_id), video_id)\n\n        fields = dict(re.findall(r'''(?x)<input\\s+\n            type=\"hidden\"\\s+\n            name=\"([^\"]+)\"\\s+\n            (?:id=\"[^\"]+\"\\s+)?\n            value=\"([^\"]*)\"\n            ''', webpage))\n        \n        if fields['op'] == 'download1':\n            post = compat_urllib_parse.urlencode(fields)\n\n            req = compat_urllib_request.Request(url, post)\n            req.add_header('Content-type', 'application/x-www-form-urlencoded')\n\n            webpage = self._download_webpage(req, video_id, 'Downloading video page')\n\n        title = self._search_regex(r'style=\"z-index: [0-9]+;\">([0-9a-zA-Z ]+)(?:-.+)?</span>', webpage, 'title')\n        thumbnail = self._search_regex(r'image:\\'(http[^\\']+)\\',', webpage, 'thumbnail')\n        url = self._search_regex(r'file: \\'(http[^\\']+)\\',', webpage, 'file url')\n\n        formats = [{\n            'format_id': 'sd',\n            'url': url,\n            'ext': determine_ext(url),\n            'quality': 1,\n        }]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 51,
        "end_line": 88,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.discovery.DiscoveryIE._real_extract#26",
        "src_path": "youtube_dl/extractor/discovery.py",
        "class_name": "youtube_dl.extractor.discovery.DiscoveryIE",
        "signature": "youtube_dl.extractor.discovery.DiscoveryIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n\n        video_list_json = self._search_regex(r'var videoListJSON = ({.*?});',\n            webpage, 'video list', flags=re.DOTALL)\n        video_list = json.loads(video_list_json)\n        info = video_list['clips'][0]\n        formats = []\n        for f in info['mp4']:\n            formats.append(\n                {'url': f['src'], 'ext': 'mp4', 'tbr': int(f['bitrate'][:-1])})\n\n        return {\n            'id': info['contentId'],\n            'title': video_list['name'],\n            'formats': formats,\n            'description': info['videoCaption'],\n            'thumbnail': info.get('videoStillURL') or info.get('thumbnailURL'),\n            'duration': info['duration'],\n        }",
        "begin_line": 26,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoBaseInfoExtractor._login#29",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoBaseInfoExtractor",
        "signature": "youtube_dl.extractor.vimeo.VimeoBaseInfoExtractor._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            if self._LOGIN_REQUIRED:\n                raise ExtractorError('No login info available, needed for using %s.' % self.IE_NAME, expected=True)\n            return\n        self.report_login()\n        login_url = 'https://vimeo.com/log_in'\n        webpage = self._download_webpage(login_url, None, False)\n        token = self._search_regex(r'xsrft: \\'(.*?)\\'', webpage, 'login token')\n        data = urlencode_postdata({\n            'email': username,\n            'password': password,\n            'action': 'login',\n            'service': 'vimeo',\n            'token': token,\n        })\n        login_request = compat_urllib_request.Request(login_url, data)\n        login_request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        login_request.add_header('Cookie', 'xsrft=%s' % token)\n        self._download_webpage(login_request, None, False, 'Wrong login info')",
        "begin_line": 29,
        "end_line": 49,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0021231422505307855,
            "pseudo_dstar_susp": 0.0017889087656529517,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0017889087656529517,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoIE._verify_video_password#157",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoIE._verify_video_password(self, url, video_id, webpage)",
        "snippet": "    def _verify_video_password(self, url, video_id, webpage):\n        password = self._downloader.params.get('videopassword', None)\n        if password is None:\n            raise ExtractorError('This video is protected by a password, use the --video-password option')\n        token = self._search_regex(r'xsrft: \\'(.*?)\\'', webpage, 'login token')\n        data = compat_urllib_parse.urlencode({\n            'password': password,\n            'token': token,\n        })\n        # I didn't manage to use the password with https\n        if url.startswith('https'):\n            pass_url = url.replace('https', 'http')\n        else:\n            pass_url = url\n        password_request = compat_urllib_request.Request(pass_url + '/password', data)\n        password_request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        password_request.add_header('Cookie', 'xsrft=%s' % token)\n        self._download_webpage(password_request, video_id,\n                               'Verifying the password',\n                               'Wrong password')",
        "begin_line": 157,
        "end_line": 176,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoIE._verify_player_video_password#178",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoIE._verify_player_video_password(self, url, video_id)",
        "snippet": "    def _verify_player_video_password(self, url, video_id):\n        password = self._downloader.params.get('videopassword', None)\n        if password is None:\n            raise ExtractorError('This video is protected by a password, use the --video-password option')\n        data = compat_urllib_parse.urlencode({'password': password})\n        pass_url = url + '/check-password'\n        password_request = compat_urllib_request.Request(pass_url, data)\n        password_request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        return self._download_json(\n            password_request, video_id,\n            'Verifying the password',\n            'Wrong password')",
        "begin_line": 178,
        "end_line": 189,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoIE._real_initialize#191",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 191,
        "end_line": 192,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0021231422505307855,
            "pseudo_dstar_susp": 0.0017889087656529517,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0017889087656529517,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoIE._real_extract#194",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url, data = unsmuggle_url(url)\n        headers = std_headers\n        if data is not None:\n            headers = headers.copy()\n            headers.update(data)\n        if 'Referer' not in headers:\n            headers['Referer'] = url\n\n        # Extract ID from URL\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        if mobj.group('pro') or mobj.group('player'):\n            url = 'http://player.vimeo.com/video/' + video_id\n\n        # Retrieve video webpage to extract further information\n        request = compat_urllib_request.Request(url, None, headers)\n        try:\n            webpage = self._download_webpage(request, video_id)\n        except ExtractorError as ee:\n            if isinstance(ee.cause, compat_HTTPError) and ee.cause.code == 403:\n                errmsg = ee.cause.read()\n                if b'Because of its privacy settings, this video cannot be played here' in errmsg:\n                    raise ExtractorError(\n                        'Cannot download embed-only video without embedding '\n                        'URL. Please call youtube-dl with the URL of the page '\n                        'that embeds this video.',\n                        expected=True)\n            raise\n\n        # Now we begin extracting as much information as we can from what we\n        # retrieved. First we extract the information common to all extractors,\n        # and latter we extract those that are Vimeo specific.\n        self.report_extraction(video_id)\n\n        # Extract the config JSON\n        try:\n            try:\n                config_url = self._html_search_regex(\n                    r' data-config-url=\"(.+?)\"', webpage, 'config URL')\n                config_json = self._download_webpage(config_url, video_id)\n                config = json.loads(config_json)\n            except RegexNotFoundError:\n                # For pro videos or player.vimeo.com urls\n                # We try to find out to which variable is assigned the config dic\n                m_variable_name = re.search('(\\w)\\.video\\.id', webpage)\n                if m_variable_name is not None:\n                    config_re = r'%s=({.+?});' % re.escape(m_variable_name.group(1))\n                else:\n                    config_re = [r' = {config:({.+?}),assets:', r'(?:[abc])=({.+?});']\n                config = self._search_regex(config_re, webpage, 'info section',\n                    flags=re.DOTALL)\n                config = json.loads(config)\n        except Exception as e:\n            if re.search('The creator of this video has not given you permission to embed it on this domain.', webpage):\n                raise ExtractorError('The author has restricted the access to this video, try with the \"--referer\" option')\n\n            if re.search('<form[^>]+?id=\"pw_form\"', webpage) is not None:\n                self._verify_video_password(url, video_id, webpage)\n                return self._real_extract(url)\n            else:\n                raise ExtractorError('Unable to extract info section',\n                                     cause=e)\n        else:\n            if config.get('view') == 4:\n                config = self._verify_player_video_password(url, video_id)\n\n        # Extract title\n        video_title = config[\"video\"][\"title\"]\n\n        # Extract uploader and uploader_id\n        video_uploader = config[\"video\"][\"owner\"][\"name\"]\n        video_uploader_id = config[\"video\"][\"owner\"][\"url\"].split('/')[-1] if config[\"video\"][\"owner\"][\"url\"] else None\n\n        # Extract video thumbnail\n        video_thumbnail = config[\"video\"].get(\"thumbnail\")\n        if video_thumbnail is None:\n            video_thumbs = config[\"video\"].get(\"thumbs\")\n            if video_thumbs and isinstance(video_thumbs, dict):\n                _, video_thumbnail = sorted((int(width if width.isdigit() else 0), t_url) for (width, t_url) in video_thumbs.items())[-1]\n\n        # Extract video description\n        video_description = None\n        try:\n            video_description = get_element_by_attribute(\"class\", \"description_wrapper\", webpage)\n            if video_description:\n                video_description = clean_html(video_description)\n        except AssertionError as err:\n            # On some pages like (http://player.vimeo.com/video/54469442) the\n            # html tags are not closed, python 2.6 cannot handle it\n            if err.args[0] == 'we should not get here!':\n                pass\n            else:\n                raise\n\n        # Extract video duration\n        video_duration = int_or_none(config[\"video\"].get(\"duration\"))\n\n        # Extract upload date\n        video_upload_date = None\n        mobj = re.search(r'<meta itemprop=\"dateCreated\" content=\"(\\d{4})-(\\d{2})-(\\d{2})T', webpage)\n        if mobj is not None:\n            video_upload_date = mobj.group(1) + mobj.group(2) + mobj.group(3)\n\n        try:\n            view_count = int(self._search_regex(r'UserPlays:(\\d+)', webpage, 'view count'))\n            like_count = int(self._search_regex(r'UserLikes:(\\d+)', webpage, 'like count'))\n            comment_count = int(self._search_regex(r'UserComments:(\\d+)', webpage, 'comment count'))\n        except RegexNotFoundError:\n            # This info is only available in vimeo.com/{id} urls\n            view_count = None\n            like_count = None\n            comment_count = None\n\n        # Vimeo specific: extract request signature and timestamp\n        sig = config['request']['signature']\n        timestamp = config['request']['timestamp']\n\n        # Vimeo specific: extract video codec and quality information\n        # First consider quality, then codecs, then take everything\n        codecs = [('vp6', 'flv'), ('vp8', 'flv'), ('h264', 'mp4')]\n        files = {'hd': [], 'sd': [], 'other': []}\n        config_files = config[\"video\"].get(\"files\") or config[\"request\"].get(\"files\")\n        for codec_name, codec_extension in codecs:\n            for quality in config_files.get(codec_name, []):\n                format_id = '-'.join((codec_name, quality)).lower()\n                key = quality if quality in files else 'other'\n                video_url = None\n                if isinstance(config_files[codec_name], dict):\n                    file_info = config_files[codec_name][quality]\n                    video_url = file_info.get('url')\n                else:\n                    file_info = {}\n                if video_url is None:\n                    video_url = \"http://player.vimeo.com/play_redirect?clip_id=%s&sig=%s&time=%s&quality=%s&codecs=%s&type=moogaloop_local&embed_location=\" \\\n                        % (video_id, sig, timestamp, quality, codec_name.upper())\n\n                files[key].append({\n                    'ext': codec_extension,\n                    'url': video_url,\n                    'format_id': format_id,\n                    'width': file_info.get('width'),\n                    'height': file_info.get('height'),\n                })\n        formats = []\n        for key in ('other', 'sd', 'hd'):\n            formats += files[key]\n        if len(formats) == 0:\n            raise ExtractorError('No known codec found')\n\n        subtitles = {}\n        text_tracks = config['request'].get('text_tracks')\n        if text_tracks:\n            for tt in text_tracks:\n                subtitles[tt['lang']] = 'http://vimeo.com' + tt['url']\n\n        video_subtitles = self.extract_subtitles(video_id, subtitles)\n        if self._downloader.params.get('listsubtitles', False):\n            self._list_available_subtitles(video_id, subtitles)\n            return\n\n        return {\n            'id': video_id,\n            'uploader': video_uploader,\n            'uploader_id': video_uploader_id,\n            'upload_date': video_upload_date,\n            'title': video_title,\n            'thumbnail': video_thumbnail,\n            'description': video_description,\n            'duration': video_duration,\n            'formats': formats,\n            'webpage_url': url,\n            'view_count': view_count,\n            'like_count': like_count,\n            'comment_count': comment_count,\n            'subtitles': video_subtitles,\n        }",
        "begin_line": 194,
        "end_line": 370,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0021231422505307855,
            "pseudo_dstar_susp": 0.0017889087656529517,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0017889087656529517,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoChannelIE._page_url#386",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoChannelIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoChannelIE._page_url(self, base_url, pagenum)",
        "snippet": "    def _page_url(self, base_url, pagenum):\n        return '%s/videos/page:%d/' % (base_url, pagenum)",
        "begin_line": 386,
        "end_line": 387,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.0001840942562592047,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoChannelIE._extract_list_title#389",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoChannelIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoChannelIE._extract_list_title(self, webpage)",
        "snippet": "    def _extract_list_title(self, webpage):\n        return self._html_search_regex(self._TITLE_RE, webpage, 'list title')",
        "begin_line": 389,
        "end_line": 390,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0002318034306907742,
            "pseudo_dstar_susp": 0.00023153507756425097,
            "pseudo_tarantula_susp": 0.00025746652935118434,
            "pseudo_op2_susp": 0.00023153507756425097,
            "pseudo_barinel_susp": 0.00025687130747495504
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoChannelIE._extract_videos#392",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoChannelIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoChannelIE._extract_videos(self, list_id, base_url)",
        "snippet": "    def _extract_videos(self, list_id, base_url):\n        video_ids = []\n        for pagenum in itertools.count(1):\n            webpage = self._download_webpage(\n                self._page_url(base_url, pagenum), list_id,\n                'Downloading page %s' % pagenum)\n            video_ids.extend(re.findall(r'id=\"clip_(\\d+?)\"', webpage))\n            if re.search(self._MORE_PAGES_INDICATOR, webpage, re.DOTALL) is None:\n                break\n\n        entries = [self.url_result('http://vimeo.com/%s' % video_id, 'Vimeo')\n                   for video_id in video_ids]\n        return {'_type': 'playlist',\n                'id': list_id,\n                'title': self._extract_list_title(webpage),\n                'entries': entries,\n                }",
        "begin_line": 392,
        "end_line": 408,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0006640106241699867,
            "pseudo_tarantula_susp": 0.0002772387025228722,
            "pseudo_op2_susp": 0.0006640106241699867,
            "pseudo_barinel_susp": 0.00027631942525559546
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoChannelIE._real_extract#410",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoChannelIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        channel_id = mobj.group('id')\n        return self._extract_videos(channel_id, 'http://vimeo.com/channels/%s' % channel_id)",
        "begin_line": 410,
        "end_line": 413,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoUserIE._real_extract#428",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoUserIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        name = mobj.group('name')\n        return self._extract_videos(name, 'http://vimeo.com/%s' % name)",
        "begin_line": 428,
        "end_line": 431,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoAlbumIE._page_url#446",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoAlbumIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoAlbumIE._page_url(self, base_url, pagenum)",
        "snippet": "    def _page_url(self, base_url, pagenum):\n        return '%s/page:%d/' % (base_url, pagenum)",
        "begin_line": 446,
        "end_line": 447,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoAlbumIE._real_extract#449",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoAlbumIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoAlbumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        album_id = mobj.group('id')\n        return self._extract_videos(album_id, 'http://vimeo.com/album/%s' % album_id)",
        "begin_line": 449,
        "end_line": 452,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoGroupsIE._extract_list_title#466",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoGroupsIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoGroupsIE._extract_list_title(self, webpage)",
        "snippet": "    def _extract_list_title(self, webpage):\n        return self._og_search_title(webpage)",
        "begin_line": 466,
        "end_line": 467,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoGroupsIE._real_extract#469",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoGroupsIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoGroupsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        name = mobj.group('name')\n        return self._extract_videos(name, 'http://vimeo.com/groups/%s' % name)",
        "begin_line": 469,
        "end_line": 472,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoReviewIE._real_extract#501",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoReviewIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoReviewIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        player_url = 'https://player.vimeo.com/player/' + video_id\n        return self.url_result(player_url, 'Vimeo', video_id)",
        "begin_line": 501,
        "end_line": 505,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoWatchLaterIE._real_initialize#519",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoWatchLaterIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoWatchLaterIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 519,
        "end_line": 520,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoWatchLaterIE._page_url#522",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoWatchLaterIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoWatchLaterIE._page_url(self, base_url, pagenum)",
        "snippet": "    def _page_url(self, base_url, pagenum):\n        url = '%s/page:%d/' % (base_url, pagenum)\n        request = compat_urllib_request.Request(url)\n        # Set the header to get a partial html page with the ids,\n        # the normal page doesn't contain them.\n        request.add_header('X-Requested-With', 'XMLHttpRequest')\n        return request",
        "begin_line": 522,
        "end_line": 528,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoWatchLaterIE._real_extract#530",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoWatchLaterIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoWatchLaterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        return self._extract_videos('watchlater', 'https://vimeo.com/home/watchlater')",
        "begin_line": 530,
        "end_line": 531,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.mtv._media_xml_tag#19",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv",
        "signature": "youtube_dl.extractor.mtv._media_xml_tag(tag)",
        "snippet": "def _media_xml_tag(tag):\n    return '{http://search.yahoo.com/mrss/}%s' % tag",
        "begin_line": 19,
        "end_line": 20,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._id_from_uri#27",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._id_from_uri(uri)",
        "snippet": "    def _id_from_uri(uri):\n        return uri.split(':')[-1]",
        "begin_line": 27,
        "end_line": 28,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_feed_url#39",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_feed_url(self, uri)",
        "snippet": "    def _get_feed_url(self, uri):\n        return self._FEED_URL",
        "begin_line": 39,
        "end_line": 40,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_thumbnail_url#42",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_thumbnail_url(self, uri, itemdoc)",
        "snippet": "    def _get_thumbnail_url(self, uri, itemdoc):\n        search_path = '%s/%s' % (_media_xml_tag('group'), _media_xml_tag('thumbnail'))\n        thumb_node = itemdoc.find(search_path)\n        if thumb_node is None:\n            return None\n        else:\n            return thumb_node.attrib['url']",
        "begin_line": 42,
        "end_line": 48,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._extract_mobile_video_formats#50",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._extract_mobile_video_formats(self, mtvn_id)",
        "snippet": "    def _extract_mobile_video_formats(self, mtvn_id):\n        webpage_url = self._MOBILE_TEMPLATE % mtvn_id\n        req = compat_urllib_request.Request(webpage_url)\n        # Otherwise we get a webpage that would execute some javascript\n        req.add_header('Youtubedl-user-agent', 'curl/7')\n        webpage = self._download_webpage(req, mtvn_id,\n            'Downloading mobile page')\n        metrics_url = unescapeHTML(self._search_regex(r'<a href=\"(http://metrics.+?)\"', webpage, 'url'))\n        req = HEADRequest(metrics_url)\n        response = self._request_webpage(req, mtvn_id, 'Resolving url')\n        url = response.geturl()\n        # Transform the url to get the best quality:\n        url = re.sub(r'.+pxE=mp4', 'http://mtvnmobile.vo.llnwd.net/kip0/_pxn=0+_pxK=18639+_pxE=mp4', url, 1)\n        return [{'url': url,'ext': 'mp4'}]",
        "begin_line": 50,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._extract_video_formats#65",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._extract_video_formats(self, mdoc, mtvn_id)",
        "snippet": "    def _extract_video_formats(self, mdoc, mtvn_id):\n        if re.match(r'.*/(error_country_block\\.swf|geoblock\\.mp4)$', mdoc.find('.//src').text) is not None:\n            if mtvn_id is not None and self._MOBILE_TEMPLATE is not None:\n                self.to_screen('The normal version is not available from your '\n                    'country, trying with the mobile version')\n                return self._extract_mobile_video_formats(mtvn_id)\n            raise ExtractorError('This video is not available from your country.',\n                expected=True)\n\n        formats = []\n        for rendition in mdoc.findall('.//rendition'):\n            try:\n                _, _, ext = rendition.attrib['type'].partition('/')\n                rtmp_video_url = rendition.find('./src').text\n                formats.append({'ext': ext,\n                                'url': self._transform_rtmp_url(rtmp_video_url),\n                                'format_id': rendition.get('bitrate'),\n                                'width': int(rendition.get('width')),\n                                'height': int(rendition.get('height')),\n                                })\n            except (KeyError, TypeError):\n                raise ExtractorError('Invalid rendition field.')\n        self._sort_formats(formats)\n        return formats",
        "begin_line": 65,
        "end_line": 88,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_video_info#90",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_video_info(self, itemdoc)",
        "snippet": "    def _get_video_info(self, itemdoc):\n        uri = itemdoc.find('guid').text\n        video_id = self._id_from_uri(uri)\n        self.report_extraction(video_id)\n        mediagen_url = itemdoc.find('%s/%s' % (_media_xml_tag('group'), _media_xml_tag('content'))).attrib['url']\n        # Remove the templates, like &device={device}\n        mediagen_url = re.sub(r'&[^=]*?={.*?}(?=(&|$))', '', mediagen_url)\n        if 'acceptMethods' not in mediagen_url:\n            mediagen_url += '&acceptMethods=fms'\n\n        mediagen_doc = self._download_xml(mediagen_url, video_id,\n            'Downloading video urls')\n\n        description_node = itemdoc.find('description')\n        if description_node is not None:\n            description = description_node.text.strip()\n        else:\n            description = None\n\n        title_el = None\n        if title_el is None:\n            title_el = find_xpath_attr(\n                itemdoc, './/{http://search.yahoo.com/mrss/}category',\n                'scheme', 'urn:mtvn:video_title')\n        if title_el is None:\n            title_el = itemdoc.find('.//{http://search.yahoo.com/mrss/}title')\n        if title_el is None:\n            title_el = itemdoc.find('.//title')\n            if title_el.text is None:\n                title_el = None\n\n        title = title_el.text\n        if title is None:\n            raise ExtractorError('Could not find video title')\n        title = title.strip()\n\n        # This a short id that's used in the webpage urls\n        mtvn_id = None\n        mtvn_id_node = find_xpath_attr(itemdoc, './/{http://search.yahoo.com/mrss/}category',\n                'scheme', 'urn:mtvn:id')\n        if mtvn_id_node is not None:\n            mtvn_id = mtvn_id_node.text\n\n        return {\n            'title': title,\n            'formats': self._extract_video_formats(mediagen_doc, mtvn_id),\n            'id': video_id,\n            'thumbnail': self._get_thumbnail_url(uri, itemdoc),\n            'description': description,\n        }",
        "begin_line": 90,
        "end_line": 139,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_videos_info#141",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_videos_info(self, uri)",
        "snippet": "    def _get_videos_info(self, uri):\n        video_id = self._id_from_uri(uri)\n        feed_url = self._get_feed_url(uri)\n        data = compat_urllib_parse.urlencode({'uri': uri})\n        idoc = self._download_xml(\n            feed_url + '?' + data, video_id,\n            'Downloading info', transform_source=fix_xml_ampersands)\n        return [self._get_video_info(item) for item in idoc.findall('.//item')]",
        "begin_line": 141,
        "end_line": 148,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._real_extract#150",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        title = url_basename(url)\n        webpage = self._download_webpage(url, title)\n        try:\n            # the url can be http://media.mtvnservices.com/fb/{mgid}.swf\n            # or http://media.mtvnservices.com/{mgid}\n            og_url = self._og_search_video_url(webpage)\n            mgid = url_basename(og_url)\n            if mgid.endswith('.swf'):\n                mgid = mgid[:-4]\n        except RegexNotFoundError:\n            mgid = None\n\n        if mgid is None or ':' not in mgid:\n            mgid = self._search_regex(\n                [r'data-mgid=\"(.*?)\"', r'swfobject.embedSWF\\(\".*?(mgid:.*?)\"'],\n                webpage, u'mgid')\n        return self._get_videos_info(mgid)",
        "begin_line": 150,
        "end_line": 167,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011918951132300357,
            "pseudo_dstar_susp": 0.0008110300081103001,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0008110300081103001,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesEmbeddedIE._get_feed_url#186",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesEmbeddedIE",
        "signature": "youtube_dl.extractor.mtv.MTVServicesEmbeddedIE._get_feed_url(self, uri)",
        "snippet": "    def _get_feed_url(self, uri):\n        video_id = self._id_from_uri(uri)\n        site_id = uri.replace(video_id, '')\n        config_url = 'http://media.mtvnservices.com/pmt/e1/players/{0}/config.xml'.format(site_id)\n        config_doc = self._download_xml(config_url, video_id)\n        feed_node = config_doc.find('.//feed')\n        feed_url = feed_node.text.strip().split('?')[0]\n        return feed_url",
        "begin_line": 186,
        "end_line": 193,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesEmbeddedIE._real_extract#195",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesEmbeddedIE",
        "signature": "youtube_dl.extractor.mtv.MTVServicesEmbeddedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        mgid = mobj.group('mgid')\n        return self._get_videos_info(mgid)",
        "begin_line": 195,
        "end_line": 198,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVIE._get_thumbnail_url#232",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVIE",
        "signature": "youtube_dl.extractor.mtv.MTVIE._get_thumbnail_url(self, uri, itemdoc)",
        "snippet": "    def _get_thumbnail_url(self, uri, itemdoc):\n        return 'http://mtv.mtvnimages.com/uri/' + uri",
        "begin_line": 232,
        "end_line": 233,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVIE._real_extract#235",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVIE",
        "signature": "youtube_dl.extractor.mtv.MTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n        uri = mobj.groupdict().get('mgid')\n        if uri is None:\n            webpage = self._download_webpage(url, video_id)\n    \n            # Some videos come from Vevo.com\n            m_vevo = re.search(r'isVevoVideo = true;.*?vevoVideoId = \"(.*?)\";',\n                               webpage, re.DOTALL)\n            if m_vevo:\n                vevo_id = m_vevo.group(1);\n                self.to_screen('Vevo video detected: %s' % vevo_id)\n                return self.url_result('vevo:%s' % vevo_id, ie='Vevo')\n    \n            uri = self._html_search_regex(r'/uri/(.*?)\\?', webpage, 'uri')\n        return self._get_videos_info(uri)",
        "begin_line": 235,
        "end_line": 251,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.mitele.MiTeleIE._real_extract#32",
        "src_path": "youtube_dl/extractor/mitele.py",
        "class_name": "youtube_dl.extractor.mitele.MiTeleIE",
        "signature": "youtube_dl.extractor.mitele.MiTeleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        episode = mobj.group('episode')\n        webpage = self._download_webpage(url, episode)\n        embed_data_json = self._search_regex(\n            r'MSV\\.embedData\\[.*?\\]\\s*=\\s*({.*?});', webpage, 'embed data',\n            flags=re.DOTALL\n        ).replace('\\'', '\"')\n        embed_data = json.loads(embed_data_json)\n\n        info_url = embed_data['flashvars']['host']\n        info_el = self._download_xml(info_url, episode).find('./video/info')\n\n        video_link = info_el.find('videoUrl/link').text\n        token_query = compat_urllib_parse.urlencode({'id': video_link})\n        token_info = self._download_json(\n            'http://token.mitele.es/?' + token_query, episode,\n            transform_source=strip_jsonp\n        )\n\n        return {\n            'id': embed_data['videoId'],\n            'display_id': episode,\n            'title': info_el.find('title').text,\n            'url': token_info['tokenizedUrl'],\n            'description': get_element_by_attribute('class', 'text', webpage),\n            'thumbnail': info_el.find('thumb').text,\n            'duration': parse_duration(info_el.find('duration').text),\n        }",
        "begin_line": 32,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.__init__#186",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.__init__(self, params=None)",
        "snippet": "    def __init__(self, params=None):\n        \"\"\"Create a FileDownloader object with the given options.\"\"\"\n        if params is None:\n            params = {}\n        self._ies = []\n        self._ies_instances = {}\n        self._pps = []\n        self._progress_hooks = []\n        self._download_retcode = 0\n        self._num_downloads = 0\n        self._screen_file = [sys.stdout, sys.stderr][params.get('logtostderr', False)]\n        self._err_file = sys.stderr\n        self.params = params\n        self.cache = Cache(self)\n\n        if params.get('bidi_workaround', False):\n            try:\n                import pty\n                master, slave = pty.openpty()\n                width = get_term_width()\n                if width is None:\n                    width_args = []\n                else:\n                    width_args = ['-w', str(width)]\n                sp_kwargs = dict(\n                    stdin=subprocess.PIPE,\n                    stdout=slave,\n                    stderr=self._err_file)\n                try:\n                    self._output_process = subprocess.Popen(\n                        ['bidiv'] + width_args, **sp_kwargs\n                    )\n                except OSError:\n                    self._output_process = subprocess.Popen(\n                        ['fribidi', '-c', 'UTF-8'] + width_args, **sp_kwargs)\n                self._output_channel = os.fdopen(master, 'rb')\n            except OSError as ose:\n                if ose.errno == 2:\n                    self.report_warning('Could not find fribidi executable, ignoring --bidi-workaround . Make sure that  fribidi  is an executable file in one of the directories in your $PATH.')\n                else:\n                    raise\n\n        if (sys.version_info >= (3,) and sys.platform != 'win32' and\n                sys.getfilesystemencoding() in ['ascii', 'ANSI_X3.4-1968']\n                and not params['restrictfilenames']):\n            # On Python 3, the Unicode filesystem API will throw errors (#1474)\n            self.report_warning(\n                'Assuming --restrict-filenames since file system encoding '\n                'cannot encode all charactes. '\n                'Set the LC_ALL environment variable to fix this.')\n            self.params['restrictfilenames'] = True\n\n        if '%(stitle)s' in self.params.get('outtmpl', ''):\n            self.report_warning('%(stitle)s is deprecated. Use the %(title)s and the --restrict-filenames flag(which also secures %(uploader)s et al) instead.')\n\n        self._setup_opener()",
        "begin_line": 186,
        "end_line": 241,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.018518518518518517,
            "pseudo_dstar_susp": 0.03225806451612903,
            "pseudo_tarantula_susp": 0.00030902348578491963,
            "pseudo_op2_susp": 0.03225806451612903,
            "pseudo_barinel_susp": 0.00030902348578491963
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.add_info_extractor#243",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.add_info_extractor(self, ie)",
        "snippet": "    def add_info_extractor(self, ie):\n        \"\"\"Add an InfoExtractor object to the end of the list.\"\"\"\n        self._ies.append(ie)\n        self._ies_instances[ie.ie_key()] = ie\n        ie.set_downloader(self)",
        "begin_line": 243,
        "end_line": 247,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.009259259259259259,
            "pseudo_dstar_susp": 0.00980392156862745,
            "pseudo_tarantula_susp": 0.00031655587211142766,
            "pseudo_op2_susp": 0.00980392156862745,
            "pseudo_barinel_susp": 0.00031655587211142766
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.get_info_extractor#249",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.get_info_extractor(self, ie_key)",
        "snippet": "    def get_info_extractor(self, ie_key):\n        \"\"\"\n        Get an instance of an IE with name ie_key, it will try to get one from\n        the _ies list, if there's no instance it will create a new one and add\n        it to the extractor list.\n        \"\"\"\n        ie = self._ies_instances.get(ie_key)\n        if ie is None:\n            ie = get_info_extractor(ie_key)()\n            self.add_info_extractor(ie)\n        return ie",
        "begin_line": 249,
        "end_line": 259,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0017241379310344827,
            "pseudo_dstar_susp": 0.001445086705202312,
            "pseudo_tarantula_susp": 0.00031867431485022306,
            "pseudo_op2_susp": 0.001445086705202312,
            "pseudo_barinel_susp": 0.00031857279388340236
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.add_default_info_extractors#261",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.add_default_info_extractors(self)",
        "snippet": "    def add_default_info_extractors(self):\n        \"\"\"\n        Add the InfoExtractors returned by gen_extractors to the end of the list\n        \"\"\"\n        for ie in gen_extractors():\n            self.add_info_extractor(ie)",
        "begin_line": 261,
        "end_line": 266,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.007246376811594203,
            "pseudo_dstar_susp": 0.006993006993006993,
            "pseudo_tarantula_susp": 0.00031338138514572234,
            "pseudo_op2_susp": 0.006993006993006993,
            "pseudo_barinel_susp": 0.00031338138514572234
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.add_post_processor#268",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.add_post_processor(self, pp)",
        "snippet": "    def add_post_processor(self, pp):\n        \"\"\"Add a PostProcessor object to the end of the chain.\"\"\"\n        self._pps.append(pp)\n        pp.set_downloader(self)",
        "begin_line": 268,
        "end_line": 271,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.add_progress_hook#273",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.add_progress_hook(self, ph)",
        "snippet": "    def add_progress_hook(self, ph):\n        \"\"\"Add the progress hook (currently only for the file downloader)\"\"\"\n        self._progress_hooks.append(ph)",
        "begin_line": 273,
        "end_line": 275,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.006666666666666667,
            "pseudo_dstar_susp": 0.006666666666666667,
            "pseudo_tarantula_susp": 0.00031308703819661864,
            "pseudo_op2_susp": 0.006666666666666667,
            "pseudo_barinel_susp": 0.00031308703819661864
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._bidi_workaround#277",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._bidi_workaround(self, message)",
        "snippet": "    def _bidi_workaround(self, message):\n        if not hasattr(self, '_output_channel'):\n            return message\n\n        assert hasattr(self, '_output_process')\n        assert isinstance(message, compat_str)\n        line_count = message.count('\\n') + 1\n        self._output_process.stdin.write((message + '\\n').encode('utf-8'))\n        self._output_process.stdin.flush()\n        res = ''.join(self._output_channel.readline().decode('utf-8')\n                       for _ in range(line_count))\n        return res[:-len('\\n')]",
        "begin_line": 277,
        "end_line": 288,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.008064516129032258,
            "pseudo_dstar_susp": 0.008333333333333333,
            "pseudo_tarantula_susp": 0.00031486146095717883,
            "pseudo_op2_susp": 0.008333333333333333,
            "pseudo_barinel_susp": 0.00031496062992125983
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.to_screen#290",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.to_screen(self, message, skip_eol=False)",
        "snippet": "    def to_screen(self, message, skip_eol=False):\n        \"\"\"Print message to stdout if not in quiet mode.\"\"\"\n        return self.to_stdout(message, skip_eol, check_quiet=True)",
        "begin_line": 290,
        "end_line": 292,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.008064516129032258,
            "pseudo_dstar_susp": 0.008333333333333333,
            "pseudo_tarantula_susp": 0.00031486146095717883,
            "pseudo_op2_susp": 0.008333333333333333,
            "pseudo_barinel_susp": 0.00031496062992125983
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._write_string#294",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._write_string(self, s, out=None)",
        "snippet": "    def _write_string(self, s, out=None):\n        write_string(s, out=out, encoding=self.params.get('encoding'))",
        "begin_line": 294,
        "end_line": 295,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.008064516129032258,
            "pseudo_dstar_susp": 0.008333333333333333,
            "pseudo_tarantula_susp": 0.00031486146095717883,
            "pseudo_op2_susp": 0.008333333333333333,
            "pseudo_barinel_susp": 0.00031496062992125983
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.to_stdout#297",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.to_stdout(self, message, skip_eol=False, check_quiet=False)",
        "snippet": "    def to_stdout(self, message, skip_eol=False, check_quiet=False):\n        \"\"\"Print message to stdout if not in quiet mode.\"\"\"\n        if self.params.get('logger'):\n            self.params['logger'].debug(message)\n        elif not check_quiet or not self.params.get('quiet', False):\n            message = self._bidi_workaround(message)\n            terminator = ['\\n', ''][skip_eol]\n            output = message + terminator\n\n            self._write_string(output, self._screen_file)",
        "begin_line": 297,
        "end_line": 306,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.008064516129032258,
            "pseudo_dstar_susp": 0.008333333333333333,
            "pseudo_tarantula_susp": 0.00031486146095717883,
            "pseudo_op2_susp": 0.008333333333333333,
            "pseudo_barinel_susp": 0.00031496062992125983
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.to_stderr#308",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.to_stderr(self, message)",
        "snippet": "    def to_stderr(self, message):\n        \"\"\"Print message to stderr.\"\"\"\n        assert isinstance(message, compat_str)\n        if self.params.get('logger'):\n            self.params['logger'].error(message)\n        else:\n            message = self._bidi_workaround(message)\n            output = message + '\\n'\n            self._write_string(output, self._err_file)",
        "begin_line": 308,
        "end_line": 316,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007692307692307692,
            "pseudo_dstar_susp": 0.0006273525721455458,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006273525721455458,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.to_console_title#318",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.to_console_title(self, message)",
        "snippet": "    def to_console_title(self, message):\n        if not self.params.get('consoletitle', False):\n            return\n        if os.name == 'nt' and ctypes.windll.kernel32.GetConsoleWindow():\n            # c_wchar_p() might not be necessary if `message` is\n            # already of type unicode()\n            ctypes.windll.kernel32.SetConsoleTitleW(ctypes.c_wchar_p(message))\n        elif 'TERM' in os.environ:\n            self._write_string('\\033]0;%s\\007' % message, self._screen_file)",
        "begin_line": 318,
        "end_line": 326,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006693440428380187,
            "pseudo_dstar_susp": 0.0009107468123861566,
            "pseudo_tarantula_susp": 0.0002447980416156671,
            "pseudo_op2_susp": 0.0009107468123861566,
            "pseudo_barinel_susp": 0.00024467824810374357
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.save_console_title#328",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.save_console_title(self)",
        "snippet": "    def save_console_title(self):\n        if not self.params.get('consoletitle', False):\n            return\n        if 'TERM' in os.environ:\n            # Save the title on stack\n            self._write_string('\\033[22;0t', self._screen_file)",
        "begin_line": 328,
        "end_line": 333,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.restore_console_title#335",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.restore_console_title(self)",
        "snippet": "    def restore_console_title(self):\n        if not self.params.get('consoletitle', False):\n            return\n        if 'TERM' in os.environ:\n            # Restore the title from stack\n            self._write_string('\\033[23;0t', self._screen_file)",
        "begin_line": 335,
        "end_line": 340,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.__enter__#342",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.__enter__(self)",
        "snippet": "    def __enter__(self):\n        self.save_console_title()\n        return self",
        "begin_line": 342,
        "end_line": 344,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.__exit__#346",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.__exit__(self, *args)",
        "snippet": "    def __exit__(self, *args):\n        self.restore_console_title()\n\n        if self.params.get('cookiefile') is not None:\n            self.cookiejar.save()",
        "begin_line": 346,
        "end_line": 350,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.trouble#352",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.trouble(self, message=None, tb=None)",
        "snippet": "    def trouble(self, message=None, tb=None):\n        \"\"\"Determine action to take when a download problem appears.\n\n        Depending on if the downloader has been configured to ignore\n        download errors or not, this method may throw an exception or\n        not when errors are found, after printing the message.\n\n        tb, if given, is additional traceback information.\n        \"\"\"\n        if message is not None:\n            self.to_stderr(message)\n        if self.params.get('verbose'):\n            if tb is None:\n                if sys.exc_info()[0]:  # if .trouble has been called from an except block\n                    tb = ''\n                    if hasattr(sys.exc_info()[1], 'exc_info') and sys.exc_info()[1].exc_info[0]:\n                        tb += ''.join(traceback.format_exception(*sys.exc_info()[1].exc_info))\n                    tb += compat_str(traceback.format_exc())\n                else:\n                    tb_data = traceback.format_list(traceback.extract_stack())\n                    tb = ''.join(tb_data)\n            self.to_stderr(tb)\n        if not self.params.get('ignoreerrors', False):\n            if sys.exc_info()[0] and hasattr(sys.exc_info()[1], 'exc_info') and sys.exc_info()[1].exc_info[0]:\n                exc_info = sys.exc_info()[1].exc_info\n            else:\n                exc_info = sys.exc_info()\n            raise DownloadError(message, exc_info)\n        self._download_retcode = 1",
        "begin_line": 352,
        "end_line": 380,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.006024096385542169,
            "pseudo_dstar_susp": 0.005847953216374269,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.005847953216374269,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.report_warning#382",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.report_warning(self, message)",
        "snippet": "    def report_warning(self, message):\n        '''\n        Print the message to stderr, it will be prefixed with 'WARNING:'\n        If stderr is a tty file the 'WARNING:' will be colored\n        '''\n        if self.params.get('logger') is not None:\n            self.params['logger'].warning(message)\n        else:\n            if self.params.get('no_warnings'):\n                return\n            if self._err_file.isatty() and os.name != 'nt':\n                _msg_header = '\\033[0;33mWARNING:\\033[0m'\n            else:\n                _msg_header = 'WARNING:'\n            warning_message = '%s %s' % (_msg_header, message)\n            self.to_stderr(warning_message)",
        "begin_line": 382,
        "end_line": 397,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.report_error#399",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.report_error(self, message, tb=None)",
        "snippet": "    def report_error(self, message, tb=None):\n        '''\n        Do the same as trouble, but prefixes the message with 'ERROR:', colored\n        in red if stderr is a tty file.\n        '''\n        if self._err_file.isatty() and os.name != 'nt':\n            _msg_header = '\\033[0;31mERROR:\\033[0m'\n        else:\n            _msg_header = 'ERROR:'\n        error_message = '%s %s' % (_msg_header, message)\n        self.trouble(error_message, tb)",
        "begin_line": 399,
        "end_line": 409,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.006024096385542169,
            "pseudo_dstar_susp": 0.005847953216374269,
            "pseudo_tarantula_susp": 0.0003248862897985705,
            "pseudo_op2_susp": 0.005847953216374269,
            "pseudo_barinel_susp": 0.0003248862897985705
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.report_file_already_downloaded#411",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.report_file_already_downloaded(self, file_name)",
        "snippet": "    def report_file_already_downloaded(self, file_name):\n        \"\"\"Report file has already been fully downloaded.\"\"\"\n        try:\n            self.to_screen('[download] %s has already been downloaded' % file_name)\n        except UnicodeEncodeError:\n            self.to_screen('[download] The file has already been downloaded')",
        "begin_line": 411,
        "end_line": 416,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.prepare_filename#418",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.prepare_filename(self, info_dict)",
        "snippet": "    def prepare_filename(self, info_dict):\n        \"\"\"Generate the output filename.\"\"\"\n        try:\n            template_dict = dict(info_dict)\n\n            template_dict['epoch'] = int(time.time())\n            autonumber_size = self.params.get('autonumber_size')\n            if autonumber_size is None:\n                autonumber_size = 5\n            autonumber_templ = '%0' + str(autonumber_size) + 'd'\n            template_dict['autonumber'] = autonumber_templ % self._num_downloads\n            if template_dict.get('playlist_index') is not None:\n                template_dict['playlist_index'] = '%0*d' % (len(str(template_dict['n_entries'])), template_dict['playlist_index'])\n            if template_dict.get('resolution') is None:\n                if template_dict.get('width') and template_dict.get('height'):\n                    template_dict['resolution'] = '%dx%d' % (template_dict['width'], template_dict['height'])\n                elif template_dict.get('height'):\n                    template_dict['resolution'] = '%sp' % template_dict['height']\n                elif template_dict.get('width'):\n                    template_dict['resolution'] = '?x%d' % template_dict['width']\n\n            sanitize = lambda k, v: sanitize_filename(\n                compat_str(v),\n                restricted=self.params.get('restrictfilenames'),\n                is_id=(k == 'id'))\n            template_dict = dict((k, sanitize(k, v))\n                                 for k, v in template_dict.items()\n                                 if v is not None)\n            template_dict = collections.defaultdict(lambda: 'NA', template_dict)\n\n            outtmpl = self.params.get('outtmpl', DEFAULT_OUTTMPL)\n            tmpl = os.path.expanduser(outtmpl)\n            filename = tmpl % template_dict\n            return filename\n        except ValueError as err:\n            self.report_error('Error in output template: ' + str(err) + ' (encoding: ' + repr(preferredencoding()) + ')')\n            return None",
        "begin_line": 418,
        "end_line": 454,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.5,
            "pseudo_dstar_susp": 0.5,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.5,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._match_entry#456",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._match_entry(self, info_dict)",
        "snippet": "    def _match_entry(self, info_dict):\n        \"\"\" Returns None iff the file should be downloaded \"\"\"\n\n        video_title = info_dict.get('title', info_dict.get('id', 'video'))\n        if 'title' in info_dict:\n            # This can happen when we're just evaluating the playlist\n            title = info_dict['title']\n            matchtitle = self.params.get('matchtitle', False)\n            if matchtitle:\n                if not re.search(matchtitle, title, re.IGNORECASE):\n                    return '\"' + title + '\" title did not match pattern \"' + matchtitle + '\"'\n            rejecttitle = self.params.get('rejecttitle', False)\n            if rejecttitle:\n                if re.search(rejecttitle, title, re.IGNORECASE):\n                    return '\"' + title + '\" title matched reject pattern \"' + rejecttitle + '\"'\n        date = info_dict.get('upload_date', None)\n        if date is not None:\n            dateRange = self.params.get('daterange', DateRange())\n            if date not in dateRange:\n                return '%s upload date is not in range %s' % (date_from_str(date).isoformat(), dateRange)\n        view_count = info_dict.get('view_count', None)\n        if view_count is not None:\n            min_views = self.params.get('min_views')\n            if min_views is not None and view_count < min_views:\n                return 'Skipping %s, because it has not reached minimum view count (%d/%d)' % (video_title, view_count, min_views)\n            max_views = self.params.get('max_views')\n            if max_views is not None and view_count > max_views:\n                return 'Skipping %s, because it has exceeded the maximum view count (%d/%d)' % (video_title, view_count, max_views)\n        age_limit = self.params.get('age_limit')\n        if age_limit is not None:\n            actual_age_limit = info_dict.get('age_limit')\n            if actual_age_limit is None:\n                actual_age_limit = 0\n            if age_limit < actual_age_limit:\n                return 'Skipping \"' + title + '\" because it is age restricted'\n        if self.in_download_archive(info_dict):\n            return '%s has already been recorded in archive' % video_title\n        return None",
        "begin_line": 456,
        "end_line": 493,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0013717421124828531,
            "pseudo_dstar_susp": 0.002232142857142857,
            "pseudo_tarantula_susp": 0.00027114967462039046,
            "pseudo_op2_susp": 0.002232142857142857,
            "pseudo_barinel_susp": 0.0002681684097613301
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.add_extra_info#496",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.add_extra_info(info_dict, extra_info)",
        "snippet": "    def add_extra_info(info_dict, extra_info):\n        '''Set the keys from extra_info in info dict if they are missing'''\n        for key, value in extra_info.items():\n            info_dict.setdefault(key, value)",
        "begin_line": 496,
        "end_line": 499,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002680965147453083,
            "pseudo_dstar_susp": 0.0029411764705882353,
            "pseudo_tarantula_susp": 0.00028401022436807724,
            "pseudo_op2_susp": 0.0029411764705882353,
            "pseudo_barinel_susp": 0.00028401022436807724
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.extract_info#501",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.extract_info(self, url, download=True, ie_key=None, extra_info={}, process=True)",
        "snippet": "    def extract_info(self, url, download=True, ie_key=None, extra_info={},\n                     process=True):\n        '''\n        Returns a list with a dictionary for each video we find.\n        If 'download', also downloads the videos.\n        extra_info is a dict containing the extra values to add to each result\n         '''\n\n        if ie_key:\n            ies = [self.get_info_extractor(ie_key)]\n        else:\n            ies = self._ies\n\n        for ie in ies:\n            if not ie.suitable(url):\n                continue\n\n            if not ie.working():\n                self.report_warning('The program functionality for this site has been marked as broken, '\n                                    'and will probably not work.')\n\n            try:\n                ie_result = ie.extract(url)\n                if ie_result is None: # Finished already (backwards compatibility; listformats and friends should be moved here)\n                    break\n                if isinstance(ie_result, list):\n                    # Backwards compatibility: old IE result format\n                    ie_result = {\n                        '_type': 'compat_list',\n                        'entries': ie_result,\n                    }\n                self.add_default_extra_info(ie_result, ie, url)\n                if process:\n                    return self.process_ie_result(ie_result, download, extra_info)\n                else:\n                    return ie_result\n            except ExtractorError as de: # An error we somewhat expected\n                self.report_error(compat_str(de), de.format_traceback())\n                break\n            except MaxDownloadsReached:\n                raise\n            except Exception as e:\n                if self.params.get('ignoreerrors', False):\n                    self.report_error(compat_str(e), tb=compat_str(traceback.format_exc()))\n                    break\n                else:\n                    raise\n        else:\n            self.report_error('no suitable InfoExtractor for URL %s' % url)",
        "begin_line": 501,
        "end_line": 549,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.009433962264150943,
            "pseudo_dstar_susp": 0.008333333333333333,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.008333333333333333,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.add_default_extra_info#551",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.add_default_extra_info(self, ie_result, ie, url)",
        "snippet": "    def add_default_extra_info(self, ie_result, ie, url):\n        self.add_extra_info(ie_result, {\n            'extractor': ie.IE_NAME,\n            'webpage_url': url,\n            'webpage_url_basename': url_basename(url),\n            'extractor_key': ie.ie_key(),\n        })",
        "begin_line": 551,
        "end_line": 557,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0027247956403269754,
            "pseudo_dstar_susp": 0.0029940119760479044,
            "pseudo_tarantula_susp": 0.0002844950213371266,
            "pseudo_op2_susp": 0.0029940119760479044,
            "pseudo_barinel_susp": 0.0002844950213371266
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.process_ie_result#559",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.process_ie_result(self, ie_result, download=True, extra_info={})",
        "snippet": "    def process_ie_result(self, ie_result, download=True, extra_info={}):\n        \"\"\"\n        Take the result of the ie(may be modified) and resolve all unresolved\n        references (URLs, playlist items).\n\n        It will also download the videos if 'download'.\n        Returns the resolved ie_result.\n        \"\"\"\n\n        result_type = ie_result.get('_type', 'video')\n\n        if self.params.get('extract_flat', False):\n            if result_type in ('url', 'url_transparent'):\n                return ie_result\n\n        if result_type == 'video':\n            self.add_extra_info(ie_result, extra_info)\n            return self.process_video_result(ie_result, download=download)\n        elif result_type == 'url':\n            # We have to add extra_info to the results because it may be\n            # contained in a playlist\n            return self.extract_info(ie_result['url'],\n                                     download,\n                                     ie_key=ie_result.get('ie_key'),\n                                     extra_info=extra_info)\n        elif result_type == 'url_transparent':\n            # Use the information from the embedding page\n            info = self.extract_info(\n                ie_result['url'], ie_key=ie_result.get('ie_key'),\n                extra_info=extra_info, download=False, process=False)\n\n            def make_result(embedded_info):\n                new_result = ie_result.copy()\n                for f in ('_type', 'url', 'ext', 'player_url', 'formats',\n                          'entries', 'ie_key', 'duration',\n                          'subtitles', 'annotations', 'format',\n                          'thumbnail', 'thumbnails'):\n                    if f in new_result:\n                        del new_result[f]\n                    if f in embedded_info:\n                        new_result[f] = embedded_info[f]\n                return new_result\n            new_result = make_result(info)\n\n            assert new_result.get('_type') != 'url_transparent'\n            if new_result.get('_type') == 'compat_list':\n                new_result['entries'] = [\n                    make_result(e) for e in new_result['entries']]\n\n            return self.process_ie_result(\n                new_result, download=download, extra_info=extra_info)\n        elif result_type == 'playlist':\n            # We process each entry in the playlist\n            playlist = ie_result.get('title', None) or ie_result.get('id', None)\n            self.to_screen('[download] Downloading playlist: %s' % playlist)\n\n            playlist_results = []\n\n            playliststart = self.params.get('playliststart', 1) - 1\n            playlistend = self.params.get('playlistend', None)\n            # For backwards compatibility, interpret -1 as whole list\n            if playlistend == -1:\n                playlistend = None\n\n            if isinstance(ie_result['entries'], list):\n                n_all_entries = len(ie_result['entries'])\n                entries = ie_result['entries'][playliststart:playlistend]\n                n_entries = len(entries)\n                self.to_screen(\n                    \"[%s] playlist %s: Collected %d video ids (downloading %d of them)\" %\n                    (ie_result['extractor'], playlist, n_all_entries, n_entries))\n            else:\n                assert isinstance(ie_result['entries'], PagedList)\n                entries = ie_result['entries'].getslice(\n                    playliststart, playlistend)\n                n_entries = len(entries)\n                self.to_screen(\n                    \"[%s] playlist %s: Downloading %d videos\" %\n                    (ie_result['extractor'], playlist, n_entries))\n\n            for i, entry in enumerate(entries, 1):\n                self.to_screen('[download] Downloading video #%s of %s' % (i, n_entries))\n                extra = {\n                    'n_entries': n_entries,\n                    'playlist': playlist,\n                    'playlist_index': i + playliststart,\n                    'extractor': ie_result['extractor'],\n                    'webpage_url': ie_result['webpage_url'],\n                    'webpage_url_basename': url_basename(ie_result['webpage_url']),\n                    'extractor_key': ie_result['extractor_key'],\n                }\n\n                reason = self._match_entry(entry)\n                if reason is not None:\n                    self.to_screen('[download] ' + reason)\n                    continue\n\n                entry_result = self.process_ie_result(entry,\n                                                      download=download,\n                                                      extra_info=extra)\n                playlist_results.append(entry_result)\n            ie_result['entries'] = playlist_results\n            return ie_result\n        elif result_type == 'compat_list':\n            def _fixup(r):\n                self.add_extra_info(r,\n                    {\n                        'extractor': ie_result['extractor'],\n                        'webpage_url': ie_result['webpage_url'],\n                        'webpage_url_basename': url_basename(ie_result['webpage_url']),\n                        'extractor_key': ie_result['extractor_key'],\n                    })\n                return r\n            ie_result['entries'] = [\n                self.process_ie_result(_fixup(r), download, extra_info)\n                for r in ie_result['entries']\n            ]\n            return ie_result\n        else:\n            raise Exception('Invalid result type: %s' % result_type)",
        "begin_line": 559,
        "end_line": 678,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0025974025974025974,
            "pseudo_dstar_susp": 0.0029239766081871343,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0029239766081871343,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._fixup#663",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._fixup(r)",
        "snippet": "            def _fixup(r):\n                self.add_extra_info(r,\n                    {\n                        'extractor': ie_result['extractor'],\n                        'webpage_url': ie_result['webpage_url'],\n                        'webpage_url_basename': url_basename(ie_result['webpage_url']),\n                        'extractor_key': ie_result['extractor_key'],\n                    })\n                return r",
        "begin_line": 663,
        "end_line": 671,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.0004462293618920125,
            "pseudo_tarantula_susp": 0.0002772387025228722,
            "pseudo_op2_susp": 0.0004462293618920125,
            "pseudo_barinel_susp": 0.00027631942525559546
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.select_format#680",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.select_format(self, format_spec, available_formats)",
        "snippet": "    def select_format(self, format_spec, available_formats):\n        if format_spec == 'best' or format_spec is None:\n            return available_formats[-1]\n        elif format_spec == 'worst':\n            return available_formats[0]\n        elif format_spec == 'bestaudio':\n            audio_formats = [\n                f for f in available_formats\n                if f.get('vcodec') == 'none']\n            if audio_formats:\n                return audio_formats[-1]\n        elif format_spec == 'worstaudio':\n            audio_formats = [\n                f for f in available_formats\n                if f.get('vcodec') == 'none']\n            if audio_formats:\n                return audio_formats[0]\n        elif format_spec == 'bestvideo':\n            video_formats = [\n                f for f in available_formats\n                if f.get('acodec') == 'none']\n            if video_formats:\n                return video_formats[-1]\n        elif format_spec == 'worstvideo':\n            video_formats = [\n                f for f in available_formats\n                if f.get('acodec') == 'none']\n            if video_formats:\n                return video_formats[0]\n        else:\n            extensions = ['mp4', 'flv', 'webm', '3gp']\n            if format_spec in extensions:\n                filter_f = lambda f: f['ext'] == format_spec\n            else:\n                filter_f = lambda f: f['format_id'] == format_spec\n            matches = list(filter(filter_f, available_formats))\n            if matches:\n                return matches[-1]\n        return None",
        "begin_line": 680,
        "end_line": 718,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001142857142857143,
            "pseudo_dstar_susp": 0.0019880715705765406,
            "pseudo_tarantula_susp": 0.0002560163850486431,
            "pseudo_op2_susp": 0.0019880715705765406,
            "pseudo_barinel_susp": 0.0002560163850486431
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.process_video_result#720",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.process_video_result(self, info_dict, download=True)",
        "snippet": "    def process_video_result(self, info_dict, download=True):\n        assert info_dict.get('_type', 'video') == 'video'\n\n        if 'id' not in info_dict:\n            raise ExtractorError('Missing \"id\" field in extractor result')\n        if 'title' not in info_dict:\n            raise ExtractorError('Missing \"title\" field in extractor result')\n\n        if 'playlist' not in info_dict:\n            # It isn't part of a playlist\n            info_dict['playlist'] = None\n            info_dict['playlist_index'] = None\n\n        thumbnails = info_dict.get('thumbnails')\n        if thumbnails:\n            thumbnails.sort(key=lambda t: (\n                t.get('width'), t.get('height'), t.get('url')))\n            for t in thumbnails:\n                if 'width' in t and 'height' in t:\n                    t['resolution'] = '%dx%d' % (t['width'], t['height'])\n\n        if thumbnails and 'thumbnail' not in info_dict:\n            info_dict['thumbnail'] = thumbnails[-1]['url']\n\n        if 'display_id' not in info_dict and 'id' in info_dict:\n            info_dict['display_id'] = info_dict['id']\n\n        if info_dict.get('upload_date') is None and info_dict.get('timestamp') is not None:\n            upload_date = datetime.datetime.utcfromtimestamp(\n                info_dict['timestamp'])\n            info_dict['upload_date'] = upload_date.strftime('%Y%m%d')\n\n        # This extractors handle format selection themselves\n        if info_dict['extractor'] in ['Youku']:\n            if download:\n                self.process_info(info_dict)\n            return info_dict\n\n        # We now pick which formats have to be downloaded\n        if info_dict.get('formats') is None:\n            # There's only one format available\n            formats = [info_dict]\n        else:\n            formats = info_dict['formats']\n\n        if not formats:\n            raise ExtractorError('No video formats found!')\n\n        # We check that all the formats have the format and format_id fields\n        for i, format in enumerate(formats):\n            if 'url' not in format:\n                raise ExtractorError('Missing \"url\" key in result (index %d)' % i)\n\n            if format.get('format_id') is None:\n                format['format_id'] = compat_str(i)\n            if format.get('format') is None:\n                format['format'] = '{id} - {res}{note}'.format(\n                    id=format['format_id'],\n                    res=self.format_resolution(format),\n                    note=' ({0})'.format(format['format_note']) if format.get('format_note') is not None else '',\n                )\n            # Automatically determine file extension if missing\n            if 'ext' not in format:\n                format['ext'] = determine_ext(format['url']).lower()\n\n        format_limit = self.params.get('format_limit', None)\n        if format_limit:\n            formats = list(takewhile_inclusive(\n                lambda f: f['format_id'] != format_limit, formats\n            ))\n\n        # TODO Central sorting goes here\n\n        if formats[0] is not info_dict:\n            # only set the 'formats' fields if the original info_dict list them\n            # otherwise we end up with a circular reference, the first (and unique)\n            # element in the 'formats' field in info_dict is info_dict itself,\n            # wich can't be exported to json\n            info_dict['formats'] = formats\n        if self.params.get('listformats', None):\n            self.list_formats(info_dict)\n            return\n\n        req_format = self.params.get('format')\n        if req_format is None:\n            req_format = 'best'\n        formats_to_download = []\n        # The -1 is for supporting YoutubeIE\n        if req_format in ('-1', 'all'):\n            formats_to_download = formats\n        else:\n            # We can accept formats requested in the format: 34/5/best, we pick\n            # the first that is available, starting from left\n            req_formats = req_format.split('/')\n            for rf in req_formats:\n                if re.match(r'.+?\\+.+?', rf) is not None:\n                    # Two formats have been requested like '137+139'\n                    format_1, format_2 = rf.split('+')\n                    formats_info = (self.select_format(format_1, formats),\n                        self.select_format(format_2, formats))\n                    if all(formats_info):\n                        selected_format = {\n                            'requested_formats': formats_info,\n                            'format': rf,\n                            'ext': formats_info[0]['ext'],\n                        }\n                    else:\n                        selected_format = None\n                else:\n                    selected_format = self.select_format(rf, formats)\n                if selected_format is not None:\n                    formats_to_download = [selected_format]\n                    break\n        if not formats_to_download:\n            raise ExtractorError('requested format not available',\n                                 expected=True)\n\n        if download:\n            if len(formats_to_download) > 1:\n                self.to_screen('[info] %s: downloading video in %s formats' % (info_dict['id'], len(formats_to_download)))\n            for format in formats_to_download:\n                new_info = dict(info_dict)\n                new_info.update(format)\n                self.process_info(new_info)\n        # We update the info dict with the best quality format (backwards compatibility)\n        info_dict.update(formats_to_download[-1])\n        return info_dict",
        "begin_line": 720,
        "end_line": 846,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001184834123222749,
            "pseudo_dstar_susp": 0.00199203187250996,
            "pseudo_tarantula_susp": 0.00028129395218002813,
            "pseudo_op2_susp": 0.00199203187250996,
            "pseudo_barinel_susp": 0.00028129395218002813
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.process_info#848",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.process_info(self, info_dict)",
        "snippet": "    def process_info(self, info_dict):\n        \"\"\"Process a single resolved IE result.\"\"\"\n\n        assert info_dict.get('_type', 'video') == 'video'\n\n        max_downloads = self.params.get('max_downloads')\n        if max_downloads is not None:\n            if self._num_downloads >= int(max_downloads):\n                raise MaxDownloadsReached()\n\n        info_dict['fulltitle'] = info_dict['title']\n        if len(info_dict['title']) > 200:\n            info_dict['title'] = info_dict['title'][:197] + '...'\n\n        # Keep for backwards compatibility\n        info_dict['stitle'] = info_dict['title']\n\n        if 'format' not in info_dict:\n            info_dict['format'] = info_dict['ext']\n\n        reason = self._match_entry(info_dict)\n        if reason is not None:\n            self.to_screen('[download] ' + reason)\n            return\n\n        self._num_downloads += 1\n\n        filename = self.prepare_filename(info_dict)\n\n        # Forced printings\n        if self.params.get('forcetitle', False):\n            self.to_stdout(info_dict['fulltitle'])\n        if self.params.get('forceid', False):\n            self.to_stdout(info_dict['id'])\n        if self.params.get('forceurl', False):\n            # For RTMP URLs, also include the playpath\n            self.to_stdout(info_dict['url'] + info_dict.get('play_path', ''))\n        if self.params.get('forcethumbnail', False) and info_dict.get('thumbnail') is not None:\n            self.to_stdout(info_dict['thumbnail'])\n        if self.params.get('forcedescription', False) and info_dict.get('description') is not None:\n            self.to_stdout(info_dict['description'])\n        if self.params.get('forcefilename', False) and filename is not None:\n            self.to_stdout(filename)\n        if self.params.get('forceduration', False) and info_dict.get('duration') is not None:\n            self.to_stdout(formatSeconds(info_dict['duration']))\n        if self.params.get('forceformat', False):\n            self.to_stdout(info_dict['format'])\n        if self.params.get('forcejson', False):\n            info_dict['_filename'] = filename\n            self.to_stdout(json.dumps(info_dict))\n\n        # Do nothing else if in simulate mode\n        if self.params.get('simulate', False):\n            return\n\n        if filename is None:\n            return\n\n        try:\n            dn = os.path.dirname(encodeFilename(filename))\n            if dn and not os.path.exists(dn):\n                os.makedirs(dn)\n        except (OSError, IOError) as err:\n            self.report_error('unable to create directory ' + compat_str(err))\n            return\n\n        if self.params.get('writedescription', False):\n            descfn = filename + '.description'\n            if self.params.get('nooverwrites', False) and os.path.exists(encodeFilename(descfn)):\n                self.to_screen('[info] Video description is already present')\n            else:\n                try:\n                    self.to_screen('[info] Writing video description to: ' + descfn)\n                    with io.open(encodeFilename(descfn), 'w', encoding='utf-8') as descfile:\n                        descfile.write(info_dict['description'])\n                except (KeyError, TypeError):\n                    self.report_warning('There\\'s no description to write.')\n                except (OSError, IOError):\n                    self.report_error('Cannot write description file ' + descfn)\n                    return\n\n        if self.params.get('writeannotations', False):\n            annofn = filename + '.annotations.xml'\n            if self.params.get('nooverwrites', False) and os.path.exists(encodeFilename(annofn)):\n                self.to_screen('[info] Video annotations are already present')\n            else:\n                try:\n                    self.to_screen('[info] Writing video annotations to: ' + annofn)\n                    with io.open(encodeFilename(annofn), 'w', encoding='utf-8') as annofile:\n                        annofile.write(info_dict['annotations'])\n                except (KeyError, TypeError):\n                    self.report_warning('There are no annotations to write.')\n                except (OSError, IOError):\n                    self.report_error('Cannot write annotations file: ' + annofn)\n                    return\n\n        subtitles_are_requested = any([self.params.get('writesubtitles', False),\n                                       self.params.get('writeautomaticsub')])\n\n        if subtitles_are_requested and 'subtitles' in info_dict and info_dict['subtitles']:\n            # subtitles download errors are already managed as troubles in relevant IE\n            # that way it will silently go on when used with unsupporting IE\n            subtitles = info_dict['subtitles']\n            sub_format = self.params.get('subtitlesformat', 'srt')\n            for sub_lang in subtitles.keys():\n                sub = subtitles[sub_lang]\n                if sub is None:\n                    continue\n                try:\n                    sub_filename = subtitles_filename(filename, sub_lang, sub_format)\n                    if self.params.get('nooverwrites', False) and os.path.exists(encodeFilename(sub_filename)):\n                        self.to_screen('[info] Video subtitle %s.%s is already_present' % (sub_lang, sub_format))\n                    else:\n                        self.to_screen('[info] Writing video subtitles to: ' + sub_filename)\n                        with io.open(encodeFilename(sub_filename), 'w', encoding='utf-8') as subfile:\n                                subfile.write(sub)\n                except (OSError, IOError):\n                    self.report_error('Cannot write subtitles file ' + sub_filename)\n                    return\n\n        if self.params.get('writeinfojson', False):\n            infofn = os.path.splitext(filename)[0] + '.info.json'\n            if self.params.get('nooverwrites', False) and os.path.exists(encodeFilename(infofn)):\n                self.to_screen('[info] Video description metadata is already present')\n            else:\n                self.to_screen('[info] Writing video description metadata as JSON to: ' + infofn)\n                try:\n                    write_json_file(info_dict, encodeFilename(infofn))\n                except (OSError, IOError):\n                    self.report_error('Cannot write metadata to JSON file ' + infofn)\n                    return\n\n        if self.params.get('writethumbnail', False):\n            if info_dict.get('thumbnail') is not None:\n                thumb_format = determine_ext(info_dict['thumbnail'], 'jpg')\n                thumb_filename = os.path.splitext(filename)[0] + '.' + thumb_format\n                if self.params.get('nooverwrites', False) and os.path.exists(encodeFilename(thumb_filename)):\n                    self.to_screen('[%s] %s: Thumbnail is already present' %\n                                   (info_dict['extractor'], info_dict['id']))\n                else:\n                    self.to_screen('[%s] %s: Downloading thumbnail ...' %\n                                   (info_dict['extractor'], info_dict['id']))\n                    try:\n                        uf = self.urlopen(info_dict['thumbnail'])\n                        with open(thumb_filename, 'wb') as thumbf:\n                            shutil.copyfileobj(uf, thumbf)\n                        self.to_screen('[%s] %s: Writing thumbnail to: %s' %\n                            (info_dict['extractor'], info_dict['id'], thumb_filename))\n                    except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:\n                        self.report_warning('Unable to download thumbnail \"%s\": %s' %\n                            (info_dict['thumbnail'], compat_str(err)))\n\n        if not self.params.get('skip_download', False):\n            if self.params.get('nooverwrites', False) and os.path.exists(encodeFilename(filename)):\n                success = True\n            else:\n                try:\n                    def dl(name, info):\n                        fd = get_suitable_downloader(info)(self, self.params)\n                        for ph in self._progress_hooks:\n                            fd.add_progress_hook(ph)\n                        if self.params.get('verbose'):\n                            self.to_stdout('[debug] Invoking downloader on %r' % info.get('url'))\n                        return fd.download(name, info)\n                    if info_dict.get('requested_formats') is not None:\n                        downloaded = []\n                        success = True\n                        merger = FFmpegMergerPP(self, not self.params.get('keepvideo'))\n                        if not merger._get_executable():\n                            postprocessors = []\n                            self.report_warning('You have requested multiple '\n                                'formats but ffmpeg or avconv are not installed.'\n                                ' The formats won\\'t be merged')\n                        else:\n                            postprocessors = [merger]\n                        for f in info_dict['requested_formats']:\n                            new_info = dict(info_dict)\n                            new_info.update(f)\n                            fname = self.prepare_filename(new_info)\n                            fname = prepend_extension(fname, 'f%s' % f['format_id'])\n                            downloaded.append(fname)\n                            partial_success = dl(fname, new_info)\n                            success = success and partial_success\n                        info_dict['__postprocessors'] = postprocessors\n                        info_dict['__files_to_merge'] = downloaded\n                    else:\n                        # Just a single file\n                        success = dl(filename, info_dict)\n                except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:\n                    self.report_error('unable to download video data: %s' % str(err))\n                    return\n                except (OSError, IOError) as err:\n                    raise UnavailableVideoError(err)\n                except (ContentTooShortError, ) as err:\n                    self.report_error('content too short (expected %s bytes and served %s)' % (err.expected, err.downloaded))\n                    return\n\n            if success:\n                try:\n                    self.post_process(filename, info_dict)\n                except (PostProcessingError) as err:\n                    self.report_error('postprocessing: %s' % str(err))\n                    return\n\n        self.record_download_archive(info_dict)",
        "begin_line": 848,
        "end_line": 1052,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001199040767386091,
            "pseudo_dstar_susp": 0.0020161290322580645,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0020161290322580645,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.dl#1005",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.dl(name, info)",
        "snippet": "                    def dl(name, info):\n                        fd = get_suitable_downloader(info)(self, self.params)\n                        for ph in self._progress_hooks:\n                            fd.add_progress_hook(ph)\n                        if self.params.get('verbose'):\n                            self.to_stdout('[debug] Invoking downloader on %r' % info.get('url'))\n                        return fd.download(name, info)",
        "begin_line": 1005,
        "end_line": 1011,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0015822784810126582,
            "pseudo_dstar_susp": 0.002551020408163265,
            "pseudo_tarantula_susp": 0.0002627430373095113,
            "pseudo_op2_susp": 0.002551020408163265,
            "pseudo_barinel_susp": 0.0002627430373095113
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.download#1054",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.download(self, url_list)",
        "snippet": "    def download(self, url_list):\n        \"\"\"Download a given list of URLs.\"\"\"\n        outtmpl = self.params.get('outtmpl', DEFAULT_OUTTMPL)\n        if (len(url_list) > 1 and\n                '%' not in outtmpl\n                and self.params.get('max_downloads') != 1):\n            raise SameFileError(outtmpl)\n\n        for url in url_list:\n            try:\n                #It also downloads the videos\n                self.extract_info(url)\n            except UnavailableVideoError:\n                self.report_error('unable to download video')\n            except MaxDownloadsReached:\n                self.to_screen('[info] Maximum number of downloaded files reached.')\n                raise\n\n        return self._download_retcode",
        "begin_line": 1054,
        "end_line": 1072,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0010030090270812437,
            "pseudo_dstar_susp": 0.0007739938080495357,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0007739938080495357,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.download_with_info_file#1074",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.download_with_info_file(self, info_filename)",
        "snippet": "    def download_with_info_file(self, info_filename):\n        with io.open(info_filename, 'r', encoding='utf-8') as f:\n            info = json.load(f)\n        try:\n            self.process_ie_result(info, download=True)\n        except DownloadError:\n            webpage_url = info.get('webpage_url')\n            if webpage_url is not None:\n                self.report_warning('The info failed to download, trying with \"%s\"' % webpage_url)\n                return self.download([webpage_url])\n            else:\n                raise\n        return self._download_retcode",
        "begin_line": 1074,
        "end_line": 1086,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.post_process#1088",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.post_process(self, filename, ie_info)",
        "snippet": "    def post_process(self, filename, ie_info):\n        \"\"\"Run all the postprocessors on the given file.\"\"\"\n        info = dict(ie_info)\n        info['filepath'] = filename\n        keep_video = None\n        pps_chain = []\n        if ie_info.get('__postprocessors') is not None:\n            pps_chain.extend(ie_info['__postprocessors'])\n        pps_chain.extend(self._pps)\n        for pp in pps_chain:\n            try:\n                keep_video_wish, new_info = pp.run(info)\n                if keep_video_wish is not None:\n                    if keep_video_wish:\n                        keep_video = keep_video_wish\n                    elif keep_video is None:\n                        # No clear decision yet, let IE decide\n                        keep_video = keep_video_wish\n            except PostProcessingError as e:\n                self.report_error(e.msg)\n        if keep_video is False and not self.params.get('keepvideo', False):\n            try:\n                self.to_screen('Deleting original file %s (pass -k to keep)' % filename)\n                os.remove(encodeFilename(filename))\n            except (IOError, OSError):\n                self.report_warning('Unable to remove downloaded video file')",
        "begin_line": 1088,
        "end_line": 1113,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006693440428380187,
            "pseudo_dstar_susp": 0.0009107468123861566,
            "pseudo_tarantula_susp": 0.0002447980416156671,
            "pseudo_op2_susp": 0.0009107468123861566,
            "pseudo_barinel_susp": 0.00024467824810374357
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._make_archive_id#1115",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._make_archive_id(self, info_dict)",
        "snippet": "    def _make_archive_id(self, info_dict):\n        # Future-proof against any change in case\n        # and backwards compatibility with prior versions\n        extractor = info_dict.get('extractor_key')\n        if extractor is None:\n            if 'id' in info_dict:\n                extractor = info_dict.get('ie_key')  # key in a playlist\n        if extractor is None:\n            return None  # Incomplete video information\n        return extractor.lower() + ' ' + info_dict['id']",
        "begin_line": 1115,
        "end_line": 1124,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.in_download_archive#1126",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.in_download_archive(self, info_dict)",
        "snippet": "    def in_download_archive(self, info_dict):\n        fn = self.params.get('download_archive')\n        if fn is None:\n            return False\n\n        vid_id = self._make_archive_id(info_dict)\n        if vid_id is None:\n            return False  # Incomplete video information\n\n        try:\n            with locked_file(fn, 'r', encoding='utf-8') as archive_file:\n                for line in archive_file:\n                    if line.strip() == vid_id:\n                        return True\n        except IOError as ioe:\n            if ioe.errno != errno.ENOENT:\n                raise\n        return False",
        "begin_line": 1126,
        "end_line": 1143,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0013123359580052493,
            "pseudo_dstar_susp": 0.0021413276231263384,
            "pseudo_tarantula_susp": 0.0002644802962179318,
            "pseudo_op2_susp": 0.0021413276231263384,
            "pseudo_barinel_susp": 0.0002644802962179318
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.record_download_archive#1145",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.record_download_archive(self, info_dict)",
        "snippet": "    def record_download_archive(self, info_dict):\n        fn = self.params.get('download_archive')\n        if fn is None:\n            return\n        vid_id = self._make_archive_id(info_dict)\n        assert vid_id\n        with locked_file(fn, 'a', encoding='utf-8') as archive_file:\n            archive_file.write(vid_id + '\\n')",
        "begin_line": 1145,
        "end_line": 1152,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007102272727272727,
            "pseudo_dstar_susp": 0.0010162601626016261,
            "pseudo_tarantula_susp": 0.0002397506593143131,
            "pseudo_op2_susp": 0.0010162601626016261,
            "pseudo_barinel_susp": 0.0002397506593143131
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.format_resolution#1155",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.format_resolution(format, default='unknown')",
        "snippet": "    def format_resolution(format, default='unknown'):\n        if format.get('vcodec') == 'none':\n            return 'audio only'\n        if format.get('resolution') is not None:\n            return format['resolution']\n        if format.get('height') is not None:\n            if format.get('width') is not None:\n                res = '%sx%s' % (format['width'], format['height'])\n            else:\n                res = '%sp' % format['height']\n        elif format.get('width') is not None:\n            res = '?x%d' % format['width']\n        else:\n            res = default\n        return res",
        "begin_line": 1155,
        "end_line": 1169,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0010277492291880781,
            "pseudo_dstar_susp": 0.0016051364365971107,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._format_note#1171",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._format_note(self, fdict)",
        "snippet": "    def _format_note(self, fdict):\n        res = ''\n        if fdict.get('ext') in ['f4f', 'f4m']:\n            res += '(unsupported) '\n        if fdict.get('format_note') is not None:\n            res += fdict['format_note'] + ' '\n        if fdict.get('tbr') is not None:\n            res += '%4dk ' % fdict['tbr']\n        if fdict.get('container') is not None:\n            if res:\n                res += ', '\n            res += '%s container' % fdict['container']\n        if (fdict.get('vcodec') is not None and\n                fdict.get('vcodec') != 'none'):\n            if res:\n                res += ', '\n            res += fdict['vcodec']\n            if fdict.get('vbr') is not None:\n                res += '@'\n        elif fdict.get('vbr') is not None and fdict.get('abr') is not None:\n            res += 'video@'\n        if fdict.get('vbr') is not None:\n            res += '%4dk' % fdict['vbr']\n        if fdict.get('acodec') is not None:\n            if res:\n                res += ', '\n            if fdict['acodec'] == 'none':\n                res += 'video only'\n            else:\n                res += '%-5s' % fdict['acodec']\n        elif fdict.get('abr') is not None:\n            if res:\n                res += ', '\n            res += 'audio'\n        if fdict.get('abr') is not None:\n            res += '@%3dk' % fdict['abr']\n        if fdict.get('asr') is not None:\n            res += ' (%5dHz)' % fdict['asr']\n        if fdict.get('filesize') is not None:\n            if res:\n                res += ', '\n            res += format_bytes(fdict['filesize'])\n        elif fdict.get('filesize_approx') is not None:\n            if res:\n                res += ', '\n            res += '~' + format_bytes(fdict['filesize_approx'])\n        return res",
        "begin_line": 1171,
        "end_line": 1217,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.list_formats#1219",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.list_formats(self, info_dict)",
        "snippet": "    def list_formats(self, info_dict):\n        def line(format, idlen=20):\n            return (('%-' + compat_str(idlen + 1) + 's%-10s%-12s%s') % (\n                format['format_id'],\n                format['ext'],\n                self.format_resolution(format),\n                self._format_note(format),\n            ))\n\n        formats = info_dict.get('formats', [info_dict])\n        idlen = max(len('format code'),\n                    max(len(f['format_id']) for f in formats))\n        formats_s = [line(f, idlen) for f in formats]\n        if len(formats) > 1:\n            formats_s[0] += (' ' if self._format_note(formats[0]) else '') + '(worst)'\n            formats_s[-1] += (' ' if self._format_note(formats[-1]) else '') + '(best)'\n\n        header_line = line({\n            'format_id': 'format code', 'ext': 'extension',\n            'resolution': 'resolution', 'format_note': 'note'}, idlen=idlen)\n        self.to_screen('[info] Available formats for %s:\\n%s\\n%s' %\n                       (info_dict['id'], header_line, '\\n'.join(formats_s)))",
        "begin_line": 1219,
        "end_line": 1240,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.urlopen#1242",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.urlopen(self, req)",
        "snippet": "    def urlopen(self, req):\n        \"\"\" Start an HTTP download \"\"\"\n        return self._opener.open(req, timeout=self._socket_timeout)",
        "begin_line": 1242,
        "end_line": 1244,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.07142857142857142,
            "pseudo_dstar_susp": 0.016666666666666666,
            "pseudo_tarantula_susp": 0.0003191828917969997,
            "pseudo_op2_susp": 0.016666666666666666,
            "pseudo_barinel_susp": 0.0003191828917969997
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.print_debug_header#1246",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.print_debug_header(self)",
        "snippet": "    def print_debug_header(self):\n        if not self.params.get('verbose'):\n            return\n\n        if type('') is not compat_str:\n            # Python 2.6 on SLES11 SP1 (https://github.com/rg3/youtube-dl/issues/3326)\n            self.report_warning(\n                'Your Python is broken! Update to a newer and supported version')\n\n        encoding_str = (\n            '[debug] Encodings: locale %s, fs %s, out %s, pref %s\\n' % (\n                locale.getpreferredencoding(),\n                sys.getfilesystemencoding(),\n                sys.stdout.encoding,\n                self.get_encoding()))\n        write_string(encoding_str, encoding=None)\n\n        self._write_string('[debug] youtube-dl version ' + __version__ + '\\n')\n        try:\n            sp = subprocess.Popen(\n                ['git', 'rev-parse', '--short', 'HEAD'],\n                stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n                cwd=os.path.dirname(os.path.abspath(__file__)))\n            out, err = sp.communicate()\n            out = out.decode().strip()\n            if re.match('[0-9a-f]+', out):\n                self._write_string('[debug] Git HEAD: ' + out + '\\n')\n        except:\n            try:\n                sys.exc_clear()\n            except:\n                pass\n        self._write_string('[debug] Python version %s - %s' %\n                     (platform.python_version(), platform_name()) + '\\n')\n\n        proxy_map = {}\n        for handler in self._opener.handlers:\n            if hasattr(handler, 'proxies'):\n                proxy_map.update(handler.proxies)\n        self._write_string('[debug] Proxy map: ' + compat_str(proxy_map) + '\\n')",
        "begin_line": 1246,
        "end_line": 1285,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._setup_opener#1287",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._setup_opener(self)",
        "snippet": "    def _setup_opener(self):\n        timeout_val = self.params.get('socket_timeout')\n        self._socket_timeout = 600 if timeout_val is None else float(timeout_val)\n\n        opts_cookiefile = self.params.get('cookiefile')\n        opts_proxy = self.params.get('proxy')\n\n        if opts_cookiefile is None:\n            self.cookiejar = compat_cookiejar.CookieJar()\n        else:\n            self.cookiejar = compat_cookiejar.MozillaCookieJar(\n                opts_cookiefile)\n            if os.access(opts_cookiefile, os.R_OK):\n                self.cookiejar.load()\n\n        cookie_processor = compat_urllib_request.HTTPCookieProcessor(\n            self.cookiejar)\n        if opts_proxy is not None:\n            if opts_proxy == '':\n                proxies = {}\n            else:\n                proxies = {'http': opts_proxy, 'https': opts_proxy}\n        else:\n            proxies = compat_urllib_request.getproxies()\n            # Set HTTPS proxy to HTTP one if given (https://github.com/rg3/youtube-dl/issues/805)\n            if 'http' in proxies and 'https' not in proxies:\n                proxies['https'] = proxies['http']\n        proxy_handler = compat_urllib_request.ProxyHandler(proxies)\n\n        debuglevel = 1 if self.params.get('debug_printtraffic') else 0\n        https_handler = make_HTTPS_handler(\n            self.params.get('nocheckcertificate', False), debuglevel=debuglevel)\n        ydlh = YoutubeDLHandler(debuglevel=debuglevel)\n        opener = compat_urllib_request.build_opener(\n            https_handler, proxy_handler, cookie_processor, ydlh)\n        # Delete the default user-agent header, which would otherwise apply in\n        # cases where our custom HTTP handler doesn't come into play\n        # (See https://github.com/rg3/youtube-dl/issues/1309 for details)\n        opener.addheaders = []\n        self._opener = opener",
        "begin_line": 1287,
        "end_line": 1326,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.018518518518518517,
            "pseudo_dstar_susp": 0.03225806451612903,
            "pseudo_tarantula_susp": 0.00030902348578491963,
            "pseudo_op2_susp": 0.03225806451612903,
            "pseudo_barinel_susp": 0.00030902348578491963
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.encode#1328",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.encode(self, s)",
        "snippet": "    def encode(self, s):\n        if isinstance(s, bytes):\n            return s  # Already encoded\n\n        try:\n            return s.encode(self.get_encoding())\n        except UnicodeEncodeError as err:\n            err.reason = err.reason + '. Check your system encoding configuration or use the --encoding option.'\n            raise",
        "begin_line": 1328,
        "end_line": 1336,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.get_encoding#1338",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.get_encoding(self)",
        "snippet": "    def get_encoding(self):\n        encoding = self.params.get('encoding')\n        if encoding is None:\n            encoding = preferredencoding()\n        return encoding",
        "begin_line": 1338,
        "end_line": 1342,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.facebook.FacebookIE._login#45",
        "src_path": "youtube_dl/extractor/facebook.py",
        "class_name": "youtube_dl.extractor.facebook.FacebookIE",
        "signature": "youtube_dl.extractor.facebook.FacebookIE._login(self)",
        "snippet": "    def _login(self):\n        (useremail, password) = self._get_login_info()\n        if useremail is None:\n            return\n\n        login_page_req = compat_urllib_request.Request(self._LOGIN_URL)\n        login_page_req.add_header('Cookie', 'locale=en_US')\n        login_page = self._download_webpage(login_page_req, None,\n            note='Downloading login page',\n            errnote='Unable to download login page')\n        lsd = self._search_regex(\n            r'<input type=\"hidden\" name=\"lsd\" value=\"([^\"]*)\"',\n            login_page, 'lsd')\n        lgnrnd = self._search_regex(r'name=\"lgnrnd\" value=\"([^\"]*?)\"', login_page, 'lgnrnd')\n\n        login_form = {\n            'email': useremail,\n            'pass': password,\n            'lsd': lsd,\n            'lgnrnd': lgnrnd,\n            'next': 'http://facebook.com/home.php',\n            'default_persistent': '0',\n            'legacy_return': '1',\n            'timezone': '-60',\n            'trynum': '1',\n            }\n        request = compat_urllib_request.Request(self._LOGIN_URL, urlencode_postdata(login_form))\n        request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        try:\n            login_results = self._download_webpage(request, None,\n                note='Logging in', errnote='unable to fetch login page')\n            if re.search(r'<form(.*)name=\"login\"(.*)</form>', login_results) is not None:\n                self._downloader.report_warning('unable to log in: bad username/password, or exceded login rate limit (~3/min). Check credentials or wait.')\n                return\n\n            check_form = {\n                'fb_dtsg': self._search_regex(r'name=\"fb_dtsg\" value=\"(.+?)\"', login_results, 'fb_dtsg'),\n                'h': self._search_regex(\n                    r'name=\"h\"\\s+(?:\\w+=\"[^\"]+\"\\s+)*?value=\"([^\"]+)\"', login_results, 'h'),\n                'name_action_selected': 'dont_save',\n            }\n            check_req = compat_urllib_request.Request(self._CHECKPOINT_URL, urlencode_postdata(check_form))\n            check_req.add_header('Content-Type', 'application/x-www-form-urlencoded')\n            check_response = self._download_webpage(check_req, None,\n                note='Confirming login')\n            if re.search(r'id=\"checkpointSubmitButton\"', check_response) is not None:\n                self._downloader.report_warning('Unable to confirm login, you have to login in your brower and authorize the login.')\n        except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:\n            self._downloader.report_warning('unable to log in: %s' % compat_str(err))\n            return",
        "begin_line": 45,
        "end_line": 94,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.facebook.FacebookIE._real_initialize#96",
        "src_path": "youtube_dl/extractor/facebook.py",
        "class_name": "youtube_dl.extractor.facebook.FacebookIE",
        "signature": "youtube_dl.extractor.facebook.FacebookIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 96,
        "end_line": 97,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.facebook.FacebookIE._real_extract#99",
        "src_path": "youtube_dl/extractor/facebook.py",
        "class_name": "youtube_dl.extractor.facebook.FacebookIE",
        "signature": "youtube_dl.extractor.facebook.FacebookIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        url = 'https://www.facebook.com/video/video.php?v=%s' % video_id\n        webpage = self._download_webpage(url, video_id)\n\n        BEFORE = '{swf.addParam(param[0], param[1]);});\\n'\n        AFTER = '.forEach(function(variable) {swf.addVariable(variable[0], variable[1]);});'\n        m = re.search(re.escape(BEFORE) + '(.*?)' + re.escape(AFTER), webpage)\n        if not m:\n            m_msg = re.search(r'class=\"[^\"]*uiInterstitialContent[^\"]*\"><div>(.*?)</div>', webpage)\n            if m_msg is not None:\n                raise ExtractorError(\n                    'The video is not available, Facebook said: \"%s\"' % m_msg.group(1),\n                    expected=True)\n            else:\n                raise ExtractorError('Cannot parse data')\n        data = dict(json.loads(m.group(1)))\n        params_raw = compat_urllib_parse.unquote(data['params'])\n        params = json.loads(params_raw)\n        video_data = params['video_data'][0]\n        video_url = video_data.get('hd_src')\n        if not video_url:\n            video_url = video_data['sd_src']\n        if not video_url:\n            raise ExtractorError('Cannot find video URL')\n\n        video_title = self._html_search_regex(\n            r'<h2 class=\"uiHeaderTitle\">([^<]*)</h2>', webpage, 'title',\n            fatal=False)\n        if not video_title:\n            video_title = self._html_search_regex(\n                r'(?s)<span class=\"fbPhotosPhotoCaption\".*?id=\"fbPhotoPageCaption\"><span class=\"hasCaption\">(.*?)</span>',\n                webpage, 'alternative title', default=None)\n            if len(video_title) > 80 + 3:\n                video_title = video_title[:80] + '...'\n        if not video_title:\n            video_title = 'Facebook video #%s' % video_id\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'url': video_url,\n            'duration': int(video_data['video_duration']),\n            'thumbnail': video_data['thumbnail_src'],\n        }",
        "begin_line": 99,
        "end_line": 145,
        "comment": "",
        "is_bug": true,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.ustream.UstreamIE._real_extract#26",
        "src_path": "youtube_dl/extractor/ustream.py",
        "class_name": "youtube_dl.extractor.ustream.UstreamIE",
        "signature": "youtube_dl.extractor.ustream.UstreamIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('videoID')\n\n        # some sites use this embed format (see: http://github.com/rg3/youtube-dl/issues/2990)\n        if m.group('type') == 'embed/recorded':\n            video_id = m.group('videoID')\n            desktop_url = 'http://www.ustream.tv/recorded/' + video_id\n            return self.url_result(desktop_url, 'Ustream')\n        if m.group('type') == 'embed':\n            video_id = m.group('videoID')\n            webpage = self._download_webpage(url, video_id)\n            desktop_video_id = self._html_search_regex(\n                r'ContentVideoIds=\\[\"([^\"]*?)\"\\]', webpage, 'desktop_video_id')\n            desktop_url = 'http://www.ustream.tv/recorded/' + desktop_video_id\n            return self.url_result(desktop_url, 'Ustream')\n\n        video_url = 'http://tcdn.ustream.tv/video/%s' % video_id\n        webpage = self._download_webpage(url, video_id)\n\n        self.report_extraction(video_id)\n\n        video_title = self._html_search_regex(r'data-title=\"(?P<title>.+)\"',\n            webpage, 'title')\n\n        uploader = self._html_search_regex(r'data-content-type=\"channel\".*?>(?P<uploader>.*?)</a>',\n            webpage, 'uploader', fatal=False, flags=re.DOTALL)\n\n        thumbnail = self._html_search_regex(r'<link rel=\"image_src\" href=\"(?P<thumb>.*?)\"',\n            webpage, 'thumbnail', fatal=False)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'ext': 'flv',\n            'title': video_title,\n            'uploader': uploader,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 26,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.ustream.UstreamChannelIE._real_extract#78",
        "src_path": "youtube_dl/extractor/ustream.py",
        "class_name": "youtube_dl.extractor.ustream.UstreamChannelIE",
        "signature": "youtube_dl.extractor.ustream.UstreamChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        display_id = m.group('slug')\n        webpage = self._download_webpage(url, display_id)\n        channel_id = get_meta_content('ustream:channel_id', webpage)\n\n        BASE = 'http://www.ustream.tv'\n        next_url = '/ajax/socialstream/videos/%s/1.json' % channel_id\n        video_ids = []\n        while next_url:\n            reply = self._download_json(\n                compat_urlparse.urljoin(BASE, next_url), display_id,\n                note='Downloading video information (next: %d)' % (len(video_ids) + 1))\n            video_ids.extend(re.findall(r'data-content-id=\"(\\d.*)\"', reply['data']))\n            next_url = reply['nextUrl']\n\n        entries = [\n            self.url_result('http://www.ustream.tv/recorded/' + vid, 'Ustream')\n            for vid in video_ids]\n        return {\n            '_type': 'playlist',\n            'id': channel_id,\n            'display_id': display_id,\n            'entries': entries,\n        }",
        "begin_line": 78,
        "end_line": 102,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.moevideo.MoeVideoIE._real_extract#57",
        "src_path": "youtube_dl/extractor/moevideo.py",
        "class_name": "youtube_dl.extractor.moevideo.MoeVideoIE",
        "signature": "youtube_dl.extractor.moevideo.MoeVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(\n            'http://%s/video/%s' % (mobj.group('host'), video_id),\n            video_id, 'Downloading webpage')\n\n        title = self._og_search_title(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n        description = self._og_search_description(webpage)\n\n        r = [\n            self._API_KEY,\n            [\n                'preview/flv_link',\n                {\n                    'uid': video_id,\n                },\n            ],\n        ]\n        r_json = json.dumps(r)\n        post = compat_urllib_parse.urlencode({'r': r_json})\n        req = compat_urllib_request.Request(self._API_URL, post)\n        req.add_header('Content-type', 'application/x-www-form-urlencoded')\n\n        response = self._download_json(req, video_id)\n        if response['status'] != 'OK':\n            raise ExtractorError(\n                '%s returned error: %s' % (self.IE_NAME, response['data']),\n                expected=True\n            )\n        item = response['data'][0]\n        video_url = item['link']\n        duration = int_or_none(item['length'])\n        width = int_or_none(item['width'])\n        height = int_or_none(item['height'])\n        filesize = int_or_none(item['convert_size'])\n\n        formats = [{\n            'format_id': 'sd',\n            'http_headers': {'Range': 'bytes=0-'},  # Required to download\n            'url': video_url,\n            'width': width,\n            'height': height,\n            'filesize': filesize,\n        }]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'description': description,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 57,
        "end_line": 112,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.breakcom.BreakIE._real_extract#21",
        "src_path": "youtube_dl/extractor/breakcom.py",
        "class_name": "youtube_dl.extractor.breakcom.BreakIE",
        "signature": "youtube_dl.extractor.breakcom.BreakIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group(1).split(\"-\")[-1]\n        embed_url = 'http://www.break.com/embed/%s' % video_id\n        webpage = self._download_webpage(embed_url, video_id)\n        info_json = self._search_regex(r'var embedVars = ({.*})\\s*?</script>',\n            webpage, 'info json', flags=re.DOTALL)\n        info = json.loads(info_json)\n        video_url = info['videoUri']\n        youtube_id = info.get('youtubeId')\n        if youtube_id:\n            return self.url_result(youtube_id, 'Youtube')\n\n        final_url = video_url + '?' + info['AuthToken']\n        return {\n            'id': video_id,\n            'url': final_url,\n            'title': info['contentName'],\n            'thumbnail': info['thumbUri'],\n        }",
        "begin_line": 21,
        "end_line": 40,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.ign.IGNIE._find_video_id#72",
        "src_path": "youtube_dl/extractor/ign.py",
        "class_name": "youtube_dl.extractor.ign.IGNIE",
        "signature": "youtube_dl.extractor.ign.IGNIE._find_video_id(self, webpage)",
        "snippet": "    def _find_video_id(self, webpage):\n        res_id = [\n            r'data-video-id=\"(.+?)\"',\n            r'<object id=\"vid_(.+?)\"',\n            r'<meta name=\"og:image\" content=\".*/(.+?)-(.+?)/.+.jpg\"',\n            r'class=\"hero-poster[^\"]*?\"[^>]*id=\"(.+?)\"',\n        ]\n        return self._search_regex(res_id, webpage, 'video id')",
        "begin_line": 72,
        "end_line": 79,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007692307692307692,
            "pseudo_dstar_susp": 0.0006273525721455458,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006273525721455458,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.ign.IGNIE._real_extract#81",
        "src_path": "youtube_dl/extractor/ign.py",
        "class_name": "youtube_dl.extractor.ign.IGNIE",
        "signature": "youtube_dl.extractor.ign.IGNIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        name_or_id = mobj.group('name_or_id')\n        page_type = mobj.group('type')\n        webpage = self._download_webpage(url, name_or_id)\n        if page_type != 'video':\n            multiple_urls = re.findall(\n                '<param name=\"flashvars\" value=\"[^\"]*?url=(https?://www\\.ign\\.com/videos/.*?)[\"&]',\n                webpage)\n            if multiple_urls:\n                return [self.url_result(u, ie='IGN') for u in multiple_urls]\n\n        video_id = self._find_video_id(webpage)\n        result = self._get_video_info(video_id)\n        description = self._html_search_regex(self._DESCRIPTION_RE,\n            webpage, 'video description', flags=re.DOTALL)\n        result['description'] = description\n        return result",
        "begin_line": 81,
        "end_line": 98,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009000900090009,
            "pseudo_dstar_susp": 0.0006983240223463687,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006983240223463687,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.ign.IGNIE._get_video_info#100",
        "src_path": "youtube_dl/extractor/ign.py",
        "class_name": "youtube_dl.extractor.ign.IGNIE",
        "signature": "youtube_dl.extractor.ign.IGNIE._get_video_info(self, video_id)",
        "snippet": "    def _get_video_info(self, video_id):\n        config_url = self._CONFIG_URL_TEMPLATE % video_id\n        config = self._download_json(config_url, video_id)\n        media = config['playlist']['media']\n\n        return {\n            'id': media['metadata']['videoId'],\n            'url': media['url'],\n            'title': media['metadata']['title'],\n            'thumbnail': media['poster'][0]['url'].replace('{size}', 'grande'),\n        }",
        "begin_line": 100,
        "end_line": 110,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.ign.OneUPIE._real_extract#130",
        "src_path": "youtube_dl/extractor/ign.py",
        "class_name": "youtube_dl.extractor.ign.OneUPIE",
        "signature": "youtube_dl.extractor.ign.OneUPIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        result = super(OneUPIE, self)._real_extract(url)\n        result['id'] = mobj.group('name_or_id')\n        return result",
        "begin_line": 130,
        "end_line": 134,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.stanfordoc.StanfordOpenClassroomIE._real_extract#24",
        "src_path": "youtube_dl/extractor/stanfordoc.py",
        "class_name": "youtube_dl.extractor.stanfordoc.StanfordOpenClassroomIE",
        "signature": "youtube_dl.extractor.stanfordoc.StanfordOpenClassroomIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        if mobj is None:\n            raise ExtractorError(u'Invalid URL: %s' % url)\n\n        if mobj.group('course') and mobj.group('video'): # A specific video\n            course = mobj.group('course')\n            video = mobj.group('video')\n            info = {\n                'id': course + '_' + video,\n                'uploader': None,\n                'upload_date': None,\n            }\n\n            self.report_extraction(info['id'])\n            baseUrl = 'http://openclassroom.stanford.edu/MainFolder/courses/' + course + '/videos/'\n            xmlUrl = baseUrl + video + '.xml'\n            mdoc = self._download_xml(xmlUrl, info['id'])\n            try:\n                info['title'] = mdoc.findall('./title')[0].text\n                info['url'] = baseUrl + mdoc.findall('./videoFile')[0].text\n            except IndexError:\n                raise ExtractorError(u'Invalid metadata XML file')\n            info['ext'] = info['url'].rpartition('.')[2]\n            return [info]\n        elif mobj.group('course'): # A course page\n            course = mobj.group('course')\n            info = {\n                'id': course,\n                'type': 'playlist',\n                'uploader': None,\n                'upload_date': None,\n            }\n\n            coursepage = self._download_webpage(url, info['id'],\n                                        note='Downloading course info page',\n                                        errnote='Unable to download course info page')\n\n            info['title'] = self._html_search_regex('<h1>([^<]+)</h1>', coursepage, 'title', default=info['id'])\n\n            info['description'] = self._html_search_regex('<description>([^<]+)</description>',\n                coursepage, u'description', fatal=False)\n\n            links = orderedSet(re.findall('<a href=\"(VideoPage.php\\?[^\"]+)\">', coursepage))\n            info['list'] = [\n                {\n                    'type': 'reference',\n                    'url': 'http://openclassroom.stanford.edu/MainFolder/' + unescapeHTML(vpage),\n                }\n                    for vpage in links]\n            results = []\n            for entry in info['list']:\n                assert entry['type'] == 'reference'\n                results += self.extract(entry['url'])\n            return results\n        else: # Root page\n            info = {\n                'id': 'Stanford OpenClassroom',\n                'type': 'playlist',\n                'uploader': None,\n                'upload_date': None,\n            }\n\n            rootURL = 'http://openclassroom.stanford.edu/MainFolder/HomePage.php'\n            rootpage = self._download_webpage(rootURL, info['id'],\n                errnote=u'Unable to download course info page')\n\n            info['title'] = info['id']\n\n            links = orderedSet(re.findall('<a href=\"(CoursePage.php\\?[^\"]+)\">', rootpage))\n            info['list'] = [\n                {\n                    'type': 'reference',\n                    'url': 'http://openclassroom.stanford.edu/MainFolder/' + unescapeHTML(cpage),\n                }\n                    for cpage in links]\n\n            results = []\n            for entry in info['list']:\n                assert entry['type'] == 'reference'\n                results += self.extract(entry['url'])\n            return results",
        "begin_line": 24,
        "end_line": 105,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.gdcvault.GDCVaultIE._parse_mp4#46",
        "src_path": "youtube_dl/extractor/gdcvault.py",
        "class_name": "youtube_dl.extractor.gdcvault.GDCVaultIE",
        "signature": "youtube_dl.extractor.gdcvault.GDCVaultIE._parse_mp4(self, xml_description)",
        "snippet": "    def _parse_mp4(self, xml_description):\n        video_formats = []\n        mp4_video = xml_description.find('./metadata/mp4video')\n        if mp4_video is None:\n            return None\n\n        mobj = re.match(r'(?P<root>https?://.*?/).*', mp4_video.text)\n        video_root = mobj.group('root')\n        formats = xml_description.findall('./metadata/MBRVideos/MBRVideo')\n        for format in formats:\n            mobj = re.match(r'mp4\\:(?P<path>.*)', format.find('streamName').text)\n            url = video_root + mobj.group('path')\n            vbr = format.find('bitrate').text\n            video_formats.append({\n                'url': url,\n                'vbr': int(vbr),\n            })\n        return video_formats",
        "begin_line": 46,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.gdcvault.GDCVaultIE._parse_flv#65",
        "src_path": "youtube_dl/extractor/gdcvault.py",
        "class_name": "youtube_dl.extractor.gdcvault.GDCVaultIE",
        "signature": "youtube_dl.extractor.gdcvault.GDCVaultIE._parse_flv(self, xml_description)",
        "snippet": "    def _parse_flv(self, xml_description):\n        video_formats = []\n        akami_url = xml_description.find('./metadata/akamaiHost').text\n        slide_video_path = xml_description.find('./metadata/slideVideo').text\n        video_formats.append({\n            'url': 'rtmp://' + akami_url + '/' + slide_video_path,\n            'format_note': 'slide deck video',\n            'quality': -2,\n            'preference': -2,\n            'format_id': 'slides',\n        })\n        speaker_video_path = xml_description.find('./metadata/speakerVideo').text\n        video_formats.append({\n            'url': 'rtmp://' + akami_url + '/' + speaker_video_path,\n            'format_note': 'speaker video',\n            'quality': -1,\n            'preference': -1,\n            'format_id': 'speaker',\n        })\n        return video_formats",
        "begin_line": 65,
        "end_line": 84,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.gdcvault.GDCVaultIE._login#86",
        "src_path": "youtube_dl/extractor/gdcvault.py",
        "class_name": "youtube_dl.extractor.gdcvault.GDCVaultIE",
        "signature": "youtube_dl.extractor.gdcvault.GDCVaultIE._login(self, webpage_url, video_id)",
        "snippet": "    def _login(self, webpage_url, video_id):\n        (username, password) = self._get_login_info()\n        if username is None or password is None:\n            self.report_warning('It looks like ' + webpage_url + ' requires a login. Try specifying a username and password and try again.')\n            return None\n\n        mobj = re.match(r'(?P<root_url>https?://.*?/).*', webpage_url)\n        login_url = mobj.group('root_url') + 'api/login.php'\n        logout_url = mobj.group('root_url') + 'logout'\n\n        login_form = {\n            'email': username,\n            'password': password,\n        }\n\n        request = compat_urllib_request.Request(login_url, compat_urllib_parse.urlencode(login_form))\n        request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        self._download_webpage(request, video_id, 'Logging in')\n        start_page = self._download_webpage(webpage_url, video_id, 'Getting authenticated video page')\n        self._download_webpage(logout_url, video_id, 'Logging out')\n\n        return start_page",
        "begin_line": 86,
        "end_line": 107,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007692307692307692,
            "pseudo_dstar_susp": 0.0006273525721455458,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006273525721455458,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.gdcvault.GDCVaultIE._real_extract#109",
        "src_path": "youtube_dl/extractor/gdcvault.py",
        "class_name": "youtube_dl.extractor.gdcvault.GDCVaultIE",
        "signature": "youtube_dl.extractor.gdcvault.GDCVaultIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n        webpage_url = 'http://www.gdcvault.com/play/' + video_id\n        start_page = self._download_webpage(webpage_url, video_id)\n\n        direct_url = self._search_regex(\n            r's1\\.addVariable\\(\"file\",\\s*encodeURIComponent\\(\"(/[^\"]+)\"\\)\\);',\n            start_page, 'url', default=None)\n        if direct_url:\n            video_url = 'http://www.gdcvault.com/' + direct_url\n            title = self._html_search_regex(\n                r'<td><strong>Session Name</strong></td>\\s*<td>(.*?)</td>',\n                start_page, 'title')\n\n            return {\n                'id': video_id,\n                'url': video_url,\n                'ext': 'flv',\n                'title': title,\n            }\n\n        xml_root = self._html_search_regex(\n            r'<iframe src=\"(?P<xml_root>.*?)player.html.*?\".*?</iframe>',\n            start_page, 'xml root', default=None)\n        if xml_root is None:\n            # Probably need to authenticate\n            login_res = self._login(webpage_url, video_id)\n            if login_res is None:\n                self.report_warning('Could not login.')\n            else:\n                start_page = login_res\n                # Grab the url from the authenticated page\n                xml_root = self._html_search_regex(\n                    r'<iframe src=\"(.*?)player.html.*?\".*?</iframe>',\n                    start_page, 'xml root')\n\n        xml_name = self._html_search_regex(\n            r'<iframe src=\".*?\\?xml=(.+?\\.xml).*?\".*?</iframe>',\n            start_page, 'xml filename', default=None)\n        if xml_name is None:\n            # Fallback to the older format\n            xml_name = self._html_search_regex(r'<iframe src=\".*?\\?xmlURL=xml/(?P<xml_file>.+?\\.xml).*?\".*?</iframe>', start_page, 'xml filename')\n\n        xml_decription_url = xml_root + 'xml/' + xml_name\n        xml_description = self._download_xml(xml_decription_url, video_id)\n\n        video_title = xml_description.find('./metadata/title').text\n        video_formats = self._parse_mp4(xml_description)\n        if video_formats is None:\n            video_formats = self._parse_flv(xml_description)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'formats': video_formats,\n        }",
        "begin_line": 109,
        "end_line": 166,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007692307692307692,
            "pseudo_dstar_susp": 0.0006273525721455458,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006273525721455458,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.rai.RaiIE._real_extract#65",
        "src_path": "youtube_dl/extractor/rai.py",
        "class_name": "youtube_dl.extractor.rai.RaiIE",
        "signature": "youtube_dl.extractor.rai.RaiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        media = self._download_json('%s?json' % mobj.group('url'), video_id, 'Downloading video JSON')\n\n        title = media.get('name')\n        description = media.get('desc')\n        thumbnail = media.get('image_300') or media.get('image_medium') or media.get('image')\n        duration = parse_duration(media.get('length'))\n        uploader = media.get('author')\n        upload_date = unified_strdate(media.get('date'))\n\n        formats = []\n\n        for format_id in ['wmv', 'm3u8', 'mediaUri', 'h264']:\n            media_url = media.get(format_id)\n            if not media_url:\n                continue\n            formats.append({\n                'url': media_url,\n                'format_id': format_id,\n                'ext': 'mp4',\n            })\n\n        if self._downloader.params.get('listsubtitles', False):\n            page = self._download_webpage(url, video_id)\n            self._list_available_subtitles(video_id, page)\n            return\n\n        subtitles = {}\n        if self._have_to_download_any_subtitles:\n            page = self._download_webpage(url, video_id)\n            subtitles = self.extract_subtitles(video_id, page)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'upload_date': upload_date,\n            'duration': duration,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 65,
        "end_line": 110,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.rai.RaiIE._get_available_subtitles#112",
        "src_path": "youtube_dl/extractor/rai.py",
        "class_name": "youtube_dl.extractor.rai.RaiIE",
        "signature": "youtube_dl.extractor.rai.RaiIE._get_available_subtitles(self, video_id, webpage)",
        "snippet": "    def _get_available_subtitles(self, video_id, webpage):\n        subtitles = {}\n        m = re.search(r'<meta name=\"closedcaption\" content=\"(?P<captions>[^\"]+)\"', webpage)\n        if m:\n            captions = m.group('captions')\n            STL_EXT = '.stl'\n            SRT_EXT = '.srt'\n            if captions.endswith(STL_EXT):\n                captions = captions[:-len(STL_EXT)] + SRT_EXT\n            subtitles['it'] = 'http://www.rai.tv%s' % compat_urllib_parse.quote(captions)\n        return subtitles",
        "begin_line": 112,
        "end_line": 122,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.sina.SinaIE.suitable#43",
        "src_path": "youtube_dl/extractor/sina.py",
        "class_name": "youtube_dl.extractor.sina.SinaIE",
        "signature": "youtube_dl.extractor.sina.SinaIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return re.match(cls._VALID_URL, url, flags=re.VERBOSE) is not None",
        "begin_line": 43,
        "end_line": 44,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0034965034965034965,
            "pseudo_dstar_susp": 0.003484320557491289,
            "pseudo_tarantula_susp": 0.0003031221582297666,
            "pseudo_op2_susp": 0.003484320557491289,
            "pseudo_barinel_susp": 0.0003031221582297666
        }
    },
    {
        "name": "youtube_dl.extractor.sina.SinaIE._extract_video#46",
        "src_path": "youtube_dl/extractor/sina.py",
        "class_name": "youtube_dl.extractor.sina.SinaIE",
        "signature": "youtube_dl.extractor.sina.SinaIE._extract_video(self, video_id)",
        "snippet": "    def _extract_video(self, video_id):\n        data = compat_urllib_parse.urlencode({'vid': video_id})\n        url_doc = self._download_xml('http://v.iask.com/v_play.php?%s' % data,\n            video_id, 'Downloading video url')\n        image_page = self._download_webpage(\n            'http://interface.video.sina.com.cn/interface/common/getVideoImage.php?%s' % data,\n            video_id, 'Downloading thumbnail info')\n\n        return {'id': video_id,\n                'url': url_doc.find('./durl/url').text,\n                'ext': 'flv',\n                'title': url_doc.find('./vname').text,\n                'thumbnail': image_page.split('=')[1],\n                }",
        "begin_line": 46,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.0001840942562592047,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.sina.SinaIE._real_extract#61",
        "src_path": "youtube_dl/extractor/sina.py",
        "class_name": "youtube_dl.extractor.sina.SinaIE",
        "signature": "youtube_dl.extractor.sina.SinaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url, flags=re.VERBOSE)\n        video_id = mobj.group('id')\n        if mobj.group('token') is not None:\n            # The video id is in the redirected url\n            self.to_screen('Getting video id')\n            request = compat_urllib_request.Request(url)\n            request.get_method = lambda: 'HEAD'\n            (_, urlh) = self._download_webpage_handle(request, 'NA', False)\n            return self._real_extract(urlh.geturl())\n        elif video_id is None:\n            pseudo_id = mobj.group('pseudo_id')\n            webpage = self._download_webpage(url, pseudo_id)\n            video_id = self._search_regex(r'vid:\\'(\\d+?)\\'', webpage, 'video id')\n\n        return self._extract_video(video_id)",
        "begin_line": 61,
        "end_line": 76,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.0001840942562592047,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.nosvideo.NosVideoIE._real_extract#34",
        "src_path": "youtube_dl/extractor/nosvideo.py",
        "class_name": "youtube_dl.extractor.nosvideo.NosVideoIE",
        "signature": "youtube_dl.extractor.nosvideo.NosVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        fields = {\n            'id': video_id,\n            'op': 'download1',\n            'method_free': 'Continue to Video',\n        }\n        req = compat_urllib_request.Request(url, urlencode_postdata(fields))\n        req.add_header('Content-type', 'application/x-www-form-urlencoded')\n        webpage = self._download_webpage(req, video_id,\n                                         'Downloading download page')\n        if re.search(self._FILE_DELETED_REGEX, webpage) is not None:\n            raise ExtractorError('Video %s does not exist' % video_id,\n                                 expected=True)\n\n        xml_id = self._search_regex(r'php\\|([^\\|]+)\\|', webpage, 'XML ID')\n        playlist_url = self._PLAYLIST_URL.format(xml_id=xml_id)\n        playlist = self._download_xml(playlist_url, video_id)\n\n        track = playlist.find(_x('.//xspf:track'))\n        title = _find(track, './xspf:title')\n        url = _find(track, './xspf:file')\n        thumbnail = _find(track, './xspf:image')\n\n        formats = [{\n            'format_id': 'sd',\n            'url': url,\n        }]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 34,
        "end_line": 70,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.bandcamp.BandcampIE._real_extract#27",
        "src_path": "youtube_dl/extractor/bandcamp.py",
        "class_name": "youtube_dl.extractor.bandcamp.BandcampIE",
        "signature": "youtube_dl.extractor.bandcamp.BandcampIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        title = mobj.group('title')\n        webpage = self._download_webpage(url, title)\n        m_download = re.search(r'freeDownloadPage: \"(.*?)\"', webpage)\n        if not m_download:\n            m_trackinfo = re.search(r'trackinfo: (.+),\\s*?\\n', webpage)\n            if m_trackinfo:\n                json_code = m_trackinfo.group(1)\n                data = json.loads(json_code)[0]\n\n                formats = []\n                for format_id, format_url in data['file'].items():\n                    ext, abr_str = format_id.split('-', 1)\n                    formats.append({\n                        'format_id': format_id,\n                        'url': format_url,\n                        'ext': ext,\n                        'vcodec': 'none',\n                        'acodec': ext,\n                        'abr': int(abr_str),\n                    })\n\n                self._sort_formats(formats)\n\n                return {\n                    'id': compat_str(data['id']),\n                    'title': data['title'],\n                    'formats': formats,\n                    'duration': float(data['duration']),\n                }\n            else:\n                raise ExtractorError('No free songs found')\n\n        download_link = m_download.group(1)\n        video_id = re.search(\n            r'var TralbumData = {(.*?)id: (?P<id>\\d*?)$',\n            webpage, re.MULTILINE | re.DOTALL).group('id')\n\n        download_webpage = self._download_webpage(download_link, video_id, 'Downloading free downloads page')\n        # We get the dictionary of the track from some javascript code\n        info = re.search(r'items: (.*?),$', download_webpage, re.MULTILINE).group(1)\n        info = json.loads(info)[0]\n        # We pick mp3-320 for now, until format selection can be easily implemented.\n        mp3_info = info['downloads']['mp3-320']\n        # If we try to use this url it says the link has expired\n        initial_url = mp3_info['url']\n        re_url = r'(?P<server>http://(.*?)\\.bandcamp\\.com)/download/track\\?enc=mp3-320&fsig=(?P<fsig>.*?)&id=(?P<id>.*?)&ts=(?P<ts>.*)$'\n        m_url = re.match(re_url, initial_url)\n        #We build the url we will use to get the final track url\n        # This url is build in Bandcamp in the script download_bunde_*.js\n        request_url = '%s/statdownload/track?enc=mp3-320&fsig=%s&id=%s&ts=%s&.rand=665028774616&.vrs=1' % (m_url.group('server'), m_url.group('fsig'), video_id, m_url.group('ts'))\n        final_url_webpage = self._download_webpage(request_url, video_id, 'Requesting download url')\n        # If we could correctly generate the .rand field the url would be\n        #in the \"download_url\" key\n        final_url = re.search(r'\"retry_url\":\"(.*?)\"', final_url_webpage).group(1)\n\n        return {\n            'id': video_id,\n            'title': info['title'],\n            'ext': 'mp3',\n            'vcodec': 'none',\n            'url': final_url,\n            'thumbnail': info.get('thumb_url'),\n            'uploader': info.get('artist'),\n        }",
        "begin_line": 27,
        "end_line": 92,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.bandcamp.BandcampAlbumIE._real_extract#129",
        "src_path": "youtube_dl/extractor/bandcamp.py",
        "class_name": "youtube_dl.extractor.bandcamp.BandcampAlbumIE",
        "signature": "youtube_dl.extractor.bandcamp.BandcampAlbumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('subdomain')\n        title = mobj.group('title')\n        display_id = title or playlist_id\n        webpage = self._download_webpage(url, display_id)\n        tracks_paths = re.findall(r'<a href=\"(.*?)\" itemprop=\"url\">', webpage)\n        if not tracks_paths:\n            raise ExtractorError('The page doesn\\'t contain any tracks')\n        entries = [\n            self.url_result(compat_urlparse.urljoin(url, t_path), ie=BandcampIE.ie_key())\n            for t_path in tracks_paths]\n        title = self._search_regex(r'album_title : \"(.*?)\"', webpage, 'title')\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'display_id': display_id,\n            'title': title,\n            'entries': entries,\n        }",
        "begin_line": 129,
        "end_line": 148,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.ninegag.NineGagIE._real_extract#42",
        "src_path": "youtube_dl/extractor/ninegag.py",
        "class_name": "youtube_dl.extractor.ninegag.NineGagIE",
        "signature": "youtube_dl.extractor.ninegag.NineGagIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('numid') or mobj.group('id')\n        display_id = mobj.group('display_id') or video_id\n\n        webpage = self._download_webpage(url, display_id)\n\n        post_view = json.loads(self._html_search_regex(\n            r'var postView = new app\\.PostView\\({\\s*post:\\s*({.+?}),\\s*posts:\\s*prefetchedCurrentPost', webpage, 'post view'))\n\n        youtube_id = post_view['videoExternalId']\n        title = post_view['title']\n        description = post_view['description']\n        view_count = str_to_int(post_view['externalView'])\n        thumbnail = post_view.get('thumbnail_700w') or post_view.get('ogImageUrl') or post_view.get('thumbnail_300w')\n\n        return {\n            '_type': 'url_transparent',\n            'url': youtube_id,\n            'ie_key': 'Youtube',\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'view_count': view_count,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 42,
        "end_line": 68,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.gamestar.GameStarIE._real_extract#31",
        "src_path": "youtube_dl/extractor/gamestar.py",
        "class_name": "youtube_dl.extractor.gamestar.GameStarIE",
        "signature": "youtube_dl.extractor.gamestar.GameStarIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        og_title = self._og_search_title(webpage)\n        title = og_title.replace(' - Video bei GameStar.de', '').strip()\n\n        url = 'http://gamestar.de/_misc/videos/portal/getVideoUrl.cfm?premium=0&videoId=' + video_id\n\n        description = self._og_search_description(webpage).strip()\n\n        thumbnail = self._proto_relative_url(\n            self._og_search_thumbnail(webpage), scheme='http:')\n\n        upload_date = unified_strdate(self._html_search_regex(\n            r'<span style=\"float:left;font-size:11px;\">Datum: ([0-9]+\\.[0-9]+\\.[0-9]+)&nbsp;&nbsp;',\n            webpage, 'upload_date', fatal=False))\n\n        duration = parse_duration(self._html_search_regex(\n            r'&nbsp;&nbsp;L\u00e4nge: ([0-9]+:[0-9]+)</span>', webpage, 'duration',\n            fatal=False))\n\n        view_count = str_to_int(self._html_search_regex(\n            r'&nbsp;&nbsp;Zuschauer: ([0-9\\.]+)&nbsp;&nbsp;', webpage,\n            'view_count', fatal=False))\n\n        comment_count = int_or_none(self._html_search_regex(\n            r'>Kommentieren \\(([0-9]+)\\)</a>', webpage, 'comment_count',\n            fatal=False))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': url,\n            'ext': 'mp4',\n            'thumbnail': thumbnail,\n            'description': description,\n            'upload_date': upload_date,\n            'duration': duration,\n            'view_count': view_count,\n            'comment_count': comment_count\n        }",
        "begin_line": 31,
        "end_line": 74,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.promptfile.PromptFileIE._real_extract#29",
        "src_path": "youtube_dl/extractor/promptfile.py",
        "class_name": "youtube_dl.extractor.promptfile.PromptFileIE",
        "signature": "youtube_dl.extractor.promptfile.PromptFileIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n\n        if re.search(self._FILE_NOT_FOUND_REGEX, webpage) is not None:\n            raise ExtractorError('Video %s does not exist' % video_id,\n                                 expected=True)\n\n        fields = dict(re.findall(r'''(?x)type=\"hidden\"\\s+\n            name=\"(.+?)\"\\s+\n            value=\"(.*?)\"\n            ''', webpage))\n        post = compat_urllib_parse.urlencode(fields)\n        req = compat_urllib_request.Request(url, post)\n        req.add_header('Content-type', 'application/x-www-form-urlencoded')\n        webpage = self._download_webpage(\n            req, video_id, 'Downloading video page')\n\n        url = self._html_search_regex(r'url:\\s*\\'([^\\']+)\\'', webpage, 'URL')\n        title = self._html_search_regex(\n            r'<span.+title=\"([^\"]+)\">', webpage, 'title')\n        thumbnail = self._html_search_regex(\n            r'<div id=\"player_overlay\">.*button>.*?<img src=\"([^\"]+)\"',\n            webpage, 'thumbnail', fatal=False, flags=re.DOTALL)\n\n        formats = [{\n            'format_id': 'sd',\n            'url': url,\n            'ext': determine_ext(title),\n        }]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 29,
        "end_line": 67,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.macgamestore.MacGameStoreIE._real_extract#23",
        "src_path": "youtube_dl/extractor/macgamestore.py",
        "class_name": "youtube_dl.extractor.macgamestore.MacGameStoreIE",
        "signature": "youtube_dl.extractor.macgamestore.MacGameStoreIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id, 'Downloading trailer page')\n\n        if re.search(r'>Missing Media<', webpage) is not None:\n            raise ExtractorError('Trailer %s does not exist' % video_id, expected=True)\n\n        video_title = self._html_search_regex(\n            r'<title>MacGameStore: (.*?) Trailer</title>', webpage, 'title')\n\n        video_url = self._html_search_regex(\n            r'(?s)<div\\s+id=\"video-player\".*?href=\"([^\"]+)\"\\s*>',\n            webpage, 'video URL')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': video_title\n        }",
        "begin_line": 23,
        "end_line": 43,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.syfy.SyfyIE._real_extract#34",
        "src_path": "youtube_dl/extractor/syfy.py",
        "class_name": "youtube_dl.extractor.syfy.SyfyIE",
        "signature": "youtube_dl.extractor.syfy.SyfyIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_name = mobj.group('video_name')\n        if video_name:\n            generic_webpage = self._download_webpage(url, video_name)\n            video_id = self._search_regex(\n                r'<iframe.*?class=\"video_iframe_page\"\\s+src=\"/_utils/video/thP_video_controller.php.*?_vid([0-9]+)\">',\n                generic_webpage, 'video ID')\n            url = 'http://www.syfy.com/videos/%s/%s/vid:%s' % (\n                video_name, video_name, video_id)\n        else:\n            video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        return self.url_result(self._og_search_video_url(webpage))",
        "begin_line": 34,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.videolecturesnet.VideoLecturesNetIE._real_extract#31",
        "src_path": "youtube_dl/extractor/videolecturesnet.py",
        "class_name": "youtube_dl.extractor.videolecturesnet.VideoLecturesNetIE",
        "signature": "youtube_dl.extractor.videolecturesnet.VideoLecturesNetIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        smil_url = 'http://videolectures.net/%s/video/1/smil.xml' % video_id\n        smil = self._download_xml(smil_url, video_id)\n\n        title = find_xpath_attr(smil, './/meta', 'name', 'title').attrib['content']\n        description_el = find_xpath_attr(smil, './/meta', 'name', 'abstract')\n        description = (\n            None if description_el is None\n            else description_el.attrib['content'])\n        upload_date = unified_strdate(\n            find_xpath_attr(smil, './/meta', 'name', 'date').attrib['content'])\n\n        switch = smil.find('.//switch')\n        duration = parse_duration(switch.attrib.get('dur'))\n        thumbnail_el = find_xpath_attr(switch, './image', 'type', 'thumbnail')\n        thumbnail = (\n            None if thumbnail_el is None else thumbnail_el.attrib.get('src'))\n\n        formats = [{\n            'url': v.attrib['src'],\n            'width': int_or_none(v.attrib.get('width')),\n            'height': int_or_none(v.attrib.get('height')),\n            'filesize': int_or_none(v.attrib.get('size')),\n            'tbr': int_or_none(v.attrib.get('systemBitrate')) / 1000.0,\n            'ext': v.attrib.get('ext'),\n        } for v in switch.findall('./video')\n            if v.attrib.get('proto') == 'http']\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'upload_date': upload_date,\n            'duration': duration,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 31,
        "end_line": 70,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.playvid.PlayvidIE._real_extract#25",
        "src_path": "youtube_dl/extractor/playvid.py",
        "class_name": "youtube_dl.extractor.playvid.PlayvidIE",
        "signature": "youtube_dl.extractor.playvid.PlayvidIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_title = None\n        duration = None\n        video_thumbnail = None\n        formats = []\n\n        # most of the information is stored in the flashvars\n        flashvars = self._html_search_regex(\n            r'flashvars=\"(.+?)\"', webpage, 'flashvars')\n\n        infos = compat_urllib_parse.unquote(flashvars).split(r'&')\n        for info in infos:\n            videovars_match = re.match(r'^video_vars\\[(.+?)\\]=(.+?)$', info)\n            if videovars_match:\n                key = videovars_match.group(1)\n                val = videovars_match.group(2)\n\n                if key == 'title':\n                    video_title = compat_urllib_parse.unquote_plus(val)\n                if key == 'duration':\n                    try:\n                        duration = int(val)\n                    except ValueError:\n                        pass\n                if key == 'big_thumb':\n                    video_thumbnail = val\n\n                videourl_match = re.match(\n                    r'^video_urls\\]\\[(?P<resolution>[0-9]+)p', key)\n                if videourl_match:\n                    height = int(videourl_match.group('resolution'))\n                    formats.append({\n                        'height': height,\n                        'url': val,\n                    })\n        self._sort_formats(formats)\n\n        # Extract title - should be in the flashvars; if not, look elsewhere\n        if video_title is None:\n            video_title = self._html_search_regex(\n                r'<title>(.*?)</title', webpage, 'title')\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': video_title,\n            'thumbnail': video_thumbnail,\n            'duration': duration,\n            'description': None,\n            'age_limit': 18\n        }",
        "begin_line": 25,
        "end_line": 80,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.streamcloud.StreamcloudIE._real_extract#29",
        "src_path": "youtube_dl/extractor/streamcloud.py",
        "class_name": "youtube_dl.extractor.streamcloud.StreamcloudIE",
        "signature": "youtube_dl.extractor.streamcloud.StreamcloudIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        orig_webpage = self._download_webpage(url, video_id)\n\n        fields = re.findall(r'''(?x)<input\\s+\n            type=\"(?:hidden|submit)\"\\s+\n            name=\"([^\"]+)\"\\s+\n            (?:id=\"[^\"]+\"\\s+)?\n            value=\"([^\"]*)\"\n            ''', orig_webpage)\n        post = compat_urllib_parse.urlencode(fields)\n\n        self.to_screen('%s: Waiting for timeout' % video_id)\n        time.sleep(12)\n        headers = {\n            b'Content-Type': b'application/x-www-form-urlencoded',\n        }\n        req = compat_urllib_request.Request(url, post, headers)\n\n        webpage = self._download_webpage(\n            req, video_id, note='Downloading video page ...')\n        title = self._html_search_regex(\n            r'<h1[^>]*>([^<]+)<', webpage, 'title')\n        video_url = self._search_regex(\n            r'file:\\s*\"([^\"]+)\"', webpage, 'video URL')\n        thumbnail = self._search_regex(\n            r'image:\\s*\"([^\"]+)\"', webpage, 'thumbnail URL', fatal=False)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 29,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.everyonesmixtape.EveryonesMixtapeIE._real_extract#38",
        "src_path": "youtube_dl/extractor/everyonesmixtape.py",
        "class_name": "youtube_dl.extractor.everyonesmixtape.EveryonesMixtapeIE",
        "signature": "youtube_dl.extractor.everyonesmixtape.EveryonesMixtapeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('id')\n\n        pllist_url = 'http://everyonesmixtape.com/mixtape.php?a=getMixes&u=-1&linked=%s&explore=' % playlist_id\n        pllist_req = compat_urllib_request.Request(pllist_url)\n        pllist_req.add_header('X-Requested-With', 'XMLHttpRequest')\n\n        playlist_list = self._download_json(\n            pllist_req, playlist_id, note='Downloading playlist metadata')\n        try:\n            playlist_no = next(playlist['id']\n                               for playlist in playlist_list\n                               if playlist['code'] == playlist_id)\n        except StopIteration:\n            raise ExtractorError('Playlist id not found')\n\n        pl_url = 'http://everyonesmixtape.com/mixtape.php?a=getMix&id=%s&userId=null&code=' % playlist_no\n        pl_req = compat_urllib_request.Request(pl_url)\n        pl_req.add_header('X-Requested-With', 'XMLHttpRequest')\n        playlist = self._download_json(\n            pl_req, playlist_id, note='Downloading playlist info')\n\n        entries = [{\n            '_type': 'url',\n            'url': t['url'],\n            'title': t['title'],\n        } for t in playlist['tracks']]\n\n        if mobj.group('songnr'):\n            songnr = int(mobj.group('songnr')) - 1\n            return entries[songnr]\n\n        playlist_title = playlist['mixData']['name']\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'title': playlist_title,\n            'entries': entries,\n        }",
        "begin_line": 38,
        "end_line": 77,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.youporn.YouPornIE._real_extract#37",
        "src_path": "youtube_dl/extractor/youporn.py",
        "class_name": "youtube_dl.extractor.youporn.YouPornIE",
        "signature": "youtube_dl.extractor.youporn.YouPornIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n        url = mobj.group('proto') + 'www.' + mobj.group('url')\n\n        req = compat_urllib_request.Request(url)\n        req.add_header('Cookie', 'age_verified=1')\n        webpage = self._download_webpage(req, video_id)\n        age_limit = self._rta_search(webpage)\n\n        # Get JSON parameters\n        json_params = self._search_regex(r'var currentVideo = new Video\\((.*)\\);', webpage, 'JSON parameters')\n        try:\n            params = json.loads(json_params)\n        except:\n            raise ExtractorError(u'Invalid JSON')\n\n        self.report_extraction(video_id)\n        try:\n            video_title = params['title']\n            upload_date = unified_strdate(params['release_date_f'])\n            video_description = params['description']\n            video_uploader = params['submitted_by']\n            thumbnail = params['thumbnails'][0]['image']\n        except KeyError:\n            raise ExtractorError('Missing JSON parameter: ' + sys.exc_info()[1])\n\n        # Get all of the links from the page\n        DOWNLOAD_LIST_RE = r'(?s)<ul class=\"downloadList\">(?P<download_list>.*?)</ul>'\n        download_list_html = self._search_regex(DOWNLOAD_LIST_RE,\n            webpage, 'download list').strip()\n        LINK_RE = r'<a href=\"([^\"]+)\">'\n        links = re.findall(LINK_RE, download_list_html)\n\n        # Get all encrypted links\n        encrypted_links = re.findall(r'var encryptedQuality[0-9]{3}URL = \\'([a-zA-Z0-9+/]+={0,2})\\';', webpage)\n        for encrypted_link in encrypted_links:\n            link = aes_decrypt_text(encrypted_link, video_title, 32).decode('utf-8')\n            links.append(link)\n        \n        formats = []\n        for link in links:\n            # A link looks like this:\n            # http://cdn1.download.youporn.phncdn.com/201210/31/8004515/480p_370k_8004515/YouPorn%20-%20Nubile%20Films%20The%20Pillow%20Fight.mp4?nvb=20121113051249&nva=20121114051249&ir=1200&sr=1200&hash=014b882080310e95fb6a0\n            # A path looks like this:\n            # /201210/31/8004515/480p_370k_8004515/YouPorn%20-%20Nubile%20Films%20The%20Pillow%20Fight.mp4\n            video_url = unescapeHTML(link)\n            path = compat_urllib_parse_urlparse(video_url).path\n            format_parts = path.split('/')[4].split('_')[:2]\n\n            dn = compat_urllib_parse_urlparse(video_url).netloc.partition('.')[0]\n\n            resolution = format_parts[0]\n            height = int(resolution[:-len('p')])\n            bitrate = int(format_parts[1][:-len('k')])\n            format = '-'.join(format_parts) + '-' + dn\n\n            formats.append({\n                'url': video_url,\n                'format': format,\n                'format_id': format,\n                'height': height,\n                'tbr': bitrate,\n                'resolution': resolution,\n            })\n\n        self._sort_formats(formats)\n\n        if not formats:\n            raise ExtractorError(u'ERROR: no known formats available for video')\n        \n        return {\n            'id': video_id,\n            'uploader': video_uploader,\n            'upload_date': upload_date,\n            'title': video_title,\n            'thumbnail': thumbnail,\n            'description': video_description,\n            'age_limit': age_limit,\n            'formats': formats,\n        }",
        "begin_line": 37,
        "end_line": 117,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.sbs.SBSIE._real_extract#32",
        "src_path": "youtube_dl/extractor/sbs.py",
        "class_name": "youtube_dl.extractor.sbs.SBSIE",
        "signature": "youtube_dl.extractor.sbs.SBSIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n\n        release_urls_json = js_to_json(self._search_regex(\n            r'(?s)playerParams\\.releaseUrls\\s*=\\s*(\\{.*?\\n\\});\\n',\n            webpage, ''))\n        release_urls = json.loads(release_urls_json)\n        theplatform_url = (\n            release_urls.get('progressive') or release_urls.get('standard'))\n\n        title = remove_end(self._og_search_title(webpage), ' (The Feed)')\n        description = self._html_search_meta('description', webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        return {\n            '_type': 'url_transparent',\n            'id': video_id,\n            'url': theplatform_url,\n\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 32,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.reverbnation.ReverbNationIE._real_extract#24",
        "src_path": "youtube_dl/extractor/reverbnation.py",
        "class_name": "youtube_dl.extractor.reverbnation.ReverbNationIE",
        "signature": "youtube_dl.extractor.reverbnation.ReverbNationIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        song_id = mobj.group('id')\n\n        api_res = self._download_json(\n            'https://api.reverbnation.com/song/%s' % song_id,\n            song_id,\n            note='Downloading information of song %s' % song_id\n        )\n\n        return {\n            'id': song_id,\n            'title': api_res.get('name'),\n            'url': api_res.get('url'),\n            'uploader': api_res.get('artist', {}).get('name'),\n            'uploader_id': str_or_none(api_res.get('artist', {}).get('id')),\n            'thumbnail': self._proto_relative_url(\n                api_res.get('image', api_res.get('thumbnail'))),\n            'ext': 'mp3',\n            'vcodec': 'none',\n        }",
        "begin_line": 24,
        "end_line": 44,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.clubic.ClubicIE._real_extract#29",
        "src_path": "youtube_dl/extractor/clubic.py",
        "class_name": "youtube_dl.extractor.clubic.ClubicIE",
        "signature": "youtube_dl.extractor.clubic.ClubicIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        player_url = 'http://player.m6web.fr/v1/player/clubic/%s.html' % video_id\n        player_page = self._download_webpage(player_url, video_id)\n\n        config_json = self._search_regex(\n            r'(?m)M6\\.Player\\.config\\s*=\\s*(\\{.+?\\});$', player_page,\n            'configuration')\n        config = json.loads(config_json)\n\n        video_info = config['videoInfo']\n        sources = config['sources']\n        quality_order = qualities(['sd', 'hq'])\n\n        formats = [{\n            'format_id': src['streamQuality'],\n            'url': src['src'],\n            'quality': quality_order(src['streamQuality']),\n        } for src in sources]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video_info['title'],\n            'formats': formats,\n            'description': clean_html(video_info.get('description')),\n            'thumbnail': config.get('poster'),\n        }",
        "begin_line": 29,
        "end_line": 58,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.scivee.SciVeeIE._real_extract#23",
        "src_path": "youtube_dl/extractor/scivee.py",
        "class_name": "youtube_dl.extractor.scivee.SciVeeIE",
        "signature": "youtube_dl.extractor.scivee.SciVeeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        # annotations XML is malformed\n        annotations = self._download_webpage(\n            'http://www.scivee.tv/assets/annotations/%s' % video_id, video_id, 'Downloading annotations')\n\n        title = self._html_search_regex(r'<title>([^<]+)</title>', annotations, 'title')\n        description = self._html_search_regex(r'<abstract>([^<]+)</abstract>', annotations, 'abstract', fatal=False)\n        filesize = int_or_none(self._html_search_regex(\n            r'<filesize>([^<]+)</filesize>', annotations, 'filesize', fatal=False))\n\n        formats = [\n            {\n                'url': 'http://www.scivee.tv/assets/audio/%s' % video_id,\n                'ext': 'mp3',\n                'format_id': 'audio',\n            },\n            {\n                'url': 'http://www.scivee.tv/assets/video/%s' % video_id,\n                'ext': 'mp4',\n                'format_id': 'video',\n                'filesize': filesize,\n            },\n        ]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': 'http://www.scivee.tv/assets/videothumb/%s' % video_id,\n            'formats': formats,\n        }",
        "begin_line": 23,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.kankan.KankanIE._real_extract#24",
        "src_path": "youtube_dl/extractor/kankan.py",
        "class_name": "youtube_dl.extractor.kankan.KankanIE",
        "signature": "youtube_dl.extractor.kankan.KankanIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._search_regex(r'(?:G_TITLE=|G_MOVIE_TITLE = )[\\'\"](.+?)[\\'\"]', webpage, 'video title')\n        surls = re.search(r'surls:\\[\\'.+?\\'\\]|lurl:\\'.+?\\.flv\\'', webpage).group(0)\n        gcids = re.findall(r\"http://.+?/.+?/(.+?)/\", surls)\n        gcid = gcids[-1]\n\n        info_url = 'http://p2s.cl.kankan.com/getCdnresource_flv?gcid=%s' % gcid\n        video_info_page = self._download_webpage(\n            info_url, video_id, 'Downloading video url info')\n        ip = self._search_regex(r'ip:\"(.+?)\"', video_info_page, 'video url ip')\n        path = self._search_regex(r'path:\"(.+?)\"', video_info_page, 'video url path')\n        param1 = self._search_regex(r'param1:(\\d+)', video_info_page, 'param1')\n        param2 = self._search_regex(r'param2:(\\d+)', video_info_page, 'param2')\n        key = _md5('xl_mp43651' + param1 + param2)\n        video_url = 'http://%s%s?key=%s&key1=%s' % (ip, path, key, param2)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n        }",
        "begin_line": 24,
        "end_line": 48,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.clipsyndicate.ClipsyndicateIE._real_extract#27",
        "src_path": "youtube_dl/extractor/clipsyndicate.py",
        "class_name": "youtube_dl.extractor.clipsyndicate.ClipsyndicateIE",
        "signature": "youtube_dl.extractor.clipsyndicate.ClipsyndicateIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        js_player = self._download_webpage(\n            'http://eplayer.clipsyndicate.com/embed/player.js?va_id=%s' % video_id,\n            video_id, 'Downlaoding player')\n        # it includes a required token\n        flvars = self._search_regex(r'flvars: \"(.*?)\"', js_player, 'flvars')\n\n        pdoc = self._download_xml(\n            'http://eplayer.clipsyndicate.com/osmf/playlist?%s' % flvars,\n            video_id, 'Downloading video info',\n            transform_source=fix_xml_ampersands)\n\n        track_doc = pdoc.find('trackList/track')\n        def find_param(name):\n            node = find_xpath_attr(track_doc, './/param', 'name', name)\n            if node is not None:\n                return node.attrib['value']\n\n        return {\n            'id': video_id,\n            'title': find_param('title'),\n            'url': track_doc.find('location').text,\n            'thumbnail': find_param('thumbnail'),\n            'duration': int(find_param('duration')),\n        }",
        "begin_line": 27,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.rutv.RUTVIE._extract_url#96",
        "src_path": "youtube_dl/extractor/rutv.py",
        "class_name": "youtube_dl.extractor.rutv.RUTVIE",
        "signature": "youtube_dl.extractor.rutv.RUTVIE._extract_url(cls, webpage)",
        "snippet": "    def _extract_url(cls, webpage):\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>https?://player\\.rutv\\.ru/(?:iframe/(?:swf|video|live)/id|index/iframe/cast_id)/.+?)\\1', webpage)\n        if mobj:\n            return mobj.group('url')\n\n        mobj = re.search(\n            r'<meta[^>]+?property=([\"\\'])og:video\\1[^>]+?content=([\"\\'])(?P<url>https?://player\\.(?:rutv\\.ru|vgtrk\\.com)/flash2v/container\\.swf\\?id=.+?\\2)',\n            webpage)\n        if mobj:\n            return mobj.group('url')",
        "begin_line": 96,
        "end_line": 106,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0020161290322580645,
            "pseudo_dstar_susp": 0.0014903129657228018,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0014903129657228018,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.rutv.RUTVIE._real_extract#108",
        "src_path": "youtube_dl/extractor/rutv.py",
        "class_name": "youtube_dl.extractor.rutv.RUTVIE",
        "signature": "youtube_dl.extractor.rutv.RUTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        video_path = mobj.group('path')\n\n        if video_path.startswith('flash2v'):\n            video_type = 'video'\n        elif video_path.startswith('iframe'):\n            video_type = mobj.group('type')\n            if video_type == 'swf':\n                video_type = 'video'\n        elif video_path.startswith('index/iframe/cast_id'):\n            video_type = 'live'\n\n        json_data = self._download_json(\n            'http://player.rutv.ru/iframe/%splay/id/%s' % ('live-' if video_type == 'live' else '', video_id),\n            video_id, 'Downloading JSON')\n\n        if json_data['errors']:\n            raise ExtractorError('%s said: %s' % (self.IE_NAME, json_data['errors']), expected=True)\n\n        playlist = json_data['data']['playlist']\n        medialist = playlist['medialist']\n        media = medialist[0]\n\n        if media['errors']:\n            raise ExtractorError('%s said: %s' % (self.IE_NAME, media['errors']), expected=True)\n\n        view_count = playlist.get('count_views')\n        priority_transport = playlist['priority_transport']\n\n        thumbnail = media['picture']\n        width = int_or_none(media['width'])\n        height = int_or_none(media['height'])\n        description = media['anons']\n        title = media['title']\n        duration = int_or_none(media.get('duration'))\n\n        formats = []\n\n        for transport, links in media['sources'].items():\n            for quality, url in links.items():\n                if transport == 'rtmp':\n                    mobj = re.search(r'^(?P<url>rtmp://[^/]+/(?P<app>.+))/(?P<playpath>.+)$', url)\n                    if not mobj:\n                        continue\n                    fmt = {\n                        'url': mobj.group('url'),\n                        'play_path': mobj.group('playpath'),\n                        'app': mobj.group('app'),\n                        'page_url': 'http://player.rutv.ru',\n                        'player_url': 'http://player.rutv.ru/flash2v/osmf.swf?i=22',\n                        'rtmp_live': True,\n                        'ext': 'flv',\n                        'vbr': int(quality),\n                    }\n                elif transport == 'm3u8':\n                    fmt = {\n                        'url': url,\n                        'ext': 'mp4',\n                    }\n                else:\n                    fmt = {\n                        'url': url\n                    }\n                fmt.update({\n                    'width': width,\n                    'height': height,\n                    'format_id': '%s-%s' % (transport, quality),\n                    'preference': -1 if priority_transport == transport else -2,\n                })\n                formats.append(fmt)\n\n        if not formats:\n            raise ExtractorError('No media links available for %s' % video_id)\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'view_count': view_count,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 108,
        "end_line": 194,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0010030090270812437,
            "pseudo_dstar_susp": 0.0007739938080495357,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0007739938080495357,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.la7.LA7IE._real_extract#33",
        "src_path": "youtube_dl/extractor/la7.py",
        "class_name": "youtube_dl.extractor.la7.LA7IE",
        "signature": "youtube_dl.extractor.la7.LA7IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        xml_url = 'http://www.la7.tv/repliche/content/index.php?contentId=%s' % video_id\n        doc = self._download_xml(xml_url, video_id)\n\n        video_title = doc.find('title').text\n        description = doc.find('description').text\n        duration = parse_duration(doc.find('duration').text)\n        thumbnail = doc.find('img').text\n        view_count = int(doc.find('views').text)\n\n        prefix = doc.find('.//fqdn').text.strip().replace('auto:', 'http:')\n\n        formats = [{\n            'format': vnode.find('quality').text,\n            'tbr': int(vnode.find('quality').text),\n            'url': vnode.find('fms').text.strip().replace('mp4:', prefix),\n        } for vnode in doc.findall('.//videos/video')]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n            'view_count': view_count,\n        }",
        "begin_line": 33,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.godtube.GodTubeIE._real_extract#31",
        "src_path": "youtube_dl/extractor/godtube.py",
        "class_name": "youtube_dl.extractor.godtube.GodTubeIE",
        "signature": "youtube_dl.extractor.godtube.GodTubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        config = self._download_xml(\n            'http://www.godtube.com/resource/mediaplayer/%s.xml' % video_id.lower(),\n            video_id, 'Downloading player config XML')\n\n        video_url = config.find('.//file').text\n        uploader = config.find('.//author').text\n        timestamp = parse_iso8601(config.find('.//date').text)\n        duration = parse_duration(config.find('.//duration').text)\n        thumbnail = config.find('.//image').text\n\n        media = self._download_xml(\n            'http://www.godtube.com/media/xml/?v=%s' % video_id, video_id, 'Downloading media XML')\n\n        title = media.find('.//title').text\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'duration': duration,\n        }",
        "begin_line": 31,
        "end_line": 58,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.jukebox.JukeboxIE._real_extract#26",
        "src_path": "youtube_dl/extractor/jukebox.py",
        "class_name": "youtube_dl.extractor.jukebox.JukeboxIE",
        "signature": "youtube_dl.extractor.jukebox.JukeboxIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('video_id')\n\n        html = self._download_webpage(url, video_id)\n        iframe_url = unescapeHTML(self._search_regex(r'<iframe .*src=\"([^\"]*)\"', html, 'iframe url'))\n\n        iframe_html = self._download_webpage(iframe_url, video_id, 'Downloading iframe')\n        if re.search(r'class=\"jkb_waiting\"', iframe_html) is not None:\n            raise ExtractorError('Video is not available(in your country?)!')\n\n        self.report_extraction(video_id)\n\n        try:\n            video_url = self._search_regex(r'\"config\":{\"file\":\"(?P<video_url>http:[^\"]+\\?mdtk=[0-9]+)\"',\n                iframe_html, 'video url')\n            video_url = unescapeHTML(video_url).replace('\\/', '/')\n        except RegexNotFoundError:\n            youtube_url = self._search_regex(\n                r'config\":{\"file\":\"(http:\\\\/\\\\/www\\.youtube\\.com\\\\/watch\\?v=[^\"]+)\"',\n                iframe_html, 'youtube url')\n            youtube_url = unescapeHTML(youtube_url).replace('\\/', '/')\n            self.to_screen('Youtube video detected')\n            return self.url_result(youtube_url, ie='Youtube')\n\n        title = self._html_search_regex(r'<h1 class=\"inline\">([^<]+)</h1>',\n            html, 'title')\n        artist = self._html_search_regex(r'<span id=\"infos_article_artist\">([^<]+)</span>',\n            html, 'artist')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': artist + '-' + title,\n            'uploader': artist,\n        }",
        "begin_line": 26,
        "end_line": 61,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.freespeech.FreespeechIE._real_extract#26",
        "src_path": "youtube_dl/extractor/freespeech.py",
        "class_name": "youtube_dl.extractor.freespeech.FreespeechIE",
        "signature": "youtube_dl.extractor.freespeech.FreespeechIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        title = mobj.group('title')\n        webpage = self._download_webpage(url, title)\n        info_json = self._search_regex(r'jQuery.extend\\(Drupal.settings, ({.*?})\\);', webpage, 'info')\n        info = json.loads(info_json)\n\n        return {\n            '_type': 'url',\n            'url': info['jw_player']['basic_video_node_player']['file'],\n            'ie_key': 'Youtube',\n        }",
        "begin_line": 26,
        "end_line": 37,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.cnet.CNETIE._real_extract#30",
        "src_path": "youtube_dl/extractor/cnet.py",
        "class_name": "youtube_dl.extractor.cnet.CNETIE",
        "signature": "youtube_dl.extractor.cnet.CNETIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, display_id)\n        data_json = self._html_search_regex(\n            r\"<div class=\\\"cnetVideoPlayer\\\"\\s+.*?data-cnet-video-options='([^']+)'\",\n            webpage, 'data json')\n        data = json.loads(data_json)\n        vdata = data['video']\n        if not vdata:\n            vdata = data['videos'][0]\n        if not vdata:\n            raise ExtractorError('Cannot find video data')\n\n        video_id = vdata['id']\n        title = vdata.get('headline')\n        if title is None:\n            title = vdata.get('title')\n        if title is None:\n            raise ExtractorError('Cannot find title!')\n        description = vdata.get('dek')\n        thumbnail = vdata.get('image', {}).get('path')\n        author = vdata.get('author')\n        if author:\n            uploader = '%s %s' % (author['firstName'], author['lastName'])\n            uploader_id = author.get('email')\n        else:\n            uploader = None\n            uploader_id = None\n\n        formats = [{\n            'format_id': '%s-%s-%s' % (\n                f['type'], f['format'],\n                int_or_none(f.get('bitrate'), 1000, default='')),\n            'url': f['uri'],\n            'tbr': int_or_none(f.get('bitrate'), 1000),\n        } for f in vdata['files']['data']]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'formats': formats,\n            'description': description,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 30,
        "end_line": 79,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.udemy.UdemyIE._handle_error#32",
        "src_path": "youtube_dl/extractor/udemy.py",
        "class_name": "youtube_dl.extractor.udemy.UdemyIE",
        "signature": "youtube_dl.extractor.udemy.UdemyIE._handle_error(self, response)",
        "snippet": "    def _handle_error(self, response):\n        if not isinstance(response, dict):\n            return\n        error = response.get('error')\n        if error:\n            error_str = 'Udemy returned error #%s: %s' % (error.get('code'), error.get('message'))\n            error_data = error.get('data')\n            if error_data:\n                error_str += ' - %s' % error_data.get('formErrors')\n            raise ExtractorError(error_str, expected=True)",
        "begin_line": 32,
        "end_line": 41,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.udemy.UdemyIE._download_json#43",
        "src_path": "youtube_dl/extractor/udemy.py",
        "class_name": "youtube_dl.extractor.udemy.UdemyIE",
        "signature": "youtube_dl.extractor.udemy.UdemyIE._download_json(self, url, video_id, note='Downloading JSON metadata')",
        "snippet": "    def _download_json(self, url, video_id, note='Downloading JSON metadata'):\n        response = super(UdemyIE, self)._download_json(url, video_id, note)\n        self._handle_error(response)\n        return response",
        "begin_line": 43,
        "end_line": 46,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.udemy.UdemyIE._real_initialize#48",
        "src_path": "youtube_dl/extractor/udemy.py",
        "class_name": "youtube_dl.extractor.udemy.UdemyIE",
        "signature": "youtube_dl.extractor.udemy.UdemyIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 48,
        "end_line": 49,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.udemy.UdemyIE._login#51",
        "src_path": "youtube_dl/extractor/udemy.py",
        "class_name": "youtube_dl.extractor.udemy.UdemyIE",
        "signature": "youtube_dl.extractor.udemy.UdemyIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            raise ExtractorError(\n                'Udemy account is required, use --username and --password options to provide account credentials.',\n                expected=True)\n\n        login_popup = self._download_webpage(\n            'https://www.udemy.com/join/login-popup?displayType=ajax&showSkipButton=1', None,\n            'Downloading login popup')\n\n        if login_popup == '<div class=\"run-command close-popup redirect\" data-url=\"https://www.udemy.com/\"></div>':\n            return\n\n        csrf = self._html_search_regex(r'<input type=\"hidden\" name=\"csrf\" value=\"(.+?)\"', login_popup, 'csrf token')\n\n        login_form = {\n            'email': username,\n            'password': password,\n            'csrf': csrf,\n            'displayType': 'json',\n            'isSubmitted': '1',\n        }\n        request = compat_urllib_request.Request(self._LOGIN_URL, compat_urllib_parse.urlencode(login_form))\n        response = self._download_json(request, None, 'Logging in as %s' % username)\n\n        if 'returnUrl' not in response:\n            raise ExtractorError('Unable to log in')",
        "begin_line": 51,
        "end_line": 78,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.udemy.UdemyIE._real_extract#80",
        "src_path": "youtube_dl/extractor/udemy.py",
        "class_name": "youtube_dl.extractor.udemy.UdemyIE",
        "signature": "youtube_dl.extractor.udemy.UdemyIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        lecture_id = mobj.group('id')\n\n        lecture = self._download_json(\n            'https://www.udemy.com/api-1.1/lectures/%s' % lecture_id, lecture_id, 'Downloading lecture JSON')\n\n        if lecture['assetType'] != 'Video':\n            raise ExtractorError('Lecture %s is not a video' % lecture_id, expected=True)\n\n        asset = lecture['asset']\n\n        stream_url = asset['streamUrl']\n        mobj = re.search(r'(https?://www\\.youtube\\.com/watch\\?v=.*)', stream_url)\n        if mobj:\n            return self.url_result(mobj.group(1), 'Youtube')\n\n        video_id = asset['id']\n        thumbnail = asset['thumbnailUrl']\n        duration = asset['data']['duration']\n\n        download_url = asset['downloadUrl']\n\n        formats = [\n            {\n                'url': download_url['Video480p'][0],\n                'format_id': '360p',\n            },\n            {\n                'url': download_url['Video'][0],\n                'format_id': '720p',\n            },\n        ]\n\n        title = lecture['title']\n        description = lecture['description']\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats\n        }",
        "begin_line": 80,
        "end_line": 124,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.udemy.UdemyCourseIE.suitable#135",
        "src_path": "youtube_dl/extractor/udemy.py",
        "class_name": "youtube_dl.extractor.udemy.UdemyCourseIE",
        "signature": "youtube_dl.extractor.udemy.UdemyCourseIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return False if UdemyIE.suitable(url) else super(UdemyCourseIE, cls).suitable(url)",
        "begin_line": 135,
        "end_line": 136,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.003355704697986577,
            "pseudo_dstar_susp": 0.003355704697986577,
            "pseudo_tarantula_susp": 0.00029197080291970805,
            "pseudo_op2_susp": 0.003355704697986577,
            "pseudo_barinel_susp": 0.00029197080291970805
        }
    },
    {
        "name": "youtube_dl.extractor.udemy.UdemyCourseIE._real_extract#138",
        "src_path": "youtube_dl/extractor/udemy.py",
        "class_name": "youtube_dl.extractor.udemy.UdemyCourseIE",
        "signature": "youtube_dl.extractor.udemy.UdemyCourseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        course_path = mobj.group('coursepath')\n\n        response = self._download_json(\n            'https://www.udemy.com/api-1.1/courses/%s' % course_path, course_path, 'Downloading course JSON')\n\n        course_id = int(response['id'])\n        course_title = response['title']\n\n        webpage = self._download_webpage(\n            'https://www.udemy.com/course/subscribe/?courseId=%s' % course_id, course_id, 'Enrolling in the course')\n\n        if self._SUCCESSFULLY_ENROLLED in webpage:\n            self.to_screen('%s: Successfully enrolled in' % course_id)\n        elif self._ALREADY_ENROLLED in webpage:\n            self.to_screen('%s: Already enrolled in' % course_id)\n\n        response = self._download_json('https://www.udemy.com/api-1.1/courses/%s/curriculum' % course_id,\n            course_id, 'Downloading course curriculum')\n\n        entries = [\n            self.url_result('https://www.udemy.com/%s/#/lecture/%s' % (course_path, asset['id']), 'Udemy')\n            for asset in response if asset.get('assetType') == 'Video'\n        ]\n\n        return self.playlist_result(entries, course_id, course_title)",
        "begin_line": 138,
        "end_line": 164,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.photobucket.PhotobucketIE._real_extract#24",
        "src_path": "youtube_dl/extractor/photobucket.py",
        "class_name": "youtube_dl.extractor.photobucket.PhotobucketIE",
        "signature": "youtube_dl.extractor.photobucket.PhotobucketIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        video_extension = mobj.group('ext')\n\n        webpage = self._download_webpage(url, video_id)\n\n        # Extract URL, uploader, and title from webpage\n        self.report_extraction(video_id)\n        info_json = self._search_regex(r'Pb\\.Data\\.Shared\\.put\\(Pb\\.Data\\.Shared\\.MEDIA, (.*?)\\);',\n            webpage, 'info json')\n        info = json.loads(info_json)\n        url = compat_urllib_parse.unquote(self._html_search_regex(r'file=(.+\\.mp4)', info['linkcodes']['html'], 'url'))\n        return {\n            'id': video_id,\n            'url': url,\n            'uploader': info['username'],\n            'timestamp': info['creationDate'],\n            'title': info['title'],\n            'ext': video_extension,\n            'thumbnail': info['thumbUrl'],\n        }",
        "begin_line": 24,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.spike.SpikeIE._real_extract#27",
        "src_path": "youtube_dl/extractor/spike.py",
        "class_name": "youtube_dl.extractor.spike.SpikeIE",
        "signature": "youtube_dl.extractor.spike.SpikeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.search(self._VALID_URL, url)\n        mobile_id = mobj.group('mobile_id')\n        if mobile_id is not None:\n            url = 'http://www.spike.com/video-clips/%s' % mobile_id\n        return super(SpikeIE, self)._real_extract(url)",
        "begin_line": 27,
        "end_line": 32,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor._have_to_download_any_subtitles#11",
        "src_path": "youtube_dl/extractor/subtitles.py",
        "class_name": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor",
        "signature": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor._have_to_download_any_subtitles(self)",
        "snippet": "    def _have_to_download_any_subtitles(self):\n        return any([self._downloader.params.get('writesubtitles', False),\n                    self._downloader.params.get('writeautomaticsub')])",
        "begin_line": 11,
        "end_line": 13,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor._list_available_subtitles#15",
        "src_path": "youtube_dl/extractor/subtitles.py",
        "class_name": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor",
        "signature": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor._list_available_subtitles(self, video_id, webpage)",
        "snippet": "    def _list_available_subtitles(self, video_id, webpage):\n        \"\"\" outputs the available subtitles for the video \"\"\"\n        sub_lang_list = self._get_available_subtitles(video_id, webpage)\n        auto_captions_list = self._get_available_automatic_caption(video_id, webpage)\n        sub_lang = \",\".join(list(sub_lang_list.keys()))\n        self.to_screen(u'%s: Available subtitles for video: %s' %\n                       (video_id, sub_lang))\n        auto_lang = \",\".join(auto_captions_list.keys())\n        self.to_screen(u'%s: Available automatic captions for video: %s' %\n                       (video_id, auto_lang))",
        "begin_line": 15,
        "end_line": 24,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor.extract_subtitles#26",
        "src_path": "youtube_dl/extractor/subtitles.py",
        "class_name": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor",
        "signature": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor.extract_subtitles(self, video_id, webpage)",
        "snippet": "    def extract_subtitles(self, video_id, webpage):\n        \"\"\"\n        returns {sub_lang: sub} ,{} if subtitles not found or None if the\n        subtitles aren't requested.\n        \"\"\"\n        if not self._have_to_download_any_subtitles:\n            return None\n        available_subs_list = {}\n        if self._downloader.params.get('writeautomaticsub', False):\n            available_subs_list.update(self._get_available_automatic_caption(video_id, webpage))\n        if self._downloader.params.get('writesubtitles', False):\n            available_subs_list.update(self._get_available_subtitles(video_id, webpage))\n\n        if not available_subs_list:  # error, it didn't get the available subtitles\n            return {}\n        if self._downloader.params.get('allsubtitles', False):\n            sub_lang_list = available_subs_list\n        else:\n            if self._downloader.params.get('subtitleslangs', False):\n                requested_langs = self._downloader.params.get('subtitleslangs')\n            elif 'en' in available_subs_list:\n                requested_langs = ['en']\n            else:\n                requested_langs = [list(available_subs_list.keys())[0]]\n\n            sub_lang_list = {}\n            for sub_lang in requested_langs:\n                if not sub_lang in available_subs_list:\n                    self._downloader.report_warning(u'no closed captions found in the specified language \"%s\"' % sub_lang)\n                    continue\n                sub_lang_list[sub_lang] = available_subs_list[sub_lang]\n\n        subtitles = {}\n        for sub_lang, url in sub_lang_list.items():\n            subtitle = self._request_subtitle_url(sub_lang, url)\n            if subtitle:\n                subtitles[sub_lang] = subtitle\n        return subtitles",
        "begin_line": 26,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor._download_subtitle_url#65",
        "src_path": "youtube_dl/extractor/subtitles.py",
        "class_name": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor",
        "signature": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor._download_subtitle_url(self, sub_lang, url)",
        "snippet": "    def _download_subtitle_url(self, sub_lang, url):\n        return self._download_webpage(url, None, note=False)",
        "begin_line": 65,
        "end_line": 66,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor._request_subtitle_url#68",
        "src_path": "youtube_dl/extractor/subtitles.py",
        "class_name": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor",
        "signature": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor._request_subtitle_url(self, sub_lang, url)",
        "snippet": "    def _request_subtitle_url(self, sub_lang, url):\n        \"\"\" makes the http request for the subtitle \"\"\"\n        try:\n            sub = self._download_subtitle_url(sub_lang, url)\n        except ExtractorError as err:\n            self._downloader.report_warning(u'unable to download video subtitles for %s: %s' % (sub_lang, compat_str(err)))\n            return\n        if not sub:\n            self._downloader.report_warning(u'Did not fetch video subtitles')\n            return\n        return sub",
        "begin_line": 68,
        "end_line": 78,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor._get_available_subtitles#80",
        "src_path": "youtube_dl/extractor/subtitles.py",
        "class_name": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor",
        "signature": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor._get_available_subtitles(self, video_id, webpage)",
        "snippet": "    def _get_available_subtitles(self, video_id, webpage):\n        \"\"\"\n        returns {sub_lang: url} or {} if not available\n        Must be redefined by the subclasses\n        \"\"\"\n\n        # By default, allow implementations to simply pass in the result\n        assert isinstance(webpage, dict), \\\n            '_get_available_subtitles not implemented'\n        return webpage",
        "begin_line": 80,
        "end_line": 89,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor._get_available_automatic_caption#91",
        "src_path": "youtube_dl/extractor/subtitles.py",
        "class_name": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor",
        "signature": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor._get_available_automatic_caption(self, video_id, webpage)",
        "snippet": "    def _get_available_automatic_caption(self, video_id, webpage):\n        \"\"\"\n        returns {sub_lang: url} or {} if not available\n        Must be redefined by the subclasses that support automatic captions,\n        otherwise it will return {}\n        \"\"\"\n        self._downloader.report_warning(u'Automatic Captions not supported by this server')\n        return {}",
        "begin_line": 91,
        "end_line": 98,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.vodlocker.VodlockerIE._real_extract#26",
        "src_path": "youtube_dl/extractor/vodlocker.py",
        "class_name": "youtube_dl.extractor.vodlocker.VodlockerIE",
        "signature": "youtube_dl.extractor.vodlocker.VodlockerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n\n        fields = dict(re.findall(r'''(?x)<input\\s+\n            type=\"hidden\"\\s+\n            name=\"([^\"]+)\"\\s+\n            (?:id=\"[^\"]+\"\\s+)?\n            value=\"([^\"]*)\"\n            ''', webpage))\n\n        if fields['op'] == 'download1':\n            self._sleep(3, video_id)  # they do detect when requests happen too fast!\n            post = compat_urllib_parse.urlencode(fields)\n            req = compat_urllib_request.Request(url, post)\n            req.add_header('Content-type', 'application/x-www-form-urlencoded')\n            webpage = self._download_webpage(\n                req, video_id, 'Downloading video page')\n\n        title = self._search_regex(\n            r'id=\"file_title\".*?>\\s*(.*?)\\s*<(?:br|span)', webpage, 'title')\n        thumbnail = self._search_regex(\n            r'image:\\s*\"(http[^\\\"]+)\",', webpage, 'thumbnail')\n        url = self._search_regex(\n            r'file:\\s*\"(http[^\\\"]+)\",', webpage, 'file url')\n\n        formats = [{\n            'format_id': 'sd',\n            'url': url,\n        }]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 26,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.trilulilu.TriluliluIE._real_extract#22",
        "src_path": "youtube_dl/extractor/trilulilu.py",
        "class_name": "youtube_dl.extractor.trilulilu.TriluliluIE",
        "signature": "youtube_dl.extractor.trilulilu.TriluliluIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('video_id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._og_search_title(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n        description = self._og_search_description(webpage)\n\n        log_str = self._search_regex(\n            r'block_flash_vars[ ]=[ ]({[^}]+})', webpage, u'log info')\n        log = json.loads(log_str)\n\n        format_url = (u'http://fs%(server)s.trilulilu.ro/%(hash)s/'\n                      u'video-formats2' % log)\n        format_doc = self._download_xml(\n            format_url, video_id,\n            note=u'Downloading formats',\n            errnote=u'Error while downloading formats')\n \n        video_url_template = (\n            u'http://fs%(server)s.trilulilu.ro/stream.php?type=video'\n            u'&source=site&hash=%(hash)s&username=%(userid)s&'\n            u'key=ministhebest&format=%%s&sig=&exp=' %\n            log)\n        formats = [\n            {\n                'format': fnode.text,\n                'url': video_url_template % fnode.text,\n                'ext': fnode.text.partition('-')[0]\n            }\n\n            for fnode in format_doc.findall('./formats/format')\n        ]\n\n        return {\n            '_type': 'video',\n            'id': video_id,\n            'formats': formats,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 22,
        "end_line": 65,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.xtube.XTubeIE._real_extract#30",
        "src_path": "youtube_dl/extractor/xtube.py",
        "class_name": "youtube_dl.extractor.xtube.XTubeIE",
        "signature": "youtube_dl.extractor.xtube.XTubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n        url = 'http://www.' + mobj.group('url')\n\n        req = compat_urllib_request.Request(url)\n        req.add_header('Cookie', 'age_verified=1')\n        webpage = self._download_webpage(req, video_id)\n\n        video_title = self._html_search_regex(r'<p class=\"title\">([^<]+)', webpage, 'title')\n        video_uploader = self._html_search_regex(\n            r'so_s\\.addVariable\\(\"owner_u\", \"([^\"]+)', webpage, 'uploader', fatal=False)\n        video_description = self._html_search_regex(\n            r'<p class=\"fieldsDesc\">([^<]+)', webpage, 'description', fatal=False)\n        duration = parse_duration(self._html_search_regex(\n            r'<span class=\"bold\">Runtime:</span> ([^<]+)</p>', webpage, 'duration', fatal=False))\n        view_count = self._html_search_regex(\n            r'<span class=\"bold\">Views:</span> ([\\d,\\.]+)</p>', webpage, 'view count', fatal=False)\n        if view_count:\n            view_count = str_to_int(view_count)\n        comment_count = self._html_search_regex(\n            r'<div id=\"commentBar\">([\\d,\\.]+) Comments</div>', webpage, 'comment count', fatal=False)\n        if comment_count:\n            comment_count = str_to_int(comment_count)\n\n        player_quality_option = json.loads(self._html_search_regex(\n            r'playerQualityOption = ({.+?});', webpage, 'player quality option'))\n\n        QUALITIES = ['3gp', 'mp4_normal', 'mp4_high', 'flv', 'mp4_ultra', 'mp4_720', 'mp4_1080']\n        formats = [\n            {\n                'url': furl,\n                'format_id': format_id,\n                'preference': QUALITIES.index(format_id) if format_id in QUALITIES else -1,\n            } for format_id, furl in player_quality_option.items()\n        ]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'uploader': video_uploader,\n            'description': video_description,\n            'duration': duration,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'formats': formats,\n            'age_limit': 18,\n        }",
        "begin_line": 30,
        "end_line": 78,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.xtube.XTubeUserIE._real_extract#92",
        "src_path": "youtube_dl/extractor/xtube.py",
        "class_name": "youtube_dl.extractor.xtube.XTubeUserIE",
        "signature": "youtube_dl.extractor.xtube.XTubeUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        username = mobj.group('username')\n\n        profile_page = self._download_webpage(\n            url, username, note='Retrieving profile page')\n\n        video_count = int(self._search_regex(\n            r'<strong>%s\\'s Videos \\(([0-9]+)\\)</strong>'%username, profile_page,\n            'video count'))\n\n        PAGE_SIZE = 25\n        urls = []\n        page_count = (video_count + PAGE_SIZE + 1) // PAGE_SIZE\n        for n in range(1, page_count + 1):\n            lpage_url = 'http://www.xtube.com/user_videos.php?page=%d&u=%s' % (n, username)\n            lpage = self._download_webpage(\n                lpage_url, username,\n                note='Downloading page %d/%d' % (n, page_count))\n            urls.extend(\n                re.findall(r'addthis:url=\"([^\"]+)\"', lpage))\n\n        return {\n            '_type': 'playlist',\n            'id': username,\n            'entries': [{\n                '_type': 'url',\n                'url': eurl,\n                'ie_key': 'XTube',\n            } for eurl in urls]\n        }",
        "begin_line": 92,
        "end_line": 122,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.bambuser.BambuserIE._real_extract#37",
        "src_path": "youtube_dl/extractor/bambuser.py",
        "class_name": "youtube_dl.extractor.bambuser.BambuserIE",
        "signature": "youtube_dl.extractor.bambuser.BambuserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        info_url = ('http://player-c.api.bambuser.com/getVideo.json?'\n            '&api_key=%s&vid=%s' % (self._API_KEY, video_id))\n        info_json = self._download_webpage(info_url, video_id)\n        info = json.loads(info_json)['result']\n\n        return {\n            'id': video_id,\n            'title': info['title'],\n            'url': info['url'],\n            'thumbnail': info.get('preview'),\n            'duration': int(info['length']),\n            'view_count': int(info['views_total']),\n            'uploader': info['username'],\n            'uploader_id': info['uid'],\n        }",
        "begin_line": 37,
        "end_line": 54,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.bambuser.BambuserChannelIE._real_extract#70",
        "src_path": "youtube_dl/extractor/bambuser.py",
        "class_name": "youtube_dl.extractor.bambuser.BambuserChannelIE",
        "signature": "youtube_dl.extractor.bambuser.BambuserChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        user = mobj.group('user')\n        urls = []\n        last_id = ''\n        for i in itertools.count(1):\n            req_url = ('http://bambuser.com/xhr-api/index.php?username={user}'\n                '&sort=created&access_mode=0%2C1%2C2&limit={count}'\n                '&method=broadcast&format=json&vid_older_than={last}'\n                ).format(user=user, count=self._STEP, last=last_id)\n            req = compat_urllib_request.Request(req_url)\n            # Without setting this header, we wouldn't get any result\n            req.add_header('Referer', 'http://bambuser.com/channel/%s' % user)\n            data = self._download_json(\n                req, user, 'Downloading page %d' % i)\n            results = data['result']\n            if not results:\n                break\n            last_id = results[-1]['vid']\n            urls.extend(self.url_result(v['page'], 'Bambuser') for v in results)\n\n        return {\n            '_type': 'playlist',\n            'title': user,\n            'entries': urls,\n        }",
        "begin_line": 70,
        "end_line": 95,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.muzu.MuzuTVIE._real_extract#26",
        "src_path": "youtube_dl/extractor/muzu.py",
        "class_name": "youtube_dl.extractor.muzu.MuzuTVIE",
        "signature": "youtube_dl.extractor.muzu.MuzuTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        info_data = compat_urllib_parse.urlencode({'format': 'json',\n                                                   'url': url,\n                                                   })\n        video_info_page = self._download_webpage('http://www.muzu.tv/api/oembed/?%s' % info_data,\n                                                 video_id, u'Downloading video info')\n        info = json.loads(video_info_page)\n\n        player_info_page = self._download_webpage('http://player.muzu.tv/player/playerInit?ai=%s' % video_id,\n                                                  video_id, u'Downloading player info')\n        video_info = json.loads(player_info_page)['videos'][0]\n        for quality in ['1080' , '720', '480', '360']:\n            if video_info.get('v%s' % quality):\n                break\n\n        data = compat_urllib_parse.urlencode({'ai': video_id,\n                                              # Even if each time you watch a video the hash changes,\n                                              # it seems to work for different videos, and it will work\n                                              # even if you use any non empty string as a hash\n                                              'viewhash': 'VBNff6djeV4HV5TRPW5kOHub2k',\n                                              'device': 'web',\n                                              'qv': quality,\n                                              })\n        video_url_page = self._download_webpage('http://player.muzu.tv/player/requestVideo?%s' % data,\n                                                video_id, u'Downloading video url')\n        video_url_info = json.loads(video_url_page)\n        video_url = video_url_info['url']\n\n        return {'id': video_id,\n                'title': info['title'],\n                'url': video_url,\n                'ext': determine_ext(video_url),\n                'thumbnail': info['thumbnail_url'],\n                'description': info['description'],\n                'uploader': info['author_name'],\n                }",
        "begin_line": 26,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.downloader.hls.HlsFD.real_download#12",
        "src_path": "youtube_dl/downloader/hls.py",
        "class_name": "youtube_dl.downloader.hls.HlsFD",
        "signature": "youtube_dl.downloader.hls.HlsFD.real_download(self, filename, info_dict)",
        "snippet": "    def real_download(self, filename, info_dict):\n        url = info_dict['url']\n        self.report_destination(filename)\n        tmpfilename = self.temp_name(filename)\n\n        args = [\n            '-y', '-i', url, '-f', 'mp4', '-c', 'copy',\n            '-bsf:a', 'aac_adtstoasc',\n            encodeFilename(tmpfilename, for_subprocess=True)]\n\n        for program in ['avconv', 'ffmpeg']:\n            if check_executable(program, ['-version']):\n                break\n        else:\n            self.report_error(u'm3u8 download detected but ffmpeg or avconv could not be found. Please install one.')\n            return False\n        cmd = [program] + args\n\n        retval = subprocess.call(cmd)\n        if retval == 0:\n            fsize = os.path.getsize(encodeFilename(tmpfilename))\n            self.to_screen(u'\\r[%s] %s bytes' % (cmd[0], fsize))\n            self.try_rename(tmpfilename, filename)\n            self._hook_progress({\n                'downloaded_bytes': fsize,\n                'total_bytes': fsize,\n                'filename': filename,\n                'status': 'finished',\n            })\n            return True\n        else:\n            self.to_stderr(u\"\\n\")\n            self.report_error(u'%s exited with code %d' % (program, retval))\n            return False",
        "begin_line": 12,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.dotsub.DotsubIE._real_extract#25",
        "src_path": "youtube_dl/extractor/dotsub.py",
        "class_name": "youtube_dl.extractor.dotsub.DotsubIE",
        "signature": "youtube_dl.extractor.dotsub.DotsubIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        info_url = \"https://dotsub.com/api/media/%s/metadata\" % video_id\n        info = self._download_json(info_url, video_id)\n        date = time.gmtime(info['dateCreated']/1000) # The timestamp is in miliseconds\n\n        return {\n            'id': video_id,\n            'url': info['mediaURI'],\n            'ext': 'flv',\n            'title': info['title'],\n            'thumbnail': info['screenshotURI'],\n            'description': info['description'],\n            'uploader': info['user'],\n            'view_count': info['numberOfViews'],\n            'upload_date': '%04i%02i%02i' % (date.tm_year, date.tm_mon, date.tm_mday),\n        }",
        "begin_line": 25,
        "end_line": 42,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.ministrygrid.MinistryGridIE._real_extract#28",
        "src_path": "youtube_dl/extractor/ministrygrid.py",
        "class_name": "youtube_dl.extractor.ministrygrid.MinistryGridIE",
        "signature": "youtube_dl.extractor.ministrygrid.MinistryGridIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        portlets_json = self._search_regex(\n            r'Liferay\\.Portlet\\.list=(\\[.+?\\])', webpage, 'portlet list')\n        portlets = json.loads(portlets_json)\n        pl_id = self._search_regex(\n            r'<!--\\s*p_l_id - ([0-9]+)<br>', webpage, 'p_l_id')\n\n        for i, portlet in enumerate(portlets):\n            portlet_url = 'http://www.ministrygrid.com/c/portal/render_portlet?p_l_id=%s&p_p_id=%s' % (pl_id, portlet)\n            portlet_code = self._download_webpage(\n                portlet_url, video_id,\n                note='Looking in portlet %s (%d/%d)' % (portlet, i + 1, len(portlets)),\n                fatal=False)\n            video_iframe_url = self._search_regex(\n                r'<iframe.*?src=\"([^\"]+)\"', portlet_code, 'video iframe',\n                default=None)\n            if video_iframe_url:\n                surl = smuggle_url(\n                    video_iframe_url, {'force_videoid': video_id})\n                return {\n                    '_type': 'url',\n                    'id': video_id,\n                    'url': surl,\n                }\n\n        raise ExtractorError('Could not find video iframe in any portlets')",
        "begin_line": 28,
        "end_line": 57,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.motherless.MotherlessIE._real_extract#46",
        "src_path": "youtube_dl/extractor/motherless.py",
        "class_name": "youtube_dl.extractor.motherless.MotherlessIE",
        "signature": "youtube_dl.extractor.motherless.MotherlessIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self,url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(r'id=\"view-upload-title\">\\s+([^<]+)<', webpage, 'title')\n        \n        video_url = self._html_search_regex(r'setup\\(\\{\\s+\"file\".+: \"([^\"]+)\",', webpage, 'video_url')\n        age_limit = self._rta_search(webpage)\n\n        view_count = self._html_search_regex(r'<strong>Views</strong>\\s+([^<]+)<', webpage, 'view_count')\n \n        upload_date = self._html_search_regex(r'<strong>Uploaded</strong>\\s+([^<]+)<', webpage, 'upload_date')\n        if 'Ago' in upload_date:\n            days = int(re.search(r'([0-9]+)', upload_date).group(1))\n            upload_date = (datetime.datetime.now() - datetime.timedelta(days=days)).strftime('%Y%m%d')\n        else:\n            upload_date = unified_strdate(upload_date)\n\n        like_count = self._html_search_regex(r'<strong>Favorited</strong>\\s+([^<]+)<', webpage, 'like_count')\n\n        comment_count = webpage.count('class=\"media-comment-contents\"')\n        uploader_id = self._html_search_regex(r'\"thumb-member-username\">\\s+<a href=\"/m/([^\"]+)\"', webpage, 'uploader_id')\n\n        categories = self._html_search_meta('keywords', webpage)\n        if categories:\n            categories = [cat.strip() for cat in categories.split(',')]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'upload_date': upload_date,\n            'uploader_id': uploader_id,\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'categories': categories,\n            'view_count': int_or_none(view_count.replace(',', '')),\n            'like_count': int_or_none(like_count.replace(',', '')),\n            'comment_count': comment_count,\n            'age_limit': age_limit,\n            'url': video_url,\n        }",
        "begin_line": 46,
        "end_line": 87,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.ringtv.RingTVIE._real_extract#20",
        "src_path": "youtube_dl/extractor/ringtv.py",
        "class_name": "youtube_dl.extractor.ringtv.RingTVIE",
        "signature": "youtube_dl.extractor.ringtv.RingTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id').split('-')[0]\n        webpage = self._download_webpage(url, video_id)\n\n        if mobj.group('type') == 'news':\n            video_id = self._search_regex(\n                r'''(?x)<iframe[^>]+src=\"http://cms\\.springboardplatform\\.com/\n                        embed_iframe/[0-9]+/video/([0-9]+)/''',\n                webpage, 'real video ID')\n        title = self._og_search_title(webpage)\n        description = self._html_search_regex(\n            r'addthis:description=\"([^\"]+)\"',\n            webpage, 'description', fatal=False)\n        final_url = \"http://ringtv.craveonline.springboardplatform.com/storage/ringtv.craveonline.com/conversion/%s.mp4\" % video_id\n        thumbnail_url = \"http://ringtv.craveonline.springboardplatform.com/storage/ringtv.craveonline.com/snapshots/%s.jpg\" % video_id\n\n        return {\n            'id': video_id,\n            'url': final_url,\n            'title': title,\n            'thumbnail': thumbnail_url,\n            'description': description,\n        }",
        "begin_line": 20,
        "end_line": 43,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.sunporno.SunPornoIE._real_extract#30",
        "src_path": "youtube_dl/extractor/sunporno.py",
        "class_name": "youtube_dl.extractor.sunporno.SunPornoIE",
        "signature": "youtube_dl.extractor.sunporno.SunPornoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(r'<title>([^<]+)</title>', webpage, 'title')\n        description = self._html_search_meta('description', webpage, 'description')\n        thumbnail = self._html_search_regex(\n            r'poster=\"([^\"]+)\"', webpage, 'thumbnail', fatal=False)\n\n        duration = parse_duration(self._search_regex(\n            r'<span>Duration: (\\d+:\\d+)</span>', webpage, 'duration', fatal=False))\n\n        view_count = int_or_none(self._html_search_regex(\n            r'<span class=\"views\">(\\d+)</span>', webpage, 'view count', fatal=False))\n        comment_count = int_or_none(self._html_search_regex(\n            r'(\\d+)</b> Comments?', webpage, 'comment count', fatal=False))\n\n        formats = []\n        quality = qualities(['mp4', 'flv'])\n        for video_url in re.findall(r'<source src=\"([^\"]+)\"', webpage):\n            video_ext = determine_ext(video_url)\n            formats.append({\n                'url': video_url,\n                'format_id': video_ext,\n                'quality': quality(video_ext),\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'formats': formats,\n            'age_limit': 18,\n        }",
        "begin_line": 30,
        "end_line": 70,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.videofyme.VideofyMeIE._real_extract#26",
        "src_path": "youtube_dl/extractor/videofyme.py",
        "class_name": "youtube_dl.extractor.videofyme.VideofyMeIE",
        "signature": "youtube_dl.extractor.videofyme.VideofyMeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        config = self._download_xml('http://sunshine.videofy.me/?videoId=%s' % video_id,\n                                            video_id)\n        video = config.find('video')\n        sources = video.find('sources')\n        url_node = next(node for node in [find_xpath_attr(sources, 'source', 'id', 'HQ %s' % key) \n            for key in ['on', 'av', 'off']] if node is not None)\n        video_url = url_node.find('url').text\n\n        return {'id': video_id,\n                'title': video.find('title').text,\n                'url': video_url,\n                'ext': determine_ext(video_url),\n                'thumbnail': video.find('thumb').text,\n                'description': video.find('description').text,\n                'uploader': config.find('blog/name').text,\n                'uploader_id': video.find('identifier').text,\n                'view_count': re.search(r'\\d+', video.find('views').text).group(),\n                }",
        "begin_line": 26,
        "end_line": 46,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.eitb.EitbIE._real_extract#27",
        "src_path": "youtube_dl/extractor/eitb.py",
        "class_name": "youtube_dl.extractor.eitb.EitbIE",
        "signature": "youtube_dl.extractor.eitb.EitbIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        chapter_id = mobj.group('chapter_id')\n        webpage = self._download_webpage(url, chapter_id)\n        bc_url = BrightcoveIE._extract_brightcove_url(webpage)\n        if bc_url is None:\n            raise ExtractorError(u'Could not extract the Brightcove url')\n        # The BrightcoveExperience object doesn't contain the video id, we set\n        # it manually\n        bc_url += '&%40videoPlayer={0}'.format(chapter_id)\n        return self.url_result(bc_url, BrightcoveIE.ie_key())",
        "begin_line": 27,
        "end_line": 37,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.hentaistigma.HentaiStigmaIE._real_extract#21",
        "src_path": "youtube_dl/extractor/hentaistigma.py",
        "class_name": "youtube_dl.extractor.hentaistigma.HentaiStigmaIE",
        "signature": "youtube_dl.extractor.hentaistigma.HentaiStigmaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(\n            r'<h2 class=\"posttitle\"><a[^>]*>([^<]+)</a>',\n            webpage, 'title')\n        wrap_url = self._html_search_regex(\n            r'<iframe src=\"([^\"]+mp4)\"', webpage, 'wrapper url')\n        wrap_webpage = self._download_webpage(wrap_url, video_id)\n\n        video_url = self._html_search_regex(\n            r'clip:\\s*{\\s*url: \"([^\"]*)\"', wrap_webpage, 'video url')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'age_limit': 18,\n        }",
        "begin_line": 21,
        "end_line": 42,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.kickstarter.KickStarterIE._real_extract#37",
        "src_path": "youtube_dl/extractor/kickstarter.py",
        "class_name": "youtube_dl.extractor.kickstarter.KickStarterIE",
        "signature": "youtube_dl.extractor.kickstarter.KickStarterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('id')\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(\n            r'<title>\\s*(.*?)(?:\\s*&mdash; Kickstarter)?\\s*</title>',\n            webpage, 'title')\n        video_url = self._search_regex(\n            r'data-video-url=\"(.*?)\"',\n            webpage, 'video URL', default=None)\n        if video_url is None:  # No native kickstarter, look for embedded videos\n            return {\n                '_type': 'url_transparent',\n                'ie_key': 'Generic',\n                'url': url,\n                'title': title,\n            }\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': self._og_search_description(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n        }",
        "begin_line": 37,
        "end_line": 62,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.__init__._real_main#125",
        "src_path": "youtube_dl/__init__.py",
        "class_name": "youtube_dl.__init__",
        "signature": "youtube_dl.__init__._real_main(argv=None)",
        "snippet": "def _real_main(argv=None):\n    # Compatibility fixes for Windows\n    if sys.platform == 'win32':\n        # https://github.com/rg3/youtube-dl/issues/820\n        codecs.register(lambda name: codecs.lookup('utf-8') if name == 'cp65001' else None)\n\n    setproctitle(u'youtube-dl')\n\n    parser, opts, args = parseOpts(argv)\n\n    # Set user agent\n    if opts.user_agent is not None:\n        std_headers['User-Agent'] = opts.user_agent\n\n    # Set referer\n    if opts.referer is not None:\n        std_headers['Referer'] = opts.referer\n\n    # Custom HTTP headers\n    if opts.headers is not None:\n        for h in opts.headers:\n            if h.find(':', 1) < 0:\n                parser.error(u'wrong header formatting, it should be key:value, not \"%s\"'%h)\n            key, value = h.split(':', 2)\n            if opts.verbose:\n                write_string(u'[debug] Adding header from command line option %s:%s\\n'%(key, value))\n            std_headers[key] = value\n\n    # Dump user agent\n    if opts.dump_user_agent:\n        compat_print(std_headers['User-Agent'])\n        sys.exit(0)\n\n    # Batch file verification\n    batch_urls = []\n    if opts.batchfile is not None:\n        try:\n            if opts.batchfile == '-':\n                batchfd = sys.stdin\n            else:\n                batchfd = io.open(opts.batchfile, 'r', encoding='utf-8', errors='ignore')\n            batch_urls = read_batch_urls(batchfd)\n            if opts.verbose:\n                write_string(u'[debug] Batch file urls: ' + repr(batch_urls) + u'\\n')\n        except IOError:\n            sys.exit(u'ERROR: batch file could not be read')\n    all_urls = batch_urls + args\n    all_urls = [url.strip() for url in all_urls]\n    _enc = preferredencoding()\n    all_urls = [url.decode(_enc, 'ignore') if isinstance(url, bytes) else url for url in all_urls]\n\n    extractors = gen_extractors()\n\n    if opts.list_extractors:\n        for ie in sorted(extractors, key=lambda ie: ie.IE_NAME.lower()):\n            compat_print(ie.IE_NAME + (' (CURRENTLY BROKEN)' if not ie._WORKING else ''))\n            matchedUrls = [url for url in all_urls if ie.suitable(url)]\n            for mu in matchedUrls:\n                compat_print(u'  ' + mu)\n        sys.exit(0)\n    if opts.list_extractor_descriptions:\n        for ie in sorted(extractors, key=lambda ie: ie.IE_NAME.lower()):\n            if not ie._WORKING:\n                continue\n            desc = getattr(ie, 'IE_DESC', ie.IE_NAME)\n            if desc is False:\n                continue\n            if hasattr(ie, 'SEARCH_KEY'):\n                _SEARCHES = (u'cute kittens', u'slithering pythons', u'falling cat', u'angry poodle', u'purple fish', u'running tortoise', u'sleeping bunny')\n                _COUNTS = (u'', u'5', u'10', u'all')\n                desc += u' (Example: \"%s%s:%s\" )' % (ie.SEARCH_KEY, random.choice(_COUNTS), random.choice(_SEARCHES))\n            compat_print(desc)\n        sys.exit(0)\n\n\n    # Conflicting, missing and erroneous options\n    if opts.usenetrc and (opts.username is not None or opts.password is not None):\n        parser.error(u'using .netrc conflicts with giving username/password')\n    if opts.password is not None and opts.username is None:\n        parser.error(u'account username missing\\n')\n    if opts.outtmpl is not None and (opts.usetitle or opts.autonumber or opts.useid):\n        parser.error(u'using output template conflicts with using title, video ID or auto number')\n    if opts.usetitle and opts.useid:\n        parser.error(u'using title conflicts with using video ID')\n    if opts.username is not None and opts.password is None:\n        opts.password = compat_getpass(u'Type account password and press [Return]: ')\n    if opts.ratelimit is not None:\n        numeric_limit = FileDownloader.parse_bytes(opts.ratelimit)\n        if numeric_limit is None:\n            parser.error(u'invalid rate limit specified')\n        opts.ratelimit = numeric_limit\n    if opts.min_filesize is not None:\n        numeric_limit = FileDownloader.parse_bytes(opts.min_filesize)\n        if numeric_limit is None:\n            parser.error(u'invalid min_filesize specified')\n        opts.min_filesize = numeric_limit\n    if opts.max_filesize is not None:\n        numeric_limit = FileDownloader.parse_bytes(opts.max_filesize)\n        if numeric_limit is None:\n            parser.error(u'invalid max_filesize specified')\n        opts.max_filesize = numeric_limit\n    if opts.retries is not None:\n        try:\n            opts.retries = int(opts.retries)\n        except (TypeError, ValueError):\n            parser.error(u'invalid retry count specified')\n    if opts.buffersize is not None:\n        numeric_buffersize = FileDownloader.parse_bytes(opts.buffersize)\n        if numeric_buffersize is None:\n            parser.error(u'invalid buffer size specified')\n        opts.buffersize = numeric_buffersize\n    if opts.playliststart <= 0:\n        raise ValueError(u'Playlist start must be positive')\n    if opts.playlistend not in (-1, None) and opts.playlistend < opts.playliststart:\n        raise ValueError(u'Playlist end must be greater than playlist start')\n    if opts.extractaudio:\n        if opts.audioformat not in ['best', 'aac', 'mp3', 'm4a', 'opus', 'vorbis', 'wav']:\n            parser.error(u'invalid audio format specified')\n    if opts.audioquality:\n        opts.audioquality = opts.audioquality.strip('k').strip('K')\n        if not opts.audioquality.isdigit():\n            parser.error(u'invalid audio quality specified')\n    if opts.recodevideo is not None:\n        if opts.recodevideo not in ['mp4', 'flv', 'webm', 'ogg', 'mkv']:\n            parser.error(u'invalid video recode format specified')\n    if opts.date is not None:\n        date = DateRange.day(opts.date)\n    else:\n        date = DateRange(opts.dateafter, opts.datebefore)\n    if opts.default_search not in ('auto', 'auto_warning', 'error', 'fixup_error', None) and ':' not in opts.default_search:\n        parser.error(u'--default-search invalid; did you forget a colon (:) at the end?')\n\n    # Do not download videos when there are audio-only formats\n    if opts.extractaudio and not opts.keepvideo and opts.format is None:\n        opts.format = 'bestaudio/best'\n\n    # --all-sub automatically sets --write-sub if --write-auto-sub is not given\n    # this was the old behaviour if only --all-sub was given.\n    if opts.allsubtitles and (opts.writeautomaticsub == False):\n        opts.writesubtitles = True\n\n    if sys.version_info < (3,):\n        # In Python 2, sys.argv is a bytestring (also note http://bugs.python.org/issue2128 for Windows systems)\n        if opts.outtmpl is not None:\n            opts.outtmpl = opts.outtmpl.decode(preferredencoding())\n    outtmpl =((opts.outtmpl is not None and opts.outtmpl)\n            or (opts.format == '-1' and opts.usetitle and u'%(title)s-%(id)s-%(format)s.%(ext)s')\n            or (opts.format == '-1' and u'%(id)s-%(format)s.%(ext)s')\n            or (opts.usetitle and opts.autonumber and u'%(autonumber)s-%(title)s-%(id)s.%(ext)s')\n            or (opts.usetitle and u'%(title)s-%(id)s.%(ext)s')\n            or (opts.useid and u'%(id)s.%(ext)s')\n            or (opts.autonumber and u'%(autonumber)s-%(id)s.%(ext)s')\n            or DEFAULT_OUTTMPL)\n    if not os.path.splitext(outtmpl)[1] and opts.extractaudio:\n        parser.error(u'Cannot download a video and extract audio into the same'\n                     u' file! Use \"{0}.%(ext)s\" instead of \"{0}\" as the output'\n                     u' template'.format(outtmpl))\n\n    any_printing = opts.geturl or opts.gettitle or opts.getid or opts.getthumbnail or opts.getdescription or opts.getfilename or opts.getformat or opts.getduration or opts.dumpjson\n    download_archive_fn = os.path.expanduser(opts.download_archive) if opts.download_archive is not None else opts.download_archive\n\n    ydl_opts = {\n        'usenetrc': opts.usenetrc,\n        'username': opts.username,\n        'password': opts.password,\n        'twofactor': opts.twofactor,\n        'videopassword': opts.videopassword,\n        'quiet': (opts.quiet or any_printing),\n        'no_warnings': opts.no_warnings,\n        'forceurl': opts.geturl,\n        'forcetitle': opts.gettitle,\n        'forceid': opts.getid,\n        'forcethumbnail': opts.getthumbnail,\n        'forcedescription': opts.getdescription,\n        'forceduration': opts.getduration,\n        'forcefilename': opts.getfilename,\n        'forceformat': opts.getformat,\n        'forcejson': opts.dumpjson,\n        'simulate': opts.simulate,\n        'skip_download': (opts.skip_download or opts.simulate or any_printing),\n        'format': opts.format,\n        'format_limit': opts.format_limit,\n        'listformats': opts.listformats,\n        'outtmpl': outtmpl,\n        'autonumber_size': opts.autonumber_size,\n        'restrictfilenames': opts.restrictfilenames,\n        'ignoreerrors': opts.ignoreerrors,\n        'ratelimit': opts.ratelimit,\n        'nooverwrites': opts.nooverwrites,\n        'retries': opts.retries,\n        'buffersize': opts.buffersize,\n        'noresizebuffer': opts.noresizebuffer,\n        'continuedl': opts.continue_dl,\n        'noprogress': opts.noprogress,\n        'progress_with_newline': opts.progress_with_newline,\n        'playliststart': opts.playliststart,\n        'playlistend': opts.playlistend,\n        'noplaylist': opts.noplaylist,\n        'logtostderr': opts.outtmpl == '-',\n        'consoletitle': opts.consoletitle,\n        'nopart': opts.nopart,\n        'updatetime': opts.updatetime,\n        'writedescription': opts.writedescription,\n        'writeannotations': opts.writeannotations,\n        'writeinfojson': opts.writeinfojson,\n        'writethumbnail': opts.writethumbnail,\n        'writesubtitles': opts.writesubtitles,\n        'writeautomaticsub': opts.writeautomaticsub,\n        'allsubtitles': opts.allsubtitles,\n        'listsubtitles': opts.listsubtitles,\n        'subtitlesformat': opts.subtitlesformat,\n        'subtitleslangs': opts.subtitleslangs,\n        'matchtitle': decodeOption(opts.matchtitle),\n        'rejecttitle': decodeOption(opts.rejecttitle),\n        'max_downloads': opts.max_downloads,\n        'prefer_free_formats': opts.prefer_free_formats,\n        'verbose': opts.verbose,\n        'dump_intermediate_pages': opts.dump_intermediate_pages,\n        'write_pages': opts.write_pages,\n        'test': opts.test,\n        'keepvideo': opts.keepvideo,\n        'min_filesize': opts.min_filesize,\n        'max_filesize': opts.max_filesize,\n        'min_views': opts.min_views,\n        'max_views': opts.max_views,\n        'daterange': date,\n        'cachedir': opts.cachedir,\n        'youtube_print_sig_code': opts.youtube_print_sig_code,\n        'age_limit': opts.age_limit,\n        'download_archive': download_archive_fn,\n        'cookiefile': opts.cookiefile,\n        'nocheckcertificate': opts.no_check_certificate,\n        'prefer_insecure': opts.prefer_insecure,\n        'proxy': opts.proxy,\n        'socket_timeout': opts.socket_timeout,\n        'bidi_workaround': opts.bidi_workaround,\n        'debug_printtraffic': opts.debug_printtraffic,\n        'prefer_ffmpeg': opts.prefer_ffmpeg,\n        'include_ads': opts.include_ads,\n        'default_search': opts.default_search,\n        'youtube_include_dash_manifest': opts.youtube_include_dash_manifest,\n        'encoding': opts.encoding,\n        'exec_cmd': opts.exec_cmd,\n    }\n\n    with YoutubeDL(ydl_opts) as ydl:\n        ydl.print_debug_header()\n        ydl.add_default_info_extractors()\n\n        # PostProcessors\n        # Add the metadata pp first, the other pps will copy it\n        if opts.addmetadata:\n            ydl.add_post_processor(FFmpegMetadataPP())\n        if opts.extractaudio:\n            ydl.add_post_processor(FFmpegExtractAudioPP(preferredcodec=opts.audioformat, preferredquality=opts.audioquality, nopostoverwrites=opts.nopostoverwrites))\n        if opts.recodevideo:\n            ydl.add_post_processor(FFmpegVideoConvertor(preferedformat=opts.recodevideo))\n        if opts.embedsubtitles:\n            ydl.add_post_processor(FFmpegEmbedSubtitlePP(subtitlesformat=opts.subtitlesformat))\n        if opts.xattrs:\n            ydl.add_post_processor(XAttrMetadataPP())\n        if opts.embedthumbnail:\n            if not opts.addmetadata:\n                ydl.add_post_processor(FFmpegAudioFixPP())\n            ydl.add_post_processor(AtomicParsleyPP())\n\n\n        # Please keep ExecAfterDownload towards the bottom as it allows the user to modify the final file in any way.\n        # So if the user is able to remove the file before your postprocessor runs it might cause a few problems.\n        if opts.exec_cmd:\n            ydl.add_post_processor(ExecAfterDownloadPP(\n                verboseOutput=opts.verbose, exec_cmd=opts.exec_cmd))\n\n        # Update version\n        if opts.update_self:\n            update_self(ydl.to_screen, opts.verbose)\n\n        # Remove cache dir\n        if opts.rm_cachedir:\n            ydl.cache.remove()\n\n        # Maybe do nothing\n        if (len(all_urls) < 1) and (opts.load_info_filename is None):\n            if not (opts.update_self or opts.rm_cachedir):\n                parser.error(u'you must provide at least one URL')\n            else:\n                sys.exit()\n\n        try:\n            if opts.load_info_filename is not None:\n                retcode = ydl.download_with_info_file(opts.load_info_filename)\n            else:\n                retcode = ydl.download(all_urls)\n        except MaxDownloadsReached:\n            ydl.to_screen(u'--max-download limit reached, aborting.')\n            retcode = 101\n\n    sys.exit(retcode)",
        "begin_line": 125,
        "end_line": 422,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.0001840942562592047,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.__init__.main#425",
        "src_path": "youtube_dl/__init__.py",
        "class_name": "youtube_dl.__init__",
        "signature": "youtube_dl.__init__.main(argv=None)",
        "snippet": "def main(argv=None):\n    try:\n        _real_main(argv)\n    except DownloadError:\n        sys.exit(1)\n    except SameFileError:\n        sys.exit(u'ERROR: fixed output name but more than one file to download')\n    except KeyboardInterrupt:\n        sys.exit(u'\\nERROR: Interrupted by user')",
        "begin_line": 425,
        "end_line": 433,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.0001840942562592047,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.wrzuta.WrzutaIE._real_extract#42",
        "src_path": "youtube_dl/extractor/wrzuta.py",
        "class_name": "youtube_dl.extractor.wrzuta.WrzutaIE",
        "signature": "youtube_dl.extractor.wrzuta.WrzutaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        typ = mobj.group('typ')\n        uploader = mobj.group('uploader')\n\n        webpage = self._download_webpage(url, video_id)\n\n        quality = qualities(['SD', 'MQ', 'HQ', 'HD'])\n\n        audio_table = {'flv': 'mp3', 'webm': 'ogg'}\n\n        embedpage = self._download_json('http://www.wrzuta.pl/npp/embed/%s/%s' % (uploader, video_id), video_id)\n\n        formats = []\n        for media in embedpage['url']:\n            if typ == 'audio':\n                ext = audio_table[media['type'].split('@')[0]]\n            else:\n                ext = media['type'].split('@')[0]\n\n            formats.append({\n                'format_id': '%s_%s' % (ext, media['quality'].lower()),\n                'url': media['url'],\n                'ext': ext,\n                'quality': quality(media['quality']),\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'formats': formats,\n            'duration': int_or_none(embedpage['duration']),\n            'uploader_id': uploader,\n            'description': self._og_search_description(webpage),\n            'age_limit': embedpage.get('minimalAge', 0),\n        }",
        "begin_line": 42,
        "end_line": 81,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.smotri.SmotriIE._extract_url#117",
        "src_path": "youtube_dl/extractor/smotri.py",
        "class_name": "youtube_dl.extractor.smotri.SmotriIE",
        "signature": "youtube_dl.extractor.smotri.SmotriIE._extract_url(cls, webpage)",
        "snippet": "    def _extract_url(cls, webpage):\n        mobj = re.search(\n            r'<embed[^>]src=([\"\\'])(?P<url>http://pics\\.smotri\\.com/(?:player|scrubber_custom8)\\.swf\\?file=v.+?\\1)',\n            webpage)\n        if mobj is not None:\n            return mobj.group('url')\n\n        mobj = re.search(\n            r'''(?x)<div\\s+class=\"video_file\">http://smotri\\.com/video/download/file/[^<]+</div>\\s*\n                    <div\\s+class=\"video_image\">[^<]+</div>\\s*\n                    <div\\s+class=\"video_id\">(?P<id>[^<]+)</div>''', webpage)\n        if mobj is not None:\n            return 'http://smotri.com/video/view/?id=%s' % mobj.group('id')",
        "begin_line": 117,
        "end_line": 129,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0015015015015015015,
            "pseudo_dstar_susp": 0.0011235955056179776,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0011235955056179776,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.smotri.SmotriIE._search_meta#131",
        "src_path": "youtube_dl/extractor/smotri.py",
        "class_name": "youtube_dl.extractor.smotri.SmotriIE",
        "signature": "youtube_dl.extractor.smotri.SmotriIE._search_meta(self, name, html, display_name=None)",
        "snippet": "    def _search_meta(self, name, html, display_name=None):\n        if display_name is None:\n            display_name = name\n        return self._html_search_regex(\n            r'<meta itemprop=\"%s\" content=\"([^\"]+)\" />' % re.escape(name),\n            html, display_name, fatal=False)\n        return self._html_search_meta(name, html, display_name)",
        "begin_line": 131,
        "end_line": 137,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.smotri.SmotriIE._real_extract#139",
        "src_path": "youtube_dl/extractor/smotri.py",
        "class_name": "youtube_dl.extractor.smotri.SmotriIE",
        "signature": "youtube_dl.extractor.smotri.SmotriIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n        real_video_id = mobj.group('realvideoid')\n\n        # Download video JSON data\n        video_json_url = 'http://smotri.com/vt.php?id=%s' % real_video_id\n        video_json_page = self._download_webpage(video_json_url, video_id, 'Downloading video JSON')\n        video_json = json.loads(video_json_page)\n\n        status = video_json['status']\n        if status == self._VIDEO_NOT_FOUND:\n            raise ExtractorError('Video %s does not exist' % video_id, expected=True)\n        elif status == self._PASSWORD_DETECTED: # The video is protected by a password, retry with\n                                                # video-password set\n            video_password = self._downloader.params.get('videopassword', None)\n            if not video_password:\n                raise ExtractorError('This video is protected by a password, use the --video-password option', expected=True)\n            video_json_url += '&md5pass=%s' % hashlib.md5(video_password.encode('utf-8')).hexdigest()\n            video_json_page = self._download_webpage(video_json_url, video_id, 'Downloading video JSON (video-password set)')\n            video_json = json.loads(video_json_page)\n            status = video_json['status']\n            if status == self._PASSWORD_NOT_VERIFIED:\n                raise ExtractorError('Video password is invalid', expected=True)\n\n        if status != self._SUCCESS:\n            raise ExtractorError('Unexpected status value %s' % status)\n\n        # Extract the URL of the video\n        video_url = video_json['file_data']\n\n        # Video JSON does not provide enough meta data\n        # We will extract some from the video web page instead\n        video_page_url = 'http://smotri.com/video/view/?id=%s' % video_id\n        video_page = self._download_webpage(video_page_url, video_id, 'Downloading video page')\n\n        # Warning if video is unavailable\n        warning = self._html_search_regex(\n            r'<div class=\"videoUnModer\">(.*?)</div>', video_page,\n            'warning message', default=None)\n        if warning is not None:\n            self._downloader.report_warning(\n                'Video %s may not be available; smotri said: %s ' %\n                (video_id, warning))\n\n        # Adult content\n        if re.search('EroConfirmText\">', video_page) is not None:\n            self.report_age_confirmation()\n            confirm_string = self._html_search_regex(\n                r'<a href=\"/video/view/\\?id=%s&confirm=([^\"]+)\" title=\"[^\"]+\">' % video_id,\n                video_page, 'confirm string')\n            confirm_url = video_page_url + '&confirm=%s' % confirm_string\n            video_page = self._download_webpage(confirm_url, video_id, 'Downloading video page (age confirmed)')\n            adult_content = True\n        else:\n            adult_content = False\n\n        # Extract the rest of meta data\n        video_title = self._search_meta('name', video_page, 'title')\n        if not video_title:\n            video_title = os.path.splitext(url_basename(video_url))[0]\n\n        video_description = self._search_meta('description', video_page)\n        END_TEXT = ' \u043d\u0430 \u0441\u0430\u0439\u0442\u0435 Smotri.com'\n        if video_description and video_description.endswith(END_TEXT):\n            video_description = video_description[:-len(END_TEXT)]\n        START_TEXT = '\u0421\u043c\u043e\u0442\u0440\u0435\u0442\u044c \u043e\u043d\u043b\u0430\u0439\u043d \u0440\u043e\u043b\u0438\u043a '\n        if video_description and video_description.startswith(START_TEXT):\n            video_description = video_description[len(START_TEXT):]\n        video_thumbnail = self._search_meta('thumbnail', video_page)\n\n        upload_date_str = self._search_meta('uploadDate', video_page, 'upload date')\n        if upload_date_str:\n            upload_date_m = re.search(r'(?P<year>\\d{4})\\.(?P<month>\\d{2})\\.(?P<day>\\d{2})T', upload_date_str)\n            video_upload_date = (\n                (\n                    upload_date_m.group('year') +\n                    upload_date_m.group('month') +\n                    upload_date_m.group('day')\n                )\n                if upload_date_m else None\n            )\n        else:\n            video_upload_date = None\n\n        duration_str = self._search_meta('duration', video_page)\n        if duration_str:\n            duration_m = re.search(r'T(?P<hours>[0-9]{2})H(?P<minutes>[0-9]{2})M(?P<seconds>[0-9]{2})S', duration_str)\n            video_duration = (\n                (\n                    (int(duration_m.group('hours')) * 60 * 60) +\n                    (int(duration_m.group('minutes')) * 60) +\n                    int(duration_m.group('seconds'))\n                )\n                if duration_m else None\n            )\n        else:\n            video_duration = None\n\n        video_uploader = self._html_search_regex(\n            '<div class=\"DescrUser\"><div>\u0410\u0432\u0442\u043e\u0440.*?onmouseover=\"popup_user_info[^\"]+\">(.*?)</a>',\n            video_page, 'uploader', fatal=False, flags=re.MULTILINE|re.DOTALL)\n\n        video_uploader_id = self._html_search_regex(\n            '<div class=\"DescrUser\"><div>\u0410\u0432\u0442\u043e\u0440.*?onmouseover=\"popup_user_info\\\\(.*?\\'([^\\']+)\\'\\\\);\">',\n            video_page, 'uploader id', fatal=False, flags=re.MULTILINE|re.DOTALL)\n\n        video_view_count = self._html_search_regex(\n            '\u041e\u0431\u0449\u0435\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0440\u043e\u0441\u043c\u043e\u0442\u0440\u043e\u0432.*?<span class=\"Number\">(\\\\d+)</span>',\n            video_page, 'view count', fatal=False, flags=re.MULTILINE|re.DOTALL)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': video_title,\n            'thumbnail': video_thumbnail,\n            'description': video_description,\n            'uploader': video_uploader,\n            'upload_date': video_upload_date,\n            'uploader_id': video_uploader_id,\n            'duration': video_duration,\n            'view_count': int_or_none(video_view_count),\n            'age_limit': 18 if adult_content else 0,\n            'video_page_url': video_page_url\n        }",
        "begin_line": 139,
        "end_line": 263,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0010030090270812437,
            "pseudo_dstar_susp": 0.0007739938080495357,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0007739938080495357,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.smotri.SmotriCommunityIE._real_extract#279",
        "src_path": "youtube_dl/extractor/smotri.py",
        "class_name": "youtube_dl.extractor.smotri.SmotriCommunityIE",
        "signature": "youtube_dl.extractor.smotri.SmotriCommunityIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        community_id = mobj.group('communityid')\n\n        url = 'http://smotri.com/export/rss/video/by/community/-/%s/video.xml' % community_id\n        rss = self._download_xml(url, community_id, 'Downloading community RSS')\n\n        entries = [self.url_result(video_url.text, 'Smotri')\n                   for video_url in rss.findall('./channel/item/link')]\n\n        description_text = rss.find('./channel/description').text\n        community_title = self._html_search_regex(\n            '^\u0412\u0438\u0434\u0435\u043e \u0441\u043e\u043e\u0431\u0449\u0435\u0441\u0442\u0432\u0430 \"([^\"]+)\"$', description_text, 'community title')\n\n        return self.playlist_result(entries, community_id, community_title)",
        "begin_line": 279,
        "end_line": 293,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.smotri.SmotriUserIE._real_extract#309",
        "src_path": "youtube_dl/extractor/smotri.py",
        "class_name": "youtube_dl.extractor.smotri.SmotriUserIE",
        "signature": "youtube_dl.extractor.smotri.SmotriUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        user_id = mobj.group('userid')\n\n        url = 'http://smotri.com/export/rss/user/video/-/%s/video.xml' % user_id\n        rss = self._download_xml(url, user_id, 'Downloading user RSS')\n\n        entries = [self.url_result(video_url.text, 'Smotri')\n                   for video_url in rss.findall('./channel/item/link')]\n\n        description_text = rss.find('./channel/description').text\n        user_nickname = self._html_search_regex(\n            '^\u0412\u0438\u0434\u0435\u043e \u0440\u0435\u0436\u0438\u0441\u0441\u0435\u0440\u0430 (.*)$', description_text,\n            'user nickname')\n\n        return self.playlist_result(entries, user_id, user_nickname)",
        "begin_line": 309,
        "end_line": 324,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.smotri.SmotriBroadcastIE._real_extract#332",
        "src_path": "youtube_dl/extractor/smotri.py",
        "class_name": "youtube_dl.extractor.smotri.SmotriBroadcastIE",
        "signature": "youtube_dl.extractor.smotri.SmotriBroadcastIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        broadcast_id = mobj.group('broadcastid')\n\n        broadcast_url = 'http://' + mobj.group('url')\n        broadcast_page = self._download_webpage(broadcast_url, broadcast_id, 'Downloading broadcast page')\n\n        if re.search('>\u0420\u0435\u0436\u0438\u0441\u0441\u0435\u0440 \u0441 \u043b\u043e\u0433\u0438\u043d\u043e\u043c <br/>\"%s\"<br/> <span>\u043d\u0435 \u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0443\u0435\u0442<' % broadcast_id, broadcast_page) is not None:\n            raise ExtractorError('Broadcast %s does not exist' % broadcast_id, expected=True)\n\n        # Adult content\n        if re.search('EroConfirmText\">', broadcast_page) is not None:\n\n            (username, password) = self._get_login_info()\n            if username is None:\n                raise ExtractorError('Erotic broadcasts allowed only for registered users, '\n                    'use --username and --password options to provide account credentials.', expected=True)\n\n            login_form = {\n                'login-hint53': '1',\n                'confirm_erotic': '1',\n                'login': username,\n                'password': password,\n            }\n\n            request = compat_urllib_request.Request(broadcast_url + '/?no_redirect=1', compat_urllib_parse.urlencode(login_form))\n            request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n            broadcast_page = self._download_webpage(request, broadcast_id, 'Logging in and confirming age')\n\n            if re.search('>\u041d\u0435\u0432\u0435\u0440\u043d\u044b\u0439 \u043b\u043e\u0433\u0438\u043d \u0438\u043b\u0438 \u043f\u0430\u0440\u043e\u043b\u044c<', broadcast_page) is not None:\n                raise ExtractorError('Unable to log in: bad username or password', expected=True)\n\n            adult_content = True\n        else:\n            adult_content = False\n\n        ticket = self._html_search_regex(\n            'window\\.broadcast_control\\.addFlashVar\\\\(\\'file\\', \\'([^\\']+)\\'\\\\);',\n            broadcast_page, 'broadcast ticket')\n\n        url = 'http://smotri.com/broadcast/view/url/?ticket=%s' % ticket\n\n        broadcast_password = self._downloader.params.get('videopassword', None)\n        if broadcast_password:\n            url += '&pass=%s' % hashlib.md5(broadcast_password.encode('utf-8')).hexdigest()\n\n        broadcast_json_page = self._download_webpage(url, broadcast_id, 'Downloading broadcast JSON')\n\n        try:\n            broadcast_json = json.loads(broadcast_json_page)\n\n            protected_broadcast = broadcast_json['_pass_protected'] == 1\n            if protected_broadcast and not broadcast_password:\n                raise ExtractorError('This broadcast is protected by a password, use the --video-password option', expected=True)\n\n            broadcast_offline = broadcast_json['is_play'] == 0\n            if broadcast_offline:\n                raise ExtractorError('Broadcast %s is offline' % broadcast_id, expected=True)\n\n            rtmp_url = broadcast_json['_server']\n            if not rtmp_url.startswith('rtmp://'):\n                raise ExtractorError('Unexpected broadcast rtmp URL')\n\n            broadcast_playpath = broadcast_json['_streamName']\n            broadcast_thumbnail = broadcast_json['_imgURL']\n            broadcast_title = broadcast_json['title']\n            broadcast_description = broadcast_json['description']\n            broadcaster_nick = broadcast_json['nick']\n            broadcaster_login = broadcast_json['login']\n            rtmp_conn = 'S:%s' % uuid.uuid4().hex\n        except KeyError:\n            if protected_broadcast:\n                raise ExtractorError('Bad broadcast password', expected=True)\n            raise ExtractorError('Unexpected broadcast JSON')\n\n        return {\n            'id': broadcast_id,\n            'url': rtmp_url,\n            'title': broadcast_title,\n            'thumbnail': broadcast_thumbnail,\n            'description': broadcast_description,\n            'uploader': broadcaster_nick,\n            'uploader_id': broadcaster_login,\n            'age_limit': 18 if adult_content else 0,\n            'ext': 'flv',\n            'play_path': broadcast_playpath,\n            'rtmp_live': True,\n            'rtmp_conn': rtmp_conn\n        }",
        "begin_line": 332,
        "end_line": 420,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.patreon.PatreonIE._real_extract#67",
        "src_path": "youtube_dl/extractor/patreon.py",
        "class_name": "youtube_dl.extractor.patreon.PatreonIE",
        "signature": "youtube_dl.extractor.patreon.PatreonIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group(1)\n\n        webpage = self._download_webpage(url, video_id)\n        title = self._og_search_title(webpage).strip()\n\n        attach_fn = self._html_search_regex(\n            r'<div class=\"attach\"><a target=\"_blank\" href=\"([^\"]+)\">',\n            webpage, 'attachment URL', default=None)\n        if attach_fn is not None:\n            video_url = 'http://www.patreon.com' + attach_fn\n            thumbnail = self._og_search_thumbnail(webpage)\n            uploader = self._html_search_regex(\n                r'<strong>(.*?)</strong> is creating', webpage, 'uploader')\n        else:\n            playlist_js = self._search_regex(\n                r'(?s)new\\s+jPlayerPlaylist\\(\\s*\\{\\s*[^}]*},\\s*(\\[.*?,?\\s*\\])',\n                webpage, 'playlist JSON')\n            playlist_json = js_to_json(playlist_js)\n            playlist = json.loads(playlist_json)\n            data = playlist[0]\n            video_url = self._proto_relative_url(data['mp3'])\n            thumbnail = self._proto_relative_url(data.get('cover'))\n            uploader = data.get('artist')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'ext': 'mp3',\n            'title': title,\n            'uploader': uploader,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 67,
        "end_line": 100,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.options.parseOpts#15",
        "src_path": "youtube_dl/options.py",
        "class_name": "youtube_dl.options",
        "signature": "youtube_dl.options.parseOpts(overrideArguments=None)",
        "snippet": "def parseOpts(overrideArguments=None):\n    def _readOptions(filename_bytes, default=[]):\n        try:\n            optionf = open(filename_bytes)\n        except IOError:\n            return default  # silently skip if file is not present\n        try:\n            res = []\n            for l in optionf:\n                res += shlex.split(l, comments=True)\n        finally:\n            optionf.close()\n        return res\n\n    def _readUserConf():\n        xdg_config_home = os.environ.get('XDG_CONFIG_HOME')\n        if xdg_config_home:\n            userConfFile = os.path.join(xdg_config_home, 'youtube-dl', 'config')\n            if not os.path.isfile(userConfFile):\n                userConfFile = os.path.join(xdg_config_home, 'youtube-dl.conf')\n        else:\n            userConfFile = os.path.join(os.path.expanduser('~'), '.config', 'youtube-dl', 'config')\n            if not os.path.isfile(userConfFile):\n                userConfFile = os.path.join(os.path.expanduser('~'), '.config', 'youtube-dl.conf')\n        userConf = _readOptions(userConfFile, None)\n\n        if userConf is None:\n            appdata_dir = os.environ.get('appdata')\n            if appdata_dir:\n                userConf = _readOptions(\n                    os.path.join(appdata_dir, 'youtube-dl', 'config'),\n                    default=None)\n                if userConf is None:\n                    userConf = _readOptions(\n                        os.path.join(appdata_dir, 'youtube-dl', 'config.txt'),\n                        default=None)\n\n        if userConf is None:\n            userConf = _readOptions(\n                os.path.join(os.path.expanduser('~'), 'youtube-dl.conf'),\n                default=None)\n        if userConf is None:\n            userConf = _readOptions(\n                os.path.join(os.path.expanduser('~'), 'youtube-dl.conf.txt'),\n                default=None)\n\n        if userConf is None:\n            userConf = []\n\n        return userConf\n\n    def _format_option_string(option):\n        ''' ('-o', '--option') -> -o, --format METAVAR'''\n\n        opts = []\n\n        if option._short_opts:\n            opts.append(option._short_opts[0])\n        if option._long_opts:\n            opts.append(option._long_opts[0])\n        if len(opts) > 1:\n            opts.insert(1, ', ')\n\n        if option.takes_value(): opts.append(' %s' % option.metavar)\n\n        return \"\".join(opts)\n\n    def _comma_separated_values_options_callback(option, opt_str, value, parser):\n        setattr(parser.values, option.dest, value.split(','))\n\n    def _hide_login_info(opts):\n        opts = list(opts)\n        for private_opt in ['-p', '--password', '-u', '--username', '--video-password']:\n            try:\n                i = opts.index(private_opt)\n                opts[i+1] = '<PRIVATE>'\n            except ValueError:\n                pass\n        return opts\n\n    max_width = 80\n    max_help_position = 80\n\n    # No need to wrap help messages if we're on a wide console\n    columns = get_term_width()\n    if columns: max_width = columns\n\n    fmt = optparse.IndentedHelpFormatter(width=max_width, max_help_position=max_help_position)\n    fmt.format_option_strings = _format_option_string\n\n    kw = {\n        'version'   : __version__,\n        'formatter' : fmt,\n        'usage' : '%prog [options] url [url...]',\n        'conflict_handler' : 'resolve',\n    }\n\n    parser = optparse.OptionParser(**kw)\n\n    # option groups\n    general        = optparse.OptionGroup(parser, 'General Options')\n    selection      = optparse.OptionGroup(parser, 'Video Selection')\n    authentication = optparse.OptionGroup(parser, 'Authentication Options')\n    video_format   = optparse.OptionGroup(parser, 'Video Format Options')\n    subtitles      = optparse.OptionGroup(parser, 'Subtitle Options')\n    downloader     = optparse.OptionGroup(parser, 'Download Options')\n    postproc       = optparse.OptionGroup(parser, 'Post-processing Options')\n    filesystem     = optparse.OptionGroup(parser, 'Filesystem Options')\n    workarounds    = optparse.OptionGroup(parser, 'Workarounds')\n    verbosity      = optparse.OptionGroup(parser, 'Verbosity / Simulation Options')\n\n    general.add_option('-h', '--help',\n            action='help', help='print this help text and exit')\n    general.add_option('-v', '--version',\n            action='version', help='print program version and exit')\n    general.add_option('-U', '--update',\n            action='store_true', dest='update_self', help='update this program to latest version. Make sure that you have sufficient permissions (run with sudo if needed)')\n    general.add_option('-i', '--ignore-errors',\n            action='store_true', dest='ignoreerrors', help='continue on download errors, for example to skip unavailable videos in a playlist', default=False)\n    general.add_option('--abort-on-error',\n            action='store_false', dest='ignoreerrors',\n            help='Abort downloading of further videos (in the playlist or the command line) if an error occurs')\n    general.add_option('--dump-user-agent',\n            action='store_true', dest='dump_user_agent',\n            help='display the current browser identification', default=False)\n    general.add_option('--list-extractors',\n            action='store_true', dest='list_extractors',\n            help='List all supported extractors and the URLs they would handle', default=False)\n    general.add_option('--extractor-descriptions',\n            action='store_true', dest='list_extractor_descriptions',\n            help='Output descriptions of all supported extractors', default=False)\n    general.add_option(\n        '--proxy', dest='proxy', default=None, metavar='URL',\n        help='Use the specified HTTP/HTTPS proxy. Pass in an empty string (--proxy \"\") for direct connection')\n    general.add_option(\n        '--socket-timeout', dest='socket_timeout',\n        type=float, default=None, help=u'Time to wait before giving up, in seconds')\n    general.add_option(\n        '--default-search',\n        dest='default_search', metavar='PREFIX',\n        help='Use this prefix for unqualified URLs. For example \"gvsearch2:\" downloads two videos from google videos for  youtube-dl \"large apple\". Use the value \"auto\" to let youtube-dl guess (\"auto_warning\" to emit a warning when guessing). \"error\" just throws an error. The default value \"fixup_error\" repairs broken URLs, but emits an error if this is not possible instead of searching.')\n    general.add_option(\n        '--ignore-config',\n        action='store_true',\n        help='Do not read configuration files. When given in the global configuration file /etc/youtube-dl.conf: do not read the user configuration in ~/.config/youtube-dl.conf (%APPDATA%/youtube-dl/config.txt on Windows)')\n\n    selection.add_option(\n        '--playlist-start',\n        dest='playliststart', metavar='NUMBER', default=1, type=int,\n        help='playlist video to start at (default is %default)')\n    selection.add_option(\n        '--playlist-end',\n        dest='playlistend', metavar='NUMBER', default=None, type=int,\n        help='playlist video to end at (default is last)')\n    selection.add_option('--match-title', dest='matchtitle', metavar='REGEX',help='download only matching titles (regex or caseless sub-string)')\n    selection.add_option('--reject-title', dest='rejecttitle', metavar='REGEX',help='skip download for matching titles (regex or caseless sub-string)')\n    selection.add_option('--max-downloads', metavar='NUMBER',\n                         dest='max_downloads', type=int, default=None,\n                         help='Abort after downloading NUMBER files')\n    selection.add_option('--min-filesize', metavar='SIZE', dest='min_filesize', help=\"Do not download any videos smaller than SIZE (e.g. 50k or 44.6m)\", default=None)\n    selection.add_option('--max-filesize', metavar='SIZE', dest='max_filesize', help=\"Do not download any videos larger than SIZE (e.g. 50k or 44.6m)\", default=None)\n    selection.add_option('--date', metavar='DATE', dest='date', help='download only videos uploaded in this date', default=None)\n    selection.add_option(\n        '--datebefore', metavar='DATE', dest='datebefore', default=None,\n        help='download only videos uploaded on or before this date (i.e. inclusive)')\n    selection.add_option(\n        '--dateafter', metavar='DATE', dest='dateafter', default=None,\n        help='download only videos uploaded on or after this date (i.e. inclusive)')\n    selection.add_option(\n        '--min-views', metavar='COUNT', dest='min_views',\n        default=None, type=int,\n        help=\"Do not download any videos with less than COUNT views\",)\n    selection.add_option(\n        '--max-views', metavar='COUNT', dest='max_views',\n        default=None, type=int,\n        help=\"Do not download any videos with more than COUNT views\",)\n    selection.add_option('--no-playlist', action='store_true', dest='noplaylist', help='download only the currently playing video', default=False)\n    selection.add_option('--age-limit', metavar='YEARS', dest='age_limit',\n                         help='download only videos suitable for the given age',\n                         default=None, type=int)\n    selection.add_option('--download-archive', metavar='FILE',\n                         dest='download_archive',\n                         help='Download only videos not listed in the archive file. Record the IDs of all downloaded videos in it.')\n    selection.add_option(\n        '--include-ads', dest='include_ads',\n        action='store_true',\n        help='Download advertisements as well (experimental)')\n    selection.add_option(\n        '--youtube-include-dash-manifest', action='store_true',\n        dest='youtube_include_dash_manifest', default=False,\n        help='Try to download the DASH manifest on YouTube videos (experimental)')\n\n    authentication.add_option('-u', '--username',\n            dest='username', metavar='USERNAME', help='account username')\n    authentication.add_option('-p', '--password',\n            dest='password', metavar='PASSWORD', help='account password')\n    authentication.add_option('-2', '--twofactor',\n            dest='twofactor', metavar='TWOFACTOR', help='two-factor auth code')\n    authentication.add_option('-n', '--netrc',\n            action='store_true', dest='usenetrc', help='use .netrc authentication data', default=False)\n    authentication.add_option('--video-password',\n            dest='videopassword', metavar='PASSWORD', help='video password (vimeo, smotri)')\n\n\n    video_format.add_option('-f', '--format',\n            action='store', dest='format', metavar='FORMAT', default=None,\n            help='video format code, specify the order of preference using slashes: \"-f 22/17/18\". \"-f mp4\" and \"-f flv\" are also supported. You can also use the special names \"best\", \"bestvideo\", \"bestaudio\", \"worst\", \"worstvideo\" and \"worstaudio\". By default, youtube-dl will pick the best quality.')\n    video_format.add_option('--all-formats',\n            action='store_const', dest='format', help='download all available video formats', const='all')\n    video_format.add_option('--prefer-free-formats',\n            action='store_true', dest='prefer_free_formats', default=False, help='prefer free video formats unless a specific one is requested')\n    video_format.add_option('--max-quality',\n            action='store', dest='format_limit', metavar='FORMAT', help='highest quality format to download')\n    video_format.add_option('-F', '--list-formats',\n            action='store_true', dest='listformats', help='list all available formats')\n\n    subtitles.add_option('--write-sub', '--write-srt',\n            action='store_true', dest='writesubtitles',\n            help='write subtitle file', default=False)\n    subtitles.add_option('--write-auto-sub', '--write-automatic-sub',\n            action='store_true', dest='writeautomaticsub',\n            help='write automatic subtitle file (youtube only)', default=False)\n    subtitles.add_option('--all-subs',\n            action='store_true', dest='allsubtitles',\n            help='downloads all the available subtitles of the video', default=False)\n    subtitles.add_option('--list-subs',\n            action='store_true', dest='listsubtitles',\n            help='lists all available subtitles for the video', default=False)\n    subtitles.add_option('--sub-format',\n            action='store', dest='subtitlesformat', metavar='FORMAT',\n            help='subtitle format (default=srt) ([sbv/vtt] youtube only)', default='srt')\n    subtitles.add_option('--sub-lang', '--sub-langs', '--srt-lang',\n            action='callback', dest='subtitleslangs', metavar='LANGS', type='str',\n            default=[], callback=_comma_separated_values_options_callback,\n            help='languages of the subtitles to download (optional) separated by commas, use IETF language tags like \\'en,pt\\'')\n\n    downloader.add_option('-r', '--rate-limit',\n            dest='ratelimit', metavar='LIMIT', help='maximum download rate in bytes per second (e.g. 50K or 4.2M)')\n    downloader.add_option('-R', '--retries',\n            dest='retries', metavar='RETRIES', help='number of retries (default is %default)', default=10)\n    downloader.add_option('--buffer-size',\n            dest='buffersize', metavar='SIZE', help='size of download buffer (e.g. 1024 or 16K) (default is %default)', default=\"1024\")\n    downloader.add_option('--no-resize-buffer',\n            action='store_true', dest='noresizebuffer',\n            help='do not automatically adjust the buffer size. By default, the buffer size is automatically resized from an initial value of SIZE.', default=False)\n    downloader.add_option('--test', action='store_true', dest='test', default=False, help=optparse.SUPPRESS_HELP)\n\n    workarounds.add_option(\n        '--encoding', dest='encoding', metavar='ENCODING',\n        help='Force the specified encoding (experimental)')\n    workarounds.add_option(\n        '--no-check-certificate', action='store_true',\n        dest='no_check_certificate', default=False,\n        help='Suppress HTTPS certificate validation.')\n    workarounds.add_option(\n        '--prefer-insecure', '--prefer-unsecure', action='store_true', dest='prefer_insecure',\n        help='Use an unencrypted connection to retrieve information about the video. (Currently supported only for YouTube)')\n    workarounds.add_option(\n        '--user-agent', metavar='UA',\n        dest='user_agent', help='specify a custom user agent')\n    workarounds.add_option(\n        '--referer', metavar='REF',\n        dest='referer', default=None,\n        help='specify a custom referer, use if the video access is restricted to one domain',\n    )\n    workarounds.add_option(\n        '--add-header', metavar='FIELD:VALUE',\n        dest='headers', action='append',\n        help='specify a custom HTTP header and its value, separated by a colon \\':\\'. You can use this option multiple times',\n    )\n    workarounds.add_option(\n        '--bidi-workaround', dest='bidi_workaround', action='store_true',\n        help=u'Work around terminals that lack bidirectional text support. Requires bidiv or fribidi executable in PATH')\n\n    verbosity.add_option('-q', '--quiet',\n            action='store_true', dest='quiet', help='activates quiet mode', default=False)\n    verbosity.add_option(\n        '--no-warnings',\n        dest='no_warnings', action='store_true', default=False,\n        help='Ignore warnings')\n    verbosity.add_option('-s', '--simulate',\n            action='store_true', dest='simulate', help='do not download the video and do not write anything to disk', default=False)\n    verbosity.add_option('--skip-download',\n            action='store_true', dest='skip_download', help='do not download the video', default=False)\n    verbosity.add_option('-g', '--get-url',\n            action='store_true', dest='geturl', help='simulate, quiet but print URL', default=False)\n    verbosity.add_option('-e', '--get-title',\n            action='store_true', dest='gettitle', help='simulate, quiet but print title', default=False)\n    verbosity.add_option('--get-id',\n            action='store_true', dest='getid', help='simulate, quiet but print id', default=False)\n    verbosity.add_option('--get-thumbnail',\n            action='store_true', dest='getthumbnail',\n            help='simulate, quiet but print thumbnail URL', default=False)\n    verbosity.add_option('--get-description',\n            action='store_true', dest='getdescription',\n            help='simulate, quiet but print video description', default=False)\n    verbosity.add_option('--get-duration',\n            action='store_true', dest='getduration',\n            help='simulate, quiet but print video length', default=False)\n    verbosity.add_option('--get-filename',\n            action='store_true', dest='getfilename',\n            help='simulate, quiet but print output filename', default=False)\n    verbosity.add_option('--get-format',\n            action='store_true', dest='getformat',\n            help='simulate, quiet but print output format', default=False)\n    verbosity.add_option('-j', '--dump-json',\n            action='store_true', dest='dumpjson',\n            help='simulate, quiet but print JSON information. See --output for a description of available keys.', default=False)\n    verbosity.add_option('--newline',\n            action='store_true', dest='progress_with_newline', help='output progress bar as new lines', default=False)\n    verbosity.add_option('--no-progress',\n            action='store_true', dest='noprogress', help='do not print progress bar', default=False)\n    verbosity.add_option('--console-title',\n            action='store_true', dest='consoletitle',\n            help='display progress in console titlebar', default=False)\n    verbosity.add_option('-v', '--verbose',\n            action='store_true', dest='verbose', help='print various debugging information', default=False)\n    verbosity.add_option('--dump-intermediate-pages',\n            action='store_true', dest='dump_intermediate_pages', default=False,\n            help='print downloaded pages to debug problems (very verbose)')\n    verbosity.add_option('--write-pages',\n            action='store_true', dest='write_pages', default=False,\n            help='Write downloaded intermediary pages to files in the current directory to debug problems')\n    verbosity.add_option('--youtube-print-sig-code',\n            action='store_true', dest='youtube_print_sig_code', default=False,\n            help=optparse.SUPPRESS_HELP)\n    verbosity.add_option('--print-traffic',\n            dest='debug_printtraffic', action='store_true', default=False,\n            help='Display sent and read HTTP traffic')\n\n\n    filesystem.add_option('-a', '--batch-file',\n            dest='batchfile', metavar='FILE', help='file containing URLs to download (\\'-\\' for stdin)')\n    filesystem.add_option('--id',\n            action='store_true', dest='useid', help='use only video ID in file name', default=False)\n    filesystem.add_option('-A', '--auto-number',\n            action='store_true', dest='autonumber',\n            help='number downloaded files starting from 00000', default=False)\n    filesystem.add_option('-o', '--output',\n            dest='outtmpl', metavar='TEMPLATE',\n            help=('output filename template. Use %(title)s to get the title, '\n                  '%(uploader)s for the uploader name, %(uploader_id)s for the uploader nickname if different, '\n                  '%(autonumber)s to get an automatically incremented number, '\n                  '%(ext)s for the filename extension, '\n                  '%(format)s for the format description (like \"22 - 1280x720\" or \"HD\"), '\n                  '%(format_id)s for the unique id of the format (like Youtube\\'s itags: \"137\"), '\n                  '%(upload_date)s for the upload date (YYYYMMDD), '\n                  '%(extractor)s for the provider (youtube, metacafe, etc), '\n                  '%(id)s for the video id, %(playlist)s for the playlist the video is in, '\n                  '%(playlist_index)s for the position in the playlist and %% for a literal percent. '\n                  '%(height)s and %(width)s for the width and height of the video format. '\n                  '%(resolution)s for a textual description of the resolution of the video format. '\n                  'Use - to output to stdout. Can also be used to download to a different directory, '\n                  'for example with -o \\'/my/downloads/%(uploader)s/%(title)s-%(id)s.%(ext)s\\' .'))\n    filesystem.add_option('--autonumber-size',\n            dest='autonumber_size', metavar='NUMBER',\n            help='Specifies the number of digits in %(autonumber)s when it is present in output filename template or --auto-number option is given')\n    filesystem.add_option('--restrict-filenames',\n            action='store_true', dest='restrictfilenames',\n            help='Restrict filenames to only ASCII characters, and avoid \"&\" and spaces in filenames', default=False)\n    filesystem.add_option('-t', '--title',\n            action='store_true', dest='usetitle', help='[deprecated] use title in file name (default)', default=False)\n    filesystem.add_option('-l', '--literal',\n            action='store_true', dest='usetitle', help='[deprecated] alias of --title', default=False)\n    filesystem.add_option('-w', '--no-overwrites',\n            action='store_true', dest='nooverwrites', help='do not overwrite files', default=False)\n    filesystem.add_option('-c', '--continue',\n            action='store_true', dest='continue_dl', help='force resume of partially downloaded files. By default, youtube-dl will resume downloads if possible.', default=True)\n    filesystem.add_option('--no-continue',\n            action='store_false', dest='continue_dl',\n            help='do not resume partially downloaded files (restart from beginning)')\n    filesystem.add_option('--no-part',\n            action='store_true', dest='nopart', help='do not use .part files', default=False)\n    filesystem.add_option('--no-mtime',\n            action='store_false', dest='updatetime',\n            help='do not use the Last-modified header to set the file modification time', default=True)\n    filesystem.add_option('--write-description',\n            action='store_true', dest='writedescription',\n            help='write video description to a .description file', default=False)\n    filesystem.add_option('--write-info-json',\n            action='store_true', dest='writeinfojson',\n            help='write video metadata to a .info.json file', default=False)\n    filesystem.add_option('--write-annotations',\n            action='store_true', dest='writeannotations',\n            help='write video annotations to a .annotation file', default=False)\n    filesystem.add_option('--write-thumbnail',\n            action='store_true', dest='writethumbnail',\n            help='write thumbnail image to disk', default=False)\n    filesystem.add_option('--load-info',\n            dest='load_info_filename', metavar='FILE',\n            help='json file containing the video information (created with the \"--write-json\" option)')\n    filesystem.add_option('--cookies',\n            dest='cookiefile', metavar='FILE', help='file to read cookies from and dump cookie jar in')\n    filesystem.add_option(\n        '--cache-dir', dest='cachedir', default=None, metavar='DIR',\n        help='Location in the filesystem where youtube-dl can store some downloaded information permanently. By default $XDG_CACHE_HOME/youtube-dl or ~/.cache/youtube-dl . At the moment, only YouTube player files (for videos with obfuscated signatures) are cached, but that may change.')\n    filesystem.add_option(\n        '--no-cache-dir', action='store_const', const=False, dest='cachedir',\n        help='Disable filesystem caching')\n    filesystem.add_option(\n        '--rm-cache-dir', action='store_true', dest='rm_cachedir',\n        help='Delete all filesystem cache files')\n\n\n    postproc.add_option('-x', '--extract-audio', action='store_true', dest='extractaudio', default=False,\n            help='convert video files to audio-only files (requires ffmpeg or avconv and ffprobe or avprobe)')\n    postproc.add_option('--audio-format', metavar='FORMAT', dest='audioformat', default='best',\n            help='\"best\", \"aac\", \"vorbis\", \"mp3\", \"m4a\", \"opus\", or \"wav\"; best by default')\n    postproc.add_option('--audio-quality', metavar='QUALITY', dest='audioquality', default='5',\n            help='ffmpeg/avconv audio quality specification, insert a value between 0 (better) and 9 (worse) for VBR or a specific bitrate like 128K (default 5)')\n    postproc.add_option('--recode-video', metavar='FORMAT', dest='recodevideo', default=None,\n            help='Encode the video to another format if necessary (currently supported: mp4|flv|ogg|webm|mkv)')\n    postproc.add_option('-k', '--keep-video', action='store_true', dest='keepvideo', default=False,\n            help='keeps the video file on disk after the post-processing; the video is erased by default')\n    postproc.add_option('--no-post-overwrites', action='store_true', dest='nopostoverwrites', default=False,\n            help='do not overwrite post-processed files; the post-processed files are overwritten by default')\n    postproc.add_option('--embed-subs', action='store_true', dest='embedsubtitles', default=False,\n            help='embed subtitles in the video (only for mp4 videos)')\n    postproc.add_option('--embed-thumbnail', action='store_true', dest='embedthumbnail', default=False,\n            help='embed thumbnail in the audio as cover art')\n    postproc.add_option('--add-metadata', action='store_true', dest='addmetadata', default=False,\n            help='write metadata to the video file')\n    postproc.add_option('--xattrs', action='store_true', dest='xattrs', default=False,\n            help='write metadata to the video file\\'s xattrs (using dublin core and xdg standards)')\n    postproc.add_option('--prefer-avconv', action='store_false', dest='prefer_ffmpeg',\n        help='Prefer avconv over ffmpeg for running the postprocessors (default)')\n    postproc.add_option('--prefer-ffmpeg', action='store_true', dest='prefer_ffmpeg',\n        help='Prefer ffmpeg over avconv for running the postprocessors')\n    postproc.add_option(\n        '--exec', metavar='CMD', dest='exec_cmd',\n        help='Execute a command on the file after downloading, similar to find\\'s -exec syntax. Example: --exec \\'adb push {} /sdcard/Music/ && rm {}\\'' )\n\n    parser.add_option_group(general)\n    parser.add_option_group(selection)\n    parser.add_option_group(downloader)\n    parser.add_option_group(filesystem)\n    parser.add_option_group(verbosity)\n    parser.add_option_group(workarounds)\n    parser.add_option_group(video_format)\n    parser.add_option_group(subtitles)\n    parser.add_option_group(authentication)\n    parser.add_option_group(postproc)\n\n    if overrideArguments is not None:\n        opts, args = parser.parse_args(overrideArguments)\n        if opts.verbose:\n            write_string(u'[debug] Override config: ' + repr(overrideArguments) + '\\n')\n    else:\n        commandLineConf = sys.argv[1:]\n        if '--ignore-config' in commandLineConf:\n            systemConf = []\n            userConf = []\n        else:\n            systemConf = _readOptions('/etc/youtube-dl.conf')\n            if '--ignore-config' in systemConf:\n                userConf = []\n            else:\n                userConf = _readUserConf()\n        argv = systemConf + userConf + commandLineConf\n\n        opts, args = parser.parse_args(argv)\n        if opts.verbose:\n            write_string(u'[debug] System config: ' + repr(_hide_login_info(systemConf)) + '\\n')\n            write_string(u'[debug] User config: ' + repr(_hide_login_info(userConf)) + '\\n')\n            write_string(u'[debug] Command-line args: ' + repr(_hide_login_info(commandLineConf)) + '\\n')\n\n    return parser, opts, args",
        "begin_line": 15,
        "end_line": 481,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.0001840942562592047,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.options._readOptions#16",
        "src_path": "youtube_dl/options.py",
        "class_name": "youtube_dl.options",
        "signature": "youtube_dl.options._readOptions(filename_bytes, default=[])",
        "snippet": "    def _readOptions(filename_bytes, default=[]):\n        try:\n            optionf = open(filename_bytes)\n        except IOError:\n            return default  # silently skip if file is not present\n        try:\n            res = []\n            for l in optionf:\n                res += shlex.split(l, comments=True)\n        finally:\n            optionf.close()\n        return res",
        "begin_line": 16,
        "end_line": 27,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.0001840942562592047,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.options._readUserConf#29",
        "src_path": "youtube_dl/options.py",
        "class_name": "youtube_dl.options",
        "signature": "youtube_dl.options._readUserConf()",
        "snippet": "    def _readUserConf():\n        xdg_config_home = os.environ.get('XDG_CONFIG_HOME')\n        if xdg_config_home:\n            userConfFile = os.path.join(xdg_config_home, 'youtube-dl', 'config')\n            if not os.path.isfile(userConfFile):\n                userConfFile = os.path.join(xdg_config_home, 'youtube-dl.conf')\n        else:\n            userConfFile = os.path.join(os.path.expanduser('~'), '.config', 'youtube-dl', 'config')\n            if not os.path.isfile(userConfFile):\n                userConfFile = os.path.join(os.path.expanduser('~'), '.config', 'youtube-dl.conf')\n        userConf = _readOptions(userConfFile, None)\n\n        if userConf is None:\n            appdata_dir = os.environ.get('appdata')\n            if appdata_dir:\n                userConf = _readOptions(\n                    os.path.join(appdata_dir, 'youtube-dl', 'config'),\n                    default=None)\n                if userConf is None:\n                    userConf = _readOptions(\n                        os.path.join(appdata_dir, 'youtube-dl', 'config.txt'),\n                        default=None)\n\n        if userConf is None:\n            userConf = _readOptions(\n                os.path.join(os.path.expanduser('~'), 'youtube-dl.conf'),\n                default=None)\n        if userConf is None:\n            userConf = _readOptions(\n                os.path.join(os.path.expanduser('~'), 'youtube-dl.conf.txt'),\n                default=None)\n\n        if userConf is None:\n            userConf = []\n\n        return userConf",
        "begin_line": 29,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.0001840942562592047,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.options._format_option_string#66",
        "src_path": "youtube_dl/options.py",
        "class_name": "youtube_dl.options",
        "signature": "youtube_dl.options._format_option_string(option)",
        "snippet": "    def _format_option_string(option):\n        ''' ('-o', '--option') -> -o, --format METAVAR'''\n\n        opts = []\n\n        if option._short_opts:\n            opts.append(option._short_opts[0])\n        if option._long_opts:\n            opts.append(option._long_opts[0])\n        if len(opts) > 1:\n            opts.insert(1, ', ')\n\n        if option.takes_value(): opts.append(' %s' % option.metavar)\n\n        return \"\".join(opts)",
        "begin_line": 66,
        "end_line": 80,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.0001840942562592047,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.options._comma_separated_values_options_callback#82",
        "src_path": "youtube_dl/options.py",
        "class_name": "youtube_dl.options",
        "signature": "youtube_dl.options._comma_separated_values_options_callback(option, opt_str, value, parser)",
        "snippet": "    def _comma_separated_values_options_callback(option, opt_str, value, parser):\n        setattr(parser.values, option.dest, value.split(','))",
        "begin_line": 82,
        "end_line": 83,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.0001840942562592047,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.options._hide_login_info#85",
        "src_path": "youtube_dl/options.py",
        "class_name": "youtube_dl.options",
        "signature": "youtube_dl.options._hide_login_info(opts)",
        "snippet": "    def _hide_login_info(opts):\n        opts = list(opts)\n        for private_opt in ['-p', '--password', '-u', '--username', '--video-password']:\n            try:\n                i = opts.index(private_opt)\n                opts[i+1] = '<PRIVATE>'\n            except ValueError:\n                pass\n        return opts",
        "begin_line": 85,
        "end_line": 93,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.0001840942562592047,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.engadget.EngadgetIE._real_extract#29",
        "src_path": "youtube_dl/extractor/engadget.py",
        "class_name": "youtube_dl.extractor.engadget.EngadgetIE",
        "signature": "youtube_dl.extractor.engadget.EngadgetIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        if video_id is not None:\n            return FiveMinIE._build_result(video_id)\n        else:\n            title = url_basename(url)\n            webpage = self._download_webpage(url, title)\n            ids = re.findall(r'<iframe[^>]+?playList=(\\d+)', webpage)\n            return {\n                '_type': 'playlist',\n                'title': title,\n                'entries': [FiveMinIE._build_result(id) for id in ids]\n            }",
        "begin_line": 29,
        "end_line": 43,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.videott.VideoTtIE._real_extract#31",
        "src_path": "youtube_dl/extractor/videott.py",
        "class_name": "youtube_dl.extractor.videott.VideoTtIE",
        "signature": "youtube_dl.extractor.videott.VideoTtIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        settings = self._download_json(\n            'http://www.video.tt/player_control/settings.php?v=%s' % video_id, video_id,\n            'Downloading video JSON')['settings']\n\n        video = settings['video_details']['video']\n\n        formats = [\n            {\n                'url': base64.b64decode(res['u']).decode('utf-8'),\n                'ext': 'flv',\n                'format_id': res['l'],\n            } for res in settings['res'] if res['u']\n        ]\n\n        return {\n            'id': video_id,\n            'title': video['title'],\n            'description': video['description'],\n            'thumbnail': settings['config']['thumbnail'],\n            'upload_date': unified_strdate(video['added']),\n            'uploader': video['owner'],\n            'view_count': int_or_none(video['view_count']),\n            'comment_count': None if video.get('comment_count') == '--' else int_or_none(video['comment_count']),\n            'like_count': int_or_none(video['liked']),\n            'dislike_count': int_or_none(video['disliked']),\n            'formats': formats,\n        }",
        "begin_line": 31,
        "end_line": 61,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.servingsys.ServingSysIE._real_extract#43",
        "src_path": "youtube_dl/extractor/servingsys.py",
        "class_name": "youtube_dl.extractor.servingsys.ServingSysIE",
        "signature": "youtube_dl.extractor.servingsys.ServingSysIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        pl_id = mobj.group('id')\n\n        vast_doc = self._download_xml(url, pl_id)\n        title = vast_doc.find('.//AdTitle').text\n        media = vast_doc.find('.//MediaFile').text\n        info_url = self._search_regex(r'&adData=([^&]+)&', media, 'info URL')\n\n        doc = self._download_xml(info_url, pl_id, 'Downloading video info')\n        entries = [{\n            '_type': 'video',\n            'id': a.attrib['id'],\n            'title': '%s (%s)' % (title, a.attrib['assetID']),\n            'url': a.attrib['URL'],\n            'duration': int_or_none(a.attrib.get('length')),\n            'tbr': int_or_none(a.attrib.get('bitrate')),\n            'height': int_or_none(a.attrib.get('height')),\n            'width': int_or_none(a.attrib.get('width')),\n        } for a in doc.findall('.//AdditionalAssets/asset')]\n\n        return {\n            '_type': 'playlist',\n            'id': pl_id,\n            'title': title,\n            'entries': entries,\n        }",
        "begin_line": 43,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.downloader.http.HttpFD.real_download#19",
        "src_path": "youtube_dl/downloader/http.py",
        "class_name": "youtube_dl.downloader.http.HttpFD",
        "signature": "youtube_dl.downloader.http.HttpFD.real_download(self, filename, info_dict)",
        "snippet": "    def real_download(self, filename, info_dict):\n        url = info_dict['url']\n        tmpfilename = self.temp_name(filename)\n        stream = None\n\n        # Do not include the Accept-Encoding header\n        headers = {'Youtubedl-no-compression': 'True'}\n        if 'user_agent' in info_dict:\n            headers['Youtubedl-user-agent'] = info_dict['user_agent']\n        if 'http_referer' in info_dict:\n            headers['Referer'] = info_dict['http_referer']\n        add_headers = info_dict.get('http_headers')\n        if add_headers:\n            headers.update(add_headers)\n        data = info_dict.get('http_post_data')\n        http_method = info_dict.get('http_method')\n        basic_request = compat_urllib_request.Request(url, data, headers)\n        request = compat_urllib_request.Request(url, data, headers)\n        if http_method is not None:\n            basic_request.get_method = lambda: http_method\n            request.get_method = lambda: http_method\n\n        is_test = self.params.get('test', False)\n\n        if is_test:\n            request.add_header('Range', 'bytes=0-%s' % str(self._TEST_FILE_SIZE - 1))\n\n        # Establish possible resume length\n        if os.path.isfile(encodeFilename(tmpfilename)):\n            resume_len = os.path.getsize(encodeFilename(tmpfilename))\n        else:\n            resume_len = 0\n\n        open_mode = 'wb'\n        if resume_len != 0:\n            if self.params.get('continuedl', False):\n                self.report_resuming_byte(resume_len)\n                request.add_header('Range', 'bytes=%d-' % resume_len)\n                open_mode = 'ab'\n            else:\n                resume_len = 0\n\n        count = 0\n        retries = self.params.get('retries', 0)\n        while count <= retries:\n            # Establish connection\n            try:\n                data = self.ydl.urlopen(request)\n                break\n            except (compat_urllib_error.HTTPError, ) as err:\n                if (err.code < 500 or err.code >= 600) and err.code != 416:\n                    # Unexpected HTTP error\n                    raise\n                elif err.code == 416:\n                    # Unable to resume (requested range not satisfiable)\n                    try:\n                        # Open the connection again without the range header\n                        data = self.ydl.urlopen(basic_request)\n                        content_length = data.info()['Content-Length']\n                    except (compat_urllib_error.HTTPError, ) as err:\n                        if err.code < 500 or err.code >= 600:\n                            raise\n                    else:\n                        # Examine the reported length\n                        if (content_length is not None and\n                                (resume_len - 100 < int(content_length) < resume_len + 100)):\n                            # The file had already been fully downloaded.\n                            # Explanation to the above condition: in issue #175 it was revealed that\n                            # YouTube sometimes adds or removes a few bytes from the end of the file,\n                            # changing the file size slightly and causing problems for some users. So\n                            # I decided to implement a suggested change and consider the file\n                            # completely downloaded if the file size differs less than 100 bytes from\n                            # the one in the hard drive.\n                            self.report_file_already_downloaded(filename)\n                            self.try_rename(tmpfilename, filename)\n                            self._hook_progress({\n                                'filename': filename,\n                                'status': 'finished',\n                            })\n                            return True\n                        else:\n                            # The length does not match, we start the download over\n                            self.report_unable_to_resume()\n                            resume_len = 0\n                            open_mode = 'wb'\n                            break\n            # Retry\n            count += 1\n            if count <= retries:\n                self.report_retry(count, retries)\n\n        if count > retries:\n            self.report_error(u'giving up after %s retries' % retries)\n            return False\n\n        data_len = data.info().get('Content-length', None)\n\n        # Range HTTP header may be ignored/unsupported by a webserver\n        # (e.g. extractor/scivee.py, extractor/bambuser.py).\n        # However, for a test we still would like to download just a piece of a file.\n        # To achieve this we limit data_len to _TEST_FILE_SIZE and manually control\n        # block size when downloading a file.\n        if is_test and (data_len is None or int(data_len) > self._TEST_FILE_SIZE):\n            data_len = self._TEST_FILE_SIZE\n\n        if data_len is not None:\n            data_len = int(data_len) + resume_len\n            min_data_len = self.params.get(\"min_filesize\", None)\n            max_data_len = self.params.get(\"max_filesize\", None)\n            if min_data_len is not None and data_len < min_data_len:\n                self.to_screen(u'\\r[download] File is smaller than min-filesize (%s bytes < %s bytes). Aborting.' % (data_len, min_data_len))\n                return False\n            if max_data_len is not None and data_len > max_data_len:\n                self.to_screen(u'\\r[download] File is larger than max-filesize (%s bytes > %s bytes). Aborting.' % (data_len, max_data_len))\n                return False\n\n        data_len_str = format_bytes(data_len)\n        byte_counter = 0 + resume_len\n        block_size = self.params.get('buffersize', 1024)\n        start = time.time()\n        while True:\n            # Download and write\n            before = time.time()\n            data_block = data.read(block_size if not is_test else min(block_size, data_len - byte_counter))\n            after = time.time()\n            if len(data_block) == 0:\n                break\n            byte_counter += len(data_block)\n\n            # Open file just in time\n            if stream is None:\n                try:\n                    (stream, tmpfilename) = sanitize_open(tmpfilename, open_mode)\n                    assert stream is not None\n                    filename = self.undo_temp_name(tmpfilename)\n                    self.report_destination(filename)\n                except (OSError, IOError) as err:\n                    self.report_error(u'unable to open for writing: %s' % str(err))\n                    return False\n            try:\n                stream.write(data_block)\n            except (IOError, OSError) as err:\n                self.to_stderr(u\"\\n\")\n                self.report_error(u'unable to write data: %s' % str(err))\n                return False\n            if not self.params.get('noresizebuffer', False):\n                block_size = self.best_block_size(after - before, len(data_block))\n\n            # Progress message\n            speed = self.calc_speed(start, time.time(), byte_counter - resume_len)\n            if data_len is None:\n                eta = percent = None\n            else:\n                percent = self.calc_percent(byte_counter, data_len)\n                eta = self.calc_eta(start, time.time(), data_len - resume_len, byte_counter - resume_len)\n            self.report_progress(percent, data_len_str, speed, eta)\n\n            self._hook_progress({\n                'downloaded_bytes': byte_counter,\n                'total_bytes': data_len,\n                'tmpfilename': tmpfilename,\n                'filename': filename,\n                'status': 'downloading',\n                'eta': eta,\n                'speed': speed,\n            })\n\n            if is_test and byte_counter == data_len:\n                break\n\n            # Apply rate limit\n            self.slow_down(start, byte_counter - resume_len)\n\n        if stream is None:\n            self.to_stderr(u\"\\n\")\n            self.report_error(u'Did not get any data blocks')\n            return False\n        if tmpfilename != u'-':\n            stream.close()\n        self.report_finish(data_len_str, (time.time() - start))\n        if data_len is not None and byte_counter != data_len:\n            raise ContentTooShortError(byte_counter, int(data_len))\n        self.try_rename(tmpfilename, filename)\n\n        # Update file modification time\n        if self.params.get('updatetime', True):\n            info_dict['filetime'] = self.try_utime(filename, data.info().get('last-modified', None))\n\n        self._hook_progress({\n            'downloaded_bytes': byte_counter,\n            'total_bytes': byte_counter,\n            'filename': filename,\n            'status': 'finished',\n        })\n\n        return True",
        "begin_line": 19,
        "end_line": 214,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.000968054211035818,
            "pseudo_dstar_susp": 0.0014204545454545455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0014204545454545455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.bbccouk.BBCCoUkIE._extract_asx_playlist#61",
        "src_path": "youtube_dl/extractor/bbccouk.py",
        "class_name": "youtube_dl.extractor.bbccouk.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbccouk.BBCCoUkIE._extract_asx_playlist(self, connection, programme_id)",
        "snippet": "    def _extract_asx_playlist(self, connection, programme_id):\n        asx = self._download_xml(connection.get('href'), programme_id, 'Downloading ASX playlist')\n        return [ref.get('href') for ref in asx.findall('./Entry/ref')]",
        "begin_line": 61,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.bbccouk.BBCCoUkIE._extract_connection#65",
        "src_path": "youtube_dl/extractor/bbccouk.py",
        "class_name": "youtube_dl.extractor.bbccouk.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbccouk.BBCCoUkIE._extract_connection(self, connection, programme_id)",
        "snippet": "    def _extract_connection(self, connection, programme_id):\n        formats = []\n        protocol = connection.get('protocol')\n        supplier = connection.get('supplier')\n        if protocol == 'http':\n            href = connection.get('href')\n            # ASX playlist\n            if supplier == 'asx':\n                for i, ref in enumerate(self._extract_asx_playlist(connection, programme_id)):\n                    formats.append({\n                        'url': ref,\n                        'format_id': 'ref%s_%s' % (i, supplier),\n                    })\n            # Direct link\n            else:\n                formats.append({\n                    'url': href,\n                    'format_id': supplier,\n                })\n        elif protocol == 'rtmp':\n            application = connection.get('application', 'ondemand')\n            auth_string = connection.get('authString')\n            identifier = connection.get('identifier')\n            server = connection.get('server')\n            formats.append({\n                'url': '%s://%s/%s?%s' % (protocol, server, application, auth_string),\n                'play_path': identifier,\n                'app': '%s?%s' % (application, auth_string),\n                'page_url': 'http://www.bbc.co.uk',\n                'player_url': 'http://www.bbc.co.uk/emp/releases/iplayer/revisions/617463_618125_4/617463_618125_4_emp.swf',\n                'rtmp_live': False,\n                'ext': 'flv',\n                'format_id': supplier,\n            })\n        return formats",
        "begin_line": 65,
        "end_line": 99,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.bbccouk.BBCCoUkIE._extract_items#101",
        "src_path": "youtube_dl/extractor/bbccouk.py",
        "class_name": "youtube_dl.extractor.bbccouk.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbccouk.BBCCoUkIE._extract_items(self, playlist)",
        "snippet": "    def _extract_items(self, playlist):\n        return playlist.findall('./{http://bbc.co.uk/2008/emp/playlist}item')",
        "begin_line": 101,
        "end_line": 102,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.bbccouk.BBCCoUkIE._extract_medias#104",
        "src_path": "youtube_dl/extractor/bbccouk.py",
        "class_name": "youtube_dl.extractor.bbccouk.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbccouk.BBCCoUkIE._extract_medias(self, media_selection)",
        "snippet": "    def _extract_medias(self, media_selection):\n        return media_selection.findall('./{http://bbc.co.uk/2008/mp/mediaselection}media')",
        "begin_line": 104,
        "end_line": 105,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.bbccouk.BBCCoUkIE._extract_connections#107",
        "src_path": "youtube_dl/extractor/bbccouk.py",
        "class_name": "youtube_dl.extractor.bbccouk.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbccouk.BBCCoUkIE._extract_connections(self, media)",
        "snippet": "    def _extract_connections(self, media):\n        return media.findall('./{http://bbc.co.uk/2008/mp/mediaselection}connection')",
        "begin_line": 107,
        "end_line": 108,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.bbccouk.BBCCoUkIE._extract_video#110",
        "src_path": "youtube_dl/extractor/bbccouk.py",
        "class_name": "youtube_dl.extractor.bbccouk.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbccouk.BBCCoUkIE._extract_video(self, media, programme_id)",
        "snippet": "    def _extract_video(self, media, programme_id):\n        formats = []\n        vbr = int(media.get('bitrate'))\n        vcodec = media.get('encoding')\n        service = media.get('service')\n        width = int(media.get('width'))\n        height = int(media.get('height'))\n        file_size = int(media.get('media_file_size'))\n        for connection in self._extract_connections(media):\n            conn_formats = self._extract_connection(connection, programme_id)\n            for format in conn_formats:\n                format.update({\n                    'format_id': '%s_%s' % (service, format['format_id']),\n                    'width': width,\n                    'height': height,\n                    'vbr': vbr,\n                    'vcodec': vcodec,\n                    'filesize': file_size,\n                })\n            formats.extend(conn_formats)\n        return formats",
        "begin_line": 110,
        "end_line": 130,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.bbccouk.BBCCoUkIE._extract_audio#132",
        "src_path": "youtube_dl/extractor/bbccouk.py",
        "class_name": "youtube_dl.extractor.bbccouk.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbccouk.BBCCoUkIE._extract_audio(self, media, programme_id)",
        "snippet": "    def _extract_audio(self, media, programme_id):\n        formats = []\n        abr = int(media.get('bitrate'))\n        acodec = media.get('encoding')\n        service = media.get('service')\n        for connection in self._extract_connections(media):\n            conn_formats = self._extract_connection(connection, programme_id)\n            for format in conn_formats:\n                format.update({\n                    'format_id': '%s_%s' % (service, format['format_id']),\n                    'abr': abr,\n                    'acodec': acodec,\n                })\n            formats.extend(conn_formats)\n        return formats",
        "begin_line": 132,
        "end_line": 146,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.bbccouk.BBCCoUkIE._extract_captions#148",
        "src_path": "youtube_dl/extractor/bbccouk.py",
        "class_name": "youtube_dl.extractor.bbccouk.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbccouk.BBCCoUkIE._extract_captions(self, media, programme_id)",
        "snippet": "    def _extract_captions(self, media, programme_id):\n        subtitles = {}\n        for connection in self._extract_connections(media):\n            captions = self._download_xml(connection.get('href'), programme_id, 'Downloading captions')\n            lang = captions.get('{http://www.w3.org/XML/1998/namespace}lang', 'en')\n            ps = captions.findall('./{0}body/{0}div/{0}p'.format('{http://www.w3.org/2006/10/ttaf1}'))\n            srt = ''\n            for pos, p in enumerate(ps):\n                srt += '%s\\r\\n%s --> %s\\r\\n%s\\r\\n\\r\\n' % (str(pos), p.get('begin'), p.get('end'),\n                                                          p.text.strip() if p.text is not None else '')\n            subtitles[lang] = srt\n        return subtitles",
        "begin_line": 148,
        "end_line": 159,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.bbccouk.BBCCoUkIE._real_extract#161",
        "src_path": "youtube_dl/extractor/bbccouk.py",
        "class_name": "youtube_dl.extractor.bbccouk.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbccouk.BBCCoUkIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        group_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, group_id, 'Downloading video page')\n        if re.search(r'id=\"emp-error\" class=\"notinuk\">', webpage):\n            raise ExtractorError('Currently BBC iPlayer TV programmes are available to play in the UK only',\n                expected=True)\n\n        playlist = self._download_xml('http://www.bbc.co.uk/iplayer/playlist/%s' % group_id, group_id,\n            'Downloading playlist XML')\n\n        no_items = playlist.find('./{http://bbc.co.uk/2008/emp/playlist}noItems')\n        if no_items is not None:\n            reason = no_items.get('reason')\n            if reason == 'preAvailability':\n                msg = 'Episode %s is not yet available' % group_id\n            elif reason == 'postAvailability':\n                msg = 'Episode %s is no longer available' % group_id\n            else:\n                msg = 'Episode %s is not available: %s' % (group_id, reason)\n            raise ExtractorError(msg, expected=True)\n\n        formats = []\n        subtitles = None\n\n        for item in self._extract_items(playlist):\n            kind = item.get('kind')\n            if kind != 'programme' and kind != 'radioProgramme':\n                continue\n            title = playlist.find('./{http://bbc.co.uk/2008/emp/playlist}title').text\n            description = playlist.find('./{http://bbc.co.uk/2008/emp/playlist}summary').text\n\n            programme_id = item.get('identifier')\n            duration = int(item.get('duration'))\n\n            media_selection = self._download_xml(\n                'http://open.live.bbc.co.uk/mediaselector/5/select/version/2.0/mediaset/pc/vpid/%s'  % programme_id,\n                programme_id, 'Downloading media selection XML')\n\n            for media in self._extract_medias(media_selection):\n                kind = media.get('kind')\n                if kind == 'audio':\n                    formats.extend(self._extract_audio(media, programme_id))\n                elif kind == 'video':\n                    formats.extend(self._extract_video(media, programme_id))\n                elif kind == 'captions':\n                    subtitles = self._extract_captions(media, programme_id)\n\n        if self._downloader.params.get('listsubtitles', False):\n            self._list_available_subtitles(programme_id, subtitles)\n            return\n\n        self._sort_formats(formats)\n\n        return {\n            'id': programme_id,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 161,
        "end_line": 223,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.nfb.NFBIE._real_extract#34",
        "src_path": "youtube_dl/extractor/nfb.py",
        "class_name": "youtube_dl.extractor.nfb.NFBIE",
        "signature": "youtube_dl.extractor.nfb.NFBIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        page = self._download_webpage('https://www.nfb.ca/film/%s' % video_id, video_id, 'Downloading film page')\n\n        uploader_id = self._html_search_regex(r'<a class=\"director-link\" href=\"/explore-all-directors/([^/]+)/\"',\n            page, 'director id', fatal=False)\n        uploader = self._html_search_regex(r'<em class=\"director-name\" itemprop=\"name\">([^<]+)</em>',\n            page, 'director name', fatal=False)\n\n        request = compat_urllib_request.Request('https://www.nfb.ca/film/%s/player_config' % video_id,\n            compat_urllib_parse.urlencode({'getConfig': 'true'}).encode('ascii'))\n        request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        request.add_header('X-NFB-Referer', 'http://www.nfb.ca/medias/flash/NFBVideoPlayer.swf')\n\n        config = self._download_xml(request, video_id, 'Downloading player config XML')\n\n        title = None\n        description = None\n        thumbnail = None\n        duration = None\n        formats = []\n\n        def extract_thumbnail(media):\n            thumbnails = {}\n            for asset in media.findall('assets/asset'):\n                thumbnails[asset.get('quality')] = asset.find('default/url').text\n            if not thumbnails:\n                return None\n            if 'high' in thumbnails:\n                return thumbnails['high']\n            return list(thumbnails.values())[0]\n\n        for media in config.findall('./player/stream/media'):\n            if media.get('type') == 'posterImage':\n                thumbnail = extract_thumbnail(media)\n            elif media.get('type') == 'video':\n                duration = int(media.get('duration'))\n                title = media.find('title').text\n                description = media.find('description').text\n                # It seems assets always go from lower to better quality, so no need to sort\n                for asset in media.findall('assets/asset'):\n                    for x in asset:\n                        formats.append({\n                            'url': x.find('streamerURI').text,\n                            'app': x.find('streamerURI').text.split('/', 3)[3],\n                            'play_path': x.find('url').text,\n                            'rtmp_live': False,\n                            'ext': 'mp4',\n                            'format_id': '%s-%s' % (x.tag, asset.get('quality')),\n                        })\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'formats': formats,\n        }",
        "begin_line": 34,
        "end_line": 96,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.podomatic.PodomaticIE._real_extract#40",
        "src_path": "youtube_dl/extractor/podomatic.py",
        "class_name": "youtube_dl.extractor.podomatic.PodomaticIE",
        "signature": "youtube_dl.extractor.podomatic.PodomaticIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        channel = mobj.group('channel')\n\n        json_url = (('%s://%s.podomatic.com/entry/embed_params/%s' +\n                     '?permalink=true&rtmp=0') %\n                    (mobj.group('proto'), channel, video_id))\n        data_json = self._download_webpage(\n            json_url, video_id, 'Downloading video info')\n        data = json.loads(data_json)\n\n        video_url = data['downloadLink']\n        if not video_url:\n            video_url = '%s/%s' % (data['streamer'].replace('rtmp', 'http'), data['mediaLocation'])\n        uploader = data['podcast']\n        title = data['title']\n        thumbnail = data['imageLocation']\n        duration = int_or_none(data.get('length'), 1000)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'uploader': uploader,\n            'uploader_id': channel,\n            'thumbnail': thumbnail,\n            'duration': duration,\n        }",
        "begin_line": 40,
        "end_line": 68,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00023618327822390176,
            "pseudo_dstar_susp": 0.000233590282644242,
            "pseudo_tarantula_susp": 0.0002772387025228722,
            "pseudo_op2_susp": 0.000233590282644242,
            "pseudo_barinel_susp": 0.00027631942525559546
        }
    },
    {
        "name": "youtube_dl.extractor.infoq.InfoQIE._real_extract#26",
        "src_path": "youtube_dl/extractor/infoq.py",
        "class_name": "youtube_dl.extractor.infoq.InfoQIE",
        "signature": "youtube_dl.extractor.infoq.InfoQIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_title = self._html_search_regex(r'<title>(.*?)</title>', webpage, 'title')\n        video_description = self._html_search_meta('description', webpage, 'description')\n\n        # The server URL is hardcoded\n        video_url = 'rtmpe://video.infoq.com/cfx/st/'\n\n        # Extract video URL\n        encoded_id = self._search_regex(\n            r\"jsclassref\\s*=\\s*'([^']*)'\", webpage, 'encoded id')\n        real_id = compat_urllib_parse.unquote(base64.b64decode(encoded_id.encode('ascii')).decode('utf-8'))\n        playpath = 'mp4:' + real_id\n\n        video_filename = playpath.split('/')[-1]\n        video_id, extension = video_filename.split('.')\n\n        http_base = self._search_regex(\n            r'EXPRESSINSTALL_SWF\\s*=\\s*\"(https?://[^/\"]+/)', webpage,\n            'HTTP base URL')\n\n        formats = [{\n            'format_id': 'rtmp',\n            'url': video_url,\n            'ext': extension,\n            'play_path': playpath,\n        }, {\n            'format_id': 'http',\n            'url': http_base + real_id,\n        }]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'description': video_description,\n            'formats': formats,\n        }",
        "begin_line": 26,
        "end_line": 67,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.worldstarhiphop.WorldStarHipHopIE._real_extract#20",
        "src_path": "youtube_dl/extractor/worldstarhiphop.py",
        "class_name": "youtube_dl.extractor.worldstarhiphop.WorldStarHipHopIE",
        "signature": "youtube_dl.extractor.worldstarhiphop.WorldStarHipHopIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('id')\n\n        webpage_src = self._download_webpage(url, video_id)\n\n        m_vevo_id = re.search(r'videoId=(.*?)&amp?',\n                              webpage_src)\n        if m_vevo_id is not None:\n            return self.url_result('vevo:%s' % m_vevo_id.group(1), ie='Vevo')\n\n        video_url = self._search_regex(\n            r'so\\.addVariable\\(\"file\",\"(.*?)\"\\)', webpage_src, 'video URL')\n\n        if 'youtube' in video_url:\n            return self.url_result(video_url, ie='Youtube')\n\n        video_title = self._html_search_regex(\n            r\"<title>(.*)</title>\", webpage_src, 'title')\n\n        # Getting thumbnail and if not thumbnail sets correct title for WSHH candy video.\n        thumbnail = self._html_search_regex(\n            r'rel=\"image_src\" href=\"(.*)\" />', webpage_src, 'thumbnail',\n            fatal=False)\n        if not thumbnail:\n            _title = r\"\"\"candytitles.*>(.*)</span>\"\"\"\n            mobj = re.search(_title, webpage_src)\n            if mobj is not None:\n                video_title = mobj.group(1)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': video_title,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 20,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.rtve._decrypt_url#15",
        "src_path": "youtube_dl/extractor/rtve.py",
        "class_name": "youtube_dl.extractor.rtve",
        "signature": "youtube_dl.extractor.rtve._decrypt_url(png)",
        "snippet": "def _decrypt_url(png):\n    encrypted_data = base64.b64decode(png)\n    text_index = encrypted_data.find(b'tEXt')\n    text_chunk = encrypted_data[text_index - 4:]\n    length = struct_unpack('!I', text_chunk[:4])[0]\n    # Use bytearray to get integers when iterating in both python 2.x and 3.x\n    data = bytearray(text_chunk[8:8 + length])\n    data = [chr(b) for b in data if b != 0]\n    hash_index = data.index('#')\n    alphabet_data = data[:hash_index]\n    url_data = data[hash_index + 1:]\n\n    alphabet = []\n    e = 0\n    d = 0\n    for l in alphabet_data:\n        if d == 0:\n            alphabet.append(l)\n            d = e = (e + 1) % 4\n        else:\n            d -= 1\n    url = ''\n    f = 0\n    e = 3\n    b = 1\n    for letter in url_data:\n        if f == 0:\n            l = int(letter) * 10\n            f = 1\n        else:\n            if e == 0:\n                l += int(letter)\n                url += alphabet[l]\n                e = (b + 3) % 4\n                f = 0\n                b += 1\n            else:\n                e -= 1\n\n    return url",
        "begin_line": 15,
        "end_line": 54,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009000900090009,
            "pseudo_dstar_susp": 0.0006983240223463687,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006983240223463687,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.rtve.RTVEALaCartaIE._real_extract#81",
        "src_path": "youtube_dl/extractor/rtve.py",
        "class_name": "youtube_dl.extractor.rtve.RTVEALaCartaIE",
        "signature": "youtube_dl.extractor.rtve.RTVEALaCartaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        info = self._download_json(\n            'http://www.rtve.es/api/videos/%s/config/alacarta_videos.json' % video_id,\n            video_id)['page']['items'][0]\n        png_url = 'http://www.rtve.es/ztnr/movil/thumbnail/default/videos/%s.png' % video_id\n        png = self._download_webpage(png_url, video_id, 'Downloading url information')\n        video_url = _decrypt_url(png)\n\n        return {\n            'id': video_id,\n            'title': info['title'],\n            'url': video_url,\n            'thumbnail': info.get('image'),\n            'page_url': url,\n        }",
        "begin_line": 81,
        "end_line": 97,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.rtve.RTVELiveIE._real_extract#117",
        "src_path": "youtube_dl/extractor/rtve.py",
        "class_name": "youtube_dl.extractor.rtve.RTVELiveIE",
        "signature": "youtube_dl.extractor.rtve.RTVELiveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        start_time = time.gmtime()\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        player_url = self._search_regex(\n            r'<param name=\"movie\" value=\"([^\"]+)\"/>', webpage, 'player URL')\n        title = remove_end(self._og_search_title(webpage), ' en directo')\n        title += ' ' + time.strftime('%Y-%m-%dZ%H%M%S', start_time)\n\n        vidplayer_id = self._search_regex(\n            r' id=\"vidplayer([0-9]+)\"', webpage, 'internal video ID')\n        png_url = 'http://www.rtve.es/ztnr/movil/thumbnail/default/videos/%s.png' % vidplayer_id\n        png = self._download_webpage(png_url, video_id, 'Downloading url information')\n        video_url = _decrypt_url(png)\n\n        return {\n            'id': video_id,\n            'ext': 'flv',\n            'title': title,\n            'url': video_url,\n            'app': 'rtve-live-live?ovpfv=2.1.2',\n            'player_url': player_url,\n            'rtmp_live': True,\n        }",
        "begin_line": 117,
        "end_line": 142,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.firsttv.FirstTVIE._real_extract#29",
        "src_path": "youtube_dl/extractor/firsttv.py",
        "class_name": "youtube_dl.extractor.firsttv.FirstTVIE",
        "signature": "youtube_dl.extractor.firsttv.FirstTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id, 'Downloading page')\n\n        video_url = self._html_search_regex(\n            r'''(?s)jwplayer\\('flashvideoportal_1'\\)\\.setup\\({.*?'file': '([^']+)'.*?}\\);''', webpage, 'video URL')\n\n        title = self._html_search_regex(\n            r'<div class=\"tv_translation\">\\s*<h1><a href=\"[^\"]+\">([^<]*)</a>', webpage, 'title')\n        description = self._html_search_regex(\n            r'<div class=\"descr\">\\s*<div>&nbsp;</div>\\s*<p>([^<]*)</p></div>', webpage, 'description', fatal=False)\n\n        thumbnail = self._og_search_thumbnail(webpage)\n        duration = self._og_search_property('video:duration', webpage, 'video duration', fatal=False)\n\n        like_count = self._html_search_regex(r'title=\"\u041f\u043e\u043d\u0440\u0430\u0432\u0438\u043b\u043e\u0441\u044c\".*?/></label> \\[(\\d+)\\]',\n            webpage, 'like count', fatal=False)\n        dislike_count = self._html_search_regex(r'title=\"\u041d\u0435 \u043f\u043e\u043d\u0440\u0430\u0432\u0438\u043b\u043e\u0441\u044c\".*?/></label> \\[(\\d+)\\]',\n            webpage, 'dislike count', fatal=False)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'thumbnail': thumbnail,\n            'title': title,\n            'description': description,\n            'duration': int_or_none(duration),\n            'like_count': int_or_none(like_count),\n            'dislike_count': int_or_none(dislike_count),\n        }",
        "begin_line": 29,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.orf.ORFTVthekIE._real_extract#35",
        "src_path": "youtube_dl/extractor/orf.py",
        "class_name": "youtube_dl.extractor.orf.ORFTVthekIE",
        "signature": "youtube_dl.extractor.orf.ORFTVthekIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('id')\n        webpage = self._download_webpage(url, playlist_id)\n\n        data_json = self._search_regex(\n            r'initializeAdworx\\((.+?)\\);\\n', webpage, 'video info')\n        all_data = json.loads(data_json)\n\n        def get_segments(all_data):\n            for data in all_data:\n                if data['name'] == 'Tracker::EPISODE_DETAIL_PAGE_OVER_PROGRAM':\n                    return data['values']['segments']\n\n        sdata = get_segments(all_data)\n        if not sdata:\n            raise ExtractorError('Unable to extract segments')\n\n        def quality_to_int(s):\n            m = re.search('([0-9]+)', s)\n            if m is None:\n                return -1\n            return int(m.group(1))\n\n        entries = []\n        for sd in sdata:\n            video_id = sd['id']\n            formats = [{\n                'preference': -10 if fd['delivery'] == 'hls' else None,\n                'format_id': '%s-%s-%s' % (\n                    fd['delivery'], fd['quality'], fd['quality_string']),\n                'url': fd['src'],\n                'protocol': fd['protocol'],\n                'quality': quality_to_int(fd['quality']),\n            } for fd in sd['playlist_item_array']['sources']]\n\n            # Check for geoblocking.\n            # There is a property is_geoprotection, but that's always false\n            geo_str = sd.get('geoprotection_string')\n            if geo_str:\n                try:\n                    http_url = next(\n                        f['url']\n                        for f in formats\n                        if re.match(r'^https?://.*\\.mp4$', f['url']))\n                except StopIteration:\n                    pass\n                else:\n                    req = HEADRequest(http_url)\n                    self._request_webpage(\n                        req, video_id,\n                        note='Testing for geoblocking',\n                        errnote=((\n                            'This video seems to be blocked outside of %s. '\n                            'You may want to try the streaming-* formats.')\n                            % geo_str),\n                        fatal=False)\n\n            self._sort_formats(formats)\n\n            upload_date = unified_strdate(sd['created_date'])\n            entries.append({\n                '_type': 'video',\n                'id': video_id,\n                'title': sd['header'],\n                'formats': formats,\n                'description': sd.get('description'),\n                'duration': int(sd['duration_in_seconds']),\n                'upload_date': upload_date,\n                'thumbnail': sd.get('image_full_url'),\n            })\n\n        return {\n            '_type': 'playlist',\n            'entries': entries,\n            'id': playlist_id,\n        }",
        "begin_line": 35,
        "end_line": 111,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.orf.ORFOE1IE._real_extract#122",
        "src_path": "youtube_dl/extractor/orf.py",
        "class_name": "youtube_dl.extractor.orf.ORFOE1IE",
        "signature": "youtube_dl.extractor.orf.ORFOE1IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        show_id = mobj.group('id')\n\n        data = self._download_json(\n            'http://oe1.orf.at/programm/%s/konsole' % show_id,\n            show_id\n        )\n\n        timestamp = datetime.datetime.strptime('%s %s' % (\n            data['item']['day_label'],\n            data['item']['time']\n        ), '%d.%m.%Y %H:%M')\n        unix_timestamp = calendar.timegm(timestamp.utctimetuple())\n\n        return {\n            'id': show_id,\n            'title': data['item']['title'],\n            'url': data['item']['url_stream'],\n            'ext': 'mp3',\n            'description': data['item'].get('info'),\n            'timestamp': unix_timestamp\n        }",
        "begin_line": 122,
        "end_line": 144,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.orf.ORFFM4IE._real_extract#152",
        "src_path": "youtube_dl/extractor/orf.py",
        "class_name": "youtube_dl.extractor.orf.ORFFM4IE",
        "signature": "youtube_dl.extractor.orf.ORFFM4IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        show_date = mobj.group('date')\n        show_id = mobj.group('show')\n\n        data = self._download_json(\n            'http://audioapi.orf.at/fm4/json/2.0/broadcasts/%s/4%s' % (show_date, show_id),\n            show_id\n        )\n\n        def extract_entry_dict(info, title, subtitle):\n            return {\n                'id': info['loopStreamId'].replace('.mp3', ''),\n                'url': 'http://loopstream01.apa.at/?channel=fm4&id=%s' % info['loopStreamId'],\n                'title': title,\n                'description': subtitle,\n                'duration': (info['end'] - info['start']) / 1000,\n                'timestamp': info['start'] / 1000,\n                'ext': 'mp3'\n            }\n\n        entries = [extract_entry_dict(t, data['title'], data['subtitle']) for t in data['streams']]\n\n        return {\n            '_type': 'playlist',\n            'id': show_id,\n            'title': data['title'],\n            'description': data['subtitle'],\n            'entries': entries\n        }",
        "begin_line": 152,
        "end_line": 181,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.yahoo.YahooIE._real_extract#62",
        "src_path": "youtube_dl/extractor/yahoo.py",
        "class_name": "youtube_dl.extractor.yahoo.YahooIE",
        "signature": "youtube_dl.extractor.yahoo.YahooIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        url = mobj.group('url')\n        webpage = self._download_webpage(url, video_id)\n\n        items_json = self._search_regex(\n            r'mediaItems: ({.*?})$', webpage, 'items', flags=re.MULTILINE,\n            default=None)\n        if items_json is None:\n            CONTENT_ID_REGEXES = [\n                r'YUI\\.namespace\\(\"Media\"\\)\\.CONTENT_ID\\s*=\\s*\"([^\"]+)\"',\n                r'root\\.App\\.Cache\\.context\\.videoCache\\.curVideo = \\{\"([^\"]+)\"',\n                r'\"first_videoid\"\\s*:\\s*\"([^\"]+)\"',\n            ]\n            long_id = self._search_regex(CONTENT_ID_REGEXES, webpage, 'content ID')\n            video_id = long_id\n        else:\n            items = json.loads(items_json)\n            info = items['mediaItems']['query']['results']['mediaObj'][0]\n            # The 'meta' field is not always in the video webpage, we request it\n            # from another page\n            long_id = info['id']\n        return self._get_info(long_id, video_id, webpage)",
        "begin_line": 62,
        "end_line": 85,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009000900090009,
            "pseudo_dstar_susp": 0.0006983240223463687,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006983240223463687,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.yahoo.YahooIE._get_info#87",
        "src_path": "youtube_dl/extractor/yahoo.py",
        "class_name": "youtube_dl.extractor.yahoo.YahooIE",
        "signature": "youtube_dl.extractor.yahoo.YahooIE._get_info(self, long_id, video_id, webpage)",
        "snippet": "    def _get_info(self, long_id, video_id, webpage):\n        query = ('SELECT * FROM yahoo.media.video.streams WHERE id=\"%s\"'\n                 ' AND plrs=\"86Gj0vCaSzV_Iuf6hNylf2\" AND region=\"US\"'\n                 ' AND protocol=\"http\"' % long_id)\n        data = compat_urllib_parse.urlencode({\n            'q': query,\n            'env': 'prod',\n            'format': 'json',\n        })\n        query_result = self._download_json(\n            'http://video.query.yahoo.com/v1/public/yql?' + data,\n            video_id, 'Downloading video info')\n        info = query_result['query']['results']['mediaObj'][0]\n        meta = info['meta']\n\n        formats = []\n        for s in info['streams']:\n            format_info = {\n                'width': int_or_none(s.get('width')),\n                'height': int_or_none(s.get('height')),\n                'tbr': int_or_none(s.get('bitrate')),\n            }\n\n            host = s['host']\n            path = s['path']\n            if host.startswith('rtmp'):\n                format_info.update({\n                    'url': host,\n                    'play_path': path,\n                    'ext': 'flv',\n                })\n            else:\n                format_url = compat_urlparse.urljoin(host, path)\n                format_info['url'] = format_url\n            formats.append(format_info)\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': meta['title'],\n            'formats': formats,\n            'description': clean_html(meta['description']),\n            'thumbnail': meta['thumbnail'] if meta.get('thumbnail') else self._og_search_thumbnail(webpage),\n        }",
        "begin_line": 87,
        "end_line": 131,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.yahoo.YahooNewsIE._real_extract#149",
        "src_path": "youtube_dl/extractor/yahoo.py",
        "class_name": "youtube_dl.extractor.yahoo.YahooNewsIE",
        "signature": "youtube_dl.extractor.yahoo.YahooNewsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        long_id = self._search_regex(r'contentId: \\'(.+?)\\',', webpage, 'long id')\n        return self._get_info(long_id, video_id, webpage)",
        "begin_line": 149,
        "end_line": 154,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.yahoo.YahooSearchIE._get_n_results#163",
        "src_path": "youtube_dl/extractor/yahoo.py",
        "class_name": "youtube_dl.extractor.yahoo.YahooSearchIE",
        "signature": "youtube_dl.extractor.yahoo.YahooSearchIE._get_n_results(self, query, n)",
        "snippet": "    def _get_n_results(self, query, n):\n        \"\"\"Get a specified number of results for a query\"\"\"\n        entries = []\n        for pagenum in itertools.count(0):\n            result_url = 'http://video.search.yahoo.com/search/?p=%s&fr=screen&o=js&gs=0&b=%d' % (compat_urllib_parse.quote_plus(query), pagenum * 30)\n            info = self._download_json(result_url, query,\n                note='Downloading results page '+str(pagenum+1))\n            m = info['m']\n            results = info['results']\n\n            for (i, r) in enumerate(results):\n                if (pagenum * 30) + i >= n:\n                    break\n                mobj = re.search(r'(?P<url>screen\\.yahoo\\.com/.*?-\\d*?\\.html)\"', r)\n                e = self.url_result('http://' + mobj.group('url'), 'Yahoo')\n                entries.append(e)\n            if (pagenum * 30 + i >= n) or (m['last'] >= (m['total'] - 1)):\n                break\n\n        return {\n            '_type': 'playlist',\n            'id': query,\n            'entries': entries,\n        }",
        "begin_line": 163,
        "end_line": 186,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.nrk.NRKIE._real_extract#40",
        "src_path": "youtube_dl/extractor/nrk.py",
        "class_name": "youtube_dl.extractor.nrk.NRKIE",
        "signature": "youtube_dl.extractor.nrk.NRKIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        page = self._download_webpage(url, video_id)\n\n        video_id = self._html_search_regex(r'<div class=\"nrk-video\" data-nrk-id=\"(\\d+)\">', page, 'video id')\n\n        data = self._download_json(\n            'http://v7.psapi.nrk.no/mediaelement/%s' % video_id, video_id, 'Downloading media JSON')\n\n        if data['usageRights']['isGeoBlocked']:\n            raise ExtractorError('NRK har ikke rettig-heter til \u00e5 vise dette programmet utenfor Norge', expected=True)\n\n        video_url = data['mediaUrl'] + '?hdcore=3.1.1&plugin=aasp-3.1.1.69.124'\n\n        images = data.get('images')\n        if images:\n            thumbnails = images['webImages']\n            thumbnails.sort(key=lambda image: image['pixelWidth'])\n            thumbnail = thumbnails[-1]['imageUrl']\n        else:\n            thumbnail = None\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'ext': 'flv',\n            'title': data['title'],\n            'description': data['description'],\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 40,
        "end_line": 71,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.nrk.NRKTVIE._real_extract#104",
        "src_path": "youtube_dl/extractor/nrk.py",
        "class_name": "youtube_dl.extractor.nrk.NRKTVIE",
        "signature": "youtube_dl.extractor.nrk.NRKTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        page = self._download_webpage(url, video_id)\n\n        title = self._html_search_meta('title', page, 'title')\n        description = self._html_search_meta('description', page, 'description')\n        thumbnail = self._html_search_regex(r'data-posterimage=\"([^\"]+)\"', page, 'thumbnail', fatal=False)\n        upload_date = unified_strdate(self._html_search_meta('rightsfrom', page, 'upload date', fatal=False))\n        duration = float_or_none(\n            self._html_search_regex(r'data-duration=\"([^\"]+)\"', page, 'duration', fatal=False))\n\n        formats = []\n\n        f4m_url = re.search(r'data-media=\"([^\"]+)\"', page)\n        if f4m_url:\n            formats.append({\n                'url': f4m_url.group(1) + '?hdcore=3.1.1&plugin=aasp-3.1.1.69.124',\n                'format_id': 'f4m',\n                'ext': 'flv',\n            })\n\n        m3u8_url = re.search(r'data-hls-media=\"([^\"]+)\"', page)\n        if m3u8_url:\n            formats.append({\n                'url': m3u8_url.group(1),\n                'format_id': 'm3u8',\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 104,
        "end_line": 144,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.vh1.VH1IE._real_extract#111",
        "src_path": "youtube_dl/extractor/vh1.py",
        "class_name": "youtube_dl.extractor.vh1.VH1IE",
        "signature": "youtube_dl.extractor.vh1.VH1IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        if mobj.group('music_id'):\n            id_field = 'vid'\n            video_id = mobj.group('music_id')\n        else:\n            video_id = mobj.group('playlist_id') or mobj.group('video_id')\n            id_field = 'id'\n        doc_url = '%s?%s=%s' % (self._FEED_URL, id_field, video_id)\n\n        idoc = self._download_xml(\n            doc_url, video_id,\n            'Downloading info', transform_source=fix_xml_ampersands)\n        return [self._get_video_info(item) for item in idoc.findall('.//item')]",
        "begin_line": 111,
        "end_line": 124,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.newstube.NewstubeIE._real_extract#27",
        "src_path": "youtube_dl/extractor/newstube.py",
        "class_name": "youtube_dl.extractor.newstube.NewstubeIE",
        "signature": "youtube_dl.extractor.newstube.NewstubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        page = self._download_webpage(url, video_id, 'Downloading page')\n\n        video_guid = self._html_search_regex(\n            r'<meta property=\"og:video\" content=\"https?://(?:www\\.)?newstube\\.ru/freshplayer\\.swf\\?guid=(?P<guid>[\\da-f]{8}-[\\da-f]{4}-[\\da-f]{4}-[\\da-f]{4}-[\\da-f]{12})',\n            page, 'video GUID')\n\n        player = self._download_xml(\n            'http://p.newstube.ru/v2/player.asmx/GetAutoPlayInfo6?state=&url=%s&sessionId=&id=%s&placement=profile&location=n2' % (url, video_guid),\n            video_guid, 'Downloading player XML')\n\n        def ns(s):\n            return s.replace('/', '/%(ns)s') % {'ns': '{http://app1.newstube.ru/N2SiteWS/player.asmx}'}\n\n        error_message = player.find(ns('./ErrorMessage'))\n        if error_message is not None:\n            raise ExtractorError('%s returned error: %s' % (self.IE_NAME, error_message.text), expected=True)\n\n        session_id = player.find(ns('./SessionId')).text\n        media_info = player.find(ns('./Medias/MediaInfo'))\n        title = media_info.find(ns('./Name')).text\n        description = self._og_search_description(page)\n        thumbnail = media_info.find(ns('./KeyFrame')).text\n        duration = int(media_info.find(ns('./Duration')).text) / 1000.0\n\n        formats = []\n\n        for stream_info in media_info.findall(ns('./Streams/StreamInfo')):\n            media_location = stream_info.find(ns('./MediaLocation'))\n            if media_location is None:\n                continue\n\n            server = media_location.find(ns('./Server')).text\n            app = media_location.find(ns('./App')).text\n            media_id = stream_info.find(ns('./Id')).text\n            quality_id = stream_info.find(ns('./QualityId')).text\n            name = stream_info.find(ns('./Name')).text\n            width = int(stream_info.find(ns('./Width')).text)\n            height = int(stream_info.find(ns('./Height')).text)\n\n            formats.append({\n                'url': 'rtmp://%s/%s' % (server, app),\n                'app': app,\n                'play_path': '01/%s' % video_guid.upper(),\n                'rtmp_conn': ['S:%s' % session_id, 'S:%s' % media_id, 'S:n2'],\n                'page_url': url,\n                'ext': 'flv',\n                'format_id': quality_id,\n                'format_note': name,\n                'width': width,\n                'height': height,\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_guid,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 27,
        "end_line": 92,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.faz.FazIE._real_extract#23",
        "src_path": "youtube_dl/extractor/faz.py",
        "class_name": "youtube_dl.extractor.faz.FazIE",
        "signature": "youtube_dl.extractor.faz.FazIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        self.to_screen(video_id)\n        webpage = self._download_webpage(url, video_id)\n        config_xml_url = self._search_regex(r'writeFLV\\(\\'(.+?)\\',', webpage,\n            u'config xml url')\n        config = self._download_xml(config_xml_url, video_id,\n            u'Downloading config xml')\n\n        encodings = config.find('ENCODINGS')\n        formats = []\n        for code in ['LOW', 'HIGH', 'HQ']:\n            encoding = encodings.find(code)\n            if encoding is None:\n                continue\n            encoding_url = encoding.find('FILENAME').text\n            formats.append({\n                'url': encoding_url,\n                'ext': determine_ext(encoding_url),\n                'format_id': code.lower(),\n            })\n\n        descr = self._html_search_regex(r'<p class=\"Content Copy\">(.*?)</p>', webpage, u'description')\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n            'formats': formats,\n            'description': descr,\n            'thumbnail': config.find('STILL/STILL_BIG').text,\n        }",
        "begin_line": 23,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.cnn.CNNIE._real_extract#39",
        "src_path": "youtube_dl/extractor/cnn.py",
        "class_name": "youtube_dl.extractor.cnn.CNNIE",
        "signature": "youtube_dl.extractor.cnn.CNNIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        path = mobj.group('path')\n        page_title = mobj.group('title')\n        info_url = 'http://cnn.com/video/data/3.0/%s/index.xml' % path\n        info = self._download_xml(info_url, page_title)\n\n        formats = []\n        rex = re.compile(r'''(?x)\n            (?P<width>[0-9]+)x(?P<height>[0-9]+)\n            (?:_(?P<bitrate>[0-9]+)k)?\n        ''')\n        for f in info.findall('files/file'):\n            video_url = 'http://ht.cdn.turner.com/cnn/big%s' % (f.text.strip())\n            fdct = {\n                'format_id': f.attrib['bitrate'],\n                'url': video_url,\n            }\n\n            mf = rex.match(f.attrib['bitrate'])\n            if mf:\n                fdct['width'] = int(mf.group('width'))\n                fdct['height'] = int(mf.group('height'))\n                fdct['tbr'] = int_or_none(mf.group('bitrate'))\n            else:\n                mf = rex.search(f.text)\n                if mf:\n                    fdct['width'] = int(mf.group('width'))\n                    fdct['height'] = int(mf.group('height'))\n                    fdct['tbr'] = int_or_none(mf.group('bitrate'))\n                else:\n                    mi = re.match(r'ios_(audio|[0-9]+)$', f.attrib['bitrate'])\n                    if mi:\n                        if mi.group(1) == 'audio':\n                            fdct['vcodec'] = 'none'\n                            fdct['ext'] = 'm4a'\n                        else:\n                            fdct['tbr'] = int(mi.group(1))\n\n            formats.append(fdct)\n\n        self._sort_formats(formats)\n\n        thumbnails = [{\n            'height': int(t.attrib['height']),\n            'width': int(t.attrib['width']),\n            'url': t.text,\n        } for t in info.findall('images/image')]\n\n        metas_el = info.find('metas')\n        upload_date = (\n            metas_el.attrib.get('version') if metas_el is not None else None)\n\n        duration_el = info.find('length')\n        duration = parse_duration(duration_el.text)\n\n        return {\n            'id': info.attrib['id'],\n            'title': info.find('headline').text,\n            'formats': formats,\n            'thumbnails': thumbnails,\n            'description': info.find('description').text,\n            'duration': duration,\n            'upload_date': upload_date,\n        }",
        "begin_line": 39,
        "end_line": 103,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.cnn.CNNBlogsIE._real_extract#121",
        "src_path": "youtube_dl/extractor/cnn.py",
        "class_name": "youtube_dl.extractor.cnn.CNNBlogsIE",
        "signature": "youtube_dl.extractor.cnn.CNNBlogsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        webpage = self._download_webpage(url, url_basename(url))\n        cnn_url = self._html_search_regex(r'data-url=\"(.+?)\"', webpage, 'cnn url')\n        return {\n            '_type': 'url',\n            'url': cnn_url,\n            'ie_key': CNNIE.ie_key(),\n        }",
        "begin_line": 121,
        "end_line": 128,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.testurl.TestURLIE._real_extract#15",
        "src_path": "youtube_dl/extractor/testurl.py",
        "class_name": "youtube_dl.extractor.testurl.TestURLIE",
        "signature": "youtube_dl.extractor.testurl.TestURLIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        from ..extractor import gen_extractors\n\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        extractor_id = mobj.group('extractor')\n        all_extractors = gen_extractors()\n\n        rex = re.compile(extractor_id, flags=re.IGNORECASE)\n        matching_extractors = [\n            e for e in all_extractors if rex.search(e.IE_NAME)]\n\n        if len(matching_extractors) == 0:\n            raise ExtractorError(\n                'No extractors matching %r found' % extractor_id,\n                expected=True)\n        elif len(matching_extractors) > 1:\n            # Is it obvious which one to pick?\n            try:\n                extractor = next(\n                    ie for ie in matching_extractors\n                    if ie.IE_NAME.lower() == extractor_id.lower())\n            except StopIteration:\n                raise ExtractorError(\n                    ('Found multiple matching extractors: %s' %\n                        ' '.join(ie.IE_NAME for ie in matching_extractors)),\n                    expected=True)\n        else:\n            extractor = matching_extractors[0]\n\n        num_str = mobj.group('num')\n        num = int(num_str) if num_str else 0\n\n        testcases = []\n        t = getattr(extractor, '_TEST', None)\n        if t:\n            testcases.append(t)\n        testcases.extend(getattr(extractor, '_TESTS', []))\n\n        try:\n            tc = testcases[num]\n        except IndexError:\n            raise ExtractorError(\n                ('Test case %d not found, got only %d tests' %\n                    (num, len(testcases))),\n                expected=True)\n\n        self.to_screen('Test URL: %s' % tc['url'])\n\n        return {\n            '_type': 'url',\n            'url': tc['url'],\n            'id': video_id,\n        }",
        "begin_line": 15,
        "end_line": 68,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.byutv.BYUtvIE._real_extract#26",
        "src_path": "youtube_dl/extractor/byutv.py",
        "class_name": "youtube_dl.extractor.byutv.BYUtvIE",
        "signature": "youtube_dl.extractor.byutv.BYUtvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('video_id')\n\n        webpage = self._download_webpage(url, video_id)\n        episode_code = self._search_regex(\n            r'(?s)episode:(.*?\\}),\\s*\\n', webpage, 'episode information')\n        episode_json = re.sub(\n            r'(\\n\\s+)([a-zA-Z]+):\\s+\\'(.*?)\\'', r'\\1\"\\2\": \"\\3\"', episode_code)\n        ep = json.loads(episode_json)\n\n        if ep['providerType'] == 'Ooyala':\n            return {\n                '_type': 'url_transparent',\n                'ie_key': 'Ooyala',\n                'url': 'ooyala:%s' % ep['providerId'],\n                'id': video_id,\n                'title': ep['title'],\n                'description': ep.get('description'),\n                'thumbnail': ep.get('imageThumbnail'),\n            }\n        else:\n            raise ExtractorError('Unsupported provider %s' % ep['provider'])",
        "begin_line": 26,
        "end_line": 48,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.generic.GenericIE.report_download_webpage#387",
        "src_path": "youtube_dl/extractor/generic.py",
        "class_name": "youtube_dl.extractor.generic.GenericIE",
        "signature": "youtube_dl.extractor.generic.GenericIE.report_download_webpage(self, video_id)",
        "snippet": "    def report_download_webpage(self, video_id):\n        \"\"\"Report webpage download.\"\"\"\n        if not self._downloader.params.get('test', False):\n            self._downloader.report_warning('Falling back on generic information extractor.')\n        super(GenericIE, self).report_download_webpage(video_id)",
        "begin_line": 387,
        "end_line": 391,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0018281535648994515,
            "pseudo_dstar_susp": 0.0013458950201884253,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0013458950201884253,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.generic.GenericIE.report_following_redirect#393",
        "src_path": "youtube_dl/extractor/generic.py",
        "class_name": "youtube_dl.extractor.generic.GenericIE",
        "signature": "youtube_dl.extractor.generic.GenericIE.report_following_redirect(self, new_url)",
        "snippet": "    def report_following_redirect(self, new_url):\n        \"\"\"Report information extraction.\"\"\"\n        self._downloader.to_screen('[redirect] Following redirect to %s' % new_url)",
        "begin_line": 393,
        "end_line": 395,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001644736842105263,
            "pseudo_dstar_susp": 0.0012453300124533001,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0012453300124533001,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.generic.GenericIE._extract_rss#397",
        "src_path": "youtube_dl/extractor/generic.py",
        "class_name": "youtube_dl.extractor.generic.GenericIE",
        "signature": "youtube_dl.extractor.generic.GenericIE._extract_rss(self, url, video_id, doc)",
        "snippet": "    def _extract_rss(self, url, video_id, doc):\n        playlist_title = doc.find('./channel/title').text\n        playlist_desc_el = doc.find('./channel/description')\n        playlist_desc = None if playlist_desc_el is None else playlist_desc_el.text\n\n        entries = [{\n            '_type': 'url',\n            'url': e.find('link').text,\n            'title': e.find('title').text,\n        } for e in doc.findall('./channel/item')]\n\n        return {\n            '_type': 'playlist',\n            'id': url,\n            'title': playlist_title,\n            'description': playlist_desc,\n            'entries': entries,\n        }",
        "begin_line": 397,
        "end_line": 414,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.generic.GenericIE._extract_camtasia#416",
        "src_path": "youtube_dl/extractor/generic.py",
        "class_name": "youtube_dl.extractor.generic.GenericIE",
        "signature": "youtube_dl.extractor.generic.GenericIE._extract_camtasia(self, url, video_id, webpage)",
        "snippet": "    def _extract_camtasia(self, url, video_id, webpage):\n        \"\"\" Returns None if no camtasia video can be found. \"\"\"\n\n        camtasia_cfg = self._search_regex(\n            r'fo\\.addVariable\\(\\s*\"csConfigFile\",\\s*\"([^\"]+)\"\\s*\\);',\n            webpage, 'camtasia configuration file', default=None)\n        if camtasia_cfg is None:\n            return None\n\n        title = self._html_search_meta('DC.title', webpage, fatal=True)\n\n        camtasia_url = compat_urlparse.urljoin(url, camtasia_cfg)\n        camtasia_cfg = self._download_xml(\n            camtasia_url, video_id,\n            note='Downloading camtasia configuration',\n            errnote='Failed to download camtasia configuration')\n        fileset_node = camtasia_cfg.find('./playlist/array/fileset')\n\n        entries = []\n        for n in fileset_node.getchildren():\n            url_n = n.find('./uri')\n            if url_n is None:\n                continue\n\n            entries.append({\n                'id': os.path.splitext(url_n.text.rpartition('/')[2])[0],\n                'title': '%s - %s' % (title, n.tag),\n                'url': compat_urlparse.urljoin(url, url_n.text),\n                'duration': float_or_none(n.find('./duration').text),\n            })\n\n        return {\n            '_type': 'playlist',\n            'entries': entries,\n            'title': title,\n        }",
        "begin_line": 416,
        "end_line": 451,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0018281535648994515,
            "pseudo_dstar_susp": 0.0013458950201884253,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0013458950201884253,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.generic.GenericIE._real_extract#453",
        "src_path": "youtube_dl/extractor/generic.py",
        "class_name": "youtube_dl.extractor.generic.GenericIE",
        "signature": "youtube_dl.extractor.generic.GenericIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        if url.startswith('//'):\n            return {\n                '_type': 'url',\n                'url': self.http_scheme() + url,\n            }\n\n        parsed_url = compat_urlparse.urlparse(url)\n        if not parsed_url.scheme:\n            default_search = self._downloader.params.get('default_search')\n            if default_search is None:\n                default_search = 'fixup_error'\n\n            if default_search in ('auto', 'auto_warning', 'fixup_error'):\n                if '/' in url:\n                    self._downloader.report_warning('The url doesn\\'t specify the protocol, trying with http')\n                    return self.url_result('http://' + url)\n                elif default_search != 'fixup_error':\n                    if default_search == 'auto_warning':\n                        if re.match(r'^(?:url|URL)$', url):\n                            raise ExtractorError(\n                                'Invalid URL:  %r . Call youtube-dl like this:  youtube-dl -v \"https://www.youtube.com/watch?v=BaW_jenozKc\"  ' % url,\n                                expected=True)\n                        else:\n                            self._downloader.report_warning(\n                                'Falling back to youtube search for  %s . Set --default-search \"auto\" to suppress this warning.' % url)\n                    return self.url_result('ytsearch:' + url)\n\n            if default_search in ('error', 'fixup_error'):\n                raise ExtractorError(\n                    ('%r is not a valid URL. '\n                     'Set --default-search \"ytsearch\" (or run  youtube-dl \"ytsearch:%s\" ) to search YouTube'\n                    ) % (url, url), expected=True)\n            else:\n                assert ':' in default_search\n                return self.url_result(default_search + url)\n\n        url, smuggled_data = unsmuggle_url(url)\n        force_videoid = None\n        if smuggled_data and 'force_videoid' in smuggled_data:\n            force_videoid = smuggled_data['force_videoid']\n            video_id = force_videoid\n        else:\n            video_id = os.path.splitext(url.rstrip('/').split('/')[-1])[0]\n\n        self.to_screen('%s: Requesting header' % video_id)\n\n        head_req = HEADRequest(url)\n        response = self._request_webpage(\n            head_req, video_id,\n            note=False, errnote='Could not send HEAD request to %s' % url,\n            fatal=False)\n\n        if response is not False:\n            # Check for redirect\n            new_url = response.geturl()\n            if url != new_url:\n                self.report_following_redirect(new_url)\n                if force_videoid:\n                    new_url = smuggle_url(\n                        new_url, {'force_videoid': force_videoid})\n                return self.url_result(new_url)\n\n            # Check for direct link to a video\n            content_type = response.headers.get('Content-Type', '')\n            m = re.match(r'^(?P<type>audio|video|application(?=/ogg$))/(?P<format_id>.+)$', content_type)\n            if m:\n                upload_date = response.headers.get('Last-Modified')\n                if upload_date:\n                    upload_date = unified_strdate(upload_date)\n                return {\n                    'id': video_id,\n                    'title': os.path.splitext(url_basename(url))[0],\n                    'formats': [{\n                        'format_id': m.group('format_id'),\n                        'url': url,\n                        'vcodec': 'none' if m.group('type') == 'audio' else None\n                    }],\n                    'upload_date': upload_date,\n                }\n\n        try:\n            webpage = self._download_webpage(url, video_id)\n        except ValueError:\n            # since this is the last-resort InfoExtractor, if\n            # this error is thrown, it'll be thrown here\n            raise ExtractorError('Failed to download URL: %s' % url)\n\n        self.report_extraction(video_id)\n\n        # Is it an RSS feed?\n        try:\n            doc = parse_xml(webpage)\n            if doc.tag == 'rss':\n                return self._extract_rss(url, video_id, doc)\n        except compat_xml_parse_error:\n            pass\n\n        # Is it a Camtasia project?\n        camtasia_res = self._extract_camtasia(url, video_id, webpage)\n        if camtasia_res is not None:\n            return camtasia_res\n\n        # Sometimes embedded video player is hidden behind percent encoding\n        # (e.g. https://github.com/rg3/youtube-dl/issues/2448)\n        # Unescaping the whole page allows to handle those cases in a generic way\n        webpage = compat_urllib_parse.unquote(webpage)\n\n        # it's tempting to parse this further, but you would\n        # have to take into account all the variations like\n        #   Video Title - Site Name\n        #   Site Name | Video Title\n        #   Video Title - Tagline | Site Name\n        # and so on and so forth; it's just not practical\n        video_title = self._html_search_regex(\n            r'(?s)<title>(.*?)</title>', webpage, 'video title',\n            default='video')\n\n        # Try to detect age limit automatically\n        age_limit = self._rta_search(webpage)\n        # And then there are the jokers who advertise that they use RTA,\n        # but actually don't.\n        AGE_LIMIT_MARKERS = [\n            r'Proudly Labeled <a href=\"http://www.rtalabel.org/\" title=\"Restricted to Adults\">RTA</a>',\n        ]\n        if any(re.search(marker, webpage) for marker in AGE_LIMIT_MARKERS):\n            age_limit = 18\n\n        # video uploader is domain name\n        video_uploader = self._search_regex(\n            r'^(?:https?://)?([^/]*)/.*', url, 'video uploader')\n\n        # Helper method\n        def _playlist_from_matches(matches, getter, ie=None):\n            urlrs = orderedSet(self.url_result(getter(m), ie) for m in matches)\n            return self.playlist_result(\n                urlrs, playlist_id=video_id, playlist_title=video_title)\n\n        # Look for BrightCove:\n        bc_urls = BrightcoveIE._extract_brightcove_urls(webpage)\n        if bc_urls:\n            self.to_screen('Brightcove video detected.')\n            entries = [{\n                '_type': 'url',\n                'url': smuggle_url(bc_url, {'Referer': url}),\n                'ie_key': 'Brightcove'\n            } for bc_url in bc_urls]\n\n            return {\n                '_type': 'playlist',\n                'title': video_title,\n                'id': video_id,\n                'entries': entries,\n            }\n\n        # Look for embedded (iframe) Vimeo player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//player\\.vimeo\\.com/video/.+?)\\1', webpage)\n        if mobj:\n            player_url = unescapeHTML(mobj.group('url'))\n            surl = smuggle_url(player_url, {'Referer': url})\n            return self.url_result(surl, 'Vimeo')\n\n        # Look for embedded (swf embed) Vimeo player\n        mobj = re.search(\n            r'<embed[^>]+?src=\"(https?://(?:www\\.)?vimeo\\.com/moogaloop\\.swf.+?)\"', webpage)\n        if mobj:\n            return self.url_result(mobj.group(1), 'Vimeo')\n\n        # Look for embedded YouTube player\n        matches = re.findall(r'''(?x)\n            (?:\n                <iframe[^>]+?src=|\n                data-video-url=|\n                <embed[^>]+?src=|\n                embedSWF\\(?:\\s*\n            )\n            ([\"\\'])\n                (?P<url>(?:https?:)?//(?:www\\.)?youtube(?:-nocookie)?\\.com/\n                (?:embed|v)/.+?)\n            \\1''', webpage)\n        if matches:\n            return _playlist_from_matches(\n                matches, lambda m: unescapeHTML(m[1]), ie='Youtube')\n\n        # Look for embedded Dailymotion player\n        matches = re.findall(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//(?:www\\.)?dailymotion\\.com/embed/video/.+?)\\1', webpage)\n        if matches:\n            return _playlist_from_matches(\n                matches, lambda m: unescapeHTML(m[1]))\n\n        # Look for embedded Wistia player\n        match = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//(?:fast\\.)?wistia\\.net/embed/iframe/.+?)\\1', webpage)\n        if match:\n            return {\n                '_type': 'url_transparent',\n                'url': unescapeHTML(match.group('url')),\n                'ie_key': 'Wistia',\n                'uploader': video_uploader,\n                'title': video_title,\n                'id': video_id,\n            }\n\n        # Look for embedded blip.tv player\n        mobj = re.search(r'<meta\\s[^>]*https?://api\\.blip\\.tv/\\w+/redirect/\\w+/(\\d+)', webpage)\n        if mobj:\n            return self.url_result('http://blip.tv/a/a-'+mobj.group(1), 'BlipTV')\n        mobj = re.search(r'<(?:iframe|embed|object)\\s[^>]*(https?://(?:\\w+\\.)?blip\\.tv/(?:play/|api\\.swf#)[a-zA-Z0-9_]+)', webpage)\n        if mobj:\n            return self.url_result(mobj.group(1), 'BlipTV')\n\n        # Look for embedded condenast player\n        matches = re.findall(\n            r'<iframe\\s+(?:[a-zA-Z-]+=\"[^\"]+\"\\s+)*?src=\"(https?://player\\.cnevids\\.com/embed/[^\"]+\")',\n            webpage)\n        if matches:\n            return {\n                '_type': 'playlist',\n                'entries': [{\n                    '_type': 'url',\n                    'ie_key': 'CondeNast',\n                    'url': ma,\n                } for ma in matches],\n                'title': video_title,\n                'id': video_id,\n            }\n\n        # Look for Bandcamp pages with custom domain\n        mobj = re.search(r'<meta property=\"og:url\"[^>]*?content=\"(.*?bandcamp\\.com.*?)\"', webpage)\n        if mobj is not None:\n            burl = unescapeHTML(mobj.group(1))\n            # Don't set the extractor because it can be a track url or an album\n            return self.url_result(burl)\n\n        # Look for embedded Vevo player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//(?:cache\\.)?vevo\\.com/.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'))\n\n        # Look for Ooyala videos\n        mobj = (re.search(r'player.ooyala.com/[^\"?]+\\?[^\"]*?(?:embedCode|ec)=(?P<ec>[^\"&]+)', webpage) or\n             re.search(r'OO.Player.create\\([\\'\"].*?[\\'\"],\\s*[\\'\"](?P<ec>.{32})[\\'\"]', webpage))\n        if mobj is not None:\n            return OoyalaIE._build_url_result(mobj.group('ec'))\n\n        # Look for Aparat videos\n        mobj = re.search(r'<iframe .*?src=\"(http://www\\.aparat\\.com/video/[^\"]+)\"', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group(1), 'Aparat')\n\n        # Look for MPORA videos\n        mobj = re.search(r'<iframe .*?src=\"(http://mpora\\.(?:com|de)/videos/[^\"]+)\"', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group(1), 'Mpora')\n\n        # Look for embedded NovaMov-based player\n        mobj = re.search(\n            r'''(?x)<(?:pagespeed_)?iframe[^>]+?src=([\"\\'])\n                    (?P<url>http://(?:(?:embed|www)\\.)?\n                        (?:novamov\\.com|\n                           nowvideo\\.(?:ch|sx|eu|at|ag|co)|\n                           videoweed\\.(?:es|com)|\n                           movshare\\.(?:net|sx|ag)|\n                           divxstage\\.(?:eu|net|ch|co|at|ag))\n                        /embed\\.php.+?)\\1''', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'))\n\n        # Look for embedded Facebook player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>https://www\\.facebook\\.com/video/embed.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'Facebook')\n\n        # Look for embedded VK player\n        mobj = re.search(r'<iframe[^>]+?src=([\"\\'])(?P<url>https?://vk\\.com/video_ext\\.php.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'VK')\n\n        # Look for embedded ivi player\n        mobj = re.search(r'<embed[^>]+?src=([\"\\'])(?P<url>https?://(?:www\\.)?ivi\\.ru/video/player.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'Ivi')\n\n        # Look for embedded Huffington Post player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>https?://embed\\.live\\.huffingtonpost\\.com/.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'HuffPost')\n\n        # Look for embed.ly\n        mobj = re.search(r'class=[\"\\']embedly-card[\"\\'][^>]href=[\"\\'](?P<url>[^\"\\']+)', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'))\n        mobj = re.search(r'class=[\"\\']embedly-embed[\"\\'][^>]src=[\"\\'][^\"\\']*url=(?P<url>[^&]+)', webpage)\n        if mobj is not None:\n            return self.url_result(compat_urllib_parse.unquote(mobj.group('url')))\n\n        # Look for funnyordie embed\n        matches = re.findall(r'<iframe[^>]+?src=\"(https?://(?:www\\.)?funnyordie\\.com/embed/[^\"]+)\"', webpage)\n        if matches:\n            return _playlist_from_matches(\n                matches, getter=unescapeHTML, ie='FunnyOrDie')\n\n        # Look for embedded RUTV player\n        rutv_url = RUTVIE._extract_url(webpage)\n        if rutv_url:\n            return self.url_result(rutv_url, 'RUTV')\n\n        # Look for embedded TED player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>http://embed\\.ted\\.com/.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'TED')\n\n        # Look for embedded Ustream videos\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>http://www\\.ustream\\.tv/embed/.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'Ustream')\n\n        # Look for embedded arte.tv player\n        mobj = re.search(\n            r'<script [^>]*?src=\"(?P<url>http://www\\.arte\\.tv/playerv2/embed[^\"]+)\"',\n            webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'ArteTVEmbed')\n\n        # Look for embedded smotri.com player\n        smotri_url = SmotriIE._extract_url(webpage)\n        if smotri_url:\n            return self.url_result(smotri_url, 'Smotri')\n\n        # Look for embeded soundcloud player\n        mobj = re.search(\n            r'<iframe src=\"(?P<url>https?://(?:w\\.)?soundcloud\\.com/player[^\"]+)\"',\n            webpage)\n        if mobj is not None:\n            url = unescapeHTML(mobj.group('url'))\n            return self.url_result(url)\n\n        # Look for embedded vulture.com player\n        mobj = re.search(\n            r'<iframe src=\"(?P<url>https?://video\\.vulture\\.com/[^\"]+)\"',\n            webpage)\n        if mobj is not None:\n            url = unescapeHTML(mobj.group('url'))\n            return self.url_result(url, ie='Vulture')\n\n        # Look for embedded mtvservices player\n        mobj = re.search(\n            r'<iframe src=\"(?P<url>https?://media\\.mtvnservices\\.com/embed/[^\"]+)\"',\n            webpage)\n        if mobj is not None:\n            url = unescapeHTML(mobj.group('url'))\n            return self.url_result(url, ie='MTVServicesEmbedded')\n\n        # Look for embedded yahoo player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>https?://(?:screen|movies)\\.yahoo\\.com/.+?\\.html\\?format=embed)\\1',\n            webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'Yahoo')\n\n        # Look for embedded sbs.com.au player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>https?://(?:www\\.)sbs\\.com\\.au/ondemand/video/single/.+?)\\1',\n            webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'SBS')\n\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>https?://m\\.mlb\\.com/shared/video/embed/embed\\.html\\?.+?)\\1',\n            webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'MLB')\n\n        # Start with something easy: JW Player in SWFObject\n        found = re.findall(r'flashvars: [\\'\"](?:.*&)?file=(http[^\\'\"&]*)', webpage)\n        if not found:\n            # Look for gorilla-vid style embedding\n            found = re.findall(r'''(?sx)\n                (?:\n                    jw_plugins|\n                    JWPlayerOptions|\n                    jwplayer\\s*\\(\\s*[\"'][^'\"]+[\"']\\s*\\)\\s*\\.setup\n                )\n                .*?file\\s*:\\s*[\"\\'](.*?)[\"\\']''', webpage)\n        if not found:\n            # Broaden the search a little bit\n            found = re.findall(r'[^A-Za-z0-9]?(?:file|source)=(http[^\\'\"&]*)', webpage)\n        if not found:\n            # Broaden the findall a little bit: JWPlayer JS loader\n            found = re.findall(r'[^A-Za-z0-9]?file[\"\\']?:\\s*[\"\\'](http(?![^\\'\"]+\\.[0-9]+[\\'\"])[^\\'\"]+)[\"\\']', webpage)\n        if not found:\n            # Flow player\n            found = re.findall(r'''(?xs)\n                flowplayer\\(\"[^\"]+\",\\s*\n                    \\{[^}]+?\\}\\s*,\n                    \\s*{[^}]+? [\"']?clip[\"']?\\s*:\\s*\\{\\s*\n                        [\"']?url[\"']?\\s*:\\s*[\"']([^\"']+)[\"']\n            ''', webpage)\n        if not found:\n            # Try to find twitter cards info\n            found = re.findall(r'<meta (?:property|name)=\"twitter:player:stream\" (?:content|value)=\"(.+?)\"', webpage)\n        if not found:\n            # We look for Open Graph info:\n            # We have to match any number spaces between elements, some sites try to align them (eg.: statigr.am)\n            m_video_type = re.findall(r'<meta.*?property=\"og:video:type\".*?content=\"video/(.*?)\"', webpage)\n            # We only look in og:video if the MIME type is a video, don't try if it's a Flash player:\n            if m_video_type is not None:\n                def check_video(vurl):\n                    vpath = compat_urlparse.urlparse(vurl).path\n                    vext = determine_ext(vpath)\n                    return '.' in vpath and vext not in ('swf', 'png', 'jpg')\n                found = list(filter(\n                    check_video,\n                    re.findall(r'<meta.*?property=\"og:video\".*?content=\"(.*?)\"', webpage)))\n        if not found:\n            # HTML5 video\n            found = re.findall(r'(?s)<video[^<]*(?:>.*?<source[^>]+)? src=\"([^\"]+)\"', webpage)\n        if not found:\n            found = re.search(\n                r'(?i)<meta\\s+(?=(?:[a-z-]+=\"[^\"]+\"\\s+)*http-equiv=\"refresh\")'\n                r'(?:[a-z-]+=\"[^\"]+\"\\s+)*?content=\"[0-9]{,2};url=\\'([^\\']+)\\'\"',\n                webpage)\n            if found:\n                new_url = found.group(1)\n                self.report_following_redirect(new_url)\n                return {\n                    '_type': 'url',\n                    'url': new_url,\n                }\n        if not found:\n            raise ExtractorError('Unsupported URL: %s' % url)\n\n        entries = []\n        for video_url in found:\n            video_url = compat_urlparse.urljoin(url, video_url)\n            video_id = compat_urllib_parse.unquote(os.path.basename(video_url))\n\n            # Sometimes, jwplayer extraction will result in a YouTube URL\n            if YoutubeIE.suitable(video_url):\n                entries.append(self.url_result(video_url, 'Youtube'))\n                continue\n\n            # here's a fun little line of code for you:\n            video_id = os.path.splitext(video_id)[0]\n\n            entries.append({\n                'id': video_id,\n                'url': video_url,\n                'uploader': video_uploader,\n                'title': video_title,\n                'age_limit': age_limit,\n            })\n\n        if len(entries) == 1:\n            return entries[0]\n        else:\n            for num, e in enumerate(entries, start=1):\n                e['title'] = '%s (%d)' % (e['title'], num)\n            return {\n                '_type': 'playlist',\n                'entries': entries,\n            }",
        "begin_line": 453,
        "end_line": 921,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0025,
            "pseudo_dstar_susp": 0.0024752475247524753,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0024752475247524753,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.generic.GenericIE._playlist_from_matches#586",
        "src_path": "youtube_dl/extractor/generic.py",
        "class_name": "youtube_dl.extractor.generic.GenericIE",
        "signature": "youtube_dl.extractor.generic.GenericIE._playlist_from_matches(matches, getter, ie=None)",
        "snippet": "        def _playlist_from_matches(matches, getter, ie=None):\n            urlrs = orderedSet(self.url_result(getter(m), ie) for m in matches)\n            return self.playlist_result(\n                urlrs, playlist_id=video_id, playlist_title=video_title)",
        "begin_line": 586,
        "end_line": 589,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0018281535648994515,
            "pseudo_dstar_susp": 0.0013458950201884253,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0013458950201884253,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.generic.GenericIE.check_video#867",
        "src_path": "youtube_dl/extractor/generic.py",
        "class_name": "youtube_dl.extractor.generic.GenericIE",
        "signature": "youtube_dl.extractor.generic.GenericIE.check_video(vurl)",
        "snippet": "                def check_video(vurl):\n                    vpath = compat_urlparse.urlparse(vurl).path\n                    vext = determine_ext(vpath)\n                    return '.' in vpath and vext not in ('swf', 'png', 'jpg')",
        "begin_line": 867,
        "end_line": 870,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0013986013986013986,
            "pseudo_dstar_susp": 0.0010482180293501049,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0010482180293501049,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionBaseInfoExtractor._build_request#23",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionBaseInfoExtractor",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionBaseInfoExtractor._build_request(url)",
        "snippet": "    def _build_request(url):\n        \"\"\"Build a request with the family filter disabled\"\"\"\n        request = compat_urllib_request.Request(url)\n        request.add_header('Cookie', 'family_filter=off')\n        request.add_header('Cookie', 'ff=off')\n        return request",
        "begin_line": 23,
        "end_line": 28,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001644736842105263,
            "pseudo_dstar_susp": 0.0012453300124533001,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0012453300124533001,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionIE._real_extract#84",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionIE",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        # Extract id and simplified title from URL\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n\n        url = 'http://www.dailymotion.com/video/%s' % video_id\n\n        # Retrieve video webpage to extract further information\n        request = self._build_request(url)\n        webpage = self._download_webpage(request, video_id)\n\n        # Extract URL, uploader and title from webpage\n        self.report_extraction(video_id)\n\n        # It may just embed a vevo video:\n        m_vevo = re.search(\n            r'<link rel=\"video_src\" href=\"[^\"]*?vevo.com[^\"]*?videoId=(?P<id>[\\w]*)',\n            webpage)\n        if m_vevo is not None:\n            vevo_id = m_vevo.group('id')\n            self.to_screen('Vevo video detected: %s' % vevo_id)\n            return self.url_result('vevo:%s' % vevo_id, ie='Vevo')\n\n        age_limit = self._rta_search(webpage)\n\n        video_upload_date = None\n        mobj = re.search(r'<div class=\"[^\"]*uploaded_cont[^\"]*\" title=\"[^\"]*\">([0-9]{2})-([0-9]{2})-([0-9]{4})</div>', webpage)\n        if mobj is not None:\n            video_upload_date = mobj.group(3) + mobj.group(2) + mobj.group(1)\n\n        embed_url = 'http://www.dailymotion.com/embed/video/%s' % video_id\n        embed_page = self._download_webpage(embed_url, video_id,\n                                            'Downloading embed page')\n        info = self._search_regex(r'var info = ({.*?}),$', embed_page,\n            'video info', flags=re.MULTILINE)\n        info = json.loads(info)\n        if info.get('error') is not None:\n            msg = 'Couldn\\'t get video, Dailymotion says: %s' % info['error']['title']\n            raise ExtractorError(msg, expected=True)\n\n        formats = []\n        for (key, format_id) in self._FORMATS:\n            video_url = info.get(key)\n            if video_url is not None:\n                m_size = re.search(r'H264-(\\d+)x(\\d+)', video_url)\n                if m_size is not None:\n                    width, height = map(int_or_none, (m_size.group(1), m_size.group(2)))\n                else:\n                    width, height = None, None\n                formats.append({\n                    'url': video_url,\n                    'ext': 'mp4',\n                    'format_id': format_id,\n                    'width': width,\n                    'height': height,\n                })\n        if not formats:\n            raise ExtractorError('Unable to extract video URL')\n\n        # subtitles\n        video_subtitles = self.extract_subtitles(video_id, webpage)\n        if self._downloader.params.get('listsubtitles', False):\n            self._list_available_subtitles(video_id, webpage)\n            return\n\n        view_count = self._search_regex(\n            r'video_views_count[^>]+>\\s+([\\d\\.,]+)', webpage, 'view count', fatal=False)\n        if view_count is not None:\n            view_count = str_to_int(view_count)\n\n        return {\n            'id':       video_id,\n            'formats': formats,\n            'uploader': info['owner.screenname'],\n            'upload_date':  video_upload_date,\n            'title':    self._og_search_title(webpage),\n            'subtitles':    video_subtitles,\n            'thumbnail': info['thumbnail_url'],\n            'age_limit': age_limit,\n            'view_count': view_count,\n        }",
        "begin_line": 84,
        "end_line": 165,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0015015015015015015,
            "pseudo_dstar_susp": 0.0011235955056179776,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0011235955056179776,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionIE._get_available_subtitles#167",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionIE",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionIE._get_available_subtitles(self, video_id, webpage)",
        "snippet": "    def _get_available_subtitles(self, video_id, webpage):\n        try:\n            sub_list = self._download_webpage(\n                'https://api.dailymotion.com/video/%s/subtitles?fields=id,language,url' % video_id,\n                video_id, note=False)\n        except ExtractorError as err:\n            self._downloader.report_warning('unable to download video subtitles: %s' % compat_str(err))\n            return {}\n        info = json.loads(sub_list)\n        if (info['total'] > 0):\n            sub_lang_list = dict((l['language'], l['url']) for l in info['list'])\n            return sub_lang_list\n        self._downloader.report_warning('video doesn\\'t have subtitles')\n        return {}",
        "begin_line": 167,
        "end_line": 180,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionPlaylistIE._extract_entries#196",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionPlaylistIE",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionPlaylistIE._extract_entries(self, id)",
        "snippet": "    def _extract_entries(self, id):\n        video_ids = []\n        for pagenum in itertools.count(1):\n            request = self._build_request(self._PAGE_TEMPLATE % (id, pagenum))\n            webpage = self._download_webpage(request,\n                                             id, 'Downloading page %s' % pagenum)\n\n            video_ids.extend(re.findall(r'data-xid=\"(.+?)\"', webpage))\n\n            if re.search(self._MORE_PAGES_INDICATOR, webpage) is None:\n                break\n        return [self.url_result('http://www.dailymotion.com/video/%s' % video_id, 'Dailymotion')\n                   for video_id in orderedSet(video_ids)]",
        "begin_line": 196,
        "end_line": 208,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionPlaylistIE._real_extract#210",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionPlaylistIE",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('id')\n        webpage = self._download_webpage(url, playlist_id)\n\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'title': self._og_search_title(webpage),\n            'entries': self._extract_entries(playlist_id),\n        }",
        "begin_line": 210,
        "end_line": 220,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionUserIE._real_extract#236",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionUserIE",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        user = mobj.group('user')\n        webpage = self._download_webpage(url, user)\n        full_user = unescapeHTML(self._html_search_regex(\n            r'<a class=\"nav-image\" title=\"([^\"]+)\" href=\"/%s\">' % re.escape(user),\n            webpage, 'user'))\n\n        return {\n            '_type': 'playlist',\n            'id': user,\n            'title': full_user,\n            'entries': self._extract_entries(user),\n        }",
        "begin_line": 236,
        "end_line": 249,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.tlc.TlcDeIE._real_extract#45",
        "src_path": "youtube_dl/extractor/tlc.py",
        "class_name": "youtube_dl.extractor.tlc.TlcDeIE",
        "signature": "youtube_dl.extractor.tlc.TlcDeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        title = mobj.group('title')\n        webpage = self._download_webpage(url, title)\n        iframe_url = self._search_regex(\n            '<iframe src=\"(http://www\\.tlc\\.de/wp-content/.+?)\"', webpage,\n            'iframe url')\n        # Otherwise we don't get the correct 'BrightcoveExperience' element,\n        # example: http://www.tlc.de/sendungen/cake-boss/videos/cake-boss-cannoli-drama/\n        iframe_url = iframe_url.replace('.htm?', '.php?')\n        url_fragment = compat_urlparse.urlparse(url).fragment\n        if url_fragment:\n            # Since the fragment is not send to the server, we always get the same iframe\n            iframe_url = re.sub(r'playlist=(\\d+)', 'playlist=%s' % url_fragment, iframe_url)\n        iframe = self._download_webpage(iframe_url, title)\n\n        return {\n            '_type': 'url',\n            'url': BrightcoveIE._extract_brightcove_url(iframe),\n            'ie': BrightcoveIE.ie_key(),\n        }",
        "begin_line": 45,
        "end_line": 65,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.videopremium.VideoPremiumIE._real_extract#21",
        "src_path": "youtube_dl/extractor/videopremium.py",
        "class_name": "youtube_dl.extractor.videopremium.VideoPremiumIE",
        "signature": "youtube_dl.extractor.videopremium.VideoPremiumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n        webpage_url = 'http://videopremium.tv/' + video_id\n        webpage = self._download_webpage(webpage_url, video_id)\n\n        if re.match(r\"^<html><head><script[^>]*>window.location\\s*=\", webpage):\n            # Download again, we need a cookie\n            webpage = self._download_webpage(\n                webpage_url, video_id,\n                note=u'Downloading webpage again (with cookie)')\n\n        video_title = self._html_search_regex(\n            r'<h2(?:.*?)>\\s*(.+?)\\s*<', webpage, u'video title')\n\n        return {\n            'id':          video_id,\n            'url':         \"rtmp://e%d.md.iplay.md/play\" % random.randint(1, 16),\n            'play_path':   \"mp4:%s.f4v\" % video_id,\n            'page_url':    \"http://videopremium.tv/\" + video_id,\n            'player_url':  \"http://videopremium.tv/uplayer/uppod.swf\",\n            'ext':         'f4v',\n            'title':       video_title,\n        }",
        "begin_line": 21,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.malemotion.MalemotionIE._real_extract#23",
        "src_path": "youtube_dl/extractor/malemotion.py",
        "class_name": "youtube_dl.extractor.malemotion.MalemotionIE",
        "signature": "youtube_dl.extractor.malemotion.MalemotionIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group(\"id\")\n\n        webpage = self._download_webpage(url, video_id)\n\n        self.report_extraction(video_id)\n\n        # Extract video URL\n        video_url = compat_urllib_parse.unquote(\n            self._search_regex(r'<source type=\"video/mp4\" src=\"(.+?)\"', webpage, 'video URL'))\n\n        # Extract title\n        video_title = self._html_search_regex(\n            r'<title>(.*?)</title', webpage, 'title')\n\n        # Extract video thumbnail\n        video_thumbnail = self._search_regex(\n            r'<video .+?poster=\"(.+?)\"', webpage, 'thumbnail', fatal=False)\n\n        formats = [{\n            'url': video_url,\n            'ext': 'mp4',\n            'format_id': 'mp4',\n            'preference': 1,\n        }]\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'uploader': None,\n            'upload_date': None,\n            'title': video_title,\n            'thumbnail': video_thumbnail,\n            'description': None,\n            'age_limit': 18,\n        }",
        "begin_line": 23,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.sapo.SapoIE._real_extract#65",
        "src_path": "youtube_dl/extractor/sapo.py",
        "class_name": "youtube_dl.extractor.sapo.SapoIE",
        "signature": "youtube_dl.extractor.sapo.SapoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        item = self._download_xml(\n            'http://rd3.videos.sapo.pt/%s/rss2' % video_id, video_id).find('./channel/item')\n\n        title = item.find('./title').text\n        description = item.find('./{http://videos.sapo.pt/mrss/}synopse').text\n        thumbnail = item.find('./{http://search.yahoo.com/mrss/}content').get('url')\n        duration = parse_duration(item.find('./{http://videos.sapo.pt/mrss/}time').text)\n        uploader = item.find('./{http://videos.sapo.pt/mrss/}author').text\n        upload_date = unified_strdate(item.find('./pubDate').text)\n        view_count = int(item.find('./{http://videos.sapo.pt/mrss/}views').text)\n        comment_count = int(item.find('./{http://videos.sapo.pt/mrss/}comment_count').text)\n        tags = item.find('./{http://videos.sapo.pt/mrss/}tags').text\n        categories = tags.split() if tags else []\n        age_limit = 18 if item.find('./{http://videos.sapo.pt/mrss/}m18').text == 'true' else 0\n\n        video_url = item.find('./{http://videos.sapo.pt/mrss/}videoFile').text\n        video_size = item.find('./{http://videos.sapo.pt/mrss/}videoSize').text.split('x')\n\n        formats = [{\n            'url': video_url,\n            'ext': 'mp4',\n            'format_id': 'sd',\n            'width': int(video_size[0]),\n            'height': int(video_size[1]),\n        }]\n\n        if item.find('./{http://videos.sapo.pt/mrss/}HD').text == 'true':\n            formats.append({\n                'url': re.sub(r'/mov/1$', '/mov/39', video_url),\n                'ext': 'mp4',\n                'format_id': 'hd',\n                'width': 1280,\n                'height': 720,\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'uploader': uploader,\n            'upload_date': upload_date,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'categories': categories,\n            'age_limit': age_limit,\n            'formats': formats,\n        }",
        "begin_line": 65,
        "end_line": 119,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.savefrom.SaveFromIE._real_extract#30",
        "src_path": "youtube_dl/extractor/savefrom.py",
        "class_name": "youtube_dl.extractor.savefrom.SaveFromIE",
        "signature": "youtube_dl.extractor.savefrom.SaveFromIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = os.path.splitext(url.split('/')[-1])[0]\n        return {\n            '_type': 'url',\n            'id': video_id,\n            'url': mobj.group('url'),\n        }",
        "begin_line": 30,
        "end_line": 37,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.criterion.CriterionIE._real_extract#22",
        "src_path": "youtube_dl/extractor/criterion.py",
        "class_name": "youtube_dl.extractor.criterion.CriterionIE",
        "signature": "youtube_dl.extractor.criterion.CriterionIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n\n        final_url = self._search_regex(\n            r'so.addVariable\\(\"videoURL\", \"(.+?)\"\\)\\;', webpage, 'video url')\n        title = self._og_search_title(webpage)\n        description = self._html_search_regex(\n            r'<meta name=\"description\" content=\"(.+?)\" />',\n            webpage, 'video description')\n        thumbnail = self._search_regex(\n            r'so.addVariable\\(\"thumbnailURL\", \"(.+?)\"\\)\\;',\n            webpage, 'thumbnail url')\n\n        return {\n            'id': video_id,\n            'url': final_url,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 22,
        "end_line": 43,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.lynda.LyndaIE._real_initialize#40",
        "src_path": "youtube_dl/extractor/lynda.py",
        "class_name": "youtube_dl.extractor.lynda.LyndaIE",
        "signature": "youtube_dl.extractor.lynda.LyndaIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 40,
        "end_line": 41,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.lynda.LyndaIE._real_extract#43",
        "src_path": "youtube_dl/extractor/lynda.py",
        "class_name": "youtube_dl.extractor.lynda.LyndaIE",
        "signature": "youtube_dl.extractor.lynda.LyndaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group(1)\n\n        page = self._download_webpage('http://www.lynda.com/ajax/player?videoId=%s&type=video' % video_id, video_id,\n            'Downloading video JSON')\n        video_json = json.loads(page)\n\n        if 'Status' in video_json:\n            raise ExtractorError('lynda returned error: %s' % video_json['Message'], expected=True)\n\n        if video_json['HasAccess'] is False:\n            raise ExtractorError(\n                'Video %s is only available for members. ' % video_id + self.ACCOUNT_CREDENTIALS_HINT, expected=True)\n\n        video_id = compat_str(video_json['ID'])\n        duration = video_json['DurationInSeconds']\n        title = video_json['Title']\n\n        formats = []\n\n        fmts = video_json.get('Formats')\n        if fmts:\n            formats.extend([\n                {\n                    'url': fmt['Url'],\n                    'ext': fmt['Extension'],\n                    'width': fmt['Width'],\n                    'height': fmt['Height'],\n                    'filesize': fmt['FileSize'],\n                    'format_id': str(fmt['Resolution'])\n                } for fmt in fmts])\n\n        prioritized_streams = video_json.get('PrioritizedStreams')\n        if prioritized_streams:\n            formats.extend([\n                {\n                    'url': video_url,\n                    'width': int_or_none(format_id),\n                    'format_id': format_id,\n                } for format_id, video_url in prioritized_streams['0'].items()\n            ])\n\n        self._sort_formats(formats)\n\n        if self._downloader.params.get('listsubtitles', False):\n            self._list_available_subtitles(video_id, page)\n            return\n\n        subtitles = self._fix_subtitles(self.extract_subtitles(video_id, page))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'duration': duration,\n            'subtitles': subtitles,\n            'formats': formats\n        }",
        "begin_line": 43,
        "end_line": 100,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.lynda.LyndaIE._login#102",
        "src_path": "youtube_dl/extractor/lynda.py",
        "class_name": "youtube_dl.extractor.lynda.LyndaIE",
        "signature": "youtube_dl.extractor.lynda.LyndaIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n\n        login_form = {\n            'username': username,\n            'password': password,\n            'remember': 'false',\n            'stayPut': 'false'\n        }        \n        request = compat_urllib_request.Request(self._LOGIN_URL, compat_urllib_parse.urlencode(login_form))\n        login_page = self._download_webpage(request, None, 'Logging in as %s' % username)\n\n        # Not (yet) logged in\n        m = re.search(r'loginResultJson = \\'(?P<json>[^\\']+)\\';', login_page)\n        if m is not None:\n            response = m.group('json')\n            response_json = json.loads(response)            \n            state = response_json['state']\n\n            if state == 'notlogged':\n                raise ExtractorError('Unable to login, incorrect username and/or password', expected=True)\n\n            # This is when we get popup:\n            # > You're already logged in to lynda.com on two devices.\n            # > If you log in here, we'll log you out of another device.\n            # So, we need to confirm this.\n            if state == 'conflicted':\n                confirm_form = {\n                    'username': '',\n                    'password': '',\n                    'resolve': 'true',\n                    'remember': 'false',\n                    'stayPut': 'false',\n                }\n                request = compat_urllib_request.Request(self._LOGIN_URL, compat_urllib_parse.urlencode(confirm_form))\n                login_page = self._download_webpage(request, None, 'Confirming log in and log out from another device')\n\n        if re.search(self._SUCCESSFUL_LOGIN_REGEX, login_page) is None:\n            raise ExtractorError('Unable to log in')",
        "begin_line": 102,
        "end_line": 142,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.lynda.LyndaIE._fix_subtitles#144",
        "src_path": "youtube_dl/extractor/lynda.py",
        "class_name": "youtube_dl.extractor.lynda.LyndaIE",
        "signature": "youtube_dl.extractor.lynda.LyndaIE._fix_subtitles(self, subtitles)",
        "snippet": "    def _fix_subtitles(self, subtitles):\n        if subtitles is None:\n            return subtitles  # subtitles not requested\n\n        fixed_subtitles = {}\n        for k, v in subtitles.items():\n            subs = json.loads(v)\n            if len(subs) == 0:\n                continue\n            srt = ''\n            for pos in range(0, len(subs) - 1):\n                seq_current = subs[pos]\n                m_current = re.match(self._TIMECODE_REGEX, seq_current['Timecode'])\n                if m_current is None:\n                    continue\n                seq_next = subs[pos + 1]\n                m_next = re.match(self._TIMECODE_REGEX, seq_next['Timecode'])\n                if m_next is None:\n                    continue\n                appear_time = m_current.group('timecode')\n                disappear_time = m_next.group('timecode')\n                text = seq_current['Caption']\n                srt += '%s\\r\\n%s --> %s\\r\\n%s' % (str(pos), appear_time, disappear_time, text)\n            if srt:\n                fixed_subtitles[k] = srt\n        return fixed_subtitles",
        "begin_line": 144,
        "end_line": 169,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.lynda.LyndaIE._get_available_subtitles#171",
        "src_path": "youtube_dl/extractor/lynda.py",
        "class_name": "youtube_dl.extractor.lynda.LyndaIE",
        "signature": "youtube_dl.extractor.lynda.LyndaIE._get_available_subtitles(self, video_id, webpage)",
        "snippet": "    def _get_available_subtitles(self, video_id, webpage):\n        url = 'http://www.lynda.com/ajax/player?videoId=%s&type=transcript' % video_id\n        sub = self._download_webpage(url, None, False)\n        sub_json = json.loads(sub)\n        return {'en': url} if len(sub_json) > 0 else {}",
        "begin_line": 171,
        "end_line": 175,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.lynda.LyndaCourseIE._real_extract#186",
        "src_path": "youtube_dl/extractor/lynda.py",
        "class_name": "youtube_dl.extractor.lynda.LyndaCourseIE",
        "signature": "youtube_dl.extractor.lynda.LyndaCourseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        course_path = mobj.group('coursepath')\n        course_id = mobj.group('courseid')\n        \n        page = self._download_webpage('http://www.lynda.com/ajax/player?courseId=%s&type=course' % course_id,\n                                      course_id, 'Downloading course JSON')\n        course_json = json.loads(page)\n\n        if 'Status' in course_json and course_json['Status'] == 'NotFound':\n            raise ExtractorError('Course %s does not exist' % course_id, expected=True)\n\n        unaccessible_videos = 0\n        videos = []\n        (username, _) = self._get_login_info()\n\n        # Might want to extract videos right here from video['Formats'] as it seems 'Formats' is not provided\n        # by single video API anymore\n\n        for chapter in course_json['Chapters']:\n            for video in chapter['Videos']:\n                if username is None and video['HasAccess'] is False:\n                    unaccessible_videos += 1\n                    continue\n                videos.append(video['ID'])\n\n        if unaccessible_videos > 0:\n            self._downloader.report_warning('%s videos are only available for members and will not be downloaded. '\n                                            % unaccessible_videos + LyndaIE.ACCOUNT_CREDENTIALS_HINT)\n\n        entries = [\n            self.url_result('http://www.lynda.com/%s/%s-4.html' %\n                            (course_path, video_id),\n                            'Lynda')\n            for video_id in videos]\n\n        course_title = course_json['Title']\n\n        return self.playlist_result(entries, course_id, course_title)",
        "begin_line": 186,
        "end_line": 224,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.extremetube.ExtremeTubeIE._real_extract#30",
        "src_path": "youtube_dl/extractor/extremetube.py",
        "class_name": "youtube_dl.extractor.extremetube.ExtremeTubeIE",
        "signature": "youtube_dl.extractor.extremetube.ExtremeTubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n        url = 'http://www.' + mobj.group('url')\n\n        req = compat_urllib_request.Request(url)\n        req.add_header('Cookie', 'age_verified=1')\n        webpage = self._download_webpage(req, video_id)\n\n        video_title = self._html_search_regex(\n            r'<h1 [^>]*?title=\"([^\"]+)\"[^>]*>', webpage, 'title')\n        uploader = self._html_search_regex(\n            r'>Posted by:(?=<)(?:\\s|<[^>]*>)*(.+?)\\|', webpage, 'uploader',\n            fatal=False)\n        video_url = compat_urllib_parse.unquote(self._html_search_regex(\n            r'video_url=(.+?)&amp;', webpage, 'video_url'))\n        path = compat_urllib_parse_urlparse(video_url).path\n        format = path.split('/')[5].split('_')[:2]\n        format = \"-\".join(format)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'uploader': uploader,\n            'url': video_url,\n            'format': format,\n            'format_id': format,\n            'age_limit': 18,\n        }",
        "begin_line": 30,
        "end_line": 58,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.iprima.IPrimaIE._real_extract#45",
        "src_path": "youtube_dl/extractor/iprima.py",
        "class_name": "youtube_dl.extractor.iprima.IPrimaIE",
        "signature": "youtube_dl.extractor.iprima.IPrimaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        if re.search(r'Nem\u00e1te opr\u00e1vn\u011bn\u00ed p\u0159istupovat na tuto str\u00e1nku\\.\\s*</div>', webpage):\n            raise ExtractorError(\n                '%s said: You do not have permission to access this page' % self.IE_NAME, expected=True)\n\n        player_url = (\n            'http://embed.livebox.cz/iprimaplay/player-embed-v2.js?__tok%s__=%s' %\n            (floor(random()*1073741824), floor(random()*1073741824))\n        )\n\n        req = compat_urllib_request.Request(player_url)\n        req.add_header('Referer', url)\n        playerpage = self._download_webpage(req, video_id)\n\n        base_url = ''.join(re.findall(r\"embed\\['stream'\\] = '(.+?)'.+'(\\?auth=)'.+'(.+?)';\", playerpage)[1])\n\n        zoneGEO = self._html_search_regex(r'\"zoneGEO\":(.+?),', webpage, 'zoneGEO')\n        if zoneGEO != '0':\n            base_url = base_url.replace('token', 'token_' + zoneGEO)\n\n        formats = []\n        for format_id in ['lq', 'hq', 'hd']:\n            filename = self._html_search_regex(\n                r'\"%s_id\":(.+?),' % format_id, webpage, 'filename')\n\n            if filename == 'null':\n                continue\n\n            real_id = self._search_regex(\n                r'Prima-(?:[0-9]{10}|WEB)-([0-9]+)[-_]',\n                filename, 'real video id')\n\n            if format_id == 'lq':\n                quality = 0\n            elif format_id == 'hq':\n                quality = 1\n            elif format_id == 'hd':\n                quality = 2\n                filename = 'hq/' + filename\n\n            formats.append({\n                'format_id': format_id,\n                'url': base_url,\n                'quality': quality,\n                'play_path': 'mp4:' + filename.replace('\"', '')[:-4],\n                'rtmp_live': True,\n                'ext': 'flv',\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': real_id,\n            'title': self._og_search_title(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'formats': formats,\n            'description': self._og_search_description(webpage),\n        }",
        "begin_line": 45,
        "end_line": 107,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.musicvault.MusicVaultIE._real_extract#31",
        "src_path": "youtube_dl/extractor/musicvault.py",
        "class_name": "youtube_dl.extractor.musicvault.MusicVaultIE",
        "signature": "youtube_dl.extractor.musicvault.MusicVaultIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('display_id')\n        webpage = self._download_webpage(url, display_id)\n\n        thumbnail = self._search_regex(\n            r'<meta itemprop=\"thumbnail\" content=\"([^\"]+)\"',\n            webpage, 'thumbnail', fatal=False)\n\n        data_div = self._search_regex(\n            r'(?s)<div class=\"data\">(.*?)</div>', webpage, 'data fields')\n        uploader = self._html_search_regex(\n            r'<h1.*?>(.*?)</h1>', data_div, 'uploader', fatal=False)\n        title = self._html_search_regex(\n            r'<h2.*?>(.*?)</h2>', data_div, 'title')\n        upload_date = unified_strdate(self._html_search_regex(\n            r'<h3.*?>(.*?)</h3>', data_div, 'uploader', fatal=False))\n        location = self._html_search_regex(\n            r'<h4.*?>(.*?)</h4>', data_div, 'location', fatal=False)\n\n        duration = parse_duration(self._html_search_meta('duration', webpage))\n\n        VIDEO_URL_TEMPLATE = 'http://cdnapi.kaltura.com/p/%(uid)s/sp/%(wid)s/playManifest/entryId/%(entry_id)s/format/url/protocol/http'\n        kaltura_id = self._search_regex(\n            r'<div id=\"video-detail-player\" data-kaltura-id=\"([^\"]+)\"',\n            webpage, 'kaltura ID')\n        video_url = VIDEO_URL_TEMPLATE % {\n            'entry_id': kaltura_id,\n            'wid': self._search_regex(r'/wid/_([0-9]+)/', webpage, 'wid'),\n            'uid': self._search_regex(r'uiconf_id/([0-9]+)/', webpage, 'uid'),\n        }\n\n        return {\n            'id': mobj.group('id'),\n            'url': video_url,\n            'ext': 'mp4',\n            'display_id': display_id,\n            'uploader_id': mobj.group('uploader_id'),\n            'thumbnail': thumbnail,\n            'description': self._html_search_meta('description', webpage),\n            'upload_date': upload_date,\n            'location': location,\n            'title': title,\n            'uploader': uploader,\n            'duration': duration,\n        }",
        "begin_line": 31,
        "end_line": 76,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.tumblr.TumblrIE._real_extract#36",
        "src_path": "youtube_dl/extractor/tumblr.py",
        "class_name": "youtube_dl.extractor.tumblr.TumblrIE",
        "signature": "youtube_dl.extractor.tumblr.TumblrIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m_url = re.match(self._VALID_URL, url)\n        video_id = m_url.group('id')\n        blog = m_url.group('blog_name')\n\n        url = 'http://%s.tumblr.com/post/%s/' % (blog, video_id)\n        webpage = self._download_webpage(url, video_id)\n\n        re_video = r'src=\\\\x22(?P<video_url>http://%s\\.tumblr\\.com/video_file/%s/(.*?))\\\\x22 type=\\\\x22video/(?P<ext>.*?)\\\\x22' % (blog, video_id)\n        video = re.search(re_video, webpage)\n        if video is None:\n            raise ExtractorError('Unable to extract video')\n        video_url = video.group('video_url')\n        ext = video.group('ext')\n\n        video_thumbnail = self._search_regex(\n            r'posters.*?\\[\\\\x22(.*?)\\\\x22',\n            webpage, 'thumbnail', fatal=False)  # We pick the first poster\n        if video_thumbnail:\n            video_thumbnail = video_thumbnail.replace('\\\\\\\\/', '/')\n\n        # The only place where you can get a title, it's not complete,\n        # but searching in other places doesn't work for all videos\n        video_title = self._html_search_regex(\n            r'(?s)<title>(?P<title>.*?)(?: \\| Tumblr)?</title>',\n            webpage, 'title')\n\n        return {\n            'id': video_id,\n             'url': video_url,\n             'title': video_title,\n             'description': self._html_search_meta('description', webpage),\n             'thumbnail': video_thumbnail,\n             'ext': ext,\n        }",
        "begin_line": 36,
        "end_line": 70,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.grooveshark.GroovesharkHtmlParser.__init__#20",
        "src_path": "youtube_dl/extractor/grooveshark.py",
        "class_name": "youtube_dl.extractor.grooveshark.GroovesharkHtmlParser",
        "signature": "youtube_dl.extractor.grooveshark.GroovesharkHtmlParser.__init__(self)",
        "snippet": "    def __init__(self):\n        self._current_object = None\n        self.objects = []\n        compat_html_parser.HTMLParser.__init__(self)",
        "begin_line": 20,
        "end_line": 23,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.grooveshark.GroovesharkHtmlParser.handle_starttag#25",
        "src_path": "youtube_dl/extractor/grooveshark.py",
        "class_name": "youtube_dl.extractor.grooveshark.GroovesharkHtmlParser",
        "signature": "youtube_dl.extractor.grooveshark.GroovesharkHtmlParser.handle_starttag(self, tag, attrs)",
        "snippet": "    def handle_starttag(self, tag, attrs):\n        attrs = dict((k, v) for k, v in attrs)\n        if tag == 'object':\n            self._current_object = {'attrs': attrs, 'params': []}\n        elif tag == 'param':\n            self._current_object['params'].append(attrs)",
        "begin_line": 25,
        "end_line": 30,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.grooveshark.GroovesharkHtmlParser.handle_endtag#32",
        "src_path": "youtube_dl/extractor/grooveshark.py",
        "class_name": "youtube_dl.extractor.grooveshark.GroovesharkHtmlParser",
        "signature": "youtube_dl.extractor.grooveshark.GroovesharkHtmlParser.handle_endtag(self, tag)",
        "snippet": "    def handle_endtag(self, tag):\n        if tag == 'object':\n            self.objects.append(self._current_object)\n            self._current_object = None",
        "begin_line": 32,
        "end_line": 35,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.grooveshark.GroovesharkHtmlParser.extract_object_tags#38",
        "src_path": "youtube_dl/extractor/grooveshark.py",
        "class_name": "youtube_dl.extractor.grooveshark.GroovesharkHtmlParser",
        "signature": "youtube_dl.extractor.grooveshark.GroovesharkHtmlParser.extract_object_tags(cls, html)",
        "snippet": "    def extract_object_tags(cls, html):\n        p = cls()\n        p.feed(html)\n        p.close()\n        return p.objects",
        "begin_line": 38,
        "end_line": 42,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.grooveshark.GroovesharkIE._parse_target#61",
        "src_path": "youtube_dl/extractor/grooveshark.py",
        "class_name": "youtube_dl.extractor.grooveshark.GroovesharkIE",
        "signature": "youtube_dl.extractor.grooveshark.GroovesharkIE._parse_target(self, target)",
        "snippet": "    def _parse_target(self, target):\n        uri = compat_urlparse.urlparse(target)\n        hash = uri.fragment[1:].split('?')[0]\n        token = os.path.basename(hash.rstrip('/'))\n        return (uri, hash, token)",
        "begin_line": 61,
        "end_line": 65,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.grooveshark.GroovesharkIE._build_bootstrap_url#67",
        "src_path": "youtube_dl/extractor/grooveshark.py",
        "class_name": "youtube_dl.extractor.grooveshark.GroovesharkIE",
        "signature": "youtube_dl.extractor.grooveshark.GroovesharkIE._build_bootstrap_url(self, target)",
        "snippet": "    def _build_bootstrap_url(self, target):\n        (uri, hash, token) = self._parse_target(target)\n        query = 'getCommunicationToken=1&hash=%s&%d' % (compat_urllib_parse.quote(hash, safe=''), self.ts)\n        return (compat_urlparse.urlunparse((uri.scheme, uri.netloc, '/preload.php', None, query, None)), token)",
        "begin_line": 67,
        "end_line": 70,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.grooveshark.GroovesharkIE._build_meta_url#72",
        "src_path": "youtube_dl/extractor/grooveshark.py",
        "class_name": "youtube_dl.extractor.grooveshark.GroovesharkIE",
        "signature": "youtube_dl.extractor.grooveshark.GroovesharkIE._build_meta_url(self, target)",
        "snippet": "    def _build_meta_url(self, target):\n        (uri, hash, token) = self._parse_target(target)\n        query = 'hash=%s&%d' % (compat_urllib_parse.quote(hash, safe=''), self.ts)\n        return (compat_urlparse.urlunparse((uri.scheme, uri.netloc, '/preload.php', None, query, None)), token)",
        "begin_line": 72,
        "end_line": 75,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.grooveshark.GroovesharkIE._build_stream_url#77",
        "src_path": "youtube_dl/extractor/grooveshark.py",
        "class_name": "youtube_dl.extractor.grooveshark.GroovesharkIE",
        "signature": "youtube_dl.extractor.grooveshark.GroovesharkIE._build_stream_url(self, meta)",
        "snippet": "    def _build_stream_url(self, meta):\n        return compat_urlparse.urlunparse(('http', meta['streamKey']['ip'], '/stream.php', None, None, None))",
        "begin_line": 77,
        "end_line": 78,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.grooveshark.GroovesharkIE._build_swf_referer#80",
        "src_path": "youtube_dl/extractor/grooveshark.py",
        "class_name": "youtube_dl.extractor.grooveshark.GroovesharkIE",
        "signature": "youtube_dl.extractor.grooveshark.GroovesharkIE._build_swf_referer(self, target, obj)",
        "snippet": "    def _build_swf_referer(self, target, obj):\n        (uri, _, _) = self._parse_target(target)\n        return compat_urlparse.urlunparse((uri.scheme, uri.netloc, obj['attrs']['data'], None, None, None))",
        "begin_line": 80,
        "end_line": 82,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.grooveshark.GroovesharkIE._transform_bootstrap#84",
        "src_path": "youtube_dl/extractor/grooveshark.py",
        "class_name": "youtube_dl.extractor.grooveshark.GroovesharkIE",
        "signature": "youtube_dl.extractor.grooveshark.GroovesharkIE._transform_bootstrap(self, js)",
        "snippet": "    def _transform_bootstrap(self, js):\n        return re.split('(?m)^\\s*try\\s*{', js)[0] \\\n                 .split(' = ', 1)[1].strip().rstrip(';')",
        "begin_line": 84,
        "end_line": 86,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.grooveshark.GroovesharkIE._transform_meta#88",
        "src_path": "youtube_dl/extractor/grooveshark.py",
        "class_name": "youtube_dl.extractor.grooveshark.GroovesharkIE",
        "signature": "youtube_dl.extractor.grooveshark.GroovesharkIE._transform_meta(self, js)",
        "snippet": "    def _transform_meta(self, js):\n        return js.split('\\n')[0].split('=')[1].rstrip(';')",
        "begin_line": 88,
        "end_line": 89,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.grooveshark.GroovesharkIE._get_meta#91",
        "src_path": "youtube_dl/extractor/grooveshark.py",
        "class_name": "youtube_dl.extractor.grooveshark.GroovesharkIE",
        "signature": "youtube_dl.extractor.grooveshark.GroovesharkIE._get_meta(self, target)",
        "snippet": "    def _get_meta(self, target):\n        (meta_url, token) = self._build_meta_url(target)\n        self.to_screen('Metadata URL: %s' % meta_url)\n\n        headers = {'Referer': compat_urlparse.urldefrag(target)[0]}\n        req = compat_urllib_request.Request(meta_url, headers=headers)\n        res = self._download_json(req, token,\n                                  transform_source=self._transform_meta)\n\n        if 'getStreamKeyWithSong' not in res:\n            raise ExtractorError(\n                'Metadata not found. URL may be malformed, or Grooveshark API may have changed.')\n\n        if res['getStreamKeyWithSong'] is None:\n            raise ExtractorError(\n                'Metadata download failed, probably due to Grooveshark anti-abuse throttling. Wait at least an hour before retrying from this IP.',\n                expected=True)\n\n        return res['getStreamKeyWithSong']",
        "begin_line": 91,
        "end_line": 109,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.grooveshark.GroovesharkIE._get_bootstrap#111",
        "src_path": "youtube_dl/extractor/grooveshark.py",
        "class_name": "youtube_dl.extractor.grooveshark.GroovesharkIE",
        "signature": "youtube_dl.extractor.grooveshark.GroovesharkIE._get_bootstrap(self, target)",
        "snippet": "    def _get_bootstrap(self, target):\n        (bootstrap_url, token) = self._build_bootstrap_url(target)\n\n        headers = {'Referer': compat_urlparse.urldefrag(target)[0]}\n        req = compat_urllib_request.Request(bootstrap_url, headers=headers)\n        res = self._download_json(req, token, fatal=False,\n                                  note='Downloading player bootstrap data',\n                                  errnote='Unable to download player bootstrap data',\n                                  transform_source=self._transform_bootstrap)\n        return res",
        "begin_line": 111,
        "end_line": 120,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.grooveshark.GroovesharkIE._get_playerpage#122",
        "src_path": "youtube_dl/extractor/grooveshark.py",
        "class_name": "youtube_dl.extractor.grooveshark.GroovesharkIE",
        "signature": "youtube_dl.extractor.grooveshark.GroovesharkIE._get_playerpage(self, target)",
        "snippet": "    def _get_playerpage(self, target):\n        (_, _, token) = self._parse_target(target)\n\n        webpage = self._download_webpage(\n            target, token,\n            note='Downloading player page',\n            errnote='Unable to download player page',\n            fatal=False)\n\n        if webpage is not None:\n            # Search (for example German) error message\n            error_msg = self._html_search_regex(\n                r'<div id=\"content\">\\s*<h2>(.*?)</h2>', webpage,\n                'error message', default=None)\n            if error_msg is not None:\n                error_msg = error_msg.replace('\\n', ' ')\n                raise ExtractorError('Grooveshark said: %s' % error_msg)\n\n        if webpage is not None:\n            o = GroovesharkHtmlParser.extract_object_tags(webpage)\n            return (webpage, [x for x in o if x['attrs']['id'] == 'jsPlayerEmbed'])\n\n        return (webpage, None)",
        "begin_line": 122,
        "end_line": 144,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.grooveshark.GroovesharkIE._real_initialize#146",
        "src_path": "youtube_dl/extractor/grooveshark.py",
        "class_name": "youtube_dl.extractor.grooveshark.GroovesharkIE",
        "signature": "youtube_dl.extractor.grooveshark.GroovesharkIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self.ts = int(time.time() * 1000)  # timestamp in millis",
        "begin_line": 146,
        "end_line": 147,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.grooveshark.GroovesharkIE._real_extract#149",
        "src_path": "youtube_dl/extractor/grooveshark.py",
        "class_name": "youtube_dl.extractor.grooveshark.GroovesharkIE",
        "signature": "youtube_dl.extractor.grooveshark.GroovesharkIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        (target_uri, _, token) = self._parse_target(url)\n\n        # 1. Fill cookiejar by making a request to the player page\n        swf_referer = None\n        if self.do_playerpage_request:\n            (_, player_objs) = self._get_playerpage(url)\n            if player_objs is not None:\n                swf_referer = self._build_swf_referer(url, player_objs[0])\n                self.to_screen('SWF Referer: %s' % swf_referer)\n\n        # 2. Ask preload.php for swf bootstrap data to better mimic webapp\n        if self.do_bootstrap_request:\n            bootstrap = self._get_bootstrap(url)\n            self.to_screen('CommunicationToken: %s' % bootstrap['getCommunicationToken'])\n\n        # 3. Ask preload.php for track metadata.\n        meta = self._get_meta(url)\n\n        # 4. Construct stream request for track.\n        stream_url = self._build_stream_url(meta)\n        duration = int(math.ceil(float(meta['streamKey']['uSecs']) / 1000000))\n        post_dict = {'streamKey': meta['streamKey']['streamKey']}\n        post_data = compat_urllib_parse.urlencode(post_dict).encode('utf-8')\n        headers = {\n            'Content-Length': len(post_data),\n            'Content-Type': 'application/x-www-form-urlencoded'\n        }\n        if swf_referer is not None:\n            headers['Referer'] = swf_referer\n\n        return {\n            'id': token,\n            'title': meta['song']['Name'],\n            'http_method': 'POST',\n            'url': stream_url,\n            'ext': 'mp3',\n            'format': 'mp3 audio',\n            'duration': duration,\n            'http_post_data': post_data,\n            'http_headers': headers,\n        }",
        "begin_line": 149,
        "end_line": 190,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.youjizz.YouJizzIE._real_extract#23",
        "src_path": "youtube_dl/extractor/youjizz.py",
        "class_name": "youtube_dl.extractor.youjizz.YouJizzIE",
        "signature": "youtube_dl.extractor.youjizz.YouJizzIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('videoid')\n\n        # Get webpage content\n        webpage = self._download_webpage(url, video_id)\n\n        age_limit = self._rta_search(webpage)\n\n        # Get the video title\n        video_title = self._html_search_regex(r'<title>(?P<title>.*)</title>',\n            webpage, 'title').strip()\n\n        # Get the embed page\n        result = re.search(r'https?://www.youjizz.com/videos/embed/(?P<videoid>[0-9]+)', webpage)\n        if result is None:\n            raise ExtractorError('ERROR: unable to extract embed page')\n\n        embed_page_url = result.group(0).strip()\n        video_id = result.group('videoid')\n\n        webpage = self._download_webpage(embed_page_url, video_id)\n\n        # Get the video URL\n        m_playlist = re.search(r'so.addVariable\\(\"playlist\", ?\"(?P<playlist>.+?)\"\\);', webpage)\n        if m_playlist is not None:\n            playlist_url = m_playlist.group('playlist')\n            playlist_page = self._download_webpage(playlist_url, video_id,\n                                                   'Downloading playlist page')\n            m_levels = list(re.finditer(r'<level bitrate=\"(\\d+?)\" file=\"(.*?)\"', playlist_page))\n            if len(m_levels) == 0:\n                raise ExtractorError('Unable to extract video url')\n            videos = [(int(m.group(1)), m.group(2)) for m in m_levels]\n            (_, video_url) = sorted(videos)[0]\n            video_url = video_url.replace('%252F', '%2F')\n        else:\n            video_url = self._search_regex(r'so.addVariable\\(\"file\",encodeURIComponent\\(\"(?P<source>[^\"]+)\"\\)\\);',\n                                           webpage, 'video URL')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': video_title,\n            'ext': 'flv',\n            'format': 'flv',\n            'player_url': embed_page_url,\n            'age_limit': age_limit,\n        }",
        "begin_line": 23,
        "end_line": 71,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.pornotube.PornotubeIE._real_extract#27",
        "src_path": "youtube_dl/extractor/pornotube.py",
        "class_name": "youtube_dl.extractor.pornotube.PornotubeIE",
        "signature": "youtube_dl.extractor.pornotube.PornotubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('videoid')\n        video_title = mobj.group('title')\n\n        # Get webpage content\n        webpage = self._download_webpage(url, video_id)\n\n        # Get the video URL\n        VIDEO_URL_RE = r'url: \"(?P<url>http://video[0-9].pornotube.com/.+\\.flv)\",'\n        video_url = self._search_regex(VIDEO_URL_RE, webpage, 'video url')\n        video_url = compat_urllib_parse.unquote(video_url)\n\n        #Get the uploaded date\n        VIDEO_UPLOADED_RE = r'<div class=\"video_added_by\">Added (?P<date>[0-9\\/]+) by'\n        upload_date = self._html_search_regex(VIDEO_UPLOADED_RE, webpage, 'upload date', fatal=False)\n        if upload_date:\n            upload_date = unified_strdate(upload_date)\n        age_limit = self._rta_search(webpage)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'upload_date': upload_date,\n            'title': video_title,\n            'ext': 'flv',\n            'format': 'flv',\n            'age_limit': age_limit,\n        }",
        "begin_line": 27,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.wimp.WimpIE._real_extract#35",
        "src_path": "youtube_dl/extractor/wimp.py",
        "class_name": "youtube_dl.extractor.wimp.WimpIE",
        "signature": "youtube_dl.extractor.wimp.WimpIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group(1)\n        webpage = self._download_webpage(url, video_id)\n        video_url = self._search_regex(\n            r's1\\.addVariable\\(\"file\",\\s*\"([^\"]+)\"\\);', webpage, 'video URL')\n        if YoutubeIE.suitable(video_url):\n            self.to_screen('Found YouTube video')\n            return {\n                '_type': 'url',\n                'url': video_url,\n                'ie_key': YoutubeIE.ie_key(),\n            }\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': self._og_search_title(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'description': self._og_search_description(webpage),\n        }",
        "begin_line": 35,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.tutv.TutvIE._real_extract#22",
        "src_path": "youtube_dl/extractor/tutv.py",
        "class_name": "youtube_dl.extractor.tutv.TutvIE",
        "signature": "youtube_dl.extractor.tutv.TutvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        internal_id = self._search_regex(r'codVideo=([0-9]+)', webpage, 'internal video ID')\n\n        data_content = self._download_webpage(\n            'http://tu.tv/flvurl.php?codVideo=%s' % internal_id, video_id, 'Downloading video info')\n        video_url = base64.b64decode(compat_parse_qs(data_content)['kpt'][0]).decode('utf-8')\n\n        return {\n            'id': internal_id,\n            'url': video_url,\n            'title': self._og_search_title(webpage),\n        }",
        "begin_line": 22,
        "end_line": 37,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.myspace.MySpaceIE._real_extract#47",
        "src_path": "youtube_dl/extractor/myspace.py",
        "class_name": "youtube_dl.extractor.myspace.MySpaceIE",
        "signature": "youtube_dl.extractor.myspace.MySpaceIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n\n        if mobj.group('mediatype').startswith('music/song'):\n            # songs don't store any useful info in the 'context' variable\n            def search_data(name):\n                return self._search_regex(r'data-%s=\"(.*?)\"' % name, webpage,\n                    name)\n            streamUrl = search_data('stream-url')\n            info = {\n                'id': video_id,\n                'title': self._og_search_title(webpage),\n                'uploader_id': search_data('artist-username'),\n                'thumbnail': self._og_search_thumbnail(webpage),\n            }\n        else:\n            context = json.loads(self._search_regex(r'context = ({.*?});', webpage,\n                u'context'))\n            video = context['video']\n            streamUrl = video['streamUrl']\n            info = {\n                'id': compat_str(video['mediaId']),\n                'title': video['title'],\n                'description': video['description'],\n                'thumbnail': video['imageUrl'],\n                'uploader': video['artistName'],\n                'uploader_id': video['artistUsername'],\n            }\n\n        rtmp_url, play_path = streamUrl.split(';', 1)\n        info.update({\n            'url': rtmp_url,\n            'play_path': play_path,\n            'ext': 'flv',\n        })\n        return info",
        "begin_line": 47,
        "end_line": 84,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00023618327822390176,
            "pseudo_dstar_susp": 0.000233590282644242,
            "pseudo_tarantula_susp": 0.0002772387025228722,
            "pseudo_op2_susp": 0.000233590282644242,
            "pseudo_barinel_susp": 0.00027631942525559546
        }
    },
    {
        "name": "youtube_dl.extractor.myspace.MySpaceIE.search_data#54",
        "src_path": "youtube_dl/extractor/myspace.py",
        "class_name": "youtube_dl.extractor.myspace.MySpaceIE",
        "signature": "youtube_dl.extractor.myspace.MySpaceIE.search_data(name)",
        "snippet": "            def search_data(name):\n                return self._search_regex(r'data-%s=\"(.*?)\"' % name, webpage,\n                    name)",
        "begin_line": 54,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.niconico.NiconicoIE._real_initialize#45",
        "src_path": "youtube_dl/extractor/niconico.py",
        "class_name": "youtube_dl.extractor.niconico.NiconicoIE",
        "signature": "youtube_dl.extractor.niconico.NiconicoIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        if self._downloader.params.get('username', None) is not None:\n            self._AUTHENTICATE = True\n\n        if self._AUTHENTICATE:\n            self._login()",
        "begin_line": 45,
        "end_line": 50,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.niconico.NiconicoIE._login#52",
        "src_path": "youtube_dl/extractor/niconico.py",
        "class_name": "youtube_dl.extractor.niconico.NiconicoIE",
        "signature": "youtube_dl.extractor.niconico.NiconicoIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n\n        # Log in\n        login_form_strs = {\n            'mail': username,\n            'password': password,\n        }\n        # Convert to UTF-8 *before* urlencode because Python 2.x's urlencode\n        # chokes on unicode\n        login_form = dict((k.encode('utf-8'), v.encode('utf-8')) for k, v in login_form_strs.items())\n        login_data = compat_urllib_parse.urlencode(login_form).encode('utf-8')\n        request = compat_urllib_request.Request(\n            'https://secure.nicovideo.jp/secure/login', login_data)\n        login_results = self._download_webpage(\n            request, None, note='Logging in', errnote='Unable to log in')\n        if re.search(r'(?i)<h1 class=\"mb8p4\">Log in error</h1>', login_results) is not None:\n            self._downloader.report_warning('unable to log in: bad username or password')\n            return False\n        return True",
        "begin_line": 52,
        "end_line": 71,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.niconico.NiconicoIE._real_extract#73",
        "src_path": "youtube_dl/extractor/niconico.py",
        "class_name": "youtube_dl.extractor.niconico.NiconicoIE",
        "signature": "youtube_dl.extractor.niconico.NiconicoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group(1)\n\n        # Get video webpage. We are not actually interested in it, but need\n        # the cookies in order to be able to download the info webpage\n        self._download_webpage('http://www.nicovideo.jp/watch/' + video_id, video_id)\n\n        video_info = self._download_xml(\n            'http://ext.nicovideo.jp/api/getthumbinfo/' + video_id, video_id,\n            note='Downloading video info page')\n\n        if self._AUTHENTICATE:\n            # Get flv info\n            flv_info_webpage = self._download_webpage(\n                'http://flapi.nicovideo.jp/api/getflv?v=' + video_id,\n                video_id, 'Downloading flv info')\n        else:\n            # Get external player info\n            ext_player_info = self._download_webpage(\n                'http://ext.nicovideo.jp/thumb_watch/' + video_id, video_id)\n            thumb_play_key = self._search_regex(\n                r'\\'thumbPlayKey\\'\\s*:\\s*\\'(.*?)\\'', ext_player_info, 'thumbPlayKey')\n\n            # Get flv info\n            flv_info_data = compat_urllib_parse.urlencode({\n                'k': thumb_play_key,\n                'v': video_id\n            })\n            flv_info_request = compat_urllib_request.Request(\n                'http://ext.nicovideo.jp/thumb_watch', flv_info_data,\n                {'Content-Type': 'application/x-www-form-urlencoded'})\n            flv_info_webpage = self._download_webpage(\n                flv_info_request, video_id,\n                note='Downloading flv info', errnote='Unable to download flv info')\n\n        video_real_url = compat_urlparse.parse_qs(flv_info_webpage)['url'][0]\n\n        # Start extracting information\n        title = video_info.find('.//title').text\n        extension = video_info.find('.//movie_type').text\n        video_format = extension.upper()\n        thumbnail = video_info.find('.//thumbnail_url').text\n        description = video_info.find('.//description').text\n        upload_date = unified_strdate(video_info.find('.//first_retrieve').text.split('+')[0])\n        view_count = int_or_none(video_info.find('.//view_counter').text)\n        comment_count = int_or_none(video_info.find('.//comment_num').text)\n        duration = parse_duration(video_info.find('.//length').text)\n        webpage_url = video_info.find('.//watch_url').text\n\n        if video_info.find('.//ch_id') is not None:\n            uploader_id = video_info.find('.//ch_id').text\n            uploader = video_info.find('.//ch_name').text\n        elif video_info.find('.//user_id') is not None:\n            uploader_id = video_info.find('.//user_id').text\n            uploader = video_info.find('.//user_nickname').text\n        else:\n            uploader_id = uploader = None\n\n        return {\n            'id': video_id,\n            'url': video_real_url,\n            'title': title,\n            'ext': extension,\n            'format': video_format,\n            'thumbnail': thumbnail,\n            'description': description,\n            'uploader': uploader,\n            'upload_date': upload_date,\n            'uploader_id': uploader_id,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'duration': duration,\n            'webpage_url': webpage_url,\n        }",
        "begin_line": 73,
        "end_line": 147,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.swrmediathek.SWRMediathekIE._real_extract#57",
        "src_path": "youtube_dl/extractor/swrmediathek.py",
        "class_name": "youtube_dl.extractor.swrmediathek.SWRMediathekIE",
        "signature": "youtube_dl.extractor.swrmediathek.SWRMediathekIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        video = self._download_json(\n            'http://swrmediathek.de/AjaxEntry?ekey=%s' % video_id, video_id, 'Downloading video JSON')\n\n        attr = video['attr']\n        media_type = attr['entry_etype']\n\n        formats = []\n        for entry in video['sub']:\n            if entry['name'] != 'entry_media':\n                continue\n\n            entry_attr = entry['attr']\n            codec = entry_attr['val0']\n            quality = int(entry_attr['val1'])\n\n            fmt = {\n                'url': entry_attr['val2'],\n                'quality': quality,\n            }\n\n            if media_type == 'Video':\n                fmt.update({\n                    'format_note': ['144p', '288p', '544p'][quality-1],\n                    'vcodec': codec,\n                })\n            elif media_type == 'Audio':\n                fmt.update({\n                    'acodec': codec,\n                })\n            formats.append(fmt)\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': attr['entry_title'],\n            'description': attr['entry_descl'],\n            'thumbnail': attr['entry_image_16_9'],\n            'duration': parse_duration(attr['entry_durat']),\n            'upload_date': attr['entry_pdatet'][:-4],\n            'uploader': attr['channel_title'],\n            'uploader_id': attr['channel_idkey'],\n            'formats': formats,\n        }",
        "begin_line": 57,
        "end_line": 104,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007692307692307692,
            "pseudo_dstar_susp": 0.0006273525721455458,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006273525721455458,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.washingtonpost.WashingtonPostIE._real_extract#46",
        "src_path": "youtube_dl/extractor/washingtonpost.py",
        "class_name": "youtube_dl.extractor.washingtonpost.WashingtonPostIE",
        "signature": "youtube_dl.extractor.washingtonpost.WashingtonPostIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        page_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, page_id)\n        title = self._og_search_title(webpage)\n        uuids = re.findall(r'data-video-uuid=\"([^\"]+)\"', webpage)\n        entries = []\n        for i, uuid in enumerate(uuids, start=1):\n            vinfo_all = self._download_json(\n                'http://www.washingtonpost.com/posttv/c/videojson/%s?resType=jsonp' % uuid,\n                page_id,\n                transform_source=strip_jsonp,\n                note='Downloading information of video %d/%d' % (i, len(uuids))\n            )\n            vinfo = vinfo_all[0]['contentConfig']\n            uploader = vinfo.get('credits', {}).get('source')\n            timestamp = int_or_none(\n                vinfo.get('dateConfig', {}).get('dateFirstPublished'), 1000)\n\n            formats = [{\n                'format_id': (\n                    '%s-%s-%s' % (s.get('type'), s.get('width'), s.get('bitrate'))\n                    if s.get('width')\n                    else s.get('type')),\n                'vbr': s.get('bitrate') if s.get('width') != 0 else None,\n                'width': s.get('width'),\n                'height': s.get('height'),\n                'acodec': s.get('audioCodec'),\n                'vcodec': s.get('videoCodec') if s.get('width') != 0 else 'none',\n                'filesize': s.get('fileSize'),\n                'url': s.get('url'),\n                'ext': 'mp4',\n                'protocol': {\n                    'MP4': 'http',\n                    'F4F': 'f4m',\n                }.get(s.get('type'))\n            } for s in vinfo.get('streams', [])]\n            source_media_url = vinfo.get('sourceMediaURL')\n            if source_media_url:\n                formats.append({\n                    'format_id': 'source_media',\n                    'url': source_media_url,\n                })\n            self._sort_formats(formats)\n            entries.append({\n                'id': uuid,\n                'title': vinfo['title'],\n                'description': vinfo.get('blurb'),\n                'uploader': uploader,\n                'formats': formats,\n                'duration': int_or_none(vinfo.get('videoDuration'), 100),\n                'timestamp': timestamp,\n            })\n\n        return {\n            '_type': 'playlist',\n            'entries': entries,\n            'id': page_id,\n            'title': title,\n        }",
        "begin_line": 46,
        "end_line": 106,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveIE._extract_brightcove_url#146",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveIE._extract_brightcove_url(cls, webpage)",
        "snippet": "    def _extract_brightcove_url(cls, webpage):\n        \"\"\"Try to extract the brightcove url from the webpage, returns None\n        if it can't be found\n        \"\"\"\n        urls = cls._extract_brightcove_urls(webpage)\n        return urls[0] if urls else None",
        "begin_line": 146,
        "end_line": 151,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveIE._extract_brightcove_urls#154",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveIE._extract_brightcove_urls(cls, webpage)",
        "snippet": "    def _extract_brightcove_urls(cls, webpage):\n        \"\"\"Return a list of all Brightcove URLs from the webpage \"\"\"\n\n        url_m = re.search(\n            r'<meta\\s+property=\"og:video\"\\s+content=\"(https?://(?:secure|c)\\.brightcove.com/[^\"]+)\"',\n            webpage)\n        if url_m:\n            url = unescapeHTML(url_m.group(1))\n            # Some sites don't add it, we can't download with this url, for example:\n            # http://www.ktvu.com/videos/news/raw-video-caltrain-releases-video-of-man-almost/vCTZdY/\n            if 'playerKey' in url or 'videoId' in url:\n                return [url]\n\n        matches = re.findall(\n            r'''(?sx)<object\n            (?:\n                [^>]+?class=[\\'\"][^>]*?BrightcoveExperience.*?[\\'\"] |\n                [^>]*?>\\s*<param\\s+name=\"movie\"\\s+value=\"https?://[^/]*brightcove\\.com/\n            ).+?</object>''',\n            webpage)\n        return [cls._build_brighcove_url(m) for m in matches]",
        "begin_line": 154,
        "end_line": 174,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026109660574412533,
            "pseudo_dstar_susp": 0.002531645569620253,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.002531645569620253,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveIE._real_extract#176",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url, smuggled_data = unsmuggle_url(url, {})\n\n        # Change the 'videoId' and others field to '@videoPlayer'\n        url = re.sub(r'(?<=[?&])(videoI(d|D)|bctid)', '%40videoPlayer', url)\n        # Change bckey (used by bcove.me urls) to playerKey\n        url = re.sub(r'(?<=[?&])bckey', 'playerKey', url)\n        mobj = re.match(self._VALID_URL, url)\n        query_str = mobj.group('query')\n        query = compat_urlparse.parse_qs(query_str)\n\n        videoPlayer = query.get('@videoPlayer')\n        if videoPlayer:\n            # We set the original url as the default 'Referer' header\n            referer = smuggled_data.get('Referer', url)\n            return self._get_video_info(\n                videoPlayer[0], query_str, query, referer=referer)\n        elif 'playerKey' in query:\n            player_key = query['playerKey']\n            return self._get_playlist_info(player_key[0])\n        else:\n            raise ExtractorError(\n                'Cannot find playerKey= variable. Did you forget quotes in a shell invocation?',\n                expected=True)",
        "begin_line": 176,
        "end_line": 199,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0010030090270812437,
            "pseudo_dstar_susp": 0.0007739938080495357,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0007739938080495357,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveIE._get_video_info#201",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveIE._get_video_info(self, video_id, query_str, query, referer=None)",
        "snippet": "    def _get_video_info(self, video_id, query_str, query, referer=None):\n        request_url = self._FEDERATED_URL_TEMPLATE % query_str\n        req = compat_urllib_request.Request(request_url)\n        linkBase = query.get('linkBaseURL')\n        if linkBase is not None:\n            referer = linkBase[0]\n        if referer is not None:\n            req.add_header('Referer', referer)\n        webpage = self._download_webpage(req, video_id)\n\n        error_msg = self._html_search_regex(\n            r\"<h1>We're sorry.</h1>\\s*<p>(.*?)</p>\", webpage,\n            'error message', default=None)\n        if error_msg is not None:\n            raise ExtractorError(\n                'brightcove said: %s' % error_msg, expected=True)\n\n        self.report_extraction(video_id)\n        info = self._search_regex(r'var experienceJSON = ({.*});', webpage, 'json')\n        info = json.loads(info)['data']\n        video_info = info['programmedContent']['videoPlayer']['mediaDTO']\n        video_info['_youtubedl_adServerURL'] = info.get('adServerURL')\n\n        return self._extract_video_info(video_info)",
        "begin_line": 201,
        "end_line": 224,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0010030090270812437,
            "pseudo_dstar_susp": 0.0007739938080495357,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0007739938080495357,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveIE._get_playlist_info#226",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveIE._get_playlist_info(self, player_key)",
        "snippet": "    def _get_playlist_info(self, player_key):\n        info_url = 'http://c.brightcove.com/services/json/experience/runtime/?command=get_programming_for_experience&playerKey=%s' % player_key\n        playlist_info = self._download_webpage(\n            info_url, player_key, 'Downloading playlist information')\n\n        json_data = json.loads(playlist_info)\n        if 'videoList' not in json_data:\n            raise ExtractorError('Empty playlist')\n        playlist_info = json_data['videoList']\n        videos = [self._extract_video_info(video_info) for video_info in playlist_info['mediaCollectionDTO']['videoDTOs']]\n\n        return self.playlist_result(videos, playlist_id=playlist_info['id'],\n                                    playlist_title=playlist_info['mediaCollectionDTO']['displayName'])",
        "begin_line": 226,
        "end_line": 238,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveIE._extract_video_info#240",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveIE._extract_video_info(self, video_info)",
        "snippet": "    def _extract_video_info(self, video_info):\n        info = {\n            'id': compat_str(video_info['id']),\n            'title': video_info['displayName'].strip(),\n            'description': video_info.get('shortDescription'),\n            'thumbnail': video_info.get('videoStillURL') or video_info.get('thumbnailURL'),\n            'uploader': video_info.get('publisherName'),\n        }\n\n        renditions = video_info.get('renditions')\n        if renditions:\n            formats = []\n            for rend in renditions:\n                url = rend['defaultURL']\n                if rend['remote']:\n                    # This type of renditions are served through akamaihd.net,\n                    # but they don't use f4m manifests\n                    url = url.replace('control/', '') + '?&v=3.3.0&fp=13&r=FEEFJ&g=RTSJIMBMPFPB'\n                    ext = 'flv'\n                else:\n                    ext = determine_ext(url)\n                size = rend.get('size')\n                formats.append({\n                    'url': url,\n                    'ext': ext,\n                    'height': rend.get('frameHeight'),\n                    'width': rend.get('frameWidth'),\n                    'filesize': size if size != 0 else None,\n                })\n            self._sort_formats(formats)\n            info['formats'] = formats\n        elif video_info.get('FLVFullLengthURL') is not None:\n            info.update({\n                'url': video_info['FLVFullLengthURL'],\n            })\n\n        if self._downloader.params.get('include_ads', False):\n            adServerURL = video_info.get('_youtubedl_adServerURL')\n            if adServerURL:\n                ad_info = {\n                    '_type': 'url',\n                    'url': adServerURL,\n                }\n                if 'url' in info:\n                    return {\n                        '_type': 'playlist',\n                        'title': info['title'],\n                        'entries': [ad_info, info],\n                    }\n                else:\n                    return ad_info\n\n        if 'url' not in info and not info.get('formats'):\n            raise ExtractorError('Unable to extract video url for %s' % info['id'])\n        return info",
        "begin_line": 240,
        "end_line": 294,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.vine.VineIE._real_extract#27",
        "src_path": "youtube_dl/extractor/vine.py",
        "class_name": "youtube_dl.extractor.vine.VineIE",
        "signature": "youtube_dl.extractor.vine.VineIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage('https://vine.co/v/' + video_id, video_id)\n\n        data = json.loads(self._html_search_regex(\n            r'window\\.POST_DATA = { %s: ({.+?}) }' % video_id, webpage, 'vine data'))\n\n        formats = [\n            {\n                'url': data['videoLowURL'],\n                'ext': 'mp4',\n                'format_id': 'low',\n            },\n            {\n                'url': data['videoUrl'],\n                'ext': 'mp4',\n                'format_id': 'standard',\n            }\n        ]\n\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n            'description': data['description'],\n            'thumbnail': data['thumbnailUrl'],\n            'upload_date': unified_strdate(data['created']),\n            'uploader': data['username'],\n            'uploader_id': data['userIdStr'],\n            'like_count': data['likes']['count'],\n            'comment_count': data['comments']['count'],\n            'repost_count': data['reposts']['count'],\n            'formats': formats,\n        }",
        "begin_line": 27,
        "end_line": 61,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.vine.VineUserIE._real_extract#76",
        "src_path": "youtube_dl/extractor/vine.py",
        "class_name": "youtube_dl.extractor.vine.VineUserIE",
        "signature": "youtube_dl.extractor.vine.VineUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        user = mobj.group('user')\n\n        profile_url = \"%sapi/users/profiles/vanity/%s\" % (\n            self._VINE_BASE_URL, user)\n        profile_data = self._download_json(\n            profile_url, user, note='Downloading user profile data')\n\n        user_id = profile_data['data']['userId']\n        timeline_data = []\n        for pagenum in itertools.count(1):\n            timeline_url = \"%sapi/timelines/users/%s?page=%s\" % (\n                self._VINE_BASE_URL, user_id, pagenum)\n            timeline_page = self._download_json(\n                timeline_url, user, note='Downloading page %d' % pagenum)\n            timeline_data.extend(timeline_page['data']['records'])\n            if timeline_page['data']['nextPage'] is None:\n                break\n\n        entries = [\n            self.url_result(e['permalinkUrl'], 'Vine') for e in timeline_data]\n        return self.playlist_result(entries, user)",
        "begin_line": 76,
        "end_line": 98,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.naver.NaverIE._real_extract#27",
        "src_path": "youtube_dl/extractor/naver.py",
        "class_name": "youtube_dl.extractor.naver.NaverIE",
        "signature": "youtube_dl.extractor.naver.NaverIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group(1)\n        webpage = self._download_webpage(url, video_id)\n        m_id = re.search(r'var rmcPlayer = new nhn.rmcnmv.RMCVideoPlayer\\(\"(.+?)\", \"(.+?)\"',\n            webpage)\n        if m_id is None:\n            raise ExtractorError('couldn\\'t extract vid and key')\n        vid = m_id.group(1)\n        key = m_id.group(2)\n        query = compat_urllib_parse.urlencode({'vid': vid, 'inKey': key,})\n        query_urls = compat_urllib_parse.urlencode({\n            'masterVid': vid,\n            'protocol': 'p2p',\n            'inKey': key,\n        })\n        info = self._download_xml(\n            'http://serviceapi.rmcnmv.naver.com/flash/videoInfo.nhn?' + query,\n            video_id, 'Downloading video info')\n        urls = self._download_xml(\n            'http://serviceapi.rmcnmv.naver.com/flash/playableEncodingOption.nhn?' + query_urls,\n            video_id, 'Downloading video formats info')\n\n        formats = []\n        for format_el in urls.findall('EncodingOptions/EncodingOption'):\n            domain = format_el.find('Domain').text\n            f = {\n                'url': domain + format_el.find('uri').text,\n                'ext': 'mp4',\n                'width': int(format_el.find('width').text),\n                'height': int(format_el.find('height').text),\n            }\n            if domain.startswith('rtmp'):\n                f.update({\n                    'ext': 'flv',\n                    'rtmp_protocol': '1', # rtmpt\n                })\n            formats.append(f)\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': info.find('Subject').text,\n            'formats': formats,\n            'description': self._og_search_description(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'upload_date': info.find('WriteDate').text.replace('.', ''),\n            'view_count': int(info.find('PlayCount').text),\n        }",
        "begin_line": 27,
        "end_line": 75,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.ina.InaIE._real_extract#21",
        "src_path": "youtube_dl/extractor/ina.py",
        "class_name": "youtube_dl.extractor.ina.InaIE",
        "signature": "youtube_dl.extractor.ina.InaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n        mrss_url = 'http://player.ina.fr/notices/%s.mrss' % video_id\n        info_doc = self._download_xml(mrss_url, video_id)\n\n        self.report_extraction(video_id)\n\n        video_url = info_doc.find('.//{http://search.yahoo.com/mrss/}player').attrib['url']\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': info_doc.find('.//title').text,\n        }",
        "begin_line": 21,
        "end_line": 36,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.movieclips.MovieClipsIE._real_extract#31",
        "src_path": "youtube_dl/extractor/movieclips.py",
        "class_name": "youtube_dl.extractor.movieclips.MovieClipsIE",
        "signature": "youtube_dl.extractor.movieclips.MovieClipsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n        show_id = display_id or video_id\n\n        config = self._download_xml(\n            'http://config.movieclips.com/player/config/%s' % video_id,\n            show_id, 'Downloading player config')\n\n        if config.find('./country-region').text == 'false':\n            raise ExtractorError(\n                '%s said: %s' % (self.IE_NAME, config.find('./region_alert').text), expected=True)\n\n        properties = config.find('./video/properties')\n        smil_file = properties.attrib['smil_file']\n\n        smil = self._download_xml(smil_file, show_id, 'Downloading SMIL')\n        base_url = smil.find('./head/meta').attrib['base']\n\n        formats = []\n        for video in smil.findall('./body/switch/video'):\n            vbr = int(video.attrib['system-bitrate']) / 1000\n            src = video.attrib['src']\n            formats.append({\n                'url': base_url,\n                'play_path': src,\n                'ext': src.split(':')[0],\n                'vbr': vbr,\n                'format_id': '%dk' % vbr,\n            })\n\n        self._sort_formats(formats)\n\n        title = '%s - %s' % (properties.attrib['clip_movie_title'], properties.attrib['clip_title'])\n        description = clean_html(compat_str(properties.attrib['clip_description']))\n        thumbnail = properties.attrib['image']\n        categories = properties.attrib['clip_categories'].split(',')\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'categories': categories,\n            'formats': formats,\n        }",
        "begin_line": 31,
        "end_line": 78,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.techtalks.TechTalksIE._real_extract#43",
        "src_path": "youtube_dl/extractor/techtalks.py",
        "class_name": "youtube_dl.extractor.techtalks.TechTalksIE",
        "signature": "youtube_dl.extractor.techtalks.TechTalksIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        talk_id = mobj.group('id')\n        webpage = self._download_webpage(url, talk_id)\n        rtmp_url = self._search_regex(\n            r'netConnectionUrl: \\'(.*?)\\'', webpage, 'rtmp url')\n        play_path = self._search_regex(\n            r'href=\\'(.*?)\\' [^>]*id=\"flowplayer_presenter\"',\n            webpage, 'presenter play path')\n        title = clean_html(get_element_by_attribute('class', 'title', webpage))\n        video_info = {\n            'id': talk_id,\n            'title': title,\n            'url': rtmp_url,\n            'play_path': play_path,\n            'ext': 'flv',\n        }\n        m_slides = re.search(r'<a class=\"slides\" href=\\'(.*?)\\'', webpage)\n        if m_slides is None:\n            return video_info\n        else:\n            return {\n                '_type': 'playlist',\n                'id': talk_id,\n                'title': title,\n                'entries': [\n                    video_info,\n                    # The slides video\n                    {\n                        'id': talk_id + '-slides',\n                        'title': title,\n                        'url': rtmp_url,\n                        'play_path': m_slides.group(1),\n                        'ext': 'flv',\n                    },\n                ],\n            }",
        "begin_line": 43,
        "end_line": 79,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.xhamster.XHamsterIE._real_extract#45",
        "src_path": "youtube_dl/extractor/xhamster.py",
        "class_name": "youtube_dl.extractor.xhamster.XHamsterIE",
        "signature": "youtube_dl.extractor.xhamster.XHamsterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self,url):\n        def extract_video_url(webpage):\n            mp4 = re.search(r'<video\\s+.*?file=\"([^\"]+)\".*?>', webpage)\n            if mp4 is None:\n                raise ExtractorError('Unable to extract media URL')\n            else:\n                return mp4.group(1)\n\n        def is_hd(webpage):\n            return '<div class=\\'icon iconHD\\'' in webpage\n\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n        seo = mobj.group('seo')\n        mrss_url = 'http://xhamster.com/movies/%s/%s.html' % (video_id, seo)\n        webpage = self._download_webpage(mrss_url, video_id)\n\n        title = self._html_search_regex(r'<title>(?P<title>.+?) - xHamster\\.com</title>', webpage, 'title')\n\n        # Only a few videos have an description\n        mobj = re.search(r'<span>Description: </span>([^<]+)', webpage)\n        description = mobj.group(1) if mobj else None\n\n        upload_date = self._html_search_regex(r'hint=\\'(\\d{4}-\\d{2}-\\d{2}) \\d{2}:\\d{2}:\\d{2} [A-Z]{3,4}\\'',\n            webpage, 'upload date', fatal=False)\n        if upload_date:\n            upload_date = unified_strdate(upload_date)\n\n        uploader_id = self._html_search_regex(r'<a href=\\'/user/[^>]+>(?P<uploader_id>[^<]+)',\n            webpage, 'uploader id', default='anonymous')\n\n        thumbnail = self._html_search_regex(r'<video\\s+.*?poster=\"([^\"]+)\".*?>', webpage, 'thumbnail', fatal=False)\n\n        duration = parse_duration(self._html_search_regex(r'<span>Runtime:</span> (\\d+:\\d+)</div>',\n            webpage, 'duration', fatal=False))\n\n        view_count = self._html_search_regex(r'<span>Views:</span> ([^<]+)</div>', webpage, 'view count', fatal=False)\n        if view_count:\n            view_count = str_to_int(view_count)\n\n        mobj = re.search(r\"hint='(?P<likecount>\\d+) Likes / (?P<dislikecount>\\d+) Dislikes'\", webpage)\n        (like_count, dislike_count) = (mobj.group('likecount'), mobj.group('dislikecount')) if mobj else (None, None)\n\n        mobj = re.search(r'</label>Comments \\((?P<commentcount>\\d+)\\)</div>', webpage)\n        comment_count = mobj.group('commentcount') if mobj else 0\n\n        age_limit = self._rta_search(webpage)\n\n        hd = is_hd(webpage)\n\n        video_url = extract_video_url(webpage)\n        formats = [{\n            'url': video_url,\n            'format_id': 'hd' if hd else 'sd',\n            'preference': 1,\n        }]\n\n        if not hd:\n            mrss_url = self._search_regex(r'<link rel=\"canonical\" href=\"([^\"]+)', webpage, 'mrss_url')\n            webpage = self._download_webpage(mrss_url + '?hd', video_id, note='Downloading HD webpage')\n            if is_hd(webpage):\n                video_url = extract_video_url(webpage)\n                formats.append({\n                    'url': video_url,\n                    'format_id': 'hd',\n                    'preference': 2,\n                })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'upload_date': upload_date,\n            'uploader_id': uploader_id,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'view_count': view_count,\n            'like_count': int_or_none(like_count),\n            'dislike_count': int_or_none(dislike_count),\n            'comment_count': int_or_none(comment_count),\n            'age_limit': age_limit,\n            'formats': formats,\n        }",
        "begin_line": 45,
        "end_line": 130,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.xhamster.XHamsterIE.extract_video_url#46",
        "src_path": "youtube_dl/extractor/xhamster.py",
        "class_name": "youtube_dl.extractor.xhamster.XHamsterIE",
        "signature": "youtube_dl.extractor.xhamster.XHamsterIE.extract_video_url(webpage)",
        "snippet": "        def extract_video_url(webpage):\n            mp4 = re.search(r'<video\\s+.*?file=\"([^\"]+)\".*?>', webpage)\n            if mp4 is None:\n                raise ExtractorError('Unable to extract media URL')\n            else:\n                return mp4.group(1)",
        "begin_line": 46,
        "end_line": 51,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.xhamster.XHamsterIE.is_hd#53",
        "src_path": "youtube_dl/extractor/xhamster.py",
        "class_name": "youtube_dl.extractor.xhamster.XHamsterIE",
        "signature": "youtube_dl.extractor.xhamster.XHamsterIE.is_hd(webpage)",
        "snippet": "        def is_hd(webpage):\n            return '<div class=\\'icon iconHD\\'' in webpage",
        "begin_line": 53,
        "end_line": 54,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.pyvideo.PyvideoIE._real_extract#38",
        "src_path": "youtube_dl/extractor/pyvideo.py",
        "class_name": "youtube_dl.extractor.pyvideo.PyvideoIE",
        "signature": "youtube_dl.extractor.pyvideo.PyvideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        m_youtube = re.search(r'(https?://www\\.youtube\\.com/watch\\?v=.*)', webpage)\n        if m_youtube is not None:\n            return self.url_result(m_youtube.group(1), 'Youtube')\n\n        title = self._html_search_regex(\n            r'<div class=\"section\">\\s*<h3(?:\\s+class=\"[^\"]*\"[^>]*)?>([^>]+?)</h3>',\n            webpage, 'title', flags=re.DOTALL)\n        video_url = self._search_regex(\n            [r'<source src=\"(.*?)\"', r'<dt>Download</dt>.*?<a href=\"(.+?)\"'],\n            webpage, 'video url', flags=re.DOTALL)\n\n        return {\n            'id': video_id,\n            'title': os.path.splitext(title)[0],\n            'url': video_url,\n        }",
        "begin_line": 38,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.franceinter.FranceInterIE._real_extract#20",
        "src_path": "youtube_dl/extractor/franceinter.py",
        "class_name": "youtube_dl.extractor.franceinter.FranceInterIE",
        "signature": "youtube_dl.extractor.franceinter.FranceInterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        title = self._html_search_regex(\n            r'<span class=\"roll_overflow\">(.*?)</span></h1>', webpage, 'title')\n        path = self._search_regex(\n            r'&urlAOD=(.*?)&startTime', webpage, 'video url')\n        video_url = 'http://www.franceinter.fr/' + path\n\n        return {\n            'id': video_id,\n            'formats': [{\n                'url': video_url,\n                'vcodec': 'none',\n            }],\n            'title': title,\n        }",
        "begin_line": 20,
        "end_line": 38,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.myspass.MySpassIE._real_extract#24",
        "src_path": "youtube_dl/extractor/myspass.py",
        "class_name": "youtube_dl.extractor.myspass.MySpassIE",
        "signature": "youtube_dl.extractor.myspass.MySpassIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        META_DATA_URL_TEMPLATE = 'http://www.myspass.de/myspass/includes/apps/video/getvideometadataxml.php?id=%s'\n\n        # video id is the last path element of the URL\n        # usually there is a trailing slash, so also try the second but last\n        url_path = compat_urllib_parse_urlparse(url).path\n        url_parent_path, video_id = os.path.split(url_path)\n        if not video_id:\n            _, video_id = os.path.split(url_parent_path)\n\n        # get metadata\n        metadata_url = META_DATA_URL_TEMPLATE % video_id\n        metadata = self._download_xml(metadata_url, video_id)\n\n        # extract values from metadata\n        url_flv_el = metadata.find('url_flv')\n        if url_flv_el is None:\n            raise ExtractorError('Unable to extract download url')\n        video_url = url_flv_el.text\n        title_el = metadata.find('title')\n        if title_el is None:\n            raise ExtractorError('Unable to extract title')\n        title = title_el.text\n        format_id_el = metadata.find('format_id')\n        if format_id_el is None:\n            format = 'mp4'\n        else:\n            format = format_id_el.text\n        description_el = metadata.find('description')\n        if description_el is not None:\n            description = description_el.text\n        else:\n            description = None\n        imagePreview_el = metadata.find('imagePreview')\n        if imagePreview_el is not None:\n            thumbnail = imagePreview_el.text\n        else:\n            thumbnail = None\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'format': format,\n            'thumbnail': thumbnail,\n            'description': description,\n        }",
        "begin_line": 24,
        "end_line": 70,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.xbef.XBefIE._real_extract#25",
        "src_path": "youtube_dl/extractor/xbef.py",
        "class_name": "youtube_dl.extractor.xbef.XBefIE",
        "signature": "youtube_dl.extractor.xbef.XBefIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        title = self._html_search_regex(\n            r'<h1[^>]*>(.*?)</h1>', webpage, 'title')\n\n        config_url_enc = self._download_webpage(\n            'http://xbef.com/Main/GetVideoURLEncoded/%s' % video_id, video_id,\n            note='Retrieving config URL')\n        config_url = compat_urllib_parse.unquote(config_url_enc)\n        config = self._download_xml(\n            config_url, video_id, note='Retrieving config')\n\n        video_url = config.find('./file').text\n        thumbnail = config.find('./image').text\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'thumbnail': thumbnail,\n            'age_limit': 18,\n        }",
        "begin_line": 25,
        "end_line": 49,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.rtbf.RTBFIE._real_extract#26",
        "src_path": "youtube_dl/extractor/rtbf.py",
        "class_name": "youtube_dl.extractor.rtbf.RTBFIE",
        "signature": "youtube_dl.extractor.rtbf.RTBFIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        page = self._download_webpage('https://www.rtbf.be/video/embed?id=%s' % video_id, video_id)\n\n        data = json.loads(self._html_search_regex(\n            r'<div class=\"js-player-embed(?: player-embed)?\" data-video=\"([^\"]+)\"', page, 'data video'))['data']\n\n        video_url = data.get('downloadUrl') or data.get('url')\n\n        if data['provider'].lower() == 'youtube':\n            return self.url_result(video_url, 'Youtube')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': data['title'],\n            'description': data.get('description') or data.get('subtitle'),\n            'thumbnail': data['thumbnail']['large'],\n            'duration': data.get('duration') or data.get('realDuration'),\n            'timestamp': data['created'],\n            'view_count': data['viewCount'],\n        }",
        "begin_line": 26,
        "end_line": 49,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.rts.RTSIE._real_extract#97",
        "src_path": "youtube_dl/extractor/rts.py",
        "class_name": "youtube_dl.extractor.rts.RTSIE",
        "signature": "youtube_dl.extractor.rts.RTSIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('id')\n\n        def download_json(internal_id):\n            return self._download_json(\n                'http://www.rts.ch/a/%s.html?f=json/article' % internal_id,\n                video_id)\n\n        all_info = download_json(video_id)\n\n        # video_id extracted out of URL is not always a real id\n        if 'video' not in all_info and 'audio' not in all_info:\n            page = self._download_webpage(url, video_id)\n            internal_id = self._html_search_regex(\n                r'<(?:video|audio) data-id=\"([0-9]+)\"', page,\n                'internal video id')\n            all_info = download_json(internal_id)\n\n        info = all_info['video']['JSONinfo'] if 'video' in all_info else all_info['audio']\n\n        upload_timestamp = parse_iso8601(info.get('broadcast_date'))\n        duration = info.get('duration') or info.get('cutout') or info.get('cutduration')\n        if isinstance(duration, compat_str):\n            duration = parse_duration(duration)\n        view_count = info.get('plays')\n        thumbnail = unescapeHTML(info.get('preview_image_url'))\n\n        def extract_bitrate(url):\n            return int_or_none(self._search_regex(\n                r'-([0-9]+)k\\.', url, 'bitrate', default=None))\n\n        formats = [{\n            'format_id': fid,\n            'url': furl,\n            'tbr': extract_bitrate(furl),\n        } for fid, furl in info['streams'].items()]\n\n        if 'media' in info:\n            formats.extend([{\n                'format_id': '%s-%sk' % (media['ext'], media['rate']),\n                'url': 'http://download-video.rts.ch/%s' % media['url'],\n                'tbr': media['rate'] or extract_bitrate(media['url']),\n            } for media in info['media'] if media.get('rate')])\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': info['title'],\n            'description': info.get('intro'),\n            'duration': duration,\n            'view_count': view_count,\n            'uploader': info.get('programName'),\n            'timestamp': upload_timestamp,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 97,
        "end_line": 154,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.rts.RTSIE.download_json#101",
        "src_path": "youtube_dl/extractor/rts.py",
        "class_name": "youtube_dl.extractor.rts.RTSIE",
        "signature": "youtube_dl.extractor.rts.RTSIE.download_json(internal_id)",
        "snippet": "        def download_json(internal_id):\n            return self._download_json(\n                'http://www.rts.ch/a/%s.html?f=json/article' % internal_id,\n                video_id)",
        "begin_line": 101,
        "end_line": 104,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00023618327822390176,
            "pseudo_dstar_susp": 0.0004278990158322636,
            "pseudo_tarantula_susp": 0.000231000231000231,
            "pseudo_op2_susp": 0.0004278990158322636,
            "pseudo_barinel_susp": 0.000231000231000231
        }
    },
    {
        "name": "youtube_dl.extractor.rts.RTSIE.extract_bitrate#125",
        "src_path": "youtube_dl/extractor/rts.py",
        "class_name": "youtube_dl.extractor.rts.RTSIE",
        "signature": "youtube_dl.extractor.rts.RTSIE.extract_bitrate(url)",
        "snippet": "        def extract_bitrate(url):\n            return int_or_none(self._search_regex(\n                r'-([0-9]+)k\\.', url, 'bitrate', default=None))",
        "begin_line": 125,
        "end_line": 127,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.urort.UrortIE._real_extract#35",
        "src_path": "youtube_dl/extractor/urort.py",
        "class_name": "youtube_dl.extractor.urort.UrortIE",
        "signature": "youtube_dl.extractor.urort.UrortIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('id')\n\n        fstr = compat_urllib_parse.quote(\"InternalBandUrl eq '%s'\" % playlist_id)\n        json_url = 'http://urort.p3.no/breeze/urort/TrackDtos?$filter=' + fstr\n        songs = self._download_json(json_url, playlist_id)\n        print(songs[0])\n\n        entries = [{\n            'id': '%d-%s' % (s['BandId'], s['$id']),\n            'title': s['Title'],\n            'url': s['TrackUrl'],\n            'ext': 'mp3',\n            'uploader_id': playlist_id,\n            'uploader': s.get('BandName', playlist_id),\n            'like_count': s.get('LikeCount'),\n            'thumbnail': 'http://urort.p3.no/cloud/images/%s' % s['Image'],\n            'upload_date': unified_strdate(s.get('Released')),\n        } for s in songs]\n\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'title': playlist_id,\n            'entries': entries,\n        }",
        "begin_line": 35,
        "end_line": 61,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.utils.compat_ord#202",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.compat_ord(c)",
        "snippet": "def compat_ord(c):\n    if type(c) is int: return c\n    else: return ord(c)",
        "begin_line": 202,
        "end_line": 204,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.preferredencoding#217",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.preferredencoding()",
        "snippet": "def preferredencoding():\n    \"\"\"Get preferred encoding.\n\n    Returns the best encoding scheme for the system, based on\n    locale.getpreferredencoding() and some further tweaks.\n    \"\"\"\n    try:\n        pref = locale.getpreferredencoding()\n        u'TEST'.encode(pref)\n    except:\n        pref = 'UTF-8'\n\n    return pref",
        "begin_line": 217,
        "end_line": 229,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.compat_print#235",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.compat_print(s)",
        "snippet": "    def compat_print(s):\n        assert type(s) == type(u'')\n        print(s)",
        "begin_line": 235,
        "end_line": 237,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.write_json_file#240",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.write_json_file(obj, fn)",
        "snippet": "def write_json_file(obj, fn):\n    \"\"\" Encode obj as JSON and write it to fn, atomically \"\"\"\n\n    args = {\n        'suffix': '.tmp',\n        'prefix': os.path.basename(fn) + '.',\n        'dir': os.path.dirname(fn),\n        'delete': False,\n    }\n\n    # In Python 2.x, json.dump expects a bytestream.\n    # In Python 3.x, it writes to a character stream\n    if sys.version_info < (3, 0):\n        args['mode'] = 'wb'\n    else:\n        args.update({\n            'mode': 'w',\n            'encoding': 'utf-8',\n        })\n\n    tf = tempfile.NamedTemporaryFile(**args)\n\n    try:\n        with tf:\n            json.dump(obj, tf)\n        os.rename(tf.name, fn)\n    except:\n        try:\n            os.remove(tf.name)\n        except OSError:\n            pass\n        raise",
        "begin_line": 240,
        "end_line": 271,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0010526315789473684,
            "pseudo_dstar_susp": 0.001639344262295082,
            "pseudo_tarantula_susp": 0.00025826446280991736,
            "pseudo_op2_susp": 0.001639344262295082,
            "pseudo_barinel_susp": 0.00025826446280991736
        }
    },
    {
        "name": "youtube_dl.utils.find_xpath_attr#275",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.find_xpath_attr(node, xpath, key, val)",
        "snippet": "    def find_xpath_attr(node, xpath, key, val):\n        \"\"\" Find the xpath xpath[@key=val] \"\"\"\n        assert re.match(r'^[a-zA-Z-]+$', key)\n        assert re.match(r'^[a-zA-Z0-9@\\s:._-]*$', val)\n        expr = xpath + u\"[@%s='%s']\" % (key, val)\n        return node.find(expr)",
        "begin_line": 275,
        "end_line": 280,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 6.75219446320054e-05,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.xpath_with_ns#295",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.xpath_with_ns(path, ns_map)",
        "snippet": "def xpath_with_ns(path, ns_map):\n    components = [c.split(':') for c in path.split('/')]\n    replaced = []\n    for c in components:\n        if len(c) == 1:\n            replaced.append(c[0])\n        else:\n            ns, tag = c\n            replaced.append('{%s}%s' % (ns_map[ns], tag))\n    return '/'.join(replaced)",
        "begin_line": 295,
        "end_line": 304,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.0001840942562592047,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.xpath_text#307",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.xpath_text(node, xpath, name=None, fatal=False)",
        "snippet": "def xpath_text(node, xpath, name=None, fatal=False):\n    if sys.version_info < (2, 7):  # Crazy 2.6\n        xpath = xpath.encode('ascii')\n\n    n = node.find(xpath)\n    if n is None:\n        if fatal:\n            name = xpath if name is None else name\n            raise ExtractorError('Could not find XML element %s' % name)\n        else:\n            return None\n    return n.text",
        "begin_line": 307,
        "end_line": 318,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.BaseHTMLParser.__init#323",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.BaseHTMLParser",
        "signature": "youtube_dl.utils.BaseHTMLParser.__init(self)",
        "snippet": "    def __init(self):\n        compat_html_parser.HTMLParser.__init__(self)\n        self.html = None",
        "begin_line": 323,
        "end_line": 325,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.BaseHTMLParser.loads#327",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.BaseHTMLParser",
        "signature": "youtube_dl.utils.BaseHTMLParser.loads(self, html)",
        "snippet": "    def loads(self, html):\n        self.html = html\n        self.feed(html)\n        self.close()",
        "begin_line": 327,
        "end_line": 330,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006337135614702154,
            "pseudo_dstar_susp": 0.0005952380952380953,
            "pseudo_tarantula_susp": 0.0002909514111143439,
            "pseudo_op2_susp": 0.0005952380952380953,
            "pseudo_barinel_susp": 0.0002910360884749709
        }
    },
    {
        "name": "youtube_dl.utils.AttrParser.__init__#334",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.AttrParser",
        "signature": "youtube_dl.utils.AttrParser.__init__(self, attribute, value)",
        "snippet": "    def __init__(self, attribute, value):\n        self.attribute = attribute\n        self.value = value\n        self.result = None\n        self.started = False\n        self.depth = {}\n        self.watch_startpos = False\n        self.error_count = 0\n        BaseHTMLParser.__init__(self)",
        "begin_line": 334,
        "end_line": 342,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007692307692307692,
            "pseudo_dstar_susp": 0.0006273525721455458,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006273525721455458,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.utils.AttrParser.error#344",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.AttrParser",
        "signature": "youtube_dl.utils.AttrParser.error(self, message)",
        "snippet": "    def error(self, message):\n        if self.error_count > 10 or self.started:\n            raise compat_html_parser.HTMLParseError(message, self.getpos())\n        self.rawdata = '\\n'.join(self.html.split('\\n')[self.getpos()[0]:]) # skip one line\n        self.error_count += 1\n        self.goahead(1)",
        "begin_line": 344,
        "end_line": 349,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.AttrParser.handle_starttag#351",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.AttrParser",
        "signature": "youtube_dl.utils.AttrParser.handle_starttag(self, tag, attrs)",
        "snippet": "    def handle_starttag(self, tag, attrs):\n        attrs = dict(attrs)\n        if self.started:\n            self.find_startpos(None)\n        if self.attribute in attrs and attrs[self.attribute] == self.value:\n            self.result = [tag]\n            self.started = True\n            self.watch_startpos = True\n        if self.started:\n            if not tag in self.depth: self.depth[tag] = 0\n            self.depth[tag] += 1",
        "begin_line": 351,
        "end_line": 361,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007692307692307692,
            "pseudo_dstar_susp": 0.0006273525721455458,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006273525721455458,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.utils.AttrParser.handle_endtag#363",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.AttrParser",
        "signature": "youtube_dl.utils.AttrParser.handle_endtag(self, tag)",
        "snippet": "    def handle_endtag(self, tag):\n        if self.started:\n            if tag in self.depth: self.depth[tag] -= 1\n            if self.depth[self.result[0]] == 0:\n                self.started = False\n                self.result.append(self.getpos())",
        "begin_line": 363,
        "end_line": 368,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007692307692307692,
            "pseudo_dstar_susp": 0.0006273525721455458,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006273525721455458,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.utils.AttrParser.find_startpos#370",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.AttrParser",
        "signature": "youtube_dl.utils.AttrParser.find_startpos(self, x)",
        "snippet": "    def find_startpos(self, x):\n        \"\"\"Needed to put the start position of the result (self.result[1])\n        after the opening tag with the requested id\"\"\"\n        if self.watch_startpos:\n            self.watch_startpos = False\n            self.result.append(self.getpos())",
        "begin_line": 370,
        "end_line": 375,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007692307692307692,
            "pseudo_dstar_susp": 0.0006273525721455458,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006273525721455458,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.utils.AttrParser.get_result#379",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.AttrParser",
        "signature": "youtube_dl.utils.AttrParser.get_result(self)",
        "snippet": "    def get_result(self):\n        if self.result is None:\n            return None\n        if len(self.result) != 3:\n            return None\n        lines = self.html.split('\\n')\n        lines = lines[self.result[1][0]-1:self.result[2][0]]\n        lines[0] = lines[0][self.result[1][1]:]\n        if len(lines) == 1:\n            lines[-1] = lines[-1][:self.result[2][1]-self.result[1][1]]\n        lines[-1] = lines[-1][:self.result[2][1]]\n        return '\\n'.join(lines).strip()",
        "begin_line": 379,
        "end_line": 390,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007692307692307692,
            "pseudo_dstar_susp": 0.0006273525721455458,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006273525721455458,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.utils.get_element_by_id#398",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.get_element_by_id(id, html)",
        "snippet": "def get_element_by_id(id, html):\n    \"\"\"Return the content of the tag with the specified ID in the passed HTML document\"\"\"\n    return get_element_by_attribute(\"id\", id, html)",
        "begin_line": 398,
        "end_line": 400,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.get_element_by_attribute#402",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.get_element_by_attribute(attribute, value, html)",
        "snippet": "def get_element_by_attribute(attribute, value, html):\n    \"\"\"Return the content of the tag with the specified attribute in the passed HTML document\"\"\"\n    parser = AttrParser(attribute, value)\n    try:\n        parser.loads(html)\n    except compat_html_parser.HTMLParseError:\n        pass\n    return parser.get_result()",
        "begin_line": 402,
        "end_line": 409,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007692307692307692,
            "pseudo_dstar_susp": 0.0006273525721455458,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006273525721455458,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.utils.MetaParser.__init__#416",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.MetaParser",
        "signature": "youtube_dl.utils.MetaParser.__init__(self, name)",
        "snippet": "    def __init__(self, name):\n        BaseHTMLParser.__init__(self)\n        self.name = name\n        self.content = None\n        self.result = None",
        "begin_line": 416,
        "end_line": 420,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.MetaParser.handle_starttag#422",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.MetaParser",
        "signature": "youtube_dl.utils.MetaParser.handle_starttag(self, tag, attrs)",
        "snippet": "    def handle_starttag(self, tag, attrs):\n        if tag != 'meta':\n            return\n        attrs = dict(attrs)\n        if attrs.get('name') == self.name:\n            self.result = attrs.get('content')",
        "begin_line": 422,
        "end_line": 427,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.MetaParser.get_result#429",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.MetaParser",
        "signature": "youtube_dl.utils.MetaParser.get_result(self)",
        "snippet": "    def get_result(self):\n        return self.result",
        "begin_line": 429,
        "end_line": 430,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.get_meta_content#432",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.get_meta_content(name, html)",
        "snippet": "def get_meta_content(name, html):\n    \"\"\"\n    Return the content attribute from the meta tag with the given name attribute.\n    \"\"\"\n    parser = MetaParser(name)\n    try:\n        parser.loads(html)\n    except compat_html_parser.HTMLParseError:\n        pass\n    return parser.get_result()",
        "begin_line": 432,
        "end_line": 441,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.clean_html#444",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.clean_html(html)",
        "snippet": "def clean_html(html):\n    \"\"\"Clean an HTML snippet into a readable string\"\"\"\n    # Newline vs <br />\n    html = html.replace('\\n', ' ')\n    html = re.sub(r'\\s*<\\s*br\\s*/?\\s*>\\s*', '\\n', html)\n    html = re.sub(r'<\\s*/\\s*p\\s*>\\s*<\\s*p[^>]*>', '\\n', html)\n    # Strip html tags\n    html = re.sub('<.*?>', '', html)\n    # Replace html entities\n    html = unescapeHTML(html)\n    return html.strip()",
        "begin_line": 444,
        "end_line": 454,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002898550724637681,
            "pseudo_dstar_susp": 0.002770083102493075,
            "pseudo_tarantula_susp": 0.00029515938606847696,
            "pseudo_op2_susp": 0.002770083102493075,
            "pseudo_barinel_susp": 0.00029515938606847696
        }
    },
    {
        "name": "youtube_dl.utils.sanitize_open#457",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.sanitize_open(filename, open_mode)",
        "snippet": "def sanitize_open(filename, open_mode):\n    \"\"\"Try to open the given filename, and slightly tweak it if this fails.\n\n    Attempts to open the given filename. If this fails, it tries to change\n    the filename slightly, step by step, until it's either able to open it\n    or it fails and raises a final exception, like the standard open()\n    function.\n\n    It returns the tuple (stream, definitive_file_name).\n    \"\"\"\n    try:\n        if filename == u'-':\n            if sys.platform == 'win32':\n                import msvcrt\n                msvcrt.setmode(sys.stdout.fileno(), os.O_BINARY)\n            return (sys.stdout.buffer if hasattr(sys.stdout, 'buffer') else sys.stdout, filename)\n        stream = open(encodeFilename(filename), open_mode)\n        return (stream, filename)\n    except (IOError, OSError) as err:\n        if err.errno in (errno.EACCES,):\n            raise\n\n        # In case of error, try to remove win32 forbidden chars\n        alt_filename = os.path.join(\n                        re.sub(u'[/<>:\"\\\\|\\\\\\\\?\\\\*]', u'#', path_part)\n                        for path_part in os.path.split(filename)\n                       )\n        if alt_filename == filename:\n            raise\n        else:\n            # An exception here should be caught in the caller\n            stream = open(encodeFilename(filename), open_mode)\n            return (stream, alt_filename)",
        "begin_line": 457,
        "end_line": 489,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006693440428380187,
            "pseudo_dstar_susp": 0.0009107468123861566,
            "pseudo_tarantula_susp": 0.0002447980416156671,
            "pseudo_op2_susp": 0.0009107468123861566,
            "pseudo_barinel_susp": 0.00024467824810374357
        }
    },
    {
        "name": "youtube_dl.utils.timeconvert#492",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.timeconvert(timestr)",
        "snippet": "def timeconvert(timestr):\n    \"\"\"Convert RFC 2822 defined time string into system timestamp\"\"\"\n    timestamp = None\n    timetuple = email.utils.parsedate_tz(timestr)\n    if timetuple is not None:\n        timestamp = email.utils.mktime_tz(timetuple)\n    return timestamp",
        "begin_line": 492,
        "end_line": 498,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007163323782234957,
            "pseudo_dstar_susp": 0.0009823182711198428,
            "pseudo_tarantula_susp": 0.0002527805864509606,
            "pseudo_op2_susp": 0.0009823182711198428,
            "pseudo_barinel_susp": 0.0002527805864509606
        }
    },
    {
        "name": "youtube_dl.utils.sanitize_filename#500",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.sanitize_filename(s, restricted=False, is_id=False)",
        "snippet": "def sanitize_filename(s, restricted=False, is_id=False):\n    \"\"\"Sanitizes a string so it could be used as part of a filename.\n    If restricted is set, use a stricter subset of allowed characters.\n    Set is_id if this is not an arbitrary string, but an ID that should be kept if possible\n    \"\"\"\n    def replace_insane(char):\n        if char == '?' or ord(char) < 32 or ord(char) == 127:\n            return ''\n        elif char == '\"':\n            return '' if restricted else '\\''\n        elif char == ':':\n            return '_-' if restricted else ' -'\n        elif char in '\\\\/|*<>':\n            return '_'\n        if restricted and (char in '!&\\'()[]{}$;`^,#' or char.isspace()):\n            return '_'\n        if restricted and ord(char) > 127:\n            return '_'\n        return char\n\n    result = u''.join(map(replace_insane, s))\n    if not is_id:\n        while '__' in result:\n            result = result.replace('__', '_')\n        result = result.strip('_')\n        # Common case of \"Foreign band name - English song title\"\n        if restricted and result.startswith('-_'):\n            result = result[2:]\n        if not result:\n            result = '_'\n    return result",
        "begin_line": 500,
        "end_line": 530,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004484304932735426,
            "pseudo_dstar_susp": 0.004672897196261682,
            "pseudo_tarantula_susp": 0.00030339805825242716,
            "pseudo_op2_susp": 0.004672897196261682,
            "pseudo_barinel_susp": 0.00030339805825242716
        }
    },
    {
        "name": "youtube_dl.utils.replace_insane#505",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.replace_insane(char)",
        "snippet": "    def replace_insane(char):\n        if char == '?' or ord(char) < 32 or ord(char) == 127:\n            return ''\n        elif char == '\"':\n            return '' if restricted else '\\''\n        elif char == ':':\n            return '_-' if restricted else ' -'\n        elif char in '\\\\/|*<>':\n            return '_'\n        if restricted and (char in '!&\\'()[]{}$;`^,#' or char.isspace()):\n            return '_'\n        if restricted and ord(char) > 127:\n            return '_'\n        return char",
        "begin_line": 505,
        "end_line": 518,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.25,
            "pseudo_dstar_susp": 0.25,
            "pseudo_tarantula_susp": 0.00030248033877797946,
            "pseudo_op2_susp": 0.25,
            "pseudo_barinel_susp": 0.00030248033877797946
        }
    },
    {
        "name": "youtube_dl.utils.orderedSet#532",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.orderedSet(iterable)",
        "snippet": "def orderedSet(iterable):\n    \"\"\" Remove all duplicates from the input iterable \"\"\"\n    res = []\n    for el in iterable:\n        if el not in res:\n            res.append(el)\n    return res",
        "begin_line": 532,
        "end_line": 538,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0012919896640826874,
            "pseudo_dstar_susp": 0.000998003992015968,
            "pseudo_tarantula_susp": 0.0003224766204450177,
            "pseudo_op2_susp": 0.000998003992015968,
            "pseudo_barinel_susp": 0.0003224766204450177
        }
    },
    {
        "name": "youtube_dl.utils._htmlentity_transform#541",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils._htmlentity_transform(entity)",
        "snippet": "def _htmlentity_transform(entity):\n    \"\"\"Transforms an HTML entity to a character.\"\"\"\n    # Known non-numeric HTML entity\n    if entity in compat_html_entities.name2codepoint:\n        return compat_chr(compat_html_entities.name2codepoint[entity])\n\n    mobj = re.match(r'#(x?[0-9]+)', entity)\n    if mobj is not None:\n        numstr = mobj.group(1)\n        if numstr.startswith(u'x'):\n            base = 16\n            numstr = u'0%s' % numstr\n        else:\n            base = 10\n        return compat_chr(int(numstr, base))\n\n    # Unknown entity in name, return its literal representation\n    return (u'&%s;' % entity)",
        "begin_line": 541,
        "end_line": 558,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011890606420927466,
            "pseudo_dstar_susp": 0.0010718113612004287,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0010718113612004287,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.utils.unescapeHTML#561",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.unescapeHTML(s)",
        "snippet": "def unescapeHTML(s):\n    if s is None:\n        return None\n    assert type(s) == compat_str\n\n    return re.sub(\n        r'&([^;]+);', lambda m: _htmlentity_transform(m.group(1)), s)",
        "begin_line": 561,
        "end_line": 567,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0031847133757961785,
            "pseudo_dstar_susp": 0.003278688524590164,
            "pseudo_tarantula_susp": 0.0002948982601002654,
            "pseudo_op2_susp": 0.003278688524590164,
            "pseudo_barinel_susp": 0.0002948982601002654
        }
    },
    {
        "name": "youtube_dl.utils.encodeFilename#570",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.encodeFilename(s, for_subprocess=False)",
        "snippet": "def encodeFilename(s, for_subprocess=False):\n    \"\"\"\n    @param s The name of the file\n    \"\"\"\n\n    assert type(s) == compat_str\n\n    # Python 3 has a Unicode API\n    if sys.version_info >= (3, 0):\n        return s\n\n    if sys.platform == 'win32' and sys.getwindowsversion()[0] >= 5:\n        # Pass u'' directly to use Unicode APIs on Windows 2000 and up\n        # (Detecting Windows NT 4 is tricky because 'major >= 4' would\n        # match Windows 9x series as well. Besides, NT 4 is obsolete.)\n        if not for_subprocess:\n            return s\n        else:\n            # For subprocess calls, encode with locale encoding\n            # Refer to http://stackoverflow.com/a/9951851/35070\n            encoding = preferredencoding()\n    else:\n        encoding = sys.getfilesystemencoding()\n    if encoding is None:\n        encoding = 'utf-8'\n    return s.encode(encoding, 'ignore')",
        "begin_line": 570,
        "end_line": 595,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0010526315789473684,
            "pseudo_dstar_susp": 0.001639344262295082,
            "pseudo_tarantula_susp": 0.00025826446280991736,
            "pseudo_op2_susp": 0.001639344262295082,
            "pseudo_barinel_susp": 0.00025826446280991736
        }
    },
    {
        "name": "youtube_dl.utils.encodeArgument#598",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.encodeArgument(s)",
        "snippet": "def encodeArgument(s):\n    if not isinstance(s, compat_str):\n        # Legacy code that uses byte strings\n        # Uncomment the following line after fixing all post processors\n        #assert False, 'Internal error: %r should be of type %r, is %r' % (s, compat_str, type(s))\n        s = s.decode('ascii')\n    return encodeFilename(s, True)",
        "begin_line": 598,
        "end_line": 604,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.decodeOption#607",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.decodeOption(optval)",
        "snippet": "def decodeOption(optval):\n    if optval is None:\n        return optval\n    if isinstance(optval, bytes):\n        optval = optval.decode(preferredencoding())\n\n    assert isinstance(optval, compat_str)\n    return optval",
        "begin_line": 607,
        "end_line": 614,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.formatSeconds#616",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.formatSeconds(secs)",
        "snippet": "def formatSeconds(secs):\n    if secs > 3600:\n        return '%d:%02d:%02d' % (secs // 3600, (secs % 3600) // 60, secs % 60)\n    elif secs > 60:\n        return '%d:%02d' % (secs // 60, secs % 60)\n    else:\n        return '%d' % secs",
        "begin_line": 616,
        "end_line": 622,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.make_HTTPS_handler#625",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.make_HTTPS_handler(opts_no_check_certificate, **kwargs)",
        "snippet": "def make_HTTPS_handler(opts_no_check_certificate, **kwargs):\n    if sys.version_info < (3, 2):\n        import httplib\n\n        class HTTPSConnectionV3(httplib.HTTPSConnection):\n            def __init__(self, *args, **kwargs):\n                httplib.HTTPSConnection.__init__(self, *args, **kwargs)\n\n            def connect(self):\n                sock = socket.create_connection((self.host, self.port), self.timeout)\n                if getattr(self, '_tunnel_host', False):\n                    self.sock = sock\n                    self._tunnel()\n                try:\n                    self.sock = ssl.wrap_socket(sock, self.key_file, self.cert_file, ssl_version=ssl.PROTOCOL_TLSv1)\n                except ssl.SSLError:\n                    self.sock = ssl.wrap_socket(sock, self.key_file, self.cert_file, ssl_version=ssl.PROTOCOL_SSLv23)\n\n        class HTTPSHandlerV3(compat_urllib_request.HTTPSHandler):\n            def https_open(self, req):\n                return self.do_open(HTTPSConnectionV3, req)\n        return HTTPSHandlerV3(**kwargs)\n    elif hasattr(ssl, 'create_default_context'):  # Python >= 3.4\n        context = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)\n        context.options &= ~ssl.OP_NO_SSLv3  # Allow older, not-as-secure SSLv3\n        if opts_no_check_certificate:\n            context.verify_mode = ssl.CERT_NONE\n        return compat_urllib_request.HTTPSHandler(context=context, **kwargs)\n    else:  # Python < 3.4\n        context = ssl.SSLContext(ssl.PROTOCOL_SSLv23)\n        context.verify_mode = (ssl.CERT_NONE\n                               if opts_no_check_certificate\n                               else ssl.CERT_REQUIRED)\n        context.set_default_verify_paths()\n        try:\n            context.load_default_certs()\n        except AttributeError:\n            pass  # Python < 3.4\n        return compat_urllib_request.HTTPSHandler(context=context, **kwargs)",
        "begin_line": 625,
        "end_line": 663,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.018518518518518517,
            "pseudo_dstar_susp": 0.03225806451612903,
            "pseudo_tarantula_susp": 0.00030902348578491963,
            "pseudo_op2_susp": 0.03225806451612903,
            "pseudo_barinel_susp": 0.00030902348578491963
        }
    },
    {
        "name": "youtube_dl.utils.ExtractorError.__init__#667",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.ExtractorError",
        "signature": "youtube_dl.utils.ExtractorError.__init__(self, msg, tb=None, expected=False, cause=None, video_id=None)",
        "snippet": "    def __init__(self, msg, tb=None, expected=False, cause=None, video_id=None):\n        \"\"\" tb, if given, is the original traceback (so that it can be printed out).\n        If expected is set, this is a normal error message and most likely not a bug in youtube-dl.\n        \"\"\"\n\n        if sys.exc_info()[0] in (compat_urllib_error.URLError, socket.timeout, UnavailableVideoError):\n            expected = True\n        if video_id is not None:\n            msg = video_id + ': ' + msg\n        if not expected:\n            msg = msg + u'; please report this issue on https://yt-dl.org/bug . Be sure to call youtube-dl with the --verbose flag and include its complete output. Make sure you are using the latest version; type  youtube-dl -U  to update.'\n        super(ExtractorError, self).__init__(msg)\n\n        self.traceback = tb\n        self.exc_info = sys.exc_info()  # preserve original exception\n        self.cause = cause\n        self.video_id = video_id",
        "begin_line": 667,
        "end_line": 683,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.1,
            "pseudo_dstar_susp": 0.0064516129032258064,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0064516129032258064,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.utils.ExtractorError.format_traceback#685",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.ExtractorError",
        "signature": "youtube_dl.utils.ExtractorError.format_traceback(self)",
        "snippet": "    def format_traceback(self):\n        if self.traceback is None:\n            return None\n        return u''.join(traceback.format_tb(self.traceback))",
        "begin_line": 685,
        "end_line": 688,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.005747126436781609,
            "pseudo_dstar_susp": 0.005319148936170213,
            "pseudo_tarantula_susp": 0.00033772374197906115,
            "pseudo_op2_susp": 0.005319148936170213,
            "pseudo_barinel_susp": 0.00033772374197906115
        }
    },
    {
        "name": "youtube_dl.utils.DownloadError.__init__#703",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.DownloadError",
        "signature": "youtube_dl.utils.DownloadError.__init__(self, msg, exc_info=None)",
        "snippet": "    def __init__(self, msg, exc_info=None):\n        \"\"\" exc_info, if given, is the original exception that caused the trouble (as returned by sys.exc_info()). \"\"\"\n        super(DownloadError, self).__init__(msg)\n        self.exc_info = exc_info",
        "begin_line": 703,
        "end_line": 706,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.006024096385542169,
            "pseudo_dstar_susp": 0.005847953216374269,
            "pseudo_tarantula_susp": 0.0003248862897985705,
            "pseudo_op2_susp": 0.005847953216374269,
            "pseudo_barinel_susp": 0.0003248862897985705
        }
    },
    {
        "name": "youtube_dl.utils.PostProcessingError.__init__#724",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.PostProcessingError",
        "signature": "youtube_dl.utils.PostProcessingError.__init__(self, msg)",
        "snippet": "    def __init__(self, msg):\n        self.msg = msg",
        "begin_line": 724,
        "end_line": 725,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.ContentTooShortError.__init__#752",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.ContentTooShortError",
        "signature": "youtube_dl.utils.ContentTooShortError.__init__(self, downloaded, expected)",
        "snippet": "    def __init__(self, downloaded, expected):\n        self.downloaded = downloaded\n        self.expected = expected",
        "begin_line": 752,
        "end_line": 754,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.YoutubeDLHandler.addinfourl_wrapper#782",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.YoutubeDLHandler",
        "signature": "youtube_dl.utils.YoutubeDLHandler.addinfourl_wrapper(stream, headers, url, code)",
        "snippet": "    def addinfourl_wrapper(stream, headers, url, code):\n        if hasattr(compat_urllib_request.addinfourl, 'getcode'):\n            return compat_urllib_request.addinfourl(stream, headers, url, code)\n        ret = compat_urllib_request.addinfourl(stream, headers, url)\n        ret.code = code\n        return ret",
        "begin_line": 782,
        "end_line": 787,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.005154639175257732,
            "pseudo_dstar_susp": 0.004291845493562232,
            "pseudo_tarantula_susp": 0.00033400133600534405,
            "pseudo_op2_susp": 0.004291845493562232,
            "pseudo_barinel_susp": 0.00033400133600534405
        }
    },
    {
        "name": "youtube_dl.utils.YoutubeDLHandler.http_request#789",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.YoutubeDLHandler",
        "signature": "youtube_dl.utils.YoutubeDLHandler.http_request(self, req)",
        "snippet": "    def http_request(self, req):\n        for h, v in std_headers.items():\n            if h not in req.headers:\n                req.add_header(h, v)\n        if 'Youtubedl-no-compression' in req.headers:\n            if 'Accept-encoding' in req.headers:\n                del req.headers['Accept-encoding']\n            del req.headers['Youtubedl-no-compression']\n        if 'Youtubedl-user-agent' in req.headers:\n            if 'User-agent' in req.headers:\n                del req.headers['User-agent']\n            req.headers['User-agent'] = req.headers['Youtubedl-user-agent']\n            del req.headers['Youtubedl-user-agent']\n        return req",
        "begin_line": 789,
        "end_line": 802,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.07142857142857142,
            "pseudo_dstar_susp": 0.016666666666666666,
            "pseudo_tarantula_susp": 0.0003191828917969997,
            "pseudo_op2_susp": 0.016666666666666666,
            "pseudo_barinel_susp": 0.0003191828917969997
        }
    },
    {
        "name": "youtube_dl.utils.YoutubeDLHandler.http_response#804",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.YoutubeDLHandler",
        "signature": "youtube_dl.utils.YoutubeDLHandler.http_response(self, req, resp)",
        "snippet": "    def http_response(self, req, resp):\n        old_resp = resp\n        # gzip\n        if resp.headers.get('Content-encoding', '') == 'gzip':\n            content = resp.read()\n            gz = gzip.GzipFile(fileobj=io.BytesIO(content), mode='rb')\n            try:\n                uncompressed = io.BytesIO(gz.read())\n            except IOError as original_ioerror:\n                # There may be junk add the end of the file\n                # See http://stackoverflow.com/q/4928560/35070 for details\n                for i in range(1, 1024):\n                    try:\n                        gz = gzip.GzipFile(fileobj=io.BytesIO(content[:-i]), mode='rb')\n                        uncompressed = io.BytesIO(gz.read())\n                    except IOError:\n                        continue\n                    break\n                else:\n                    raise original_ioerror\n            resp = self.addinfourl_wrapper(uncompressed, old_resp.headers, old_resp.url, old_resp.code)\n            resp.msg = old_resp.msg\n        # deflate\n        if resp.headers.get('Content-encoding', '') == 'deflate':\n            gz = io.BytesIO(self.deflate(resp.read()))\n            resp = self.addinfourl_wrapper(gz, old_resp.headers, old_resp.url, old_resp.code)\n            resp.msg = old_resp.msg\n        return resp",
        "begin_line": 804,
        "end_line": 831,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.16666666666666666,
            "pseudo_dstar_susp": 0.01282051282051282,
            "pseudo_tarantula_susp": 0.00033478406427854036,
            "pseudo_op2_susp": 0.01282051282051282,
            "pseudo_barinel_susp": 0.00033478406427854036
        }
    },
    {
        "name": "youtube_dl.utils.parse_iso8601#837",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.parse_iso8601(date_str, delimiter='T')",
        "snippet": "def parse_iso8601(date_str, delimiter='T'):\n    \"\"\" Return a UNIX timestamp from the given date \"\"\"\n\n    if date_str is None:\n        return None\n\n    m = re.search(\n        r'Z$| ?(?P<sign>\\+|-)(?P<hours>[0-9]{2}):?(?P<minutes>[0-9]{2})$',\n        date_str)\n    if not m:\n        timezone = datetime.timedelta()\n    else:\n        date_str = date_str[:-len(m.group(0))]\n        if not m.group('sign'):\n            timezone = datetime.timedelta()\n        else:\n            sign = 1 if m.group('sign') == '+' else -1\n            timezone = datetime.timedelta(\n                hours=sign * int(m.group('hours')),\n                minutes=sign * int(m.group('minutes')))\n    date_format =  '%Y-%m-%d{0}%H:%M:%S'.format(delimiter)\n    dt = datetime.datetime.strptime(date_str, date_format) - timezone\n    return calendar.timegm(dt.timetuple())",
        "begin_line": 837,
        "end_line": 859,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00023923444976076556,
            "pseudo_dstar_susp": 0.0005813953488372093,
            "pseudo_tarantula_susp": 0.000231000231000231,
            "pseudo_op2_susp": 0.0005813953488372093,
            "pseudo_barinel_susp": 0.000231000231000231
        }
    },
    {
        "name": "youtube_dl.utils.unified_strdate#862",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.unified_strdate(date_str)",
        "snippet": "def unified_strdate(date_str):\n    \"\"\"Return a string with the date in the format YYYYMMDD\"\"\"\n\n    if date_str is None:\n        return None\n\n    upload_date = None\n    #Replace commas\n    date_str = date_str.replace(',', ' ')\n    # %z (UTC offset) is only supported in python>=3.2\n    date_str = re.sub(r' ?(\\+|-)[0-9]{2}:?[0-9]{2}$', '', date_str)\n    format_expressions = [\n        '%d %B %Y',\n        '%d %b %Y',\n        '%B %d %Y',\n        '%b %d %Y',\n        '%b %dst %Y %I:%M%p',\n        '%b %dnd %Y %I:%M%p',\n        '%b %dth %Y %I:%M%p',\n        '%Y-%m-%d',\n        '%Y/%m/%d',\n        '%d.%m.%Y',\n        '%d/%m/%Y',\n        '%d/%m/%y',\n        '%Y/%m/%d %H:%M:%S',\n        '%Y-%m-%d %H:%M:%S',\n        '%d.%m.%Y %H:%M',\n        '%d.%m.%Y %H.%M',\n        '%Y-%m-%dT%H:%M:%SZ',\n        '%Y-%m-%dT%H:%M:%S.%fZ',\n        '%Y-%m-%dT%H:%M:%S.%f0Z',\n        '%Y-%m-%dT%H:%M:%S',\n        '%Y-%m-%dT%H:%M:%S.%f',\n        '%Y-%m-%dT%H:%M',\n    ]\n    for expression in format_expressions:\n        try:\n            upload_date = datetime.datetime.strptime(date_str, expression).strftime('%Y%m%d')\n        except ValueError:\n            pass\n    if upload_date is None:\n        timetuple = email.utils.parsedate_tz(date_str)\n        if timetuple:\n            upload_date = datetime.datetime(*timetuple[:6]).strftime('%Y%m%d')\n    return upload_date",
        "begin_line": 862,
        "end_line": 906,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00023299161230195712,
            "pseudo_dstar_susp": 0.00042408821034775233,
            "pseudo_tarantula_susp": 0.00022079929344226098,
            "pseudo_op2_susp": 0.00042408821034775233,
            "pseudo_barinel_susp": 0.0002207505518763797
        }
    },
    {
        "name": "youtube_dl.utils.determine_ext#908",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.determine_ext(url, default_ext=u'unknown_video')",
        "snippet": "def determine_ext(url, default_ext=u'unknown_video'):\n    if url is None:\n        return default_ext\n    guess = url.partition(u'?')[0].rpartition(u'.')[2]\n    if re.match(r'^[A-Za-z0-9]+$', guess):\n        return guess\n    else:\n        return default_ext",
        "begin_line": 908,
        "end_line": 915,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001303780964797914,
            "pseudo_dstar_susp": 0.0020491803278688526,
            "pseudo_tarantula_susp": 0.0002714440825190011,
            "pseudo_op2_susp": 0.0020491803278688526,
            "pseudo_barinel_susp": 0.0002714440825190011
        }
    },
    {
        "name": "youtube_dl.utils.subtitles_filename#917",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.subtitles_filename(filename, sub_lang, sub_format)",
        "snippet": "def subtitles_filename(filename, sub_lang, sub_format):\n    return filename.rsplit('.', 1)[0] + u'.' + sub_lang + u'.' + sub_format",
        "begin_line": 917,
        "end_line": 918,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.date_from_str#920",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.date_from_str(date_str)",
        "snippet": "def date_from_str(date_str):\n    \"\"\"\n    Return a datetime object from a string in the format YYYYMMDD or\n    (now|today)[+-][0-9](day|week|month|year)(s)?\"\"\"\n    today = datetime.date.today()\n    if date_str == 'now'or date_str == 'today':\n        return today\n    match = re.match('(now|today)(?P<sign>[+-])(?P<time>\\d+)(?P<unit>day|week|month|year)(s)?', date_str)\n    if match is not None:\n        sign = match.group('sign')\n        time = int(match.group('time'))\n        if sign == '-':\n            time = -time\n        unit = match.group('unit')\n        #A bad aproximation?\n        if unit == 'month':\n            unit = 'day'\n            time *= 30\n        elif unit == 'year':\n            unit = 'day'\n            time *= 365\n        unit += 's'\n        delta = datetime.timedelta(**{unit: time})\n        return today + delta\n    return datetime.datetime.strptime(date_str, \"%Y%m%d\").date()",
        "begin_line": 920,
        "end_line": 944,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.0007326007326007326,
            "pseudo_tarantula_susp": 0.00022079929344226098,
            "pseudo_op2_susp": 0.0007326007326007326,
            "pseudo_barinel_susp": 0.0002207505518763797
        }
    },
    {
        "name": "youtube_dl.utils.hyphenate_date#946",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.hyphenate_date(date_str)",
        "snippet": "def hyphenate_date(date_str):\n    \"\"\"\n    Convert a date in 'YYYYMMDD' format to 'YYYY-MM-DD' format\"\"\"\n    match = re.match(r'^(\\d\\d\\d\\d)(\\d\\d)(\\d\\d)$', date_str)\n    if match is not None:\n        return '-'.join(match.groups())\n    else:\n        return date_str",
        "begin_line": 946,
        "end_line": 953,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.DateRange.__init__#957",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.DateRange",
        "signature": "youtube_dl.utils.DateRange.__init__(self, start=None, end=None)",
        "snippet": "    def __init__(self, start=None, end=None):\n        \"\"\"start and end must be strings in the format accepted by date\"\"\"\n        if start is not None:\n            self.start = date_from_str(start)\n        else:\n            self.start = datetime.datetime.min.date()\n        if end is not None:\n            self.end = date_from_str(end)\n        else:\n            self.end = datetime.datetime.max.date()\n        if self.start > self.end:\n            raise ValueError('Date range: \"%s\" , the start date must be before the end date' % self)",
        "begin_line": 957,
        "end_line": 968,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.0007326007326007326,
            "pseudo_tarantula_susp": 0.00022079929344226098,
            "pseudo_op2_susp": 0.0007326007326007326,
            "pseudo_barinel_susp": 0.0002207505518763797
        }
    },
    {
        "name": "youtube_dl.utils.DateRange.__contains__#973",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.DateRange",
        "signature": "youtube_dl.utils.DateRange.__contains__(self, date)",
        "snippet": "    def __contains__(self, date):\n        \"\"\"Check if the date is in the range\"\"\"\n        if not isinstance(date, datetime.date):\n            date = date_from_str(date)\n        return self.start <= date <= self.end",
        "begin_line": 973,
        "end_line": 977,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.0007326007326007326,
            "pseudo_tarantula_susp": 0.00022079929344226098,
            "pseudo_op2_susp": 0.0007326007326007326,
            "pseudo_barinel_susp": 0.0002207505518763797
        }
    },
    {
        "name": "youtube_dl.utils.DateRange.__str__#978",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.DateRange",
        "signature": "youtube_dl.utils.DateRange.__str__(self)",
        "snippet": "    def __str__(self):\n        return '%s - %s' % ( self.start.isoformat(), self.end.isoformat())",
        "begin_line": 978,
        "end_line": 979,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.platform_name#982",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.platform_name()",
        "snippet": "def platform_name():\n    \"\"\" Returns the platform name as a compat_str \"\"\"\n    res = platform.platform()\n    if isinstance(res, bytes):\n        res = res.decode(preferredencoding())\n\n    assert isinstance(res, compat_str)\n    return res",
        "begin_line": 982,
        "end_line": 989,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils._windows_write_string#992",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils._windows_write_string(s, out)",
        "snippet": "def _windows_write_string(s, out):\n    \"\"\" Returns True if the string was written using special methods,\n    False if it has yet to be written out.\"\"\"\n    # Adapted from http://stackoverflow.com/a/3259271/35070\n\n    import ctypes\n    import ctypes.wintypes\n\n    WIN_OUTPUT_IDS = {\n        1: -11,\n        2: -12,\n    }\n\n    try:\n        fileno = out.fileno()\n    except AttributeError:\n        # If the output stream doesn't have a fileno, it's virtual\n        return False\n    if fileno not in WIN_OUTPUT_IDS:\n        return False\n\n    GetStdHandle = ctypes.WINFUNCTYPE(\n        ctypes.wintypes.HANDLE, ctypes.wintypes.DWORD)(\n        (\"GetStdHandle\", ctypes.windll.kernel32))\n    h = GetStdHandle(WIN_OUTPUT_IDS[fileno])\n\n    WriteConsoleW = ctypes.WINFUNCTYPE(\n        ctypes.wintypes.BOOL, ctypes.wintypes.HANDLE, ctypes.wintypes.LPWSTR,\n        ctypes.wintypes.DWORD, ctypes.POINTER(ctypes.wintypes.DWORD),\n        ctypes.wintypes.LPVOID)((\"WriteConsoleW\", ctypes.windll.kernel32))\n    written = ctypes.wintypes.DWORD(0)\n\n    GetFileType = ctypes.WINFUNCTYPE(ctypes.wintypes.DWORD, ctypes.wintypes.DWORD)((\"GetFileType\", ctypes.windll.kernel32))\n    FILE_TYPE_CHAR = 0x0002\n    FILE_TYPE_REMOTE = 0x8000\n    GetConsoleMode = ctypes.WINFUNCTYPE(\n        ctypes.wintypes.BOOL, ctypes.wintypes.HANDLE,\n        ctypes.POINTER(ctypes.wintypes.DWORD))(\n        (\"GetConsoleMode\", ctypes.windll.kernel32))\n    INVALID_HANDLE_VALUE = ctypes.wintypes.DWORD(-1).value\n\n    def not_a_console(handle):\n        if handle == INVALID_HANDLE_VALUE or handle is None:\n            return True\n        return ((GetFileType(handle) & ~FILE_TYPE_REMOTE) != FILE_TYPE_CHAR\n                or GetConsoleMode(handle, ctypes.byref(ctypes.wintypes.DWORD())) == 0)\n\n    if not_a_console(h):\n        return False\n\n    def next_nonbmp_pos(s):\n        try:\n            return next(i for i, c in enumerate(s) if ord(c) > 0xffff)\n        except StopIteration:\n            return len(s)\n\n    while s:\n        count = min(next_nonbmp_pos(s), 1024)\n\n        ret = WriteConsoleW(\n            h, s, count if count else 2, ctypes.byref(written), None)\n        if ret == 0:\n            raise OSError('Failed to write string')\n        if not count:  # We just wrote a non-BMP character\n            assert written.value == 2\n            s = s[1:]\n        else:\n            assert written.value > 0\n            s = s[written.value:]\n    return True",
        "begin_line": 992,
        "end_line": 1061,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.write_string#1064",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.write_string(s, out=None, encoding=None)",
        "snippet": "def write_string(s, out=None, encoding=None):\n    if out is None:\n        out = sys.stderr\n    assert type(s) == compat_str\n\n    if sys.platform == 'win32' and encoding is None and hasattr(out, 'fileno'):\n        if _windows_write_string(s, out):\n            return\n\n    if ('b' in getattr(out, 'mode', '') or\n            sys.version_info[0] < 3):  # Python 2 lies about mode of sys.stderr\n        byt = s.encode(encoding or preferredencoding(), 'ignore')\n        out.write(byt)\n    elif hasattr(out, 'buffer'):\n        enc = encoding or getattr(out, 'encoding', None) or preferredencoding()\n        byt = s.encode(enc, 'ignore')\n        out.buffer.write(byt)\n    else:\n        out.write(s)\n    out.flush()",
        "begin_line": 1064,
        "end_line": 1083,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.008064516129032258,
            "pseudo_dstar_susp": 0.008333333333333333,
            "pseudo_tarantula_susp": 0.00031486146095717883,
            "pseudo_op2_susp": 0.008333333333333333,
            "pseudo_barinel_susp": 0.00031496062992125983
        }
    },
    {
        "name": "youtube_dl.utils.bytes_to_intlist#1086",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.bytes_to_intlist(bs)",
        "snippet": "def bytes_to_intlist(bs):\n    if not bs:\n        return []\n    if isinstance(bs[0], int):  # Python 3\n        return list(bs)\n    else:\n        return [ord(c) for c in bs]",
        "begin_line": 1086,
        "end_line": 1092,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.intlist_to_bytes#1095",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.intlist_to_bytes(xs)",
        "snippet": "def intlist_to_bytes(xs):\n    if not xs:\n        return b''\n    if isinstance(chr(0), bytes):  # Python 2\n        return ''.join([chr(x) for x in xs])\n    else:\n        return bytes(xs)",
        "begin_line": 1095,
        "end_line": 1101,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils._lock_file#1162",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils._lock_file(f, exclusive)",
        "snippet": "    def _lock_file(f, exclusive):\n        fcntl.flock(f, fcntl.LOCK_EX if exclusive else fcntl.LOCK_SH)",
        "begin_line": 1162,
        "end_line": 1163,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils._unlock_file#1165",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils._unlock_file(f)",
        "snippet": "    def _unlock_file(f):\n        fcntl.flock(f, fcntl.LOCK_UN)",
        "begin_line": 1165,
        "end_line": 1166,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.locked_file.__init__#1170",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.locked_file",
        "signature": "youtube_dl.utils.locked_file.__init__(self, filename, mode, encoding=None)",
        "snippet": "    def __init__(self, filename, mode, encoding=None):\n        assert mode in ['r', 'a', 'w']\n        self.f = io.open(filename, mode, encoding=encoding)\n        self.mode = mode",
        "begin_line": 1170,
        "end_line": 1173,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.locked_file.__enter__#1175",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.locked_file",
        "signature": "youtube_dl.utils.locked_file.__enter__(self)",
        "snippet": "    def __enter__(self):\n        exclusive = self.mode != 'r'\n        try:\n            _lock_file(self.f, exclusive)\n        except IOError:\n            self.f.close()\n            raise\n        return self",
        "begin_line": 1175,
        "end_line": 1182,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.locked_file.__exit__#1184",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.locked_file",
        "signature": "youtube_dl.utils.locked_file.__exit__(self, etype, value, traceback)",
        "snippet": "    def __exit__(self, etype, value, traceback):\n        try:\n            _unlock_file(self.f)\n        finally:\n            self.f.close()",
        "begin_line": 1184,
        "end_line": 1188,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.locked_file.__iter__#1190",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.locked_file",
        "signature": "youtube_dl.utils.locked_file.__iter__(self)",
        "snippet": "    def __iter__(self):\n        return iter(self.f)",
        "begin_line": 1190,
        "end_line": 1191,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.locked_file.write#1193",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.locked_file",
        "signature": "youtube_dl.utils.locked_file.write(self, *args)",
        "snippet": "    def write(self, *args):\n        return self.f.write(*args)",
        "begin_line": 1193,
        "end_line": 1194,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.locked_file.read#1196",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.locked_file",
        "signature": "youtube_dl.utils.locked_file.read(self, *args)",
        "snippet": "    def read(self, *args):\n        return self.f.read(*args)",
        "begin_line": 1196,
        "end_line": 1197,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.shell_quote#1200",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.shell_quote(args)",
        "snippet": "def shell_quote(args):\n    quoted_args = []\n    encoding = sys.getfilesystemencoding()\n    if encoding is None:\n        encoding = 'utf-8'\n    for a in args:\n        if isinstance(a, bytes):\n            # We may get a filename encoded with 'encodeFilename'\n            a = a.decode(encoding)\n        quoted_args.append(pipes.quote(a))\n    return u' '.join(quoted_args)",
        "begin_line": 1200,
        "end_line": 1210,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.takewhile_inclusive#1213",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.takewhile_inclusive(pred, seq)",
        "snippet": "def takewhile_inclusive(pred, seq):\n    \"\"\" Like itertools.takewhile, but include the latest evaluated element\n        (the first element so that Not pred(e)) \"\"\"\n    for e in seq:\n        yield e\n        if not pred(e):\n            return",
        "begin_line": 1213,
        "end_line": 1219,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.smuggle_url#1222",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.smuggle_url(url, data)",
        "snippet": "def smuggle_url(url, data):\n    \"\"\" Pass additional data in a URL for internal use. \"\"\"\n\n    sdata = compat_urllib_parse.urlencode(\n        {u'__youtubedl_smuggle': json.dumps(data)})\n    return url + u'#' + sdata",
        "begin_line": 1222,
        "end_line": 1227,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.unsmuggle_url#1230",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.unsmuggle_url(smug_url, default=None)",
        "snippet": "def unsmuggle_url(smug_url, default=None):\n    if not '#__youtubedl_smuggle' in smug_url:\n        return smug_url, default\n    url, _, sdata = smug_url.rpartition(u'#')\n    jsond = compat_parse_qs(sdata)[u'__youtubedl_smuggle'][0]\n    data = json.loads(jsond)\n    return url, data",
        "begin_line": 1230,
        "end_line": 1236,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0030581039755351682,
            "pseudo_dstar_susp": 0.002849002849002849,
            "pseudo_tarantula_susp": 0.00033500837520938025,
            "pseudo_op2_susp": 0.002849002849002849,
            "pseudo_barinel_susp": 0.00033500837520938025
        }
    },
    {
        "name": "youtube_dl.utils.format_bytes#1239",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.format_bytes(bytes)",
        "snippet": "def format_bytes(bytes):\n    if bytes is None:\n        return u'N/A'\n    if type(bytes) is str:\n        bytes = float(bytes)\n    if bytes == 0.0:\n        exponent = 0\n    else:\n        exponent = int(math.log(bytes, 1024.0))\n    suffix = [u'B', u'KiB', u'MiB', u'GiB', u'TiB', u'PiB', u'EiB', u'ZiB', u'YiB'][exponent]\n    converted = float(bytes) / float(1024 ** exponent)\n    return u'%.2f%s' % (converted, suffix)",
        "begin_line": 1239,
        "end_line": 1250,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006693440428380187,
            "pseudo_dstar_susp": 0.0009107468123861566,
            "pseudo_tarantula_susp": 0.0002447980416156671,
            "pseudo_op2_susp": 0.0009107468123861566,
            "pseudo_barinel_susp": 0.00024467824810374357
        }
    },
    {
        "name": "youtube_dl.utils.get_term_width#1253",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.get_term_width()",
        "snippet": "def get_term_width():\n    columns = os.environ.get('COLUMNS', None)\n    if columns:\n        return int(columns)\n\n    try:\n        sp = subprocess.Popen(\n            ['stty', 'size'],\n            stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        out, err = sp.communicate()\n        return int(out.split()[1])\n    except:\n        pass\n    return None",
        "begin_line": 1253,
        "end_line": 1266,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.0001840942562592047,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.month_by_name#1269",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.month_by_name(name)",
        "snippet": "def month_by_name(name):\n    \"\"\" Return the number of a month by (locale-independently) English name \"\"\"\n\n    ENGLISH_NAMES = [\n        u'January', u'February', u'March', u'April', u'May', u'June',\n        u'July', u'August', u'September', u'October', u'November', u'December']\n    try:\n        return ENGLISH_NAMES.index(name) + 1\n    except ValueError:\n        return None",
        "begin_line": 1269,
        "end_line": 1278,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.fix_xml_ampersands#1281",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.fix_xml_ampersands(xml_str)",
        "snippet": "def fix_xml_ampersands(xml_str):\n    \"\"\"Replace all the '&' by '&amp;' in XML\"\"\"\n    return re.sub(\n        r'&(?!amp;|lt;|gt;|apos;|quot;|#x[0-9a-fA-F]{,4};|#[0-9]{,4};)',\n        u'&amp;',\n        xml_str)",
        "begin_line": 1281,
        "end_line": 1286,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.setproctitle#1289",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.setproctitle(title)",
        "snippet": "def setproctitle(title):\n    assert isinstance(title, compat_str)\n    try:\n        libc = ctypes.cdll.LoadLibrary(\"libc.so.6\")\n    except OSError:\n        return\n    title_bytes = title.encode('utf-8')\n    buf = ctypes.create_string_buffer(len(title_bytes))\n    buf.value = title_bytes\n    try:\n        libc.prctl(15, buf, 0, 0, 0)\n    except AttributeError:\n        return  # Strange libc, just skip this",
        "begin_line": 1289,
        "end_line": 1301,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.0001840942562592047,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.remove_start#1304",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.remove_start(s, start)",
        "snippet": "def remove_start(s, start):\n    if s.startswith(start):\n        return s[len(start):]\n    return s",
        "begin_line": 1304,
        "end_line": 1307,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.remove_end#1310",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.remove_end(s, end)",
        "snippet": "def remove_end(s, end):\n    if s.endswith(end):\n        return s[:-len(end)]\n    return s",
        "begin_line": 1310,
        "end_line": 1313,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.utils.url_basename#1316",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.url_basename(url)",
        "snippet": "def url_basename(url):\n    path = compat_urlparse.urlparse(url).path\n    return path.strip(u'/').split(u'/')[-1]",
        "begin_line": 1316,
        "end_line": 1318,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002967359050445104,
            "pseudo_dstar_susp": 0.0030959752321981426,
            "pseudo_tarantula_susp": 0.00028571428571428574,
            "pseudo_op2_susp": 0.0030959752321981426,
            "pseudo_barinel_susp": 0.00028571428571428574
        }
    },
    {
        "name": "youtube_dl.utils.HEADRequest.get_method#1322",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.HEADRequest",
        "signature": "youtube_dl.utils.HEADRequest.get_method(self)",
        "snippet": "    def get_method(self):\n        return \"HEAD\"",
        "begin_line": 1322,
        "end_line": 1323,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002347417840375587,
            "pseudo_dstar_susp": 0.0023148148148148147,
            "pseudo_tarantula_susp": 0.00033145508783559825,
            "pseudo_op2_susp": 0.0023148148148148147,
            "pseudo_barinel_susp": 0.00033145508783559825
        }
    },
    {
        "name": "youtube_dl.utils.int_or_none#1326",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.int_or_none(v, scale=1, default=None, get_attr=None, invscale=1)",
        "snippet": "def int_or_none(v, scale=1, default=None, get_attr=None, invscale=1):\n    if get_attr:\n        if v is not None:\n            v = getattr(v, get_attr, None)\n    if v == '':\n        v = None\n    return default if v is None else (int(v) * invscale // scale)",
        "begin_line": 1326,
        "end_line": 1332,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007077140835102619,
            "pseudo_dstar_susp": 0.0008064516129032258,
            "pseudo_tarantula_susp": 0.0002680246582685607,
            "pseudo_op2_susp": 0.0008064516129032258,
            "pseudo_barinel_susp": 0.0002681684097613301
        }
    },
    {
        "name": "youtube_dl.utils.str_or_none#1335",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.str_or_none(v, default=None)",
        "snippet": "def str_or_none(v, default=None):\n    return default if v is None else compat_str(v)",
        "begin_line": 1335,
        "end_line": 1336,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.utils.str_to_int#1339",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.str_to_int(int_str)",
        "snippet": "def str_to_int(int_str):\n    \"\"\" A more relaxed version of int_or_none \"\"\"\n    if int_str is None:\n        return None\n    int_str = re.sub(r'[,\\.\\+]', u'', int_str)\n    return int(int_str)",
        "begin_line": 1339,
        "end_line": 1344,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.float_or_none#1347",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.float_or_none(v, scale=1, invscale=1, default=None)",
        "snippet": "def float_or_none(v, scale=1, invscale=1, default=None):\n    return default if v is None else (float(v) * invscale / scale)",
        "begin_line": 1347,
        "end_line": 1348,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.utils.parse_duration#1351",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.parse_duration(s)",
        "snippet": "def parse_duration(s):\n    if s is None:\n        return None\n\n    s = s.strip()\n\n    m = re.match(\n        r'(?i)(?:(?:(?P<hours>[0-9]+)\\s*(?:[:h]|hours?)\\s*)?(?P<mins>[0-9]+)\\s*(?:[:m]|mins?|minutes?)\\s*)?(?P<secs>[0-9]+)(?P<ms>\\.[0-9]+)?\\s*(?:s|secs?|seconds?)?$', s)\n    if not m:\n        return None\n    res = int(m.group('secs'))\n    if m.group('mins'):\n        res += int(m.group('mins')) * 60\n        if m.group('hours'):\n            res += int(m.group('hours')) * 60 * 60\n    if m.group('ms'):\n        res += float(m.group('ms'))\n    return res",
        "begin_line": 1351,
        "end_line": 1368,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00047393364928909954,
            "pseudo_dstar_susp": 0.0008032128514056225,
            "pseudo_tarantula_susp": 0.0002772387025228722,
            "pseudo_op2_susp": 0.0008032128514056225,
            "pseudo_barinel_susp": 0.00027631942525559546
        }
    },
    {
        "name": "youtube_dl.utils.prepend_extension#1371",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.prepend_extension(filename, ext)",
        "snippet": "def prepend_extension(filename, ext):\n    name, real_ext = os.path.splitext(filename) \n    return u'{0}.{1}{2}'.format(name, ext, real_ext)",
        "begin_line": 1371,
        "end_line": 1373,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.check_executable#1376",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.check_executable(exe, args=[])",
        "snippet": "def check_executable(exe, args=[]):\n    \"\"\" Checks if the given binary is installed somewhere in PATH, and returns its name.\n    args can be a list of arguments for a short output (like -version) \"\"\"\n    try:\n        subprocess.Popen([exe] + args, stdout=subprocess.PIPE, stderr=subprocess.PIPE).communicate()\n    except OSError:\n        return False\n    return exe",
        "begin_line": 1376,
        "end_line": 1383,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.utils.PagedList.__init__#1387",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.PagedList",
        "signature": "youtube_dl.utils.PagedList.__init__(self, pagefunc, pagesize)",
        "snippet": "    def __init__(self, pagefunc, pagesize):\n        self._pagefunc = pagefunc\n        self._pagesize = pagesize",
        "begin_line": 1387,
        "end_line": 1389,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0004610419548178884,
            "pseudo_dstar_susp": 0.000449842555105713,
            "pseudo_tarantula_susp": 0.0002880184331797235,
            "pseudo_op2_susp": 0.000449842555105713,
            "pseudo_barinel_susp": 0.0002880184331797235
        }
    },
    {
        "name": "youtube_dl.utils.PagedList.__len__#1391",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.PagedList",
        "signature": "youtube_dl.utils.PagedList.__len__(self)",
        "snippet": "    def __len__(self):\n        # This is only useful for tests\n        return len(self.getslice())",
        "begin_line": 1391,
        "end_line": 1393,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.utils.PagedList.getslice#1395",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.PagedList",
        "signature": "youtube_dl.utils.PagedList.getslice(self, start=0, end=None)",
        "snippet": "    def getslice(self, start=0, end=None):\n        res = []\n        for pagenum in itertools.count(start // self._pagesize):\n            firstid = pagenum * self._pagesize\n            nextfirstid = pagenum * self._pagesize + self._pagesize\n            if start >= nextfirstid:\n                continue\n\n            page_results = list(self._pagefunc(pagenum))\n\n            startv = (\n                start % self._pagesize\n                if firstid <= start < nextfirstid\n                else 0)\n\n            endv = (\n                ((end - 1) % self._pagesize) + 1\n                if (end is not None and firstid <= end <= nextfirstid)\n                else None)\n\n            if startv != 0 or endv is not None:\n                page_results = page_results[startv:endv]\n            res.extend(page_results)\n\n            # A little optimization - if current page is not \"full\", ie. does\n            # not contain page_size videos then we can assume that this page\n            # is the last one - there are no more ids on further pages -\n            # i.e. no need to query again.\n            if len(page_results) + startv < self._pagesize:\n                break\n\n            # If we got the whole page, but the next page is not interesting,\n            # break out early as well\n            if end == nextfirstid:\n                break\n        return res",
        "begin_line": 1395,
        "end_line": 1430,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0004610419548178884,
            "pseudo_dstar_susp": 0.000449842555105713,
            "pseudo_tarantula_susp": 0.0002880184331797235,
            "pseudo_op2_susp": 0.000449842555105713,
            "pseudo_barinel_susp": 0.0002880184331797235
        }
    },
    {
        "name": "youtube_dl.utils.uppercase_escape#1433",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.uppercase_escape(s)",
        "snippet": "def uppercase_escape(s):\n    unicode_escape = codecs.getdecoder('unicode_escape')\n    return re.sub(\n        r'\\\\U[0-9a-fA-F]{8}',\n        lambda m: unicode_escape(m.group(0))[0],\n        s)",
        "begin_line": 1433,
        "end_line": 1438,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.read_batch_urls#1458",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.read_batch_urls(batch_fd)",
        "snippet": "def read_batch_urls(batch_fd):\n    def fixup(url):\n        if not isinstance(url, compat_str):\n            url = url.decode('utf-8', 'replace')\n        BOM_UTF8 = u'\\xef\\xbb\\xbf'\n        if url.startswith(BOM_UTF8):\n            url = url[len(BOM_UTF8):]\n        url = url.strip()\n        if url.startswith(('#', ';', ']')):\n            return False\n        return url\n\n    with contextlib.closing(batch_fd) as fd:\n        return [url for url in map(fixup, fd) if url]",
        "begin_line": 1458,
        "end_line": 1471,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.fixup#1459",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.fixup(url)",
        "snippet": "    def fixup(url):\n        if not isinstance(url, compat_str):\n            url = url.decode('utf-8', 'replace')\n        BOM_UTF8 = u'\\xef\\xbb\\xbf'\n        if url.startswith(BOM_UTF8):\n            url = url[len(BOM_UTF8):]\n        url = url.strip()\n        if url.startswith(('#', ';', ']')):\n            return False\n        return url",
        "begin_line": 1459,
        "end_line": 1468,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.urlencode_postdata#1474",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.urlencode_postdata(*args, **kargs)",
        "snippet": "def urlencode_postdata(*args, **kargs):\n    return compat_urllib_parse.urlencode(*args, **kargs).encode('ascii')",
        "begin_line": 1474,
        "end_line": 1475,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00023618327822390176,
            "pseudo_dstar_susp": 0.000233590282644242,
            "pseudo_tarantula_susp": 0.0002772387025228722,
            "pseudo_op2_susp": 0.000233590282644242,
            "pseudo_barinel_susp": 0.00027631942525559546
        }
    },
    {
        "name": "youtube_dl.utils.parse_xml#1484",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.parse_xml(s)",
        "snippet": "def parse_xml(s):\n    class TreeBuilder(xml.etree.ElementTree.TreeBuilder):\n        def doctype(self, name, pubid, system):\n            pass  # Ignore doctypes\n\n    parser = xml.etree.ElementTree.XMLParser(target=TreeBuilder())\n    kwargs = {'parser': parser} if sys.version_info >= (2, 7) else {}\n    tree = xml.etree.ElementTree.XML(s.encode('utf-8'), **kwargs)\n    # Fix up XML parser in Python 2.x\n    if sys.version_info < (3, 0):\n        for n in etree_iter(tree):\n            if n.text is not None:\n                if not isinstance(n.text, compat_str):\n                    n.text = n.text.decode('utf-8')\n    return tree",
        "begin_line": 1484,
        "end_line": 1498,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0018281535648994515,
            "pseudo_dstar_susp": 0.0013458950201884253,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0013458950201884253,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.utils.TreeBuilder.parse_xml#1484",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.TreeBuilder",
        "signature": "youtube_dl.utils.TreeBuilder.parse_xml(s)",
        "snippet": "def parse_xml(s):\n    class TreeBuilder(xml.etree.ElementTree.TreeBuilder):\n        def doctype(self, name, pubid, system):\n            pass  # Ignore doctypes\n\n    parser = xml.etree.ElementTree.XMLParser(target=TreeBuilder())\n    kwargs = {'parser': parser} if sys.version_info >= (2, 7) else {}\n    tree = xml.etree.ElementTree.XML(s.encode('utf-8'), **kwargs)\n    # Fix up XML parser in Python 2.x\n    if sys.version_info < (3, 0):\n        for n in etree_iter(tree):\n            if n.text is not None:\n                if not isinstance(n.text, compat_str):\n                    n.text = n.text.decode('utf-8')\n    return tree",
        "begin_line": 1484,
        "end_line": 1498,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0025,
            "pseudo_dstar_susp": 0.0024752475247524753,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0024752475247524753,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.utils.TreeBuilder.doctype#1486",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.TreeBuilder",
        "signature": "youtube_dl.utils.TreeBuilder.doctype(self, name, pubid, system)",
        "snippet": "        def doctype(self, name, pubid, system):\n            pass  # Ignore doctypes",
        "begin_line": 1486,
        "end_line": 1487,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0022935779816513763,
            "pseudo_dstar_susp": 0.002183406113537118,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.002183406113537118,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.utils.strip_jsonp#1519",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.strip_jsonp(code)",
        "snippet": "def strip_jsonp(code):\n    return re.sub(r'(?s)^[a-zA-Z0-9_]+\\s*\\(\\s*(.*)\\);?\\s*?\\s*$', r'\\1', code)",
        "begin_line": 1519,
        "end_line": 1520,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00023618327822390176,
            "pseudo_dstar_susp": 0.000233590282644242,
            "pseudo_tarantula_susp": 0.0002772387025228722,
            "pseudo_op2_susp": 0.000233590282644242,
            "pseudo_barinel_susp": 0.00027631942525559546
        }
    },
    {
        "name": "youtube_dl.utils.js_to_json#1523",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.js_to_json(code)",
        "snippet": "def js_to_json(code):\n    def fix_kv(m):\n        key = m.group(2)\n        if key.startswith(\"'\"):\n            assert key.endswith(\"'\")\n            assert '\"' not in key\n            key = '\"%s\"' % key[1:-1]\n        elif not key.startswith('\"'):\n            key = '\"%s\"' % key\n\n        value = m.group(4)\n        if value.startswith(\"'\"):\n            assert value.endswith(\"'\")\n            assert '\"' not in value\n            value = '\"%s\"' % value[1:-1]\n\n        return m.group(1) + key + m.group(3) + value\n\n    res = re.sub(r'''(?x)\n            ([{,]\\s*)\n            (\"[^\"]*\"|\\'[^\\']*\\'|[a-z0-9A-Z]+)\n            (:\\s*)\n            ([0-9.]+|true|false|\"[^\"]*\"|\\'[^\\']*\\'|\\[|\\{)\n        ''', fix_kv, code)\n    res = re.sub(r',(\\s*\\])', lambda m: m.group(1), res)\n    return res",
        "begin_line": 1523,
        "end_line": 1548,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.utils.qualities#1551",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.qualities(quality_ids)",
        "snippet": "def qualities(quality_ids):\n    \"\"\" Get a numeric quality value out of a list of possible values \"\"\"\n    def q(qid):\n        try:\n            return quality_ids.index(qid)\n        except ValueError:\n            return -1\n    return q",
        "begin_line": 1551,
        "end_line": 1558,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007194244604316547,
            "pseudo_dstar_susp": 0.0006729475100942127,
            "pseudo_tarantula_susp": 0.0002880184331797235,
            "pseudo_op2_susp": 0.0006729475100942127,
            "pseudo_barinel_susp": 0.0002880184331797235
        }
    },
    {
        "name": "youtube_dl.utils.q#1553",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.q(qid)",
        "snippet": "    def q(qid):\n        try:\n            return quality_ids.index(qid)\n        except ValueError:\n            return -1",
        "begin_line": 1553,
        "end_line": 1557,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008583690987124463,
            "pseudo_dstar_susp": 0.0008077544426494346,
            "pseudo_tarantula_susp": 0.00028538812785388126,
            "pseudo_op2_susp": 0.0008077544426494346,
            "pseudo_barinel_susp": 0.00028538812785388126
        }
    },
    {
        "name": "youtube_dl.extractor.tenplay.TenPlayIE._real_extract#32",
        "src_path": "youtube_dl/extractor/tenplay.py",
        "class_name": "youtube_dl.extractor.tenplay.TenPlayIE",
        "signature": "youtube_dl.extractor.tenplay.TenPlayIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        webpage = self._download_webpage(url, url)\n        video_id = self._html_search_regex(\n            r'videoID: \"(\\d+?)\"', webpage, 'video_id')\n        api_token = self._html_search_regex(\n            r'apiToken: \"([a-zA-Z0-9-_\\.]+?)\"', webpage, 'api_token')\n        title = self._html_search_regex(\n            r'<meta property=\"og:title\" content=\"\\s*(.*?)\\s*\"\\s*/?\\s*>',\n            webpage, 'title')\n\n        json = self._download_json('https://api.brightcove.com/services/library?command=find_video_by_id&video_id=%s&token=%s&video_fields=%s' % (video_id, api_token, ','.join(self._video_fields)), title)\n\n        formats = []\n        for rendition in json['renditions']:\n            url = rendition['remoteUrl'] or rendition['url']\n            protocol = 'rtmp' if url.startswith('rtmp') else 'http'\n            ext = 'flv' if protocol == 'rtmp' else rendition['videoContainer'].lower()\n\n            if protocol == 'rtmp':\n                url = url.replace('&mp4:', '')\n\n            formats.append({\n                'format_id': '_'.join(['rtmp', rendition['videoContainer'].lower(), rendition['videoCodec'].lower()]),\n                'width': rendition['frameWidth'],\n                'height': rendition['frameHeight'],\n                'tbr': rendition['encodingRate'] / 1024,\n                'filesize': rendition['size'],\n                'protocol': protocol,\n                'ext': ext,\n                'vcodec': rendition['videoCodec'].lower(),\n                'container': rendition['videoContainer'].lower(),\n                'url': url,\n            })\n\n        return {\n            'id': video_id,\n            'display_id': json['referenceId'],\n            'title': json['name'],\n            'description': json['shortDescription'] or json['longDescription'],\n            'formats': formats,\n            'thumbnails': [{\n                'url': json['videoStillURL']\n            }, {\n                'url': json['thumbnailURL']\n            }],\n            'thumbnail': json['videoStillURL'],\n            'duration': json['length'] / 1000,\n            'timestamp': float(json['creationDate']) / 1000,\n            'uploader': json['customFields']['production_company_distributor'] if 'production_company_distributor' in json['customFields'] else 'TENplay',\n            'view_count': json['playsTotal']\n        }",
        "begin_line": 32,
        "end_line": 82,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.eighttracks.EightTracksIE._real_extract#102",
        "src_path": "youtube_dl/extractor/eighttracks.py",
        "class_name": "youtube_dl.extractor.eighttracks.EightTracksIE",
        "signature": "youtube_dl.extractor.eighttracks.EightTracksIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        json_like = self._search_regex(\n            r\"(?s)PAGE.mix = (.*?);\\n\", webpage, 'trax information')\n        data = json.loads(json_like)\n\n        session = str(random.randint(0, 1000000000))\n        mix_id = data['id']\n        track_count = data['tracks_count']\n        first_url = 'http://8tracks.com/sets/%s/play?player=sm&mix_id=%s&format=jsonh' % (session, mix_id)\n        next_url = first_url\n        entries = []\n        for i in range(track_count):\n            api_json = self._download_webpage(\n                next_url, playlist_id,\n                note='Downloading song information %d/%d' % (i + 1, track_count),\n                errnote='Failed to download song information')\n            api_data = json.loads(api_json)\n            track_data = api_data['set']['track']\n            info = {\n                'id': compat_str(track_data['id']),\n                'url': track_data['track_file_stream_url'],\n                'title': track_data['performer'] + u' - ' + track_data['name'],\n                'raw_title': track_data['name'],\n                'uploader_id': data['user']['login'],\n                'ext': 'm4a',\n            }\n            entries.append(info)\n            next_url = 'http://8tracks.com/sets/%s/next?player=sm&mix_id=%s&format=jsonh&track_id=%s' % (\n                session, mix_id, track_data['id'])\n        return {\n            '_type': 'playlist',\n            'entries': entries,\n            'id': compat_str(mix_id),\n            'display_id': playlist_id,\n            'title': data.get('name'),\n            'description': data.get('description'),\n        }",
        "begin_line": 102,
        "end_line": 143,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.redtube.RedTubeIE._real_extract#22",
        "src_path": "youtube_dl/extractor/redtube.py",
        "class_name": "youtube_dl.extractor.redtube.RedTubeIE",
        "signature": "youtube_dl.extractor.redtube.RedTubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n        video_extension = 'mp4'\n        webpage = self._download_webpage(url, video_id)\n\n        self.report_extraction(video_id)\n\n        video_url = self._html_search_regex(\n            r'<source src=\"(.+?)\" type=\"video/mp4\">', webpage, u'video URL')\n\n        video_title = self._html_search_regex(\n            r'<h1 class=\"videoTitle[^\"]*\">(.+?)</h1>',\n            webpage, u'title')\n\n        video_thumbnail = self._og_search_thumbnail(webpage)\n\n        # No self-labeling, but they describe themselves as\n        # \"Home of Videos Porno\"\n        age_limit = 18\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'ext': video_extension,\n            'title': video_title,\n            'thumbnail': video_thumbnail,\n            'age_limit': age_limit,\n        }",
        "begin_line": 22,
        "end_line": 51,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.addanime.AddAnimeIE._real_extract#30",
        "src_path": "youtube_dl/extractor/addanime.py",
        "class_name": "youtube_dl.extractor.addanime.AddAnimeIE",
        "signature": "youtube_dl.extractor.addanime.AddAnimeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        try:\n            mobj = re.match(self._VALID_URL, url)\n            video_id = mobj.group('video_id')\n            webpage = self._download_webpage(url, video_id)\n        except ExtractorError as ee:\n            if not isinstance(ee.cause, compat_HTTPError) or \\\n               ee.cause.code != 503:\n                raise\n\n            redir_webpage = ee.cause.read().decode('utf-8')\n            action = self._search_regex(\n                r'<form id=\"challenge-form\" action=\"([^\"]+)\"',\n                redir_webpage, 'Redirect form')\n            vc = self._search_regex(\n                r'<input type=\"hidden\" name=\"jschl_vc\" value=\"([^\"]+)\"/>',\n                redir_webpage, 'redirect vc value')\n            av = re.search(\n                r'a\\.value = ([0-9]+)[+]([0-9]+)[*]([0-9]+);',\n                redir_webpage)\n            if av is None:\n                raise ExtractorError(u'Cannot find redirect math task')\n            av_res = int(av.group(1)) + int(av.group(2)) * int(av.group(3))\n\n            parsed_url = compat_urllib_parse_urlparse(url)\n            av_val = av_res + len(parsed_url.netloc)\n            confirm_url = (\n                parsed_url.scheme + '://' + parsed_url.netloc +\n                action + '?' +\n                compat_urllib_parse.urlencode({\n                    'jschl_vc': vc, 'jschl_answer': compat_str(av_val)}))\n            self._download_webpage(\n                confirm_url, video_id,\n                note='Confirming after redirect')\n            webpage = self._download_webpage(url, video_id)\n\n        formats = []\n        for format_id in ('normal', 'hq'):\n            rex = r\"var %s_video_file = '(.*?)';\" % re.escape(format_id)\n            video_url = self._search_regex(rex, webpage, 'video file URLx',\n                                           fatal=False)\n            if not video_url:\n                continue\n            formats.append({\n                'format_id': format_id,\n                'url': video_url,\n            })\n        self._sort_formats(formats)\n        video_title = self._og_search_title(webpage)\n        video_description = self._og_search_description(webpage)\n\n        return {\n            '_type': 'video',\n            'id': video_id,\n            'formats': formats,\n            'title': video_title,\n            'description': video_description\n        }",
        "begin_line": 30,
        "end_line": 87,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.chilloutzone.ChilloutzoneIE._real_extract#52",
        "src_path": "youtube_dl/extractor/chilloutzone.py",
        "class_name": "youtube_dl.extractor.chilloutzone.ChilloutzoneIE",
        "signature": "youtube_dl.extractor.chilloutzone.ChilloutzoneIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        base64_video_info = self._html_search_regex(\n            r'var cozVidData = \"(.+?)\";', webpage, 'video data')\n        decoded_video_info = base64.b64decode(base64_video_info).decode(\"utf-8\")\n        video_info_dict = json.loads(decoded_video_info)\n\n        # get video information from dict\n        video_url = video_info_dict['mediaUrl']\n        description = clean_html(video_info_dict.get('description'))\n        title = video_info_dict['title']\n        native_platform = video_info_dict['nativePlatform']\n        native_video_id = video_info_dict['nativeVideoId']\n        source_priority = video_info_dict['sourcePriority']\n\n        # If nativePlatform is None a fallback mechanism is used (i.e. youtube embed)\n        if native_platform is None:\n            youtube_url = self._html_search_regex(\n                r'<iframe.* src=\"((?:https?:)?//(?:[^.]+\\.)?youtube\\.com/.+?)\"',\n                webpage, 'fallback video URL', default=None)\n            if youtube_url is not None:\n                return self.url_result(youtube_url, ie='Youtube')\n\n        # Non Fallback: Decide to use native source (e.g. youtube or vimeo) or\n        # the own CDN\n        if source_priority == 'native':\n            if native_platform == 'youtube':\n                return self.url_result(native_video_id, ie='Youtube')\n            if native_platform == 'vimeo':\n                return self.url_result(\n                    'http://vimeo.com/' + native_video_id, ie='Vimeo')\n\n        if not video_url:\n            raise ExtractorError('No video found')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'ext': 'mp4',\n            'title': title,\n            'description': description,\n        }",
        "begin_line": 52,
        "end_line": 97,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007692307692307692,
            "pseudo_dstar_susp": 0.0006273525721455458,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006273525721455458,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.dump.DumpIE._real_extract#23",
        "src_path": "youtube_dl/extractor/dump.py",
        "class_name": "youtube_dl.extractor.dump.DumpIE",
        "signature": "youtube_dl.extractor.dump.DumpIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        video_url = self._search_regex(\n            r's1.addVariable\\(\"file\",\\s*\"([^\"]+)\"', webpage, 'video URL')\n\n        thumb = self._og_search_thumbnail(webpage)\n        title = self._search_regex(r'<b>([^\"]+)</b>', webpage, 'title')\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'thumbnail': thumb,\n        }",
        "begin_line": 23,
        "end_line": 39,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.viddler.ViddlerIE._real_extract#20",
        "src_path": "youtube_dl/extractor/viddler.py",
        "class_name": "youtube_dl.extractor.viddler.ViddlerIE",
        "signature": "youtube_dl.extractor.viddler.ViddlerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        embed_url = mobj.group('domain') + u'/embed/' + video_id\n        webpage = self._download_webpage(embed_url, video_id)\n\n        video_sources_code = self._search_regex(\n            r\"(?ms)sources\\s*:\\s*(\\{.*?\\})\", webpage, u'video URLs')\n        video_sources = json.loads(video_sources_code.replace(\"'\", '\"'))\n\n        formats = [{\n            'url': video_url,\n            'format': format_id,\n        } for video_url, format_id in video_sources.items()]\n\n        title = self._html_search_regex(\n            r\"title\\s*:\\s*'([^']*)'\", webpage, u'title')\n        uploader = self._html_search_regex(\n            r\"authorName\\s*:\\s*'([^']*)'\", webpage, u'uploader', fatal=False)\n        duration_s = self._html_search_regex(\n            r\"duration\\s*:\\s*([0-9.]*)\", webpage, u'duration', fatal=False)\n        duration = float(duration_s) if duration_s else None\n        thumbnail = self._html_search_regex(\n            r\"thumbnail\\s*:\\s*'([^']*)'\",\n            webpage, u'thumbnail', fatal=False)\n\n        return {\n            '_type': 'video',\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 20,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.ard.ARDMediathekIE._real_extract#44",
        "src_path": "youtube_dl/extractor/ard.py",
        "class_name": "youtube_dl.extractor.ard.ARDMediathekIE",
        "signature": "youtube_dl.extractor.ard.ARDMediathekIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        # determine video id from url\n        m = re.match(self._VALID_URL, url)\n\n        numid = re.search(r'documentId=([0-9]+)', url)\n        if numid:\n            video_id = numid.group(1)\n        else:\n            video_id = m.group('video_id')\n\n        urlp = compat_urllib_parse_urlparse(url)\n        url = urlp._replace(path=compat_urllib_parse.quote(urlp.path.encode('utf-8'))).geturl()\n\n        webpage = self._download_webpage(url, video_id)\n\n        if '>Der gew\u00fcnschte Beitrag ist nicht mehr verf\u00fcgbar.<' in webpage:\n            raise ExtractorError('Video %s is no longer available' % video_id, expected=True)\n\n        title = self._html_search_regex(\n            [r'<h1(?:\\s+class=\"boxTopHeadline\")?>(.*?)</h1>',\n             r'<meta name=\"dcterms.title\" content=\"(.*?)\"/>',\n             r'<h4 class=\"headline\">(.*?)</h4>'],\n            webpage, 'title')\n        description = self._html_search_meta(\n            'dcterms.abstract', webpage, 'description', default=None)\n        if description is None:\n            description = self._html_search_meta(\n                'description', webpage, 'meta description')\n\n        # Thumbnail is sometimes not present.\n        # It is in the mobile version, but that seems to use a different URL\n        # structure altogether.\n        thumbnail = self._og_search_thumbnail(webpage, default=None)\n\n        media_streams = re.findall(r'''(?x)\n            mediaCollection\\.addMediaStream\\([0-9]+,\\s*[0-9]+,\\s*\"[^\"]*\",\\s*\n            \"([^\"]+)\"''', webpage)\n\n        if media_streams:\n            QUALITIES = qualities(['lo', 'hi', 'hq'])\n            formats = []\n            for furl in set(media_streams):\n                if furl.endswith('.f4m'):\n                    fid = 'f4m'\n                else:\n                    fid_m = re.match(r'.*\\.([^.]+)\\.[^.]+$', furl)\n                    fid = fid_m.group(1) if fid_m else None\n                formats.append({\n                    'quality': QUALITIES(fid),\n                    'format_id': fid,\n                    'url': furl,\n                })\n        else:  # request JSON file\n            media_info = self._download_json(\n                'http://www.ardmediathek.de/play/media/%s' % video_id, video_id)\n            # The second element of the _mediaArray contains the standard http urls\n            streams = media_info['_mediaArray'][1]['_mediaStreamArray']\n            if not streams:\n                if '\"fsk\"' in webpage:\n                    raise ExtractorError('This video is only available after 20:00')\n\n            formats = []\n            for s in streams:\n                if type(s['_stream']) == list:\n                    for index, url in enumerate(s['_stream'][::-1]):\n                        quality = s['_quality'] + index\n                        formats.append({\n                            'quality': quality,\n                            'url': url,\n                            'format_id': '%s-%s' % (determine_ext(url), quality)\n                        })\n                    continue\n\n                format = {\n                    'quality': s['_quality'],\n                    'url': s['_stream'],\n                }\n\n                format['format_id'] = '%s-%s' % (\n                    determine_ext(format['url']), format['quality'])\n\n                formats.append(format)\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'formats': formats,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 44,
        "end_line": 135,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.ard.ARDIE._real_extract#154",
        "src_path": "youtube_dl/extractor/ard.py",
        "class_name": "youtube_dl.extractor.ard.ARDIE",
        "signature": "youtube_dl.extractor.ard.ARDIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('display_id')\n\n        player_url = mobj.group('mainurl') + '~playerXml.xml'\n        doc = self._download_xml(player_url, display_id)\n        video_node = doc.find('./video')\n        upload_date = unified_strdate(xpath_text(\n            video_node, './broadcastDate'))\n        thumbnail = xpath_text(video_node, './/teaserImage//variant/url')\n\n        formats = []\n        for a in video_node.findall('.//asset'):\n            f = {\n                'format_id': a.attrib['type'],\n                'width': int_or_none(a.find('./frameWidth').text),\n                'height': int_or_none(a.find('./frameHeight').text),\n                'vbr': int_or_none(a.find('./bitrateVideo').text),\n                'abr': int_or_none(a.find('./bitrateAudio').text),\n                'vcodec': a.find('./codecVideo').text,\n                'tbr': int_or_none(a.find('./totalBitrate').text),\n            }\n            if a.find('./serverPrefix').text:\n                f['url'] = a.find('./serverPrefix').text\n                f['playpath'] = a.find('./fileName').text\n            else:\n                f['url'] = a.find('./fileName').text\n            formats.append(f)\n        self._sort_formats(formats)\n\n        return {\n            'id': mobj.group('id'),\n            'formats': formats,\n            'display_id': display_id,\n            'title': video_node.find('./title').text,\n            'duration': parse_duration(video_node.find('./duration').text),\n            'upload_date': upload_date,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 154,
        "end_line": 192,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.prosiebensat1.ProSiebenSat1IE._real_extract#182",
        "src_path": "youtube_dl/extractor/prosiebensat1.py",
        "class_name": "youtube_dl.extractor.prosiebensat1.ProSiebenSat1IE",
        "signature": "youtube_dl.extractor.prosiebensat1.ProSiebenSat1IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        page = self._download_webpage(url, video_id, 'Downloading page')\n\n        clip_id = self._html_search_regex(self._CLIPID_REGEXES, page, 'clip id')\n\n        access_token = 'testclient'\n        client_name = 'kolibri-1.2.5'\n        client_location = url\n\n        videos_api_url = 'http://vas.sim-technik.de/vas/live/v2/videos?%s' % compat_urllib_parse.urlencode({\n            'access_token': access_token,\n            'client_location': client_location,\n            'client_name': client_name,\n            'ids': clip_id,\n        })\n\n        videos = self._download_json(videos_api_url, clip_id, 'Downloading videos JSON')\n\n        duration = float(videos[0]['duration'])\n        source_ids = [source['id'] for source in videos[0]['sources']]\n        source_ids_str = ','.join(map(str, source_ids))\n\n        g = '01!8d8F_)r9]4s[qeuXfP%'\n\n        client_id = g[:2] + sha1(''.join([clip_id, g, access_token, client_location, g, client_name])\n                                 .encode('utf-8')).hexdigest()\n\n        sources_api_url = 'http://vas.sim-technik.de/vas/live/v2/videos/%s/sources?%s' % (clip_id, compat_urllib_parse.urlencode({\n            'access_token': access_token,\n            'client_id': client_id,\n            'client_location': client_location,\n            'client_name': client_name,\n        }))\n\n        sources = self._download_json(sources_api_url, clip_id, 'Downloading sources JSON')\n        server_id = sources['server_id']\n\n        client_id = g[:2] + sha1(''.join([g, clip_id, access_token, server_id,\n                                          client_location, source_ids_str, g, client_name])\n                                 .encode('utf-8')).hexdigest()\n\n        url_api_url = 'http://vas.sim-technik.de/vas/live/v2/videos/%s/sources/url?%s' % (clip_id, compat_urllib_parse.urlencode({\n            'access_token': access_token,\n            'client_id': client_id,\n            'client_location': client_location,\n            'client_name': client_name,\n            'server_id': server_id,\n            'source_ids': source_ids_str,\n        }))\n\n        urls = self._download_json(url_api_url, clip_id, 'Downloading urls JSON')\n\n        title = self._html_search_regex(self._TITLE_REGEXES, page, 'title')\n        description = self._html_search_regex(self._DESCRIPTION_REGEXES, page, 'description', fatal=False)\n        thumbnail = self._og_search_thumbnail(page)\n\n        upload_date = unified_strdate(self._html_search_regex(\n            self._UPLOAD_DATE_REGEXES, page, 'upload date', default=None))\n\n        formats = []\n\n        urls_sources = urls['sources']\n        if isinstance(urls_sources, dict):\n            urls_sources = urls_sources.values()\n\n        def fix_bitrate(bitrate):\n            return (bitrate // 1000) if bitrate % 1000 == 0 else bitrate\n\n        for source in urls_sources:\n            protocol = source['protocol']\n            if protocol == 'rtmp' or protocol == 'rtmpe':\n                mobj = re.search(r'^(?P<url>rtmpe?://[^/]+/(?P<app>[^/]+))/(?P<playpath>.+)$', source['url'])\n                if not mobj:\n                    continue\n                formats.append({\n                    'url': mobj.group('url'),\n                    'app': mobj.group('app'),\n                    'play_path': mobj.group('playpath'),\n                    'player_url': 'http://livepassdl.conviva.com/hf/ver/2.79.0.17083/LivePassModuleMain.swf',\n                    'page_url': 'http://www.prosieben.de',\n                    'vbr': fix_bitrate(source['bitrate']),\n                    'ext': 'mp4',\n                    'format_id': '%s_%s' % (source['cdn'], source['bitrate']),\n                })\n            else:\n                formats.append({\n                    'url': source['url'],\n                    'vbr': fix_bitrate(source['bitrate']),\n                })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': clip_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 182,
        "end_line": 285,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0013458950201884253,
            "pseudo_dstar_susp": 0.0010070493454179255,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0010070493454179255,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.tvp.TvpIE._real_extract#22",
        "src_path": "youtube_dl/extractor/tvp.py",
        "class_name": "youtube_dl.extractor.tvp.TvpIE",
        "signature": "youtube_dl.extractor.tvp.TvpIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        json_url = 'http://www.tvp.pl/pub/stat/videofileinfo?video_id=%s' % video_id\n        json_params = self._download_webpage(\n            json_url, video_id, u\"Downloading video metadata\")\n\n        params = json.loads(json_params)\n        self.report_extraction(video_id)\n        video_url = params['video_url']\n\n        title = self._og_search_title(webpage, fatal=True)\n        return {\n            'id': video_id,\n            'title': title,\n            'ext': 'wmv',\n            'url': video_url,\n            'description': self._og_search_description(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n        }",
        "begin_line": 22,
        "end_line": 42,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.vidme.VidmeIE._real_extract#30",
        "src_path": "youtube_dl/extractor/vidme.py",
        "class_name": "youtube_dl.extractor.vidme.VidmeIE",
        "signature": "youtube_dl.extractor.vidme.VidmeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = self._html_search_regex(r'<source src=\"([^\"]+)\"', webpage, 'video URL')\n\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage, default='')\n        thumbnail = self._og_search_thumbnail(webpage)\n        timestamp = int_or_none(self._og_search_property('updated_time', webpage, fatal=False))\n        width = int_or_none(self._og_search_property('video:width', webpage, fatal=False))\n        height = int_or_none(self._og_search_property('video:height', webpage, fatal=False))\n        duration = float_or_none(self._html_search_regex(\n            r'data-duration=\"([^\"]+)\"', webpage, 'duration', fatal=False))\n        view_count = str_to_int(self._html_search_regex(\n            r'<span class=\"video_views\">\\s*([\\d,\\.]+)\\s*plays?', webpage, 'view count', fatal=False))\n        like_count = str_to_int(self._html_search_regex(\n            r'class=\"score js-video-vote-score\"[^>]+data-score=\"([\\d,\\.\\s]+)\">',\n            webpage, 'like count', fatal=False))\n        comment_count = str_to_int(self._html_search_regex(\n            r'class=\"js-comment-count\"[^>]+data-count=\"([\\d,\\.\\s]+)\">',\n            webpage, 'comment count', fatal=False))\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n            'width': width,\n            'height': height,\n            'duration': duration,\n            'view_count': view_count,\n            'like_count': like_count,\n            'comment_count': comment_count,\n        }",
        "begin_line": 30,
        "end_line": 68,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.aol.AolIE._real_extract#42",
        "src_path": "youtube_dl/extractor/aol.py",
        "class_name": "youtube_dl.extractor.aol.AolIE",
        "signature": "youtube_dl.extractor.aol.AolIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        playlist_id = mobj.group('playlist_id')\n        if playlist_id and not self._downloader.params.get('noplaylist'):\n            self.to_screen('Downloading playlist %s - add --no-playlist to just download video %s' % (playlist_id, video_id))\n\n            webpage = self._download_webpage(url, playlist_id)\n            title = self._html_search_regex(\n                r'<h1 class=\"video-title[^\"]*\">(.+?)</h1>', webpage, 'title')\n            playlist_html = self._search_regex(\n                r\"(?s)<ul\\s+class='video-related[^']*'>(.*?)</ul>\", webpage,\n                'playlist HTML')\n            entries = [{\n                '_type': 'url',\n                'url': 'aol-video:%s' % m.group('id'),\n                'ie_key': 'Aol',\n            } for m in re.finditer(\n                r\"<a\\s+href='.*videoid=(?P<id>[0-9]+)'\\s+class='video-thumb'>\",\n                playlist_html)]\n\n            return {\n                '_type': 'playlist',\n                'id': playlist_id,\n                'display_id': mobj.group('playlist_display_id'),\n                'title': title,\n                'entries': entries,\n            }\n\n        return FiveMinIE._build_result(video_id)",
        "begin_line": 42,
        "end_line": 72,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.rbmaradio.RBMARadioIE._real_extract#29",
        "src_path": "youtube_dl/extractor/rbmaradio.py",
        "class_name": "youtube_dl.extractor.rbmaradio.RBMARadioIE",
        "signature": "youtube_dl.extractor.rbmaradio.RBMARadioIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('videoID')\n\n        webpage = self._download_webpage(url, video_id)\n\n        json_data = self._search_regex(r'window\\.gon.*?gon\\.show=(.+?);$',\n            webpage, 'json data', flags=re.MULTILINE)\n\n        try:\n            data = json.loads(json_data)\n        except ValueError as e:\n            raise ExtractorError('Invalid JSON: ' + str(e))\n\n        video_url = data['akamai_url'] + '&cbr=256'\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': data['title'],\n            'description': data.get('teaser_text'),\n            'location': data.get('country_of_origin'),\n            'uploader': data.get('host', {}).get('name'),\n            'uploader_id': data.get('host', {}).get('slug'),\n            'thumbnail': data.get('image', {}).get('large_url_2x'),\n            'duration': data.get('duration'),\n        }",
        "begin_line": 29,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._restore_bytes#57",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._restore_bytes(self, formatted_size)",
        "snippet": "    def _restore_bytes(self, formatted_size):\n        if not formatted_size:\n            return 0\n        m = re.match(r'^(?P<size>\\d+(?:\\.\\d+)?)\\s+(?P<units>[a-zA-Z]+)', formatted_size)\n        if not m:\n            return 0\n        units = m.group('units')\n        try:\n            exponent = ['B', 'KB', 'MB', 'GB', 'TB', 'PB', 'EB', 'ZB', 'YB'].index(units.upper())\n        except ValueError:\n            return 0\n        size = float(m.group('size'))\n        return int(size * (1024 ** exponent))",
        "begin_line": 57,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._formats_from_html#71",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._formats_from_html(self, html)",
        "snippet": "    def _formats_from_html(self, html):\n        FORMAT_REGEX = r'''\n            (?x)\n            <a\\s+href=\"(?P<url>[^\"]+)\">(?P<quality>[^<]+)</a>\\s*\n            <span\\s+class=\"usage\">\\((?P<note>[^\\)]+)\\)</span>\\s*\n            (?:<div\\s+class=\"popup\\s+rounded\">\\s*\n            <h3>File\\s+size</h3>\\s*(?P<filesize>.*?)\\s*\n            </div>)?                                                # File size part may be missing\n        '''\n        # Extract known formats\n        formats = [{\n            'url': x.group('url'),\n            'format_id': x.group('quality'),\n            'format_note': x.group('note'),\n            'format': '%s (%s)' % (x.group('quality'), x.group('note')),\n            'filesize': self._restore_bytes(x.group('filesize')), # File size is approximate\n            'preference': self._known_formats.index(x.group('quality')),\n            'vcodec': 'none' if x.group('note') == 'Audio only' else None,\n        } for x in list(re.finditer(FORMAT_REGEX, html)) if x.group('quality') in self._known_formats]\n\n        self._sort_formats(formats)\n\n        return formats",
        "begin_line": 71,
        "end_line": 93,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_title#95",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_title(self, html)",
        "snippet": "    def _extract_title(self, html):\n        title = self._html_search_meta('title', html, 'title')\n        if title is None:           \n            title = self._og_search_title(html)\n            TITLE_SUFFIX = ' (Channel 9)'\n            if title is not None and title.endswith(TITLE_SUFFIX):\n                title = title[:-len(TITLE_SUFFIX)]\n        return title",
        "begin_line": 95,
        "end_line": 102,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_description#104",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_description(self, html)",
        "snippet": "    def _extract_description(self, html):\n        DESCRIPTION_REGEX = r'''(?sx)\n            <div\\s+class=\"entry-content\">\\s*\n            <div\\s+id=\"entry-body\">\\s*\n            (?P<description>.+?)\\s*\n            </div>\\s*\n            </div>\n        '''\n        m = re.search(DESCRIPTION_REGEX, html)\n        if m is not None:\n            return m.group('description')\n        return self._html_search_meta('description', html, 'description')",
        "begin_line": 104,
        "end_line": 115,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_duration#117",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_duration(self, html)",
        "snippet": "    def _extract_duration(self, html):\n        m = re.search(r'data-video_duration=\"(?P<hours>\\d{2}):(?P<minutes>\\d{2}):(?P<seconds>\\d{2})\"', html)\n        return ((int(m.group('hours')) * 60 * 60) + (int(m.group('minutes')) * 60) + int(m.group('seconds'))) if m else None",
        "begin_line": 117,
        "end_line": 119,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_slides#121",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_slides(self, html)",
        "snippet": "    def _extract_slides(self, html):\n        m = re.search(r'<a href=\"(?P<slidesurl>[^\"]+)\" class=\"slides\">Slides</a>', html)\n        return m.group('slidesurl') if m is not None else None",
        "begin_line": 121,
        "end_line": 123,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_zip#125",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_zip(self, html)",
        "snippet": "    def _extract_zip(self, html):\n        m = re.search(r'<a href=\"(?P<zipurl>[^\"]+)\" class=\"zip\">Zip</a>', html)\n        return m.group('zipurl') if m is not None else None",
        "begin_line": 125,
        "end_line": 127,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_avg_rating#129",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_avg_rating(self, html)",
        "snippet": "    def _extract_avg_rating(self, html):\n        m = re.search(r'<p class=\"avg-rating\">Avg Rating: <span>(?P<avgrating>[^<]+)</span></p>', html)\n        return float(m.group('avgrating')) if m is not None else 0",
        "begin_line": 129,
        "end_line": 131,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_rating_count#133",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_rating_count(self, html)",
        "snippet": "    def _extract_rating_count(self, html):\n        m = re.search(r'<div class=\"rating-count\">\\((?P<ratingcount>[^<]+)\\)</div>', html)\n        return int(self._fix_count(m.group('ratingcount'))) if m is not None else 0",
        "begin_line": 133,
        "end_line": 135,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_view_count#137",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_view_count(self, html)",
        "snippet": "    def _extract_view_count(self, html):\n        m = re.search(r'<li class=\"views\">\\s*<span class=\"count\">(?P<viewcount>[^<]+)</span> Views\\s*</li>', html)\n        return int(self._fix_count(m.group('viewcount'))) if m is not None else 0",
        "begin_line": 137,
        "end_line": 139,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_comment_count#141",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_comment_count(self, html)",
        "snippet": "    def _extract_comment_count(self, html):\n        m = re.search(r'<li class=\"comments\">\\s*<a href=\"#comments\">\\s*<span class=\"count\">(?P<commentcount>[^<]+)</span> Comments\\s*</a>\\s*</li>', html)\n        return int(self._fix_count(m.group('commentcount'))) if m is not None else 0",
        "begin_line": 141,
        "end_line": 143,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._fix_count#145",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._fix_count(self, count)",
        "snippet": "    def _fix_count(self, count):\n        return int(str(count).replace(',', '')) if count is not None else None",
        "begin_line": 145,
        "end_line": 146,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_authors#148",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_authors(self, html)",
        "snippet": "    def _extract_authors(self, html):\n        m = re.search(r'(?s)<li class=\"author\">(.*?)</li>', html)\n        if m is None:\n            return None\n        return re.findall(r'<a href=\"/Niners/[^\"]+\">([^<]+)</a>', m.group(1))",
        "begin_line": 148,
        "end_line": 152,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_session_code#154",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_session_code(self, html)",
        "snippet": "    def _extract_session_code(self, html):\n        m = re.search(r'<li class=\"code\">\\s*(?P<code>.+?)\\s*</li>', html)\n        return m.group('code') if m is not None else None",
        "begin_line": 154,
        "end_line": 156,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_session_day#158",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_session_day(self, html)",
        "snippet": "    def _extract_session_day(self, html):\n        m = re.search(r'<li class=\"day\">\\s*<a href=\"/Events/[^\"]+\">(?P<day>[^<]+)</a>\\s*</li>', html)\n        return m.group('day') if m is not None else None",
        "begin_line": 158,
        "end_line": 160,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_session_room#162",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_session_room(self, html)",
        "snippet": "    def _extract_session_room(self, html):\n        m = re.search(r'<li class=\"room\">\\s*(?P<room>.+?)\\s*</li>', html)\n        return m.group('room') if m is not None else None",
        "begin_line": 162,
        "end_line": 164,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_session_speakers#166",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_session_speakers(self, html)",
        "snippet": "    def _extract_session_speakers(self, html):\n        return re.findall(r'<a href=\"/Events/Speakers/[^\"]+\">([^<]+)</a>', html)",
        "begin_line": 166,
        "end_line": 167,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_content#169",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_content(self, html, content_path)",
        "snippet": "    def _extract_content(self, html, content_path):\n        # Look for downloadable content        \n        formats = self._formats_from_html(html)\n        slides = self._extract_slides(html)\n        zip_ = self._extract_zip(html)\n\n        # Nothing to download\n        if len(formats) == 0 and slides is None and zip_ is None:\n            self._downloader.report_warning('None of recording, slides or zip are available for %s' % content_path)\n            return\n\n        # Extract meta\n        title = self._extract_title(html)\n        description = self._extract_description(html)\n        thumbnail = self._og_search_thumbnail(html)\n        duration = self._extract_duration(html)\n        avg_rating = self._extract_avg_rating(html)\n        rating_count = self._extract_rating_count(html)\n        view_count = self._extract_view_count(html)\n        comment_count = self._extract_comment_count(html)\n\n        common = {'_type': 'video',\n                  'id': content_path,\n                  'description': description,\n                  'thumbnail': thumbnail,\n                  'duration': duration,\n                  'avg_rating': avg_rating,\n                  'rating_count': rating_count,\n                  'view_count': view_count,\n                  'comment_count': comment_count,\n                }\n\n        result = []\n\n        if slides is not None:\n            d = common.copy()\n            d.update({ 'title': title + '-Slides', 'url': slides })\n            result.append(d)\n\n        if zip_ is not None:\n            d = common.copy()\n            d.update({ 'title': title + '-Zip', 'url': zip_ })\n            result.append(d)\n\n        if len(formats) > 0:\n            d = common.copy()\n            d.update({ 'title': title, 'formats': formats })\n            result.append(d)\n\n        return result",
        "begin_line": 169,
        "end_line": 218,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_entry_item#220",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_entry_item(self, html, content_path)",
        "snippet": "    def _extract_entry_item(self, html, content_path):\n        contents = self._extract_content(html, content_path)\n        if contents is None:\n            return contents\n\n        authors = self._extract_authors(html)\n\n        for content in contents:\n            content['authors'] = authors\n\n        return contents",
        "begin_line": 220,
        "end_line": 230,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_session#232",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_session(self, html, content_path)",
        "snippet": "    def _extract_session(self, html, content_path):\n        contents = self._extract_content(html, content_path)\n        if contents is None:\n            return contents\n\n        session_meta = {'session_code': self._extract_session_code(html),\n                        'session_day': self._extract_session_day(html),\n                        'session_room': self._extract_session_room(html),\n                        'session_speakers': self._extract_session_speakers(html),\n                        }\n\n        for content in contents:\n            content.update(session_meta)\n\n        return contents",
        "begin_line": 232,
        "end_line": 246,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_list#248",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_list(self, content_path)",
        "snippet": "    def _extract_list(self, content_path):\n        rss = self._download_xml(self._RSS_URL % content_path, content_path, 'Downloading RSS')\n        entries = [self.url_result(session_url.text, 'Channel9')\n                   for session_url in rss.findall('./channel/item/link')]\n        title_text = rss.find('./channel/title').text\n        return self.playlist_result(entries, content_path, title_text)",
        "begin_line": 248,
        "end_line": 253,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._real_extract#255",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        content_path = mobj.group('contentpath')\n\n        webpage = self._download_webpage(url, content_path, 'Downloading web page')\n\n        page_type_m = re.search(r'<meta name=\"Search.PageType\" content=\"(?P<pagetype>[^\"]+)\"/>', webpage)\n        if page_type_m is None:\n            raise ExtractorError('Search.PageType not found, don\\'t know how to process this page', expected=True)\n\n        page_type = page_type_m.group('pagetype')\n        if page_type == 'List':         # List page, may contain list of 'item'-like objects\n            return self._extract_list(content_path)\n        elif page_type == 'Entry.Item': # Any 'item'-like page, may contain downloadable content\n            return self._extract_entry_item(webpage, content_path)\n        elif page_type == 'Session':    # Event session page, may contain downloadable content\n            return self._extract_session(webpage, content_path)\n        else:\n            raise ExtractorError('Unexpected Search.PageType %s' % page_type, expected=True)",
        "begin_line": 255,
        "end_line": 273,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.hypem.HypemIE._real_extract#29",
        "src_path": "youtube_dl/extractor/hypem.py",
        "class_name": "youtube_dl.extractor.hypem.HypemIE",
        "signature": "youtube_dl.extractor.hypem.HypemIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        track_id = mobj.group(1)\n\n        data = {'ax': 1, 'ts': time.time()}\n        data_encoded = compat_urllib_parse.urlencode(data)\n        complete_url = url + \"?\" + data_encoded\n        request = compat_urllib_request.Request(complete_url)\n        response, urlh = self._download_webpage_handle(\n            request, track_id, 'Downloading webpage with the url')\n        cookie = urlh.headers.get('Set-Cookie', '')\n\n        html_tracks = self._html_search_regex(\n            r'(?ms)<script type=\"application/json\" id=\"displayList-data\">\\s*(.*?)\\s*</script>',\n            response, 'tracks')\n        try:\n            track_list = json.loads(html_tracks)\n            track = track_list['tracks'][0]\n        except ValueError:\n            raise ExtractorError('Hypemachine contained invalid JSON.')\n\n        key = track['key']\n        track_id = track['id']\n        artist = track['artist']\n        title = track['song']\n\n        serve_url = \"http://hypem.com/serve/source/%s/%s\" % (track_id, key)\n        request = compat_urllib_request.Request(\n            serve_url, '', {'Content-Type': 'application/json'})\n        request.add_header('cookie', cookie)\n        song_data = self._download_json(request, track_id, 'Downloading metadata')\n        final_url = song_data[\"url\"]\n\n        return {\n            'id': track_id,\n            'url': final_url,\n            'ext': 'mp3',\n            'title': title,\n            'uploader': artist,\n        }",
        "begin_line": 29,
        "end_line": 68,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.mailru.MailRuIE._real_extract#45",
        "src_path": "youtube_dl/extractor/mailru.py",
        "class_name": "youtube_dl.extractor.mailru.MailRuIE",
        "signature": "youtube_dl.extractor.mailru.MailRuIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('idv1')\n\n        if not video_id:\n            video_id = mobj.group('idv2prefix') + mobj.group('idv2suffix')\n\n        video_data = self._download_json(\n            'http://api.video.mail.ru/videos/%s.json?new=1' % video_id, video_id, 'Downloading video JSON')\n\n        author = video_data['author']\n        uploader = author['name']\n        uploader_id = author['id']\n\n        movie = video_data['movie']\n        content_id = str(movie['contentId'])\n        title = movie['title']\n        if title.endswith('.mp4'):\n            title = title[:-4]\n        thumbnail = movie['poster']\n        duration = movie['duration']\n\n        view_count = video_data['views_count']\n\n        formats = [\n            {\n                'url': video['url'],\n                'format_id': video['name'],\n            } for video in video_data['videos']\n        ]\n\n        return {\n            'id': content_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'timestamp': video_data['timestamp'],\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'duration': duration,\n            'view_count': view_count,\n            'formats': formats,\n        }",
        "begin_line": 45,
        "end_line": 86,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.fktv.FKTVIE._real_extract#26",
        "src_path": "youtube_dl/extractor/fktv.py",
        "class_name": "youtube_dl.extractor.fktv.FKTVIE",
        "signature": "youtube_dl.extractor.fktv.FKTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        episode = int(mobj.group('ep'))\n\n        server = random.randint(2, 4)\n        video_thumbnail = 'http://fernsehkritik.tv/images/magazin/folge%d.jpg' % episode\n        start_webpage = self._download_webpage('http://fernsehkritik.tv/folge-%d/Start' % episode,\n            episode)\n        playlist = self._search_regex(r'playlist = (\\[.*?\\]);', start_webpage,\n            u'playlist', flags=re.DOTALL)\n        files = json.loads(re.sub('{[^{}]*?}', '{}', playlist))\n        # TODO: return a single multipart video\n        videos = []\n        for i, _ in enumerate(files, 1):\n            video_id = '%04d%d' % (episode, i)\n            video_url = 'http://dl%d.fernsehkritik.tv/fernsehkritik%d%s.flv' % (server, episode, '' if i == 1 else '-%d' % i)\n            videos.append({\n                'id': video_id,\n                'url': video_url,\n                'ext': determine_ext(video_url),\n                'title': clean_html(get_element_by_id('eptitle', start_webpage)),\n                'description': clean_html(get_element_by_id('contentlist', start_webpage)),\n                'thumbnail': video_thumbnail\n            })\n        return videos",
        "begin_line": 26,
        "end_line": 50,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.fktv.FKTVPosteckeIE._real_extract#65",
        "src_path": "youtube_dl/extractor/fktv.py",
        "class_name": "youtube_dl.extractor.fktv.FKTVPosteckeIE",
        "signature": "youtube_dl.extractor.fktv.FKTVPosteckeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        episode = int(mobj.group('ep'))\n\n        server = random.randint(2, 4)\n        video_id = '%04d' % episode\n        video_url = 'http://dl%d.fernsehkritik.tv/postecke/postecke%d.flv' % (server, episode)\n        video_title = 'Postecke %d' % episode\n        return {\n            'id':       video_id,\n            'url':      video_url,\n            'ext':      determine_ext(video_url),\n            'title':    video_title,\n        }",
        "begin_line": 65,
        "end_line": 78,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.streamcz.StreamCZIE._real_extract#41",
        "src_path": "youtube_dl/extractor/streamcz.py",
        "class_name": "youtube_dl.extractor.streamcz.StreamCZIE",
        "signature": "youtube_dl.extractor.streamcz.StreamCZIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n\n        webpage = self._download_webpage(url, video_id)\n\n        data = self._html_search_regex(r'Stream\\.Data\\.Episode\\((.+?)\\);', webpage, 'stream data')\n\n        jsonData = json.loads(data)\n\n        formats = []\n        for video in jsonData['instances']:\n            for video_format in video['instances']:\n                format_id = video_format['quality']\n\n                if format_id == '240p':\n                    quality = 0\n                elif format_id == '360p':\n                    quality = 1\n                elif format_id == '480p':\n                    quality = 2\n                elif format_id == '720p':\n                    quality = 3\n\n                formats.append({\n                    'format_id': '%s-%s' % (video_format['type'].split('/')[1], format_id),\n                    'url': video_format['source'],\n                    'quality': quality,\n                })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': compat_str(jsonData['episode_id']),\n            'title': self._og_search_title(webpage),\n            'thumbnail': jsonData['episode_image_original_url'].replace('//', 'http://'),\n            'formats': formats,\n            'description': self._og_search_description(webpage),\n            'duration': int_or_none(jsonData['duration']),\n            'view_count': int_or_none(jsonData['stats_total']),\n        }",
        "begin_line": 41,
        "end_line": 81,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.telemb.TeleMBIE._real_extract#40",
        "src_path": "youtube_dl/extractor/telemb.py",
        "class_name": "youtube_dl.extractor.telemb.TeleMBIE",
        "signature": "youtube_dl.extractor.telemb.TeleMBIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        formats = []\n        for video_url in re.findall(r'file\\s*:\\s*\"([^\"]+)\"', webpage):\n            fmt = {\n                'url': video_url,\n                'format_id': video_url.split(':')[0]\n            }\n            rtmp = re.search(r'^(?P<url>rtmp://[^/]+/(?P<app>.+))/(?P<playpath>mp4:.+)$', video_url)\n            if rtmp:\n                fmt.update({\n                    'play_path': rtmp.group('playpath'),\n                    'app': rtmp.group('app'),\n                    'player_url': 'http://p.jwpcdn.com/6/10/jwplayer.flash.swf',\n                    'page_url': 'http://www.telemb.be',\n                    'preference': -1,\n                })\n            formats.append(fmt)\n        self._sort_formats(formats)\n\n        title = remove_start(self._og_search_title(webpage), 'T\u00e9l\u00e9MB : ')\n        description = self._html_search_regex(\n            r'<meta property=\"og:description\" content=\"(.+?)\" />',\n            webpage, 'description', fatal=False)\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 40,
        "end_line": 78,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.br.BRIE._real_extract#68",
        "src_path": "youtube_dl/extractor/br.py",
        "class_name": "youtube_dl.extractor.br.BRIE",
        "signature": "youtube_dl.extractor.br.BRIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('id')\n        page = self._download_webpage(url, display_id)\n        xml_url = self._search_regex(\n            r\"return BRavFramework\\.register\\(BRavFramework\\('avPlayer_(?:[a-f0-9-]{36})'\\)\\.setup\\({dataURL:'(/(?:[a-z0-9\\-]+/)+[a-z0-9/~_.-]+)'}\\)\\);\", page, 'XMLURL')\n        xml = self._download_xml(self._BASE_URL + xml_url, None)\n\n        medias = []\n\n        for xml_media in xml.findall('video') + xml.findall('audio'):\n            media = {\n                'id': xml_media.get('externalId'),\n                'title': xml_media.find('title').text,\n                'duration': parse_duration(xml_media.find('duration').text),\n                'formats': self._extract_formats(xml_media.find('assets')),\n                'thumbnails': self._extract_thumbnails(xml_media.find('teaserImage/variants')),\n                'description': ' '.join(xml_media.find('shareTitle').text.splitlines()),\n                'webpage_url': xml_media.find('permalink').text\n            }\n            if xml_media.find('author').text:\n                media['uploader'] = xml_media.find('author').text\n            if xml_media.find('broadcastDate').text:\n                media['upload_date'] = ''.join(reversed(xml_media.find('broadcastDate').text.split('.')))\n            medias.append(media)\n\n        if len(medias) > 1:\n            self._downloader.report_warning(\n                'found multiple medias; please '\n                'report this with the video URL to http://yt-dl.org/bug')\n        if not medias:\n            raise ExtractorError('No media entries found')\n        return medias[0]",
        "begin_line": 68,
        "end_line": 100,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009000900090009,
            "pseudo_dstar_susp": 0.0006983240223463687,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006983240223463687,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.br.BRIE._extract_formats#102",
        "src_path": "youtube_dl/extractor/br.py",
        "class_name": "youtube_dl.extractor.br.BRIE",
        "signature": "youtube_dl.extractor.br.BRIE._extract_formats(self, assets)",
        "snippet": "    def _extract_formats(self, assets):\n\n        def text_or_none(asset, tag):\n            elem = asset.find(tag)\n            return None if elem is None else elem.text\n\n        formats = [{\n            'url': text_or_none(asset, 'downloadUrl'),\n            'ext': text_or_none(asset, 'mediaType'),\n            'format_id': asset.get('type'),\n            'width': int_or_none(text_or_none(asset, 'frameWidth')),\n            'height': int_or_none(text_or_none(asset, 'frameHeight')),\n            'tbr': int_or_none(text_or_none(asset, 'bitrateVideo')),\n            'abr': int_or_none(text_or_none(asset, 'bitrateAudio')),\n            'vcodec': text_or_none(asset, 'codecVideo'),\n            'acodec': text_or_none(asset, 'codecAudio'),\n            'container': text_or_none(asset, 'mediaType'),\n            'filesize': int_or_none(text_or_none(asset, 'size')),\n        } for asset in assets.findall('asset')\n            if asset.find('downloadUrl') is not None]\n\n        self._sort_formats(formats)\n        return formats",
        "begin_line": 102,
        "end_line": 124,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009000900090009,
            "pseudo_dstar_susp": 0.0006983240223463687,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006983240223463687,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.br.BRIE.text_or_none#104",
        "src_path": "youtube_dl/extractor/br.py",
        "class_name": "youtube_dl.extractor.br.BRIE",
        "signature": "youtube_dl.extractor.br.BRIE.text_or_none(asset, tag)",
        "snippet": "        def text_or_none(asset, tag):\n            elem = asset.find(tag)\n            return None if elem is None else elem.text",
        "begin_line": 104,
        "end_line": 106,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009000900090009,
            "pseudo_dstar_susp": 0.0006983240223463687,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006983240223463687,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.br.BRIE._extract_thumbnails#126",
        "src_path": "youtube_dl/extractor/br.py",
        "class_name": "youtube_dl.extractor.br.BRIE",
        "signature": "youtube_dl.extractor.br.BRIE._extract_thumbnails(self, variants)",
        "snippet": "    def _extract_thumbnails(self, variants):\n        thumbnails = [{\n            'url': self._BASE_URL + variant.find('url').text,\n            'width': int_or_none(variant.find('width').text),\n            'height': int_or_none(variant.find('height').text),\n        } for variant in variants.findall('variant')]\n        thumbnails.sort(key=lambda x: x['width'] * x['height'], reverse=True)\n        return thumbnails",
        "begin_line": 126,
        "end_line": 133,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009000900090009,
            "pseudo_dstar_susp": 0.0006983240223463687,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006983240223463687,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.teachertube.TeacherTubeIE._real_extract#59",
        "src_path": "youtube_dl/extractor/teachertube.py",
        "class_name": "youtube_dl.extractor.teachertube.TeacherTubeIE",
        "signature": "youtube_dl.extractor.teachertube.TeacherTubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_meta('title', webpage, 'title', fatal=True)\n        TITLE_SUFFIX = ' - TeacherTube'\n        if title.endswith(TITLE_SUFFIX):\n            title = title[:-len(TITLE_SUFFIX)].strip()\n\n        description = self._html_search_meta('description', webpage, 'description')\n        if description:\n            description = description.strip()\n\n        quality = qualities(['mp3', 'flv', 'mp4'])\n\n        media_urls = re.findall(r'data-contenturl=\"([^\"]+)\"', webpage)\n        media_urls.extend(re.findall(r'var\\s+filePath\\s*=\\s*\"([^\"]+)\"', webpage))\n        media_urls.extend(re.findall(r'\\'file\\'\\s*:\\s*[\"\\']([^\"\\']+)[\"\\'],', webpage))\n\n        formats = [\n            {\n                'url': media_url,\n                'quality': quality(determine_ext(media_url))\n            } for media_url in set(media_urls)\n        ]\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': self._html_search_regex(r'\\'image\\'\\s*:\\s*[\"\\']([^\"\\']+)[\"\\']', webpage, 'thumbnail'),\n            'formats': formats,\n            'description': description,\n        }",
        "begin_line": 59,
        "end_line": 95,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009000900090009,
            "pseudo_dstar_susp": 0.0006983240223463687,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006983240223463687,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.teachertube.TeacherTubeUserIE._real_extract#117",
        "src_path": "youtube_dl/extractor/teachertube.py",
        "class_name": "youtube_dl.extractor.teachertube.TeacherTubeUserIE",
        "signature": "youtube_dl.extractor.teachertube.TeacherTubeUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        user_id = mobj.group('user')\n\n        urls = []\n        webpage = self._download_webpage(url, user_id)\n        urls.extend(re.findall(self._MEDIA_RE, webpage))\n        \n        pages = re.findall(r'/ajax-user/user-videos/%s\\?page=([0-9]+)' % user_id, webpage)[:-1]\n        for p in pages:\n            more = 'http://www.teachertube.com/ajax-user/user-videos/%s?page=%s' % (user_id, p)\n            webpage = self._download_webpage(more, user_id, 'Downloading page %s/%s' % (p, len(pages)))\n            video_urls = re.findall(self._MEDIA_RE, webpage)\n            urls.extend(video_urls)\n\n        entries = [self.url_result(vurl, 'TeacherTube') for vurl in urls]\n        return self.playlist_result(entries, user_id)",
        "begin_line": 117,
        "end_line": 133,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.ro220.Ro220IE._real_extract#25",
        "src_path": "youtube_dl/extractor/ro220.py",
        "class_name": "youtube_dl.extractor.ro220.Ro220IE",
        "signature": "youtube_dl.extractor.ro220.Ro220IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('video_id')\n\n        webpage = self._download_webpage(url, video_id)\n        flashVars_str = self._search_regex(\n            r'<param name=\"flashVars\" value=\"([^\"]+)\"',\n            webpage, 'flashVars')\n        flashVars = compat_parse_qs(flashVars_str)\n\n        return {\n            '_type': 'video',\n            'id': video_id,\n            'ext': 'mp4',\n            'url': flashVars['videoURL'][0],\n            'title': flashVars['title'][0],\n            'description': clean_html(flashVars['desc'][0]),\n            'thumbnail': flashVars['preview'][0],\n        }",
        "begin_line": 25,
        "end_line": 43,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.dfb.DFBIE._real_extract#23",
        "src_path": "youtube_dl/extractor/dfb.py",
        "class_name": "youtube_dl.extractor.dfb.DFBIE",
        "signature": "youtube_dl.extractor.dfb.DFBIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        player_info = self._download_xml(\n            'http://tv.dfb.de/server/hd_video.php?play=%s' % video_id,\n            video_id)\n        video_info = player_info.find('video')\n\n        f4m_info = self._download_xml(self._proto_relative_url(video_info.find('url').text.strip()), video_id)\n        token_el = f4m_info.find('token')\n        manifest_url = token_el.attrib['url'] + '?' + 'hdnea=' + token_el.attrib['auth'] + '&hdcore=3.2.0'\n\n        return {\n            'id': video_id,\n            'title': video_info.find('title').text,\n            'url': manifest_url,\n            'ext': 'flv',\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'upload_date': ''.join(video_info.find('time_date').text.split('.')[::-1]),\n        }",
        "begin_line": 23,
        "end_line": 44,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.khanacademy.KhanAcademyIE._real_extract#37",
        "src_path": "youtube_dl/extractor/khanacademy.py",
        "class_name": "youtube_dl.extractor.khanacademy.KhanAcademyIE",
        "signature": "youtube_dl.extractor.khanacademy.KhanAcademyIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('id')\n\n        if m.group('key') == 'video':\n            data = self._download_json(\n                'http://api.khanacademy.org/api/v1/videos/' + video_id,\n                video_id, 'Downloading video info')\n\n            upload_date = unified_strdate(data['date_added'])\n            uploader = ', '.join(data['author_names'])\n            return {\n                '_type': 'url_transparent',\n                'url': data['url'],\n                'id': video_id,\n                'title': data['title'],\n                'thumbnail': data['image_url'],\n                'duration': data['duration'],\n                'description': data['description'],\n                'uploader': uploader,\n                'upload_date': upload_date,\n            }\n        else:\n            # topic\n            data = self._download_json(\n                'http://api.khanacademy.org/api/v1/topic/' + video_id,\n                video_id, 'Downloading topic info')\n\n            entries = [\n                {\n                    '_type': 'url',\n                    'url': c['url'],\n                    'id': c['id'],\n                    'title': c['title'],\n                }\n                for c in data['children'] if c['kind'] in ('Video', 'Topic')]\n\n            return {\n                '_type': 'playlist',\n                'id': video_id,\n                'title': data['title'],\n                'description': data['description'],\n                'entries': entries,\n            }",
        "begin_line": 37,
        "end_line": 80,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.swfinterp._extract_tags#14",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp",
        "signature": "youtube_dl.swfinterp._extract_tags(file_contents)",
        "snippet": "def _extract_tags(file_contents):\n    if file_contents[1:3] != b'WS':\n        raise ExtractorError(\n            'Not an SWF file; header is %r' % file_contents[:3])\n    if file_contents[:1] == b'C':\n        content = zlib.decompress(file_contents[8:])\n    else:\n        raise NotImplementedError(\n            'Unsupported compression format %r' %\n            file_contents[:1])\n\n    # Determine number of bits in framesize rectangle\n    framesize_nbits = struct_unpack('!B', content[:1])[0] >> 3\n    framesize_len = (5 + 4 * framesize_nbits + 7) // 8\n\n    pos = framesize_len + 2 + 2\n    while pos < len(content):\n        header16 = struct_unpack('<H', content[pos:pos + 2])[0]\n        pos += 2\n        tag_code = header16 >> 6\n        tag_len = header16 & 0x3f\n        if tag_len == 0x3f:\n            tag_len = struct_unpack('<I', content[pos:pos + 4])[0]\n            pos += 4\n        assert pos + tag_len <= len(content), \\\n            ('Tag %d ends at %d+%d - that\\'s longer than the file (%d)'\n                % (tag_code, pos, tag_len, len(content)))\n        yield (tag_code, content[pos:pos + tag_len])\n        pos += tag_len",
        "begin_line": 14,
        "end_line": 42,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.swfinterp._AVMClass_Object.__init__#46",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._AVMClass_Object",
        "signature": "youtube_dl.swfinterp._AVMClass_Object.__init__(self, avm_class)",
        "snippet": "    def __init__(self, avm_class):\n        self.avm_class = avm_class",
        "begin_line": 46,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.swfinterp._AVMClass_Object.__repr__#49",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._AVMClass_Object",
        "signature": "youtube_dl.swfinterp._AVMClass_Object.__repr__(self)",
        "snippet": "    def __repr__(self):\n        return '%s#%x' % (self.avm_class.name, id(self))",
        "begin_line": 49,
        "end_line": 50,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.swfinterp._ScopeDict.__init__#54",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._ScopeDict",
        "signature": "youtube_dl.swfinterp._ScopeDict.__init__(self, avm_class)",
        "snippet": "    def __init__(self, avm_class):\n        super(_ScopeDict, self).__init__()\n        self.avm_class = avm_class",
        "begin_line": 54,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.swfinterp._ScopeDict.__repr__#58",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._ScopeDict",
        "signature": "youtube_dl.swfinterp._ScopeDict.__repr__(self)",
        "snippet": "    def __repr__(self):\n        return '%s__Scope(%s)' % (\n            self.avm_class.name,\n            super(_ScopeDict, self).__repr__())",
        "begin_line": 58,
        "end_line": 61,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.swfinterp._AVMClass.__init__#65",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._AVMClass",
        "signature": "youtube_dl.swfinterp._AVMClass.__init__(self, name_idx, name)",
        "snippet": "    def __init__(self, name_idx, name):\n        self.name_idx = name_idx\n        self.name = name\n        self.method_names = {}\n        self.method_idxs = {}\n        self.methods = {}\n        self.method_pyfunctions = {}\n\n        self.variables = _ScopeDict(self)",
        "begin_line": 65,
        "end_line": 73,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.swfinterp._AVMClass.make_object#75",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._AVMClass",
        "signature": "youtube_dl.swfinterp._AVMClass.make_object(self)",
        "snippet": "    def make_object(self):\n        return _AVMClass_Object(self)",
        "begin_line": 75,
        "end_line": 76,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.swfinterp._AVMClass.__repr__#78",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._AVMClass",
        "signature": "youtube_dl.swfinterp._AVMClass.__repr__(self)",
        "snippet": "    def __repr__(self):\n        return '_AVMClass(%s)' % (self.name)",
        "begin_line": 78,
        "end_line": 79,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.swfinterp._AVMClass.register_methods#81",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._AVMClass",
        "signature": "youtube_dl.swfinterp._AVMClass.register_methods(self, methods)",
        "snippet": "    def register_methods(self, methods):\n        self.method_names.update(methods.items())\n        self.method_idxs.update(dict(\n            (idx, name)\n            for name, idx in methods.items()))",
        "begin_line": 81,
        "end_line": 85,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.swfinterp._Multiname.__init__#89",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._Multiname",
        "signature": "youtube_dl.swfinterp._Multiname.__init__(self, kind)",
        "snippet": "    def __init__(self, kind):\n        self.kind = kind",
        "begin_line": 89,
        "end_line": 90,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.swfinterp._Multiname.__repr__#92",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp._Multiname",
        "signature": "youtube_dl.swfinterp._Multiname.__repr__(self)",
        "snippet": "    def __repr__(self):\n        return '[MULTINAME kind: 0x%x]' % self.kind",
        "begin_line": 92,
        "end_line": 93,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.swfinterp._read_int#96",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp",
        "signature": "youtube_dl.swfinterp._read_int(reader)",
        "snippet": "def _read_int(reader):\n    res = 0\n    shift = 0\n    for _ in range(5):\n        buf = reader.read(1)\n        assert len(buf) == 1\n        b = struct_unpack('<B', buf)[0]\n        res = res | ((b & 0x7f) << shift)\n        if b & 0x80 == 0:\n            break\n        shift += 7\n    return res",
        "begin_line": 96,
        "end_line": 107,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.swfinterp._u30#110",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp",
        "signature": "youtube_dl.swfinterp._u30(reader)",
        "snippet": "def _u30(reader):\n    res = _read_int(reader)\n    assert res & 0xf0000000 == 0\n    return res",
        "begin_line": 110,
        "end_line": 113,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.swfinterp._s32#117",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp",
        "signature": "youtube_dl.swfinterp._s32(reader)",
        "snippet": "def _s32(reader):\n    v = _read_int(reader)\n    if v & 0x80000000 != 0:\n        v = - ((v ^ 0xffffffff) + 1)\n    return v",
        "begin_line": 117,
        "end_line": 121,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.swfinterp._s24#124",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp",
        "signature": "youtube_dl.swfinterp._s24(reader)",
        "snippet": "def _s24(reader):\n    bs = reader.read(3)\n    assert len(bs) == 3\n    last_byte = b'\\xff' if (ord(bs[2:3]) >= 0x80) else b'\\x00'\n    return struct_unpack('<i', bs + last_byte)[0]",
        "begin_line": 124,
        "end_line": 128,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.swfinterp._read_string#131",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp",
        "signature": "youtube_dl.swfinterp._read_string(reader)",
        "snippet": "def _read_string(reader):\n    slen = _u30(reader)\n    resb = reader.read(slen)\n    assert len(resb) == slen\n    return resb.decode('utf-8')",
        "begin_line": 131,
        "end_line": 135,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.swfinterp._read_bytes#138",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp",
        "signature": "youtube_dl.swfinterp._read_bytes(count, reader)",
        "snippet": "def _read_bytes(count, reader):\n    assert count >= 0\n    resb = reader.read(count)\n    assert len(resb) == count\n    return resb",
        "begin_line": 138,
        "end_line": 142,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.swfinterp._read_byte#145",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp",
        "signature": "youtube_dl.swfinterp._read_byte(reader)",
        "snippet": "def _read_byte(reader):\n    resb = _read_bytes(1, reader=reader)\n    res = struct_unpack('<B', resb)[0]\n    return res",
        "begin_line": 145,
        "end_line": 148,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.swfinterp.SWFInterpreter.__init__#152",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp.SWFInterpreter",
        "signature": "youtube_dl.swfinterp.SWFInterpreter.__init__(self, file_contents)",
        "snippet": "    def __init__(self, file_contents):\n        code_tag = next(tag\n                        for tag_code, tag in _extract_tags(file_contents)\n                        if tag_code == 82)\n        p = code_tag.index(b'\\0', 4) + 1\n        code_reader = io.BytesIO(code_tag[p:])\n\n        # Parse ABC (AVM2 ByteCode)\n\n        # Define a couple convenience methods\n        u30 = lambda *args: _u30(*args, reader=code_reader)\n        s32 = lambda *args: _s32(*args, reader=code_reader)\n        u32 = lambda *args: _u32(*args, reader=code_reader)\n        read_bytes = lambda *args: _read_bytes(*args, reader=code_reader)\n        read_byte = lambda *args: _read_byte(*args, reader=code_reader)\n\n        # minor_version + major_version\n        read_bytes(2 + 2)\n\n        # Constant pool\n        int_count = u30()\n        for _c in range(1, int_count):\n            s32()\n        uint_count = u30()\n        for _c in range(1, uint_count):\n            u32()\n        double_count = u30()\n        read_bytes(max(0, (double_count - 1)) * 8)\n        string_count = u30()\n        self.constant_strings = ['']\n        for _c in range(1, string_count):\n            s = _read_string(code_reader)\n            self.constant_strings.append(s)\n        namespace_count = u30()\n        for _c in range(1, namespace_count):\n            read_bytes(1)  # kind\n            u30()  # name\n        ns_set_count = u30()\n        for _c in range(1, ns_set_count):\n            count = u30()\n            for _c2 in range(count):\n                u30()\n        multiname_count = u30()\n        MULTINAME_SIZES = {\n            0x07: 2,  # QName\n            0x0d: 2,  # QNameA\n            0x0f: 1,  # RTQName\n            0x10: 1,  # RTQNameA\n            0x11: 0,  # RTQNameL\n            0x12: 0,  # RTQNameLA\n            0x09: 2,  # Multiname\n            0x0e: 2,  # MultinameA\n            0x1b: 1,  # MultinameL\n            0x1c: 1,  # MultinameLA\n        }\n        self.multinames = ['']\n        for _c in range(1, multiname_count):\n            kind = u30()\n            assert kind in MULTINAME_SIZES, 'Invalid multiname kind %r' % kind\n            if kind == 0x07:\n                u30()  # namespace_idx\n                name_idx = u30()\n                self.multinames.append(self.constant_strings[name_idx])\n            else:\n                self.multinames.append(_Multiname(kind))\n                for _c2 in range(MULTINAME_SIZES[kind]):\n                    u30()\n\n        # Methods\n        method_count = u30()\n        MethodInfo = collections.namedtuple(\n            'MethodInfo',\n            ['NEED_ARGUMENTS', 'NEED_REST'])\n        method_infos = []\n        for method_id in range(method_count):\n            param_count = u30()\n            u30()  # return type\n            for _ in range(param_count):\n                u30()  # param type\n            u30()  # name index (always 0 for youtube)\n            flags = read_byte()\n            if flags & 0x08 != 0:\n                # Options present\n                option_count = u30()\n                for c in range(option_count):\n                    u30()  # val\n                    read_bytes(1)  # kind\n            if flags & 0x80 != 0:\n                # Param names present\n                for _ in range(param_count):\n                    u30()  # param name\n            mi = MethodInfo(flags & 0x01 != 0, flags & 0x04 != 0)\n            method_infos.append(mi)\n\n        # Metadata\n        metadata_count = u30()\n        for _c in range(metadata_count):\n            u30()  # name\n            item_count = u30()\n            for _c2 in range(item_count):\n                u30()  # key\n                u30()  # value\n\n        def parse_traits_info():\n            trait_name_idx = u30()\n            kind_full = read_byte()\n            kind = kind_full & 0x0f\n            attrs = kind_full >> 4\n            methods = {}\n            if kind in [0x00, 0x06]:  # Slot or Const\n                u30()  # Slot id\n                u30()  # type_name_idx\n                vindex = u30()\n                if vindex != 0:\n                    read_byte()  # vkind\n            elif kind in [0x01, 0x02, 0x03]:  # Method / Getter / Setter\n                u30()  # disp_id\n                method_idx = u30()\n                methods[self.multinames[trait_name_idx]] = method_idx\n            elif kind == 0x04:  # Class\n                u30()  # slot_id\n                u30()  # classi\n            elif kind == 0x05:  # Function\n                u30()  # slot_id\n                function_idx = u30()\n                methods[function_idx] = self.multinames[trait_name_idx]\n            else:\n                raise ExtractorError('Unsupported trait kind %d' % kind)\n\n            if attrs & 0x4 != 0:  # Metadata present\n                metadata_count = u30()\n                for _c3 in range(metadata_count):\n                    u30()  # metadata index\n\n            return methods\n\n        # Classes\n        class_count = u30()\n        classes = []\n        for class_id in range(class_count):\n            name_idx = u30()\n\n            cname = self.multinames[name_idx]\n            avm_class = _AVMClass(name_idx, cname)\n            classes.append(avm_class)\n\n            u30()  # super_name idx\n            flags = read_byte()\n            if flags & 0x08 != 0:  # Protected namespace is present\n                u30()  # protected_ns_idx\n            intrf_count = u30()\n            for _c2 in range(intrf_count):\n                u30()\n            u30()  # iinit\n            trait_count = u30()\n            for _c2 in range(trait_count):\n                trait_methods = parse_traits_info()\n                avm_class.register_methods(trait_methods)\n\n        assert len(classes) == class_count\n        self._classes_by_name = dict((c.name, c) for c in classes)\n\n        for avm_class in classes:\n            u30()  # cinit\n            trait_count = u30()\n            for _c2 in range(trait_count):\n                trait_methods = parse_traits_info()\n                avm_class.register_methods(trait_methods)\n\n        # Scripts\n        script_count = u30()\n        for _c in range(script_count):\n            u30()  # init\n            trait_count = u30()\n            for _c2 in range(trait_count):\n                parse_traits_info()\n\n        # Method bodies\n        method_body_count = u30()\n        Method = collections.namedtuple('Method', ['code', 'local_count'])\n        for _c in range(method_body_count):\n            method_idx = u30()\n            u30()  # max_stack\n            local_count = u30()\n            u30()  # init_scope_depth\n            u30()  # max_scope_depth\n            code_length = u30()\n            code = read_bytes(code_length)\n            for avm_class in classes:\n                if method_idx in avm_class.method_idxs:\n                    m = Method(code, local_count)\n                    avm_class.methods[avm_class.method_idxs[method_idx]] = m\n            exception_count = u30()\n            for _c2 in range(exception_count):\n                u30()  # from\n                u30()  # to\n                u30()  # target\n                u30()  # exc_type\n                u30()  # var_name\n            trait_count = u30()\n            for _c2 in range(trait_count):\n                parse_traits_info()\n\n        assert p + code_reader.tell() == len(code_tag)",
        "begin_line": 152,
        "end_line": 355,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009000900090009,
            "pseudo_dstar_susp": 0.0006983240223463687,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006983240223463687,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.swfinterp.SWFInterpreter.extract_class#357",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp.SWFInterpreter",
        "signature": "youtube_dl.swfinterp.SWFInterpreter.extract_class(self, class_name)",
        "snippet": "    def extract_class(self, class_name):\n        try:\n            return self._classes_by_name[class_name]\n        except KeyError:\n            raise ExtractorError('Class %r not found' % class_name)",
        "begin_line": 357,
        "end_line": 361,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.swfinterp.SWFInterpreter.extract_function#363",
        "src_path": "youtube_dl/swfinterp.py",
        "class_name": "youtube_dl.swfinterp.SWFInterpreter",
        "signature": "youtube_dl.swfinterp.SWFInterpreter.extract_function(self, avm_class, func_name)",
        "snippet": "    def extract_function(self, avm_class, func_name):\n        if func_name in avm_class.method_pyfunctions:\n            return avm_class.method_pyfunctions[func_name]\n        if func_name in self._classes_by_name:\n            return self._classes_by_name[func_name].make_object()\n        if func_name not in avm_class.methods:\n            raise ExtractorError('Cannot find function %s.%s' % (\n                avm_class.name, func_name))\n        m = avm_class.methods[func_name]\n\n        def resfunc(args):\n            # Helper functions\n            coder = io.BytesIO(m.code)\n            s24 = lambda: _s24(coder)\n            u30 = lambda: _u30(coder)\n\n            registers = [avm_class.variables] + list(args) + [None] * m.local_count\n            stack = []\n            scopes = collections.deque([\n                self._classes_by_name, avm_class.variables])\n            while True:\n                opcode = _read_byte(coder)\n                if opcode == 17:  # iftrue\n                    offset = s24()\n                    value = stack.pop()\n                    if value:\n                        coder.seek(coder.tell() + offset)\n                elif opcode == 18:  # iffalse\n                    offset = s24()\n                    value = stack.pop()\n                    if not value:\n                        coder.seek(coder.tell() + offset)\n                elif opcode == 36:  # pushbyte\n                    v = _read_byte(coder)\n                    stack.append(v)\n                elif opcode == 42:  # dup\n                    value = stack[-1]\n                    stack.append(value)\n                elif opcode == 44:  # pushstring\n                    idx = u30()\n                    stack.append(self.constant_strings[idx])\n                elif opcode == 48:  # pushscope\n                    new_scope = stack.pop()\n                    scopes.append(new_scope)\n                elif opcode == 66:  # construct\n                    arg_count = u30()\n                    args = list(reversed(\n                        [stack.pop() for _ in range(arg_count)]))\n                    obj = stack.pop()\n                    res = obj.avm_class.make_object()\n                    stack.append(res)\n                elif opcode == 70:  # callproperty\n                    index = u30()\n                    mname = self.multinames[index]\n                    arg_count = u30()\n                    args = list(reversed(\n                        [stack.pop() for _ in range(arg_count)]))\n                    obj = stack.pop()\n\n                    if isinstance(obj, _AVMClass_Object):\n                        func = self.extract_function(obj.avm_class, mname)\n                        res = func(args)\n                        stack.append(res)\n                        continue\n                    elif isinstance(obj, _ScopeDict):\n                        if mname in obj.avm_class.method_names:\n                            func = self.extract_function(obj.avm_class, mname)\n                            res = func(args)\n                        else:\n                            res = obj[mname]\n                        stack.append(res)\n                        continue\n                    elif isinstance(obj, compat_str):\n                        if mname == 'split':\n                            assert len(args) == 1\n                            assert isinstance(args[0], compat_str)\n                            if args[0] == '':\n                                res = list(obj)\n                            else:\n                                res = obj.split(args[0])\n                            stack.append(res)\n                            continue\n                    elif isinstance(obj, list):\n                        if mname == 'slice':\n                            assert len(args) == 1\n                            assert isinstance(args[0], int)\n                            res = obj[args[0]:]\n                            stack.append(res)\n                            continue\n                        elif mname == 'join':\n                            assert len(args) == 1\n                            assert isinstance(args[0], compat_str)\n                            res = args[0].join(obj)\n                            stack.append(res)\n                            continue\n                    raise NotImplementedError(\n                        'Unsupported property %r on %r'\n                        % (mname, obj))\n                elif opcode == 72:  # returnvalue\n                    res = stack.pop()\n                    return res\n                elif opcode == 74:  # constructproperty\n                    index = u30()\n                    arg_count = u30()\n                    args = list(reversed(\n                        [stack.pop() for _ in range(arg_count)]))\n                    obj = stack.pop()\n\n                    mname = self.multinames[index]\n                    assert isinstance(obj, _AVMClass)\n\n                    # We do not actually call the constructor for now;\n                    # we just pretend it does nothing\n                    stack.append(obj.make_object())\n                elif opcode == 79:  # callpropvoid\n                    index = u30()\n                    mname = self.multinames[index]\n                    arg_count = u30()\n                    args = list(reversed(\n                        [stack.pop() for _ in range(arg_count)]))\n                    obj = stack.pop()\n                    if mname == 'reverse':\n                        assert isinstance(obj, list)\n                        obj.reverse()\n                    else:\n                        raise NotImplementedError(\n                            'Unsupported (void) property %r on %r'\n                            % (mname, obj))\n                elif opcode == 86:  # newarray\n                    arg_count = u30()\n                    arr = []\n                    for i in range(arg_count):\n                        arr.append(stack.pop())\n                    arr = arr[::-1]\n                    stack.append(arr)\n                elif opcode == 93:  # findpropstrict\n                    index = u30()\n                    mname = self.multinames[index]\n                    for s in reversed(scopes):\n                        if mname in s:\n                            res = s\n                            break\n                    else:\n                        res = scopes[0]\n                    stack.append(res[mname])\n                elif opcode == 94:  # findproperty\n                    index = u30()\n                    mname = self.multinames[index]\n                    for s in reversed(scopes):\n                        if mname in s:\n                            res = s\n                            break\n                    else:\n                        res = avm_class.variables\n                    stack.append(res)\n                elif opcode == 96:  # getlex\n                    index = u30()\n                    mname = self.multinames[index]\n                    for s in reversed(scopes):\n                        if mname in s:\n                            scope = s\n                            break\n                    else:\n                        scope = avm_class.variables\n                    # I cannot find where static variables are initialized\n                    # so let's just return None\n                    res = scope.get(mname)\n                    stack.append(res)\n                elif opcode == 97:  # setproperty\n                    index = u30()\n                    value = stack.pop()\n                    idx = self.multinames[index]\n                    if isinstance(idx, _Multiname):\n                        idx = stack.pop()\n                    obj = stack.pop()\n                    obj[idx] = value\n                elif opcode == 98:  # getlocal\n                    index = u30()\n                    stack.append(registers[index])\n                elif opcode == 99:  # setlocal\n                    index = u30()\n                    value = stack.pop()\n                    registers[index] = value\n                elif opcode == 102:  # getproperty\n                    index = u30()\n                    pname = self.multinames[index]\n                    if pname == 'length':\n                        obj = stack.pop()\n                        assert isinstance(obj, list)\n                        stack.append(len(obj))\n                    else:  # Assume attribute access\n                        idx = stack.pop()\n                        assert isinstance(idx, int)\n                        obj = stack.pop()\n                        assert isinstance(obj, list)\n                        stack.append(obj[idx])\n                elif opcode == 115:  # convert_\n                    value = stack.pop()\n                    intvalue = int(value)\n                    stack.append(intvalue)\n                elif opcode == 128:  # coerce\n                    u30()\n                elif opcode == 133:  # coerce_s\n                    assert isinstance(stack[-1], (type(None), compat_str))\n                elif opcode == 160:  # add\n                    value2 = stack.pop()\n                    value1 = stack.pop()\n                    res = value1 + value2\n                    stack.append(res)\n                elif opcode == 161:  # subtract\n                    value2 = stack.pop()\n                    value1 = stack.pop()\n                    res = value1 - value2\n                    stack.append(res)\n                elif opcode == 164:  # modulo\n                    value2 = stack.pop()\n                    value1 = stack.pop()\n                    res = value1 % value2\n                    stack.append(res)\n                elif opcode == 175:  # greaterequals\n                    value2 = stack.pop()\n                    value1 = stack.pop()\n                    result = value1 >= value2\n                    stack.append(result)\n                elif opcode == 208:  # getlocal_0\n                    stack.append(registers[0])\n                elif opcode == 209:  # getlocal_1\n                    stack.append(registers[1])\n                elif opcode == 210:  # getlocal_2\n                    stack.append(registers[2])\n                elif opcode == 211:  # getlocal_3\n                    stack.append(registers[3])\n                elif opcode == 212:  # setlocal_0\n                    registers[0] = stack.pop()\n                elif opcode == 213:  # setlocal_1\n                    registers[1] = stack.pop()\n                elif opcode == 214:  # setlocal_2\n                    registers[2] = stack.pop()\n                elif opcode == 215:  # setlocal_3\n                    registers[3] = stack.pop()\n                else:\n                    raise NotImplementedError(\n                        'Unsupported opcode %d' % opcode)\n\n        avm_class.method_pyfunctions[func_name] = resfunc\n        return resfunc",
        "begin_line": 363,
        "end_line": 608,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.francetv.FranceTVBaseInfoExtractor._extract_video#15",
        "src_path": "youtube_dl/extractor/francetv.py",
        "class_name": "youtube_dl.extractor.francetv.FranceTVBaseInfoExtractor",
        "signature": "youtube_dl.extractor.francetv.FranceTVBaseInfoExtractor._extract_video(self, video_id)",
        "snippet": "    def _extract_video(self, video_id):\n        info = self._download_xml(\n            'http://www.francetvinfo.fr/appftv/webservices/video/'\n            'getInfosOeuvre.php?id-diffusion='\n            + video_id, video_id, 'Downloading XML config')\n\n        manifest_url = info.find('videos/video/url').text\n        manifest_url = manifest_url.replace('/z/', '/i/')\n        \n        if manifest_url.startswith('rtmp'):\n            formats = [{'url': manifest_url, 'ext': 'flv'}]\n        else:\n            formats = []\n            available_formats = self._search_regex(r'/[^,]*,(.*?),k\\.mp4', manifest_url, 'available formats')\n            for index, format_descr in enumerate(available_formats.split(',')):\n                format_info = {\n                    'url': manifest_url.replace('manifest.f4m', 'index_%d_av.m3u8' % index),\n                    'ext': 'mp4',\n                }\n                m_resolution = re.search(r'(?P<width>\\d+)x(?P<height>\\d+)', format_descr)\n                if m_resolution is not None:\n                    format_info.update({\n                        'width': int(m_resolution.group('width')),\n                        'height': int(m_resolution.group('height')),\n                    })\n                formats.append(format_info)\n\n        thumbnail_path = info.find('image').text\n\n        return {\n            'id': video_id,\n            'title': info.find('titre').text,\n            'formats': formats,\n            'thumbnail': compat_urlparse.urljoin('http://pluzz.francetv.fr', thumbnail_path),\n            'description': info.find('synopsis').text,\n        }",
        "begin_line": 15,
        "end_line": 50,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007692307692307692,
            "pseudo_dstar_susp": 0.0006273525721455458,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006273525721455458,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.francetv.PluzzIE._real_extract#59",
        "src_path": "youtube_dl/extractor/francetv.py",
        "class_name": "youtube_dl.extractor.francetv.PluzzIE",
        "signature": "youtube_dl.extractor.francetv.PluzzIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        title = re.match(self._VALID_URL, url).group(1)\n        webpage = self._download_webpage(url, title)\n        video_id = self._search_regex(\n            r'data-diffusion=\"(\\d+)\"', webpage, 'ID')\n        return self._extract_video(video_id)",
        "begin_line": 59,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.francetv.FranceTvInfoIE._real_extract#94",
        "src_path": "youtube_dl/extractor/francetv.py",
        "class_name": "youtube_dl.extractor.francetv.FranceTvInfoIE",
        "signature": "youtube_dl.extractor.francetv.FranceTvInfoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        page_title = mobj.group('title')\n        webpage = self._download_webpage(url, page_title)\n        video_id = self._search_regex(r'id-video=((?:[^0-9]*?_)?[0-9]+)[@\"]', webpage, 'video id')\n        return self._extract_video(video_id)",
        "begin_line": 94,
        "end_line": 99,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.francetv.FranceTVIE._real_extract#184",
        "src_path": "youtube_dl/extractor/francetv.py",
        "class_name": "youtube_dl.extractor.francetv.FranceTVIE",
        "signature": "youtube_dl.extractor.francetv.FranceTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        if mobj.group('key'):\n            webpage = self._download_webpage(url, mobj.group('key'))\n            id_res = [\n                (r'''(?x)<div\\s+class=\"video-player\">\\s*\n                    <a\\s+href=\"http://videos.francetv.fr/video/([0-9]+)\"\\s+\n                    class=\"francetv-video-player\">'''),\n                (r'<a id=\"player_direct\" href=\"http://info\\.francetelevisions'\n                 '\\.fr/\\?id-video=([^\"/&]+)'),\n                (r'<a class=\"video\" id=\"ftv_player_(.+?)\"'),\n            ]\n            video_id = self._html_search_regex(id_res, webpage, 'video ID')\n        else:\n            video_id = mobj.group('id')\n        return self._extract_video(video_id)",
        "begin_line": 184,
        "end_line": 199,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009000900090009,
            "pseudo_dstar_susp": 0.0006983240223463687,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006983240223463687,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.francetv.GenerationQuoiIE._real_extract#220",
        "src_path": "youtube_dl/extractor/francetv.py",
        "class_name": "youtube_dl.extractor.francetv.GenerationQuoiIE",
        "signature": "youtube_dl.extractor.francetv.GenerationQuoiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        name = mobj.group('name')\n        info_url = compat_urlparse.urljoin(url, '/medias/video/%s.json' % name)\n        info_json = self._download_webpage(info_url, name)\n        info = json.loads(info_json)\n        return self.url_result('http://www.dailymotion.com/video/%s' % info['id'],\n            ie='Dailymotion')",
        "begin_line": 220,
        "end_line": 227,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.francetv.CultureboxIE._real_extract#248",
        "src_path": "youtube_dl/extractor/francetv.py",
        "class_name": "youtube_dl.extractor.francetv.CultureboxIE",
        "signature": "youtube_dl.extractor.francetv.CultureboxIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        name = mobj.group('name')\n        webpage = self._download_webpage(url, name)\n        video_id = self._search_regex(r'\"http://videos\\.francetv\\.fr/video/(.*?)\"', webpage, 'video id')\n        return self._extract_video(video_id)",
        "begin_line": 248,
        "end_line": 253,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.iconosquare.IconosquareIE._real_extract#22",
        "src_path": "youtube_dl/extractor/iconosquare.py",
        "class_name": "youtube_dl.extractor.iconosquare.IconosquareIE",
        "signature": "youtube_dl.extractor.iconosquare.IconosquareIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        html_title = self._html_search_regex(\n            r'<title>(.+?)</title>',\n            webpage, 'title')\n        title = re.sub(r'(?: *\\(Videos?\\))? \\| (?:Iconosquare|Statigram)$', '', html_title)\n        uploader_id = self._html_search_regex(\n            r'@([^ ]+)', title, 'uploader name', fatal=False)\n\n        return {\n            'id': video_id,\n            'url': self._og_search_video_url(webpage),\n            'title': title,\n            'description': self._og_search_description(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'uploader_id': uploader_id\n        }",
        "begin_line": 22,
        "end_line": 40,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.ku6.Ku6IE._real_extract#20",
        "src_path": "youtube_dl/extractor/ku6.py",
        "class_name": "youtube_dl.extractor.ku6.Ku6IE",
        "signature": "youtube_dl.extractor.ku6.Ku6IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        title = self._search_regex(r'<h1 title=.*>(.*?)</h1>', webpage, 'title')\n        dataUrl = 'http://v.ku6.com/fetchVideo4Player/%s.html' % video_id\n        jsonData = self._download_json(dataUrl, video_id)\n        downloadUrl = jsonData['data']['f']\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': downloadUrl\n        }",
        "begin_line": 20,
        "end_line": 34,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.tinypic.TinyPicIE._real_extract#24",
        "src_path": "youtube_dl/extractor/tinypic.py",
        "class_name": "youtube_dl.extractor.tinypic.TinyPicIE",
        "signature": "youtube_dl.extractor.tinypic.TinyPicIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id, 'Downloading page')\n        \n        mobj = re.search(r'(?m)fo\\.addVariable\\(\"file\",\\s\"(?P<fileid>[\\da-z]+)\"\\);\\n'\n            '\\s+fo\\.addVariable\\(\"s\",\\s\"(?P<serverid>\\d+)\"\\);', webpage)\n        if mobj is None:\n            raise ExtractorError('Video %s does not exist' % video_id, expected=True)\n\n        file_id = mobj.group('fileid')\n        server_id = mobj.group('serverid')\n\n        KEYWORDS_SUFFIX = ', Video, images, photos, videos, myspace, ebay, video hosting, photo hosting'\n        keywords = self._html_search_meta('keywords', webpage, 'title')\n        title = keywords[:-len(KEYWORDS_SUFFIX)] if keywords.endswith(KEYWORDS_SUFFIX) else ''\n\n        video_url = 'http://v%s.tinypic.com/%s.flv' % (server_id, file_id)\n        thumbnail = 'http://v%s.tinypic.com/%s_th.jpg' % (server_id, file_id)\n\n        return {\n            'id': file_id,\n            'url': video_url,\n            'thumbnail': thumbnail,\n            'title': title\n        }",
        "begin_line": 24,
        "end_line": 50,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.morningstar.MorningstarIE._real_extract#24",
        "src_path": "youtube_dl/extractor/morningstar.py",
        "class_name": "youtube_dl.extractor.morningstar.MorningstarIE",
        "signature": "youtube_dl.extractor.morningstar.MorningstarIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        title = self._html_search_regex(\n            r'<h1 id=\"titleLink\">(.*?)</h1>', webpage, 'title')\n        video_url = self._html_search_regex(\n            r'<input type=\"hidden\" id=\"hidVideoUrl\" value=\"([^\"]+)\"',\n            webpage, 'video URL')\n        thumbnail = self._html_search_regex(\n            r'<input type=\"hidden\" id=\"hidSnapshot\" value=\"([^\"]+)\"',\n            webpage, 'thumbnail', fatal=False)\n        description = self._html_search_regex(\n            r'<div id=\"mstarDeck\".*?>(.*?)</div>',\n            webpage, 'description', fatal=False)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'thumbnail': thumbnail,\n            'description': description,\n        }",
        "begin_line": 24,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.pornhub.PornHubIE._extract_count#31",
        "src_path": "youtube_dl/extractor/pornhub.py",
        "class_name": "youtube_dl.extractor.pornhub.PornHubIE",
        "signature": "youtube_dl.extractor.pornhub.PornHubIE._extract_count(self, pattern, webpage, name)",
        "snippet": "    def _extract_count(self, pattern, webpage, name):\n        count = self._html_search_regex(pattern, webpage, '%s count' % name, fatal=False)\n        if count:\n            count = str_to_int(count)\n        return count",
        "begin_line": 31,
        "end_line": 35,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.pornhub.PornHubIE._real_extract#37",
        "src_path": "youtube_dl/extractor/pornhub.py",
        "class_name": "youtube_dl.extractor.pornhub.PornHubIE",
        "signature": "youtube_dl.extractor.pornhub.PornHubIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n        url = 'http://www.' + mobj.group('url')\n\n        req = compat_urllib_request.Request(url)\n        req.add_header('Cookie', 'age_verified=1')\n        webpage = self._download_webpage(req, video_id)\n\n        video_title = self._html_search_regex(r'<h1 [^>]+>([^<]+)', webpage, 'title')\n        video_uploader = self._html_search_regex(\n            r'(?s)From:&nbsp;.+?<(?:a href=\"/users/|<span class=\"username)[^>]+>(.+?)<',\n            webpage, 'uploader', fatal=False)\n        thumbnail = self._html_search_regex(r'\"image_url\":\"([^\"]+)', webpage, 'thumbnail', fatal=False)\n        if thumbnail:\n            thumbnail = compat_urllib_parse.unquote(thumbnail)\n\n        view_count = self._extract_count(r'<span class=\"count\">([\\d,\\.]+)</span> views', webpage, 'view')\n        like_count = self._extract_count(r'<span class=\"votesUp\">([\\d,\\.]+)</span>', webpage, 'like')\n        dislike_count = self._extract_count(r'<span class=\"votesDown\">([\\d,\\.]+)</span>', webpage, 'dislike')\n        comment_count = self._extract_count(\n            r'All comments \\(<var class=\"videoCommentCount\">([\\d,\\.]+)</var>', webpage, 'comment')\n\n        video_urls = list(map(compat_urllib_parse.unquote , re.findall(r'\"quality_[0-9]{3}p\":\"([^\"]+)', webpage)))\n        if webpage.find('\"encrypted\":true') != -1:\n            password = compat_urllib_parse.unquote_plus(self._html_search_regex(r'\"video_title\":\"([^\"]+)', webpage, 'password'))\n            video_urls = list(map(lambda s: aes_decrypt_text(s, password, 32).decode('utf-8'), video_urls))\n\n        formats = []\n        for video_url in video_urls:\n            path = compat_urllib_parse_urlparse(video_url).path\n            extension = os.path.splitext(path)[1][1:]\n            format = path.split('/')[5].split('_')[:2]\n            format = \"-\".join(format)\n\n            m = re.match(r'^(?P<height>[0-9]+)P-(?P<tbr>[0-9]+)K$', format)\n            if m is None:\n                height = None\n                tbr = None\n            else:\n                height = int(m.group('height'))\n                tbr = int(m.group('tbr'))\n\n            formats.append({\n                'url': video_url,\n                'ext': extension,\n                'format': format,\n                'format_id': format,\n                'tbr': tbr,\n                'height': height,\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'uploader': video_uploader,\n            'title': video_title,\n            'thumbnail': thumbnail,\n            'view_count': view_count,\n            'like_count': like_count,\n            'dislike_count': dislike_count,\n            'comment_count': comment_count,\n            'formats': formats,\n            'age_limit': 18,\n        }",
        "begin_line": 37,
        "end_line": 101,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.mdr.MDRIE._real_extract#17",
        "src_path": "youtube_dl/extractor/mdr.py",
        "class_name": "youtube_dl.extractor.mdr.MDRIE",
        "signature": "youtube_dl.extractor.mdr.MDRIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('video_id')\n        domain = m.group('domain')\n\n        # determine title and media streams from webpage\n        html = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(r'<h[12]>(.*?)</h[12]>', html, 'title')\n        xmlurl = self._search_regex(\n            r'dataURL:\\'(/(?:.+)/(?:video|audio)[0-9]+-avCustom.xml)', html, 'XML URL')\n\n        doc = self._download_xml(domain + xmlurl, video_id)\n        formats = []\n        for a in doc.findall('./assets/asset'):\n            url_el = a.find('.//progressiveDownloadUrl')\n            if url_el is None:\n                continue\n            abr = int(a.find('bitrateAudio').text) // 1000\n            media_type = a.find('mediaType').text\n            format = {\n                'abr': abr,\n                'filesize': int(a.find('fileSize').text),\n                'url': url_el.text,\n            }\n\n            vbr_el = a.find('bitrateVideo')\n            if vbr_el is None:\n                format.update({\n                    'vcodec': 'none',\n                    'format_id': '%s-%d' % (media_type, abr),\n                })\n            else:\n                vbr = int(vbr_el.text) // 1000\n                format.update({\n                    'vbr': vbr,\n                    'width': int(a.find('frameWidth').text),\n                    'height': int(a.find('frameHeight').text),\n                    'format_id': '%s-%d' % (media_type, vbr),\n                })\n            formats.append(format)\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n        }",
        "begin_line": 17,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.mlb.MLBIE._real_extract#78",
        "src_path": "youtube_dl/extractor/mlb.py",
        "class_name": "youtube_dl.extractor.mlb.MLBIE",
        "signature": "youtube_dl.extractor.mlb.MLBIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        detail = self._download_xml(\n            'http://m.mlb.com/gen/multimedia/detail/%s/%s/%s/%s.xml'\n            % (video_id[-3], video_id[-2], video_id[-1], video_id), video_id)\n\n        title = detail.find('./headline').text\n        description = detail.find('./big-blurb').text\n        duration = parse_duration(detail.find('./duration').text)\n        timestamp = parse_iso8601(detail.attrib['date'][:-5])\n\n        thumbnail = find_xpath_attr(\n            detail, './thumbnailScenarios/thumbnailScenario', 'type', '45').text\n\n        formats = []\n        for media_url in detail.findall('./url'):\n            playback_scenario = media_url.attrib['playback_scenario']\n            fmt = {\n                'url': media_url.text,\n                'format_id': playback_scenario,\n            }\n            m = re.search(r'(?P<vbr>\\d+)K_(?P<width>\\d+)X(?P<height>\\d+)', playback_scenario)\n            if m:\n                fmt.update({\n                    'vbr': int(m.group('vbr')) * 1000,\n                    'width': int(m.group('width')),\n                    'height': int(m.group('height')),\n                })\n            formats.append(fmt)\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'timestamp': timestamp,\n            'formats': formats,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 78,
        "end_line": 120,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 7.217090069284065e-05,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.tvigle.TvigleIE._real_extract#46",
        "src_path": "youtube_dl/extractor/tvigle.py",
        "class_name": "youtube_dl.extractor.tvigle.TvigleIE",
        "signature": "youtube_dl.extractor.tvigle.TvigleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        video_id = self._html_search_regex(\n            r'<li class=\"video-preview current_playing\" id=\"(\\d+)\">', webpage, 'video id')\n\n        video_data = self._download_json(\n            'http://cloud.tvigle.ru/api/play/video/%s/' % video_id, display_id)\n\n        item = video_data['playlist']['items'][0]\n\n        title = item['title']\n        description = item['description']\n        thumbnail = item['thumbnail']\n        duration = float_or_none(item['durationMilliseconds'], 1000)\n        age_limit = str_to_int(item['ageRestrictions'])\n\n        formats = []\n        for vcodec, fmts in item['videos'].items():\n            for quality, video_url in fmts.items():\n                formats.append({\n                    'url': video_url,\n                    'format_id': '%s-%s' % (vcodec, quality),\n                    'vcodec': vcodec,\n                    'height': int(quality[:-1]),\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'age_limit': age_limit,\n            'formats': formats,\n        }",
        "begin_line": 46,
        "end_line": 86,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.gamespot.GameSpotIE._real_extract#28",
        "src_path": "youtube_dl/extractor/gamespot.py",
        "class_name": "youtube_dl.extractor.gamespot.GameSpotIE",
        "signature": "youtube_dl.extractor.gamespot.GameSpotIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        page_id = mobj.group('page_id')\n        webpage = self._download_webpage(url, page_id)\n        data_video_json = self._search_regex(r'data-video=[\"\\'](.*?)[\"\\']', webpage, 'data video')\n        data_video = json.loads(unescapeHTML(data_video_json))\n\n        # Transform the manifest url to a link to the mp4 files\n        # they are used in mobile devices.\n        f4m_url = data_video['videoStreams']['f4m_stream']\n        f4m_path = compat_urlparse.urlparse(f4m_url).path\n        QUALITIES_RE = r'((,\\d+)+,?)'\n        qualities = self._search_regex(QUALITIES_RE, f4m_path, 'qualities').strip(',').split(',')\n        http_path = f4m_path[1:].split('/', 1)[1]\n        http_template = re.sub(QUALITIES_RE, r'%s', http_path)\n        http_template = http_template.replace('.csmil/manifest.f4m', '')\n        http_template = compat_urlparse.urljoin('http://video.gamespotcdn.com/', http_template)\n        formats = []\n        for q in qualities:\n            formats.append({\n                'url': http_template % q,\n                'ext': 'mp4',\n                'format_id': q,\n            })\n\n        return {\n            'id': data_video['guid'],\n            'title': compat_urllib_parse.unquote(data_video['title']),\n            'formats': formats,\n            'description': get_meta_content('description', webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n        }",
        "begin_line": 28,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.sportdeutschland.SportDeutschlandIE._real_extract#46",
        "src_path": "youtube_dl/extractor/sportdeutschland.py",
        "class_name": "youtube_dl.extractor.sportdeutschland.SportDeutschlandIE",
        "signature": "youtube_dl.extractor.sportdeutschland.SportDeutschlandIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        sport_id = mobj.group('sport')\n\n        api_url = 'http://splink.tv/api/permalinks/%s/%s' % (\n            sport_id, video_id)\n        req = compat_urllib_request.Request(api_url, headers={\n            'Accept': 'application/vnd.vidibus.v2.html+json',\n            'Referer': url,\n        })\n        data = self._download_json(req, video_id)\n\n        categories = list(data.get('section', {}).get('tags', {}).values())\n        asset = data['asset']\n\n        formats = []\n        smil_url = asset['video']\n        if '.smil' in smil_url:\n            m3u8_url = smil_url.replace('.smil', '.m3u8')\n            formats.extend(\n                self._extract_m3u8_formats(m3u8_url, video_id, ext='mp4'))\n\n            smil_doc = self._download_xml(\n                smil_url, video_id, note='Downloading SMIL metadata')\n            base_url = smil_doc.find('./head/meta').attrib['base']\n            formats.extend([{\n                'format_id': 'rmtp',\n                'url': base_url,\n                'play_path': n.attrib['src'],\n                'ext': 'flv',\n                'preference': -100,\n                'format_note': 'Seems to fail at example stream',\n            } for n in smil_doc.findall('./body/video')])\n        else:\n            formats.append({'url': smil_url})\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': asset['title'],\n            'thumbnail': asset.get('image'),\n            'description': asset.get('teaser'),\n            'categories': categories,\n            'view_count': asset.get('views'),\n            'rtmp_live': asset.get('live'),\n            'timestamp': parse_iso8601(asset.get('date')),\n        }",
        "begin_line": 46,
        "end_line": 95,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.ceskatelevize.CeskaTelevizeIE._real_extract#59",
        "src_path": "youtube_dl/extractor/ceskatelevize.py",
        "class_name": "youtube_dl.extractor.ceskatelevize.CeskaTelevizeIE",
        "signature": "youtube_dl.extractor.ceskatelevize.CeskaTelevizeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url = url.replace('/porady/', '/ivysilani/').replace('/video/', '')\n\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        NOT_AVAILABLE_STRING = 'This content is not available at your territory due to limited copyright.'\n        if '%s</p>' % NOT_AVAILABLE_STRING in webpage:\n            raise ExtractorError(NOT_AVAILABLE_STRING, expected=True)\n\n        typ = self._html_search_regex(r'getPlaylistUrl\\(\\[\\{\"type\":\"(.+?)\",\"id\":\".+?\"\\}\\],', webpage, 'type')\n        episode_id = self._html_search_regex(r'getPlaylistUrl\\(\\[\\{\"type\":\".+?\",\"id\":\"(.+?)\"\\}\\],', webpage, 'episode_id')\n\n        data = {\n            'playlist[0][type]': typ,\n            'playlist[0][id]': episode_id,\n            'requestUrl': compat_urllib_parse_urlparse(url).path,\n            'requestSource': 'iVysilani',\n        }\n\n        req = compat_urllib_request.Request('http://www.ceskatelevize.cz/ivysilani/ajax/get-playlist-url',\n                                            data=compat_urllib_parse.urlencode(data))\n\n        req.add_header('Content-type', 'application/x-www-form-urlencoded')\n        req.add_header('x-addr', '127.0.0.1')\n        req.add_header('X-Requested-With', 'XMLHttpRequest')\n        req.add_header('Referer', url)\n\n        playlistpage = self._download_json(req, video_id)\n\n        req = compat_urllib_request.Request(compat_urllib_parse.unquote(playlistpage['url']))\n        req.add_header('Referer', url)\n\n        playlist = self._download_xml(req, video_id)\n        \n        formats = []\n        for i in playlist.find('smilRoot/body'):\n            if 'AD' not in i.attrib['id']:\n                base_url = i.attrib['base']\n                parsedurl = compat_urllib_parse_urlparse(base_url)\n                duration = i.attrib['duration']\n\n                for video in i.findall('video'):\n                    if video.attrib['label'] != 'AD':\n                        format_id = video.attrib['label']\n                        play_path = video.attrib['src']\n                        vbr = int(video.attrib['system-bitrate'])\n\n                        formats.append({\n                            'format_id': format_id,\n                            'url': base_url,\n                            'vbr': vbr,\n                            'play_path': play_path,\n                            'app': parsedurl.path[1:] + '?' + parsedurl.query,\n                            'rtmp_live': True,\n                            'ext': 'flv',\n                        })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': episode_id,\n            'title': self._html_search_regex(r'<title>(.+?) \u2014 iVys\u00edl\u00e1n\u00ed \u2014 \u010cesk\u00e1 televize</title>', webpage, 'title'),\n            'duration': float(duration),\n            'formats': formats,\n        }",
        "begin_line": 59,
        "end_line": 126,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.sohu.SohuIE._real_extract#23",
        "src_path": "youtube_dl/extractor/sohu.py",
        "class_name": "youtube_dl.extractor.sohu.SohuIE",
        "signature": "youtube_dl.extractor.sohu.SohuIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n\n        def _fetch_data(vid_id, mytv=False):\n            if mytv:\n                base_data_url = 'http://my.tv.sohu.com/play/videonew.do?vid='\n            else:\n                base_data_url = u'http://hot.vrs.sohu.com/vrs_flash.action?vid='\n            data_url = base_data_url + str(vid_id)\n            data_json = self._download_webpage(\n                data_url, video_id,\n                note=u'Downloading JSON data for ' + str(vid_id))\n            return json.loads(data_json)\n\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        mytv = mobj.group('mytv') is not None\n\n        webpage = self._download_webpage(url, video_id)\n        raw_title = self._html_search_regex(r'(?s)<title>(.+?)</title>',\n                                            webpage, u'video title')\n        title = raw_title.partition('-')[0].strip()\n\n        vid = self._html_search_regex(r'var vid ?= ?[\"\\'](\\d+)[\"\\']', webpage,\n                                      u'video path')\n        data = _fetch_data(vid, mytv)\n\n        QUALITIES = ('ori', 'super', 'high', 'nor')\n        vid_ids = [data['data'][q + 'Vid']\n                   for q in QUALITIES\n                   if data['data'][q + 'Vid'] != 0]\n        if not vid_ids:\n            raise ExtractorError(u'No formats available for this video')\n\n        # For now, we just pick the highest available quality\n        vid_id = vid_ids[-1]\n\n        format_data = data if vid == vid_id else _fetch_data(vid_id, mytv)\n        part_count = format_data['data']['totalBlocks']\n        allot = format_data['allot']\n        prot = format_data['prot']\n        clipsURL = format_data['data']['clipsURL']\n        su = format_data['data']['su']\n\n        playlist = []\n        for i in range(part_count):\n            part_url = ('http://%s/?prot=%s&file=%s&new=%s' %\n                        (allot, prot, clipsURL[i], su[i]))\n            part_str = self._download_webpage(\n                part_url, video_id,\n                note=u'Downloading part %d of %d' % (i+1, part_count))\n\n            part_info = part_str.split('|')\n            video_url = '%s%s?key=%s' % (part_info[0], su[i], part_info[3])\n\n            video_info = {\n                'id': '%s_part%02d' % (video_id, i + 1),\n                'title': title,\n                'url': video_url,\n                'ext': 'mp4',\n            }\n            playlist.append(video_info)\n\n        if len(playlist) == 1:\n            info = playlist[0]\n            info['id'] = video_id\n        else:\n            info = {\n                '_type': 'playlist',\n                'entries': playlist,\n                'id': video_id,\n            }\n\n        return info",
        "begin_line": 23,
        "end_line": 95,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.instagram.InstagramIE._real_extract#25",
        "src_path": "youtube_dl/extractor/instagram.py",
        "class_name": "youtube_dl.extractor.instagram.InstagramIE",
        "signature": "youtube_dl.extractor.instagram.InstagramIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        uploader_id = self._search_regex(r'\"owner\":{\"username\":\"(.+?)\"',\n            webpage, 'uploader id', fatal=False)\n        desc = self._search_regex(r'\"caption\":\"(.*?)\"', webpage, 'description',\n            fatal=False)\n\n        return {\n            'id': video_id,\n            'url': self._og_search_video_url(webpage, secure=False),\n            'ext': 'mp4',\n            'title': 'Video by %s' % uploader_id,\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'uploader_id': uploader_id,\n            'description': desc,\n        }",
        "begin_line": 25,
        "end_line": 42,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.instagram.InstagramUserIE._real_extract#74",
        "src_path": "youtube_dl/extractor/instagram.py",
        "class_name": "youtube_dl.extractor.instagram.InstagramUserIE",
        "signature": "youtube_dl.extractor.instagram.InstagramUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        uploader_id = mobj.group('username')\n\n        entries = []\n        page_count = 0\n        media_url = 'http://instagram.com/%s/media' % uploader_id\n        while True:\n            page = self._download_json(\n                media_url, uploader_id,\n                note='Downloading page %d ' % (page_count + 1),\n            )\n            page_count += 1\n\n            for it in page['items']:\n                if it.get('type') != 'video':\n                    continue\n                like_count = int_or_none(it.get('likes', {}).get('count'))\n                user = it.get('user', {})\n\n                formats = [{\n                    'format_id': k,\n                    'height': v.get('height'),\n                    'width': v.get('width'),\n                    'url': v['url'],\n                } for k, v in it['videos'].items()]\n                self._sort_formats(formats)\n\n                thumbnails_el = it.get('images', {})\n                thumbnail = thumbnails_el.get('thumbnail', {}).get('url')\n\n                title = it.get('caption', {}).get('text', it['id'])\n\n                entries.append({\n                    'id': it['id'],\n                    'title': title,\n                    'formats': formats,\n                    'thumbnail': thumbnail,\n                    'webpage_url': it.get('link'),\n                    'uploader': user.get('full_name'),\n                    'uploader_id': user.get('username'),\n                    'like_count': like_count,\n                    'timestamp': int_or_none(it.get('created_time')),\n                })\n\n            if not page['items']:\n                break\n            max_id = page['items'][-1]['id']\n            media_url = (\n                'http://instagram.com/%s/media?max_id=%s' % (\n                    uploader_id, max_id))\n\n        return {\n            '_type': 'playlist',\n            'entries': entries,\n            'id': uploader_id,\n            'title': uploader_id,\n        }",
        "begin_line": 74,
        "end_line": 131,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.musicplayon.MusicPlayOnIE._real_extract#29",
        "src_path": "youtube_dl/extractor/musicplayon.py",
        "class_name": "youtube_dl.extractor.musicplayon.MusicPlayOnIE",
        "signature": "youtube_dl.extractor.musicplayon.MusicPlayOnIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        page = self._download_webpage(url, video_id)\n\n        title = self._og_search_title(page)\n        description = self._og_search_description(page)\n        thumbnail = self._og_search_thumbnail(page)\n        duration = self._html_search_meta('video:duration', page, 'duration', fatal=False)\n        view_count = self._og_search_property('count', page, fatal=False)\n        uploader = self._html_search_regex(\n            r'<div>by&nbsp;<a href=\"[^\"]+\" class=\"purple\">([^<]+)</a></div>', page, 'uploader', fatal=False)\n\n        formats = [\n            {\n                'url': 'http://media0-eu-nl.musicplayon.com/stream-mobile?id=%s&type=.mp4' % video_id,\n                'ext': 'mp4',\n            }\n        ]\n\n        manifest = self._download_webpage(\n            'http://en.musicplayon.com/manifest.m3u8?v=%s' % video_id, video_id, 'Downloading manifest')\n\n        for entry in manifest.split('#')[1:]:\n            if entry.startswith('EXT-X-STREAM-INF:'):\n                meta, url, _ = entry.split('\\n')\n                params = dict(param.split('=') for param in meta.split(',')[1:])\n                formats.append({\n                    'url': url,\n                    'ext': 'mp4',\n                    'tbr': int(params['BANDWIDTH']),\n                    'width': int(params['RESOLUTION'].split('x')[1]),\n                    'height': int(params['RESOLUTION'].split('x')[-1]),\n                    'format_note': params['NAME'].replace('\"', '').strip(),\n                })\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'duration': int_or_none(duration),\n            'view_count': int_or_none(view_count),\n            'formats': formats,\n        }",
        "begin_line": 29,
        "end_line": 75,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.vk.VKIE._login#108",
        "src_path": "youtube_dl/extractor/vk.py",
        "class_name": "youtube_dl.extractor.vk.VKIE",
        "signature": "youtube_dl.extractor.vk.VKIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n\n        login_form = {\n            'act': 'login',\n            'role': 'al_frame',\n            'expire': '1',\n            'email': username,\n            'pass': password,\n        }\n\n        request = compat_urllib_request.Request('https://login.vk.com/?act=login',\n            compat_urllib_parse.urlencode(login_form).encode('utf-8'))\n        login_page = self._download_webpage(request, None, note='Logging in as %s' % username)\n\n        if re.search(r'onLoginFailed', login_page):\n            raise ExtractorError('Unable to login, incorrect username and/or password', expected=True)",
        "begin_line": 108,
        "end_line": 126,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007692307692307692,
            "pseudo_dstar_susp": 0.0006273525721455458,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006273525721455458,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.vk.VKIE._real_initialize#128",
        "src_path": "youtube_dl/extractor/vk.py",
        "class_name": "youtube_dl.extractor.vk.VKIE",
        "signature": "youtube_dl.extractor.vk.VKIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 128,
        "end_line": 129,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007692307692307692,
            "pseudo_dstar_susp": 0.0006273525721455458,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006273525721455458,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.vk.VKIE._real_extract#131",
        "src_path": "youtube_dl/extractor/vk.py",
        "class_name": "youtube_dl.extractor.vk.VKIE",
        "signature": "youtube_dl.extractor.vk.VKIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n\n        if not video_id:\n            video_id = '%s_%s' % (mobj.group('oid'), mobj.group('id'))\n\n        info_url = 'http://vk.com/al_video.php?act=show&al=1&video=%s' % video_id\n        info_page = self._download_webpage(info_url, video_id)\n\n        if re.search(r'<!>Please log in or <', info_page):\n            raise ExtractorError('This video is only available for registered users, '\n                'use --username and --password options to provide account credentials.', expected=True)\n\n        m_yt = re.search(r'src=\"(http://www.youtube.com/.*?)\"', info_page)\n        if m_yt is not None:\n            self.to_screen('Youtube video detected')\n            return self.url_result(m_yt.group(1), 'Youtube')\n\n        m_opts = re.search(r'(?s)var\\s+opts\\s*=\\s*({.*?});', info_page)\n        if m_opts:\n            m_opts_url = re.search(r\"url\\s*:\\s*'([^']+)\", m_opts.group(1))\n            if m_opts_url:\n                opts_url = m_opts_url.group(1)\n                if opts_url.startswith('//'):\n                    opts_url = 'http:' + opts_url\n                return self.url_result(opts_url)\n\n        data_json = self._search_regex(r'var vars = ({.*?});', info_page, 'vars')\n        data = json.loads(data_json)\n\n        formats = [{\n            'format_id': k,\n            'url': v,\n            'width': int(k[len('url'):]),\n        } for k, v in data.items()\n            if k.startswith('url')]\n        self._sort_formats(formats)\n\n        return {\n            'id': compat_str(data['vid']),\n            'formats': formats,\n            'title': unescapeHTML(data['md_title']),\n            'thumbnail': data.get('jpg'),\n            'uploader': data.get('md_author'),\n            'duration': data.get('duration')\n        }",
        "begin_line": 131,
        "end_line": 177,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007692307692307692,
            "pseudo_dstar_susp": 0.0006273525721455458,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006273525721455458,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.aftonbladet.AftonbladetIE._real_extract#23",
        "src_path": "youtube_dl/extractor/aftonbladet.py",
        "class_name": "youtube_dl.extractor.aftonbladet.AftonbladetIE",
        "signature": "youtube_dl.extractor.aftonbladet.AftonbladetIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.search(self._VALID_URL, url)\n\n        video_id = mobj.group('video_id')\n        webpage = self._download_webpage(url, video_id)\n\n        # find internal video meta data\n        meta_url = 'http://aftonbladet-play.drlib.aptoma.no/video/%s.json'\n        internal_meta_id = self._html_search_regex(\n            r'data-aptomaId=\"([\\w\\d]+)\"', webpage, 'internal_meta_id')\n        internal_meta_url = meta_url % internal_meta_id\n        internal_meta_json = self._download_json(\n            internal_meta_url, video_id, 'Downloading video meta data')\n\n        # find internal video formats\n        format_url = 'http://aftonbladet-play.videodata.drvideo.aptoma.no/actions/video/?id=%s'\n        internal_video_id = internal_meta_json['videoId']\n        internal_formats_url = format_url % internal_video_id\n        internal_formats_json = self._download_json(\n            internal_formats_url, video_id, 'Downloading video formats')\n\n        formats = []\n        for fmt in internal_formats_json['formats']['http']['pseudostreaming']['mp4']:\n            p = fmt['paths'][0]\n            formats.append({\n                'url': 'http://%s:%d/%s/%s' % (p['address'], p['port'], p['path'], p['filename']),\n                'ext': 'mp4',\n                'width': fmt['width'],\n                'height': fmt['height'],\n                'tbr': fmt['bitrate'],\n                'protocol': 'http',\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': internal_meta_json['title'],\n            'formats': formats,\n            'thumbnail': internal_meta_json['imageUrl'],\n            'description': internal_meta_json['shortPreamble'],\n            'timestamp': internal_meta_json['timePublished'],\n            'duration': internal_meta_json['duration'],\n            'view_count': internal_meta_json['views'],\n        }",
        "begin_line": 23,
        "end_line": 66,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.tnaflix.TNAFlixIE._real_extract#34",
        "src_path": "youtube_dl/extractor/tnaflix.py",
        "class_name": "youtube_dl.extractor.tnaflix.TNAFlixIE",
        "signature": "youtube_dl.extractor.tnaflix.TNAFlixIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        title = self._html_search_regex(\n            self._TITLE_REGEX, webpage, 'title') if self._TITLE_REGEX else self._og_search_title(webpage)\n        description = self._html_search_regex(\n            self._DESCRIPTION_REGEX, webpage, 'description', fatal=False, default='')\n\n        age_limit = self._rta_search(webpage)\n\n        duration = self._html_search_meta('duration', webpage, 'duration', default=None)\n        if duration:\n            duration = parse_duration(duration[1:])\n\n        cfg_url = self._html_search_regex(\n            self._CONFIG_REGEX, webpage, 'flashvars.config')\n\n        cfg_xml = self._download_xml(\n            cfg_url, display_id, note='Downloading metadata',\n            transform_source=fix_xml_ampersands)\n\n        thumbnail = cfg_xml.find('./startThumb').text\n\n        formats = []\n        for item in cfg_xml.findall('./quality/item'):\n            video_url = re.sub('speed=\\d+', 'speed=', item.find('videoLink').text)\n            format_id = item.find('res').text\n            fmt = {\n                'url': video_url,\n                'format_id': format_id,\n            }\n            m = re.search(r'^(\\d+)', format_id)\n            if m:\n                fmt['height'] = int(m.group(1))\n            formats.append(fmt)\n        self._sort_formats(formats)\n        \n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'age_limit': age_limit,\n            'formats': formats,\n        }",
        "begin_line": 34,
        "end_line": 84,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.dropbox.DropboxIE._real_extract#22",
        "src_path": "youtube_dl/extractor/dropbox.py",
        "class_name": "youtube_dl.extractor.dropbox.DropboxIE",
        "signature": "youtube_dl.extractor.dropbox.DropboxIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        fn = compat_urllib_parse_unquote(mobj.group('title'))\n        title = os.path.splitext(fn)[0]\n        video_url = (\n            re.sub(r'[?&]dl=0', '', url) +\n            ('?' if '?' in url else '&') + 'dl=1')\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n        }",
        "begin_line": 22,
        "end_line": 35,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.__init__#47",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.__init__(self, ydl, params)",
        "snippet": "    def __init__(self, ydl, params):\n        \"\"\"Create a FileDownloader object with the given options.\"\"\"\n        self.ydl = ydl\n        self._progress_hooks = []\n        self.params = params",
        "begin_line": 47,
        "end_line": 51,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011273957158962795,
            "pseudo_dstar_susp": 0.0015432098765432098,
            "pseudo_tarantula_susp": 0.0002627430373095113,
            "pseudo_op2_susp": 0.0015432098765432098,
            "pseudo_barinel_susp": 0.0002627430373095113
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.format_seconds#54",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.format_seconds(seconds)",
        "snippet": "    def format_seconds(seconds):\n        (mins, secs) = divmod(seconds, 60)\n        (hours, mins) = divmod(mins, 60)\n        if hours > 99:\n            return '--:--:--'\n        if hours == 0:\n            return '%02d:%02d' % (mins, secs)\n        else:\n            return '%02d:%02d:%02d' % (hours, mins, secs)",
        "begin_line": 54,
        "end_line": 62,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006693440428380187,
            "pseudo_dstar_susp": 0.0009107468123861566,
            "pseudo_tarantula_susp": 0.0002447980416156671,
            "pseudo_op2_susp": 0.0009107468123861566,
            "pseudo_barinel_susp": 0.00024467824810374357
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.calc_percent#65",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.calc_percent(byte_counter, data_len)",
        "snippet": "    def calc_percent(byte_counter, data_len):\n        if data_len is None:\n            return None\n        return float(byte_counter) / float(data_len) * 100.0",
        "begin_line": 65,
        "end_line": 68,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006693440428380187,
            "pseudo_dstar_susp": 0.0009107468123861566,
            "pseudo_tarantula_susp": 0.0002447980416156671,
            "pseudo_op2_susp": 0.0009107468123861566,
            "pseudo_barinel_susp": 0.00024467824810374357
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.format_percent#71",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.format_percent(percent)",
        "snippet": "    def format_percent(percent):\n        if percent is None:\n            return '---.-%'\n        return '%6s' % ('%3.1f%%' % percent)",
        "begin_line": 71,
        "end_line": 74,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006693440428380187,
            "pseudo_dstar_susp": 0.0009107468123861566,
            "pseudo_tarantula_susp": 0.0002447980416156671,
            "pseudo_op2_susp": 0.0009107468123861566,
            "pseudo_barinel_susp": 0.00024467824810374357
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.calc_eta#77",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.calc_eta(start, now, total, current)",
        "snippet": "    def calc_eta(start, now, total, current):\n        if total is None:\n            return None\n        dif = now - start\n        if current == 0 or dif < 0.001: # One millisecond\n            return None\n        rate = float(current) / dif\n        return int((float(total) - float(current)) / rate)",
        "begin_line": 77,
        "end_line": 84,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006693440428380187,
            "pseudo_dstar_susp": 0.0009107468123861566,
            "pseudo_tarantula_susp": 0.0002447980416156671,
            "pseudo_op2_susp": 0.0009107468123861566,
            "pseudo_barinel_susp": 0.00024467824810374357
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.format_eta#87",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.format_eta(eta)",
        "snippet": "    def format_eta(eta):\n        if eta is None:\n            return '--:--'\n        return FileDownloader.format_seconds(eta)",
        "begin_line": 87,
        "end_line": 90,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006693440428380187,
            "pseudo_dstar_susp": 0.0009107468123861566,
            "pseudo_tarantula_susp": 0.0002447980416156671,
            "pseudo_op2_susp": 0.0009107468123861566,
            "pseudo_barinel_susp": 0.00024467824810374357
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.calc_speed#93",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.calc_speed(start, now, bytes)",
        "snippet": "    def calc_speed(start, now, bytes):\n        dif = now - start\n        if bytes == 0 or dif < 0.001: # One millisecond\n            return None\n        return float(bytes) / dif",
        "begin_line": 93,
        "end_line": 97,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006693440428380187,
            "pseudo_dstar_susp": 0.0009107468123861566,
            "pseudo_tarantula_susp": 0.0002447980416156671,
            "pseudo_op2_susp": 0.0009107468123861566,
            "pseudo_barinel_susp": 0.00024467824810374357
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.format_speed#100",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.format_speed(speed)",
        "snippet": "    def format_speed(speed):\n        if speed is None:\n            return '%10s' % '---b/s'\n        return '%10s' % ('%s/s' % format_bytes(speed))",
        "begin_line": 100,
        "end_line": 103,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006693440428380187,
            "pseudo_dstar_susp": 0.0009107468123861566,
            "pseudo_tarantula_susp": 0.0002447980416156671,
            "pseudo_op2_susp": 0.0009107468123861566,
            "pseudo_barinel_susp": 0.00024467824810374357
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.best_block_size#106",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.best_block_size(elapsed_time, bytes)",
        "snippet": "    def best_block_size(elapsed_time, bytes):\n        new_min = max(bytes / 2.0, 1.0)\n        new_max = min(max(bytes * 2.0, 1.0), 4194304) # Do not surpass 4 MB\n        if elapsed_time < 0.001:\n            return int(new_max)\n        rate = bytes / elapsed_time\n        if rate > new_max:\n            return int(new_max)\n        if rate < new_min:\n            return int(new_min)\n        return int(rate)",
        "begin_line": 106,
        "end_line": 116,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006693440428380187,
            "pseudo_dstar_susp": 0.0009107468123861566,
            "pseudo_tarantula_susp": 0.0002447980416156671,
            "pseudo_op2_susp": 0.0009107468123861566,
            "pseudo_barinel_susp": 0.00024467824810374357
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.to_screen#128",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.to_screen(self, *args, **kargs)",
        "snippet": "    def to_screen(self, *args, **kargs):\n        self.ydl.to_screen(*args, **kargs)",
        "begin_line": 128,
        "end_line": 129,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008576329331046312,
            "pseudo_dstar_susp": 0.0010695187165775401,
            "pseudo_tarantula_susp": 0.0002566735112936345,
            "pseudo_op2_susp": 0.0010695187165775401,
            "pseudo_barinel_susp": 0.00025687130747495504
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.to_stderr#131",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.to_stderr(self, message)",
        "snippet": "    def to_stderr(self, message):\n        self.ydl.to_screen(message)",
        "begin_line": 131,
        "end_line": 132,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.to_console_title#134",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.to_console_title(self, message)",
        "snippet": "    def to_console_title(self, message):\n        self.ydl.to_console_title(message)",
        "begin_line": 134,
        "end_line": 135,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006693440428380187,
            "pseudo_dstar_susp": 0.0009107468123861566,
            "pseudo_tarantula_susp": 0.0002447980416156671,
            "pseudo_op2_susp": 0.0009107468123861566,
            "pseudo_barinel_susp": 0.00024467824810374357
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.trouble#137",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.trouble(self, *args, **kargs)",
        "snippet": "    def trouble(self, *args, **kargs):\n        self.ydl.trouble(*args, **kargs)",
        "begin_line": 137,
        "end_line": 138,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_warning#140",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_warning(self, *args, **kargs)",
        "snippet": "    def report_warning(self, *args, **kargs):\n        self.ydl.report_warning(*args, **kargs)",
        "begin_line": 140,
        "end_line": 141,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_error#143",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_error(self, *args, **kargs)",
        "snippet": "    def report_error(self, *args, **kargs):\n        self.ydl.report_error(*args, **kargs)",
        "begin_line": 143,
        "end_line": 144,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.slow_down#146",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.slow_down(self, start_time, byte_counter)",
        "snippet": "    def slow_down(self, start_time, byte_counter):\n        \"\"\"Sleep if the download speed is over the rate limit.\"\"\"\n        rate_limit = self.params.get('ratelimit', None)\n        if rate_limit is None or byte_counter == 0:\n            return\n        now = time.time()\n        elapsed = now - start_time\n        if elapsed <= 0.0:\n            return\n        speed = float(byte_counter) / elapsed\n        if speed > rate_limit:\n            time.sleep((byte_counter - rate_limit * (now - start_time)) / rate_limit)",
        "begin_line": 146,
        "end_line": 157,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006693440428380187,
            "pseudo_dstar_susp": 0.0009107468123861566,
            "pseudo_tarantula_susp": 0.0002447980416156671,
            "pseudo_op2_susp": 0.0009107468123861566,
            "pseudo_barinel_susp": 0.00024467824810374357
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.temp_name#159",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.temp_name(self, filename)",
        "snippet": "    def temp_name(self, filename):\n        \"\"\"Returns a temporary filename for the given filename.\"\"\"\n        if self.params.get('nopart', False) or filename == u'-' or \\\n                (os.path.exists(encodeFilename(filename)) and not os.path.isfile(encodeFilename(filename))):\n            return filename\n        return filename + u'.part'",
        "begin_line": 159,
        "end_line": 164,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011273957158962795,
            "pseudo_dstar_susp": 0.0015432098765432098,
            "pseudo_tarantula_susp": 0.0002627430373095113,
            "pseudo_op2_susp": 0.0015432098765432098,
            "pseudo_barinel_susp": 0.0002627430373095113
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.undo_temp_name#166",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.undo_temp_name(self, filename)",
        "snippet": "    def undo_temp_name(self, filename):\n        if filename.endswith(u'.part'):\n            return filename[:-len(u'.part')]\n        return filename",
        "begin_line": 166,
        "end_line": 169,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006693440428380187,
            "pseudo_dstar_susp": 0.0009107468123861566,
            "pseudo_tarantula_susp": 0.0002447980416156671,
            "pseudo_op2_susp": 0.0009107468123861566,
            "pseudo_barinel_susp": 0.00024467824810374357
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.try_rename#171",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.try_rename(self, old_filename, new_filename)",
        "snippet": "    def try_rename(self, old_filename, new_filename):\n        try:\n            if old_filename == new_filename:\n                return\n            os.rename(encodeFilename(old_filename), encodeFilename(new_filename))\n        except (IOError, OSError) as err:\n            self.report_error(u'unable to rename file: %s' % compat_str(err))",
        "begin_line": 171,
        "end_line": 177,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006693440428380187,
            "pseudo_dstar_susp": 0.0009107468123861566,
            "pseudo_tarantula_susp": 0.0002447980416156671,
            "pseudo_op2_susp": 0.0009107468123861566,
            "pseudo_barinel_susp": 0.00024467824810374357
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.try_utime#179",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.try_utime(self, filename, last_modified_hdr)",
        "snippet": "    def try_utime(self, filename, last_modified_hdr):\n        \"\"\"Try to set the last-modified time of the given file.\"\"\"\n        if last_modified_hdr is None:\n            return\n        if not os.path.isfile(encodeFilename(filename)):\n            return\n        timestr = last_modified_hdr\n        if timestr is None:\n            return\n        filetime = timeconvert(timestr)\n        if filetime is None:\n            return filetime\n        # Ignore obviously invalid dates\n        if filetime == 0:\n            return\n        try:\n            os.utime(filename, (time.time(), filetime))\n        except:\n            pass\n        return filetime",
        "begin_line": 179,
        "end_line": 198,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007163323782234957,
            "pseudo_dstar_susp": 0.0009823182711198428,
            "pseudo_tarantula_susp": 0.0002527805864509606,
            "pseudo_op2_susp": 0.0009823182711198428,
            "pseudo_barinel_susp": 0.0002527805864509606
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_destination#200",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_destination(self, filename)",
        "snippet": "    def report_destination(self, filename):\n        \"\"\"Report destination filename.\"\"\"\n        self.to_screen(u'[download] Destination: ' + filename)",
        "begin_line": 200,
        "end_line": 202,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008576329331046312,
            "pseudo_dstar_susp": 0.0010695187165775401,
            "pseudo_tarantula_susp": 0.0002566735112936345,
            "pseudo_op2_susp": 0.0010695187165775401,
            "pseudo_barinel_susp": 0.00025687130747495504
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader._report_progress_status#204",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader._report_progress_status(self, msg, is_last_line=False)",
        "snippet": "    def _report_progress_status(self, msg, is_last_line=False):\n        fullmsg = u'[download] ' + msg\n        if self.params.get('progress_with_newline', False):\n            self.to_screen(fullmsg)\n        else:\n            if os.name == 'nt':\n                prev_len = getattr(self, '_report_progress_prev_line_length',\n                                   0)\n                if prev_len > len(fullmsg):\n                    fullmsg += u' ' * (prev_len - len(fullmsg))\n                self._report_progress_prev_line_length = len(fullmsg)\n                clear_line = u'\\r'\n            else:\n                clear_line = (u'\\r\\x1b[K' if sys.stderr.isatty() else u'\\r')\n            self.to_screen(clear_line + fullmsg, skip_eol=not is_last_line)\n        self.to_console_title(u'youtube-dl ' + msg)",
        "begin_line": 204,
        "end_line": 219,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006693440428380187,
            "pseudo_dstar_susp": 0.0009107468123861566,
            "pseudo_tarantula_susp": 0.0002447980416156671,
            "pseudo_op2_susp": 0.0009107468123861566,
            "pseudo_barinel_susp": 0.00024467824810374357
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_progress#221",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_progress(self, percent, data_len_str, speed, eta)",
        "snippet": "    def report_progress(self, percent, data_len_str, speed, eta):\n        \"\"\"Report download progress.\"\"\"\n        if self.params.get('noprogress', False):\n            return\n        if eta is not None:\n            eta_str = self.format_eta(eta)\n        else:\n            eta_str = 'Unknown ETA'\n        if percent is not None:\n            percent_str = self.format_percent(percent)\n        else:\n            percent_str = 'Unknown %'\n        speed_str = self.format_speed(speed)\n\n        msg = (u'%s of %s at %s ETA %s' %\n               (percent_str, data_len_str, speed_str, eta_str))\n        self._report_progress_status(msg)",
        "begin_line": 221,
        "end_line": 237,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006693440428380187,
            "pseudo_dstar_susp": 0.0009107468123861566,
            "pseudo_tarantula_susp": 0.0002447980416156671,
            "pseudo_op2_susp": 0.0009107468123861566,
            "pseudo_barinel_susp": 0.00024467824810374357
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_progress_live_stream#239",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_progress_live_stream(self, downloaded_data_len, speed, elapsed)",
        "snippet": "    def report_progress_live_stream(self, downloaded_data_len, speed, elapsed):\n        if self.params.get('noprogress', False):\n            return\n        downloaded_str = format_bytes(downloaded_data_len)\n        speed_str = self.format_speed(speed)\n        elapsed_str = FileDownloader.format_seconds(elapsed)\n        msg = u'%s at %s (%s)' % (downloaded_str, speed_str, elapsed_str)\n        self._report_progress_status(msg)",
        "begin_line": 239,
        "end_line": 246,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_finish#248",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_finish(self, data_len_str, tot_time)",
        "snippet": "    def report_finish(self, data_len_str, tot_time):\n        \"\"\"Report download finished.\"\"\"\n        if self.params.get('noprogress', False):\n            self.to_screen(u'[download] Download completed')\n        else:\n            self._report_progress_status(\n                (u'100%% of %s in %s' %\n                 (data_len_str, self.format_seconds(tot_time))),\n                is_last_line=True)",
        "begin_line": 248,
        "end_line": 256,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006693440428380187,
            "pseudo_dstar_susp": 0.0009107468123861566,
            "pseudo_tarantula_susp": 0.0002447980416156671,
            "pseudo_op2_susp": 0.0009107468123861566,
            "pseudo_barinel_susp": 0.00024467824810374357
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_resuming_byte#258",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_resuming_byte(self, resume_len)",
        "snippet": "    def report_resuming_byte(self, resume_len):\n        \"\"\"Report attempt to resume at given byte.\"\"\"\n        self.to_screen(u'[download] Resuming download at byte %s' % resume_len)",
        "begin_line": 258,
        "end_line": 260,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_retry#262",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_retry(self, count, retries)",
        "snippet": "    def report_retry(self, count, retries):\n        \"\"\"Report retry in case of HTTP error 5xx\"\"\"\n        self.to_screen(u'[download] Got server HTTP error. Retrying (attempt %d of %d)...' % (count, retries))",
        "begin_line": 262,
        "end_line": 264,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_file_already_downloaded#266",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_file_already_downloaded(self, file_name)",
        "snippet": "    def report_file_already_downloaded(self, file_name):\n        \"\"\"Report file has already been fully downloaded.\"\"\"\n        try:\n            self.to_screen(u'[download] %s has already been downloaded' % file_name)\n        except UnicodeEncodeError:\n            self.to_screen(u'[download] The file has already been downloaded')",
        "begin_line": 266,
        "end_line": 271,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_unable_to_resume#273",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_unable_to_resume(self)",
        "snippet": "    def report_unable_to_resume(self):\n        \"\"\"Report it was impossible to resume download.\"\"\"\n        self.to_screen(u'[download] Unable to resume')",
        "begin_line": 273,
        "end_line": 275,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.download#277",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.download(self, filename, info_dict)",
        "snippet": "    def download(self, filename, info_dict):\n        \"\"\"Download to a filename using the info from info_dict\n        Return True on success and False otherwise\n        \"\"\"\n        # Check file already present\n        if self.params.get('continuedl', False) and os.path.isfile(encodeFilename(filename)) and not self.params.get('nopart', False):\n            self.report_file_already_downloaded(filename)\n            self._hook_progress({\n                'filename': filename,\n                'status': 'finished',\n                'total_bytes': os.path.getsize(encodeFilename(filename)),\n            })\n            return True\n\n        return self.real_download(filename, info_dict)",
        "begin_line": 277,
        "end_line": 291,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011273957158962795,
            "pseudo_dstar_susp": 0.0015432098765432098,
            "pseudo_tarantula_susp": 0.0002627430373095113,
            "pseudo_op2_susp": 0.0015432098765432098,
            "pseudo_barinel_susp": 0.0002627430373095113
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.real_download#293",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.real_download(self, filename, info_dict)",
        "snippet": "    def real_download(self, filename, info_dict):\n        \"\"\"Real download process. Redefine in subclasses.\"\"\"\n        raise NotImplementedError(u'This method must be implemented by subclasses')",
        "begin_line": 293,
        "end_line": 295,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader._hook_progress#297",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader._hook_progress(self, status)",
        "snippet": "    def _hook_progress(self, status):\n        for ph in self._progress_hooks:\n            ph(status)",
        "begin_line": 297,
        "end_line": 299,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006693440428380187,
            "pseudo_dstar_susp": 0.0009107468123861566,
            "pseudo_tarantula_susp": 0.0002447980416156671,
            "pseudo_op2_susp": 0.0009107468123861566,
            "pseudo_barinel_susp": 0.00024467824810374357
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.add_progress_hook#301",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.add_progress_hook(self, ph)",
        "snippet": "    def add_progress_hook(self, ph):\n        \"\"\" ph gets called on download progress, with a dictionary with the entries\n        * filename: The final filename\n        * status: One of \"downloading\" and \"finished\"\n\n        It can also have some of the following entries:\n\n        * downloaded_bytes: Bytes on disks\n        * total_bytes: Total bytes, None if unknown\n        * tmpfilename: The filename we're currently writing to\n        * eta: The estimated time in seconds, None if unknown\n        * speed: The download speed in bytes/second, None if unknown\n\n        Hooks are guaranteed to be called at least once (with status \"finished\")\n        if the download is successful.\n        \"\"\"\n        self._progress_hooks.append(ph)",
        "begin_line": 301,
        "end_line": 317,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011273957158962795,
            "pseudo_dstar_susp": 0.0015432098765432098,
            "pseudo_tarantula_susp": 0.0002627430373095113,
            "pseudo_op2_susp": 0.0015432098765432098,
            "pseudo_barinel_susp": 0.0002627430373095113
        }
    },
    {
        "name": "youtube_dl.extractor.novamov.NovaMovIE._real_extract#38",
        "src_path": "youtube_dl/extractor/novamov.py",
        "class_name": "youtube_dl.extractor.novamov.NovaMovIE",
        "signature": "youtube_dl.extractor.novamov.NovaMovIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        page = self._download_webpage(\n            'http://%s/video/%s' % (self._HOST, video_id), video_id, 'Downloading video page')\n\n        if re.search(self._FILE_DELETED_REGEX, page) is not None:\n            raise ExtractorError('Video %s does not exist' % video_id, expected=True)\n\n        filekey = self._search_regex(self._FILEKEY_REGEX, page, 'filekey')\n\n        title = self._html_search_regex(self._TITLE_REGEX, page, 'title', fatal=False)\n        description = self._html_search_regex(self._DESCRIPTION_REGEX, page, 'description', default='', fatal=False)\n\n        api_response = self._download_webpage(\n            'http://%s/api/player.api.php?key=%s&file=%s' % (self._HOST, filekey, video_id), video_id,\n            'Downloading video api response')\n\n        response = compat_urlparse.parse_qs(api_response)\n\n        if 'error_msg' in response:\n            raise ExtractorError('%s returned error: %s' % (self.IE_NAME, response['error_msg'][0]), expected=True)\n\n        video_url = response['url'][0]\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': description\n        }",
        "begin_line": 38,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009000900090009,
            "pseudo_dstar_susp": 0.0006983240223463687,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006983240223463687,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.wat.WatIE.download_video_info#43",
        "src_path": "youtube_dl/extractor/wat.py",
        "class_name": "youtube_dl.extractor.wat.WatIE",
        "signature": "youtube_dl.extractor.wat.WatIE.download_video_info(self, real_id)",
        "snippet": "    def download_video_info(self, real_id):\n        # 'contentv4' is used in the website, but it also returns the related\n        # videos, we don't need them\n        info = self._download_json('http://www.wat.tv/interface/contentv3/' + real_id, real_id)\n        return info['media']",
        "begin_line": 43,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.wat.WatIE._real_extract#49",
        "src_path": "youtube_dl/extractor/wat.py",
        "class_name": "youtube_dl.extractor.wat.WatIE",
        "signature": "youtube_dl.extractor.wat.WatIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        def real_id_for_chapter(chapter):\n            return chapter['tc_start'].split('-')[0]\n        mobj = re.match(self._VALID_URL, url)\n        short_id = mobj.group('short_id')\n        display_id = mobj.group('display_id')\n        webpage = self._download_webpage(url, display_id or short_id)\n        real_id = self._search_regex(r'xtpage = \".*-(.*?)\";', webpage, 'real id')\n\n        video_info = self.download_video_info(real_id)\n\n        geo_list = video_info.get('geoList')\n        country = geo_list[0] if geo_list else ''\n\n        chapters = video_info['chapters']\n        first_chapter = chapters[0]\n        files = video_info['files']\n        first_file = files[0]\n\n        if real_id_for_chapter(first_chapter) != real_id:\n            self.to_screen('Multipart video detected')\n            chapter_urls = []\n            for chapter in chapters:\n                chapter_id = real_id_for_chapter(chapter)\n                # Yes, when we this chapter is processed by WatIE,\n                # it will download the info again\n                chapter_info = self.download_video_info(chapter_id)\n                chapter_urls.append(chapter_info['url'])\n            entries = [self.url_result(chapter_url) for chapter_url in chapter_urls]\n            return self.playlist_result(entries, real_id, video_info['title'])\n\n        upload_date = None\n        if 'date_diffusion' in first_chapter:\n            upload_date = unified_strdate(first_chapter['date_diffusion'])\n        # Otherwise we can continue and extract just one part, we have to use\n        # the short id for getting the video url\n\n        formats = [{\n            'url': 'http://wat.tv/get/android5/%s.mp4' % real_id,\n            'format_id': 'Mobile',\n        }]\n\n        fmts = [('SD', 'web')]\n        if first_file.get('hasHD'):\n            fmts.append(('HD', 'webhd'))\n\n        def compute_token(param):\n            timestamp = '%08x' % int(self._download_webpage(\n                'http://www.wat.tv/servertime', real_id,\n                'Downloading server time').split('|')[0])\n            magic = '9b673b13fa4682ed14c3cfa5af5310274b514c4133e9b3a81e6e3aba009l2564'\n            return '%s/%s' % (hashlib.md5((magic + param + timestamp).encode('ascii')).hexdigest(), timestamp)\n\n        for fmt in fmts:\n            webid = '/%s/%s' % (fmt[1], real_id)\n            video_url = self._download_webpage(\n                'http://www.wat.tv/get%s?token=%s&getURL=1&country=%s' % (webid, compute_token(webid), country),\n                real_id,\n                'Downloding %s video URL' % fmt[0],\n                'Failed to download %s video URL' % fmt[0],\n                False)\n            if not video_url:\n                continue\n            formats.append({\n                'url': video_url,\n                'ext': 'mp4',\n                'format_id': fmt[0],\n            })\n\n        return {\n            'id': real_id,\n            'display_id': display_id,\n            'title': first_chapter['title'],\n            'thumbnail': first_chapter['preview'],\n            'description': first_chapter['description'],\n            'view_count': video_info['views'],\n            'upload_date': upload_date,\n            'duration': first_file['duration'],\n            'formats': formats,\n        }",
        "begin_line": 49,
        "end_line": 128,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.wat.WatIE.real_id_for_chapter#50",
        "src_path": "youtube_dl/extractor/wat.py",
        "class_name": "youtube_dl.extractor.wat.WatIE",
        "signature": "youtube_dl.extractor.wat.WatIE.real_id_for_chapter(chapter)",
        "snippet": "        def real_id_for_chapter(chapter):\n            return chapter['tc_start'].split('-')[0]",
        "begin_line": 50,
        "end_line": 51,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.youku.YoukuIE._gen_sid#28",
        "src_path": "youtube_dl/extractor/youku.py",
        "class_name": "youtube_dl.extractor.youku.YoukuIE",
        "signature": "youtube_dl.extractor.youku.YoukuIE._gen_sid(self)",
        "snippet": "    def _gen_sid(self):\n        nowTime = int(time.time() * 1000)\n        random1 = random.randint(1000,1998)\n        random2 = random.randint(1000,9999)\n\n        return \"%d%d%d\" %(nowTime,random1,random2)",
        "begin_line": 28,
        "end_line": 33,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.youku.YoukuIE._get_file_ID_mix_string#35",
        "src_path": "youtube_dl/extractor/youku.py",
        "class_name": "youtube_dl.extractor.youku.YoukuIE",
        "signature": "youtube_dl.extractor.youku.YoukuIE._get_file_ID_mix_string(self, seed)",
        "snippet": "    def _get_file_ID_mix_string(self, seed):\n        mixed = []\n        source = list(\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ/\\:._-1234567890\")\n        seed = float(seed)\n        for i in range(len(source)):\n            seed  =  (seed * 211 + 30031) % 65536\n            index  =  math.floor(seed / 65536 * len(source))\n            mixed.append(source[int(index)])\n            source.remove(source[int(index)])\n        #return ''.join(mixed)\n        return mixed",
        "begin_line": 35,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.youku.YoukuIE._get_file_id#47",
        "src_path": "youtube_dl/extractor/youku.py",
        "class_name": "youtube_dl.extractor.youku.YoukuIE",
        "signature": "youtube_dl.extractor.youku.YoukuIE._get_file_id(self, fileId, seed)",
        "snippet": "    def _get_file_id(self, fileId, seed):\n        mixed = self._get_file_ID_mix_string(seed)\n        ids = fileId.split('*')\n        realId = []\n        for ch in ids:\n            if ch:\n                realId.append(mixed[int(ch)])\n        return ''.join(realId)",
        "begin_line": 47,
        "end_line": 54,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.youku.YoukuIE._real_extract#56",
        "src_path": "youtube_dl/extractor/youku.py",
        "class_name": "youtube_dl.extractor.youku.YoukuIE",
        "signature": "youtube_dl.extractor.youku.YoukuIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        if mobj is None:\n            raise ExtractorError(u'Invalid URL: %s' % url)\n        video_id = mobj.group('ID')\n\n        info_url = 'http://v.youku.com/player/getPlayList/VideoIDS/' + video_id\n\n        jsondata = self._download_webpage(info_url, video_id)\n\n        self.report_extraction(video_id)\n        try:\n            config = json.loads(jsondata)\n            error_code = config['data'][0].get('error_code')\n            if error_code:\n                # -8 means blocked outside China.\n                error = config['data'][0].get('error')  # Chinese and English, separated by newline.\n                raise ExtractorError(error or u'Server reported error %i' % error_code,\n                    expected=True)\n\n            video_title =  config['data'][0]['title']\n            seed = config['data'][0]['seed']\n\n            format = self._downloader.params.get('format', None)\n            supported_format = list(config['data'][0]['streamfileids'].keys())\n\n            if format is None or format == 'best':\n                if 'hd2' in supported_format:\n                    format = 'hd2'\n                else:\n                    format = 'flv'\n                ext = u'flv'\n            elif format == 'worst':\n                format = 'mp4'\n                ext = u'mp4'\n            else:\n                format = 'flv'\n                ext = u'flv'\n\n\n            fileid = config['data'][0]['streamfileids'][format]\n            keys = [s['k'] for s in config['data'][0]['segs'][format]]\n            # segs is usually a dictionary, but an empty *list* if an error occured.\n        except (UnicodeDecodeError, ValueError, KeyError):\n            raise ExtractorError(u'Unable to extract info section')\n\n        files_info=[]\n        sid = self._gen_sid()\n        fileid = self._get_file_id(fileid, seed)\n\n        #column 8,9 of fileid represent the segment number\n        #fileid[7:9] should be changed\n        for index, key in enumerate(keys):\n\n            temp_fileid = '%s%02X%s' % (fileid[0:8], index, fileid[10:])\n            download_url = 'http://f.youku.com/player/getFlvPath/sid/%s_%02X/st/flv/fileid/%s?k=%s' % (sid, index, temp_fileid, key)\n\n            info = {\n                'id': '%s_part%02d' % (video_id, index),\n                'url': download_url,\n                'uploader': None,\n                'upload_date': None,\n                'title': video_title,\n                'ext': ext,\n            }\n            files_info.append(info)\n\n        return files_info",
        "begin_line": 56,
        "end_line": 123,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.aes.aes_ctr_decrypt#10",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.aes_ctr_decrypt(data, key, counter)",
        "snippet": "def aes_ctr_decrypt(data, key, counter):\n    \"\"\"\n    Decrypt with aes in counter mode\n    \n    @param {int[]} data        cipher\n    @param {int[]} key         16/24/32-Byte cipher key\n    @param {instance} counter  Instance whose next_value function (@returns {int[]}  16-Byte block)\n                               returns the next counter block\n    @returns {int[]}           decrypted data\n    \"\"\"\n    expanded_key = key_expansion(key)\n    block_count = int(ceil(float(len(data)) / BLOCK_SIZE_BYTES))\n    \n    decrypted_data=[]\n    for i in range(block_count):\n        counter_block = counter.next_value()\n        block = data[i*BLOCK_SIZE_BYTES : (i+1)*BLOCK_SIZE_BYTES]\n        block += [0]*(BLOCK_SIZE_BYTES - len(block))\n        \n        cipher_counter_block = aes_encrypt(counter_block, expanded_key)\n        decrypted_data += xor(block, cipher_counter_block)\n    decrypted_data = decrypted_data[:len(data)]\n    \n    return decrypted_data",
        "begin_line": 10,
        "end_line": 33,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.aes.aes_cbc_decrypt#35",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.aes_cbc_decrypt(data, key, iv)",
        "snippet": "def aes_cbc_decrypt(data, key, iv):\n    \"\"\"\n    Decrypt with aes in CBC mode\n    \n    @param {int[]} data        cipher\n    @param {int[]} key         16/24/32-Byte cipher key\n    @param {int[]} iv          16-Byte IV\n    @returns {int[]}           decrypted data\n    \"\"\"\n    expanded_key = key_expansion(key)\n    block_count = int(ceil(float(len(data)) / BLOCK_SIZE_BYTES))\n    \n    decrypted_data=[]\n    previous_cipher_block = iv\n    for i in range(block_count):\n        block = data[i*BLOCK_SIZE_BYTES : (i+1)*BLOCK_SIZE_BYTES]\n        block += [0]*(BLOCK_SIZE_BYTES - len(block))\n        \n        decrypted_block = aes_decrypt(block, expanded_key)\n        decrypted_data += xor(decrypted_block, previous_cipher_block)\n        previous_cipher_block = block\n    decrypted_data = decrypted_data[:len(data)]\n    \n    return decrypted_data",
        "begin_line": 35,
        "end_line": 58,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.aes.key_expansion#60",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.key_expansion(data)",
        "snippet": "def key_expansion(data):\n    \"\"\"\n    Generate key schedule\n    \n    @param {int[]} data  16/24/32-Byte cipher key\n    @returns {int[]}     176/208/240-Byte expanded key \n    \"\"\"\n    data = data[:] # copy\n    rcon_iteration = 1\n    key_size_bytes = len(data)\n    expanded_key_size_bytes = (key_size_bytes // 4 + 7) * BLOCK_SIZE_BYTES\n    \n    while len(data) < expanded_key_size_bytes:\n        temp = data[-4:]\n        temp = key_schedule_core(temp, rcon_iteration)\n        rcon_iteration += 1\n        data += xor(temp, data[-key_size_bytes : 4-key_size_bytes])\n        \n        for _ in range(3):\n            temp = data[-4:]\n            data += xor(temp, data[-key_size_bytes : 4-key_size_bytes])\n        \n        if key_size_bytes == 32:\n            temp = data[-4:]\n            temp = sub_bytes(temp)\n            data += xor(temp, data[-key_size_bytes : 4-key_size_bytes])\n        \n        for _ in range(3 if key_size_bytes == 32  else 2 if key_size_bytes == 24 else 0):\n            temp = data[-4:]\n            data += xor(temp, data[-key_size_bytes : 4-key_size_bytes])\n    data = data[:expanded_key_size_bytes]\n    \n    return data",
        "begin_line": 60,
        "end_line": 92,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.aes.aes_encrypt#94",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.aes_encrypt(data, expanded_key)",
        "snippet": "def aes_encrypt(data, expanded_key):\n    \"\"\"\n    Encrypt one block with aes\n    \n    @param {int[]} data          16-Byte state\n    @param {int[]} expanded_key  176/208/240-Byte expanded key \n    @returns {int[]}             16-Byte cipher\n    \"\"\"\n    rounds = len(expanded_key) // BLOCK_SIZE_BYTES - 1\n\n    data = xor(data, expanded_key[:BLOCK_SIZE_BYTES])\n    for i in range(1, rounds+1):\n        data = sub_bytes(data)\n        data = shift_rows(data)\n        if i != rounds:\n            data = mix_columns(data)\n        data = xor(data, expanded_key[i*BLOCK_SIZE_BYTES : (i+1)*BLOCK_SIZE_BYTES])\n\n    return data",
        "begin_line": 94,
        "end_line": 112,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.aes.aes_decrypt#114",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.aes_decrypt(data, expanded_key)",
        "snippet": "def aes_decrypt(data, expanded_key):\n    \"\"\"\n    Decrypt one block with aes\n    \n    @param {int[]} data          16-Byte cipher\n    @param {int[]} expanded_key  176/208/240-Byte expanded key\n    @returns {int[]}             16-Byte state\n    \"\"\"\n    rounds = len(expanded_key) // BLOCK_SIZE_BYTES - 1\n    \n    for i in range(rounds, 0, -1):\n        data = xor(data, expanded_key[i*BLOCK_SIZE_BYTES : (i+1)*BLOCK_SIZE_BYTES])\n        if i != rounds:\n            data = mix_columns_inv(data)\n        data = shift_rows_inv(data)\n        data = sub_bytes_inv(data)\n    data = xor(data, expanded_key[:BLOCK_SIZE_BYTES])\n    \n    return data",
        "begin_line": 114,
        "end_line": 132,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.aes.aes_decrypt_text#134",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.aes_decrypt_text(data, password, key_size_bytes)",
        "snippet": "def aes_decrypt_text(data, password, key_size_bytes):\n    \"\"\"\n    Decrypt text\n    - The first 8 Bytes of decoded 'data' are the 8 high Bytes of the counter\n    - The cipher key is retrieved by encrypting the first 16 Byte of 'password'\n      with the first 'key_size_bytes' Bytes from 'password' (if necessary filled with 0's)\n    - Mode of operation is 'counter'\n    \n    @param {str} data                    Base64 encoded string\n    @param {str,unicode} password        Password (will be encoded with utf-8)\n    @param {int} key_size_bytes          Possible values: 16 for 128-Bit, 24 for 192-Bit or 32 for 256-Bit\n    @returns {str}                       Decrypted data\n    \"\"\"\n    NONCE_LENGTH_BYTES = 8\n    \n    data = bytes_to_intlist(base64.b64decode(data))\n    password = bytes_to_intlist(password.encode('utf-8'))\n    \n    key = password[:key_size_bytes] + [0]*(key_size_bytes - len(password))\n    key = aes_encrypt(key[:BLOCK_SIZE_BYTES], key_expansion(key)) * (key_size_bytes // BLOCK_SIZE_BYTES)\n    \n    nonce = data[:NONCE_LENGTH_BYTES]\n    cipher = data[NONCE_LENGTH_BYTES:]\n    \n    class Counter:\n        __value = nonce + [0]*(BLOCK_SIZE_BYTES - NONCE_LENGTH_BYTES)\n        def next_value(self):\n            temp = self.__value\n            self.__value = inc(self.__value)\n            return temp\n    \n    decrypted_data = aes_ctr_decrypt(cipher, key, Counter())\n    plaintext = intlist_to_bytes(decrypted_data)\n    \n    return plaintext",
        "begin_line": 134,
        "end_line": 168,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.aes.sub_bytes#244",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.sub_bytes(data)",
        "snippet": "def sub_bytes(data):\n    return [SBOX[x] for x in data]",
        "begin_line": 244,
        "end_line": 245,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.aes.sub_bytes_inv#247",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.sub_bytes_inv(data)",
        "snippet": "def sub_bytes_inv(data):\n    return [SBOX_INV[x] for x in data]",
        "begin_line": 247,
        "end_line": 248,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.aes.rotate#250",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.rotate(data)",
        "snippet": "def rotate(data):\n    return data[1:] + [data[0]]",
        "begin_line": 250,
        "end_line": 251,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.aes.key_schedule_core#253",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.key_schedule_core(data, rcon_iteration)",
        "snippet": "def key_schedule_core(data, rcon_iteration):\n    data = rotate(data)\n    data = sub_bytes(data)\n    data[0] = data[0] ^ RCON[rcon_iteration]\n    \n    return data",
        "begin_line": 253,
        "end_line": 258,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.aes.xor#260",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.xor(data1, data2)",
        "snippet": "def xor(data1, data2):\n    return [x^y for x, y in zip(data1, data2)]",
        "begin_line": 260,
        "end_line": 261,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.aes.rijndael_mul#263",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.rijndael_mul(a, b)",
        "snippet": "def rijndael_mul(a, b):\n    if(a==0 or b==0):\n        return 0\n    return RIJNDAEL_EXP_TABLE[(RIJNDAEL_LOG_TABLE[a] + RIJNDAEL_LOG_TABLE[b]) % 0xFF]",
        "begin_line": 263,
        "end_line": 266,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.aes.mix_column#268",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.mix_column(data, matrix)",
        "snippet": "def mix_column(data, matrix):\n    data_mixed = []\n    for row in range(4):\n        mixed = 0\n        for column in range(4):\n            # xor is (+) and (-)\n            mixed ^= rijndael_mul(data[column], matrix[row][column])\n        data_mixed.append(mixed)\n    return data_mixed",
        "begin_line": 268,
        "end_line": 276,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.aes.mix_columns#278",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.mix_columns(data, matrix=MIX_COLUMN_MATRIX)",
        "snippet": "def mix_columns(data, matrix=MIX_COLUMN_MATRIX):\n    data_mixed = []\n    for i in range(4):\n        column = data[i*4 : (i+1)*4]\n        data_mixed += mix_column(column, matrix)\n    return data_mixed",
        "begin_line": 278,
        "end_line": 283,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.aes.mix_columns_inv#285",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.mix_columns_inv(data)",
        "snippet": "def mix_columns_inv(data):\n    return mix_columns(data, MIX_COLUMN_MATRIX_INV)",
        "begin_line": 285,
        "end_line": 286,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.aes.shift_rows#288",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.shift_rows(data)",
        "snippet": "def shift_rows(data):\n    data_shifted = []\n    for column in range(4):\n        for row in range(4):\n            data_shifted.append( data[((column + row) & 0b11) * 4 + row] )\n    return data_shifted",
        "begin_line": 288,
        "end_line": 293,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.aes.shift_rows_inv#295",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.shift_rows_inv(data)",
        "snippet": "def shift_rows_inv(data):\n    data_shifted = []\n    for column in range(4):\n        for row in range(4):\n            data_shifted.append( data[((column - row) & 0b11) * 4 + row] )\n    return data_shifted",
        "begin_line": 295,
        "end_line": 300,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.aes.inc#302",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.inc(data)",
        "snippet": "def inc(data):\n    data = data[:] # copy\n    for i in range(len(data)-1,-1,-1):\n        if data[i] == 255:\n            data[i] = 0\n        else:\n            data[i] = data[i] + 1\n            break\n    return data",
        "begin_line": 302,
        "end_line": 310,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.cinemassacre.CinemassacreIE._real_extract#39",
        "src_path": "youtube_dl/extractor/cinemassacre.py",
        "class_name": "youtube_dl.extractor.cinemassacre.CinemassacreIE",
        "signature": "youtube_dl.extractor.cinemassacre.CinemassacreIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id)\n        video_date = mobj.group('date_Y') + mobj.group('date_m') + mobj.group('date_d')\n        mobj = re.search(r'src=\"(?P<embed_url>http://player\\.screenwavemedia\\.com/play/[a-zA-Z]+\\.php\\?id=(?:Cinemassacre-)?(?P<video_id>.+?))\"', webpage)\n        if not mobj:\n            raise ExtractorError('Can\\'t extract embed url and video id')\n        playerdata_url = mobj.group('embed_url')\n        video_id = mobj.group('video_id')\n\n        video_title = self._html_search_regex(\n            r'<title>(?P<title>.+?)\\|', webpage, 'title')\n        video_description = self._html_search_regex(\n            r'<div class=\"entry-content\">(?P<description>.+?)</div>',\n            webpage, 'description', flags=re.DOTALL, fatal=False)\n\n        playerdata = self._download_webpage(playerdata_url, video_id, 'Downloading player webpage')\n        video_thumbnail = self._search_regex(\n            r'image: \\'(?P<thumbnail>[^\\']+)\\'', playerdata, 'thumbnail', fatal=False)\n        sd_url = self._search_regex(r'file: \\'([^\\']+)\\', label: \\'SD\\'', playerdata, 'sd_file')\n        videolist_url = self._search_regex(r'file: \\'([^\\']+\\.smil)\\'}', playerdata, 'videolist_url')\n\n        videolist = self._download_xml(videolist_url, video_id, 'Downloading videolist XML')\n\n        formats = []\n        baseurl = sd_url[:sd_url.rfind('/')+1]\n        for video in videolist.findall('.//video'):\n            src = video.get('src')\n            if not src:\n                continue\n            file_ = src.partition(':')[-1]\n            width = int_or_none(video.get('width'))\n            height = int_or_none(video.get('height'))\n            bitrate = int_or_none(video.get('system-bitrate'))\n            format = {\n                'url': baseurl + file_,\n                'format_id': src.rpartition('.')[0].rpartition('_')[-1],\n            }\n            if width or height:\n                format.update({\n                    'tbr': bitrate // 1000 if bitrate else None,\n                    'width': width,\n                    'height': height,\n                })\n            else:\n                format.update({\n                    'abr': bitrate // 1000 if bitrate else None,\n                    'vcodec': 'none',\n                })\n            formats.append(format)\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'formats': formats,\n            'description': video_description,\n            'upload_date': video_date,\n            'thumbnail': video_thumbnail,\n        }",
        "begin_line": 39,
        "end_line": 100,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.goshgay.GoshgayIE._real_extract#29",
        "src_path": "youtube_dl/extractor/goshgay.py",
        "class_name": "youtube_dl.extractor.goshgay.GoshgayIE",
        "signature": "youtube_dl.extractor.goshgay.GoshgayIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        title = self._search_regex(r'class=\"video-title\"><h1>(.+?)<', webpage, 'title')\n\n        player_config = self._search_regex(\n            r'(?s)jwplayer\\(\"player\"\\)\\.setup\\(({.+?})\\)', webpage, 'config settings')\n        player_vars = json.loads(player_config.replace(\"'\", '\"'))\n        width = str_to_int(player_vars.get('width'))\n        height = str_to_int(player_vars.get('height'))\n        config_uri = player_vars.get('config')\n\n        if config_uri is None:\n            raise ExtractorError('Missing config URI')\n        node = self._download_xml(config_uri, video_id, 'Downloading player config XML',\n                                  errnote='Unable to download XML')\n        if node is None:\n            raise ExtractorError('Missing config XML')\n        if node.tag != 'config':\n            raise ExtractorError('Missing config attribute')\n        fns = node.findall('file')\n        imgs = node.findall('image')\n        if len(fns) != 1:\n            raise ExtractorError('Missing media URI')\n        video_url = fns[0].text\n        if len(imgs) < 1:\n            thumbnail = None\n        else:\n            thumbnail = imgs[0].text\n\n        url_comp = compat_urlparse.urlparse(url)\n        ref = \"%s://%s%s\" % (url_comp[0], url_comp[1], url_comp[2])\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'width': width,\n            'height': height,\n            'thumbnail': thumbnail,\n            'http_referer': ref,\n            'age_limit': 18,\n        }",
        "begin_line": 29,
        "end_line": 73,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.ndr.NDRIE._real_extract#46",
        "src_path": "youtube_dl/extractor/ndr.py",
        "class_name": "youtube_dl.extractor.ndr.NDRIE",
        "signature": "youtube_dl.extractor.ndr.NDRIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        page = self._download_webpage(url, video_id, 'Downloading page')\n\n        title = self._og_search_title(page).strip()\n        description = self._og_search_description(page)\n        if description:\n            description = description.strip()\n\n        duration = int_or_none(self._html_search_regex(r'duration: (\\d+),\\n', page, 'duration', fatal=False))\n\n        formats = []\n\n        mp3_url = re.search(r'''\\{src:'(?P<audio>[^']+)', type:\"audio/mp3\"},''', page)\n        if mp3_url:\n            formats.append({\n                'url': mp3_url.group('audio'),\n                'format_id': 'mp3',\n            })\n\n        thumbnail = None\n\n        video_url = re.search(r'''3: \\{src:'(?P<video>.+?)\\.hi\\.mp4', type:\"video/mp4\"},''', page)\n        if video_url:\n            thumbnails = re.findall(r'''\\d+: \\{src: \"([^\"]+)\"(?: \\|\\| '[^']+')?, quality: '([^']+)'}''', page)\n            if thumbnails:\n                quality_key = qualities(['xs', 's', 'm', 'l', 'xl'])\n                largest = max(thumbnails, key=lambda thumb: quality_key(thumb[1]))\n                thumbnail = 'http://www.ndr.de' + largest[0]\n\n            for format_id in 'lo', 'hi', 'hq':\n                formats.append({\n                    'url': '%s.%s.mp4' % (video_url.group('video'), format_id),\n                    'format_id': format_id,\n                })\n\n        if not formats:\n            raise ExtractorError('No media links available for %s' % video_id)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 46,
        "end_line": 94,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.izlesene.IzleseneIE._real_extract#57",
        "src_path": "youtube_dl/extractor/izlesene.py",
        "class_name": "youtube_dl.extractor.izlesene.IzleseneIE",
        "signature": "youtube_dl.extractor.izlesene.IzleseneIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        url = 'http://www.izlesene.com/video/%s' % video_id\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        uploader = self._html_search_regex(\n            r\"adduserUsername\\s*=\\s*'([^']+)';\",\n            webpage, 'uploader', fatal=False, default='')\n        timestamp = parse_iso8601(self._html_search_meta(\n            'uploadDate', webpage, 'upload date', fatal=False))\n\n        duration = float_or_none(self._html_search_regex(\n            r'\"videoduration\"\\s*:\\s*\"([^\"]+)\"',\n            webpage, 'duration', fatal=False), scale=1000)\n\n        view_count = str_to_int(get_element_by_id('videoViewCount', webpage))\n        comment_count = self._html_search_regex(\n            r'comment_count\\s*=\\s*\\'([^\\']+)\\';',\n            webpage, 'comment_count', fatal=False)\n\n        family_friendly = self._html_search_meta(\n            'isFamilyFriendly', webpage, 'age limit', fatal=False)\n\n        content_url = self._html_search_meta(\n            'contentURL', webpage, 'content URL', fatal=False)\n        ext = determine_ext(content_url, 'mp4')\n\n        # Might be empty for some videos.\n        streams = self._html_search_regex(\n            r'\"qualitylevel\"\\s*:\\s*\"([^\"]+)\"',\n            webpage, 'streams', fatal=False, default='')\n\n        formats = []\n        if streams:\n            for stream in streams.split('|'):\n                quality, url = re.search(r'\\[(\\w+)\\](.+)', stream).groups()\n                formats.append({\n                    'format_id': '%sp' % quality if quality else 'sd',\n                    'url': url,\n                    'ext': ext,\n                })\n        else:\n            stream_url = self._search_regex(\n                r'\"streamurl\"\\s?:\\s?\"([^\"]+)\"', webpage, 'stream URL')\n            formats.append({\n                'format_id': 'sd',\n                'url': stream_url,\n                'ext': ext,\n            })\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader_id': uploader,\n            'timestamp': timestamp,\n            'duration': duration,\n            'view_count': int_or_none(view_count),\n            'comment_count': int_or_none(comment_count),\n            'age_limit': 18 if family_friendly == 'False' else 0,\n            'formats': formats,\n        }",
        "begin_line": 57,
        "end_line": 125,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.canal13cl.Canal13clIE._real_extract#23",
        "src_path": "youtube_dl/extractor/canal13cl.py",
        "class_name": "youtube_dl.extractor.canal13cl.Canal13clIE",
        "signature": "youtube_dl.extractor.canal13cl.Canal13clIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        title = self._html_search_meta(\n            'twitter:title', webpage, 'title', fatal=True)\n        description = self._html_search_meta(\n            'twitter:description', webpage, 'description')\n        url = self._html_search_regex(\n            r'articuloVideo = \\\"(.*?)\\\"', webpage, 'url')\n        real_id = self._search_regex(\n            r'[^0-9]([0-9]{7,})[^0-9]', url, 'id', default=display_id)\n        thumbnail = self._html_search_regex(\n            r'articuloImagen = \\\"(.*?)\\\"', webpage, 'thumbnail')\n\n        return {\n            'id': real_id,\n            'display_id': display_id,\n            'url': url,\n            'title': title,\n            'description': description,\n            'ext': 'mp4',\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 23,
        "end_line": 48,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.parliamentliveuk.ParliamentLiveUKIE._real_extract#26",
        "src_path": "youtube_dl/extractor/parliamentliveuk.py",
        "class_name": "youtube_dl.extractor.parliamentliveuk.ParliamentLiveUKIE",
        "signature": "youtube_dl.extractor.parliamentliveuk.ParliamentLiveUKIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n\n        asx_url = self._html_search_regex(\n            r'embed.*?src=\"([^\"]+)\" name=\"MediaPlayer\"', webpage,\n            'metadata URL')\n        asx = self._download_xml(asx_url, video_id, 'Downloading ASX metadata')\n        video_url = asx.find('.//REF').attrib['HREF']\n\n        title = self._search_regex(\n            r'''(?x)player\\.setClipDetails\\(\n                (?:(?:[0-9]+|\"[^\"]+\"),\\s*){2}\n                \"([^\"]+\",\\s*\"[^\"]+)\"\n                ''',\n            webpage, 'title').replace('\", \"', ', ')\n        description = self._html_search_regex(\n            r'(?s)<span id=\"MainContentPlaceHolder_CaptionsBlock_WitnessInfo\">(.*?)</span>',\n            webpage, 'description')\n\n        return {\n            'id': video_id,\n            'ext': 'asf',\n            'url': video_url,\n            'title': title,\n            'description': description,\n        }",
        "begin_line": 26,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.downloader.__init__.get_suitable_downloader#15",
        "src_path": "youtube_dl/downloader/__init__.py",
        "class_name": "youtube_dl.downloader.__init__",
        "signature": "youtube_dl.downloader.__init__.get_suitable_downloader(info_dict)",
        "snippet": "def get_suitable_downloader(info_dict):\n    \"\"\"Get the downloader class that can handle the info dict.\"\"\"\n    url = info_dict['url']\n    protocol = info_dict.get('protocol')\n\n    if url.startswith('rtmp'):\n        return RtmpFD\n    if (protocol == 'm3u8') or (protocol is None and determine_ext(url) == 'm3u8'):\n        return HlsFD\n    if url.startswith('mms') or url.startswith('rtsp'):\n        return MplayerFD\n    if determine_ext(url) == 'f4m':\n        return F4mFD\n    else:\n        return HttpFD",
        "begin_line": 15,
        "end_line": 29,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011273957158962795,
            "pseudo_dstar_susp": 0.0015432098765432098,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0015432098765432098,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.slutload.SlutloadIE._real_extract#22",
        "src_path": "youtube_dl/extractor/slutload.py",
        "class_name": "youtube_dl.extractor.slutload.SlutloadIE",
        "signature": "youtube_dl.extractor.slutload.SlutloadIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_title = self._html_search_regex(r'<h1><strong>([^<]+)</strong>',\n            webpage, 'title').strip()\n\n        video_url = self._html_search_regex(\n            r'(?s)<div id=\"vidPlayer\"\\s+data-url=\"([^\"]+)\"',\n            webpage, 'video URL')\n        thumbnail = self._html_search_regex(\n            r'(?s)<div id=\"vidPlayer\"\\s+.*?previewer-file=\"([^\"]+)\"',\n            webpage, 'thumbnail', fatal=False)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': video_title,\n            'thumbnail': thumbnail,\n            'age_limit': 18\n        }",
        "begin_line": 22,
        "end_line": 44,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.fivemin.FiveMinIE._build_result#45",
        "src_path": "youtube_dl/extractor/fivemin.py",
        "class_name": "youtube_dl.extractor.fivemin.FiveMinIE",
        "signature": "youtube_dl.extractor.fivemin.FiveMinIE._build_result(cls, video_id)",
        "snippet": "    def _build_result(cls, video_id):\n        return cls.url_result('5min:%s' % video_id, cls.ie_key())",
        "begin_line": 45,
        "end_line": 46,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.fivemin.FiveMinIE._real_extract#48",
        "src_path": "youtube_dl/extractor/fivemin.py",
        "class_name": "youtube_dl.extractor.fivemin.FiveMinIE",
        "signature": "youtube_dl.extractor.fivemin.FiveMinIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        embed_url = 'https://embed.5min.com/playerseed/?playList=%s' % video_id\n        embed_page = self._download_webpage(embed_url, video_id,\n            'Downloading embed page')\n        sid = self._search_regex(r'sid=(\\d+)', embed_page, 'sid')\n        query = compat_urllib_parse.urlencode({\n            'func': 'GetResults',\n            'playlist': video_id,\n            'sid': sid,\n            'isPlayerSeed': 'true',\n            'url': embed_url,\n        })\n        response = self._download_json(\n            'https://syn.5min.com/handlers/SenseHandler.ashx?' + query,\n            video_id)\n        if not response['success']:\n            err_msg = response['errorMessage']\n            if err_msg == 'ErrorVideoUserNotGeo':\n                msg = 'Video not available from your location'\n            else:\n                msg = 'Aol said: %s' % err_msg\n            raise ExtractorError(msg, expected=True, video_id=video_id)\n        info = response['binding'][0]\n\n        second_id = compat_str(int(video_id[:-2]) + 1)\n        formats = []\n        for quality, height in [(1, 320), (2, 480), (4, 720), (8, 1080)]:\n            if any(r['ID'] == quality for r in info['Renditions']):\n                formats.append({\n                    'format_id': compat_str(quality),\n                    'url': 'http://avideos.5min.com/%s/%s/%s_%s.mp4' % (second_id[-3:], second_id, video_id, quality),\n                    'height': height,\n                })\n\n        return {\n            'id': video_id,\n            'title': info['Title'],\n            'formats': formats,\n        }",
        "begin_line": 48,
        "end_line": 88,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009000900090009,
            "pseudo_dstar_susp": 0.0006983240223463687,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006983240223463687,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.slideshare.SlideshareIE._real_extract#26",
        "src_path": "youtube_dl/extractor/slideshare.py",
        "class_name": "youtube_dl.extractor.slideshare.SlideshareIE",
        "signature": "youtube_dl.extractor.slideshare.SlideshareIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        page_title = mobj.group('title')\n        webpage = self._download_webpage(url, page_title)\n        slideshare_obj = self._search_regex(\n            r'var slideshare_object =  ({.*?}); var user_info =',\n            webpage, 'slideshare object')\n        info = json.loads(slideshare_obj)\n        if info['slideshow']['type'] != 'video':\n            raise ExtractorError('Webpage type is \"%s\": only video extraction is supported for Slideshare' % info['slideshow']['type'], expected=True)\n\n        doc = info['doc']\n        bucket = info['jsplayer']['video_bucket']\n        ext = info['jsplayer']['video_extension']\n        video_url = compat_urlparse.urljoin(bucket, doc + '-SD.' + ext)\n        description = self._html_search_regex(\n            r'<p\\s+(?:style=\"[^\"]*\"\\s+)?class=\"description.*?\"[^>]*>(.*?)</p>', webpage,\n            'description', fatal=False)\n\n        return {\n            '_type': 'video',\n            'id': info['slideshow']['id'],\n            'title': info['slideshow']['title'],\n            'ext': ext,\n            'url': video_url,\n            'thumbnail': info['slideshow']['pin_image_url'],\n            'description': description,\n        }",
        "begin_line": 26,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.nuvid.NuvidIE._real_extract#28",
        "src_path": "youtube_dl/extractor/nuvid.py",
        "class_name": "youtube_dl.extractor.nuvid.NuvidIE",
        "signature": "youtube_dl.extractor.nuvid.NuvidIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        formats = []\n\n        for dwnld_speed, format_id in [(0, '3gp'), (5, 'mp4')]:\n            request = compat_urllib_request.Request(\n                'http://m.nuvid.com/play/%s' % video_id)\n            request.add_header('Cookie', 'skip_download_page=1; dwnld_speed=%d; adv_show=1' % dwnld_speed)\n            webpage = self._download_webpage(\n                request, video_id, 'Downloading %s page' % format_id)\n            video_url = self._html_search_regex(\n                r'<a\\s+href=\"([^\"]+)\"\\s+class=\"b_link\">', webpage, '%s video URL' % format_id, fatal=False)\n            if not video_url:\n                continue\n            formats.append({\n                'url': video_url,\n                'format_id': format_id,\n            })\n\n        webpage = self._download_webpage(\n            'http://m.nuvid.com/video/%s' % video_id, video_id, 'Downloading video page')\n        title = self._html_search_regex(\n            [r'<span title=\"([^\"]+)\">',\n             r'<div class=\"thumb-holder video\">\\s*<h5[^>]*>([^<]+)</h5>'], webpage, 'title').strip()\n        thumbnails = [\n            {\n                'url': thumb_url,\n            } for thumb_url in re.findall(r'<img src=\"([^\"]+)\" alt=\"\" />', webpage)\n        ]\n        thumbnail = thumbnails[0]['url'] if thumbnails else None\n        duration = parse_duration(self._html_search_regex(\n            r'<i class=\"fa fa-clock-o\"></i>\\s*(\\d{2}:\\d{2})', webpage, 'duration', fatal=False))\n        upload_date = unified_strdate(self._html_search_regex(\n            r'<i class=\"fa fa-user\"></i>\\s*(\\d{4}-\\d{2}-\\d{2})', webpage, 'upload date', fatal=False))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnails': thumbnails,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'upload_date': upload_date,\n            'age_limit': 18,\n            'formats': formats,\n        }",
        "begin_line": 28,
        "end_line": 74,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.teamcoco.TeamcocoIE._real_extract#31",
        "src_path": "youtube_dl/extractor/teamcoco.py",
        "class_name": "youtube_dl.extractor.teamcoco.TeamcocoIE",
        "signature": "youtube_dl.extractor.teamcoco.TeamcocoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        display_id = mobj.group('display_id')\n        webpage = self._download_webpage(url, display_id)\n        \n        video_id = mobj.group(\"video_id\")\n        if not video_id:\n            video_id = self._html_search_regex(\n                r'data-node-id=\"(\\d+?)\"',\n                webpage, 'video id')\n\n        data_url = 'http://teamcoco.com/cvp/2.0/%s.xml' % video_id\n        data = self._download_xml(\n            data_url, display_id, 'Downloading data webpage')\n\n        qualities = ['500k', '480p', '1000k', '720p', '1080p']\n        formats = []\n        for filed in data.findall('files/file'):\n            if filed.attrib.get('playmode') == 'all':\n                # it just duplicates one of the entries\n                break\n            file_url = filed.text\n            m_format = re.search(r'(\\d+(k|p))\\.mp4', file_url)\n            if m_format is not None:\n                format_id = m_format.group(1)\n            else:\n                format_id = filed.attrib['bitrate']\n            tbr = (\n                int(filed.attrib['bitrate'])\n                if filed.attrib['bitrate'].isdigit()\n                else None)\n\n            try:\n                quality = qualities.index(format_id)\n            except ValueError:\n                quality = -1\n            formats.append({\n                'url': file_url,\n                'ext': 'mp4',\n                'tbr': tbr,\n                'format_id': format_id,\n                'quality': quality,\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'formats': formats,\n            'title': self._og_search_title(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'description': self._og_search_description(webpage),\n        }",
        "begin_line": 31,
        "end_line": 85,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.dreisat.DreiSatIE._real_extract#25",
        "src_path": "youtube_dl/extractor/dreisat.py",
        "class_name": "youtube_dl.extractor.dreisat.DreiSatIE",
        "signature": "youtube_dl.extractor.dreisat.DreiSatIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        details_url = 'http://www.3sat.de/mediathek/xmlservice/web/beitragsDetails?ak=web&id=%s' % video_id\n        details_doc = self._download_xml(details_url, video_id, 'Downloading video details')\n\n        thumbnail_els = details_doc.findall('.//teaserimage')\n        thumbnails = [{\n            'width': int(te.attrib['key'].partition('x')[0]),\n            'height': int(te.attrib['key'].partition('x')[2]),\n            'url': te.text,\n        } for te in thumbnail_els]\n\n        information_el = details_doc.find('.//information')\n        video_title = information_el.find('./title').text\n        video_description = information_el.find('./detail').text\n\n        details_el = details_doc.find('.//details')\n        video_uploader = details_el.find('./channel').text\n        upload_date = unified_strdate(details_el.find('./airtime').text)\n\n        format_els = details_doc.findall('.//formitaet')\n        formats = [{\n            'format_id': fe.attrib['basetype'],\n            'width': int(fe.find('./width').text),\n            'height': int(fe.find('./height').text),\n            'url': fe.find('./url').text,\n            'filesize': int(fe.find('./filesize').text),\n            'video_bitrate': int(fe.find('./videoBitrate').text),\n        } for fe in format_els\n            if not fe.find('./url').text.startswith('http://www.metafilegenerator.de/')]\n\n        self._sort_formats(formats)\n\n        return {\n            '_type': 'video',\n            'id': video_id,\n            'title': video_title,\n            'formats': formats,\n            'description': video_description,\n            'thumbnails': thumbnails,\n            'thumbnail': thumbnails[-1]['url'],\n            'uploader': video_uploader,\n            'upload_date': upload_date,\n        }",
        "begin_line": 25,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.collegehumor.CollegeHumorIE._real_extract#56",
        "src_path": "youtube_dl/extractor/collegehumor.py",
        "class_name": "youtube_dl.extractor.collegehumor.CollegeHumorIE",
        "signature": "youtube_dl.extractor.collegehumor.CollegeHumorIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n\n        jsonUrl = 'http://www.collegehumor.com/moogaloop/video/' + video_id + '.json'\n        data = json.loads(self._download_webpage(\n            jsonUrl, video_id, 'Downloading info JSON'))\n        vdata = data['video']\n        if vdata.get('youtubeId') is not None:\n            return {\n                '_type': 'url',\n                'url': vdata['youtubeId'],\n                'ie_key': 'Youtube',\n            }\n\n        AGE_LIMITS = {'nc17': 18, 'r': 18, 'pg13': 13, 'pg': 10, 'g': 0}\n        rating = vdata.get('rating')\n        if rating:\n            age_limit = AGE_LIMITS.get(rating.lower())\n        else:\n            age_limit = None  # None = No idea\n\n        PREFS = {'high_quality': 2, 'low_quality': 0}\n        formats = []\n        for format_key in ('mp4', 'webm'):\n            for qname, qurl in vdata.get(format_key, {}).items():\n                formats.append({\n                    'format_id': format_key + '_' + qname,\n                    'url': qurl,\n                    'format': format_key,\n                    'preference': PREFS.get(qname),\n                })\n        self._sort_formats(formats)\n\n        duration = int_or_none(vdata.get('duration'), 1000)\n        like_count = int_or_none(vdata.get('likes'))\n\n        return {\n            'id': video_id,\n            'title': vdata['title'],\n            'description': vdata.get('description'),\n            'thumbnail': vdata.get('thumbnail'),\n            'formats': formats,\n            'age_limit': age_limit,\n            'duration': duration,\n            'like_count': like_count,\n        }",
        "begin_line": 56,
        "end_line": 102,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007692307692307692,
            "pseudo_dstar_susp": 0.0006273525721455458,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006273525721455458,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.myvideo.MyVideoIE.__rc4crypt#35",
        "src_path": "youtube_dl/extractor/myvideo.py",
        "class_name": "youtube_dl.extractor.myvideo.MyVideoIE",
        "signature": "youtube_dl.extractor.myvideo.MyVideoIE.__rc4crypt(self, data, key)",
        "snippet": "    def __rc4crypt(self,data, key):\n        x = 0\n        box = list(range(256))\n        for i in list(range(256)):\n            x = (x + box[i] + compat_ord(key[i % len(key)])) % 256\n            box[i], box[x] = box[x], box[i]\n        x = 0\n        y = 0\n        out = ''\n        for char in data:\n            x = (x + 1) % 256\n            y = (y + box[x]) % 256\n            box[x], box[y] = box[y], box[x]\n            out += chr(compat_ord(char) ^ box[(box[x] + box[y]) % 256])\n        return out",
        "begin_line": 35,
        "end_line": 49,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.myvideo.MyVideoIE.__md5#51",
        "src_path": "youtube_dl/extractor/myvideo.py",
        "class_name": "youtube_dl.extractor.myvideo.MyVideoIE",
        "signature": "youtube_dl.extractor.myvideo.MyVideoIE.__md5(self, s)",
        "snippet": "    def __md5(self,s):\n        return hashlib.md5(s).hexdigest().encode()",
        "begin_line": 51,
        "end_line": 52,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.myvideo.MyVideoIE._real_extract#54",
        "src_path": "youtube_dl/extractor/myvideo.py",
        "class_name": "youtube_dl.extractor.myvideo.MyVideoIE",
        "signature": "youtube_dl.extractor.myvideo.MyVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self,url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        GK = (\n          b'WXpnME1EZGhNRGhpTTJNM01XVmhOREU0WldNNVpHTTJOakpt'\n          b'TW1FMU5tVTBNR05pWkRaa05XRXhNVFJoWVRVd1ptSXhaVEV3'\n          b'TnpsbA0KTVRkbU1tSTRNdz09'\n        )\n\n        # Get video webpage\n        webpage_url = 'http://www.myvideo.de/watch/%s' % video_id\n        webpage = self._download_webpage(webpage_url, video_id)\n\n        mobj = re.search('source src=\\'(.+?)[.]([^.]+)\\'', webpage)\n        if mobj is not None:\n            self.report_extraction(video_id)\n            video_url = mobj.group(1) + '.flv'\n\n            video_title = self._html_search_regex('<title>([^<]+)</title>',\n                webpage, 'title')\n\n            return {\n                'id': video_id,\n                'url': video_url,\n                'title': video_title,\n            }\n\n        mobj = re.search(r'data-video-service=\"/service/data/video/%s/config' % video_id, webpage)\n        if mobj is not None:\n            request = compat_urllib_request.Request('http://www.myvideo.de/service/data/video/%s/config' % video_id, '')\n            response = self._download_webpage(request, video_id,\n                                              'Downloading video info')\n            info = json.loads(base64.b64decode(response).decode('utf-8'))\n            return {\n                'id': video_id,\n                'title': info['title'],\n                'url': info['streaming_url'].replace('rtmpe', 'rtmpt'),\n                'play_path': info['filename'],\n                'ext': 'flv',\n                'thumbnail': info['thumbnail'][0]['url'],\n            }\n\n        # try encxml\n        mobj = re.search('var flashvars={(.+?)}', webpage)\n        if mobj is None:\n            raise ExtractorError('Unable to extract video')\n\n        params = {}\n        encxml = ''\n        sec = mobj.group(1)\n        for (a, b) in re.findall('(.+?):\\'(.+?)\\',?', sec):\n            if not a == '_encxml':\n                params[a] = b\n            else:\n                encxml = compat_urllib_parse.unquote(b)\n        if not params.get('domain'):\n            params['domain'] = 'www.myvideo.de'\n        xmldata_url = '%s?%s' % (encxml, compat_urllib_parse.urlencode(params))\n        if 'flash_playertype=MTV' in xmldata_url:\n            self._downloader.report_warning('avoiding MTV player')\n            xmldata_url = (\n                'http://www.myvideo.de/dynamic/get_player_video_xml.php'\n                '?flash_playertype=D&ID=%s&_countlimit=4&autorun=yes'\n            ) % video_id\n\n        # get enc data\n        enc_data = self._download_webpage(xmldata_url, video_id).split('=')[1]\n        enc_data_b = binascii.unhexlify(enc_data)\n        sk = self.__md5(\n            base64.b64decode(base64.b64decode(GK)) +\n            self.__md5(\n                str(video_id).encode('utf-8')\n            )\n        )\n        dec_data = self.__rc4crypt(enc_data_b, sk)\n\n        # extracting infos\n        self.report_extraction(video_id)\n\n        video_url = None\n        mobj = re.search('connectionurl=\\'(.*?)\\'', dec_data)\n        if mobj:\n            video_url = compat_urllib_parse.unquote(mobj.group(1))\n            if 'myvideo2flash' in video_url:\n                self.report_warning(\n                    'Rewriting URL to use unencrypted rtmp:// ...',\n                    video_id)\n                video_url = video_url.replace('rtmpe://', 'rtmp://')\n\n        if not video_url:\n            # extract non rtmp videos\n            mobj = re.search('path=\\'(http.*?)\\' source=\\'(.*?)\\'', dec_data)\n            if mobj is None:\n                raise ExtractorError('unable to extract url')\n            video_url = compat_urllib_parse.unquote(mobj.group(1)) + compat_urllib_parse.unquote(mobj.group(2))\n\n        video_file = self._search_regex('source=\\'(.*?)\\'', dec_data, 'video file')\n        video_file = compat_urllib_parse.unquote(video_file)\n\n        if not video_file.endswith('f4m'):\n            ppath, prefix = video_file.split('.')\n            video_playpath = '%s:%s' % (prefix, ppath)\n        else:\n            video_playpath = ''\n\n        video_swfobj = self._search_regex('swfobject.embedSWF\\(\\'(.+?)\\'', webpage, 'swfobj')\n        video_swfobj = compat_urllib_parse.unquote(video_swfobj)\n\n        video_title = self._html_search_regex(\"<h1(?: class='globalHd')?>(.*?)</h1>\",\n            webpage, 'title')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'tc_url': video_url,\n            'title': video_title,\n            'ext': 'flv',\n            'play_path': video_playpath,\n            'player_url': video_swfobj,\n        }",
        "begin_line": 54,
        "end_line": 174,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.playfm.PlayFMIE._real_extract#36",
        "src_path": "youtube_dl/extractor/playfm.py",
        "class_name": "youtube_dl.extractor.playfm.PlayFMIE",
        "signature": "youtube_dl.extractor.playfm.PlayFMIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        upload_date = mobj.group('upload_date')\n\n        rec_data = compat_urllib_parse.urlencode({'rec_id': video_id})\n        req = compat_urllib_request.Request(\n            'http://www.play.fm/flexRead/recording', data=rec_data)\n        req.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        rec_doc = self._download_xml(req, video_id)\n\n        error_node = rec_doc.find('./error')\n        if error_node is not None:\n            raise ExtractorError('An error occured: %s (code %s)' % (\n                error_node.text, rec_doc.find('./status').text))\n\n        recording = rec_doc.find('./recording')\n        title = recording.find('./title').text\n        view_count = int_or_none(recording.find('./stats/playcount').text)\n        duration = float_or_none(recording.find('./duration').text, scale=1000)\n        thumbnail = recording.find('./image').text\n\n        artist = recording.find('./artists/artist')\n        uploader = artist.find('./name').text\n        uploader_id = artist.find('./slug').text\n\n        video_url = '%s//%s/%s/%s/offset/0/sh/%s/rec/%s/jingle/%s/loc/%s' % (\n            'http:', recording.find('./url').text,\n            recording.find('./_class').text, recording.find('./file_id').text,\n            rec_doc.find('./uuid').text, video_id,\n            rec_doc.find('./jingle/file_id').text,\n            'http%3A%2F%2Fwww.play.fm%2Fplayer',\n        )\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'ext': 'mp3',\n            'filesize': int_or_none(recording.find('./size').text),\n            'title': title,\n            'upload_date': upload_date,\n            'view_count': view_count,\n            'duration': duration,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n        }",
        "begin_line": 36,
        "end_line": 82,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.shared.SharedIE._real_extract#28",
        "src_path": "youtube_dl/extractor/shared.py",
        "class_name": "youtube_dl.extractor.shared.SharedIE",
        "signature": "youtube_dl.extractor.shared.SharedIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        page = self._download_webpage(url, video_id)\n\n        if re.search(r'>File does not exist<', page) is not None:\n            raise ExtractorError('Video %s does not exist' % video_id, expected=True)\n\n        download_form = dict(re.findall(r'<input type=\"hidden\" name=\"([^\"]+)\" value=\"([^\"]*)\"', page))\n\n        request = compat_urllib_request.Request(url, compat_urllib_parse.urlencode(download_form))\n        request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n\n        video_page = self._download_webpage(request, video_id, 'Downloading video page')\n\n        video_url = self._html_search_regex(r'data-url=\"([^\"]+)\"', video_page, 'video URL')\n        title = base64.b64decode(self._html_search_meta('full:title', page, 'title')).decode('utf-8')\n        filesize = int_or_none(self._html_search_meta('full:size', page, 'file size', fatal=False))\n        thumbnail = self._html_search_regex(\n            r'data-poster=\"([^\"]+)\"', video_page, 'thumbnail', fatal=False, default=None)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'ext': 'mp4',\n            'filesize': filesize,\n            'title': title,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 28,
        "end_line": 57,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.adultswim.AdultSwimIE._real_extract#73",
        "src_path": "youtube_dl/extractor/adultswim.py",
        "class_name": "youtube_dl.extractor.adultswim.AdultSwimIE",
        "signature": "youtube_dl.extractor.adultswim.AdultSwimIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_path = mobj.group('path')\n\n        webpage = self._download_webpage(url, video_path)\n        episode_id = self._html_search_regex(\n            r'<link rel=\"video_src\" href=\"http://i\\.adultswim\\.com/adultswim/adultswimtv/tools/swf/viralplayer.swf\\?id=([0-9a-f]+?)\"\\s*/?\\s*>',\n            webpage, 'episode_id')\n        title = self._og_search_title(webpage)\n\n        index_url = 'http://asfix.adultswim.com/asfix-svc/episodeSearch/getEpisodesByIDs?networkName=AS&ids=%s' % episode_id\n        idoc = self._download_xml(index_url, title, 'Downloading episode index', 'Unable to download episode index')\n\n        episode_el = idoc.find('.//episode')\n        show_title = episode_el.attrib.get('collectionTitle')\n        episode_title = episode_el.attrib.get('title')\n        thumbnail = episode_el.attrib.get('thumbnailUrl')\n        description = episode_el.find('./description').text.strip()\n\n        entries = []\n        segment_els = episode_el.findall('./segments/segment')\n\n        for part_num, segment_el in enumerate(segment_els):\n            segment_id = segment_el.attrib.get('id')\n            segment_title = '%s %s part %d' % (show_title, episode_title, part_num + 1)\n            thumbnail = segment_el.attrib.get('thumbnailUrl')\n            duration = segment_el.attrib.get('duration')\n\n            segment_url = 'http://asfix.adultswim.com/asfix-svc/episodeservices/getCvpPlaylist?networkName=AS&id=%s' % segment_id\n            idoc = self._download_xml(\n                segment_url, segment_title,\n                'Downloading segment information', 'Unable to download segment information')\n\n            formats = []\n            file_els = idoc.findall('.//files/file')\n\n            for file_el in file_els:\n                bitrate = file_el.attrib.get('bitrate')\n                type = file_el.attrib.get('type')\n                width, height = self._video_dimensions.get(bitrate, (None, None))\n                formats.append({\n                    'format_id': '%s-%s' % (bitrate, type),\n                    'url': file_el.text,\n                    'ext': self._video_extensions.get(bitrate, 'mp4'),\n                    # The bitrate may not be a number (for example: 'iphone')\n                    'tbr': int(bitrate) if bitrate.isdigit() else None,\n                    'height': height,\n                    'width': width\n                })\n\n            self._sort_formats(formats)\n\n            entries.append({\n                'id': segment_id,\n                'title': segment_title,\n                'formats': formats,\n                'uploader': show_title,\n                'thumbnail': thumbnail,\n                'duration': duration,\n                'description': description\n            })\n\n        return {\n            '_type': 'playlist',\n            'id': episode_id,\n            'display_id': video_path,\n            'entries': entries,\n            'title': '%s %s' % (show_title, episode_title),\n            'description': description,\n            'thumbnail': thumbnail\n        }",
        "begin_line": 73,
        "end_line": 143,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.anitube.AnitubeIE._real_extract#24",
        "src_path": "youtube_dl/extractor/anitube.py",
        "class_name": "youtube_dl.extractor.anitube.AnitubeIE",
        "signature": "youtube_dl.extractor.anitube.AnitubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        key = self._html_search_regex(\n            r'http://www\\.anitube\\.se/embed/([A-Za-z0-9_-]*)', webpage, 'key')\n\n        config_xml = self._download_xml(\n            'http://www.anitube.se/nuevo/econfig.php?key=%s' % key, key)\n\n        video_title = config_xml.find('title').text\n        thumbnail = config_xml.find('image').text\n        duration = float(config_xml.find('duration').text)\n\n        formats = []\n        video_url = config_xml.find('file')\n        if video_url is not None:\n            formats.append({\n                'format_id': 'sd',\n                'url': video_url.text,\n            })\n        video_url = config_xml.find('filehd')\n        if video_url is not None:\n            formats.append({\n                'format_id': 'hd',\n                'url': video_url.text,\n            })\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats\n        }",
        "begin_line": 24,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.metacritic.MetacriticIE._real_extract#25",
        "src_path": "youtube_dl/extractor/metacritic.py",
        "class_name": "youtube_dl.extractor.metacritic.MetacriticIE",
        "signature": "youtube_dl.extractor.metacritic.MetacriticIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        # The xml is not well formatted, there are raw '&'\n        info = self._download_xml('http://www.metacritic.com/video_data?video=' + video_id,\n            video_id, 'Downloading info xml', transform_source=fix_xml_ampersands)\n\n        clip = next(c for c in info.findall('playList/clip') if c.find('id').text == video_id)\n        formats = []\n        for videoFile in clip.findall('httpURI/videoFile'):\n            rate_str = videoFile.find('rate').text\n            video_url = videoFile.find('filePath').text\n            formats.append({\n                'url': video_url,\n                'ext': 'mp4',\n                'format_id': rate_str,\n                'tbr': int(rate_str),\n            })\n        self._sort_formats(formats)\n\n        description = self._html_search_regex(r'<b>Description:</b>(.*?)</p>',\n            webpage, 'description', flags=re.DOTALL)\n\n        return {\n            'id': video_id,\n            'title': clip.find('title').text,\n            'formats': formats,\n            'description': description,\n            'duration': int(clip.find('duration').text),\n        }",
        "begin_line": 25,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.fourtube.FourTubeIE._real_extract#33",
        "src_path": "youtube_dl/extractor/fourtube.py",
        "class_name": "youtube_dl.extractor.fourtube.FourTubeIE",
        "signature": "youtube_dl.extractor.fourtube.FourTubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n        webpage_url = 'http://www.4tube.com/videos/' + video_id\n        webpage = self._download_webpage(webpage_url, video_id)\n\n        self.report_extraction(video_id)\n\n        playlist_json = self._html_search_regex(r'var playerConfigPlaylist\\s+=\\s+([^;]+)', webpage, 'Playlist')\n        media_id = self._search_regex(r'idMedia:\\s*(\\d+)', playlist_json, 'Media Id')\n        sources = self._search_regex(r'sources:\\s*\\[([^\\]]*)\\]', playlist_json, 'Sources').split(',')\n        title = self._search_regex(r'title:\\s*\"([^\"]*)', playlist_json, 'Title')\n        thumbnail_url = self._search_regex(r'image:\\s*\"([^\"]*)', playlist_json, 'Thumbnail', fatal=False)\n\n        uploader_str = self._search_regex(r'<span>Uploaded by</span>(.*?)<span>', webpage, 'uploader', fatal=False)\n        mobj = re.search(r'<a href=\"/sites/(?P<id>[^\"]+)\"><strong>(?P<name>[^<]+)</strong></a>', uploader_str)\n        (uploader, uploader_id) = (mobj.group('name'), mobj.group('id')) if mobj else (clean_html(uploader_str), None)\n\n        upload_date = None\n        view_count = None\n        duration = None\n        description = self._html_search_meta('description', webpage, 'description')\n        if description:\n            upload_date = self._search_regex(r'Published Date: (\\d{2} [a-zA-Z]{3} \\d{4})', description, 'upload date',\n                fatal=False)\n            if upload_date:\n                upload_date = unified_strdate(upload_date)\n            view_count = self._search_regex(r'Views: ([\\d,\\.]+)', description, 'view count', fatal=False)\n            if view_count:\n                view_count = str_to_int(view_count)\n            duration = parse_duration(self._search_regex(r'Length: (\\d+m\\d+s)', description, 'duration', fatal=False))\n\n        token_url = \"http://tkn.4tube.com/{0}/desktop/{1}\".format(media_id, \"+\".join(sources))\n        headers = {\n                b'Content-Type': b'application/x-www-form-urlencoded',\n                b'Origin': b'http://www.4tube.com',\n                }\n        token_req = compat_urllib_request.Request(token_url, b'{}', headers)\n        tokens = self._download_json(token_req, video_id)\n\n        formats = [{\n            'url': tokens[format]['token'],\n            'format_id': format + 'p',\n            'resolution': format + 'p',\n            'quality': int(format),\n            } for format in sources]\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'thumbnail': thumbnail_url,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'upload_date': upload_date,\n            'view_count': view_count,\n            'duration': duration,\n            'age_limit': 18,\n            'webpage_url': webpage_url,\n        }",
        "begin_line": 33,
        "end_line": 95,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.liveleak.LiveLeakIE._real_extract#47",
        "src_path": "youtube_dl/extractor/liveleak.py",
        "class_name": "youtube_dl.extractor.liveleak.LiveLeakIE",
        "signature": "youtube_dl.extractor.liveleak.LiveLeakIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('video_id')\n        webpage = self._download_webpage(url, video_id)\n\n        video_title = self._og_search_title(webpage).replace('LiveLeak.com -', '').strip()\n        video_description = self._og_search_description(webpage)\n        video_uploader = self._html_search_regex(\n            r'By:.*?(\\w+)</a>', webpage, 'uploader', fatal=False)\n        age_limit = int_or_none(self._search_regex(\n            r'you confirm that you are ([0-9]+) years and over.',\n            webpage, 'age limit', default=None))\n\n        sources_raw = self._search_regex(\n            r'(?s)sources:\\s*(\\[.*?\\]),', webpage, 'video URLs', default=None)\n        if sources_raw is None:\n            alt_source = self._search_regex(\n                r'(file: \".*?\"),', webpage, 'video URL', default=None)\n            if alt_source:\n                sources_raw = '[{ %s}]' % alt_source\n            else:\n                # Maybe an embed?\n                embed_url = self._search_regex(\n                    r'<iframe[^>]+src=\"(http://www.prochan.com/embed\\?[^\"]+)\"',\n                    webpage, 'embed URL')\n                return {\n                    '_type': 'url_transparent',\n                    'url': embed_url,\n                    'id': video_id,\n                    'title': video_title,\n                    'description': video_description,\n                    'uploader': video_uploader,\n                    'age_limit': age_limit,\n                }\n\n        sources_json = re.sub(r'\\s([a-z]+):\\s', r'\"\\1\": ', sources_raw)\n        sources = json.loads(sources_json)\n\n        formats = [{\n            'format_note': s.get('label'),\n            'url': s['file'],\n        } for s in sources]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'description': video_description,\n            'uploader': video_uploader,\n            'formats': formats,\n            'age_limit': age_limit,\n        }",
        "begin_line": 47,
        "end_line": 98,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007692307692307692,
            "pseudo_dstar_susp": 0.0006273525721455458,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006273525721455458,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.krasview.KrasViewIE._real_extract#31",
        "src_path": "youtube_dl/extractor/krasview.py",
        "class_name": "youtube_dl.extractor.krasview.KrasViewIE",
        "signature": "youtube_dl.extractor.krasview.KrasViewIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        flashvars = json.loads(self._search_regex(\n            r'flashvars\\s*:\\s*({.+?})\\s*}\\);', webpage, 'flashvars'))\n\n        video_url = flashvars['url']\n        title = unescapeHTML(flashvars['title'])\n        description = unescapeHTML(flashvars.get('subtitle') or self._og_search_description(webpage, default=None))\n        thumbnail = flashvars['image']\n        duration = int(flashvars['duration'])\n        filesize = int(flashvars['size'])\n        width = int_or_none(self._og_search_property('video:width', webpage, 'video width'))\n        height = int_or_none(self._og_search_property('video:height', webpage, 'video height'))\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'filesize': filesize,\n            'width': width,\n            'height': height,\n        }",
        "begin_line": 31,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.googlesearch.GoogleSearchIE._get_n_results#26",
        "src_path": "youtube_dl/extractor/googlesearch.py",
        "class_name": "youtube_dl.extractor.googlesearch.GoogleSearchIE",
        "signature": "youtube_dl.extractor.googlesearch.GoogleSearchIE._get_n_results(self, query, n)",
        "snippet": "    def _get_n_results(self, query, n):\n        \"\"\"Get a specified number of results for a query\"\"\"\n\n        entries = []\n        res = {\n            '_type': 'playlist',\n            'id': query,\n            'title': query,\n        }\n\n        for pagenum in itertools.count():\n            result_url = (\n                'http://www.google.com/search?tbm=vid&q=%s&start=%s&hl=en'\n                % (compat_urllib_parse.quote_plus(query), pagenum * 10))\n\n            webpage = self._download_webpage(\n                result_url, 'gvsearch:' + query,\n                note='Downloading result page ' + str(pagenum + 1))\n\n            for hit_idx, mobj in enumerate(re.finditer(\n                    r'<h3 class=\"r\"><a href=\"([^\"]+)\"', webpage)):\n\n                # Skip playlists\n                if not re.search(r'id=\"vidthumb%d\"' % (hit_idx + 1), webpage):\n                    continue\n\n                entries.append({\n                    '_type': 'url',\n                    'url': mobj.group(1)\n                })\n\n            if (len(entries) >= n) or not re.search(r'id=\"pnnext\"', webpage):\n                res['entries'] = entries[:n]\n                return res",
        "begin_line": 26,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.defense.DefenseGouvFrIE._real_extract#23",
        "src_path": "youtube_dl/extractor/defense.py",
        "class_name": "youtube_dl.extractor.defense.DefenseGouvFrIE",
        "signature": "youtube_dl.extractor.defense.DefenseGouvFrIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        title = re.match(self._VALID_URL, url).group(1)\n        webpage = self._download_webpage(url, title)\n        video_id = self._search_regex(\n            r\"flashvars.pvg_id=\\\"(\\d+)\\\";\",\n            webpage, 'ID')\n        \n        json_url = ('http://static.videos.gouv.fr/brightcovehub/export/json/'\n            + video_id)\n        info = self._download_webpage(json_url, title,\n                                                  'Downloading JSON config')\n        video_url = json.loads(info)['renditions'][0]['url']\n        \n        return {'id': video_id,\n                'ext': 'mp4',\n                'url': video_url,\n                'title': title,\n                }",
        "begin_line": 23,
        "end_line": 40,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.vuclip.VuClipIE._real_extract#27",
        "src_path": "youtube_dl/extractor/vuclip.py",
        "class_name": "youtube_dl.extractor.vuclip.VuClipIE",
        "signature": "youtube_dl.extractor.vuclip.VuClipIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        ad_m = re.search(\n            r'''value=\"No.*?\" onClick=\"location.href='([^\"']+)'\"''', webpage)\n        if ad_m:\n            urlr = compat_urllib_parse_urlparse(url)\n            adfree_url = urlr.scheme + '://' + urlr.netloc + ad_m.group(1)\n            webpage = self._download_webpage(\n                adfree_url, video_id, note='Download post-ad page')\n\n        links_code = self._search_regex(\n            r'(?s)<div class=\"social align_c\".*?>(.*?)<hr\\s*/?>', webpage,\n            'links')\n        title = self._html_search_regex(\n            r'<title>(.*?)-\\s*Vuclip</title>', webpage, 'title').strip()\n\n        quality_order = qualities(['Reg', 'Hi'])\n        formats = []\n        for url, q in re.findall(\n                r'<a href=\"(?P<url>[^\"]+)\".*?>(?P<q>[^<]+)</a>', links_code):\n            format_id = compat_urllib_parse_urlparse(url).scheme + '-' + q\n            formats.append({\n                'format_id': format_id,\n                'url': url,\n                'quality': quality_order(q),\n            })\n        self._sort_formats(formats)\n\n        duration = parse_duration(self._search_regex(\n            r'\\(([0-9:]+)\\)</span></h1>', webpage, 'duration', fatal=False))\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': title,\n            'duration': duration,\n        }",
        "begin_line": 27,
        "end_line": 66,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.mpora.MporaIE._real_extract#25",
        "src_path": "youtube_dl/extractor/mpora.py",
        "class_name": "youtube_dl.extractor.mpora.MporaIE",
        "signature": "youtube_dl.extractor.mpora.MporaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        data_json = self._search_regex(\n            r\"new FM\\.Player\\('[^']+',\\s*(\\{.*?)\\).player;\", webpage, 'json')\n\n        data = json.loads(data_json)\n\n        uploader = data['info_overlay'].get('username')\n        duration = data['video']['duration'] // 1000\n        thumbnail = data['video']['encodings']['sd']['poster']\n        title = data['info_overlay']['title']\n\n        formats = []\n        for encoding_id, edata in data['video']['encodings'].items():\n            for src in edata['sources']:\n                width_str = self._search_regex(\n                    r'_([0-9]+)\\.[a-zA-Z0-9]+$', src['src'],\n                    False, default=None)\n                vcodec = src['type'].partition('/')[2]\n                \n                formats.append({\n                    'format_id': encoding_id + '-' + vcodec,\n                    'url': src['src'],\n                    'vcodec': vcodec,\n                    'width': int_or_none(width_str),\n                })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'uploader': uploader,\n            'duration': duration,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 25,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.franceculture.FranceCultureIE._real_extract#31",
        "src_path": "youtube_dl/extractor/franceculture.py",
        "class_name": "youtube_dl.extractor.franceculture.FranceCultureIE",
        "signature": "youtube_dl.extractor.franceculture.FranceCultureIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        baseurl = mobj.group('baseurl')\n\n        webpage = self._download_webpage(url, video_id)\n        params_code = self._search_regex(\n            r\"<param name='movie' value='/sites/all/modules/rf/rf_player/swf/loader.swf\\?([^']+)' />\",\n            webpage, 'parameter code')\n        params = compat_parse_qs(params_code)\n        video_url = compat_urlparse.urljoin(baseurl, params['urlAOD'][0])\n\n        title = self._html_search_regex(\n            r'<h1 class=\"title[^\"]+\">(.+?)</h1>', webpage, 'title')\n        uploader = self._html_search_regex(\n            r'(?s)<div id=\"emission\".*?<span class=\"author\">(.*?)</span>',\n            webpage, 'uploader', fatal=False)\n        thumbnail_part = self._html_search_regex(\n            r'(?s)<div id=\"emission\".*?<img src=\"([^\"]+)\"', webpage,\n            'thumbnail', fatal=False)\n        if thumbnail_part is None:\n            thumbnail = None\n        else:\n            thumbnail = compat_urlparse.urljoin(baseurl, thumbnail_part)\n        description = self._html_search_regex(\n            r'(?s)<p class=\"desc\">(.*?)</p>', webpage, 'description')\n\n        info = json.loads(params['infoData'][0])[0]\n        duration = info.get('media_length')\n        upload_date_candidate = info.get('media_section5')\n        upload_date = (\n            upload_date_candidate\n            if (upload_date_candidate is not None and\n                re.match(r'[0-9]{8}$', upload_date_candidate))\n            else None)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'vcodec': 'none' if video_url.lower().endswith('.mp3') else None,\n            'duration': duration,\n            'uploader': uploader,\n            'upload_date': upload_date,\n            'title': title,\n            'thumbnail': thumbnail,\n            'description': description,\n        }",
        "begin_line": 31,
        "end_line": 77,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.jeuxvideo.JeuxVideoIE._real_extract#25",
        "src_path": "youtube_dl/extractor/jeuxvideo.py",
        "class_name": "youtube_dl.extractor.jeuxvideo.JeuxVideoIE",
        "signature": "youtube_dl.extractor.jeuxvideo.JeuxVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        title = mobj.group(1)\n        webpage = self._download_webpage(url, title)\n        xml_link = self._html_search_regex(\n            r'<param name=\"flashvars\" value=\"config=(.*?)\" />',\n            webpage, 'config URL')\n        \n        video_id = self._search_regex(\n            r'http://www\\.jeuxvideo\\.com/config/\\w+/\\d+/(.*?)/\\d+_player\\.xml',\n            xml_link, 'video ID')\n\n        config = self._download_xml(\n            xml_link, title, 'Downloading XML config')\n        info_json = config.find('format.json').text\n        info = json.loads(info_json)['versions'][0]\n        \n        video_url = 'http://video720.jeuxvideo.com/' + info['file']\n\n        return {\n            'id': video_id,\n            'title': config.find('titre_video').text,\n            'ext': 'mp4',\n            'url': video_url,\n            'description': self._og_search_description(webpage),\n            'thumbnail': config.find('image').text,\n        }",
        "begin_line": 25,
        "end_line": 51,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.radiofrance.RadioFranceIE._real_extract#25",
        "src_path": "youtube_dl/extractor/radiofrance.py",
        "class_name": "youtube_dl.extractor.radiofrance.RadioFranceIE",
        "signature": "youtube_dl.extractor.radiofrance.RadioFranceIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        title = self._html_search_regex(r'<h1>(.*?)</h1>', webpage, 'title')\n        description = self._html_search_regex(\n            r'<div class=\"bloc_page_wrapper\"><div class=\"text\">(.*?)</div>',\n            webpage, 'description', fatal=False)\n        uploader = self._html_search_regex(\n            r'<div class=\"credit\">&nbsp;&nbsp;&copy;&nbsp;(.*?)</div>',\n            webpage, 'uploader', fatal=False)\n\n        formats_str = self._html_search_regex(\n            r'class=\"jp-jplayer[^\"]*\" data-source=\"([^\"]+)\">',\n            webpage, 'audio URLs')\n        formats = [\n            {\n                'format_id': fm[0],\n                'url': fm[1],\n                'vcodec': 'none',\n                'preference': i,\n            }\n            for i, fm in\n            enumerate(re.findall(r\"([a-z0-9]+)\\s*:\\s*'([^']+)'\", formats_str))\n        ]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'description': description,\n            'uploader': uploader,\n        }",
        "begin_line": 25,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.bilibili.BiliBiliIE._real_extract#31",
        "src_path": "youtube_dl/extractor/bilibili.py",
        "class_name": "youtube_dl.extractor.bilibili.BiliBiliIE",
        "signature": "youtube_dl.extractor.bilibili.BiliBiliIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        video_code = self._search_regex(\n            r'(?s)<div itemprop=\"video\".*?>(.*?)</div>', webpage, 'video code')\n\n        title = self._html_search_meta(\n            'media:title', video_code, 'title', fatal=True)\n        duration_str = self._html_search_meta(\n            'duration', video_code, 'duration')\n        if duration_str is None:\n            duration = None\n        else:\n            duration_mobj = re.match(\n                r'^T(?:(?P<hours>[0-9]+)H)?(?P<minutes>[0-9]+)M(?P<seconds>[0-9]+)S$',\n                duration_str)\n            duration = (\n                int_or_none(duration_mobj.group('hours'), default=0) * 3600 +\n                int(duration_mobj.group('minutes')) * 60 +\n                int(duration_mobj.group('seconds')))\n        upload_date = unified_strdate(self._html_search_meta(\n            'uploadDate', video_code, fatal=False))\n        thumbnail = self._html_search_meta(\n            'thumbnailUrl', video_code, 'thumbnail', fatal=False)\n\n        player_params = compat_parse_qs(self._html_search_regex(\n            r'<iframe .*?class=\"player\" src=\"https://secure\\.bilibili\\.(?:tv|com)/secure,([^\"]+)\"',\n            webpage, 'player params'))\n\n        if 'cid' in player_params:\n            cid = player_params['cid'][0]\n\n            lq_doc = self._download_xml(\n                'http://interface.bilibili.cn/v_cdn_play?cid=%s' % cid,\n                video_id,\n                note='Downloading LQ video info'\n            )\n            lq_durl = lq_doc.find('.//durl')\n            formats = [{\n                'format_id': 'lq',\n                'quality': 1,\n                'url': lq_durl.find('./url').text,\n                'filesize': int_or_none(\n                    lq_durl.find('./size'), get_attr='text'),\n            }]\n\n            hq_doc = self._download_xml(\n                'http://interface.bilibili.cn/playurl?cid=%s' % cid,\n                video_id,\n                note='Downloading HQ video info',\n                fatal=False,\n            )\n            if hq_doc is not False:\n                hq_durl = hq_doc.find('.//durl')\n                formats.append({\n                    'format_id': 'hq',\n                    'quality': 2,\n                    'ext': 'flv',\n                    'url': hq_durl.find('./url').text,\n                    'filesize': int_or_none(\n                        hq_durl.find('./size'), get_attr='text'),\n                })\n        else:\n            raise ExtractorError('Unsupported player parameters: %r' % (player_params,))\n\n        self._sort_formats(formats)\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'duration': duration,\n            'upload_date': upload_date,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 31,
        "end_line": 106,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.vgtv.VGTVIE._real_extract#69",
        "src_path": "youtube_dl/extractor/vgtv.py",
        "class_name": "youtube_dl.extractor.vgtv.VGTVIE",
        "signature": "youtube_dl.extractor.vgtv.VGTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        data = self._download_json(\n            'http://svp.vg.no/svp/api/v1/vgtv/assets/%s?appName=vgtv-website' % video_id,\n            video_id, 'Downloading media JSON')\n\n        streams = data['streamUrls']\n\n        formats = []\n\n        hls_url = streams.get('hls')\n        if hls_url:\n            formats.extend(self._extract_m3u8_formats(hls_url, video_id, 'mp4'))\n\n        hds_url = streams.get('hds')\n        if hds_url:\n            formats.extend(self._extract_f4m_formats(hds_url + '?hdcore=3.2.0&plugin=aasp-3.2.0.77.18', video_id))\n\n        mp4_url = streams.get('mp4')\n        if mp4_url:\n            _url = hls_url or hds_url\n            MP4_URL_TEMPLATE = '%s/%%s.%s' % (mp4_url.rpartition('/')[0], mp4_url.rpartition('.')[-1])\n            for mp4_format in _url.split(','):\n                m = re.search('(?P<width>\\d+)_(?P<height>\\d+)_(?P<vbr>\\d+)', mp4_format)\n                if not m:\n                    continue\n                width = int(m.group('width'))\n                height = int(m.group('height'))\n                vbr = int(m.group('vbr'))\n                formats.append({\n                    'url': MP4_URL_TEMPLATE % mp4_format,\n                    'format_id': 'mp4-%s' % vbr,\n                    'width': width,\n                    'height': height,\n                    'vbr': vbr,\n                    'preference': 1,\n                })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': data['title'],\n            'description': data['description'],\n            'thumbnail': data['images']['main'] + '?t[]=900x506q80',\n            'timestamp': data['published'],\n            'duration': float_or_none(data['duration'], 1000),\n            'view_count': data['displays'],\n            'formats': formats,\n        }",
        "begin_line": 69,
        "end_line": 119,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007692307692307692,
            "pseudo_dstar_susp": 0.0006273525721455458,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006273525721455458,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.vulture.VultureIE._real_extract#33",
        "src_path": "youtube_dl/extractor/vulture.py",
        "class_name": "youtube_dl.extractor.vulture.VultureIE",
        "signature": "youtube_dl.extractor.vulture.VultureIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id)\n        query_string = self._search_regex(\n            r\"queryString\\s*=\\s*'([^']+)'\", webpage, 'query string')\n        video_id = self._search_regex(\n            r'content=([^&]+)', query_string, 'video ID')\n        query_url = 'http://video.vulture.com/embed/player/container/1000/1000/?%s' % query_string\n\n        query_webpage = self._download_webpage(\n            query_url, display_id, note='Downloading query page')\n        params_json = self._search_regex(\n            r'(?sm)new MagnifyEmbeddablePlayer\\({.*?contentItem:\\s*(\\{.*?\\})\\n,\\n',\n            query_webpage,\n            'player params')\n        params = json.loads(params_json)\n\n        upload_timestamp = parse_iso8601(params['posted'].replace(' ', 'T'))\n        uploader_id = params.get('user', {}).get('handle')\n\n        media_item = params['media_item']\n        title = os.path.splitext(media_item['title'])[0]\n        duration = int_or_none(media_item.get('duration_seconds'))\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'url': media_item['pipeline_xid'],\n            'title': title,\n            'timestamp': upload_timestamp,\n            'thumbnail': params.get('thumbnail_url'),\n            'uploader_id': uploader_id,\n            'description': params.get('description'),\n            'duration': duration,\n        }",
        "begin_line": 33,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.tagesschau.TagesschauIE._real_extract#30",
        "src_path": "youtube_dl/extractor/tagesschau.py",
        "class_name": "youtube_dl.extractor.tagesschau.TagesschauIE",
        "signature": "youtube_dl.extractor.tagesschau.TagesschauIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        if video_id.startswith('-'):\n            display_id = video_id.strip('-')\n        else:\n            display_id = video_id\n\n        webpage = self._download_webpage(url, display_id)\n\n        playerpage = self._download_webpage(\n            'http://www.tagesschau.de/multimedia/video/video%s~player_autoplay-true.html' % video_id,\n            display_id, 'Downloading player page')\n\n        medias = re.findall(\n            r'\"(http://media.+?)\", type:\"video/(.+?)\", quality:\"(.+?)\"',\n            playerpage)\n\n        formats = []\n        for url, ext, res in medias:\n            f = {\n                'format_id': res + '_' + ext,\n                'url': url,\n                'ext': ext,\n            }\n            f.update(self._FORMATS.get(res, {}))\n            formats.append(f)\n\n        self._sort_formats(formats)\n\n        thumbnail = re.findall(r'\"(/multimedia/.+?\\.jpg)\"', playerpage)[-1]\n\n        return {\n            'id': display_id,\n            'title': self._og_search_title(webpage).strip(),\n            'thumbnail': 'http://www.tagesschau.de' + thumbnail,\n            'formats': formats,\n            'description': self._og_search_description(webpage).strip(),\n        }",
        "begin_line": 30,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.lifenews.LifeNewsIE._real_extract#32",
        "src_path": "youtube_dl/extractor/lifenews.py",
        "class_name": "youtube_dl.extractor.lifenews.LifeNewsIE",
        "signature": "youtube_dl.extractor.lifenews.LifeNewsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage('http://lifenews.ru/news/%s' % video_id, video_id, 'Downloading page')\n\n        videos = re.findall(r'<video.*?poster=\"(?P<poster>[^\"]+)\".*?src=\"(?P<video>[^\"]+)\".*?></video>', webpage)\n        if not videos:\n            raise ExtractorError('No media links available for %s' % video_id)\n\n        title = self._og_search_title(webpage)\n        TITLE_SUFFIX = ' - \u041f\u0435\u0440\u0432\u044b\u0439 \u043f\u043e \u0441\u0440\u043e\u0447\u043d\u044b\u043c \u043d\u043e\u0432\u043e\u0441\u0442\u044f\u043c \u2014 LIFE | NEWS'\n        if title.endswith(TITLE_SUFFIX):\n            title = title[:-len(TITLE_SUFFIX)]\n\n        description = self._og_search_description(webpage)\n\n        view_count = self._html_search_regex(\n            r'<div class=\\'views\\'>(\\d+)</div>', webpage, 'view count', fatal=False)\n        comment_count = self._html_search_regex(\n            r'<div class=\\'comments\\'>\\s*<span class=\\'counter\\'>(\\d+)</span>', webpage, 'comment count', fatal=False)\n\n        upload_date = self._html_search_regex(\n            r'<time datetime=\\'([^\\']+)\\'>', webpage, 'upload date',fatal=False)\n        if upload_date is not None:\n            upload_date = unified_strdate(upload_date)\n\n        def make_entry(video_id, media, video_number=None):\n            return {\n                'id': video_id,\n                'url': media[1],\n                'thumbnail': media[0],\n                'title': title if video_number is None else '%s-video%s' % (title, video_number),\n                'description': description,\n                'view_count': int_or_none(view_count),\n                'comment_count': int_or_none(comment_count),\n                'upload_date': upload_date,\n            }\n\n        if len(videos) == 1:\n            return make_entry(video_id, videos[0])\n        else:\n            return [make_entry(video_id, media, video_number+1) for video_number, media in enumerate(videos)]",
        "begin_line": 32,
        "end_line": 74,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.trutube.TruTubeIE._real_extract#21",
        "src_path": "youtube_dl/extractor/trutube.py",
        "class_name": "youtube_dl.extractor.trutube.TruTubeIE",
        "signature": "youtube_dl.extractor.trutube.TruTubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        video_title = self._og_search_title(webpage).strip()\n        thumbnail = self._search_regex(\n            r\"var splash_img = '([^']+)';\", webpage, 'thumbnail', fatal=False)\n\n        all_formats = re.finditer(\n            r\"var (?P<key>[a-z]+)_video_file\\s*=\\s*'(?P<url>[^']+)';\", webpage)\n        formats = [{\n            'format_id': m.group('key'),\n            'quality': -i,\n            'url': m.group('url'),\n        } for i, m in enumerate(all_formats)]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'formats': formats,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 21,
        "end_line": 44,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.wayofthemaster.WayOfTheMasterIE._real_extract#21",
        "src_path": "youtube_dl/extractor/wayofthemaster.py",
        "class_name": "youtube_dl.extractor.wayofthemaster.WayOfTheMasterIE",
        "signature": "youtube_dl.extractor.wayofthemaster.WayOfTheMasterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._search_regex(\n            r'<img src=\"images/title_[^\"]+\".*?alt=\"([^\"]+)\"',\n            webpage, 'title', default=None)\n        if title is None:\n            title = self._html_search_regex(\n                r'<title>(.*?)</title>', webpage, 'page title')\n\n        url_base = self._search_regex(\n            r'<param\\s+name=\"?movie\"?\\s+value=\".*?/wotm_videoplayer_highlow[0-9]*\\.swf\\?vid=([^\"]+)\"',\n            webpage, 'URL base')\n        formats = [{\n            'format_id': 'low',\n            'quality': 1,\n            'url': url_base + '_low.mp4',\n        }, {\n            'format_id': 'high',\n            'quality': 2,\n            'url': url_base + '_high.mp4',\n        }]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n        }",
        "begin_line": 21,
        "end_line": 52,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.moviezine.MoviezineIE._real_extract#23",
        "src_path": "youtube_dl/extractor/moviezine.py",
        "class_name": "youtube_dl.extractor.moviezine.MoviezineIE",
        "signature": "youtube_dl.extractor.moviezine.MoviezineIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        jsplayer = self._download_webpage('http://www.moviezine.se/api/player.js?video=%s' % video_id, video_id, 'Downloading js api player')\n\n        formats =[{\n            'format_id': 'sd',\n            'url': self._html_search_regex(r'file: \"(.+?)\",', jsplayer, 'file'),\n            'quality': 0,\n            'ext': 'mp4',\n        }]\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': self._search_regex(r'title: \"(.+?)\",', jsplayer, 'title'),\n            'thumbnail': self._search_regex(r'image: \"(.+?)\",', jsplayer, 'image'),\n            'formats': formats,\n            'description': self._og_search_description(webpage),\n        }",
        "begin_line": 23,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.anysex.AnySexIE._real_extract#28",
        "src_path": "youtube_dl/extractor/anysex.py",
        "class_name": "youtube_dl.extractor.anysex.AnySexIE",
        "signature": "youtube_dl.extractor.anysex.AnySexIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = self._html_search_regex(r\"video_url\\s*:\\s*'([^']+)'\", webpage, 'video URL')\n\n        title = self._html_search_regex(r'<title>(.*?)</title>', webpage, 'title')\n        description = self._html_search_regex(\n            r'<div class=\"description\">([^<]+)</div>', webpage, 'description', fatal=False)\n        thumbnail = self._html_search_regex(\n            r'preview_url\\s*:\\s*\\'(.*?)\\'', webpage, 'thumbnail', fatal=False)\n\n        categories = re.findall(\n            r'<a href=\"http://anysex\\.com/categories/[^\"]+\" title=\"[^\"]*\">([^<]+)</a>', webpage)\n\n        duration = parse_duration(self._search_regex(\n            r'<b>Duration:</b> (\\d+:\\d+)', webpage, 'duration', fatal=False))\n        view_count = int_or_none(self._html_search_regex(\n            r'<b>Views:</b> (\\d+)', webpage, 'view count', fatal=False))\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'ext': 'mp4',\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'categories': categories,\n            'duration': duration,\n            'view_count': view_count,\n            'age_limit': 18,\n        }",
        "begin_line": 28,
        "end_line": 61,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.unistra.UnistraIE._real_extract#35",
        "src_path": "youtube_dl/extractor/unistra.py",
        "class_name": "youtube_dl.extractor.unistra.UnistraIE",
        "signature": "youtube_dl.extractor.unistra.UnistraIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        files = set(re.findall(r'file\\s*:\\s*\"([^\"]+)\"', webpage))\n\n        quality = qualities(['SD', 'HD'])\n        formats = []\n        for file_path in files:\n            format_id = 'HD' if file_path.endswith('-HD.mp4') else 'SD'\n            formats.append({\n                'url': 'http://vod-flash.u-strasbg.fr:8080%s' % file_path,\n                'format_id': format_id,\n                'quality': quality(format_id)\n            })\n\n        title = self._html_search_regex(\n            r'<title>UTV - (.*?)</', webpage, 'title')\n        description = self._html_search_regex(\n            r'<meta name=\"Description\" content=\"(.*?)\"', webpage, 'description', flags=re.DOTALL)\n        thumbnail = self._search_regex(\n            r'image: \"(.*?)\"', webpage, 'thumbnail')\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'formats': formats\n        }",
        "begin_line": 35,
        "end_line": 66,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.0001840942562592047,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.vevo.VevoIE._formats_from_json#72",
        "src_path": "youtube_dl/extractor/vevo.py",
        "class_name": "youtube_dl.extractor.vevo.VevoIE",
        "signature": "youtube_dl.extractor.vevo.VevoIE._formats_from_json(self, video_info)",
        "snippet": "    def _formats_from_json(self, video_info):\n        last_version = {'version': -1}\n        for version in video_info['videoVersions']:\n            # These are the HTTP downloads, other types are for different manifests\n            if version['sourceType'] == 2:\n                if version['version'] > last_version['version']:\n                    last_version = version\n        if last_version['version'] == -1:\n            raise ExtractorError('Unable to extract last version of the video')\n\n        renditions = xml.etree.ElementTree.fromstring(last_version['data'])\n        formats = []\n        # Already sorted from worst to best quality\n        for rend in renditions.findall('rendition'):\n            attr = rend.attrib\n            format_note = '%(videoCodec)s@%(videoBitrate)4sk, %(audioCodec)s@%(audioBitrate)3sk' % attr\n            formats.append({\n                'url': attr['url'],\n                'format_id': attr['name'],\n                'format_note': format_note,\n                'height': int(attr['frameheight']),\n                'width': int(attr['frameWidth']),\n            })\n        return formats",
        "begin_line": 72,
        "end_line": 95,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.vevo.VevoIE._formats_from_smil#97",
        "src_path": "youtube_dl/extractor/vevo.py",
        "class_name": "youtube_dl.extractor.vevo.VevoIE",
        "signature": "youtube_dl.extractor.vevo.VevoIE._formats_from_smil(self, smil_xml)",
        "snippet": "    def _formats_from_smil(self, smil_xml):\n        formats = []\n        smil_doc = xml.etree.ElementTree.fromstring(smil_xml.encode('utf-8'))\n        els = smil_doc.findall('.//{http://www.w3.org/2001/SMIL20/Language}video')\n        for el in els:\n            src = el.attrib['src']\n            m = re.match(r'''(?xi)\n                (?P<ext>[a-z0-9]+):\n                (?P<path>\n                    [/a-z0-9]+     # The directory and main part of the URL\n                    _(?P<cbr>[0-9]+)k\n                    _(?P<width>[0-9]+)x(?P<height>[0-9]+)\n                    _(?P<vcodec>[a-z0-9]+)\n                    _(?P<vbr>[0-9]+)\n                    _(?P<acodec>[a-z0-9]+)\n                    _(?P<abr>[0-9]+)\n                    \\.[a-z0-9]+  # File extension\n                )''', src)\n            if not m:\n                continue\n\n            format_url = self._SMIL_BASE_URL + m.group('path')\n            formats.append({\n                'url': format_url,\n                'format_id': 'SMIL_' + m.group('cbr'),\n                'vcodec': m.group('vcodec'),\n                'acodec': m.group('acodec'),\n                'vbr': int(m.group('vbr')),\n                'abr': int(m.group('abr')),\n                'ext': m.group('ext'),\n                'width': int(m.group('width')),\n                'height': int(m.group('height')),\n            })\n        return formats",
        "begin_line": 97,
        "end_line": 130,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.vevo.VevoIE._real_extract#132",
        "src_path": "youtube_dl/extractor/vevo.py",
        "class_name": "youtube_dl.extractor.vevo.VevoIE",
        "signature": "youtube_dl.extractor.vevo.VevoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        json_url = 'http://videoplayer.vevo.com/VideoService/AuthenticateVideo?isrc=%s' % video_id\n        response = self._download_json(json_url, video_id)\n        video_info = response['video']\n\n        if not video_info:\n            if 'statusMessage' in response:\n                raise ExtractorError('%s said: %s' % (self.IE_NAME, response['statusMessage']), expected=True)\n            raise ExtractorError('Unable to extract videos')\n\n        formats = self._formats_from_json(video_info)\n\n        is_explicit = video_info.get('isExplicit')\n        if is_explicit is True:\n            age_limit = 18\n        elif is_explicit is False:\n            age_limit = 0\n        else:\n            age_limit = None\n\n        # Download SMIL\n        smil_blocks = sorted((\n            f for f in video_info['videoVersions']\n            if f['sourceType'] == 13),\n            key=lambda f: f['version'])\n\n        smil_url = '%s/Video/V2/VFILE/%s/%sr.smil' % (\n            self._SMIL_BASE_URL, video_id, video_id.lower())\n        if smil_blocks:\n            smil_url_m = self._search_regex(\n                r'url=\"([^\"]+)\"', smil_blocks[-1]['data'], 'SMIL URL',\n                fatal=False)\n            if smil_url_m is not None:\n                smil_url = smil_url_m\n\n        try:\n            smil_xml = self._download_webpage(smil_url, video_id,\n                                              'Downloading SMIL info')\n            formats.extend(self._formats_from_smil(smil_xml))\n        except ExtractorError as ee:\n            if not isinstance(ee.cause, compat_HTTPError):\n                raise\n            self._downloader.report_warning(\n                'Cannot download SMIL information, falling back to JSON ..')\n\n        self._sort_formats(formats)\n        timestamp_ms = int(self._search_regex(\n            r'/Date\\((\\d+)\\)/', video_info['launchDate'], 'launch date'))\n\n        return {\n            'id': video_id,\n            'title': video_info['title'],\n            'formats': formats,\n            'thumbnail': video_info['imageUrl'],\n            'timestamp': timestamp_ms // 1000,\n            'uploader': video_info['mainArtists'][0]['artistName'],\n            'duration': video_info['duration'],\n            'age_limit': age_limit,\n        }",
        "begin_line": 132,
        "end_line": 193,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.canalc2.Canalc2IE._real_extract#23",
        "src_path": "youtube_dl/extractor/canalc2.py",
        "class_name": "youtube_dl.extractor.canalc2.Canalc2IE",
        "signature": "youtube_dl.extractor.canalc2.Canalc2IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = re.match(self._VALID_URL, url).group('id')\n        # We need to set the voir field for getting the file name\n        url = 'http://www.canalc2.tv/video.asp?idVideo=%s&voir=oui' % video_id\n        webpage = self._download_webpage(url, video_id)\n        file_name = self._search_regex(\n            r\"so\\.addVariable\\('file','(.*?)'\\);\",\n            webpage, 'file name')\n        video_url = 'http://vod-flash.u-strasbg.fr:8080/' + file_name\n\n        title = self._html_search_regex(\n            r'class=\"evenement8\">(.*?)</a>', webpage, 'title')\n\n        return {\n            'id': video_id,\n            'ext': 'mp4',\n            'url': video_url,\n            'title': title,\n        }",
        "begin_line": 23,
        "end_line": 41,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.vube.VubeIE._real_extract#76",
        "src_path": "youtube_dl/extractor/vube.py",
        "class_name": "youtube_dl.extractor.vube.VubeIE",
        "signature": "youtube_dl.extractor.vube.VubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        video = self._download_json(\n            'http://vube.com/t-api/v1/video/%s' % video_id, video_id, 'Downloading video JSON')\n\n        public_id = video['public_id']\n\n        formats = []\n\n        for media in video['media'].get('video', []) + video['media'].get('audio', []):\n            if media['transcoding_status'] != 'processed':\n                continue\n            fmt = {\n                'url': 'http://video.thestaticvube.com/video/%s/%s.mp4' % (media['media_resolution_id'], public_id),\n                'abr': int(media['audio_bitrate']),\n                'format_id': compat_str(media['media_resolution_id']),\n            }\n            vbr = int(media['video_bitrate'])\n            if vbr:\n                fmt.update({\n                    'vbr': vbr,\n                    'height': int(media['height']),\n                })\n            formats.append(fmt)\n\n        self._sort_formats(formats)\n\n        title = video['title']\n        description = video.get('description')\n        thumbnail = self._proto_relative_url(video.get('thumbnail_src'), scheme='http:')\n        uploader = video.get('user_alias') or video.get('channel')\n        timestamp = int_or_none(video.get('upload_time'))\n        duration = video['duration']\n        view_count = video.get('raw_view_count')\n        like_count = video.get('total_likes')\n        dislike_count = video.get('total_hates')\n\n        comments = video.get('comments')\n        comment_count = None\n        if comments is None:\n            comment_data = self._download_json(\n                'http://vube.com/api/video/%s/comment' % video_id,\n                video_id, 'Downloading video comment JSON', fatal=False)\n            if comment_data is not None:\n                comment_count = int_or_none(comment_data.get('total'))\n        else:\n            comment_count = len(comments)\n\n        categories = [tag['text'] for tag in video['tags']]\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'timestamp': timestamp,\n            'duration': duration,\n            'view_count': view_count,\n            'like_count': like_count,\n            'dislike_count': dislike_count,\n            'comment_count': comment_count,\n            'categories': categories,\n        }",
        "begin_line": 76,
        "end_line": 142,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.veehd.VeeHDIE._real_extract#28",
        "src_path": "youtube_dl/extractor/veehd.py",
        "class_name": "youtube_dl.extractor.veehd.VeeHDIE",
        "signature": "youtube_dl.extractor.veehd.VeeHDIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        # VeeHD seems to send garbage on the first request.\n        # See https://github.com/rg3/youtube-dl/issues/2102\n        self._download_webpage(url, video_id, 'Requesting webpage')\n        webpage = self._download_webpage(url, video_id)\n        player_path = self._search_regex(\n            r'\\$\\(\"#playeriframe\"\\).attr\\({src : \"(.+?)\"',\n            webpage, 'player path')\n        player_url = compat_urlparse.urljoin(url, player_path)\n\n        self._download_webpage(player_url, video_id, 'Requesting player page')\n        player_page = self._download_webpage(\n            player_url, video_id, 'Downloading player page')\n        config_json = self._search_regex(\n            r'value=\\'config=({.+?})\\'', player_page, 'config json')\n        config = json.loads(config_json)\n\n        video_url = compat_urlparse.unquote(config['clip']['url'])\n        title = clean_html(get_element_by_id('videoName', webpage).rpartition('|')[0])\n        uploader_id = self._html_search_regex(r'<a href=\"/profile/\\d+\">(.+?)</a>',\n            webpage, 'uploader')\n        thumbnail = self._search_regex(r'<img id=\"veehdpreview\" src=\"(.+?)\"',\n            webpage, 'thumbnail')\n        description = self._html_search_regex(r'<td class=\"infodropdown\".*?<div>(.*?)<ul',\n            webpage, 'description', flags=re.DOTALL)\n\n        return {\n            '_type': 'video',\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'ext': 'mp4',\n            'uploader_id': uploader_id,\n            'thumbnail': thumbnail,\n            'description': description,\n        }",
        "begin_line": 28,
        "end_line": 66,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_unsigned_long_long#29",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_unsigned_long_long(self)",
        "snippet": "    def read_unsigned_long_long(self):\n        return struct_unpack('!Q', self.read(8))[0]",
        "begin_line": 29,
        "end_line": 30,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_unsigned_int#32",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_unsigned_int(self)",
        "snippet": "    def read_unsigned_int(self):\n        return struct_unpack('!I', self.read(4))[0]",
        "begin_line": 32,
        "end_line": 33,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_unsigned_char#35",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_unsigned_char(self)",
        "snippet": "    def read_unsigned_char(self):\n        return struct_unpack('!B', self.read(1))[0]",
        "begin_line": 35,
        "end_line": 36,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_string#38",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_string(self)",
        "snippet": "    def read_string(self):\n        res = b''\n        while True:\n            char = self.read(1)\n            if char == b'\\x00':\n                break\n            res += char\n        return res",
        "begin_line": 38,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_box_info#47",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_box_info(self)",
        "snippet": "    def read_box_info(self):\n        \"\"\"\n        Read a box and return the info as a tuple: (box_size, box_type, box_data)\n        \"\"\"\n        real_size = size = self.read_unsigned_int()\n        box_type = self.read(4)\n        header_end = 8\n        if size == 1:\n            real_size = self.read_unsigned_long_long()\n            header_end = 16\n        return real_size, box_type, self.read(real_size-header_end)",
        "begin_line": 47,
        "end_line": 57,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_asrt#59",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_asrt(self)",
        "snippet": "    def read_asrt(self):\n        # version\n        self.read_unsigned_char()\n        # flags\n        self.read(3)\n        quality_entry_count = self.read_unsigned_char()\n        # QualityEntryCount\n        for i in range(quality_entry_count):\n            self.read_string()\n\n        segment_run_count = self.read_unsigned_int()\n        segments = []\n        for i in range(segment_run_count):\n            first_segment = self.read_unsigned_int()\n            fragments_per_segment = self.read_unsigned_int()\n            segments.append((first_segment, fragments_per_segment))\n\n        return {\n            'segment_run': segments,\n        }",
        "begin_line": 59,
        "end_line": 78,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_afrt#80",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_afrt(self)",
        "snippet": "    def read_afrt(self):\n        # version\n        self.read_unsigned_char()\n        # flags\n        self.read(3)\n        # time scale\n        self.read_unsigned_int()\n\n        quality_entry_count = self.read_unsigned_char()\n        # QualitySegmentUrlModifiers\n        for i in range(quality_entry_count):\n            self.read_string()\n\n        fragments_count = self.read_unsigned_int()\n        fragments = []\n        for i in range(fragments_count):\n            first = self.read_unsigned_int()\n            first_ts = self.read_unsigned_long_long()\n            duration = self.read_unsigned_int()\n            if duration == 0:\n                discontinuity_indicator = self.read_unsigned_char()\n            else:\n                discontinuity_indicator = None\n            fragments.append({\n                'first': first,\n                'ts': first_ts,\n                'duration': duration,\n                'discontinuity_indicator': discontinuity_indicator,\n            })\n\n        return {\n            'fragments': fragments,\n        }",
        "begin_line": 80,
        "end_line": 112,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_abst#114",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_abst(self)",
        "snippet": "    def read_abst(self):\n        # version\n        self.read_unsigned_char()\n        # flags\n        self.read(3)\n\n        self.read_unsigned_int()  # BootstrapinfoVersion\n        # Profile,Live,Update,Reserved\n        self.read(1)\n        # time scale\n        self.read_unsigned_int()\n        # CurrentMediaTime\n        self.read_unsigned_long_long()\n        # SmpteTimeCodeOffset\n        self.read_unsigned_long_long()\n\n        self.read_string()  # MovieIdentifier\n        server_count = self.read_unsigned_char()\n        # ServerEntryTable\n        for i in range(server_count):\n            self.read_string()\n        quality_count = self.read_unsigned_char()\n        # QualityEntryTable\n        for i in range(quality_count):\n            self.read_string()\n        # DrmData\n        self.read_string()\n        # MetaData\n        self.read_string()\n\n        segments_count = self.read_unsigned_char()\n        segments = []\n        for i in range(segments_count):\n            box_size, box_type, box_data = self.read_box_info()\n            assert box_type == b'asrt'\n            segment = FlvReader(box_data).read_asrt()\n            segments.append(segment)\n        fragments_run_count = self.read_unsigned_char()\n        fragments = []\n        for i in range(fragments_run_count):\n            box_size, box_type, box_data = self.read_box_info()\n            assert box_type == b'afrt'\n            fragments.append(FlvReader(box_data).read_afrt())\n\n        return {\n            'segments': segments,\n            'fragments': fragments,\n        }",
        "begin_line": 114,
        "end_line": 161,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_bootstrap_info#163",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_bootstrap_info(self)",
        "snippet": "    def read_bootstrap_info(self):\n        total_size, box_type, box_data = self.read_box_info()\n        assert box_type == b'abst'\n        return FlvReader(box_data).read_abst()",
        "begin_line": 163,
        "end_line": 166,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.read_bootstrap_info#169",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m",
        "signature": "youtube_dl.downloader.f4m.read_bootstrap_info(bootstrap_bytes)",
        "snippet": "def read_bootstrap_info(bootstrap_bytes):\n    return FlvReader(bootstrap_bytes).read_bootstrap_info()",
        "begin_line": 169,
        "end_line": 170,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.build_fragments_list#173",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m",
        "signature": "youtube_dl.downloader.f4m.build_fragments_list(boot_info)",
        "snippet": "def build_fragments_list(boot_info):\n    \"\"\" Return a list of (segment, fragment) for each fragment in the video \"\"\"\n    res = []\n    segment_run_table = boot_info['segments'][0]\n    # I've only found videos with one segment\n    segment_run_entry = segment_run_table['segment_run'][0]\n    n_frags = segment_run_entry[1]\n    fragment_run_entry_table = boot_info['fragments'][0]['fragments']\n    first_frag_number = fragment_run_entry_table[0]['first']\n    for (i, frag_number) in zip(range(1, n_frags+1), itertools.count(first_frag_number)):\n        res.append((1, frag_number))\n    return res",
        "begin_line": 173,
        "end_line": 184,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.write_flv_header#187",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m",
        "signature": "youtube_dl.downloader.f4m.write_flv_header(stream, metadata)",
        "snippet": "def write_flv_header(stream, metadata):\n    \"\"\"Writes the FLV header and the metadata to stream\"\"\"\n    # FLV header\n    stream.write(b'FLV\\x01')\n    stream.write(b'\\x05')\n    stream.write(b'\\x00\\x00\\x00\\x09')\n    # FLV File body\n    stream.write(b'\\x00\\x00\\x00\\x00')\n    # FLVTAG\n    # Script data\n    stream.write(b'\\x12')\n    # Size of the metadata with 3 bytes\n    stream.write(struct_pack('!L', len(metadata))[1:])\n    stream.write(b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00')\n    stream.write(metadata)\n    # Magic numbers extracted from the output files produced by AdobeHDS.php\n    #(https://github.com/K-S-V/Scripts)\n    stream.write(b'\\x00\\x00\\x01\\x73')",
        "begin_line": 187,
        "end_line": 204,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.downloader.f4m._add_ns#207",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m",
        "signature": "youtube_dl.downloader.f4m._add_ns(prop)",
        "snippet": "def _add_ns(prop):\n    return '{http://ns.adobe.com/f4m/1.0}%s' % prop",
        "begin_line": 207,
        "end_line": 208,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.HttpQuietDownloader.to_screen#212",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.HttpQuietDownloader",
        "signature": "youtube_dl.downloader.f4m.HttpQuietDownloader.to_screen(self, *args, **kargs)",
        "snippet": "    def to_screen(self, *args, **kargs):\n        pass",
        "begin_line": 212,
        "end_line": 213,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.F4mFD.real_download#221",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.F4mFD",
        "signature": "youtube_dl.downloader.f4m.F4mFD.real_download(self, filename, info_dict)",
        "snippet": "    def real_download(self, filename, info_dict):\n        man_url = info_dict['url']\n        requested_bitrate = info_dict.get('tbr')\n        self.to_screen('[download] Downloading f4m manifest')\n        manifest = self.ydl.urlopen(man_url).read()\n        self.report_destination(filename)\n        http_dl = HttpQuietDownloader(self.ydl,\n            {\n                'continuedl': True,\n                'quiet': True,\n                'noprogress': True,\n                'test': self.params.get('test', False),\n            })\n\n        doc = etree.fromstring(manifest)\n        formats = [(int(f.attrib.get('bitrate', -1)), f) for f in doc.findall(_add_ns('media'))]\n        if requested_bitrate is None:\n            # get the best format\n            formats = sorted(formats, key=lambda f: f[0])\n            rate, media = formats[-1]\n        else:\n            rate, media = list(filter(\n                lambda f: int(f[0]) == requested_bitrate, formats))[0]\n\n        base_url = compat_urlparse.urljoin(man_url, media.attrib['url'])\n        bootstrap = base64.b64decode(doc.find(_add_ns('bootstrapInfo')).text)\n        metadata = base64.b64decode(media.find(_add_ns('metadata')).text)\n        boot_info = read_bootstrap_info(bootstrap)\n        fragments_list = build_fragments_list(boot_info)\n        if self.params.get('test', False):\n            # We only download the first fragment\n            fragments_list = fragments_list[:1]\n        total_frags = len(fragments_list)\n\n        tmpfilename = self.temp_name(filename)\n        (dest_stream, tmpfilename) = sanitize_open(tmpfilename, 'wb')\n        write_flv_header(dest_stream, metadata)\n\n        # This dict stores the download progress, it's updated by the progress\n        # hook\n        state = {\n            'downloaded_bytes': 0,\n            'frag_counter': 0,\n        }\n        start = time.time()\n\n        def frag_progress_hook(status):\n            frag_total_bytes = status.get('total_bytes', 0)\n            estimated_size = (state['downloaded_bytes'] +\n                (total_frags - state['frag_counter']) * frag_total_bytes)\n            if status['status'] == 'finished':\n                state['downloaded_bytes'] += frag_total_bytes\n                state['frag_counter'] += 1\n                progress = self.calc_percent(state['frag_counter'], total_frags)\n                byte_counter = state['downloaded_bytes']\n            else:\n                frag_downloaded_bytes = status['downloaded_bytes']\n                byte_counter = state['downloaded_bytes'] + frag_downloaded_bytes\n                frag_progress = self.calc_percent(frag_downloaded_bytes,\n                    frag_total_bytes)\n                progress = self.calc_percent(state['frag_counter'], total_frags)\n                progress += frag_progress / float(total_frags)\n\n            eta = self.calc_eta(start, time.time(), estimated_size, byte_counter)\n            self.report_progress(progress, format_bytes(estimated_size),\n                status.get('speed'), eta)\n        http_dl.add_progress_hook(frag_progress_hook)\n\n        frags_filenames = []\n        for (seg_i, frag_i) in fragments_list:\n            name = 'Seg%d-Frag%d' % (seg_i, frag_i)\n            url = base_url + name\n            frag_filename = '%s-%s' % (tmpfilename, name)\n            success = http_dl.download(frag_filename, {'url': url})\n            if not success:\n                return False\n            with open(frag_filename, 'rb') as down:\n                down_data = down.read()\n                reader = FlvReader(down_data)\n                while True:\n                    _, box_type, box_data = reader.read_box_info()\n                    if box_type == b'mdat':\n                        dest_stream.write(box_data)\n                        break\n            frags_filenames.append(frag_filename)\n\n        dest_stream.close()\n        self.report_finish(format_bytes(state['downloaded_bytes']), time.time() - start)\n\n        self.try_rename(tmpfilename, filename)\n        for frag_file in frags_filenames:\n            os.remove(frag_file)\n\n        fsize = os.path.getsize(encodeFilename(filename))\n        self._hook_progress({\n            'downloaded_bytes': fsize,\n            'total_bytes': fsize,\n            'filename': filename,\n            'status': 'finished',\n        })\n\n        return True",
        "begin_line": 221,
        "end_line": 322,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.sharesix.ShareSixIE._real_extract#43",
        "src_path": "youtube_dl/extractor/sharesix.py",
        "class_name": "youtube_dl.extractor.sharesix.ShareSixIE",
        "signature": "youtube_dl.extractor.sharesix.ShareSixIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        fields = {\n            'method_free': 'Free'\n        }\n        post = compat_urllib_parse.urlencode(fields)\n        req = compat_urllib_request.Request(url, post)\n        req.add_header('Content-type', 'application/x-www-form-urlencoded')\n\n        webpage = self._download_webpage(req, video_id,\n                                         'Downloading video page')\n\n        video_url = self._search_regex(\n            r\"var\\slnk1\\s=\\s'([^']+)'\", webpage, 'video URL')\n        title = self._html_search_regex(\n            r'(?s)<dt>Filename:</dt>.+?<dd>(.+?)</dd>', webpage, 'title')\n        duration = parse_duration(\n            self._search_regex(\n                r'(?s)<dt>Length:</dt>.+?<dd>(.+?)</dd>',\n                webpage,\n                'duration',\n                fatal=False\n            )\n        )\n\n        m = re.search(\n            r'''(?xs)<dt>Width\\sx\\sHeight</dt>.+?\n                     <dd>(?P<width>\\d+)\\sx\\s(?P<height>\\d+)</dd>''',\n            webpage\n        )\n        width = height = None\n        if m:\n            width, height = int(m.group('width')), int(m.group('height'))\n\n        formats = [{\n            'format_id': 'sd',\n            'url': video_url,\n            'width': width,\n            'height': height,\n        }]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 43,
        "end_line": 91,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.hotnewhiphop.HotNewHipHopIE._real_extract#26",
        "src_path": "youtube_dl/extractor/hotnewhiphop.py",
        "class_name": "youtube_dl.extractor.hotnewhiphop.HotNewHipHopIE",
        "signature": "youtube_dl.extractor.hotnewhiphop.HotNewHipHopIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('id')\n\n        webpage_src = self._download_webpage(url, video_id)\n\n        video_url_base64 = self._search_regex(\n            r'data-path=\"(.*?)\"', webpage_src, u'video URL', fatal=False)\n\n        if video_url_base64 is None:\n            video_url = self._search_regex(\n                r'\"contentUrl\" content=\"(.*?)\"', webpage_src, u'video URL')\n            return self.url_result(video_url, ie='Youtube')\n\n        reqdata = compat_urllib_parse.urlencode([\n            ('mediaType', 's'),\n            ('mediaId', video_id),\n        ])\n        r = compat_urllib_request.Request(\n            'http://www.hotnewhiphop.com/ajax/media/getActions/', data=reqdata)\n        r.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        mkd = self._download_json(\n            r, video_id, note='Requesting media key',\n            errnote='Could not download media key')\n        if 'mediaKey' not in mkd:\n            raise ExtractorError('Did not get a media key')\n\n        redirect_url = base64.b64decode(video_url_base64).decode('utf-8')\n        redirect_req = HEADRequest(redirect_url)\n        req = self._request_webpage(\n            redirect_req, video_id,\n            note='Resolving final URL', errnote='Could not resolve final URL')\n        video_url = req.geturl()\n        if video_url.endswith('.html'):\n            raise ExtractorError('Redirect failed')\n\n        video_title = self._og_search_title(webpage_src).strip()\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': video_title,\n            'thumbnail': self._og_search_thumbnail(webpage_src),\n        }",
        "begin_line": 26,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.jove.JoveIE._real_extract#43",
        "src_path": "youtube_dl/extractor/jove.py",
        "class_name": "youtube_dl.extractor.jove.JoveIE",
        "signature": "youtube_dl.extractor.jove.JoveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        chapters_id = self._html_search_regex(\n            r'/video-chapters\\?videoid=([0-9]+)', webpage, 'chapters id')\n\n        chapters_xml = self._download_xml(\n            self._CHAPTERS_URL.format(video_id=chapters_id),\n            video_id, note='Downloading chapters XML',\n            errnote='Failed to download chapters XML')\n\n        video_url = chapters_xml.attrib.get('video')\n        if not video_url:\n            raise ExtractorError('Failed to get the video URL')\n\n        title = self._html_search_meta('citation_title', webpage, 'title')\n        thumbnail = self._og_search_thumbnail(webpage)\n        description = self._html_search_regex(\n            r'<div id=\"section_body_summary\"><p class=\"jove_content\">(.+?)</p>',\n            webpage, 'description', fatal=False)\n        publish_date = unified_strdate(self._html_search_meta(\n            'citation_publication_date', webpage, 'publish date', fatal=False))\n        comment_count = self._html_search_regex(\n            r'<meta name=\"num_comments\" content=\"(\\d+) Comments?\"',\n            webpage, 'comment count', fatal=False)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'thumbnail': thumbnail,\n            'description': description,\n            'upload_date': publish_date,\n            'comment_count': comment_count,\n        }",
        "begin_line": 43,
        "end_line": 80,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.ndtv.NDTVIE._real_extract#29",
        "src_path": "youtube_dl/extractor/ndtv.py",
        "class_name": "youtube_dl.extractor.ndtv.NDTVIE",
        "signature": "youtube_dl.extractor.ndtv.NDTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        filename = self._search_regex(\n            r\"__filename='([^']+)'\", webpage, 'video filename')\n        video_url = ('http://bitcast-b.bitgravity.com/ndtvod/23372/ndtv/%s' %\n                     filename)\n\n        duration = int_or_none(self._search_regex(\n            r\"__duration='([^']+)'\", webpage, 'duration', fatal=False))\n\n        date_m = re.search(r'''(?x)\n            <p\\s+class=\"vod_dateline\">\\s*\n                Published\\s+On:\\s*\n                (?P<monthname>[A-Za-z]+)\\s+(?P<day>[0-9]+),\\s*(?P<year>[0-9]+)\n            ''', webpage)\n        upload_date = None\n\n        if date_m is not None:\n            month = month_by_name(date_m.group('monthname'))\n            if month is not None:\n                upload_date = '%s%02d%02d' % (\n                    date_m.group('year'), month, int(date_m.group('day')))\n\n        description = self._og_search_description(webpage)\n        READ_MORE = ' (Read more)'\n        if description.endswith(READ_MORE):\n            description = description[:-len(READ_MORE)]\n\n        title = self._og_search_title(webpage)\n        TITLE_SUFFIX = ' - NDTV'\n        if title.endswith(TITLE_SUFFIX):\n            title = title[:-len(TITLE_SUFFIX)]\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'duration': duration,\n            'upload_date': upload_date,\n        }",
        "begin_line": 29,
        "end_line": 74,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.wistia.WistiaIE._real_extract#23",
        "src_path": "youtube_dl/extractor/wistia.py",
        "class_name": "youtube_dl.extractor.wistia.WistiaIE",
        "signature": "youtube_dl.extractor.wistia.WistiaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        data_json = self._html_search_regex(\n            r'Wistia\\.iframeInit\\((.*?), {}\\);', webpage, 'video data')\n\n        data = json.loads(data_json)\n\n        formats = []\n        thumbnails = []\n        for atype, a in data['assets'].items():\n            if atype == 'still':\n                thumbnails.append({\n                    'url': a['url'],\n                    'resolution': '%dx%d' % (a['width'], a['height']),\n                })\n                continue\n            if atype == 'preview':\n                continue\n            formats.append({\n                'format_id': atype,\n                'url': a['url'],\n                'width': a['width'],\n                'height': a['height'],\n                'filesize': a['size'],\n                'ext': a['ext'],\n                'preference': 1 if atype == 'original' else None,\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': data['name'],\n            'formats': formats,\n            'thumbnails': thumbnails,\n            'duration': data.get('duration'),\n        }",
        "begin_line": 23,
        "end_line": 62,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.spiegel.SpiegelIE._real_extract#34",
        "src_path": "youtube_dl/extractor/spiegel.py",
        "class_name": "youtube_dl.extractor.spiegel.SpiegelIE",
        "signature": "youtube_dl.extractor.spiegel.SpiegelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('videoID')\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(\n            r'<div class=\"module-title\">(.*?)</div>', webpage, 'title')\n        description = self._html_search_meta('description', webpage, 'description')\n\n        base_url = self._search_regex(\n            r'var\\s+server\\s*=\\s*\"([^\"]+)\\\"', webpage, 'server URL')\n\n        xml_url = base_url + video_id + '.xml'\n        idoc = self._download_xml(xml_url, video_id)\n\n        formats = [\n            {\n                'format_id': n.tag.rpartition('type')[2],\n                'url': base_url + n.find('./filename').text,\n                'width': int(n.find('./width').text),\n                'height': int(n.find('./height').text),\n                'abr': int(n.find('./audiobitrate').text),\n                'vbr': int(n.find('./videobitrate').text),\n                'vcodec': n.find('./codec').text,\n                'acodec': 'MP4A',\n            }\n            for n in list(idoc)\n            # Blacklist type 6, it's extremely LQ and not available on the same server\n            if n.tag.startswith('type') and n.tag != 'type6'\n        ]\n        duration = float(idoc[0].findall('./duration')[0].text)\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 34,
        "end_line": 75,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.spiegel.SpiegelArticleIE._real_extract#92",
        "src_path": "youtube_dl/extractor/spiegel.py",
        "class_name": "youtube_dl.extractor.spiegel.SpiegelArticleIE",
        "signature": "youtube_dl.extractor.spiegel.SpiegelArticleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        video_link = self._search_regex(\n            r'<a href=\"([^\"]+)\" onclick=\"return spOpenVideo\\(this,', webpage,\n            'video page URL')\n        video_url = compat_urlparse.urljoin(\n            self.http_scheme() + '//spiegel.de/', video_link)\n\n        return {\n            '_type': 'url',\n            'url': video_url,\n        }",
        "begin_line": 92,
        "end_line": 106,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.postprocessor.atomicparsley.AtomicParsleyPP.run#25",
        "src_path": "youtube_dl/postprocessor/atomicparsley.py",
        "class_name": "youtube_dl.postprocessor.atomicparsley.AtomicParsleyPP",
        "signature": "youtube_dl.postprocessor.atomicparsley.AtomicParsleyPP.run(self, info)",
        "snippet": "    def run(self, info):\n        if not check_executable('AtomicParsley', ['-v']):\n            raise AtomicParsleyPPError('AtomicParsley was not found. Please install.')\n\n        filename = info['filepath']\n        temp_filename = prepend_extension(filename, 'temp')\n        temp_thumbnail = prepend_extension(filename, 'thumb')\n\n        if not info.get('thumbnail'):\n            raise AtomicParsleyPPError('Thumbnail was not found. Nothing to do.')\n\n        compat_urlretrieve(info['thumbnail'], temp_thumbnail)\n\n        cmd = ['AtomicParsley', filename, '--artwork', temp_thumbnail, '-o', temp_filename]\n\n        self._downloader.to_screen('[atomicparsley] Adding thumbnail to \"%s\"' % filename)\n\n        if self._downloader.params.get('verbose', False):\n            self._downloader.to_screen('[debug] AtomicParsley command line: %s' % shell_quote(cmd))\n\n        p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        stdout, stderr = p.communicate()\n\n        if p.returncode != 0:\n            msg = stderr.decode('utf-8', 'replace').strip()\n            raise AtomicParsleyPPError(msg)\n\n        os.remove(encodeFilename(filename))\n        os.remove(encodeFilename(temp_thumbnail))\n        os.rename(encodeFilename(temp_filename), encodeFilename(filename))\n\n        return True, info",
        "begin_line": 25,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.vporn.VpornIE._real_extract#31",
        "src_path": "youtube_dl/extractor/vporn.py",
        "class_name": "youtube_dl.extractor.vporn.VpornIE",
        "signature": "youtube_dl.extractor.vporn.VpornIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        display_id = mobj.group('display_id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        title = self._html_search_regex(\n            r'videoname\\s*=\\s*\\'([^\\']+)\\'', webpage, 'title').strip()\n        description = self._html_search_regex(\n            r'<div class=\"description_txt\">(.*?)</div>', webpage, 'description', fatal=False)\n        thumbnail = self._html_search_regex(\n            r'flashvars\\.imageUrl\\s*=\\s*\"([^\"]+)\"', webpage, 'description', fatal=False, default=None)\n        if thumbnail:\n            thumbnail = 'http://www.vporn.com' + thumbnail\n\n        uploader = self._html_search_regex(\n            r'(?s)UPLOADED BY.*?<a href=\"/user/[^\"]+\">([^<]+)</a>',\n            webpage, 'uploader', fatal=False)\n\n        categories = re.findall(r'<a href=\"/cat/[^\"]+\">([^<]+)</a>', webpage)\n\n        duration = parse_duration(self._search_regex(\n            r'duration (\\d+ min \\d+ sec)', webpage, 'duration', fatal=False))\n\n        view_count = str_to_int(self._html_search_regex(\n            r'<span>([\\d,\\.]+) VIEWS</span>', webpage, 'view count', fatal=False))\n        like_count = str_to_int(self._html_search_regex(\n            r'<span id=\"like\" class=\"n\">([\\d,\\.]+)</span>', webpage, 'like count', fatal=False))\n        dislike_count = str_to_int(self._html_search_regex(\n            r'<span id=\"dislike\" class=\"n\">([\\d,\\.]+)</span>', webpage, 'dislike count', fatal=False))\n        comment_count = str_to_int(self._html_search_regex(\n            r'<h4>Comments \\(<b>([\\d,\\.]+)</b>\\)</h4>', webpage, 'comment count', fatal=False))\n\n        formats = []\n\n        for video in re.findall(r'flashvars\\.videoUrl([^=]+?)\\s*=\\s*\"([^\"]+)\"', webpage):\n            video_url = video[1]\n            fmt = {\n                'url': video_url,\n                'format_id': video[0],\n            }\n            m = re.search(r'_(?P<width>\\d+)x(?P<height>\\d+)_(?P<vbr>\\d+)k\\.mp4$', video_url)\n            if m:\n                fmt.update({\n                    'width': int(m.group('width')),\n                    'height': int(m.group('height')),\n                    'vbr': int(m.group('vbr')),\n                })\n            formats.append(fmt)\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'categories': categories,\n            'duration': duration,\n            'view_count': view_count,\n            'like_count': like_count,\n            'dislike_count': dislike_count,\n            'comment_count': comment_count,\n            'age_limit': 18,\n            'formats': formats,\n        }",
        "begin_line": 31,
        "end_line": 99,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.pornoxo.PornoXOIE._real_extract#27",
        "src_path": "youtube_dl/extractor/pornoxo.py",
        "class_name": "youtube_dl.extractor.pornoxo.PornoXOIE",
        "signature": "youtube_dl.extractor.pornoxo.PornoXOIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = self._html_search_regex(\n            r'\\'file\\'\\s*:\\s*\"([^\"]+)\"', webpage, 'video_url')\n\n        title = self._html_search_regex(\n            r'<title>([^<]+)\\s*-\\s*PornoXO', webpage, 'title')\n\n        description = self._html_search_regex(\n            r'<meta name=\"description\" content=\"([^\"]+)\\s*featuring',\n            webpage, 'description', fatal=False)\n\n        thumbnail = self._html_search_regex(\n            r'\\'image\\'\\s*:\\s*\"([^\"]+)\"', webpage, 'thumbnail', fatal=False)\n\n        view_count = str_to_int(self._html_search_regex(\n            r'[vV]iews:\\s*([0-9,]+)', webpage, 'view count', fatal=False))\n\n        categories_str = self._html_search_regex(\n            r'<meta name=\"description\" content=\".*featuring\\s*([^\"]+)\"',\n            webpage, 'categories', fatal=False)\n        categories = (\n            None if categories_str is None\n            else categories_str.split(','))\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'categories': categories,\n            'view_count': view_count,\n            'age_limit': 18,\n        }",
        "begin_line": 27,
        "end_line": 65,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.ellentv.EllenTVIE._real_extract#28",
        "src_path": "youtube_dl/extractor/ellentv.py",
        "class_name": "youtube_dl.extractor.ellentv.EllenTVIE",
        "signature": "youtube_dl.extractor.ellentv.EllenTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        timestamp = parse_iso8601(self._search_regex(\n            r'<span class=\"publish-date\"><time datetime=\"([^\"]+)\">',\n            webpage, 'timestamp'))\n\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n            'url': self._html_search_meta('VideoURL', webpage, 'url'),\n            'timestamp': timestamp,\n        }",
        "begin_line": 28,
        "end_line": 42,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.ellentv.EllenTVClipsIE._real_extract#57",
        "src_path": "youtube_dl/extractor/ellentv.py",
        "class_name": "youtube_dl.extractor.ellentv.EllenTVClipsIE",
        "signature": "youtube_dl.extractor.ellentv.EllenTVClipsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, playlist_id)\n        playlist = self._extract_playlist(webpage)\n\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'title': self._og_search_title(webpage),\n            'entries': self._extract_entries(playlist)\n        }",
        "begin_line": 57,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.ellentv.EllenTVClipsIE._extract_playlist#71",
        "src_path": "youtube_dl/extractor/ellentv.py",
        "class_name": "youtube_dl.extractor.ellentv.EllenTVClipsIE",
        "signature": "youtube_dl.extractor.ellentv.EllenTVClipsIE._extract_playlist(self, webpage)",
        "snippet": "    def _extract_playlist(self, webpage):\n        json_string = self._search_regex(r'playerView.addClips\\(\\[\\{(.*?)\\}\\]\\);', webpage, 'json')\n        try:\n            return json.loads(\"[{\" + json_string + \"}]\")\n        except ValueError as ve:\n            raise ExtractorError('Failed to download JSON', cause=ve)",
        "begin_line": 71,
        "end_line": 76,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.ellentv.EllenTVClipsIE._extract_entries#78",
        "src_path": "youtube_dl/extractor/ellentv.py",
        "class_name": "youtube_dl.extractor.ellentv.EllenTVClipsIE",
        "signature": "youtube_dl.extractor.ellentv.EllenTVClipsIE._extract_entries(self, playlist)",
        "snippet": "    def _extract_entries(self, playlist):\n        return [self.url_result(item['url'], 'EllenTV') for item in playlist]",
        "begin_line": 78,
        "end_line": 79,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.tudou.TudouIE._url_for_id#39",
        "src_path": "youtube_dl/extractor/tudou.py",
        "class_name": "youtube_dl.extractor.tudou.TudouIE",
        "signature": "youtube_dl.extractor.tudou.TudouIE._url_for_id(self, id, quality=None)",
        "snippet": "    def _url_for_id(self, id, quality = None):\n        info_url = \"http://v2.tudou.com/f?id=\"+str(id)\n        if quality:\n            info_url += '&hd' + quality\n        webpage = self._download_webpage(info_url, id, \"Opening the info webpage\")\n        final_url = self._html_search_regex('>(.+?)</f>',webpage, 'video url')\n        return final_url",
        "begin_line": 39,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.tudou.TudouIE._real_extract#47",
        "src_path": "youtube_dl/extractor/tudou.py",
        "class_name": "youtube_dl.extractor.tudou.TudouIE",
        "signature": "youtube_dl.extractor.tudou.TudouIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group(2)\n        webpage = self._download_webpage(url, video_id)\n\n        m = re.search(r'vcode:\\s*[\\'\"](.+?)[\\'\"]', webpage)\n        if m and m.group(1):\n            return {\n                '_type': 'url',\n                'url': 'youku:' + m.group(1),\n                'ie_key': 'Youku'\n            }\n\n        title = self._search_regex(\n            r\",kw:\\s*['\\\"](.+?)[\\\"']\", webpage, 'title')\n        thumbnail_url = self._search_regex(\n            r\",pic:\\s*[\\\"'](.+?)[\\\"']\", webpage, 'thumbnail URL', fatal=False)\n\n        segs_json = self._search_regex(r'segs: \\'(.*)\\'', webpage, 'segments')\n        segments = json.loads(segs_json)\n        # It looks like the keys are the arguments that have to be passed as\n        # the hd field in the request url, we pick the higher\n        # Also, filter non-number qualities (see issue #3643).\n        quality = sorted(filter(lambda k: k.isdigit(), segments.keys()),\n                         key=lambda k: int(k))[-1]\n        parts = segments[quality]\n        result = []\n        len_parts = len(parts)\n        if len_parts > 1:\n            self.to_screen(u'%s: found %s parts' % (video_id, len_parts))\n        for part in parts:\n            part_id = part['k']\n            final_url = self._url_for_id(part_id, quality)\n            ext = (final_url.split('?')[0]).split('.')[-1]\n            part_info = {\n                'id': '%s' % part_id,\n                'url': final_url,\n                'ext': ext,\n                'title': title,\n                'thumbnail': thumbnail_url,\n            }\n            result.append(part_info)\n\n        return result",
        "begin_line": 47,
        "end_line": 90,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.daum.DaumIE._real_extract#29",
        "src_path": "youtube_dl/extractor/daum.py",
        "class_name": "youtube_dl.extractor.daum.DaumIE",
        "signature": "youtube_dl.extractor.daum.DaumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group(1)\n        canonical_url = 'http://tvpot.daum.net/v/%s' % video_id\n        webpage = self._download_webpage(canonical_url, video_id)\n        full_id = self._search_regex(\n            r'<iframe src=\"http://videofarm.daum.net/controller/video/viewer/Video.html\\?.*?vid=(.+?)[&\"]',\n            webpage, 'full id')\n        query = compat_urllib_parse.urlencode({'vid': full_id})\n        info = self._download_xml(\n            'http://tvpot.daum.net/clip/ClipInfoXml.do?' + query, video_id,\n            'Downloading video info')\n        urls = self._download_xml(\n            'http://videofarm.daum.net/controller/api/open/v1_2/MovieData.apixml?' + query,\n            video_id, 'Downloading video formats info')\n\n        self.to_screen(u'%s: Getting video urls' % video_id)\n        formats = []\n        for format_el in urls.findall('result/output_list/output_list'):\n            profile = format_el.attrib['profile']\n            format_query = compat_urllib_parse.urlencode({\n                'vid': full_id,\n                'profile': profile,\n            })\n            url_doc = self._download_xml(\n                'http://videofarm.daum.net/controller/api/open/v1_2/MovieLocation.apixml?' + format_query,\n                video_id, note=False)\n            format_url = url_doc.find('result/url').text\n            formats.append({\n                'url': format_url,\n                'format_id': profile,\n            })\n\n        return {\n            'id': video_id,\n            'title': info.find('TITLE').text,\n            'formats': formats,\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'description': info.find('CONTENTS').text,\n            'duration': int(info.find('DURATION').text),\n            'upload_date': info.find('REGDTTM').text[:8],\n        }",
        "begin_line": 29,
        "end_line": 70,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.hostingbulk.HostingBulkIE._real_extract#32",
        "src_path": "youtube_dl/extractor/hostingbulk.py",
        "class_name": "youtube_dl.extractor.hostingbulk.HostingBulkIE",
        "signature": "youtube_dl.extractor.hostingbulk.HostingBulkIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        url = 'http://hostingbulk.com/{0:}.html'.format(video_id)\n\n        # Custom request with cookie to set language to English, so our file\n        # deleted regex would work.\n        request = compat_urllib_request.Request(\n            url, headers={'Cookie': 'lang=english'})\n        webpage = self._download_webpage(request, video_id)\n\n        if re.search(self._FILE_DELETED_REGEX, webpage) is not None:\n            raise ExtractorError('Video %s does not exist' % video_id,\n                                 expected=True)\n\n        title = self._html_search_regex(r'<h3>(.*?)</h3>', webpage, 'title')\n        filesize = int_or_none(\n            self._search_regex(\n                r'<small>\\((\\d+)\\sbytes?\\)</small>',\n                webpage,\n                'filesize',\n                fatal=False\n            )\n        )\n        thumbnail = self._search_regex(\n            r'<img src=\"([^\"]+)\".+?class=\"pic\"',\n            webpage, 'thumbnail', fatal=False)\n\n        fields = dict(re.findall(r'''(?x)<input\\s+\n            type=\"hidden\"\\s+\n            name=\"([^\"]+)\"\\s+\n            value=\"([^\"]*)\"\n            ''', webpage))\n\n        request = compat_urllib_request.Request(url, urlencode_postdata(fields))\n        request.add_header('Content-type', 'application/x-www-form-urlencoded')\n        response = self._request_webpage(request, video_id,\n                                         'Submiting download request')\n        video_url = response.geturl()\n\n        formats = [{\n            'format_id': 'sd',\n            'filesize': filesize,\n            'url': video_url,\n        }]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 32,
        "end_line": 84,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.xnxx.XNXXIE._real_extract#25",
        "src_path": "youtube_dl/extractor/xnxx.py",
        "class_name": "youtube_dl.extractor.xnxx.XNXXIE",
        "signature": "youtube_dl.extractor.xnxx.XNXXIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        # Get webpage content\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = self._search_regex(r'flv_url=(.*?)&amp;',\n            webpage, 'video URL')\n        video_url = compat_urllib_parse.unquote(video_url)\n\n        video_title = self._html_search_regex(r'<title>(.*?)\\s+-\\s+XNXX.COM',\n            webpage, 'title')\n\n        video_thumbnail = self._search_regex(r'url_bigthumb=(.*?)&amp;',\n            webpage, 'thumbnail', fatal=False)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': video_title,\n            'ext': 'flv',\n            'thumbnail': video_thumbnail,\n            'age_limit': 18,\n        }",
        "begin_line": 25,
        "end_line": 49,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.videobam.VideoBamIE._real_extract#37",
        "src_path": "youtube_dl/extractor/videobam.py",
        "class_name": "youtube_dl.extractor.videobam.VideoBamIE",
        "signature": "youtube_dl.extractor.videobam.VideoBamIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        page = self._download_webpage('http://videobam.com/%s' % video_id, video_id, 'Downloading page')\n\n        formats = []\n\n        for preference, format_id in enumerate(['low', 'high']):\n            mobj = re.search(r\"%s: '(?P<url>[^']+)'\" % format_id, page)\n            if not mobj:\n                continue\n            formats.append({\n                'url': mobj.group('url'),\n                'ext': 'mp4',\n                'format_id': format_id,\n                'preference': preference,\n            })\n\n        if not formats:\n            player_config = json.loads(self._html_search_regex(r'var player_config = ({.+?});', page, 'player config'))\n            formats = [{\n                'url': item['url'],\n                'ext': 'mp4',\n            } for item in player_config['playlist'] if 'autoPlay' in item]\n\n        self._sort_formats(formats)\n\n        title = self._og_search_title(page, default='_', fatal=False)\n        description = self._og_search_description(page, default=None)\n        thumbnail = self._og_search_thumbnail(page)\n        uploader = self._html_search_regex(r'Upload by ([^<]+)</a>', page, 'uploader', fatal=False, default=None)\n        view_count = int_or_none(\n            self._html_search_regex(r'<strong>Views:</strong> (\\d+) ', page, 'view count', fatal=False))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'view_count': view_count,\n            'formats': formats,\n            'age_limit': 18,\n        }",
        "begin_line": 37,
        "end_line": 81,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._set_language#46",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._set_language(self)",
        "snippet": "    def _set_language(self):\n        return bool(self._download_webpage(\n            self._LANG_URL, None,\n            note=u'Setting language', errnote='unable to set language',\n            fatal=False))",
        "begin_line": 46,
        "end_line": 50,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0025,
            "pseudo_dstar_susp": 0.0024752475247524753,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0024752475247524753,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._login#52",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._login(self)",
        "snippet": "    def _login(self):\n        \"\"\"\n        Attempt to log in to YouTube.\n        True is returned if successful or skipped.\n        False is returned if login failed.\n\n        If _LOGIN_REQUIRED is set and no authentication was provided, an error is raised.\n        \"\"\"\n        (username, password) = self._get_login_info()\n        # No authentication to be performed\n        if username is None:\n            if self._LOGIN_REQUIRED:\n                raise ExtractorError(u'No login info available, needed for using %s.' % self.IE_NAME, expected=True)\n            return True\n\n        login_page = self._download_webpage(\n            self._LOGIN_URL, None,\n            note=u'Downloading login page',\n            errnote=u'unable to fetch login page', fatal=False)\n        if login_page is False:\n            return\n\n        galx = self._search_regex(r'(?s)<input.+?name=\"GALX\".+?value=\"(.+?)\"',\n                                  login_page, 'Login GALX parameter')\n\n        # Log in\n        login_form_strs = {\n                'continue': 'https://www.youtube.com/signin?action_handle_signin=true&feature=sign_in_button&hl=en_US&nomobiletemp=1',\n                'Email': username,\n                'GALX': galx,\n                'Passwd': password,\n\n                'PersistentCookie': 'yes',\n                '_utf8': '\u9731',\n                'bgresponse': 'js_disabled',\n                'checkConnection': '',\n                'checkedDomains': 'youtube',\n                'dnConn': '',\n                'pstMsg': '0',\n                'rmShown': '1',\n                'secTok': '',\n                'signIn': 'Sign in',\n                'timeStmp': '',\n                'service': 'youtube',\n                'uilel': '3',\n                'hl': 'en_US',\n        }\n\n        # Convert to UTF-8 *before* urlencode because Python 2.x's urlencode\n        # chokes on unicode\n        login_form = dict((k.encode('utf-8'), v.encode('utf-8')) for k,v in login_form_strs.items())\n        login_data = compat_urllib_parse.urlencode(login_form).encode('ascii')\n\n        req = compat_urllib_request.Request(self._LOGIN_URL, login_data)\n        login_results = self._download_webpage(\n            req, None,\n            note=u'Logging in', errnote=u'unable to log in', fatal=False)\n        if login_results is False:\n            return False\n\n        if re.search(r'id=\"errormsg_0_Passwd\"', login_results) is not None:\n            raise ExtractorError(u'Please use your account password and a two-factor code instead of an application-specific password.', expected=True)\n\n        # Two-Factor\n        # TODO add SMS and phone call support - these require making a request and then prompting the user\n\n        if re.search(r'(?i)<form[^>]* id=\"gaia_secondfactorform\"', login_results) is not None:\n            tfa_code = self._get_tfa_info()\n\n            if tfa_code is None:\n                self._downloader.report_warning(u'Two-factor authentication required. Provide it with --twofactor <code>')\n                self._downloader.report_warning(u'(Note that only TOTP (Google Authenticator App) codes work at this time.)')\n                return False\n\n            # Unlike the first login form, secTok and timeStmp are both required for the TFA form\n\n            match = re.search(r'id=\"secTok\"\\n\\s+value=\\'(.+)\\'/>', login_results, re.M | re.U)\n            if match is None:\n                self._downloader.report_warning(u'Failed to get secTok - did the page structure change?')\n            secTok = match.group(1)\n            match = re.search(r'id=\"timeStmp\"\\n\\s+value=\\'(.+)\\'/>', login_results, re.M | re.U)\n            if match is None:\n                self._downloader.report_warning(u'Failed to get timeStmp - did the page structure change?')\n            timeStmp = match.group(1)\n\n            tfa_form_strs = {\n                'continue': 'https://www.youtube.com/signin?action_handle_signin=true&feature=sign_in_button&hl=en_US&nomobiletemp=1',\n                'smsToken': '',\n                'smsUserPin': tfa_code,\n                'smsVerifyPin': 'Verify',\n\n                'PersistentCookie': 'yes',\n                'checkConnection': '',\n                'checkedDomains': 'youtube',\n                'pstMsg': '1',\n                'secTok': secTok,\n                'timeStmp': timeStmp,\n                'service': 'youtube',\n                'hl': 'en_US',\n            }\n            tfa_form = dict((k.encode('utf-8'), v.encode('utf-8')) for k,v in tfa_form_strs.items())\n            tfa_data = compat_urllib_parse.urlencode(tfa_form).encode('ascii')\n\n            tfa_req = compat_urllib_request.Request(self._TWOFACTOR_URL, tfa_data)\n            tfa_results = self._download_webpage(\n                tfa_req, None,\n                note=u'Submitting TFA code', errnote=u'unable to submit tfa', fatal=False)\n\n            if tfa_results is False:\n                return False\n\n            if re.search(r'(?i)<form[^>]* id=\"gaia_secondfactorform\"', tfa_results) is not None:\n                self._downloader.report_warning(u'Two-factor code expired. Please try again, or use a one-use backup code instead.')\n                return False\n            if re.search(r'(?i)<form[^>]* id=\"gaia_loginform\"', tfa_results) is not None:\n                self._downloader.report_warning(u'unable to log in - did the page structure change?')\n                return False\n            if re.search(r'smsauth-interstitial-reviewsettings', tfa_results) is not None:\n                self._downloader.report_warning(u'Your Google account has a security notice. Please log in on your web browser, resolve the notice, and try again.')\n                return False\n\n        if re.search(r'(?i)<form[^>]* id=\"gaia_loginform\"', login_results) is not None:\n            self._downloader.report_warning(u'unable to log in: bad username or password')\n            return False\n        return True",
        "begin_line": 52,
        "end_line": 176,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002932551319648094,
            "pseudo_dstar_susp": 0.002688172043010753,
            "pseudo_tarantula_susp": 0.0003360215053763441,
            "pseudo_op2_susp": 0.002688172043010753,
            "pseudo_barinel_susp": 0.0003360215053763441
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._confirm_age#178",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._confirm_age(self)",
        "snippet": "    def _confirm_age(self):\n        age_form = {\n            'next_url': '/',\n            'action_confirm': 'Confirm',\n        }\n        req = compat_urllib_request.Request(self._AGE_URL,\n            compat_urllib_parse.urlencode(age_form).encode('ascii'))\n\n        self._download_webpage(\n            req, None,\n            note=u'Confirming age', errnote=u'Unable to confirm age')\n        return True",
        "begin_line": 178,
        "end_line": 189,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0025,
            "pseudo_dstar_susp": 0.0024752475247524753,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0024752475247524753,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._real_initialize#191",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        if self._downloader is None:\n            return\n        if not self._set_language():\n            return\n        if not self._login():\n            return\n        self._confirm_age()",
        "begin_line": 191,
        "end_line": 198,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0025,
            "pseudo_dstar_susp": 0.0024752475247524753,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0024752475247524753,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.__init__#394",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.__init__(self, *args, **kwargs)",
        "snippet": "    def __init__(self, *args, **kwargs):\n        super(YoutubeIE, self).__init__(*args, **kwargs)\n        self._player_cache = {}",
        "begin_line": 394,
        "end_line": 396,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.006578947368421052,
            "pseudo_dstar_susp": 0.010416666666666666,
            "pseudo_tarantula_susp": 0.0002984183825723665,
            "pseudo_op2_susp": 0.010416666666666666,
            "pseudo_barinel_susp": 0.0002984183825723665
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.report_video_info_webpage_download#398",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.report_video_info_webpage_download(self, video_id)",
        "snippet": "    def report_video_info_webpage_download(self, video_id):\n        \"\"\"Report attempt to download video info webpage.\"\"\"\n        self.to_screen(u'%s: Downloading video info webpage' % video_id)",
        "begin_line": 398,
        "end_line": 400,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.report_information_extraction#402",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.report_information_extraction(self, video_id)",
        "snippet": "    def report_information_extraction(self, video_id):\n        \"\"\"Report attempt to extract video information.\"\"\"\n        self.to_screen(u'%s: Extracting video information' % video_id)",
        "begin_line": 402,
        "end_line": 404,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.report_unavailable_format#406",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.report_unavailable_format(self, video_id, format)",
        "snippet": "    def report_unavailable_format(self, video_id, format):\n        \"\"\"Report extracted video URL.\"\"\"\n        self.to_screen(u'%s: Format %s not available' % (video_id, format))",
        "begin_line": 406,
        "end_line": 408,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.report_rtmp_download#410",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.report_rtmp_download(self)",
        "snippet": "    def report_rtmp_download(self):\n        \"\"\"Indicate the download will use the RTMP protocol.\"\"\"\n        self.to_screen(u'RTMP download detected')",
        "begin_line": 410,
        "end_line": 412,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._signature_cache_id#414",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._signature_cache_id(self, example_sig)",
        "snippet": "    def _signature_cache_id(self, example_sig):\n        \"\"\" Return a string representation of a signature \"\"\"\n        return '.'.join(compat_str(len(part)) for part in example_sig.split('.'))",
        "begin_line": 414,
        "end_line": 416,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._extract_signature_function#418",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._extract_signature_function(self, video_id, player_url, example_sig)",
        "snippet": "    def _extract_signature_function(self, video_id, player_url, example_sig):\n        id_m = re.match(\n            r'.*-(?P<id>[a-zA-Z0-9_-]+)(?:/watch_as3|/html5player)?\\.(?P<ext>[a-z]+)$',\n            player_url)\n        if not id_m:\n            raise ExtractorError('Cannot identify player %r' % player_url)\n        player_type = id_m.group('ext')\n        player_id = id_m.group('id')\n\n        # Read from filesystem cache\n        func_id = '%s_%s_%s' % (\n            player_type, player_id, self._signature_cache_id(example_sig))\n        assert os.path.basename(func_id) == func_id\n\n        cache_spec = self._downloader.cache.load(u'youtube-sigfuncs', func_id)\n        if cache_spec is not None:\n            return lambda s: ''.join(s[i] for i in cache_spec)\n\n        if player_type == 'js':\n            code = self._download_webpage(\n                player_url, video_id,\n                note=u'Downloading %s player %s' % (player_type, player_id),\n                errnote=u'Download of %s failed' % player_url)\n            res = self._parse_sig_js(code)\n        elif player_type == 'swf':\n            urlh = self._request_webpage(\n                player_url, video_id,\n                note=u'Downloading %s player %s' % (player_type, player_id),\n                errnote=u'Download of %s failed' % player_url)\n            code = urlh.read()\n            res = self._parse_sig_swf(code)\n        else:\n            assert False, 'Invalid player type %r' % player_type\n\n        if cache_spec is None:\n            test_string = ''.join(map(compat_chr, range(len(example_sig))))\n            cache_res = res(test_string)\n            cache_spec = [ord(c) for c in cache_res]\n\n        self._downloader.cache.store(u'youtube-sigfuncs', func_id, cache_spec)\n        return res",
        "begin_line": 418,
        "end_line": 458,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._print_sig_code#460",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._print_sig_code(self, func, example_sig)",
        "snippet": "    def _print_sig_code(self, func, example_sig):\n        def gen_sig_code(idxs):\n            def _genslice(start, end, step):\n                starts = '' if start == 0 else str(start)\n                ends = (u':%d' % (end+step)) if end + step >= 0 else ':'\n                steps = '' if step == 1 else (u':%d' % step)\n                return 's[%s%s%s]' % (starts, ends, steps)\n\n            step = None\n            start = '(Never used)'  # Quelch pyflakes warnings - start will be\n                                    # set as soon as step is set\n            for i, prev in zip(idxs[1:], idxs[:-1]):\n                if step is not None:\n                    if i - prev == step:\n                        continue\n                    yield _genslice(start, prev, step)\n                    step = None\n                    continue\n                if i - prev in [-1, 1]:\n                    step = i - prev\n                    start = prev\n                    continue\n                else:\n                    yield 's[%d]' % prev\n            if step is None:\n                yield 's[%d]' % i\n            else:\n                yield _genslice(start, i, step)\n\n        test_string = ''.join(map(compat_chr, range(len(example_sig))))\n        cache_res = func(test_string)\n        cache_spec = [ord(c) for c in cache_res]\n        expr_code = ' + '.join(gen_sig_code(cache_spec))\n        signature_id_tuple = '(%s)' % (\n            ', '.join(compat_str(len(p)) for p in example_sig.split('.')))\n        code = (u'if tuple(len(p) for p in s.split(\\'.\\')) == %s:\\n'\n                '    return %s\\n') % (signature_id_tuple, expr_code)\n        self.to_screen(u'Extracted signature function:\\n' + code)",
        "begin_line": 460,
        "end_line": 497,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._parse_sig_js#499",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._parse_sig_js(self, jscode)",
        "snippet": "    def _parse_sig_js(self, jscode):\n        funcname = self._search_regex(\n            r'signature=([$a-zA-Z]+)', jscode,\n             'Initial JS player signature function name')\n\n        jsi = JSInterpreter(jscode)\n        initial_function = jsi.extract_function(funcname)\n        return lambda s: initial_function([s])",
        "begin_line": 499,
        "end_line": 506,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 6.729927989770509e-05,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._parse_sig_swf#508",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._parse_sig_swf(self, file_contents)",
        "snippet": "    def _parse_sig_swf(self, file_contents):\n        swfi = SWFInterpreter(file_contents)\n        TARGET_CLASSNAME = 'SignatureDecipher'\n        searched_class = swfi.extract_class(TARGET_CLASSNAME)\n        initial_function = swfi.extract_function(searched_class, 'decipher')\n        return lambda s: initial_function([s])",
        "begin_line": 508,
        "end_line": 513,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._decrypt_signature#515",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._decrypt_signature(self, s, video_id, player_url, age_gate=False)",
        "snippet": "    def _decrypt_signature(self, s, video_id, player_url, age_gate=False):\n        \"\"\"Turn the encrypted s field into a working signature\"\"\"\n\n        if player_url is None:\n            raise ExtractorError(u'Cannot decrypt signature without player_url')\n\n        if player_url.startswith(u'//'):\n            player_url = 'https:' + player_url\n        try:\n            player_id = (player_url, self._signature_cache_id(s))\n            if player_id not in self._player_cache:\n                func = self._extract_signature_function(\n                    video_id, player_url, s\n                )\n                self._player_cache[player_id] = func\n            func = self._player_cache[player_id]\n            if self._downloader.params.get('youtube_print_sig_code'):\n                self._print_sig_code(func, s)\n            return func(s)\n        except Exception as e:\n            tb = traceback.format_exc()\n            raise ExtractorError(\n                'Signature extraction failed: ' + tb, cause=e)",
        "begin_line": 515,
        "end_line": 537,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._get_available_subtitles#539",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._get_available_subtitles(self, video_id, webpage)",
        "snippet": "    def _get_available_subtitles(self, video_id, webpage):\n        try:\n            sub_list = self._download_webpage(\n                'https://video.google.com/timedtext?hl=en&type=list&v=%s' % video_id,\n                video_id, note=False)\n        except ExtractorError as err:\n            self._downloader.report_warning(u'unable to download video subtitles: %s' % compat_str(err))\n            return {}\n        lang_list = re.findall(r'name=\"([^\"]*)\"[^>]+lang_code=\"([\\w\\-]+)\"', sub_list)\n\n        sub_lang_list = {}\n        for l in lang_list:\n            lang = l[1]\n            if lang in sub_lang_list:\n                continue\n            params = compat_urllib_parse.urlencode({\n                'lang': lang,\n                'v': video_id,\n                'fmt': self._downloader.params.get('subtitlesformat', 'srt'),\n                'name': unescapeHTML(l[0]).encode('utf-8'),\n            })\n            url = 'https://www.youtube.com/api/timedtext?' + params\n            sub_lang_list[lang] = url\n        if not sub_lang_list:\n            self._downloader.report_warning(u'video doesn\\'t have subtitles')\n            return {}\n        return sub_lang_list",
        "begin_line": 539,
        "end_line": 565,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._get_available_automatic_caption#567",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._get_available_automatic_caption(self, video_id, webpage)",
        "snippet": "    def _get_available_automatic_caption(self, video_id, webpage):\n        \"\"\"We need the webpage for getting the captions url, pass it as an\n           argument to speed up the process.\"\"\"\n        sub_format = self._downloader.params.get('subtitlesformat', 'srt')\n        self.to_screen(u'%s: Looking for automatic captions' % video_id)\n        mobj = re.search(r';ytplayer.config = ({.*?});', webpage)\n        err_msg = 'Couldn\\'t find automatic captions for %s' % video_id\n        if mobj is None:\n            self._downloader.report_warning(err_msg)\n            return {}\n        player_config = json.loads(mobj.group(1))\n        try:\n            args = player_config[u'args']\n            caption_url = args[u'ttsurl']\n            timestamp = args[u'timestamp']\n            # We get the available subtitles\n            list_params = compat_urllib_parse.urlencode({\n                'type': 'list',\n                'tlangs': 1,\n                'asrs': 1,\n            })\n            list_url = caption_url + '&' + list_params\n            caption_list = self._download_xml(list_url, video_id)\n            original_lang_node = caption_list.find('track')\n            if original_lang_node is None or original_lang_node.attrib.get('kind') != 'asr' :\n                self._downloader.report_warning(u'Video doesn\\'t have automatic captions')\n                return {}\n            original_lang = original_lang_node.attrib['lang_code']\n\n            sub_lang_list = {}\n            for lang_node in caption_list.findall('target'):\n                sub_lang = lang_node.attrib['lang_code']\n                params = compat_urllib_parse.urlencode({\n                    'lang': original_lang,\n                    'tlang': sub_lang,\n                    'fmt': sub_format,\n                    'ts': timestamp,\n                    'kind': 'asr',\n                })\n                sub_lang_list[sub_lang] = caption_url + '&' + params\n            return sub_lang_list\n        # An extractor error can be raise by the download process if there are\n        # no automatic captions but there are subtitles\n        except (KeyError, ExtractorError):\n            self._downloader.report_warning(err_msg)\n            return {}",
        "begin_line": 567,
        "end_line": 612,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.extract_id#615",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.extract_id(cls, url)",
        "snippet": "    def extract_id(cls, url):\n        mobj = re.match(cls._VALID_URL, url, re.VERBOSE)\n        if mobj is None:\n            raise ExtractorError(u'Invalid URL: %s' % url)\n        video_id = mobj.group(2)\n        return video_id",
        "begin_line": 615,
        "end_line": 620,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.0004462293618920125,
            "pseudo_tarantula_susp": 0.0002772387025228722,
            "pseudo_op2_susp": 0.0004462293618920125,
            "pseudo_barinel_susp": 0.00027631942525559546
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._extract_from_m3u8#622",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._extract_from_m3u8(self, manifest_url, video_id)",
        "snippet": "    def _extract_from_m3u8(self, manifest_url, video_id):\n        url_map = {}\n        def _get_urls(_manifest):\n            lines = _manifest.split('\\n')\n            urls = filter(lambda l: l and not l.startswith('#'),\n                            lines)\n            return urls\n        manifest = self._download_webpage(manifest_url, video_id, 'Downloading formats manifest')\n        formats_urls = _get_urls(manifest)\n        for format_url in formats_urls:\n            itag = self._search_regex(r'itag/(\\d+?)/', format_url, 'itag')\n            url_map[itag] = format_url\n        return url_map",
        "begin_line": 622,
        "end_line": 634,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._extract_annotations#636",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._extract_annotations(self, video_id)",
        "snippet": "    def _extract_annotations(self, video_id):\n        url = 'https://www.youtube.com/annotations_invideo?features=1&legacy=1&video_id=%s' % video_id\n        return self._download_webpage(url, video_id, note=u'Searching for annotations.', errnote=u'Unable to download video annotations.')",
        "begin_line": 636,
        "end_line": 638,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._real_extract#640",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        proto = (\n            'http' if self._downloader.params.get('prefer_insecure', False)\n            else 'https')\n\n        # Extract original video URL from URL with redirection, like age verification, using next_url parameter\n        mobj = re.search(self._NEXT_URL_RE, url)\n        if mobj:\n            url = proto + '://www.youtube.com/' + compat_urllib_parse.unquote(mobj.group(1)).lstrip('/')\n        video_id = self.extract_id(url)\n\n        # Get video webpage\n        url = proto + '://www.youtube.com/watch?v=%s&gl=US&hl=en&has_verified=1' % video_id\n        video_webpage = self._download_webpage(url, video_id)\n\n        # Attempt to extract SWF player URL\n        mobj = re.search(r'swfConfig.*?\"(https?:\\\\/\\\\/.*?watch.*?-.*?\\.swf)\"', video_webpage)\n        if mobj is not None:\n            player_url = re.sub(r'\\\\(.)', r'\\1', mobj.group(1))\n        else:\n            player_url = None\n\n        # Get video info\n        self.report_video_info_webpage_download(video_id)\n        if re.search(r'player-age-gate-content\">', video_webpage) is not None:\n            self.report_age_confirmation()\n            age_gate = True\n            # We simulate the access to the video from www.youtube.com/v/{video_id}\n            # this can be viewed without login into Youtube\n            data = compat_urllib_parse.urlencode({\n                'video_id': video_id,\n                'eurl': 'https://youtube.googleapis.com/v/' + video_id,\n                'sts': self._search_regex(\n                    r'\"sts\"\\s*:\\s*(\\d+)', video_webpage, 'sts'),\n            })\n            video_info_url = proto + '://www.youtube.com/get_video_info?' + data\n            video_info_webpage = self._download_webpage(video_info_url, video_id,\n                                    note=False,\n                                    errnote='unable to download video info webpage')\n            video_info = compat_parse_qs(video_info_webpage)\n        else:\n            age_gate = False\n            for el_type in ['&el=embedded', '&el=detailpage', '&el=vevo', '']:\n                video_info_url = (proto + '://www.youtube.com/get_video_info?&video_id=%s%s&ps=default&eurl=&gl=US&hl=en'\n                        % (video_id, el_type))\n                video_info_webpage = self._download_webpage(video_info_url, video_id,\n                                        note=False,\n                                        errnote='unable to download video info webpage')\n                video_info = compat_parse_qs(video_info_webpage)\n                if 'token' in video_info:\n                    break\n        if 'token' not in video_info:\n            if 'reason' in video_info:\n                raise ExtractorError(\n                    'YouTube said: %s' % video_info['reason'][0],\n                    expected=True, video_id=video_id)\n            else:\n                raise ExtractorError(\n                    '\"token\" parameter not in video info for unknown reason',\n                    video_id=video_id)\n\n        if 'view_count' in video_info:\n            view_count = int(video_info['view_count'][0])\n        else:\n            view_count = None\n\n        # Check for \"rental\" videos\n        if 'ypc_video_rental_bar_text' in video_info and 'author' not in video_info:\n            raise ExtractorError(u'\"rental\" videos not supported')\n\n        # Start extracting information\n        self.report_information_extraction(video_id)\n\n        # uploader\n        if 'author' not in video_info:\n            raise ExtractorError(u'Unable to extract uploader name')\n        video_uploader = compat_urllib_parse.unquote_plus(video_info['author'][0])\n\n        # uploader_id\n        video_uploader_id = None\n        mobj = re.search(r'<link itemprop=\"url\" href=\"http://www.youtube.com/(?:user|channel)/([^\"]+)\">', video_webpage)\n        if mobj is not None:\n            video_uploader_id = mobj.group(1)\n        else:\n            self._downloader.report_warning(u'unable to extract uploader nickname')\n\n        # title\n        if 'title' in video_info:\n            video_title = video_info['title'][0]\n        else:\n            self._downloader.report_warning(u'Unable to extract video title')\n            video_title = '_'\n\n        # thumbnail image\n        # We try first to get a high quality image:\n        m_thumb = re.search(r'<span itemprop=\"thumbnail\".*?href=\"(.*?)\">',\n                            video_webpage, re.DOTALL)\n        if m_thumb is not None:\n            video_thumbnail = m_thumb.group(1)\n        elif 'thumbnail_url' not in video_info:\n            self._downloader.report_warning(u'unable to extract video thumbnail')\n            video_thumbnail = None\n        else:   # don't panic if we can't find it\n            video_thumbnail = compat_urllib_parse.unquote_plus(video_info['thumbnail_url'][0])\n\n        # upload date\n        upload_date = None\n        mobj = re.search(r'(?s)id=\"eow-date.*?>(.*?)</span>', video_webpage)\n        if mobj is None:\n            mobj = re.search(\n                r'(?s)id=\"watch-uploader-info\".*?>.*?(?:Published|Uploaded|Streamed live) on (.*?)</strong>',\n                video_webpage)\n        if mobj is not None:\n            upload_date = ' '.join(re.sub(r'[/,-]', r' ', mobj.group(1)).split())\n            upload_date = unified_strdate(upload_date)\n\n        m_cat_container = self._search_regex(\n            r'(?s)<h4[^>]*>\\s*Category\\s*</h4>\\s*<ul[^>]*>(.*?)</ul>',\n            video_webpage, 'categories', fatal=False)\n        if m_cat_container:\n            category = self._html_search_regex(\n                r'(?s)<a[^<]+>(.*?)</a>', m_cat_container, 'category',\n                default=None)\n            video_categories = None if category is None else [category]\n        else:\n            video_categories = None\n\n        # description\n        video_description = get_element_by_id(\"eow-description\", video_webpage)\n        if video_description:\n            video_description = re.sub(r'''(?x)\n                <a\\s+\n                    (?:[a-zA-Z-]+=\"[^\"]+\"\\s+)*?\n                    title=\"([^\"]+)\"\\s+\n                    (?:[a-zA-Z-]+=\"[^\"]+\"\\s+)*?\n                    class=\"yt-uix-redirect-link\"\\s*>\n                [^<]+\n                </a>\n            ''', r'\\1', video_description)\n            video_description = clean_html(video_description)\n        else:\n            fd_mobj = re.search(r'<meta name=\"description\" content=\"([^\"]+)\"', video_webpage)\n            if fd_mobj:\n                video_description = unescapeHTML(fd_mobj.group(1))\n            else:\n                video_description = ''\n\n        def _extract_count(count_name):\n            count = self._search_regex(\n                r'id=\"watch-%s\"[^>]*>.*?([\\d,]+)\\s*</span>' % re.escape(count_name),\n                video_webpage, count_name, default=None)\n            if count is not None:\n                return int(count.replace(',', ''))\n            return None\n        like_count = _extract_count(u'like')\n        dislike_count = _extract_count(u'dislike')\n\n        # subtitles\n        video_subtitles = self.extract_subtitles(video_id, video_webpage)\n\n        if self._downloader.params.get('listsubtitles', False):\n            self._list_available_subtitles(video_id, video_webpage)\n            return\n\n        if 'length_seconds' not in video_info:\n            self._downloader.report_warning(u'unable to extract video duration')\n            video_duration = None\n        else:\n            video_duration = int(compat_urllib_parse.unquote_plus(video_info['length_seconds'][0]))\n\n        # annotations\n        video_annotations = None\n        if self._downloader.params.get('writeannotations', False):\n                video_annotations = self._extract_annotations(video_id)\n\n        # Decide which formats to download\n        try:\n            mobj = re.search(r';ytplayer\\.config\\s*=\\s*({.*?});', video_webpage)\n            if not mobj:\n                raise ValueError('Could not find vevo ID')\n            json_code = uppercase_escape(mobj.group(1))\n            ytplayer_config = json.loads(json_code)\n            args = ytplayer_config['args']\n            # Easy way to know if the 's' value is in url_encoded_fmt_stream_map\n            # this signatures are encrypted\n            if 'url_encoded_fmt_stream_map' not in args:\n                raise ValueError(u'No stream_map present')  # caught below\n            re_signature = re.compile(r'[&,]s=')\n            m_s = re_signature.search(args['url_encoded_fmt_stream_map'])\n            if m_s is not None:\n                self.to_screen(u'%s: Encrypted signatures detected.' % video_id)\n                video_info['url_encoded_fmt_stream_map'] = [args['url_encoded_fmt_stream_map']]\n            m_s = re_signature.search(args.get('adaptive_fmts', ''))\n            if m_s is not None:\n                if 'adaptive_fmts' in video_info:\n                    video_info['adaptive_fmts'][0] += ',' + args['adaptive_fmts']\n                else:\n                    video_info['adaptive_fmts'] = [args['adaptive_fmts']]\n        except ValueError:\n            pass\n\n        def _map_to_format_list(urlmap):\n            formats = []\n            for itag, video_real_url in urlmap.items():\n                dct = {\n                    'format_id': itag,\n                    'url': video_real_url,\n                    'player_url': player_url,\n                }\n                if itag in self._formats:\n                    dct.update(self._formats[itag])\n                formats.append(dct)\n            return formats\n\n        if 'conn' in video_info and video_info['conn'][0].startswith('rtmp'):\n            self.report_rtmp_download()\n            formats = [{\n                'format_id': '_rtmp',\n                'protocol': 'rtmp',\n                'url': video_info['conn'][0],\n                'player_url': player_url,\n            }]\n        elif len(video_info.get('url_encoded_fmt_stream_map', [])) >= 1 or len(video_info.get('adaptive_fmts', [])) >= 1:\n            encoded_url_map = video_info.get('url_encoded_fmt_stream_map', [''])[0] + ',' + video_info.get('adaptive_fmts',[''])[0]\n            if 'rtmpe%3Dyes' in encoded_url_map:\n                raise ExtractorError('rtmpe downloads are not supported, see https://github.com/rg3/youtube-dl/issues/343 for more information.', expected=True)\n            url_map = {}\n            for url_data_str in encoded_url_map.split(','):\n                url_data = compat_parse_qs(url_data_str)\n                if 'itag' not in url_data or 'url' not in url_data:\n                    continue\n                format_id = url_data['itag'][0]\n                url = url_data['url'][0]\n\n                if 'sig' in url_data:\n                    url += '&signature=' + url_data['sig'][0]\n                elif 's' in url_data:\n                    encrypted_sig = url_data['s'][0]\n\n                    if not age_gate:\n                        jsplayer_url_json = self._search_regex(\n                            r'\"assets\":.+?\"js\":\\s*(\"[^\"]+\")',\n                            video_webpage, 'JS player URL')\n                        player_url = json.loads(jsplayer_url_json)\n                    if player_url is None:\n                        player_url_json = self._search_regex(\n                            r'ytplayer\\.config.*?\"url\"\\s*:\\s*(\"[^\"]+\")',\n                            video_webpage, 'age gate player URL')\n                        player_url = json.loads(player_url_json)\n\n                    if self._downloader.params.get('verbose'):\n                        if player_url is None:\n                            player_version = 'unknown'\n                            player_desc = 'unknown'\n                        else:\n                            if player_url.endswith('swf'):\n                                player_version = self._search_regex(\n                                    r'-(.+?)(?:/watch_as3)?\\.swf$', player_url,\n                                    'flash player', fatal=False)\n                                player_desc = 'flash player %s' % player_version\n                            else:\n                                player_version = self._search_regex(\n                                    r'html5player-([^/]+?)(?:/html5player)?\\.js',\n                                    player_url,\n                                    'html5 player', fatal=False)\n                                player_desc = 'html5 player %s' % player_version\n\n                        parts_sizes = self._signature_cache_id(encrypted_sig)\n                        self.to_screen(u'{%s} signature length %s, %s' %\n                            (format_id, parts_sizes, player_desc))\n\n                    signature = self._decrypt_signature(\n                        encrypted_sig, video_id, player_url, age_gate)\n                    url += '&signature=' + signature\n                if 'ratebypass' not in url:\n                    url += '&ratebypass=yes'\n                url_map[format_id] = url\n            formats = _map_to_format_list(url_map)\n        elif video_info.get('hlsvp'):\n            manifest_url = video_info['hlsvp'][0]\n            url_map = self._extract_from_m3u8(manifest_url, video_id)\n            formats = _map_to_format_list(url_map)\n        else:\n            raise ExtractorError(u'no conn, hlsvp or url_encoded_fmt_stream_map information found in video info')\n\n        # Look for the DASH manifest\n        if (self._downloader.params.get('youtube_include_dash_manifest', False)):\n            try:\n                # The DASH manifest used needs to be the one from the original video_webpage.\n                # The one found in get_video_info seems to be using different signatures.\n                # However, in the case of an age restriction there won't be any embedded dashmpd in the video_webpage.\n                # Luckily, it seems, this case uses some kind of default signature (len == 86), so the\n                # combination of get_video_info and the _static_decrypt_signature() decryption fallback will work here.\n                if age_gate:\n                    dash_manifest_url = video_info.get('dashmpd')[0]\n                else:\n                    dash_manifest_url = ytplayer_config['args']['dashmpd']\n                def decrypt_sig(mobj):\n                    s = mobj.group(1)\n                    dec_s = self._decrypt_signature(s, video_id, player_url, age_gate)\n                    return '/signature/%s' % dec_s\n                dash_manifest_url = re.sub(r'/s/([\\w\\.]+)', decrypt_sig, dash_manifest_url)\n                dash_doc = self._download_xml(\n                    dash_manifest_url, video_id,\n                    note=u'Downloading DASH manifest',\n                    errnote=u'Could not download DASH manifest')\n                for r in dash_doc.findall(u'.//{urn:mpeg:DASH:schema:MPD:2011}Representation'):\n                    url_el = r.find('{urn:mpeg:DASH:schema:MPD:2011}BaseURL')\n                    if url_el is None:\n                        continue\n                    format_id = r.attrib['id']\n                    video_url = url_el.text\n                    filesize = int_or_none(url_el.attrib.get('{http://youtube.com/yt/2012/10/10}contentLength'))\n                    f = {\n                        'format_id': format_id,\n                        'url': video_url,\n                        'width': int_or_none(r.attrib.get('width')),\n                        'tbr': int_or_none(r.attrib.get('bandwidth'), 1000),\n                        'asr': int_or_none(r.attrib.get('audioSamplingRate')),\n                        'filesize': filesize,\n                    }\n                    try:\n                        existing_format = next(\n                            fo for fo in formats\n                            if fo['format_id'] == format_id)\n                    except StopIteration:\n                        f.update(self._formats.get(format_id, {}))\n                        formats.append(f)\n                    else:\n                        existing_format.update(f)\n\n            except (ExtractorError, KeyError) as e:\n                self.report_warning(u'Skipping DASH manifest: %s' % e, video_id)\n\n        self._sort_formats(formats)\n\n        return {\n            'id':           video_id,\n            'uploader':     video_uploader,\n            'uploader_id':  video_uploader_id,\n            'upload_date':  upload_date,\n            'title':        video_title,\n            'thumbnail':    video_thumbnail,\n            'description':  video_description,\n            'categories':   video_categories,\n            'subtitles':    video_subtitles,\n            'duration':     video_duration,\n            'age_limit':    18 if age_gate else 0,\n            'annotations':  video_annotations,\n            'webpage_url': proto + '://www.youtube.com/watch?v=%s' % video_id,\n            'view_count':   view_count,\n            'like_count': like_count,\n            'dislike_count': dislike_count,\n            'formats':      formats,\n        }",
        "begin_line": 640,
        "end_line": 994,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubePlaylistIE._real_initialize#1061",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubePlaylistIE",
        "signature": "youtube_dl.extractor.youtube.YoutubePlaylistIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 1061,
        "end_line": 1062,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0013568521031207597,
            "pseudo_dstar_susp": 0.001034126163391934,
            "pseudo_tarantula_susp": 0.00032583903551645487,
            "pseudo_op2_susp": 0.001034126163391934,
            "pseudo_barinel_susp": 0.00032583903551645487
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubePlaylistIE._ids_to_results#1064",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubePlaylistIE",
        "signature": "youtube_dl.extractor.youtube.YoutubePlaylistIE._ids_to_results(self, ids)",
        "snippet": "    def _ids_to_results(self, ids):\n        return [\n            self.url_result(vid_id, 'Youtube', video_id=vid_id)\n            for vid_id in ids]",
        "begin_line": 1064,
        "end_line": 1067,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubePlaylistIE._extract_mix#1069",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubePlaylistIE",
        "signature": "youtube_dl.extractor.youtube.YoutubePlaylistIE._extract_mix(self, playlist_id)",
        "snippet": "    def _extract_mix(self, playlist_id):\n        # The mixes are generated from a a single video\n        # the id of the playlist is just 'RD' + video_id\n        url = 'https://youtube.com/watch?v=%s&list=%s' % (playlist_id[-11:], playlist_id)\n        webpage = self._download_webpage(\n            url, playlist_id, 'Downloading Youtube mix')\n        search_title = lambda class_name: get_element_by_attribute('class', class_name, webpage)\n        title_span = (\n            search_title('playlist-title') or\n            search_title('title long-title') or\n            search_title('title'))\n        title = clean_html(title_span)\n        ids = orderedSet(re.findall(\n            r'''(?xs)data-video-username=\".*?\".*?\n                       href=\"/watch\\?v=([0-9A-Za-z_-]{11})&amp;[^\"]*?list=%s''' % re.escape(playlist_id),\n            webpage))\n        url_results = self._ids_to_results(ids)\n\n        return self.playlist_result(url_results, playlist_id, title)",
        "begin_line": 1069,
        "end_line": 1087,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubePlaylistIE._real_extract#1089",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubePlaylistIE",
        "signature": "youtube_dl.extractor.youtube.YoutubePlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        # Extract playlist id\n        mobj = re.match(self._VALID_URL, url)\n        if mobj is None:\n            raise ExtractorError(u'Invalid URL: %s' % url)\n        playlist_id = mobj.group(1) or mobj.group(2)\n\n        # Check if it's a video-specific URL\n        query_dict = compat_urlparse.parse_qs(compat_urlparse.urlparse(url).query)\n        if 'v' in query_dict:\n            video_id = query_dict['v'][0]\n            if self._downloader.params.get('noplaylist'):\n                self.to_screen(u'Downloading just video %s because of --no-playlist' % video_id)\n                return self.url_result(video_id, 'Youtube', video_id=video_id)\n            else:\n                self.to_screen(u'Downloading playlist %s - add --no-playlist to just download video %s' % (playlist_id, video_id))\n\n        if playlist_id.startswith('RD'):\n            # Mixes require a custom extraction process\n            return self._extract_mix(playlist_id)\n        if playlist_id.startswith('TL'):\n            raise ExtractorError(u'For downloading YouTube.com top lists, use '\n                'the \"yttoplist\" keyword, for example \"youtube-dl \\'yttoplist:music:Top Tracks\\'\"', expected=True)\n\n        url = self._TEMPLATE_URL % playlist_id\n        page = self._download_webpage(url, playlist_id)\n        more_widget_html = content_html = page\n\n        # Check if the playlist exists or is private\n        if re.search(r'<div class=\"yt-alert-message\">[^<]*?(The|This) playlist (does not exist|is private)[^<]*?</div>', page) is not None:\n            raise ExtractorError(\n                'The playlist doesn\\'t exist or is private, use --username or '\n                '--netrc to access it.',\n                expected=True)\n\n        # Extract the video ids from the playlist pages\n        ids = []\n\n        for page_num in itertools.count(1):\n            matches = re.finditer(self._VIDEO_RE, content_html)\n            # We remove the duplicates and the link with index 0\n            # (it's not the first video of the playlist)\n            new_ids = orderedSet(m.group('id') for m in matches if m.group('index') != '0')\n            ids.extend(new_ids)\n\n            mobj = re.search(r'data-uix-load-more-href=\"/?(?P<more>[^\"]+)\"', more_widget_html)\n            if not mobj:\n                break\n\n            more = self._download_json(\n                'https://youtube.com/%s' % mobj.group('more'), playlist_id,\n                'Downloading page #%s' % page_num,\n                transform_source=uppercase_escape)\n            content_html = more['content_html']\n            more_widget_html = more['load_more_widget_html']\n\n        playlist_title = self._html_search_regex(\n            r'(?s)<h1 class=\"pl-header-title[^\"]*\">\\s*(.*?)\\s*</h1>',\n            page, 'title')\n\n        url_results = self._ids_to_results(ids)\n        return self.playlist_result(url_results, playlist_id, playlist_title)",
        "begin_line": 1089,
        "end_line": 1150,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0020161290322580645,
            "pseudo_dstar_susp": 0.0014903129657228018,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0014903129657228018,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeTopListIE._real_extract#1160",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeTopListIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeTopListIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        channel = mobj.group('chann')\n        title = mobj.group('title')\n        query = compat_urllib_parse.urlencode({'title': title})\n        playlist_re = 'href=\"([^\"]+?%s.*?)\"' % re.escape(query)\n        channel_page = self._download_webpage('https://www.youtube.com/%s' % channel, title)\n        link = self._html_search_regex(playlist_re, channel_page, 'list')\n        url = compat_urlparse.urljoin('https://www.youtube.com/', link)\n        \n        video_re = r'data-index=\"\\d+\".*?data-video-id=\"([0-9A-Za-z_-]{11})\"'\n        ids = []\n        # sometimes the webpage doesn't contain the videos\n        # retry until we get them\n        for i in itertools.count(0):\n            msg = 'Downloading Youtube mix'\n            if i > 0:\n                msg += ', retry #%d' % i\n\n            webpage = self._download_webpage(url, title, msg)\n            ids = orderedSet(re.findall(video_re, webpage))\n            if ids:\n                break\n        url_results = self._ids_to_results(ids)\n        return self.playlist_result(url_results, playlist_title=title)",
        "begin_line": 1160,
        "end_line": 1184,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeChannelIE.extract_videos_from_page#1194",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeChannelIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeChannelIE.extract_videos_from_page(self, page)",
        "snippet": "    def extract_videos_from_page(self, page):\n        ids_in_page = []\n        for mobj in re.finditer(r'href=\"/watch\\?v=([0-9A-Za-z_-]+)&?', page):\n            if mobj.group(1) not in ids_in_page:\n                ids_in_page.append(mobj.group(1))\n        return ids_in_page",
        "begin_line": 1194,
        "end_line": 1199,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeChannelIE._real_extract#1201",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeChannelIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        # Extract channel id\n        mobj = re.match(self._VALID_URL, url)\n        if mobj is None:\n            raise ExtractorError(u'Invalid URL: %s' % url)\n\n        # Download channel page\n        channel_id = mobj.group(1)\n        video_ids = []\n        url = 'https://www.youtube.com/channel/%s/videos' % channel_id\n        channel_page = self._download_webpage(url, channel_id)\n        autogenerated = re.search(r'''(?x)\n                class=\"[^\"]*?(?:\n                    channel-header-autogenerated-label|\n                    yt-channel-title-autogenerated\n                )[^\"]*\"''', channel_page) is not None\n\n        if autogenerated:\n            # The videos are contained in a single page\n            # the ajax pages can't be used, they are empty\n            video_ids = self.extract_videos_from_page(channel_page)\n        else:\n            # Download all channel pages using the json-based channel_ajax query\n            for pagenum in itertools.count(1):\n                url = self._MORE_PAGES_URL % (pagenum, channel_id)\n                page = self._download_json(\n                    url, channel_id, note=u'Downloading page #%s' % pagenum,\n                    transform_source=uppercase_escape)\n\n                ids_in_page = self.extract_videos_from_page(page['content_html'])\n                video_ids.extend(ids_in_page)\n    \n                if self._MORE_PAGES_INDICATOR not in page['load_more_widget_html']:\n                    break\n\n        self._downloader.to_screen(u'[youtube] Channel %s: Found %i videos' % (channel_id, len(video_ids)))\n\n        url_entries = [self.url_result(video_id, 'Youtube', video_id=video_id)\n                       for video_id in video_ids]\n        return self.playlist_result(url_entries, channel_id)",
        "begin_line": 1201,
        "end_line": 1240,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeUserIE.suitable#1252",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeUserIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeUserIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        # Don't return True if the url can be extracted with other youtube\n        # extractor, the regex would is too permissive and it would match.\n        other_ies = iter(klass for (name, klass) in globals().items() if name.endswith('IE') and klass is not cls)\n        if any(ie.suitable(url) for ie in other_ies): return False\n        else: return super(YoutubeUserIE, cls).suitable(url)",
        "begin_line": 1252,
        "end_line": 1257,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00267379679144385,
            "pseudo_dstar_susp": 0.002881844380403458,
            "pseudo_tarantula_susp": 0.0002892681515765114,
            "pseudo_op2_susp": 0.002881844380403458,
            "pseudo_barinel_susp": 0.0002892681515765114
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeUserIE._real_extract#1259",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeUserIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        # Extract username\n        mobj = re.match(self._VALID_URL, url)\n        if mobj is None:\n            raise ExtractorError(u'Invalid URL: %s' % url)\n\n        username = mobj.group(1)\n\n        # Download video ids using YouTube Data API. Result size per\n        # query is limited (currently to 50 videos) so we need to query\n        # page by page until there are no video ids - it means we got\n        # all of them.\n\n        def download_page(pagenum):\n            start_index = pagenum * self._GDATA_PAGE_SIZE + 1\n\n            gdata_url = self._GDATA_URL % (username, self._GDATA_PAGE_SIZE, start_index)\n            page = self._download_webpage(\n                gdata_url, username,\n                'Downloading video ids from %d to %d' % (\n                    start_index, start_index + self._GDATA_PAGE_SIZE))\n\n            try:\n                response = json.loads(page)\n            except ValueError as err:\n                raise ExtractorError(u'Invalid JSON in API response: ' + compat_str(err))\n            if 'entry' not in response['feed']:\n                return\n\n            # Extract video identifiers\n            entries = response['feed']['entry']\n            for entry in entries:\n                title = entry['title']['$t']\n                video_id = entry['id']['$t'].split('/')[-1]\n                yield {\n                    '_type': 'url',\n                    'url': video_id,\n                    'ie_key': 'Youtube',\n                    'id': video_id,\n                    'title': title,\n                }\n        url_results = PagedList(download_page, self._GDATA_PAGE_SIZE)\n\n        return self.playlist_result(url_results, playlist_title=username)",
        "begin_line": 1259,
        "end_line": 1302,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeUserIE.download_page#1272",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeUserIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeUserIE.download_page(pagenum)",
        "snippet": "        def download_page(pagenum):\n            start_index = pagenum * self._GDATA_PAGE_SIZE + 1\n\n            gdata_url = self._GDATA_URL % (username, self._GDATA_PAGE_SIZE, start_index)\n            page = self._download_webpage(\n                gdata_url, username,\n                'Downloading video ids from %d to %d' % (\n                    start_index, start_index + self._GDATA_PAGE_SIZE))\n\n            try:\n                response = json.loads(page)\n            except ValueError as err:\n                raise ExtractorError(u'Invalid JSON in API response: ' + compat_str(err))\n            if 'entry' not in response['feed']:\n                return\n\n            # Extract video identifiers\n            entries = response['feed']['entry']\n            for entry in entries:\n                title = entry['title']['$t']\n                video_id = entry['id']['$t'].split('/')[-1]\n                yield {\n                    '_type': 'url',\n                    'url': video_id,\n                    'ie_key': 'Youtube',\n                    'id': video_id,\n                    'title': title,\n                }",
        "begin_line": 1272,
        "end_line": 1299,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009000900090009,
            "pseudo_dstar_susp": 0.0006983240223463687,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006983240223463687,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeSearchIE._get_n_results#1312",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeSearchIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeSearchIE._get_n_results(self, query, n)",
        "snippet": "    def _get_n_results(self, query, n):\n        \"\"\"Get a specified number of results for a query\"\"\"\n\n        video_ids = []\n        pagenum = 0\n        limit = n\n        PAGE_SIZE = 50\n\n        while (PAGE_SIZE * pagenum) < limit:\n            result_url = self._API_URL % (\n                compat_urllib_parse.quote_plus(query.encode('utf-8')),\n                (PAGE_SIZE * pagenum) + 1)\n            data_json = self._download_webpage(\n                result_url, video_id=u'query \"%s\"' % query,\n                note=u'Downloading page %s' % (pagenum + 1),\n                errnote=u'Unable to download API page')\n            data = json.loads(data_json)\n            api_response = data['data']\n\n            if 'items' not in api_response:\n                raise ExtractorError(\n                    '[youtube] No video results', expected=True)\n\n            new_ids = list(video['id'] for video in api_response['items'])\n            video_ids += new_ids\n\n            limit = min(n, api_response['totalItems'])\n            pagenum += 1\n\n        if len(video_ids) > n:\n            video_ids = video_ids[:n]\n        videos = [self.url_result(video_id, 'Youtube', video_id=video_id)\n                  for video_id in video_ids]\n        return self.playlist_result(videos, query)",
        "begin_line": 1312,
        "end_line": 1345,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeSearchURLIE._real_extract#1360",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeSearchURLIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeSearchURLIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        query = compat_urllib_parse.unquote_plus(mobj.group('query'))\n\n        webpage = self._download_webpage(url, query)\n        result_code = self._search_regex(\n            r'(?s)<ol class=\"item-section\"(.*?)</ol>', webpage, 'result HTML')\n\n        part_codes = re.findall(\n            r'(?s)<h3 class=\"yt-lockup-title\">(.*?)</h3>', result_code)\n        entries = []\n        for part_code in part_codes:\n            part_title = self._html_search_regex(\n                [r'(?s)title=\"([^\"]+)\"', r'>([^<]+)</a>'], part_code, 'item title', fatal=False)\n            part_url_snippet = self._html_search_regex(\n                r'(?s)href=\"([^\"]+)\"', part_code, 'item URL')\n            part_url = compat_urlparse.urljoin(\n                'https://www.youtube.com/', part_url_snippet)\n            entries.append({\n                '_type': 'url',\n                'url': part_url,\n                'title': part_title,\n            })\n\n        return {\n            '_type': 'playlist',\n            'entries': entries,\n            'title': query,\n        }",
        "begin_line": 1360,
        "end_line": 1388,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeShowIE._real_extract#1396",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeShowIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeShowIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        show_name = mobj.group(1)\n        webpage = self._download_webpage(url, show_name, 'Downloading show webpage')\n        # There's one playlist for each season of the show\n        m_seasons = list(re.finditer(r'href=\"(/playlist\\?list=.*?)\"', webpage))\n        self.to_screen(u'%s: Found %s seasons' % (show_name, len(m_seasons)))\n        return [self.url_result('https://www.youtube.com' + season.group(1), 'YoutubePlaylist') for season in m_seasons]",
        "begin_line": 1396,
        "end_line": 1403,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor.IE_NAME#1424",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor.IE_NAME(self)",
        "snippet": "    def IE_NAME(self):\n        return 'youtube:%s' % self._FEED_NAME",
        "begin_line": 1424,
        "end_line": 1425,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.0001840942562592047,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor._real_initialize#1427",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 1427,
        "end_line": 1428,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor._real_extract#1430",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        feed_entries = []\n        paging = 0\n        for i in itertools.count(1):\n            info = self._download_json(self._FEED_TEMPLATE % paging,\n                                          '%s feed' % self._FEED_NAME,\n                                          'Downloading page %s' % i)\n            feed_html = info.get('feed_html') or info.get('content_html')\n            load_more_widget_html = info.get('load_more_widget_html') or feed_html\n            m_ids = re.finditer(r'\"/watch\\?v=(.*?)[\"&]', feed_html)\n            ids = orderedSet(m.group(1) for m in m_ids)\n            feed_entries.extend(\n                self.url_result(video_id, 'Youtube', video_id=video_id)\n                for video_id in ids)\n            mobj = re.search(\n                r'data-uix-load-more-href=\"/?[^\"]+paging=(?P<paging>\\d+)',\n                load_more_widget_html)\n            if mobj is None:\n                break\n            paging = mobj.group('paging')\n        return self.playlist_result(feed_entries, playlist_title=self._PLAYLIST_TITLE)",
        "begin_line": 1430,
        "end_line": 1450,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeFavouritesIE._real_extract#1478",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeFavouritesIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeFavouritesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        webpage = self._download_webpage('https://www.youtube.com/my_favorites', 'Youtube Favourites videos')\n        playlist_id = self._search_regex(r'list=(.+?)[\"&]', webpage, 'favourites playlist id')\n        return self.url_result(playlist_id, 'YoutubePlaylist')",
        "begin_line": 1478,
        "end_line": 1481,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeSubscriptionsIE._real_extract#1490",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeSubscriptionsIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeSubscriptionsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        title = 'Youtube Subscriptions'\n        page = self._download_webpage('https://www.youtube.com/feed/subscriptions', title)\n\n        # The extraction process is the same as for playlists, but the regex\n        # for the video ids doesn't contain an index\n        ids = []\n        more_widget_html = content_html = page\n\n        for page_num in itertools.count(1):\n            matches = re.findall(r'href=\"\\s*/watch\\?v=([0-9A-Za-z_-]{11})', content_html)\n            new_ids = orderedSet(matches)\n            ids.extend(new_ids)\n\n            mobj = re.search(r'data-uix-load-more-href=\"/?(?P<more>[^\"]+)\"', more_widget_html)\n            if not mobj:\n                break\n\n            more = self._download_json(\n                'https://youtube.com/%s' % mobj.group('more'), title,\n                'Downloading page #%s' % page_num,\n                transform_source=uppercase_escape)\n            content_html = more['content_html']\n            more_widget_html = more['load_more_widget_html']\n\n        return {\n            '_type': 'playlist',\n            'title': title,\n            'entries': self._ids_to_results(ids),\n        }",
        "begin_line": 1490,
        "end_line": 1519,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeTruncatedURLIE._real_extract#1541",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeTruncatedURLIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeTruncatedURLIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        raise ExtractorError(\n            'Did you forget to quote the URL? Remember that & is a meta '\n            'character in most shells, so you want to put the URL in quotes, '\n            'like  youtube-dl '\n            '\"http://www.youtube.com/watch?feature=foo&v=BaW_jenozKc\" '\n            ' or simply  youtube-dl BaW_jenozKc  .',\n            expected=True)",
        "begin_line": 1541,
        "end_line": 1548,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.snotr.SnotrIE._real_extract#38",
        "src_path": "youtube_dl/extractor/snotr.py",
        "class_name": "youtube_dl.extractor.snotr.SnotrIE",
        "signature": "youtube_dl.extractor.snotr.SnotrIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        title = self._og_search_title(webpage)\n\n        description = self._og_search_description(webpage)\n        video_url = \"http://cdn.videos.snotr.com/%s.flv\" % video_id\n\n        view_count = str_to_int(self._html_search_regex(\n            r'<p>\\n<strong>Views:</strong>\\n([\\d,\\.]+)</p>',\n            webpage, 'view count', fatal=False))\n\n        duration = parse_duration(self._html_search_regex(\n            r'<p>\\n<strong>Length:</strong>\\n\\s*([0-9:]+).*?</p>',\n            webpage, 'duration', fatal=False))\n\n        filesize_approx = float_or_none(self._html_search_regex(\n            r'<p>\\n<strong>Filesize:</strong>\\n\\s*([0-9.]+)\\s*megabyte</p>',\n            webpage, 'filesize', fatal=False), invscale=1024 * 1024)\n\n        return {\n            'id': video_id,\n            'description': description,\n            'title': title,\n            'url': video_url,\n            'view_count': view_count,\n            'duration': duration,\n            'filesize_approx': filesize_approx,\n        }",
        "begin_line": 38,
        "end_line": 68,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.bloomberg.BloombergIE._real_extract#22",
        "src_path": "youtube_dl/extractor/bloomberg.py",
        "class_name": "youtube_dl.extractor.bloomberg.BloombergIE",
        "signature": "youtube_dl.extractor.bloomberg.BloombergIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        name = mobj.group('name')\n        webpage = self._download_webpage(url, name)\n        f4m_url = self._search_regex(\n            r'<source src=\"(https?://[^\"]+\\.f4m.*?)\"', webpage,\n            'f4m url')\n        title = re.sub(': Video$', '', self._og_search_title(webpage))\n\n        return {\n            'id': name.split('-')[-1],\n            'title': title,\n            'formats': self._extract_f4m_formats(f4m_url, name),\n            'description': self._og_search_description(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n        }",
        "begin_line": 22,
        "end_line": 37,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.nytimes.NYTimesIE._real_extract#27",
        "src_path": "youtube_dl/extractor/nytimes.py",
        "class_name": "youtube_dl.extractor.nytimes.NYTimesIE",
        "signature": "youtube_dl.extractor.nytimes.NYTimesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        video_data = self._download_json(\n            'http://www.nytimes.com/svc/video/api/v2/video/%s' % video_id, video_id, 'Downloading video JSON')\n\n        title = video_data['headline']\n        description = video_data['summary']\n        duration = video_data['duration'] / 1000.0\n\n        uploader = video_data['byline']\n        timestamp = parse_iso8601(video_data['publication_date'][:-8])\n\n        def get_file_size(file_size):\n            if isinstance(file_size, int):\n                return file_size\n            elif isinstance(file_size, dict):\n                return int(file_size.get('value', 0))\n            else:\n                return 0\n\n        formats = [\n            {\n                'url': video['url'],\n                'format_id': video['type'],\n                'vcodec': video['video_codec'],\n                'width': video['width'],\n                'height': video['height'],\n                'filesize': get_file_size(video['fileSize']),\n            } for video in video_data['renditions']\n        ]\n        self._sort_formats(formats)\n\n        thumbnails = [\n            {\n                'url': 'http://www.nytimes.com/%s' % image['url'],\n                'resolution': '%dx%d' % (image['width'], image['height']),\n            } for image in video_data['images']\n        ]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'timestamp': timestamp,\n            'uploader': uploader,\n            'duration': duration,\n            'formats': formats,\n            'thumbnails': thumbnails,\n        }",
        "begin_line": 27,
        "end_line": 77,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.nytimes.NYTimesIE.get_file_size#41",
        "src_path": "youtube_dl/extractor/nytimes.py",
        "class_name": "youtube_dl.extractor.nytimes.NYTimesIE",
        "signature": "youtube_dl.extractor.nytimes.NYTimesIE.get_file_size(file_size)",
        "snippet": "        def get_file_size(file_size):\n            if isinstance(file_size, int):\n                return file_size\n            elif isinstance(file_size, dict):\n                return int(file_size.get('value', 0))\n            else:\n                return 0",
        "begin_line": 41,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.mit.TechTVMITIE._real_extract#31",
        "src_path": "youtube_dl/extractor/mit.py",
        "class_name": "youtube_dl.extractor.mit.TechTVMITIE",
        "signature": "youtube_dl.extractor.mit.TechTVMITIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        raw_page = self._download_webpage(\n            'http://techtv.mit.edu/videos/%s' % video_id, video_id)\n        clean_page = re.compile(r'<!--.*?-->', re.S).sub('', raw_page)\n\n        base_url = self._search_regex(\n            r'ipadUrl: \\'(.+?cloudfront.net/)', raw_page, 'base url')\n        formats_json = self._search_regex(\n            r'bitrates: (\\[.+?\\])', raw_page, 'video formats')\n        formats_mit = json.loads(formats_json)\n        formats = [\n            {\n                'format_id': f['label'],\n                'url': base_url + f['url'].partition(':')[2],\n                'ext': f['url'].partition(':')[0],\n                'format': f['label'],\n                'width': f['width'],\n                'vbr': f['bitrate'],\n            }\n            for f in formats_mit\n        ]\n\n        title = get_element_by_id('edit-title', clean_page)\n        description = clean_html(get_element_by_id('edit-description', clean_page))\n        thumbnail = self._search_regex(\n            r'playlist:.*?url: \\'(.+?)\\'',\n            raw_page, 'thumbnail', flags=re.DOTALL)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'description': description,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 31,
        "end_line": 67,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.mit.MITIE._real_extract#85",
        "src_path": "youtube_dl/extractor/mit.py",
        "class_name": "youtube_dl.extractor.mit.MITIE",
        "signature": "youtube_dl.extractor.mit.MITIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        page_title = mobj.group('title')\n        webpage = self._download_webpage(url, page_title)\n        embed_url = self._search_regex(\n            r'<iframe .*?src=\"(.+?)\"', webpage, 'embed url')\n        return self.url_result(embed_url, ie='TechTVMIT')",
        "begin_line": 85,
        "end_line": 91,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.mit.OCWMITIE._real_extract#122",
        "src_path": "youtube_dl/extractor/mit.py",
        "class_name": "youtube_dl.extractor.mit.OCWMITIE",
        "signature": "youtube_dl.extractor.mit.OCWMITIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        topic = mobj.group('topic')\n\n        webpage = self._download_webpage(url, topic)\n        title = self._html_search_meta('WT.cg_s', webpage)\n        description = self._html_search_meta('Description', webpage)\n\n        # search for call to ocw_embed_chapter_media(container_id, media_url, provider, page_url, image_url, start, stop, captions_file)\n        embed_chapter_media = re.search(r'ocw_embed_chapter_media\\((.+?)\\)', webpage)\n        if embed_chapter_media:\n            metadata = re.sub(r'[\\'\"]', '', embed_chapter_media.group(1))\n            metadata = re.split(r', ?', metadata)\n            yt = metadata[1]\n            subs = compat_urlparse.urljoin(self._BASE_URL, metadata[7])\n        else:\n            # search for call to ocw_embed_chapter_media(container_id, media_url, provider, page_url, image_url, captions_file)\n            embed_media = re.search(r'ocw_embed_media\\((.+?)\\)', webpage)\n            if embed_media:\n                metadata = re.sub(r'[\\'\"]', '', embed_media.group(1))\n                metadata = re.split(r', ?', metadata)\n                yt = metadata[1]\n                subs = compat_urlparse.urljoin(self._BASE_URL, metadata[5])\n            else:\n                raise ExtractorError('Unable to find embedded YouTube video.')\n        video_id = YoutubeIE.extract_id(yt)\n\n        return {\n            '_type': 'url_transparent',\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'url': yt,\n            'url_transparent'\n            'subtitles': subs,\n            'ie_key': 'Youtube',\n        }",
        "begin_line": 122,
        "end_line": 158,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.allocine.AllocineIE._real_extract#50",
        "src_path": "youtube_dl/extractor/allocine.py",
        "class_name": "youtube_dl.extractor.allocine.AllocineIE",
        "signature": "youtube_dl.extractor.allocine.AllocineIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        typ = mobj.group('typ')\n        display_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        if typ == 'film':\n            video_id = self._search_regex(r'href=\"/video/player_gen_cmedia=([0-9]+).+\"', webpage, 'video id')\n        else:\n            player = self._search_regex(r'data-player=\\'([^\\']+)\\'>', webpage, 'data player')\n\n            player_data = json.loads(player)\n            video_id = compat_str(player_data['refMedia'])\n\n        xml = self._download_xml('http://www.allocine.fr/ws/AcVisiondataV4.ashx?media=%s' % video_id, display_id)\n\n        video = xml.find('.//AcVisionVideo').attrib\n        quality = qualities(['ld', 'md', 'hd'])\n\n        formats = []\n        for k, v in video.items():\n            if re.match(r'.+_path', k):\n                format_id = k.split('_')[0]\n                formats.append({\n                    'format_id': format_id,\n                    'quality': quality(format_id),\n                    'url': v,\n                    'ext': determine_ext(v),\n                })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video['videoTitle'],\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'formats': formats,\n            'description': self._og_search_description(webpage),\n        }",
        "begin_line": 50,
        "end_line": 89,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007692307692307692,
            "pseudo_dstar_susp": 0.0006273525721455458,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006273525721455458,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.googleplus.GooglePlusIE._real_extract#28",
        "src_path": "youtube_dl/extractor/googleplus.py",
        "class_name": "youtube_dl.extractor.googleplus.GooglePlusIE",
        "signature": "youtube_dl.extractor.googleplus.GooglePlusIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        # Extract id from URL\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n\n        # Step 1, Retrieve post webpage to extract further information\n        webpage = self._download_webpage(url, video_id, 'Downloading entry webpage')\n\n        self.report_extraction(video_id)\n\n        # Extract update date\n        upload_date = self._html_search_regex(\n            r'''(?x)<a.+?class=\"o-U-s\\s[^\"]+\"\\s+style=\"display:\\s*none\"\\s*>\n                    ([0-9]{4}-[0-9]{2}-[0-9]{2})</a>''',\n            webpage, 'upload date', fatal=False, flags=re.VERBOSE)\n        if upload_date:\n            # Convert timestring to a format suitable for filename\n            upload_date = datetime.datetime.strptime(upload_date, \"%Y-%m-%d\")\n            upload_date = upload_date.strftime('%Y%m%d')\n\n        # Extract uploader\n        uploader = self._html_search_regex(r'rel\\=\"author\".*?>(.*?)</a>',\n            webpage, 'uploader', fatal=False)\n\n        # Extract title\n        # Get the first line for title\n        video_title = self._og_search_description(webpage).splitlines()[0]\n\n        # Step 2, Simulate clicking the image box to launch video\n        DOMAIN = 'https://plus.google.com/'\n        video_page = self._search_regex(r'<a href=\"((?:%s)?photos/.*?)\"' % re.escape(DOMAIN),\n            webpage, 'video page URL')\n        if not video_page.startswith(DOMAIN):\n            video_page = DOMAIN + video_page\n\n        webpage = self._download_webpage(video_page, video_id, 'Downloading video page')\n\n        # Extract video links all sizes\n        pattern = r'\\d+,\\d+,(\\d+),\"(http\\://redirector\\.googlevideo\\.com.*?)\"'\n        mobj = re.findall(pattern, webpage)\n        if len(mobj) == 0:\n            raise ExtractorError('Unable to extract video links')\n\n        # Sort in resolution\n        links = sorted(mobj)\n\n        # Choose the lowest of the sort, i.e. highest resolution\n        video_url = links[-1]\n        # Only get the url. The resolution part in the tuple has no use anymore\n        video_url = video_url[-1]\n        # Treat escaped \\u0026 style hex\n        try:\n            video_url = video_url.decode(\"unicode_escape\")\n        except AttributeError: # Python 3\n            video_url = bytes(video_url, 'ascii').decode('unicode-escape')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'uploader': uploader,\n            'upload_date': upload_date,\n            'title': video_title,\n            'ext': 'flv',\n        }",
        "begin_line": 28,
        "end_line": 92,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.screencast.ScreencastIE._real_extract#59",
        "src_path": "youtube_dl/extractor/screencast.py",
        "class_name": "youtube_dl.extractor.screencast.ScreencastIE",
        "signature": "youtube_dl.extractor.screencast.ScreencastIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = self._html_search_regex(\n            r'<embed name=\"Video\".*?src=\"([^\"]+)\"', webpage,\n            'QuickTime embed', default=None)\n\n        if video_url is None:\n            flash_vars_s = self._html_search_regex(\n                r'<param name=\"flashVars\" value=\"([^\"]+)\"', webpage, 'flash vars',\n                default=None)\n            if not flash_vars_s:\n                flash_vars_s = self._html_search_regex(\n                    r'<param name=\"initParams\" value=\"([^\"]+)\"', webpage, 'flash vars',\n                    default=None)\n                if flash_vars_s:\n                    flash_vars_s = flash_vars_s.replace(',', '&')\n            if flash_vars_s:\n                flash_vars = compat_parse_qs(flash_vars_s)\n                video_url_raw = compat_urllib_request.quote(\n                    flash_vars['content'][0])\n                video_url = video_url_raw.replace('http%3A', 'http:')\n\n        if video_url is None:\n            video_meta = self._html_search_meta(\n                'og:video', webpage, default=None)\n            if video_meta:\n                video_url = self._search_regex(\n                    r'src=(.*?)(?:$|&)', video_meta,\n                    'meta tag video URL', default=None)\n\n        if video_url is None:\n            raise ExtractorError('Cannot find video')\n\n        title = self._og_search_title(webpage, default=None)\n        if title is None:\n            title = self._html_search_regex(\n                [r'<b>Title:</b> ([^<]*)</div>',\n                r'class=\"tabSeperator\">></span><span class=\"tabText\">(.*?)<'],\n                webpage, 'title')\n        thumbnail = self._og_search_thumbnail(webpage)\n        description = self._og_search_description(webpage, default=None)\n        if description is None:\n            description = self._html_search_meta('description', webpage)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 59,
        "end_line": 112,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009000900090009,
            "pseudo_dstar_susp": 0.0006983240223463687,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0006983240223463687,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.drtv.DRTVIE._real_extract#27",
        "src_path": "youtube_dl/extractor/drtv.py",
        "class_name": "youtube_dl.extractor.drtv.DRTVIE",
        "signature": "youtube_dl.extractor.drtv.DRTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        programcard = self._download_json(\n            'http://www.dr.dk/mu/programcard/expanded/%s' % video_id, video_id, 'Downloading video JSON')\n\n        data = programcard['Data'][0]\n\n        title = data['Title']\n        description = data['Description']\n        timestamp = parse_iso8601(data['CreatedTime'][:-5])\n\n        thumbnail = None\n        duration = None\n\n        restricted_to_denmark = False\n\n        formats = []\n        subtitles = {}\n\n        for asset in data['Assets']:\n            if asset['Kind'] == 'Image':\n                thumbnail = asset['Uri']\n            elif asset['Kind'] == 'VideoResource':\n                duration = asset['DurationInMilliseconds'] / 1000.0\n                restricted_to_denmark = asset['RestrictedToDenmark']\n                for link in asset['Links']:\n                    target = link['Target']\n                    uri = link['Uri']\n                    formats.append({\n                        'url': uri + '?hdcore=3.3.0&plugin=aasp-3.3.0.99.43' if target == 'HDS' else uri,\n                        'format_id': target,\n                        'ext': link['FileFormat'],\n                        'preference': -1 if target == 'HDS' else -2,\n                    })\n                subtitles_list = asset.get('SubtitlesList')\n                if isinstance(subtitles_list, list):\n                    LANGS = {\n                        'Danish': 'dk',\n                    }\n                    for subs in subtitles_list:\n                        lang = subs['Language']\n                        subtitles[LANGS.get(lang, lang)] = subs['Uri']\n\n        if not formats and restricted_to_denmark:\n            raise ExtractorError(\n                'Unfortunately, DR is not allowed to show this program outside Denmark.', expected=True)\n\n        self._sort_formats(formats)\n\n        if self._downloader.params.get('listsubtitles', False):\n            self._list_available_subtitles(video_id, subtitles)\n            return\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'timestamp': timestamp,\n            'duration': duration,\n            'formats': formats,\n            'subtitles': self.extract_subtitles(video_id, subtitles),\n        }",
        "begin_line": 27,
        "end_line": 91,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.rtlnow.RTLnowIE._real_extract#99",
        "src_path": "youtube_dl/extractor/rtlnow.py",
        "class_name": "youtube_dl.extractor.rtlnow.RTLnowIE",
        "signature": "youtube_dl.extractor.rtlnow.RTLnowIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_page_url = 'http://%s/' % mobj.group('domain')\n        video_id = mobj.group('video_id')\n\n        webpage = self._download_webpage('http://' + mobj.group('url'), video_id)\n\n        mobj = re.search(r'(?s)<div style=\"margin-left: 20px; font-size: 13px;\">(.*?)<div id=\"playerteaser\">', webpage)\n        if mobj:\n            raise ExtractorError(clean_html(mobj.group(1)), expected=True)\n\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage)\n        thumbnail = self._og_search_thumbnail(webpage, default=None)\n\n        upload_date = unified_strdate(self._html_search_meta('uploadDate', webpage, 'upload date'))\n\n        mobj = re.search(r'<meta itemprop=\"duration\" content=\"PT(?P<seconds>\\d+)S\" />', webpage)\n        duration = int(mobj.group('seconds')) if mobj else None\n\n        playerdata_url = self._html_search_regex(\n            r\"'playerdata': '(?P<playerdata_url>[^']+)'\", webpage, 'playerdata_url')\n\n        playerdata = self._download_xml(playerdata_url, video_id, 'Downloading player data XML')\n\n        videoinfo = playerdata.find('./playlist/videoinfo')\n        \n        formats = []\n        for filename in videoinfo.findall('filename'):\n            mobj = re.search(r'(?P<url>rtmpe://(?:[^/]+/){2})(?P<play_path>.+)', filename.text)\n            if mobj:\n                fmt = {\n                    'url': mobj.group('url'),\n                    'play_path': 'mp4:' + mobj.group('play_path'),\n                    'page_url': video_page_url,\n                    'player_url': video_page_url + 'includes/vodplayer.swf',\n                }\n            else:\n                fmt = {\n                    'url': filename.text,\n                }\n            fmt.update({\n                'width': int_or_none(filename.get('width')),\n                'height': int_or_none(filename.get('height')),\n                'vbr': int_or_none(filename.get('bitrate')),\n                'ext': 'flv',\n            })\n            formats.append(fmt)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 99,
        "end_line": 156,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.jadorecettepub.JadoreCettePubIE._real_extract#25",
        "src_path": "youtube_dl/extractor/jadorecettepub.py",
        "class_name": "youtube_dl.extractor.jadorecettepub.JadoreCettePubIE",
        "signature": "youtube_dl.extractor.jadorecettepub.JadoreCettePubIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        title = self._html_search_regex(\n            r'<span style=\"font-size: x-large;\"><b>(.*?)</b></span>',\n            webpage, 'title')\n        description = self._html_search_regex(\n            r'(?s)<div id=\"fb-root\">(.*?)<script>', webpage, 'description',\n            fatal=False)\n        real_url = self._search_regex(\n            r'\\[/postlink\\](.*)endofvid', webpage, 'video URL')\n        video_id = YoutubeIE.extract_id(real_url)\n\n        return {\n            '_type': 'url_transparent',\n            'url': real_url,\n            'id': video_id,\n            'title': title,\n            'description': description,\n        }",
        "begin_line": 25,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.toypics.ToypicsIE._real_extract#23",
        "src_path": "youtube_dl/extractor/toypics.py",
        "class_name": "youtube_dl.extractor.toypics.ToypicsIE",
        "signature": "youtube_dl.extractor.toypics.ToypicsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        page = self._download_webpage(url, video_id)\n        video_url = self._html_search_regex(\n            r'src:\\s+\"(http://static[0-9]+\\.toypics\\.net/flvideo/[^\"]+)\"', page, 'video URL')\n        title = self._html_search_regex(\n            r'<title>Toypics - ([^<]+)</title>', page, 'title')\n        username = self._html_search_regex(\n            r'toypics.net/([^/\"]+)\" class=\"user-name\">', page, 'username')\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'uploader': username,\n            'age_limit': 18,\n        }",
        "begin_line": 23,
        "end_line": 39,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.toypics.ToypicsUserIE._real_extract#53",
        "src_path": "youtube_dl/extractor/toypics.py",
        "class_name": "youtube_dl.extractor.toypics.ToypicsUserIE",
        "signature": "youtube_dl.extractor.toypics.ToypicsUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        username = mobj.group('username')\n\n        profile_page = self._download_webpage(\n            url, username, note='Retrieving profile page')\n\n        video_count = int(self._search_regex(\n            r'public/\">Public Videos \\(([0-9]+)\\)</a></li>', profile_page,\n            'video count'))\n\n        PAGE_SIZE = 8\n        urls = []\n        page_count = (video_count + PAGE_SIZE + 1) // PAGE_SIZE\n        for n in range(1, page_count + 1):\n            lpage_url = url + '/public/%d' % n\n            lpage = self._download_webpage(\n                lpage_url, username,\n                note='Downloading page %d/%d' % (n, page_count))\n            urls.extend(\n                re.findall(\n                    r'<p class=\"video-entry-title\">\\s+<a href=\"(https?://videos.toypics.net/view/[^\"]+)\">',\n                    lpage))\n\n        return {\n            '_type': 'playlist',\n            'id': username,\n            'entries': [{\n                '_type': 'url',\n                'url': eurl,\n                'ie_key': 'Toypics',\n            } for eurl in urls]\n        }",
        "begin_line": 53,
        "end_line": 85,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005402485143165856,
            "pseudo_dstar_susp": 0.0005068423720223011,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.0005068423720223011,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.theplatform.ThePlatformIE._get_info#37",
        "src_path": "youtube_dl/extractor/theplatform.py",
        "class_name": "youtube_dl.extractor.theplatform.ThePlatformIE",
        "signature": "youtube_dl.extractor.theplatform.ThePlatformIE._get_info(self, video_id, smil_url)",
        "snippet": "    def _get_info(self, video_id, smil_url):\n        meta = self._download_xml(smil_url, video_id)\n\n        try:\n            error_msg = next(\n                n.attrib['abstract']\n                for n in meta.findall(_x('.//smil:ref'))\n                if n.attrib.get('title') == 'Geographic Restriction')\n        except StopIteration:\n            pass\n        else:\n            raise ExtractorError(error_msg, expected=True)\n\n        info_url = 'http://link.theplatform.com/s/dJ5BDC/{0}?format=preview'.format(video_id)\n        info_json = self._download_webpage(info_url, video_id)\n        info = json.loads(info_json)\n\n        head = meta.find(_x('smil:head'))\n        body = meta.find(_x('smil:body'))\n\n        f4m_node = body.find(_x('smil:seq//smil:video'))\n        if f4m_node is not None:\n            f4m_url = f4m_node.attrib['src']\n            if 'manifest.f4m?' not in f4m_url:\n                f4m_url += '?'\n            # the parameters are from syfy.com, other sites may use others,\n            # they also work for nbc.com\n            f4m_url += '&g=UXWGVKRWHFSP&hdcore=3.0.3'\n            formats = [{\n                'ext': 'flv',\n                'url': f4m_url,\n            }]\n        else:\n            base_url = head.find(_x('smil:meta')).attrib['base']\n            switch = body.find(_x('smil:switch'))\n            formats = []\n            for f in switch.findall(_x('smil:video')):\n                attr = f.attrib\n                width = int(attr['width'])\n                height = int(attr['height'])\n                vbr = int(attr['system-bitrate']) // 1000\n                format_id = '%dx%d_%dk' % (width, height, vbr)\n                formats.append({\n                    'format_id': format_id,\n                    'url': base_url,\n                    'play_path': 'mp4:' + attr['src'],\n                    'ext': 'flv',\n                    'width': width,\n                    'height': height,\n                    'vbr': vbr,\n                })\n            self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': info['title'],\n            'formats': formats,\n            'description': info['description'],\n            'thumbnail': info['defaultThumbnailUrl'],\n            'duration': info['duration']//1000,\n        }",
        "begin_line": 37,
        "end_line": 97,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00023618327822390176,
            "pseudo_dstar_susp": 0.000233590282644242,
            "pseudo_tarantula_susp": 0.0002772387025228722,
            "pseudo_op2_susp": 0.000233590282644242,
            "pseudo_barinel_susp": 0.00027631942525559546
        }
    },
    {
        "name": "youtube_dl.extractor.theplatform.ThePlatformIE._real_extract#99",
        "src_path": "youtube_dl/extractor/theplatform.py",
        "class_name": "youtube_dl.extractor.theplatform.ThePlatformIE",
        "signature": "youtube_dl.extractor.theplatform.ThePlatformIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        if mobj.group('config'):\n            config_url = url+ '&form=json'\n            config_url = config_url.replace('swf/', 'config/')\n            config_url = config_url.replace('onsite/', 'onsite/config/')\n            config = self._download_json(config_url, video_id, 'Downloading config')\n            smil_url = config['releaseUrl'] + '&format=SMIL&formats=MPEG4&manifest=f4m'\n        else:\n            smil_url = ('http://link.theplatform.com/s/dJ5BDC/{0}/meta.smil?'\n                'format=smil&mbr=true'.format(video_id))\n        return self._get_info(video_id, smil_url)",
        "begin_line": 99,
        "end_line": 111,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00023618327822390176,
            "pseudo_dstar_susp": 0.000233590282644242,
            "pseudo_tarantula_susp": 0.0002772387025228722,
            "pseudo_op2_susp": 0.000233590282644242,
            "pseudo_barinel_susp": 0.00027631942525559546
        }
    },
    {
        "name": "youtube_dl.extractor.fc2.FC2IE._real_extract#28",
        "src_path": "youtube_dl/extractor/fc2.py",
        "class_name": "youtube_dl.extractor.fc2.FC2IE",
        "signature": "youtube_dl.extractor.fc2.FC2IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        self._downloader.cookiejar.clear_session_cookies()  # must clear\n\n        title = self._og_search_title(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n        refer = url.replace('/content/', '/a/content/')\n\n        mimi = hashlib.md5((video_id + '_gGddgPfeaf_gzyr').encode('utf-8')).hexdigest()\n\n        info_url = (\n            \"http://video.fc2.com/ginfo.php?mimi={1:s}&href={2:s}&v={0:s}&fversion=WIN%2011%2C6%2C602%2C180&from=2&otag=0&upid={0:s}&tk=null&\".\n            format(video_id, mimi, compat_urllib_request.quote(refer, safe='').replace('.','%2E')))\n\n        info_webpage = self._download_webpage(\n            info_url, video_id, note='Downloading info page')\n        info = compat_urlparse.parse_qs(info_webpage)\n\n        if 'err_code' in info:\n            raise ExtractorError('Error code: %s' % info['err_code'][0])\n\n        video_url = info['filepath'][0] + '?mid=' + info['mid'][0]\n        title_info = info.get('title')\n        if title_info:\n            title = title_info[0]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'ext': 'flv',\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 28,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.__init__.gen_extractors#473",
        "src_path": "youtube_dl/extractor/__init__.py",
        "class_name": "youtube_dl.extractor.__init__",
        "signature": "youtube_dl.extractor.__init__.gen_extractors()",
        "snippet": "def gen_extractors():\n    \"\"\" Return a list of an instance of every supported extractor.\n    The order does matter; the first extractor matched is the one handling the URL.\n    \"\"\"\n    return [klass() for klass in _ALL_CLASSES]",
        "begin_line": 473,
        "end_line": 477,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 1.0,
            "pseudo_dstar_susp": 1.0,
            "pseudo_tarantula_susp": 0.00030003000300030005,
            "pseudo_op2_susp": 1.0,
            "pseudo_barinel_susp": 0.00030003000300030005
        }
    },
    {
        "name": "youtube_dl.extractor.__init__.get_info_extractor#480",
        "src_path": "youtube_dl/extractor/__init__.py",
        "class_name": "youtube_dl.extractor.__init__",
        "signature": "youtube_dl.extractor.__init__.get_info_extractor(ie_name)",
        "snippet": "def get_info_extractor(ie_name):\n    \"\"\"Returns the info extractor class with the given ie_name\"\"\"\n    return globals()[ie_name+'IE']",
        "begin_line": 480,
        "end_line": 482,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.005291005291005291,
            "pseudo_dstar_susp": 0.006756756756756757,
            "pseudo_tarantula_susp": 0.00029342723004694836,
            "pseudo_op2_susp": 0.006756756756756757,
            "pseudo_barinel_susp": 0.00029342723004694836
        }
    },
    {
        "name": "youtube_dl.extractor.xboxclips.XboxClipsIE._real_extract#30",
        "src_path": "youtube_dl/extractor/xboxclips.py",
        "class_name": "youtube_dl.extractor.xboxclips.XboxClipsIE",
        "signature": "youtube_dl.extractor.xboxclips.XboxClipsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = self._html_search_regex(\n            r'>Link: <a href=\"([^\"]+)\">', webpage, 'video URL')\n        title = self._html_search_regex(\n            r'<title>XboxClips \\| ([^<]+)</title>', webpage, 'title')\n        timestamp = parse_iso8601(self._html_search_regex(\n            r'>Recorded: ([^<]+)<', webpage, 'upload date', fatal=False))\n        filesize = float_or_none(self._html_search_regex(\n            r'>Size: ([\\d\\.]+)MB<', webpage, 'file size', fatal=False), invscale=1024 * 1024)\n        duration = int_or_none(self._html_search_regex(\n            r'>Duration: (\\d+) Seconds<', webpage, 'duration', fatal=False))\n        view_count = int_or_none(self._html_search_regex(\n            r'>Views: (\\d+)<', webpage, 'view count', fatal=False))\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'timestamp': timestamp,\n            'filesize_approx': filesize,\n            'duration': duration,\n            'view_count': view_count,\n        }",
        "begin_line": 30,
        "end_line": 57,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.aparat.AparatIE._real_extract#28",
        "src_path": "youtube_dl/extractor/aparat.py",
        "class_name": "youtube_dl.extractor.aparat.AparatIE",
        "signature": "youtube_dl.extractor.aparat.AparatIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('id')\n\n        # Note: There is an easier-to-parse configuration at\n        # http://www.aparat.com/video/video/config/videohash/%video_id\n        # but the URL in there does not work\n        embed_url = ('http://www.aparat.com/video/video/embed/videohash/' +\n                     video_id + '/vt/frame')\n        webpage = self._download_webpage(embed_url, video_id)\n\n        video_urls = re.findall(r'fileList\\[[0-9]+\\]\\s*=\\s*\"([^\"]+)\"', webpage)\n        for i, video_url in enumerate(video_urls):\n            req = HEADRequest(video_url)\n            res = self._request_webpage(\n                req, video_id, note=u'Testing video URL %d' % i, errnote=False)\n            if res:\n                break\n        else:\n            raise ExtractorError(u'No working video URLs found')\n\n        title = self._search_regex(r'\\s+title:\\s*\"([^\"]+)\"', webpage, u'title')\n        thumbnail = self._search_regex(\n            r'\\s+image:\\s*\"([^\"]+)\"', webpage, u'thumbnail', fatal=False)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'ext': 'mp4',\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 28,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.imdb.ImdbIE._real_extract#29",
        "src_path": "youtube_dl/extractor/imdb.py",
        "class_name": "youtube_dl.extractor.imdb.ImdbIE",
        "signature": "youtube_dl.extractor.imdb.ImdbIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage('http://www.imdb.com/video/imdb/vi%s' % video_id, video_id)\n        descr = get_element_by_attribute('itemprop', 'description', webpage)\n        available_formats = re.findall(\n            r'case \\'(?P<f_id>.*?)\\' :$\\s+url = \\'(?P<path>.*?)\\'', webpage,\n            flags=re.MULTILINE)\n        formats = []\n        for f_id, f_path in available_formats:\n            f_path = f_path.strip()\n            format_page = self._download_webpage(\n                compat_urlparse.urljoin(url, f_path),\n                'Downloading info for %s format' % f_id)\n            json_data = self._search_regex(\n                r'<script[^>]+class=\"imdb-player-data\"[^>]*?>(.*?)</script>',\n                format_page, 'json data', flags=re.DOTALL)\n            info = json.loads(json_data)\n            format_info = info['videoPlayerObject']['video']\n            formats.append({\n                'format_id': f_id,\n                'url': format_info['url'],\n            })\n\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n            'formats': formats,\n            'description': descr,\n            'thumbnail': format_info['slate'],\n        }",
        "begin_line": 29,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.imdb.ImdbListIE._real_extract#75",
        "src_path": "youtube_dl/extractor/imdb.py",
        "class_name": "youtube_dl.extractor.imdb.ImdbListIE",
        "signature": "youtube_dl.extractor.imdb.ImdbListIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        list_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, list_id)\n        entries = [\n            self.url_result('http://www.imdb.com' + m, 'Imdb')\n            for m in re.findall(r'href=\"(/video/imdb/vi[^\"]+)\"\\s+data-type=\"playlist\"', webpage)]\n\n        list_title = self._html_search_regex(\n            r'<h1 class=\"header\">(.*?)</h1>', webpage, 'list title')\n\n        return self.playlist_result(entries, list_id, list_title)",
        "begin_line": 75,
        "end_line": 87,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.tf1.TF1IE._real_extract#26",
        "src_path": "youtube_dl/extractor/tf1.py",
        "class_name": "youtube_dl.extractor.tf1.TF1IE",
        "signature": "youtube_dl.extractor.tf1.TF1IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        embed_url = self._html_search_regex(\n            r'\"(https://www.wat.tv/embedframe/.*?)\"', webpage, 'embed url')\n        embed_page = self._download_webpage(embed_url, video_id,\n            'Downloading embed player page')\n        wat_id = self._search_regex(r'UVID=(.*?)&', embed_page, 'wat id')\n        wat_info = self._download_json(\n            'http://www.wat.tv/interface/contentv3/%s' % wat_id, video_id)\n        return self.url_result(wat_info['media']['url'], 'Wat')",
        "begin_line": 26,
        "end_line": 37,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.ruhd.RUHDIE._real_extract#23",
        "src_path": "youtube_dl/extractor/ruhd.py",
        "class_name": "youtube_dl.extractor.ruhd.RUHDIE",
        "signature": "youtube_dl.extractor.ruhd.RUHDIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = self._html_search_regex(\n            r'<param name=\"src\" value=\"([^\"]+)\"', webpage, 'video url')\n        title = self._html_search_regex(\n            r'<title>([^<]+)&nbsp;&nbsp; RUHD.ru - \u0412\u0438\u0434\u0435\u043e \u0412\u044b\u0441\u043e\u043a\u043e\u0433\u043e \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u21161 \u0432 \u0420\u043e\u0441\u0441\u0438\u0438!</title>', webpage, 'title')\n        description = self._html_search_regex(\n            r'(?s)<div id=\"longdesc\">(.+?)<span id=\"showlink\">', webpage, 'description', fatal=False)\n        thumbnail = self._html_search_regex(\n            r'<param name=\"previewImage\" value=\"([^\"]+)\"', webpage, 'thumbnail', fatal=False)\n        if thumbnail:\n            thumbnail = 'http://www.ruhd.ru' + thumbnail\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 23,
        "end_line": 46,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.canalplus.CanalplusIE._real_extract#30",
        "src_path": "youtube_dl/extractor/canalplus.py",
        "class_name": "youtube_dl.extractor.canalplus.CanalplusIE",
        "signature": "youtube_dl.extractor.canalplus.CanalplusIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.groupdict().get('id')\n\n        # Beware, some subclasses do not define an id group\n        display_id = url_basename(mobj.group('path'))\n\n        if video_id is None:\n            webpage = self._download_webpage(url, display_id)\n            video_id = self._search_regex(r'<canal:player videoId=\"(\\d+)\"', webpage, 'video id')\n\n        info_url = self._VIDEO_INFO_TEMPLATE % video_id\n        doc = self._download_xml(info_url, video_id, 'Downloading video XML')\n\n        video_info = [video for video in doc if video.find('ID').text == video_id][0]\n        media = video_info.find('MEDIA')\n        infos = video_info.find('INFOS')\n\n        preferences = ['MOBILE', 'BAS_DEBIT', 'HAUT_DEBIT', 'HD', 'HLS', 'HDS']\n\n        formats = [\n            {\n                'url': fmt.text + '?hdcore=2.11.3' if fmt.tag == 'HDS' else fmt.text,\n                'format_id': fmt.tag,\n                'ext': 'mp4' if fmt.tag == 'HLS' else 'flv',\n                'preference': preferences.index(fmt.tag) if fmt.tag in preferences else -1,\n            } for fmt in media.find('VIDEOS') if fmt.text\n        ]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'display_id': display_id,\n            'title': '%s - %s' % (infos.find('TITRAGE/TITRE').text,\n                                  infos.find('TITRAGE/SOUS_TITRE').text),\n            'upload_date': unified_strdate(infos.find('PUBLICATION/DATE').text),\n            'thumbnail': media.find('IMAGES/GRAND').text,\n            'description': infos.find('DESCRIPTION').text,\n            'view_count': int(infos.find('NB_VUES').text),\n            'like_count': int(infos.find('NB_LIKES').text),\n            'comment_count': int(infos.find('NB_COMMENTS').text),\n            'formats': formats,\n        }",
        "begin_line": 30,
        "end_line": 72,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.postprocessor.xattrpp.XAttrMetadataPP.run#26",
        "src_path": "youtube_dl/postprocessor/xattrpp.py",
        "class_name": "youtube_dl.postprocessor.xattrpp.XAttrMetadataPP",
        "signature": "youtube_dl.postprocessor.xattrpp.XAttrMetadataPP.run(self, info)",
        "snippet": "    def run(self, info):\n        \"\"\" Set extended attributes on downloaded file (if xattr support is found). \"\"\"\n\n        # This mess below finds the best xattr tool for the job and creates a\n        # \"write_xattr\" function.\n        try:\n            # try the pyxattr module...\n            import xattr\n\n            def write_xattr(path, key, value):\n                return xattr.setxattr(path, key, value)\n\n        except ImportError:\n            if os.name == 'nt':\n                # Write xattrs to NTFS Alternate Data Streams:\n                # http://en.wikipedia.org/wiki/NTFS#Alternate_data_streams_.28ADS.29\n                def write_xattr(path, key, value):\n                    assert ':' not in key\n                    assert os.path.exists(path)\n\n                    ads_fn = path + \":\" + key\n                    with open(ads_fn, \"wb\") as f:\n                        f.write(value)\n            else:\n                user_has_setfattr = check_executable(\"setfattr\", ['--version'])\n                user_has_xattr = check_executable(\"xattr\", ['-h'])\n\n                if user_has_setfattr or user_has_xattr:\n\n                    def write_xattr(path, key, value):\n                        if user_has_setfattr:\n                            cmd = ['setfattr', '-n', key, '-v', value, path]\n                        elif user_has_xattr:\n                            cmd = ['xattr', '-w', key, value, path]\n\n                        subprocess_check_output(cmd)\n\n                else:\n                    # On Unix, and can't find pyxattr, setfattr, or xattr.\n                    if sys.platform.startswith('linux'):\n                        self._downloader.report_error(\n                            \"Couldn't find a tool to set the xattrs. \"\n                            \"Install either the python 'pyxattr' or 'xattr' \"\n                            \"modules, or the GNU 'attr' package \"\n                            \"(which contains the 'setfattr' tool).\")\n                    else:\n                        self._downloader.report_error(\n                            \"Couldn't find a tool to set the xattrs. \"\n                            \"Install either the python 'xattr' module, \"\n                            \"or the 'xattr' binary.\")\n\n        # Write the metadata to the file's xattrs\n        self._downloader.to_screen('[metadata] Writing metadata to file\\'s xattrs')\n\n        filename = info['filepath']\n\n        try:\n            xattr_mapping = {\n                'user.xdg.referrer.url': 'webpage_url',\n                # 'user.xdg.comment':            'description',\n                'user.dublincore.title': 'title',\n                'user.dublincore.date': 'upload_date',\n                'user.dublincore.description': 'description',\n                'user.dublincore.contributor': 'uploader',\n                'user.dublincore.format': 'format',\n            }\n\n            for xattrname, infoname in xattr_mapping.items():\n\n                value = info.get(infoname)\n\n                if value:\n                    if infoname == \"upload_date\":\n                        value = hyphenate_date(value)\n\n                    byte_value = value.encode('utf-8')\n                    write_xattr(filename, xattrname, byte_value)\n\n            return True, info\n\n        except (subprocess.CalledProcessError, OSError):\n            self._downloader.report_error(\"This filesystem doesn't support extended attributes. (You may have to enable them in your /etc/fstab)\")\n            return False, info",
        "begin_line": 26,
        "end_line": 108,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.firstpost.FirstpostIE._real_extract#22",
        "src_path": "youtube_dl/extractor/firstpost.py",
        "class_name": "youtube_dl.extractor.firstpost.FirstpostIE",
        "signature": "youtube_dl.extractor.firstpost.FirstpostIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        page = self._download_webpage(url, video_id)\n        title = self._html_search_meta('twitter:title', page, 'title')\n        description = self._html_search_meta('twitter:description', page, 'title')\n\n        data = self._download_xml(\n            'http://www.firstpost.com/getvideoxml-%s.xml' % video_id, video_id,\n            'Downloading video XML')\n\n        item = data.find('./playlist/item')\n        thumbnail = item.find('./image').text\n\n        formats = [\n            {\n                'url': details.find('./file').text,\n                'format_id': details.find('./label').text.strip(),\n                'width': int(details.find('./width').text.strip()),\n                'height': int(details.find('./height').text.strip()),\n            } for details in item.findall('./source/file_details') if details.find('./file').text\n        ]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'formats': formats,\n        }",
        "begin_line": 22,
        "end_line": 52,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.expotv.ExpoTVIE._real_extract#29",
        "src_path": "youtube_dl/extractor/expotv.py",
        "class_name": "youtube_dl.extractor.expotv.ExpoTVIE",
        "signature": "youtube_dl.extractor.expotv.ExpoTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        player_key = self._search_regex(\n            r'<param name=\"playerKey\" value=\"([^\"]+)\"', webpage, 'player key')\n        config_url = 'http://client.expotv.com/video/config/%s/%s' % (\n            video_id, player_key)\n        config = self._download_json(\n            config_url, video_id,\n            note='Downloading video configuration')\n\n        formats = [{\n            'url': fcfg['file'],\n            'height': int_or_none(fcfg.get('height')),\n            'format_note': fcfg.get('label'),\n            'ext': self._search_regex(\n                r'filename=.*\\.([a-z0-9_A-Z]+)&', fcfg['file'],\n                'file extension', default=None),\n        } for fcfg in config['sources']]\n        self._sort_formats(formats)\n\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage)\n        thumbnail = config.get('image')\n        view_count = int_or_none(self._search_regex(\n            r'<h5>Plays: ([0-9]+)</h5>', webpage, 'view counts'))\n        uploader = self._search_regex(\n            r'<div class=\"reviewer\">\\s*<img alt=\"([^\"]+)\"', webpage, 'uploader',\n            fatal=False)\n        upload_date = unified_strdate(self._search_regex(\n            r'<h5>Reviewed on ([0-9/.]+)</h5>', webpage, 'upload date',\n            fatal=False))\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': title,\n            'description': description,\n            'view_count': view_count,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'upload_date': upload_date,\n        }",
        "begin_line": 29,
        "end_line": 73,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.downloader.mplayer.MplayerFD.real_download#11",
        "src_path": "youtube_dl/downloader/mplayer.py",
        "class_name": "youtube_dl.downloader.mplayer.MplayerFD",
        "signature": "youtube_dl.downloader.mplayer.MplayerFD.real_download(self, filename, info_dict)",
        "snippet": "    def real_download(self, filename, info_dict):\n        url = info_dict['url']\n        self.report_destination(filename)\n        tmpfilename = self.temp_name(filename)\n\n        args = ['mplayer', '-really-quiet', '-vo', 'null', '-vc', 'dummy', '-dumpstream', '-dumpfile', tmpfilename, url]\n        # Check for mplayer first\n        try:\n            subprocess.call(['mplayer', '-h'], stdout=(open(os.path.devnull, 'w')), stderr=subprocess.STDOUT)\n        except (OSError, IOError):\n            self.report_error(u'MMS or RTSP download detected but \"%s\" could not be run' % args[0])\n            return False\n\n        # Download using mplayer.\n        retval = subprocess.call(args)\n        if retval == 0:\n            fsize = os.path.getsize(encodeFilename(tmpfilename))\n            self.to_screen(u'\\r[%s] %s bytes' % (args[0], fsize))\n            self.try_rename(tmpfilename, filename)\n            self._hook_progress({\n                'downloaded_bytes': fsize,\n                'total_bytes': fsize,\n                'filename': filename,\n                'status': 'finished',\n            })\n            return True\n        else:\n            self.to_stderr(u\"\\n\")\n            self.report_error(u'mplayer exited with code %d' % retval)\n            return False",
        "begin_line": 11,
        "end_line": 40,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.cliphunter._decode#18",
        "src_path": "youtube_dl/extractor/cliphunter.py",
        "class_name": "youtube_dl.extractor.cliphunter",
        "signature": "youtube_dl.extractor.cliphunter._decode(s)",
        "snippet": "def _decode(s):\n    return ''.join(_translation_table.get(c, c) for c in s)",
        "begin_line": 18,
        "end_line": 19,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00010269049086054631,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.cliphunter.CliphunterIE._real_extract#42",
        "src_path": "youtube_dl/extractor/cliphunter.py",
        "class_name": "youtube_dl.extractor.cliphunter.CliphunterIE",
        "signature": "youtube_dl.extractor.cliphunter.CliphunterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_title = self._search_regex(\n            r'mediaTitle = \"([^\"]+)\"', webpage, 'title')\n\n        pl_fiji = self._search_regex(\n            r'pl_fiji = \\'([^\\']+)\\'', webpage, 'video data')\n        pl_c_qual = self._search_regex(\n            r'pl_c_qual = \"(.)\"', webpage, 'video quality')\n        video_url = _decode(pl_fiji)\n        formats = [{\n            'url': video_url,\n            'format_id': 'default-%s' % pl_c_qual,\n        }]\n\n        qualities_json = self._search_regex(\n            r'var pl_qualities\\s*=\\s*(.*?);\\n', webpage, 'quality info')\n        qualities_data = json.loads(qualities_json)\n\n        for i, t in enumerate(\n                re.findall(r\"pl_fiji_([a-z0-9]+)\\s*=\\s*'([^']+')\", webpage)):\n            quality_id, crypted_url = t\n            video_url = _decode(crypted_url)\n            f = {\n                'format_id': quality_id,\n                'url': video_url,\n                'quality': i,\n            }\n            if quality_id in qualities_data:\n                qd = qualities_data[quality_id]\n                m = re.match(\n                    r'''(?x)<b>(?P<width>[0-9]+)x(?P<height>[0-9]+)<\\\\/b>\n                        \\s*\\(\\s*(?P<tbr>[0-9]+)\\s*kb\\\\/s''', qd)\n                if m:\n                    f['width'] = int(m.group('width'))\n                    f['height'] = int(m.group('height'))\n                    f['tbr'] = int(m.group('tbr'))\n            formats.append(f)\n        self._sort_formats(formats)\n\n        thumbnail = self._search_regex(\n            r\"var\\s+mov_thumb\\s*=\\s*'([^']+)';\",\n            webpage, 'thumbnail', fatal=False)\n        duration = int_or_none(self._search_regex(\n            r'pl_dur\\s*=\\s*([0-9]+)', webpage, 'duration', fatal=False))\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'formats': formats,\n            'duration': duration,\n            'age_limit': self._rta_search(webpage),\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 42,
        "end_line": 99,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.helsinki.HelsinkiIE._real_extract#26",
        "src_path": "youtube_dl/extractor/helsinki.py",
        "class_name": "youtube_dl.extractor.helsinki.HelsinkiIE",
        "signature": "youtube_dl.extractor.helsinki.HelsinkiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        formats = []\n\n        mobj = re.search(r'file=((\\w+):[^&]+)', webpage)\n        if mobj:\n            formats.append({\n                'ext': mobj.group(2),\n                'play_path': mobj.group(1),\n                'url': 'rtmp://flashvideo.it.helsinki.fi/vod/',\n                'player_url': 'http://video.helsinki.fi/player.swf',\n                'format_note': 'sd',\n                'quality': 0,\n            })\n\n        mobj = re.search(r'hd\\.file=((\\w+):[^&]+)', webpage)\n        if mobj:\n            formats.append({\n                'ext': mobj.group(2),\n                'play_path': mobj.group(1),\n                'url': 'rtmp://flashvideo.it.helsinki.fi/vod/',\n                'player_url': 'http://video.helsinki.fi/player.swf',\n                'format_note': 'hd',\n                'quality': 1,\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage).replace('Video: ', ''),\n            'description': self._og_search_description(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'formats': formats,\n        }",
        "begin_line": 26,
        "end_line": 62,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.thisav.ThisAVIE._real_extract#24",
        "src_path": "youtube_dl/extractor/thisav.py",
        "class_name": "youtube_dl.extractor.thisav.ThisAVIE",
        "signature": "youtube_dl.extractor.thisav.ThisAVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        title = self._html_search_regex(r'<h1>([^<]*)</h1>', webpage, 'title')\n        video_url = self._html_search_regex(\n            r\"addVariable\\('file','([^']+)'\\);\", webpage, 'video url')\n        uploader = self._html_search_regex(\n            r': <a href=\"http://www.thisav.com/user/[0-9]+/(?:[^\"]+)\">([^<]+)</a>',\n            webpage, 'uploader name', fatal=False)\n        uploader_id = self._html_search_regex(\n            r': <a href=\"http://www.thisav.com/user/[0-9]+/([^\"]+)\">(?:[^<]+)</a>',\n            webpage, 'uploader id', fatal=False)\n        ext = determine_ext(video_url)\n        \n        return {\n            'id':          video_id,\n            'url':         video_url,\n            'uploader':    uploader,\n            'uploader_id': uploader_id,\n            'title':       title,\n            'ext':         ext,\n        }",
        "begin_line": 24,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.beeg.BeegIE._real_extract#24",
        "src_path": "youtube_dl/extractor/beeg.py",
        "class_name": "youtube_dl.extractor.beeg.BeegIE",
        "signature": "youtube_dl.extractor.beeg.BeegIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        quality_arr = self._search_regex(\n            r'(?s)var\\s+qualityArr\\s*=\\s*{\\s*(.+?)\\s*}', webpage, 'quality formats')\n\n        formats = [{\n            'url': fmt[1],\n            'format_id': fmt[0],\n            'height': int(fmt[0][:-1]),\n        } for fmt in re.findall(r\"'([^']+)'\\s*:\\s*'([^']+)'\", quality_arr)]\n\n        self._sort_formats(formats)\n\n        title = self._html_search_regex(\n            r'<title>([^<]+)\\s*-\\s*beeg\\.?</title>', webpage, 'title')\n        \n        description = self._html_search_regex(\n            r'<meta name=\"description\" content=\"([^\"]*)\"',\n            webpage, 'description', fatal=False)\n        thumbnail = self._html_search_regex(\n            r'\\'previewer.url\\'\\s*:\\s*\"([^\"]*)\"',\n            webpage, 'thumbnail', fatal=False)\n\n        categories_str = self._html_search_regex(\n            r'<meta name=\"keywords\" content=\"([^\"]+)\"', webpage, 'categories', fatal=False)\n        categories = (\n            None if categories_str is None\n            else categories_str.split(','))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'categories': categories,\n            'formats': formats,\n            'age_limit': 18,\n        }",
        "begin_line": 24,
        "end_line": 65,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.hornbunny.HornBunnyIE._real_extract#27",
        "src_path": "youtube_dl/extractor/hornbunny.py",
        "class_name": "youtube_dl.extractor.hornbunny.HornBunnyIE",
        "signature": "youtube_dl.extractor.hornbunny.HornBunnyIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(\n            url, video_id, note='Downloading initial webpage')\n        title = self._html_search_regex(\n            r'class=\"title\">(.*?)</h2>', webpage, 'title')\n        redirect_url = self._html_search_regex(\n            r'pg&settings=(.*?)\\|0\"\\);', webpage, 'title')\n        webpage2 = self._download_webpage(redirect_url, video_id)\n        video_url = self._html_search_regex(\n            r'flvMask:(.*?);', webpage2, 'video_url')\n        \n        duration = parse_duration(self._search_regex(\n            r'<strong>Runtime:</strong>\\s*([0-9:]+)</div>',\n            webpage, 'duration', fatal=False))\n        view_count = int_or_none(self._search_regex(\n            r'<strong>Views:</strong>\\s*(\\d+)</div>',\n            webpage, 'view count', fatal=False))\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'ext': 'flv',\n            'duration': duration,\n            'view_count': view_count,\n            'age_limit': 18,\n        }",
        "begin_line": 27,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.cache.Cache.__init__#17",
        "src_path": "youtube_dl/cache.py",
        "class_name": "youtube_dl.cache.Cache",
        "signature": "youtube_dl.cache.Cache.__init__(self, ydl)",
        "snippet": "    def __init__(self, ydl):\n        self._ydl = ydl",
        "begin_line": 17,
        "end_line": 18,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.018518518518518517,
            "pseudo_dstar_susp": 0.03225806451612903,
            "pseudo_tarantula_susp": 0.00030902348578491963,
            "pseudo_op2_susp": 0.03225806451612903,
            "pseudo_barinel_susp": 0.00030902348578491963
        }
    },
    {
        "name": "youtube_dl.cache.Cache._get_root_dir#20",
        "src_path": "youtube_dl/cache.py",
        "class_name": "youtube_dl.cache.Cache",
        "signature": "youtube_dl.cache.Cache._get_root_dir(self)",
        "snippet": "    def _get_root_dir(self):\n        res = self._ydl.params.get('cachedir')\n        if res is None:\n            cache_root = os.environ.get('XDG_CACHE_HOME', '~/.cache')\n            res = os.path.join(cache_root, 'youtube-dl')\n        return os.path.expanduser(res)",
        "begin_line": 20,
        "end_line": 25,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.cache.Cache._get_cache_fn#27",
        "src_path": "youtube_dl/cache.py",
        "class_name": "youtube_dl.cache.Cache",
        "signature": "youtube_dl.cache.Cache._get_cache_fn(self, section, key, dtype)",
        "snippet": "    def _get_cache_fn(self, section, key, dtype):\n        assert re.match(r'^[a-zA-Z0-9_.-]+$', section), \\\n            'invalid section %r' % section\n        assert re.match(r'^[a-zA-Z0-9_.-]+$', key), 'invalid key %r' % key\n        return os.path.join(\n            self._get_root_dir(), section, '%s.%s' % (key, dtype))",
        "begin_line": 27,
        "end_line": 32,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.cache.Cache.enabled#35",
        "src_path": "youtube_dl/cache.py",
        "class_name": "youtube_dl.cache.Cache",
        "signature": "youtube_dl.cache.Cache.enabled(self)",
        "snippet": "    def enabled(self):\n        return self._ydl.params.get('cachedir') is not False",
        "begin_line": 35,
        "end_line": 36,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.cache.Cache.store#38",
        "src_path": "youtube_dl/cache.py",
        "class_name": "youtube_dl.cache.Cache",
        "signature": "youtube_dl.cache.Cache.store(self, section, key, data, dtype='json')",
        "snippet": "    def store(self, section, key, data, dtype='json'):\n        assert dtype in ('json',)\n\n        if not self.enabled:\n            return\n\n        fn = self._get_cache_fn(section, key, dtype)\n        try:\n            try:\n                os.makedirs(os.path.dirname(fn))\n            except OSError as ose:\n                if ose.errno != errno.EEXIST:\n                    raise\n            write_json_file(data, fn)\n        except Exception:\n            tb = traceback.format_exc()\n            self._ydl.report_warning(\n                'Writing cache to %r failed: %s' % (fn, tb))",
        "begin_line": 38,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.cache.Cache.load#57",
        "src_path": "youtube_dl/cache.py",
        "class_name": "youtube_dl.cache.Cache",
        "signature": "youtube_dl.cache.Cache.load(self, section, key, dtype='json', default=None)",
        "snippet": "    def load(self, section, key, dtype='json', default=None):\n        assert dtype in ('json',)\n\n        if not self.enabled:\n            return default\n\n        cache_fn = self._get_cache_fn(section, key, dtype)\n        try:\n            try:\n                with io.open(cache_fn, 'r', encoding='utf-8') as cachef:\n                    return json.load(cachef)\n            except ValueError:\n                try:\n                    file_size = os.path.getsize(cache_fn)\n                except (OSError, IOError) as oe:\n                    file_size = str(oe)\n                self._ydl.report_warning(\n                    'Cache retrieval from %s failed (%s)' % (cache_fn, file_size))\n        except IOError:\n            pass  # No cache available\n\n        return default",
        "begin_line": 57,
        "end_line": 78,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.cache.Cache.remove#80",
        "src_path": "youtube_dl/cache.py",
        "class_name": "youtube_dl.cache.Cache",
        "signature": "youtube_dl.cache.Cache.remove(self)",
        "snippet": "    def remove(self):\n        if not self.enabled:\n            self._ydl.to_screen('Cache is disabled (Did you combine --no-cache-dir and --rm-cache-dir?)')\n            return\n\n        cachedir = self._get_root_dir()\n        if not any((term in cachedir) for term in ('cache', 'tmp')):\n            raise Exception('Not removing directory %s - this does not look like a cache dir' % cachedir)\n\n        self._ydl.to_screen(\n            'Removing cache dir %s .' % cachedir, skip_eol=True)\n        if os.path.exists(cachedir):\n            self._ydl.to_screen('.', skip_eol=True)\n            shutil.rmtree(cachedir)\n        self._ydl.to_screen('.')",
        "begin_line": 80,
        "end_line": 94,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.elpais.ElPaisIE._real_extract#26",
        "src_path": "youtube_dl/extractor/elpais.py",
        "class_name": "youtube_dl.extractor.elpais.ElPaisIE",
        "signature": "youtube_dl.extractor.elpais.ElPaisIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        prefix = self._html_search_regex(\n            r'var url_cache = \"([^\"]+)\";', webpage, 'URL prefix')\n        video_suffix = self._search_regex(\n            r\"URLMediaFile = url_cache \\+ '([^']+)'\", webpage, 'video URL')\n        video_url = prefix + video_suffix\n        thumbnail_suffix = self._search_regex(\n            r\"URLMediaStill = url_cache \\+ '([^']+)'\", webpage, 'thumbnail URL',\n            fatal=False)\n        thumbnail = (\n            None if thumbnail_suffix is None\n            else prefix + thumbnail_suffix)\n        title = self._html_search_regex(\n            '<h2 class=\"entry-header entry-title.*?>(.*?)</h2>',\n            webpage, 'title')\n        date_str = self._search_regex(\n            r'<p class=\"date-header date-int updated\"\\s+title=\"([^\"]+)\">',\n            webpage, 'upload date', fatal=False)\n        upload_date = (None if date_str is None else unified_strdate(date_str))\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': self._og_search_description(webpage),\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n        }",
        "begin_line": 26,
        "end_line": 58,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00010248001639680262,
            "pseudo_dstar_susp": 0.00010248001639680262,
            "pseudo_tarantula_susp": 0.00010248001639680262,
            "pseudo_op2_susp": 0.00020470829068577277,
            "pseudo_barinel_susp": 0.00010248001639680262
        }
    },
    {
        "name": "youtube_dl.extractor.tube8.Tube8IE._real_extract#31",
        "src_path": "youtube_dl/extractor/tube8.py",
        "class_name": "youtube_dl.extractor.tube8.Tube8IE",
        "signature": "youtube_dl.extractor.tube8.Tube8IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        req = compat_urllib_request.Request(url)\n        req.add_header('Cookie', 'age_verified=1')\n        webpage = self._download_webpage(req, video_id)\n\n        flashvars = json.loads(self._html_search_regex(\n            r'var flashvars\\s*=\\s*({.+?})', webpage, 'flashvars'))\n\n        video_url = flashvars['video_url']\n        if flashvars.get('encrypted') is True:\n            video_url = aes_decrypt_text(video_url, flashvars['video_title'], 32).decode('utf-8')\n        path = compat_urllib_parse_urlparse(video_url).path\n        format_id = '-'.join(path.split('/')[4].split('_')[:2])\n\n        thumbnail = flashvars.get('image_url')\n\n        title = self._html_search_regex(\n            r'videotitle\\s*=\\s*\"([^\"]+)', webpage, 'title')\n        description = self._html_search_regex(\n            r'>Description:</strong>(.+?)<', webpage, 'description', fatal=False)\n        uploader = self._html_search_regex(\n            r'<strong class=\"video-username\">(?:<a href=\"[^\"]+\">)?([^<]+)(?:</a>)?</strong>',\n            webpage, 'uploader', fatal=False)\n\n        like_count = int_or_none(self._html_search_regex(\n            r\"rupVar\\s*=\\s*'(\\d+)'\", webpage, 'like count', fatal=False))\n        dislike_count = int_or_none(self._html_search_regex(\n            r\"rdownVar\\s*=\\s*'(\\d+)'\", webpage, 'dislike count', fatal=False))\n        view_count = self._html_search_regex(\n            r'<strong>Views: </strong>([\\d,\\.]+)</li>', webpage, 'view count', fatal=False)\n        if view_count:\n            view_count = str_to_int(view_count)\n        comment_count = self._html_search_regex(\n            r'<span id=\"allCommentsCount\">(\\d+)</span>', webpage, 'comment count', fatal=False)\n        if comment_count:\n            comment_count = str_to_int(comment_count)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'format_id': format_id,\n            'view_count': view_count,\n            'like_count': like_count,\n            'dislike_count': dislike_count,\n            'comment_count': comment_count,\n            'age_limit': 18,\n        }",
        "begin_line": 31,
        "end_line": 84,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    },
    {
        "name": "youtube_dl.extractor.spiegeltv.SpiegeltvIE._real_extract#25",
        "src_path": "youtube_dl/extractor/spiegeltv.py",
        "class_name": "youtube_dl.extractor.spiegeltv.SpiegeltvIE",
        "signature": "youtube_dl.extractor.spiegeltv.SpiegeltvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        title = self._html_search_regex(r'<h1.*?>(.*?)</h1>', webpage, 'title')\n\n        apihost = 'http://spiegeltv-ivms2-restapi.s3.amazonaws.com'\n        version_json = self._download_json(\n            '%s/version.json' % apihost, video_id,\n            note='Downloading version information')\n        version_name = version_json['version_name']\n\n        slug_json = self._download_json(\n            '%s/%s/restapi/slugs/%s.json' % (apihost, version_name, video_id),\n            video_id,\n            note='Downloading object information')\n        oid = slug_json['object_id']\n\n        media_json = self._download_json(\n            '%s/%s/restapi/media/%s.json' % (apihost, version_name, oid),\n            video_id, note='Downloading media information')\n        uuid = media_json['uuid']\n        is_wide = media_json['is_wide']\n\n        server_json = self._download_json(\n            'http://www.spiegel.tv/streaming_servers/', video_id,\n            note='Downloading server information')\n        server = server_json[0]['endpoint']\n\n        thumbnails = []\n        for image in media_json['images']:\n            thumbnails.append({\n                'url': image['url'],\n                'width': image['width'],\n                'height': image['height'],\n            })\n\n        description = media_json['subtitle']\n        duration = media_json['duration_in_ms'] / 1000.\n\n        if is_wide:\n            format = '16x9'\n        else:\n            format = '4x3'\n\n        url = server + 'mp4:' + uuid + '_spiegeltv_0500_' + format + '.m4v'\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': url,\n            'ext': 'm4v',\n            'description': description,\n            'duration': duration,\n            'thumbnails': thumbnails\n        }",
        "begin_line": 25,
        "end_line": 81,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031867431485022306,
            "pseudo_dstar_susp": 0.00030184123151222455,
            "pseudo_tarantula_susp": 0.0006756756756756757,
            "pseudo_op2_susp": 0.00030184123151222455,
            "pseudo_barinel_susp": 0.0006756756756756757
        }
    }
]