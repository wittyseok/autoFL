[
    {
        "name": "tests.keras.preprocessing.text_test.test_one_hot#9",
        "src_path": "tests/keras/preprocessing/text_test.py",
        "class_name": "tests.keras.preprocessing.text_test",
        "signature": "tests.keras.preprocessing.text_test.test_one_hot()",
        "snippet": "def test_one_hot():\n    text = 'The cat sat on the mat.'\n    encoded = one_hot(text, 5)\n    assert len(encoded) == 6\n    assert np.max(encoded) <= 4\n    assert np.min(encoded) >= 0",
        "begin_line": 9,
        "end_line": 14,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.preprocessing.text_test.test_hashing_trick_hash#17",
        "src_path": "tests/keras/preprocessing/text_test.py",
        "class_name": "tests.keras.preprocessing.text_test",
        "signature": "tests.keras.preprocessing.text_test.test_hashing_trick_hash()",
        "snippet": "def test_hashing_trick_hash():\n    text = 'The cat sat on the mat.'\n    encoded = hashing_trick(text, 5)\n    assert len(encoded) == 6\n    assert np.max(encoded) <= 4\n    assert np.min(encoded) >= 1",
        "begin_line": 17,
        "end_line": 22,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.preprocessing.text_test.test_hashing_trick_md5#25",
        "src_path": "tests/keras/preprocessing/text_test.py",
        "class_name": "tests.keras.preprocessing.text_test",
        "signature": "tests.keras.preprocessing.text_test.test_hashing_trick_md5()",
        "snippet": "def test_hashing_trick_md5():\n    text = 'The cat sat on the mat.'\n    encoded = hashing_trick(text, 5, hash_function='md5')\n    assert len(encoded) == 6\n    assert np.max(encoded) <= 4\n    assert np.min(encoded) >= 1",
        "begin_line": 25,
        "end_line": 30,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.preprocessing.text_test.test_tokenizer#33",
        "src_path": "tests/keras/preprocessing/text_test.py",
        "class_name": "tests.keras.preprocessing.text_test",
        "signature": "tests.keras.preprocessing.text_test.test_tokenizer()",
        "snippet": "def test_tokenizer():\n    texts = ['The cat sat on the mat.',\n             'The dog sat on the log.',\n             'Dogs and cats living together.']\n    tokenizer = Tokenizer(num_words=10)\n    tokenizer.fit_on_texts(texts)\n\n    sequences = []\n    for seq in tokenizer.texts_to_sequences_generator(texts):\n        sequences.append(seq)\n    assert np.max(np.max(sequences)) < 10\n    assert np.min(np.min(sequences)) == 1\n\n    tokenizer.fit_on_sequences(sequences)\n\n    for mode in ['binary', 'count', 'tfidf', 'freq']:\n        matrix = tokenizer.texts_to_matrix(texts, mode)",
        "begin_line": 33,
        "end_line": 49,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.preprocessing.text_test.test_sequential_fit#52",
        "src_path": "tests/keras/preprocessing/text_test.py",
        "class_name": "tests.keras.preprocessing.text_test",
        "signature": "tests.keras.preprocessing.text_test.test_sequential_fit()",
        "snippet": "def test_sequential_fit():\n    texts = ['The cat sat on the mat.',\n             'The dog sat on the log.',\n             'Dogs and cats living together.']\n    word_sequences = [\n        ['The', 'cat', 'is', 'sitting'],\n        ['The', 'dog', 'is', 'standing']\n    ]\n\n    tokenizer = Tokenizer()\n    tokenizer.fit_on_texts(texts)\n    tokenizer.fit_on_texts(word_sequences)\n\n    assert tokenizer.document_count == 5\n\n    tokenizer.texts_to_matrix(texts)\n    tokenizer.texts_to_matrix(word_sequences)",
        "begin_line": 52,
        "end_line": 68,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.preprocessing.text_test.test_text_to_word_sequence#71",
        "src_path": "tests/keras/preprocessing/text_test.py",
        "class_name": "tests.keras.preprocessing.text_test",
        "signature": "tests.keras.preprocessing.text_test.test_text_to_word_sequence()",
        "snippet": "def test_text_to_word_sequence():\n    text = 'hello! ? world!'\n    assert text_to_word_sequence(text) == ['hello', 'world']",
        "begin_line": 71,
        "end_line": 73,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.preprocessing.text_test.test_text_to_word_sequence_multichar_split#76",
        "src_path": "tests/keras/preprocessing/text_test.py",
        "class_name": "tests.keras.preprocessing.text_test",
        "signature": "tests.keras.preprocessing.text_test.test_text_to_word_sequence_multichar_split()",
        "snippet": "def test_text_to_word_sequence_multichar_split():\n    text = 'hello!stop?world!'\n    assert text_to_word_sequence(text, split='stop') == ['hello', 'world']",
        "begin_line": 76,
        "end_line": 78,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.preprocessing.text_test.test_text_to_word_sequence_unicode#81",
        "src_path": "tests/keras/preprocessing/text_test.py",
        "class_name": "tests.keras.preprocessing.text_test",
        "signature": "tests.keras.preprocessing.text_test.test_text_to_word_sequence_unicode()",
        "snippet": "def test_text_to_word_sequence_unicode():\n    text = u'ali! veli? k\u0131rk dokuz elli'\n    assert text_to_word_sequence(text) == [u'ali', u'veli', u'k\u0131rk', u'dokuz', u'elli']",
        "begin_line": 81,
        "end_line": 83,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.preprocessing.text_test.test_text_to_word_sequence_unicode_multichar_split#86",
        "src_path": "tests/keras/preprocessing/text_test.py",
        "class_name": "tests.keras.preprocessing.text_test",
        "signature": "tests.keras.preprocessing.text_test.test_text_to_word_sequence_unicode_multichar_split()",
        "snippet": "def test_text_to_word_sequence_unicode_multichar_split():\n    text = u'ali!stopveli?stopk\u0131rkstopdokuzstopelli'\n    assert text_to_word_sequence(text, split='stop') == [u'ali', u'veli', u'k\u0131rk', u'dokuz', u'elli']",
        "begin_line": 86,
        "end_line": 88,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.preprocessing.text_test.test_tokenizer_unicode#91",
        "src_path": "tests/keras/preprocessing/text_test.py",
        "class_name": "tests.keras.preprocessing.text_test",
        "signature": "tests.keras.preprocessing.text_test.test_tokenizer_unicode()",
        "snippet": "def test_tokenizer_unicode():\n    texts = [u'ali veli k\u0131rk dokuz elli', u'ali veli k\u0131rk dokuz elli veli k\u0131rk dokuz']\n    tokenizer = Tokenizer(num_words=5)\n    tokenizer.fit_on_texts(texts)\n\n    assert len(tokenizer.word_counts) == 5",
        "begin_line": 91,
        "end_line": 96,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.preprocessing.text_test.test_tokenizer_oov_flag#99",
        "src_path": "tests/keras/preprocessing/text_test.py",
        "class_name": "tests.keras.preprocessing.text_test",
        "signature": "tests.keras.preprocessing.text_test.test_tokenizer_oov_flag()",
        "snippet": "def test_tokenizer_oov_flag():\n    \"\"\"\n    Test of Out of Vocabulary (OOV) flag in Tokenizer\n    \"\"\"\n    x_train = ['This text has only known words']\n    x_test = ['This text has some unknown words']  # 2 OOVs: some, unknown\n\n    # Default, without OOV flag\n    tokenizer = Tokenizer()\n    tokenizer.fit_on_texts(x_train)\n    x_test_seq = tokenizer.texts_to_sequences(x_test)\n    assert len(x_test_seq[0]) == 4  # discards 2 OOVs\n\n    # With OOV feature\n    tokenizer = Tokenizer(oov_token='<unk>')\n    tokenizer.fit_on_texts(x_train)\n    x_test_seq = tokenizer.texts_to_sequences(x_test)\n    assert len(x_test_seq[0]) == 6  # OOVs marked in place",
        "begin_line": 99,
        "end_line": 116,
        "comment": "",
        "is_bug": false
    }
]