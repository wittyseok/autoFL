[
    {
        "name": "tests.keras.engine.test_training.RandomSequence.__init__#25",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training.RandomSequence",
        "signature": "tests.keras.engine.test_training.RandomSequence.__init__(self, batch_size)",
        "snippet": "    def __init__(self, batch_size):\n        self.batch_size = batch_size",
        "begin_line": 25,
        "end_line": 26,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.RandomSequence.__len__#28",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training.RandomSequence",
        "signature": "tests.keras.engine.test_training.RandomSequence.__len__(self)",
        "snippet": "    def __len__(self):\n        return 12",
        "begin_line": 28,
        "end_line": 29,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.RandomSequence.__getitem__#31",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training.RandomSequence",
        "signature": "tests.keras.engine.test_training.RandomSequence.__getitem__(self, idx)",
        "snippet": "    def __getitem__(self, idx):\n        return [np.random.random((self.batch_size, 3)), np.random.random((self.batch_size, 3))], [\n            np.random.random((self.batch_size, 4)),\n            np.random.random((self.batch_size, 3))]",
        "begin_line": 31,
        "end_line": 34,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.RandomSequence.on_epoch_end#36",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training.RandomSequence",
        "signature": "tests.keras.engine.test_training.RandomSequence.on_epoch_end(self)",
        "snippet": "    def on_epoch_end(self):\n        pass",
        "begin_line": 36,
        "end_line": 37,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_check_array_lengths#41",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_check_array_lengths()",
        "snippet": "def test_check_array_lengths():\n    _check_array_lengths(None, None, None)\n    a_np = np.random.random((4, 3, 3))\n    _check_array_lengths(a_np, a_np, a_np)\n    _check_array_lengths([a_np, a_np], [a_np, a_np], [a_np, a_np])\n    _check_array_lengths([None], [None], [None])\n\n    b_np = np.random.random((3, 4))\n    with pytest.raises(ValueError):\n        _check_array_lengths(a_np, None, None)\n    with pytest.raises(ValueError):\n        _check_array_lengths(a_np, a_np, None)\n    with pytest.raises(ValueError):\n        _check_array_lengths([a_np], [None], None)\n    with pytest.raises(ValueError):\n        _check_array_lengths([a_np], [b_np], None)\n    with pytest.raises(ValueError):\n        _check_array_lengths([a_np], None, [b_np])",
        "begin_line": 41,
        "end_line": 58,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_slice_arrays#62",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_slice_arrays()",
        "snippet": "def test_slice_arrays():\n    input_a = np.random.random((10, 3))\n    _slice_arrays(None)\n    _slice_arrays(input_a, 0)\n    _slice_arrays(input_a, 0, 1)\n    _slice_arrays(input_a, stop=2)\n    input_a = [None, [1, 1], None, [1, 1]]\n    _slice_arrays(input_a, 0)\n    _slice_arrays(input_a, 0, 1)\n    _slice_arrays(input_a, stop=2)\n    input_a = [None]\n    _slice_arrays(input_a, 0)\n    _slice_arrays(input_a, 0, 1)\n    _slice_arrays(input_a, stop=2)\n    input_a = None\n    _slice_arrays(input_a, 0)\n    _slice_arrays(input_a, 0, 1)\n    _slice_arrays(input_a, stop=2)",
        "begin_line": 62,
        "end_line": 79,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_weighted_masked_objective#83",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_weighted_masked_objective()",
        "snippet": "def test_weighted_masked_objective():\n    a = Input(shape=(3,), name='input_a')\n\n    # weighted_masked_objective\n    def mask_dummy(y_true=None, y_pred=None, weight=None):\n        return K.placeholder(y_true.shape)\n\n    weighted_function = _weighted_masked_objective(losses.categorical_crossentropy)\n    weighted_function(a, a, None)",
        "begin_line": 83,
        "end_line": 91,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.mask_dummy#87",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.mask_dummy(y_true=None, y_pred=None, weight=None)",
        "snippet": "    def mask_dummy(y_true=None, y_pred=None, weight=None):\n        return K.placeholder(y_true.shape)",
        "begin_line": 87,
        "end_line": 88,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_model_methods#95",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_model_methods()",
        "snippet": "def test_model_methods():\n    a = Input(shape=(3,), name='input_a')\n    b = Input(shape=(3,), name='input_b')\n\n    a_2 = Dense(4, name='dense_1')(a)\n    dp = Dropout(0.5, name='dropout')\n    b_2 = dp(b)\n\n    model = Model([a, b], [a_2, b_2])\n\n    optimizer = 'rmsprop'\n    loss = 'mse'\n    loss_weights = [1., 0.5]\n\n    input_a_np = np.random.random((10, 3))\n    input_b_np = np.random.random((10, 3))\n\n    output_a_np = np.random.random((10, 4))\n    output_b_np = np.random.random((10, 3))\n\n    # training/testing doesn't work before compiling.\n    with pytest.raises(RuntimeError):\n        model.train_on_batch([input_a_np, input_b_np], [output_a_np, output_b_np])\n\n    model.compile(optimizer, loss, metrics=[], loss_weights=loss_weights,\n                  sample_weight_mode=None)\n\n    # test train_on_batch\n    out = model.train_on_batch([input_a_np, input_b_np],\n                               [output_a_np, output_b_np])\n    out = model.train_on_batch({'input_a': input_a_np, 'input_b': input_b_np},\n                               [output_a_np, output_b_np])\n    out = model.train_on_batch({'input_a': input_a_np, 'input_b': input_b_np},\n                               {'dense_1': output_a_np, 'dropout': output_b_np})\n\n    # test fit\n    out = model.fit([input_a_np, input_b_np],\n                    [output_a_np, output_b_np], epochs=1, batch_size=4)\n    out = model.fit({'input_a': input_a_np, 'input_b': input_b_np},\n                    [output_a_np, output_b_np], epochs=1, batch_size=4)\n    out = model.fit({'input_a': input_a_np, 'input_b': input_b_np},\n                    {'dense_1': output_a_np, 'dropout': output_b_np},\n                    epochs=1, batch_size=4)\n\n    # test validation_split\n    out = model.fit([input_a_np, input_b_np],\n                    [output_a_np, output_b_np],\n                    epochs=1, batch_size=4, validation_split=0.5)\n    out = model.fit({'input_a': input_a_np, 'input_b': input_b_np},\n                    [output_a_np, output_b_np],\n                    epochs=1, batch_size=4, validation_split=0.5)\n\n    # test validation data\n    out = model.fit([input_a_np, input_b_np],\n                    [output_a_np, output_b_np],\n                    epochs=1, batch_size=4,\n                    validation_data=([input_a_np, input_b_np], [output_a_np, output_b_np]))\n    out = model.fit({'input_a': input_a_np, 'input_b': input_b_np},\n                    [output_a_np, output_b_np],\n                    epochs=1, batch_size=4, validation_split=0.5,\n                    validation_data=({'input_a': input_a_np, 'input_b': input_b_np}, [output_a_np, output_b_np]))\n    out = model.fit({'input_a': input_a_np, 'input_b': input_b_np},\n                    {'dense_1': output_a_np, 'dropout': output_b_np},\n                    epochs=1, batch_size=4, validation_split=0.5,\n                    validation_data=(\n                        {'input_a': input_a_np, 'input_b': input_b_np},\n                        {'dense_1': output_a_np, 'dropout': output_b_np}))\n\n    # test_on_batch\n    out = model.test_on_batch([input_a_np, input_b_np],\n                              [output_a_np, output_b_np])\n    out = model.test_on_batch({'input_a': input_a_np, 'input_b': input_b_np},\n                              [output_a_np, output_b_np])\n    out = model.test_on_batch({'input_a': input_a_np, 'input_b': input_b_np},\n                              {'dense_1': output_a_np, 'dropout': output_b_np})\n\n    # predict_on_batch\n    out = model.predict_on_batch([input_a_np, input_b_np])\n    out = model.predict_on_batch({'input_a': input_a_np, 'input_b': input_b_np})\n\n    # predict, evaluate\n    input_a_np = np.random.random((10, 3))\n    input_b_np = np.random.random((10, 3))\n\n    output_a_np = np.random.random((10, 4))\n    output_b_np = np.random.random((10, 3))\n\n    out = model.evaluate([input_a_np, input_b_np], [output_a_np, output_b_np], batch_size=4)\n    out = model.predict([input_a_np, input_b_np], batch_size=4)\n\n    # with sample_weight\n    input_a_np = np.random.random((10, 3))\n    input_b_np = np.random.random((10, 3))\n\n    output_a_np = np.random.random((10, 4))\n    output_b_np = np.random.random((10, 3))\n\n    sample_weight = [None, np.random.random((10,))]\n    out = model.train_on_batch([input_a_np, input_b_np],\n                               [output_a_np, output_b_np],\n                               sample_weight=sample_weight)\n\n    out = model.test_on_batch([input_a_np, input_b_np],\n                              [output_a_np, output_b_np],\n                              sample_weight=sample_weight)\n\n    # test accuracy metric\n    model.compile(optimizer, loss, metrics=['acc'],\n                  sample_weight_mode=None)\n\n    out = model.train_on_batch([input_a_np, input_b_np],\n                               [output_a_np, output_b_np])\n    assert len(out) == 5\n    out = model.test_on_batch([input_a_np, input_b_np],\n                              [output_a_np, output_b_np])\n    assert len(out) == 5\n\n    # this should also work\n    model.compile(optimizer, loss, metrics={'dense_1': 'acc'},\n                  sample_weight_mode=None)\n\n    out = model.train_on_batch([input_a_np, input_b_np],\n                               [output_a_np, output_b_np])\n    assert len(out) == 4\n    out = model.test_on_batch([input_a_np, input_b_np],\n                              [output_a_np, output_b_np])\n    assert len(out) == 4\n\n    # and this as well\n    model.compile(optimizer, loss, metrics={'dense_1': ['acc']},\n                  sample_weight_mode=None)\n\n    out = model.train_on_batch([input_a_np, input_b_np],\n                               [output_a_np, output_b_np])\n    assert len(out) == 4\n    out = model.test_on_batch([input_a_np, input_b_np],\n                              [output_a_np, output_b_np])\n    assert len(out) == 4\n\n    # test starting from non-zero initial epoch\n    trained_epochs = []\n    trained_batches = []\n\n    # define tracer callback\n    def on_epoch_begin(epoch, logs):\n        trained_epochs.append(epoch)\n\n    def on_batch_begin(batch, logs):\n        trained_batches.append(batch)\n\n    tracker_cb = LambdaCallback(on_epoch_begin=on_epoch_begin,\n                                on_batch_begin=on_batch_begin)\n\n    out = model.fit([input_a_np, input_b_np],\n                    [output_a_np, output_b_np], epochs=5, batch_size=4,\n                    initial_epoch=2, callbacks=[tracker_cb])\n    assert trained_epochs == [2, 3, 4]\n\n    # test starting from non-zero initial epoch for generator too\n    trained_epochs = []\n\n    def gen_data(batch_sz):\n        while True:\n            yield ([np.random.random((batch_sz, 3)), np.random.random((batch_sz, 3))],\n                   [np.random.random((batch_sz, 4)), np.random.random((batch_sz, 3))])\n\n    out = model.fit_generator(gen_data(4), steps_per_epoch=3, epochs=5,\n                              initial_epoch=2, callbacks=[tracker_cb])\n    assert trained_epochs == [2, 3, 4]\n\n    # test with a custom metric function\n    def mse(y_true, y_pred):\n        return K.mean(K.pow(y_true - y_pred, 2))\n\n    model.compile(optimizer, loss, metrics=[mse],\n                  sample_weight_mode=None)\n\n    out = model.train_on_batch([input_a_np, input_b_np],\n                               [output_a_np, output_b_np])\n    out_len = 1 + 2 * (1 + 1)  # total loss + 2 outputs * (loss + metric)\n    assert len(out) == out_len\n    out = model.test_on_batch([input_a_np, input_b_np],\n                              [output_a_np, output_b_np])\n    assert len(out) == out_len\n\n    input_a_np = np.random.random((10, 3))\n    input_b_np = np.random.random((10, 3))\n\n    output_a_np = np.random.random((10, 4))\n    output_b_np = np.random.random((10, 3))\n\n    out = model.fit([input_a_np, input_b_np], [output_a_np, output_b_np], batch_size=4, epochs=1)\n    out = model.evaluate([input_a_np, input_b_np], [output_a_np, output_b_np], batch_size=4)\n    out = model.predict([input_a_np, input_b_np], batch_size=4)\n\n    # empty batch\n    with pytest.raises(ValueError):\n        def gen_data():\n            while True:\n                yield (np.asarray([]), np.asarray([]))\n        out = model.evaluate_generator(gen_data(), steps=1)\n\n    # x is not a list of numpy arrays.\n    with pytest.raises(ValueError):\n        out = model.predict([None])\n\n    # x does not match _feed_input_names.\n    with pytest.raises(ValueError):\n        out = model.predict([input_a_np, None, input_b_np])\n    with pytest.raises(ValueError):\n        out = model.predict([None, input_a_np, input_b_np])\n\n    # all input/output/weight arrays should have the same number of samples.\n    with pytest.raises(ValueError):\n        out = model.train_on_batch([input_a_np, input_b_np[:2]],\n                                   [output_a_np, output_b_np],\n                                   sample_weight=sample_weight)\n    with pytest.raises(ValueError):\n        out = model.train_on_batch([input_a_np, input_b_np],\n                                   [output_a_np, output_b_np[:2]],\n                                   sample_weight=sample_weight)\n    with pytest.raises(ValueError):\n        out = model.train_on_batch([input_a_np, input_b_np],\n                                   [output_a_np, output_b_np],\n                                   sample_weight=[sample_weight[1], sample_weight[1][:2]])\n\n    # `sample_weight` is neither a dict nor a list.\n    with pytest.raises(TypeError):\n        out = model.train_on_batch([input_a_np, input_b_np],\n                                   [output_a_np, output_b_np],\n                                   sample_weight=tuple(sample_weight))\n\n    # `validation_data` is neither a tuple nor a triple.\n    with pytest.raises(ValueError):\n        out = model.fit([input_a_np, input_b_np],\n                        [output_a_np, output_b_np],\n                        epochs=1, batch_size=4,\n                        validation_data=([input_a_np, input_b_np],))\n\n    # `loss` does not match outputs.\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss=['mse', 'mae', 'mape'])\n\n    # `loss_weights` does not match output_names.\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss='mse', loss_weights={'lstm': 0.5})\n\n    # `loss_weights` does not match outputs.\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss='mse', loss_weights=[0.5])\n\n    # `loss_weights` is invalid type.\n    with pytest.raises(TypeError):\n        model.compile(optimizer, loss='mse', loss_weights=(0.5, 0.5))\n\n    # `sample_weight_mode` does not match output_names.\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss='mse', sample_weight_mode={'lstm': 'temporal'})\n\n    # `sample_weight_mode` does not match output_names.\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss='mse', sample_weight_mode=['temporal'])\n\n    # `sample_weight_mode` matches output_names partially.\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss='mse', sample_weight_mode={'dense_1': 'temporal'})\n\n    # `loss` does not exist.\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss=[])\n\n    model.compile(optimizer, loss=['mse', 'mae'])\n    model.compile(optimizer, loss='mse', loss_weights={'dense_1': 0.2, 'dropout': 0.8})\n    model.compile(optimizer, loss='mse', loss_weights=[0.2, 0.8])\n\n    # the rank of weight arrays should be 1.\n    with pytest.raises(ValueError):\n        out = model.train_on_batch([input_a_np, input_b_np],\n                                   [output_a_np, output_b_np],\n                                   sample_weight=[None, np.random.random((10, 20, 30))])\n\n    model.compile(optimizer, loss='mse', sample_weight_mode={'dense_1': None, 'dropout': 'temporal'})\n    model.compile(optimizer, loss='mse', sample_weight_mode=[None, 'temporal'])\n\n    # the rank of output arrays should be at least 3D.\n    with pytest.raises(ValueError):\n        out = model.train_on_batch([input_a_np, input_b_np],\n                                   [output_a_np, output_b_np],\n                                   sample_weight=sample_weight)\n\n    model.compile(optimizer, loss, metrics=[], loss_weights=loss_weights,\n                  sample_weight_mode=None)\n    trained_epochs = []\n    trained_batches = []\n    out = model.fit_generator(generator=RandomSequence(3), steps_per_epoch=3, epochs=5,\n                              initial_epoch=0, validation_data=RandomSequence(4),\n                              validation_steps=3, callbacks=[tracker_cb])\n    assert trained_epochs == [0, 1, 2, 3, 4]\n    assert trained_batches == list(range(3)) * 5\n\n    # steps_per_epoch will be equal to len of sequence if it's unspecified\n    trained_epochs = []\n    trained_batches = []\n    out = model.fit_generator(generator=RandomSequence(3), epochs=5,\n                              initial_epoch=0, validation_data=RandomSequence(4),\n                              callbacks=[tracker_cb])\n    assert trained_epochs == [0, 1, 2, 3, 4]\n    assert trained_batches == list(range(12)) * 5\n\n    # fit_generator will throw an exception if steps is unspecified for regular generator\n    with pytest.raises(ValueError):\n        def gen_data():\n            while True:\n                yield (np.asarray([]), np.asarray([]))\n        out = model.fit_generator(generator=gen_data(), epochs=5,\n                                  initial_epoch=0, validation_data=gen_data(),\n                                  callbacks=[tracker_cb])",
        "begin_line": 95,
        "end_line": 411,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.on_epoch_begin#239",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.on_epoch_begin(epoch, logs)",
        "snippet": "    def on_epoch_begin(epoch, logs):\n        trained_epochs.append(epoch)",
        "begin_line": 239,
        "end_line": 240,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.on_batch_begin#242",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.on_batch_begin(batch, logs)",
        "snippet": "    def on_batch_begin(batch, logs):\n        trained_batches.append(batch)",
        "begin_line": 242,
        "end_line": 243,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.gen_data#256",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.gen_data(batch_sz)",
        "snippet": "    def gen_data(batch_sz):\n        while True:\n            yield ([np.random.random((batch_sz, 3)), np.random.random((batch_sz, 3))],\n                   [np.random.random((batch_sz, 4)), np.random.random((batch_sz, 3))])",
        "begin_line": 256,
        "end_line": 259,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.mse#266",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.mse(y_true, y_pred)",
        "snippet": "    def mse(y_true, y_pred):\n        return K.mean(K.pow(y_true - y_pred, 2))",
        "begin_line": 266,
        "end_line": 267,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.gen_data#292",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.gen_data()",
        "snippet": "        def gen_data():\n            while True:\n                yield (np.asarray([]), np.asarray([]))",
        "begin_line": 292,
        "end_line": 294,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.gen_data#406",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.gen_data()",
        "snippet": "        def gen_data():\n            while True:\n                yield (np.asarray([]), np.asarray([]))",
        "begin_line": 406,
        "end_line": 408,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_warnings#416",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_warnings()",
        "snippet": "def test_warnings():\n    a = Input(shape=(3,), name='input_a')\n    b = Input(shape=(3,), name='input_b')\n\n    a_2 = Dense(4, name='dense_1')(a)\n    dp = Dropout(0.5, name='dropout')\n    b_2 = dp(b)\n\n    model = Model([a, b], [a_2, b_2])\n\n    optimizer = 'rmsprop'\n    loss = 'mse'\n    loss_weights = [1., 0.5]\n    model.compile(optimizer, loss, metrics=[], loss_weights=loss_weights,\n                  sample_weight_mode=None)\n\n    def gen_data(batch_sz):\n        while True:\n            yield ([np.random.random((batch_sz, 3)), np.random.random((batch_sz, 3))],\n                   [np.random.random((batch_sz, 4)), np.random.random((batch_sz, 3))])\n\n    with pytest.warns(Warning) as w:\n        out = model.fit_generator(gen_data(4), steps_per_epoch=10, use_multiprocessing=True, workers=2)\n    warning_raised = any(['Sequence' in str(w_.message) for w_ in w])\n    assert warning_raised, 'No warning raised when using generator with processes.'\n\n    with pytest.warns(None) as w:\n        out = model.fit_generator(RandomSequence(3), steps_per_epoch=4, use_multiprocessing=True, workers=2)\n    assert all(['Sequence' not in str(w_.message) for w_ in w]), 'A warning was raised for Sequence.'",
        "begin_line": 416,
        "end_line": 444,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.gen_data#432",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.gen_data(batch_sz)",
        "snippet": "    def gen_data(batch_sz):\n        while True:\n            yield ([np.random.random((batch_sz, 3)), np.random.random((batch_sz, 3))],\n                   [np.random.random((batch_sz, 4)), np.random.random((batch_sz, 3))])",
        "begin_line": 432,
        "end_line": 435,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_sparse_input_validation_split#449",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_sparse_input_validation_split()",
        "snippet": "def test_sparse_input_validation_split():\n    test_input = sparse.random(6, 3, density=0.25).tocsr()\n    in1 = Input(shape=(3,), sparse=True)\n    out1 = Dense(4)(in1)\n    test_output = np.random.random((6, 4))\n    model = Model(in1, out1)\n    model.compile('rmsprop', 'mse')\n    model.fit(test_input, test_output, epochs=1, batch_size=2, validation_split=0.2)",
        "begin_line": 449,
        "end_line": 456,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_trainable_argument#460",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_trainable_argument()",
        "snippet": "def test_trainable_argument():\n    x = np.random.random((5, 3))\n    y = np.random.random((5, 2))\n\n    model = Sequential()\n    model.add(Dense(2, input_dim=3, trainable=False))\n    model.compile('rmsprop', 'mse')\n    out = model.predict(x)\n    model.train_on_batch(x, y)\n    out_2 = model.predict(x)\n    assert_allclose(out, out_2)\n\n    # test with nesting\n    inputs = Input(shape=(3,))\n    outputs = model(inputs)\n    model = Model(inputs, outputs)\n    model.compile('rmsprop', 'mse')\n    out = model.predict(x)\n    model.train_on_batch(x, y)\n    out_2 = model.predict(x)\n    assert_allclose(out, out_2)",
        "begin_line": 460,
        "end_line": 480,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_check_not_failing#484",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_check_not_failing()",
        "snippet": "def test_check_not_failing():\n    a = np.random.random((2, 1, 3))\n    _check_loss_and_target_compatibility([a], [losses.categorical_crossentropy], [a.shape])\n    _check_loss_and_target_compatibility([a], [losses.categorical_crossentropy], [(2, None, 3)])",
        "begin_line": 484,
        "end_line": 487,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_check_last_is_one#491",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_check_last_is_one()",
        "snippet": "def test_check_last_is_one():\n    a = np.random.random((2, 3, 1))\n    with pytest.raises(ValueError) as exc:\n        _check_loss_and_target_compatibility([a], [losses.categorical_crossentropy], [a.shape])\n\n    assert 'You are passing a target array' in str(exc)",
        "begin_line": 491,
        "end_line": 496,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_check_bad_shape#500",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_check_bad_shape()",
        "snippet": "def test_check_bad_shape():\n    a = np.random.random((2, 3, 5))\n    with pytest.raises(ValueError) as exc:\n        _check_loss_and_target_compatibility([a], [losses.categorical_crossentropy], [(2, 3, 6)])\n\n    assert 'targets to have the same shape' in str(exc)",
        "begin_line": 500,
        "end_line": 505,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_model_with_input_feed_tensor#510",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_model_with_input_feed_tensor()",
        "snippet": "def test_model_with_input_feed_tensor():\n    \"\"\"We test building a model with a TF variable as input.\n    We should be able to call fit, evaluate, predict,\n    by only passing them data for the placeholder inputs\n    in the model.\n    \"\"\"\n    import tensorflow as tf\n\n    input_a_np = np.random.random((10, 3))\n    input_b_np = np.random.random((10, 3))\n\n    output_a_np = np.random.random((10, 4))\n    output_b_np = np.random.random((10, 3))\n\n    a = Input(tensor=tf.Variable(input_a_np, dtype=tf.float32))\n    b = Input(shape=(3,), name='input_b')\n\n    a_2 = Dense(4, name='dense_1')(a)\n    dp = Dropout(0.5, name='dropout')\n    b_2 = dp(b)\n\n    model = Model([a, b], [a_2, b_2])\n    model.summary()\n\n    optimizer = 'rmsprop'\n    loss = 'mse'\n    loss_weights = [1., 0.5]\n    model.compile(optimizer, loss, metrics=['mean_squared_error'],\n                  loss_weights=loss_weights,\n                  sample_weight_mode=None)\n\n    # test train_on_batch\n    out = model.train_on_batch(input_b_np,\n                               [output_a_np, output_b_np])\n    out = model.train_on_batch({'input_b': input_b_np},\n                               [output_a_np, output_b_np])\n    out = model.test_on_batch({'input_b': input_b_np},\n                              [output_a_np, output_b_np])\n    out = model.predict_on_batch({'input_b': input_b_np})\n\n    # test fit\n    out = model.fit({'input_b': input_b_np},\n                    [output_a_np, output_b_np], epochs=1, batch_size=10)\n    out = model.fit(input_b_np,\n                    [output_a_np, output_b_np], epochs=1, batch_size=10)\n\n    # test evaluate\n    out = model.evaluate({'input_b': input_b_np},\n                         [output_a_np, output_b_np], batch_size=10)\n    out = model.evaluate(input_b_np,\n                         [output_a_np, output_b_np], batch_size=10)\n\n    # test predict\n    out = model.predict({'input_b': input_b_np}, batch_size=10)\n    out = model.predict(input_b_np, batch_size=10)\n    assert len(out) == 2\n\n    # Now test a model with a single input\n    # i.e. we don't pass any data to fit the model.\n    a = Input(tensor=tf.Variable(input_a_np, dtype=tf.float32))\n    a_2 = Dense(4, name='dense_1')(a)\n    a_2 = Dropout(0.5, name='dropout')(a_2)\n    model = Model(a, a_2)\n    model.summary()\n\n    optimizer = 'rmsprop'\n    loss = 'mse'\n    model.compile(optimizer, loss, metrics=['mean_squared_error'])\n\n    # test train_on_batch\n    out = model.train_on_batch(None,\n                               output_a_np)\n    out = model.train_on_batch(None,\n                               output_a_np)\n    out = model.test_on_batch(None,\n                              output_a_np)\n    out = model.predict_on_batch(None)\n    out = model.train_on_batch([],\n                               output_a_np)\n    out = model.train_on_batch({},\n                               output_a_np)\n\n    # test fit\n    out = model.fit(None,\n                    output_a_np, epochs=1, batch_size=10)\n    out = model.fit(None,\n                    output_a_np, epochs=1, batch_size=10)\n\n    # test evaluate\n    out = model.evaluate(None,\n                         output_a_np, batch_size=10)\n    out = model.evaluate(None,\n                         output_a_np, batch_size=10)\n\n    # test predict\n    out = model.predict(None, steps=3)\n    out = model.predict(None, steps=3)\n    assert out.shape == (10 * 3, 4)\n\n    # Same, without learning phase\n    # i.e. we don't pass any data to fit the model.\n    a = Input(tensor=tf.Variable(input_a_np, dtype=tf.float32))\n    a_2 = Dense(4, name='dense_1')(a)\n    model = Model(a, a_2)\n    model.summary()\n\n    optimizer = 'rmsprop'\n    loss = 'mse'\n    model.compile(optimizer, loss, metrics=['mean_squared_error'])\n\n    # test train_on_batch\n    out = model.train_on_batch(None,\n                               output_a_np)\n    out = model.train_on_batch(None,\n                               output_a_np)\n    out = model.test_on_batch(None,\n                              output_a_np)\n    out = model.predict_on_batch(None)\n    out = model.train_on_batch([],\n                               output_a_np)\n    out = model.train_on_batch({},\n                               output_a_np)\n\n    # test fit\n    out = model.fit(None,\n                    output_a_np, epochs=1, batch_size=10)\n    out = model.fit(None,\n                    output_a_np, epochs=1, batch_size=10)\n\n    # test evaluate\n    out = model.evaluate(None,\n                         output_a_np, batch_size=10)\n    out = model.evaluate(None,\n                         output_a_np, batch_size=10)\n\n    # test predict\n    out = model.predict(None, steps=3)\n    out = model.predict(None, steps=3)\n    assert out.shape == (10 * 3, 4)",
        "begin_line": 510,
        "end_line": 648,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_model_with_partial_loss#652",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_model_with_partial_loss()",
        "snippet": "def test_model_with_partial_loss():\n    a = Input(shape=(3,), name='input_a')\n    a_2 = Dense(4, name='dense_1')(a)\n    dp = Dropout(0.5, name='dropout')\n    a_3 = dp(a_2)\n    model = Model(a, [a_2, a_3])\n\n    optimizer = 'rmsprop'\n    loss = {'dropout': 'mse'}\n    model.compile(optimizer, loss, metrics=['mae'])\n\n    input_a_np = np.random.random((10, 3))\n    output_a_np = np.random.random((10, 4))\n\n    # test train_on_batch\n    out = model.train_on_batch(input_a_np, output_a_np)\n    out = model.test_on_batch(input_a_np, output_a_np)\n    # fit\n    out = model.fit(input_a_np, [output_a_np])\n    # evaluate\n    out = model.evaluate(input_a_np, [output_a_np])\n\n    # Same without dropout.\n    a = Input(shape=(3,), name='input_a')\n    a_2 = Dense(4, name='dense_1')(a)\n    a_3 = Dense(4, name='dense_2')(a_2)\n    model = Model(a, [a_2, a_3])\n\n    optimizer = 'rmsprop'\n    loss = {'dense_2': 'mse'}\n    model.compile(optimizer, loss, metrics={'dense_1': 'mae'})\n\n    # test train_on_batch\n    out = model.train_on_batch(input_a_np, output_a_np)\n    out = model.test_on_batch(input_a_np, output_a_np)\n    # fit\n    out = model.fit(input_a_np, [output_a_np])\n    # evaluate\n    out = model.evaluate(input_a_np, [output_a_np])",
        "begin_line": 652,
        "end_line": 690,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_model_with_external_loss#696",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_model_with_external_loss()",
        "snippet": "def test_model_with_external_loss():\n    # None loss, only regularization loss.\n    a = Input(shape=(3,), name='input_a')\n    a_2 = Dense(4, name='dense_1',\n                kernel_regularizer='l1',\n                bias_regularizer='l2')(a)\n    dp = Dropout(0.5, name='dropout')\n    a_3 = dp(a_2)\n\n    model = Model(a, [a_2, a_3])\n\n    optimizer = 'rmsprop'\n    loss = None\n    model.compile(optimizer, loss, metrics=['mae'])\n\n    input_a_np = np.random.random((10, 3))\n\n    # test train_on_batch\n    out = model.train_on_batch(input_a_np, None)\n    out = model.test_on_batch(input_a_np, None)\n    # fit\n    out = model.fit(input_a_np, None)\n    # evaluate\n    out = model.evaluate(input_a_np, None)\n\n    # No dropout, external loss.\n    a = Input(shape=(3,), name='input_a')\n    a_2 = Dense(4, name='dense_1')(a)\n    a_3 = Dense(4, name='dense_2')(a)\n\n    model = Model(a, [a_2, a_3])\n    model.add_loss(K.mean(a_3 + a_2))\n\n    optimizer = 'rmsprop'\n    loss = None\n    model.compile(optimizer, loss, metrics=['mae'])\n\n    # test train_on_batch\n    out = model.train_on_batch(input_a_np, None)\n    out = model.test_on_batch(input_a_np, None)\n    # fit\n    out = model.fit(input_a_np, None)\n    # evaluate\n    out = model.evaluate(input_a_np, None)\n\n    # Test fit with no external data at all.\n    if K.backend() == 'tensorflow':\n        import tensorflow as tf\n\n        a = Input(tensor=tf.Variable(input_a_np, dtype=tf.float32))\n        a_2 = Dense(4, name='dense_1')(a)\n        a_2 = Dropout(0.5, name='dropout')(a_2)\n        model = Model(a, a_2)\n        model.add_loss(K.mean(a_2))\n\n        model.compile(optimizer='rmsprop',\n                      loss=None,\n                      metrics=['mean_squared_error'])\n\n        # test train_on_batch\n        out = model.train_on_batch(None, None)\n        out = model.test_on_batch(None, None)\n        out = model.predict_on_batch(None)\n\n        # test fit\n        with pytest.raises(ValueError):\n            out = model.fit(None, None, epochs=1, batch_size=10)\n        out = model.fit(None, None, epochs=1, steps_per_epoch=1)\n\n        # test fit with validation data\n        with pytest.raises(ValueError):\n            out = model.fit(None, None,\n                            epochs=1,\n                            steps_per_epoch=None,\n                            validation_steps=2)\n        out = model.fit(None, None,\n                        epochs=1,\n                        steps_per_epoch=2,\n                        validation_steps=2)\n\n        # test evaluate\n        with pytest.raises(ValueError):\n            out = model.evaluate(None, None, batch_size=10)\n        out = model.evaluate(None, None, steps=3)\n\n        # test predict\n        with pytest.raises(ValueError):\n            out = model.predict(None, batch_size=10)\n        out = model.predict(None, steps=3)\n        assert out.shape == (10 * 3, 4)\n\n        # Test multi-output model without external data.\n        a = Input(tensor=tf.Variable(input_a_np, dtype=tf.float32))\n        a_1 = Dense(4, name='dense_1')(a)\n        a_2 = Dropout(0.5, name='dropout')(a_1)\n        model = Model(a, [a_1, a_2])\n        model.add_loss(K.mean(a_2))\n        model.compile(optimizer='rmsprop',\n                      loss=None,\n                      metrics=['mean_squared_error'])\n\n        # test train_on_batch\n        out = model.train_on_batch(None, None)\n        out = model.test_on_batch(None, None)\n        out = model.predict_on_batch(None)\n\n        # test fit\n        with pytest.raises(ValueError):\n            out = model.fit(None, None, epochs=1, batch_size=10)\n        out = model.fit(None, None, epochs=1, steps_per_epoch=1)\n\n        # test fit with validation data\n        with pytest.raises(ValueError):\n            out = model.fit(None, None,\n                            epochs=1,\n                            steps_per_epoch=None,\n                            validation_steps=2)\n        out = model.fit(None, None,\n                        epochs=1,\n                        steps_per_epoch=2,\n                        validation_steps=2)\n\n        # test evaluate\n        with pytest.raises(ValueError):\n            out = model.evaluate(None, None, batch_size=10)\n        out = model.evaluate(None, None, steps=3)\n\n        # test predict\n        with pytest.raises(ValueError):\n            out = model.predict(None, batch_size=10)\n        out = model.predict(None, steps=3)\n        assert len(out) == 2\n        assert out[0].shape == (10 * 3, 4)\n        assert out[1].shape == (10 * 3, 4)",
        "begin_line": 696,
        "end_line": 829,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_target_tensors#833",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_target_tensors()",
        "snippet": "def test_target_tensors():\n    # single-output, as list\n    model = keras.models.Sequential()\n    model.add(keras.layers.Dense(4, input_shape=(4,), name='dense'))\n    input_val = np.random.random((10, 4))\n    target_val = np.random.random((10, 4))\n    target = keras.backend.variable(target_val)\n    model.compile(optimizer='rmsprop', loss='mse', target_tensors=[target])\n    model.train_on_batch(input_val, None)\n\n    # single-output, as dict\n    model.compile(optimizer='rmsprop', loss='mse',\n                  target_tensors={'dense': target})\n    model.train_on_batch(input_val, None)\n\n    # test invalid arguments\n    with pytest.raises(TypeError):\n        model.compile(optimizer='rmsprop', loss='mse',\n                      target_tensors=set())\n    with pytest.raises(ValueError):\n        model.compile(optimizer='rmsprop', loss='mse',\n                      target_tensors=[target, target])\n    with pytest.raises(ValueError):\n        model.compile(optimizer='rmsprop', loss='mse',\n                      target_tensors={'dense2': None})\n    with pytest.raises(ValueError):\n        model.compile(optimizer='rmsprop', loss='mse',\n                      target_tensors=[target])\n        model.train_on_batch(input_val, target_val)\n\n    # multi-output, as list\n    input_val = np.random.random((10, 4))\n    target_val_a = np.random.random((10, 4))\n    target_val_b = np.random.random((10, 4))\n    target_a = keras.backend.variable(target_val_a)\n    target_b = keras.backend.variable(target_val_b)\n\n    inputs = keras.layers.Input(shape=(4,))\n    output_a = keras.layers.Dense(4, name='dense_a')(inputs)\n    output_b = keras.layers.Dense(4, name='dense_b')(inputs)\n    model = keras.models.Model(inputs, [output_a, output_b])\n    model.compile(optimizer='rmsprop', loss='mse',\n                  target_tensors=[target_a, target_b])\n    model.train_on_batch(input_val, None)\n\n    # multi-output, as dict\n    model.compile(optimizer='rmsprop', loss='mse',\n                  target_tensors={'dense_a': target_a,\n                                  'dense_b': target_b})\n    model.train_on_batch(input_val, None)\n\n    # test with sample weights\n    model.compile(optimizer='rmsprop', loss='mse',\n                  target_tensors=[target_a, target_b])\n    model.train_on_batch(input_val, None,\n                         sample_weight={'dense_a': np.random.random((10,))})",
        "begin_line": 833,
        "end_line": 888,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_model_custom_target_tensors#892",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_model_custom_target_tensors()",
        "snippet": "def test_model_custom_target_tensors():\n    a = Input(shape=(3,), name='input_a')\n    b = Input(shape=(3,), name='input_b')\n\n    a_2 = Dense(4, name='dense_1')(a)\n    dp = Dropout(0.5, name='dropout')\n    b_2 = dp(b)\n\n    y = K.placeholder([10, 4], name='y')\n    y1 = K.placeholder([10, 3], name='y1')\n    y2 = K.placeholder([7, 5], name='y2')\n    model = Model([a, b], [a_2, b_2])\n\n    optimizer = 'rmsprop'\n    loss = 'mse'\n    loss_weights = [1., 0.5]\n\n    # test list of target tensors\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss, metrics=[], loss_weights=loss_weights,\n                      sample_weight_mode=None, target_tensors=[y, y1, y2])\n    model.compile(optimizer, loss, metrics=[], loss_weights=loss_weights,\n                  sample_weight_mode=None, target_tensors=[y, y1])\n    input_a_np = np.random.random((10, 3))\n    input_b_np = np.random.random((10, 3))\n\n    output_a_np = np.random.random((10, 4))\n    output_b_np = np.random.random((10, 3))\n\n    out = model.train_on_batch([input_a_np, input_b_np],\n                               [output_a_np, output_b_np],\n                               {y: np.random.random((10, 4)),\n                                y1: np.random.random((10, 3))})\n    # test dictionary of target_tensors\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss,\n                      metrics=[],\n                      loss_weights=loss_weights,\n                      sample_weight_mode=None,\n                      target_tensors={'does_not_exist': y2})\n    # test dictionary of target_tensors\n    model.compile(optimizer, loss,\n                  metrics=[],\n                  loss_weights=loss_weights,\n                  sample_weight_mode=None,\n                  target_tensors={'dense_1': y, 'dropout': y1})\n    out = model.train_on_batch([input_a_np, input_b_np],\n                               [output_a_np, output_b_np],\n                               {y: np.random.random((10, 4)),\n                                y1: np.random.random((10, 3))})\n\n    if K.backend() == 'tensorflow':\n        import tensorflow as tf\n        # test with custom TF placeholder as target\n        pl_target_a = tf.placeholder('float32', shape=(None, 4))\n        model.compile(optimizer='rmsprop', loss='mse',\n                      target_tensors={'dense_1': pl_target_a})\n        model.train_on_batch([input_a_np, input_b_np],\n                             [output_a_np, output_b_np])",
        "begin_line": 892,
        "end_line": 950,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_trainable_weights_count_consistency#955",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_trainable_weights_count_consistency()",
        "snippet": "def test_trainable_weights_count_consistency():\n    \"\"\"Tests the trainable weights consistency check of Model.\n\n    This verifies that a warning is shown if model.trainable is modified\n    and the model is summarized/run without a new call to .compile()\n\n    Reproduce issue #8121\n    \"\"\"\n    a = Input(shape=(3,), name='input_a')\n    model1 = Model(inputs=a, outputs=Dense(1)(a))\n\n    model1.trainable = False\n    b = Input(shape=(3,), name='input_b')\n    y = model1(b)\n    model2 = Model(inputs=b, outputs=Dense(1)(y))\n\n    model2.compile(optimizer='adam', loss='mse')\n\n    model1.trainable = True\n\n    # Should warn on .summary()\n    with pytest.warns(UserWarning) as w:\n        model2.summary()\n    warning_raised = any(['Discrepancy' in str(w_.message) for w_ in w])\n    assert warning_raised, 'No warning raised when trainable is modified without .compile.'\n\n    # And on .fit()\n    with pytest.warns(UserWarning) as w:\n        model2.fit(x=np.zeros((5, 3)), y=np.zeros((5, 1)))\n    warning_raised = any(['Discrepancy' in str(w_.message) for w_ in w])\n    assert warning_raised, 'No warning raised when trainable is modified without .compile.'\n\n    # And shouldn't warn if we recompile\n    model2.compile(optimizer='adam', loss='mse')\n    with pytest.warns(None) as w:\n        model2.summary()\n    assert len(w) == 0, \"Warning raised even when .compile() is called after modifying .trainable\"",
        "begin_line": 955,
        "end_line": 991,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_pandas_dataframe#995",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_pandas_dataframe()",
        "snippet": "def test_pandas_dataframe():\n    input_a = Input(shape=(3,), name='input_a')\n    input_b = Input(shape=(3,), name='input_b')\n\n    x = Dense(4, name='dense_1')(input_a)\n    y = Dense(3, name='desne_2')(input_b)\n\n    model_1 = Model(inputs=input_a, outputs=x)\n    model_2 = Model(inputs=[input_a, input_b], outputs=[x, y])\n\n    optimizer = 'rmsprop'\n    loss = 'mse'\n\n    model_1.compile(optimizer=optimizer, loss=loss)\n    model_2.compile(optimizer=optimizer, loss=loss)\n\n    input_a_df = pd.DataFrame(np.random.random((10, 3)))\n    input_b_df = pd.DataFrame(np.random.random((10, 3)))\n\n    output_a_df = pd.DataFrame(np.random.random((10, 4)))\n    output_b_df = pd.DataFrame(np.random.random((10, 3)))\n\n    model_1.fit(input_a_df,\n                output_a_df)\n    model_2.fit([input_a_df, input_b_df],\n                [output_a_df, output_b_df])\n    model_1.fit([input_a_df],\n                [output_a_df])\n    model_1.fit({'input_a': input_a_df},\n                output_a_df)\n    model_2.fit({'input_a': input_a_df, 'input_b': input_b_df},\n                [output_a_df, output_b_df])\n\n    model_1.predict(input_a_df)\n    model_2.predict([input_a_df, input_b_df])\n    model_1.predict([input_a_df])\n    model_1.predict({'input_a': input_a_df})\n    model_2.predict({'input_a': input_a_df, 'input_b': input_b_df})\n\n    model_1.predict_on_batch(input_a_df)\n    model_2.predict_on_batch([input_a_df, input_b_df])\n    model_1.predict_on_batch([input_a_df])\n    model_1.predict_on_batch({'input_a': input_a_df})\n    model_2.predict_on_batch({'input_a': input_a_df, 'input_b': input_b_df})\n\n    model_1.evaluate(input_a_df,\n                     output_a_df)\n    model_2.evaluate([input_a_df, input_b_df],\n                     [output_a_df, output_b_df])\n    model_1.evaluate([input_a_df],\n                     [output_a_df])\n    model_1.evaluate({'input_a': input_a_df},\n                     output_a_df)\n    model_2.evaluate({'input_a': input_a_df, 'input_b': input_b_df},\n                     [output_a_df, output_b_df])\n\n    model_1.train_on_batch(input_a_df,\n                           output_a_df)\n    model_2.train_on_batch([input_a_df, input_b_df],\n                           [output_a_df, output_b_df])\n    model_1.train_on_batch([input_a_df],\n                           [output_a_df])\n    model_1.train_on_batch({'input_a': input_a_df},\n                           output_a_df)\n    model_2.train_on_batch({'input_a': input_a_df, 'input_b': input_b_df},\n                           [output_a_df, output_b_df])\n\n    model_1.test_on_batch(input_a_df,\n                          output_a_df)\n    model_2.test_on_batch([input_a_df, input_b_df],\n                          [output_a_df, output_b_df])\n    model_1.test_on_batch([input_a_df],\n                          [output_a_df])\n    model_1.test_on_batch({'input_a': input_a_df},\n                          output_a_df)\n    model_2.test_on_batch({'input_a': input_a_df, 'input_b': input_b_df},\n                          [output_a_df, output_b_df])",
        "begin_line": 995,
        "end_line": 1071,
        "comment": "",
        "is_bug": false
    }
]