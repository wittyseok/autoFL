[
    {
        "name": "tests.keras.legacy.conftest.clear_session_after_test#6",
        "src_path": "tests/keras/legacy/conftest.py",
        "class_name": "tests.keras.legacy.conftest",
        "signature": "tests.keras.legacy.conftest.clear_session_after_test()",
        "snippet": "def clear_session_after_test():\n    \"\"\"This wrapper runs for all the tests in the legacy directory (recursively).\n    \"\"\"\n    with warnings.catch_warnings():\n        warnings.filterwarnings('ignore', message=r'(.+) Keras 2 ',\n                                category=UserWarning)\n        yield",
        "begin_line": 6,
        "end_line": 12,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.RandomSequence.__init__#26",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training.RandomSequence",
        "signature": "tests.keras.engine.test_training.RandomSequence.__init__(self, batch_size, sequence_length=12)",
        "snippet": "    def __init__(self, batch_size, sequence_length=12):\n        self.batch_size = batch_size\n        self.sequence_length = sequence_length\n        self.logs = []  # It will work for use_multiprocessing=False",
        "begin_line": 26,
        "end_line": 29,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.RandomSequence.__len__#31",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training.RandomSequence",
        "signature": "tests.keras.engine.test_training.RandomSequence.__len__(self)",
        "snippet": "    def __len__(self):\n        return self.sequence_length",
        "begin_line": 31,
        "end_line": 32,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.RandomSequence.__getitem__#34",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training.RandomSequence",
        "signature": "tests.keras.engine.test_training.RandomSequence.__getitem__(self, idx)",
        "snippet": "    def __getitem__(self, idx):\n        self.logs.append(idx)\n        return ([np.random.random((self.batch_size, 3)),\n                 np.random.random((self.batch_size, 3))],\n                [np.random.random((self.batch_size, 4)),\n                 np.random.random((self.batch_size, 3))])",
        "begin_line": 34,
        "end_line": 39,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.RandomSequence.on_epoch_end#41",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training.RandomSequence",
        "signature": "tests.keras.engine.test_training.RandomSequence.on_epoch_end(self)",
        "snippet": "    def on_epoch_end(self):\n        pass",
        "begin_line": 41,
        "end_line": 42,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.threadsafe_iter.__init__#50",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training.threadsafe_iter",
        "signature": "tests.keras.engine.test_training.threadsafe_iter.__init__(self, it)",
        "snippet": "    def __init__(self, it):\n        self.it = it\n        self.lock = threading.Lock()",
        "begin_line": 50,
        "end_line": 52,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.threadsafe_iter.__iter__#54",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training.threadsafe_iter",
        "signature": "tests.keras.engine.test_training.threadsafe_iter.__iter__(self)",
        "snippet": "    def __iter__(self):\n        return self",
        "begin_line": 54,
        "end_line": 55,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.threadsafe_iter.__next__#57",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training.threadsafe_iter",
        "signature": "tests.keras.engine.test_training.threadsafe_iter.__next__(self)",
        "snippet": "    def __next__(self):\n        return self.next()",
        "begin_line": 57,
        "end_line": 58,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.threadsafe_iter.next#60",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training.threadsafe_iter",
        "signature": "tests.keras.engine.test_training.threadsafe_iter.next(self)",
        "snippet": "    def next(self):\n        with self.lock:\n            return next(self.it)",
        "begin_line": 60,
        "end_line": 62,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.threadsafe_generator#65",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.threadsafe_generator(f)",
        "snippet": "def threadsafe_generator(f):\n    \"\"\"A decorator that takes a generator function and makes it thread-safe.\n    \"\"\"\n\n    def g(*a, **kw):\n        return threadsafe_iter(f(*a, **kw))\n\n    return g",
        "begin_line": 65,
        "end_line": 72,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.g#69",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.g(*a, **kw)",
        "snippet": "    def g(*a, **kw):\n        return threadsafe_iter(f(*a, **kw))",
        "begin_line": 69,
        "end_line": 70,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_check_array_length_consistency#75",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_check_array_length_consistency()",
        "snippet": "def test_check_array_length_consistency():\n    training_utils.check_array_length_consistency(None, None, None)\n    a_np = np.random.random((4, 3, 3))\n    training_utils.check_array_length_consistency(a_np, a_np, a_np)\n    training_utils.check_array_length_consistency(\n        [a_np, a_np], [a_np, a_np], [a_np, a_np])\n    training_utils.check_array_length_consistency([None], [None], [None])\n\n    b_np = np.random.random((3, 4))\n    with pytest.raises(ValueError):\n        training_utils.check_array_length_consistency(a_np, None, None)\n    with pytest.raises(ValueError):\n        training_utils.check_array_length_consistency(a_np, a_np, None)\n    with pytest.raises(ValueError):\n        training_utils.check_array_length_consistency([a_np], [None], None)\n    with pytest.raises(ValueError):\n        training_utils.check_array_length_consistency([a_np], [b_np], None)\n    with pytest.raises(ValueError):\n        training_utils.check_array_length_consistency([a_np], None, [b_np])",
        "begin_line": 75,
        "end_line": 93,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.testslice_arrays#96",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.testslice_arrays()",
        "snippet": "def testslice_arrays():\n    input_a = np.random.random((10, 3))\n    slice_arrays(None)\n    slice_arrays(input_a, 0)\n    slice_arrays(input_a, 0, 1)\n    slice_arrays(input_a, stop=2)\n    input_a = [None, [1, 1], None, [1, 1]]\n    slice_arrays(input_a, 0)\n    slice_arrays(input_a, 0, 1)\n    slice_arrays(input_a, stop=2)\n    input_a = [None]\n    slice_arrays(input_a, 0)\n    slice_arrays(input_a, 0, 1)\n    slice_arrays(input_a, stop=2)\n    input_a = None\n    slice_arrays(input_a, 0)\n    slice_arrays(input_a, 0, 1)\n    slice_arrays(input_a, stop=2)",
        "begin_line": 96,
        "end_line": 113,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_weighted_masked_objective#116",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_weighted_masked_objective()",
        "snippet": "def test_weighted_masked_objective():\n    a = Input(shape=(3,), name='input_a')\n\n    # weighted_masked_objective\n    def mask_dummy(y_true=None, y_pred=None, weight=None):\n        return K.placeholder(y_true.shape)\n\n    weighted_function = training_utils.weighted_masked_objective(\n        losses.categorical_crossentropy)\n    weighted_function(a, a, None)",
        "begin_line": 116,
        "end_line": 125,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.mask_dummy#120",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.mask_dummy(y_true=None, y_pred=None, weight=None)",
        "snippet": "    def mask_dummy(y_true=None, y_pred=None, weight=None):\n        return K.placeholder(y_true.shape)",
        "begin_line": 120,
        "end_line": 121,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.get_model#128",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.get_model(num_outputs=1)",
        "snippet": "def get_model(num_outputs=1):\n    a = Input(shape=(3,), name='input_a')\n    b = Input(shape=(3,), name='input_b')\n\n    a_2 = Dense(4, name='dense_1')(a)\n    dp = Dropout(0.5, name='dropout')\n    b_2 = dp(b)\n\n    if num_outputs == 1:\n        model = Model([a, b], a_2)\n    else:\n        model = Model([a, b], [a_2, b_2])\n    return model",
        "begin_line": 128,
        "end_line": 140,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.TrackerCallback.__init__#145",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training.TrackerCallback",
        "signature": "tests.keras.engine.test_training.TrackerCallback.__init__(self)",
        "snippet": "    def __init__(self):\n        # test starting from non-zero initial epoch\n        self.trained_epochs = []\n        self.trained_batches = []\n        super(TrackerCallback, self).__init__()",
        "begin_line": 145,
        "end_line": 149,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.TrackerCallback.on_epoch_begin#152",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training.TrackerCallback",
        "signature": "tests.keras.engine.test_training.TrackerCallback.on_epoch_begin(self, epoch, logs)",
        "snippet": "    def on_epoch_begin(self, epoch, logs):\n        self.trained_epochs.append(epoch)",
        "begin_line": 152,
        "end_line": 153,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.TrackerCallback.on_batch_begin#155",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training.TrackerCallback",
        "signature": "tests.keras.engine.test_training.TrackerCallback.on_batch_begin(self, batch, logs)",
        "snippet": "    def on_batch_begin(self, batch, logs):\n        self.trained_batches.append(batch)",
        "begin_line": 155,
        "end_line": 156,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_model_methods#161",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_model_methods()",
        "snippet": "def test_model_methods():\n    model = get_model(num_outputs=2)\n\n    optimizer = 'rmsprop'\n    loss = 'mse'\n    loss_weights = [1., 0.5]\n\n    input_a_np = np.random.random((10, 3))\n    input_b_np = np.random.random((10, 3))\n\n    output_a_np = np.random.random((10, 4))\n    output_b_np = np.random.random((10, 3))\n\n    # training/testing doesn't work before compiling.\n    with pytest.raises(RuntimeError):\n        model.train_on_batch([input_a_np, input_b_np],\n                             [output_a_np, output_b_np])\n\n    model.compile(optimizer, loss, metrics=[], loss_weights=loss_weights,\n                  sample_weight_mode=None)\n\n    # test train_on_batch\n    out = model.train_on_batch([input_a_np, input_b_np],\n                               [output_a_np, output_b_np])\n    out = model.train_on_batch({'input_a': input_a_np, 'input_b': input_b_np},\n                               [output_a_np, output_b_np])\n    out = model.train_on_batch({'input_a': input_a_np, 'input_b': input_b_np},\n                               {'dense_1': output_a_np, 'dropout': output_b_np})\n\n    # test fit\n    out = model.fit([input_a_np, input_b_np],\n                    [output_a_np, output_b_np], epochs=1, batch_size=4)\n    out = model.fit({'input_a': input_a_np, 'input_b': input_b_np},\n                    [output_a_np, output_b_np], epochs=1, batch_size=4)\n    out = model.fit({'input_a': input_a_np, 'input_b': input_b_np},\n                    {'dense_1': output_a_np, 'dropout': output_b_np},\n                    epochs=1, batch_size=4)\n\n    # test validation_split\n    out = model.fit([input_a_np, input_b_np],\n                    [output_a_np, output_b_np],\n                    epochs=1, batch_size=4, validation_split=0.5)\n    out = model.fit({'input_a': input_a_np, 'input_b': input_b_np},\n                    [output_a_np, output_b_np],\n                    epochs=1, batch_size=4, validation_split=0.5)\n\n    # test validation data\n    out = model.fit([input_a_np, input_b_np],\n                    [output_a_np, output_b_np],\n                    epochs=1, batch_size=4,\n                    validation_data=([input_a_np, input_b_np],\n                                     [output_a_np, output_b_np]))\n    out = model.fit({'input_a': input_a_np, 'input_b': input_b_np},\n                    [output_a_np, output_b_np],\n                    epochs=1, batch_size=4, validation_split=0.5,\n                    validation_data=({'input_a': input_a_np,\n                                      'input_b': input_b_np},\n                                     [output_a_np, output_b_np]))\n    out = model.fit({'input_a': input_a_np, 'input_b': input_b_np},\n                    {'dense_1': output_a_np, 'dropout': output_b_np},\n                    epochs=1, batch_size=4, validation_split=0.5,\n                    validation_data=(\n                        {'input_a': input_a_np, 'input_b': input_b_np},\n                        {'dense_1': output_a_np, 'dropout': output_b_np}))\n\n    # test_on_batch\n    out = model.test_on_batch([input_a_np, input_b_np],\n                              [output_a_np, output_b_np])\n    out = model.test_on_batch({'input_a': input_a_np, 'input_b': input_b_np},\n                              [output_a_np, output_b_np])\n    out = model.test_on_batch({'input_a': input_a_np, 'input_b': input_b_np},\n                              {'dense_1': output_a_np, 'dropout': output_b_np})\n\n    # predict_on_batch\n    out = model.predict_on_batch([input_a_np, input_b_np])\n    out = model.predict_on_batch({'input_a': input_a_np,\n                                  'input_b': input_b_np})\n\n    # predict, evaluate\n    input_a_np = np.random.random((10, 3))\n    input_b_np = np.random.random((10, 3))\n\n    output_a_np = np.random.random((10, 4))\n    output_b_np = np.random.random((10, 3))\n\n    out = model.evaluate([input_a_np, input_b_np],\n                         [output_a_np, output_b_np],\n                         batch_size=4)\n    out = model.predict([input_a_np, input_b_np], batch_size=4)\n\n    # with sample_weight\n    input_a_np = np.random.random((10, 3))\n    input_b_np = np.random.random((10, 3))\n\n    output_a_np = np.random.random((10, 4))\n    output_b_np = np.random.random((10, 3))\n\n    sample_weight = [None, np.random.random((10,))]\n    out = model.train_on_batch([input_a_np, input_b_np],\n                               [output_a_np, output_b_np],\n                               sample_weight=sample_weight)\n\n    out = model.test_on_batch([input_a_np, input_b_np],\n                              [output_a_np, output_b_np],\n                              sample_weight=sample_weight)\n\n    # test accuracy metric\n    model.compile(optimizer, loss, metrics=['acc'],\n                  sample_weight_mode=None)\n\n    out = model.train_on_batch([input_a_np, input_b_np],\n                               [output_a_np, output_b_np])\n    assert len(out) == 5\n    out = model.test_on_batch([input_a_np, input_b_np],\n                              [output_a_np, output_b_np])\n    assert len(out) == 5\n\n    # this should also work\n    model.compile(optimizer, loss, metrics={'dense_1': 'acc'},\n                  sample_weight_mode=None)\n\n    out = model.train_on_batch([input_a_np, input_b_np],\n                               [output_a_np, output_b_np])\n    assert len(out) == 4\n    out = model.test_on_batch([input_a_np, input_b_np],\n                              [output_a_np, output_b_np])\n    assert len(out) == 4\n\n    # and this as well\n    model.compile(optimizer, loss, metrics={'dense_1': ['acc']},\n                  sample_weight_mode=None)\n\n    out = model.train_on_batch([input_a_np, input_b_np],\n                               [output_a_np, output_b_np])\n    assert len(out) == 4\n    out = model.test_on_batch([input_a_np, input_b_np],\n                              [output_a_np, output_b_np])\n    assert len(out) == 4\n\n    tracker_cb = TrackerCallback()\n\n    out = model.fit([input_a_np, input_b_np],\n                    [output_a_np, output_b_np], epochs=5, batch_size=4,\n                    initial_epoch=2, callbacks=[tracker_cb])\n    assert tracker_cb.trained_epochs == [2, 3, 4]\n\n    # test starting from non-zero initial epoch for generator too\n    tracker_cb = TrackerCallback()\n\n    @threadsafe_generator\n    def gen_data(batch_sz):\n        while True:\n            yield ([np.random.random((batch_sz, 3)),\n                    np.random.random((batch_sz, 3))],\n                   [np.random.random((batch_sz, 4)),\n                    np.random.random((batch_sz, 3))])\n\n    out = model.fit_generator(gen_data(4), steps_per_epoch=3, epochs=5,\n                              initial_epoch=2, callbacks=[tracker_cb])\n    assert tracker_cb.trained_epochs == [2, 3, 4]\n\n    # test with a custom metric function\n    def mse(y_true, y_pred):\n        return K.mean(K.pow(y_true - y_pred, 2))\n\n    model.compile(optimizer, loss, metrics=[mse],\n                  sample_weight_mode=None)\n\n    out = model.train_on_batch([input_a_np, input_b_np],\n                               [output_a_np, output_b_np])\n    out_len = 1 + 2 * (1 + 1)  # total loss + 2 outputs * (loss + metric)\n    assert len(out) == out_len\n    out = model.test_on_batch([input_a_np, input_b_np],\n                              [output_a_np, output_b_np])\n    assert len(out) == out_len\n\n    input_a_np = np.random.random((10, 3))\n    input_b_np = np.random.random((10, 3))\n\n    output_a_np = np.random.random((10, 4))\n    output_b_np = np.random.random((10, 3))\n\n    out = model.fit([input_a_np, input_b_np],\n                    [output_a_np, output_b_np],\n                    batch_size=4, epochs=1)\n    out = model.evaluate([input_a_np, input_b_np],\n                         [output_a_np, output_b_np],\n                         batch_size=4)\n    out = model.predict([input_a_np, input_b_np], batch_size=4)\n\n    # enable verbose for evaluate_generator\n    out = model.evaluate_generator(gen_data(4), steps=3, verbose=1)\n\n    # empty batch\n    with pytest.raises(ValueError):\n        @threadsafe_generator\n        def gen_data():\n            while True:\n                yield (np.asarray([]), np.asarray([]))\n\n        out = model.evaluate_generator(gen_data(), steps=1)\n\n    # x is not a list of numpy arrays.\n    with pytest.raises(ValueError):\n        out = model.predict([None])\n\n    # x does not match _feed_input_names.\n    with pytest.raises(ValueError):\n        out = model.predict([input_a_np, None, input_b_np])\n    with pytest.raises(ValueError):\n        out = model.predict([None, input_a_np, input_b_np])\n\n    # all input/output/weight arrays should have the same number of samples.\n    with pytest.raises(ValueError):\n        out = model.train_on_batch([input_a_np, input_b_np[:2]],\n                                   [output_a_np, output_b_np],\n                                   sample_weight=sample_weight)\n    with pytest.raises(ValueError):\n        out = model.train_on_batch([input_a_np, input_b_np],\n                                   [output_a_np, output_b_np[:2]],\n                                   sample_weight=sample_weight)\n    with pytest.raises(ValueError):\n        out = model.train_on_batch([input_a_np, input_b_np],\n                                   [output_a_np, output_b_np],\n                                   sample_weight=[sample_weight[1],\n                                                  sample_weight[1][:2]])\n\n    # `sample_weight` is neither a dict nor a list.\n    with pytest.raises(TypeError):\n        out = model.train_on_batch([input_a_np, input_b_np],\n                                   [output_a_np, output_b_np],\n                                   sample_weight=tuple(sample_weight))\n\n    # `validation_data` is neither a tuple nor a triple.\n    with pytest.raises(ValueError):\n        out = model.fit([input_a_np, input_b_np],\n                        [output_a_np, output_b_np],\n                        epochs=1, batch_size=4,\n                        validation_data=([input_a_np, input_b_np],))\n\n    # `loss` does not match outputs.\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss=['mse', 'mae', 'mape'])\n\n    # `loss_weights` does not match output_names.\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss='mse', loss_weights={'lstm': 0.5})\n\n    # `loss_weights` does not match outputs.\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss='mse', loss_weights=[0.5])\n\n    # `loss_weights` is invalid type.\n    with pytest.raises(TypeError):\n        model.compile(optimizer, loss='mse', loss_weights=(0.5, 0.5))\n\n    # `sample_weight_mode` does not match output_names.\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss='mse',\n                      sample_weight_mode={'lstm': 'temporal'})\n\n    # `sample_weight_mode` does not match output_names.\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss='mse', sample_weight_mode=['temporal'])\n\n    # `sample_weight_mode` matches output_names partially.\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss='mse',\n                      sample_weight_mode={'dense_1': 'temporal'})\n\n    # `loss` does not exist.\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss=[])\n\n    model.compile(optimizer, loss=['mse', 'mae'])\n    model.compile(optimizer, loss='mse', loss_weights={'dense_1': 0.2,\n                                                       'dropout': 0.8})\n    model.compile(optimizer, loss='mse', loss_weights=[0.2, 0.8])\n\n    # the rank of weight arrays should be 1.\n    with pytest.raises(ValueError):\n        out = model.train_on_batch(\n            [input_a_np, input_b_np],\n            [output_a_np, output_b_np],\n            sample_weight=[None, np.random.random((10, 20, 30))])\n\n    model.compile(optimizer, loss='mse',\n                  sample_weight_mode={'dense_1': None, 'dropout': 'temporal'})\n    model.compile(optimizer, loss='mse', sample_weight_mode=[None, 'temporal'])\n\n    # the rank of output arrays should be at least 3D.\n    with pytest.raises(ValueError):\n        out = model.train_on_batch([input_a_np, input_b_np],\n                                   [output_a_np, output_b_np],\n                                   sample_weight=sample_weight)",
        "begin_line": 161,
        "end_line": 455,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.gen_data#311",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.gen_data(batch_sz)",
        "snippet": "    def gen_data(batch_sz):\n        while True:\n            yield ([np.random.random((batch_sz, 3)),\n                    np.random.random((batch_sz, 3))],\n                   [np.random.random((batch_sz, 4)),\n                    np.random.random((batch_sz, 3))])",
        "begin_line": 311,
        "end_line": 316,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.mse#323",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.mse(y_true, y_pred)",
        "snippet": "    def mse(y_true, y_pred):\n        return K.mean(K.pow(y_true - y_pred, 2))",
        "begin_line": 323,
        "end_line": 324,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.gen_data#357",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.gen_data()",
        "snippet": "        def gen_data():\n            while True:\n                yield (np.asarray([]), np.asarray([]))",
        "begin_line": 357,
        "end_line": 359,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_fit_generator#460",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_fit_generator()",
        "snippet": "def test_fit_generator():\n    model = get_model(num_outputs=2)\n    optimizer = 'rmsprop'\n    loss = 'mse'\n    loss_weights = [1., 0.5]\n\n    model.compile(optimizer, loss, metrics=[], loss_weights=loss_weights,\n                  sample_weight_mode=None)\n    tracker_cb = TrackerCallback()\n    val_seq = RandomSequence(4)\n    out = model.fit_generator(generator=RandomSequence(3),\n                              steps_per_epoch=3,\n                              epochs=5,\n                              initial_epoch=0,\n                              validation_data=val_seq,\n                              validation_steps=3,\n                              max_queue_size=1,\n                              callbacks=[tracker_cb])\n    assert tracker_cb.trained_epochs == [0, 1, 2, 3, 4]\n    assert tracker_cb.trained_batches == list(range(3)) * 5\n    assert len(val_seq.logs) <= 4 * 5\n\n    # steps_per_epoch will be equal to len of sequence if it's unspecified\n    tracker_cb = TrackerCallback()\n    val_seq = RandomSequence(4)\n    out = model.fit_generator(generator=RandomSequence(3),\n                              epochs=5,\n                              initial_epoch=0,\n                              validation_data=val_seq,\n                              callbacks=[tracker_cb],\n                              max_queue_size=1)\n    assert tracker_cb.trained_epochs == [0, 1, 2, 3, 4]\n    assert tracker_cb.trained_batches == list(range(12)) * 5\n    assert 12 * 5 <= len(val_seq.logs) <= (12 * 5) + 2  # the queue may be full.\n\n    # test for workers = 0\n    tracker_cb = TrackerCallback()\n    val_seq = RandomSequence(4)\n    out = model.fit_generator(generator=RandomSequence(3),\n                              epochs=5,\n                              validation_data=val_seq,\n                              callbacks=[tracker_cb],\n                              workers=0)\n    assert tracker_cb.trained_epochs == [0, 1, 2, 3, 4]\n    assert tracker_cb.trained_batches == list(range(12)) * 5\n    assert len(val_seq.logs) == 12 * 5\n\n    # fit_generator will throw an exception\n    # if steps is unspecified for regular generator\n    with pytest.raises(ValueError):\n        @threadsafe_generator\n        def gen_data():\n            while True:\n                yield (np.asarray([]), np.asarray([]))\n\n        out = model.fit_generator(generator=gen_data(), epochs=5,\n                                  initial_epoch=0, validation_data=gen_data(),\n                                  callbacks=[tracker_cb])\n\n    # Check if generator is only accessed an expected number of times\n    gen_counters = [0, 0]\n\n    @threadsafe_generator\n    def gen_data(i):\n        while True:\n            gen_counters[i] += 1\n            yield ([np.random.random((1, 3)), np.random.random((1, 3))],\n                   [np.random.random((1, 4)), np.random.random((1, 3))])\n    out = model.fit_generator(generator=gen_data(0), epochs=3,\n                              steps_per_epoch=2,\n                              validation_data=gen_data(1),\n                              validation_steps=1,\n                              max_queue_size=2,\n                              workers=2)\n\n    # Need range check here as filling\n    # of the queue depends on sleep in the enqueuers\n    max_train = 3 * 2 + 2 * 2\n    min_train = 2 * 3\n    assert min_train <= gen_counters[0] <= max_train\n    # 12 = (epoch * workers * validation steps * max_queue_size)\n    assert 3 <= gen_counters[1] <= 12\n\n    gen_counters = [0]\n    out = model.fit_generator(generator=RandomSequence(3), epochs=3,\n                              validation_data=gen_data(0),\n                              validation_steps=1,\n                              max_queue_size=2,\n                              workers=2)\n\n    # 12 = (epoch * workers * validation steps * max_queue_size)\n    # Need range check here as filling\n    # of the queue depends on sleep in the enqueuers\n    assert 3 <= gen_counters[0] <= 12",
        "begin_line": 460,
        "end_line": 553,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.gen_data#511",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.gen_data()",
        "snippet": "        def gen_data():\n            while True:\n                yield (np.asarray([]), np.asarray([]))",
        "begin_line": 511,
        "end_line": 513,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.gen_data#523",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.gen_data(i)",
        "snippet": "    def gen_data(i):\n        while True:\n            gen_counters[i] += 1\n            yield ([np.random.random((1, 3)), np.random.random((1, 3))],\n                   [np.random.random((1, 4)), np.random.random((1, 3))])",
        "begin_line": 523,
        "end_line": 527,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_fit_generator_shape#556",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_fit_generator_shape()",
        "snippet": "def test_fit_generator_shape():\n    # predict_generator output shape behavior should be consistent\n    def expected_shape(batch_size, n_batches):\n        return (batch_size * n_batches, 4), (batch_size * n_batches, 3)\n\n    model = get_model(num_outputs=2)\n    optimizer = 'rmsprop'\n    loss = 'mse'\n\n    # Multiple outputs and one step.\n    batch_size = 5\n    sequence_length = 1\n    shape_0, shape_1 = expected_shape(batch_size, sequence_length)\n    out = model.predict_generator(\n        RandomSequence(batch_size, sequence_length=sequence_length))\n    assert np.shape(out[0]) == shape_0 and np.shape(out[1]) == shape_1\n\n    # Multiple outputs and multiple steps.\n    batch_size = 5\n    sequence_length = 2\n    shape_0, shape_1 = expected_shape(batch_size, sequence_length)\n    out = model.predict_generator(\n        RandomSequence(batch_size, sequence_length=sequence_length))\n    assert np.shape(out[0]) == shape_0 and np.shape(out[1]) == shape_1\n\n    # Create a model with a single output.\n    single_output_model = get_model(num_outputs=1)\n    single_output_model.compile(optimizer, loss,\n                                metrics=[], sample_weight_mode=None)\n\n    # Single output and one step.\n    batch_size = 5\n    sequence_length = 1\n    shape_0, _ = expected_shape(batch_size, sequence_length)\n    out = single_output_model.predict_generator(\n        RandomSequence(batch_size, sequence_length=sequence_length))\n    assert np.shape(out) == shape_0\n\n    # Single output and multiple steps.\n    batch_size = 5\n    sequence_length = 2\n    shape_0, _ = expected_shape(batch_size, sequence_length)\n    out = single_output_model.predict_generator(\n        RandomSequence(batch_size, sequence_length=sequence_length))\n    assert np.shape(out) == shape_0",
        "begin_line": 556,
        "end_line": 600,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.expected_shape#558",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.expected_shape(batch_size, n_batches)",
        "snippet": "    def expected_shape(batch_size, n_batches):\n        return (batch_size * n_batches, 4), (batch_size * n_batches, 3)",
        "begin_line": 558,
        "end_line": 559,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_warnings#605",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_warnings()",
        "snippet": "def test_warnings():\n    a = Input(shape=(3,), name='input_a')\n    b = Input(shape=(3,), name='input_b')\n\n    a_2 = Dense(4, name='dense_1')(a)\n    dp = Dropout(0.5, name='dropout')\n    b_2 = dp(b)\n\n    model = Model([a, b], [a_2, b_2])\n\n    optimizer = 'rmsprop'\n    loss = 'mse'\n    loss_weights = [1., 0.5]\n    model.compile(optimizer, loss, metrics=[], loss_weights=loss_weights,\n                  sample_weight_mode=None)\n\n    @threadsafe_generator\n    def gen_data(batch_sz):\n        while True:\n            yield ([np.random.random((batch_sz, 3)),\n                    np.random.random((batch_sz, 3))],\n                   [np.random.random((batch_sz, 4)),\n                    np.random.random((batch_sz, 3))])\n\n    with pytest.warns(Warning) as w:\n        out = model.fit_generator(gen_data(4),\n                                  steps_per_epoch=10,\n                                  use_multiprocessing=True,\n                                  workers=2)\n    warning_raised = any(['Sequence' in str(w_.message) for w_ in w])\n    assert warning_raised, 'No warning raised when using generator with processes.'\n\n    with pytest.warns(None) as w:\n        out = model.fit_generator(RandomSequence(3),\n                                  steps_per_epoch=4,\n                                  use_multiprocessing=True,\n                                  workers=2)\n    assert all(['Sequence' not in str(w_.message) for w_ in w]), (\n        'A warning was raised for Sequence.')",
        "begin_line": 605,
        "end_line": 643,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.gen_data#622",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.gen_data(batch_sz)",
        "snippet": "    def gen_data(batch_sz):\n        while True:\n            yield ([np.random.random((batch_sz, 3)),\n                    np.random.random((batch_sz, 3))],\n                   [np.random.random((batch_sz, 4)),\n                    np.random.random((batch_sz, 3))])",
        "begin_line": 622,
        "end_line": 627,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_sparse_inputs_targets#646",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_sparse_inputs_targets()",
        "snippet": "def test_sparse_inputs_targets():\n    test_inputs = [sparse.random(6, 3, density=0.25).tocsr() for _ in range(2)]\n    test_outputs = [sparse.random(6, i, density=0.25).tocsr() for i in range(3, 5)]\n    in1 = Input(shape=(3,))\n    in2 = Input(shape=(3,))\n    out1 = Dropout(0.5, name='dropout')(in1)\n    out2 = Dense(4, name='dense_1')(in2)\n    model = Model([in1, in2], [out1, out2])\n    model.predict(test_inputs, batch_size=2)\n    model.compile('rmsprop', 'mse')\n    model.fit(test_inputs, test_outputs,\n              epochs=1, batch_size=2, validation_split=0.5)\n    model.evaluate(test_inputs, test_outputs, batch_size=2)",
        "begin_line": 646,
        "end_line": 658,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_sparse_placeholder_fit#663",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_sparse_placeholder_fit()",
        "snippet": "def test_sparse_placeholder_fit():\n    test_inputs = [sparse.random(6, 3, density=0.25).tocsr() for _ in range(2)]\n    test_outputs = [sparse.random(6, i, density=0.25).tocsr() for i in range(3, 5)]\n    in1 = Input(shape=(3,))\n    in2 = Input(shape=(3,), sparse=True)\n    out1 = Dropout(0.5, name='dropout')(in1)\n    out2 = Dense(4, name='dense_1')(in2)\n    model = Model([in1, in2], [out1, out2])\n    model.predict(test_inputs, batch_size=2)\n    model.compile('rmsprop', 'mse')\n    model.fit(test_inputs, test_outputs,\n              epochs=1, batch_size=2, validation_split=0.5)\n    model.evaluate(test_inputs, test_outputs, batch_size=2)",
        "begin_line": 663,
        "end_line": 675,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_trainable_argument#678",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_trainable_argument()",
        "snippet": "def test_trainable_argument():\n    x = np.random.random((5, 3))\n    y = np.random.random((5, 2))\n\n    model = Sequential()\n    model.add(Dense(2, input_dim=3, trainable=False))\n    model.compile('rmsprop', 'mse')\n    out = model.predict(x)\n    model.train_on_batch(x, y)\n    out_2 = model.predict(x)\n    assert_allclose(out, out_2)\n\n    # test with nesting\n    inputs = Input(shape=(3,))\n    outputs = model(inputs)\n    model = Model(inputs, outputs)\n    model.compile('rmsprop', 'mse')\n    out = model.predict(x)\n    model.train_on_batch(x, y)\n    out_2 = model.predict(x)\n    assert_allclose(out, out_2)",
        "begin_line": 678,
        "end_line": 698,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_with_list_as_targets#701",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_with_list_as_targets()",
        "snippet": "def test_with_list_as_targets():\n    model = Sequential()\n    model.add(Dense(1, input_dim=3, trainable=False))\n    model.compile('rmsprop', 'mse')\n\n    x = np.random.random((2, 3))\n    y = [0, 1]\n    model.train_on_batch(x, y)",
        "begin_line": 701,
        "end_line": 708,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_check_not_failing#711",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_check_not_failing()",
        "snippet": "def test_check_not_failing():\n    a = np.random.random((2, 1, 3))\n    training_utils.check_loss_and_target_compatibility(\n        [a], [losses.categorical_crossentropy], [a.shape])\n    training_utils.check_loss_and_target_compatibility(\n        [a], [losses.categorical_crossentropy], [(2, None, 3)])",
        "begin_line": 711,
        "end_line": 716,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_check_last_is_one#719",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_check_last_is_one()",
        "snippet": "def test_check_last_is_one():\n    a = np.random.random((2, 3, 1))\n    with pytest.raises(ValueError) as exc:\n        training_utils.check_loss_and_target_compatibility(\n            [a], [losses.categorical_crossentropy], [a.shape])\n\n    assert 'You are passing a target array' in str(exc)",
        "begin_line": 719,
        "end_line": 725,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_check_bad_shape#728",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_check_bad_shape()",
        "snippet": "def test_check_bad_shape():\n    a = np.random.random((2, 3, 5))\n    with pytest.raises(ValueError) as exc:\n        training_utils.check_loss_and_target_compatibility(\n            [a], [losses.categorical_crossentropy], [(2, 3, 6)])\n\n    assert 'targets to have the same shape' in str(exc)",
        "begin_line": 728,
        "end_line": 734,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_model_with_input_feed_tensor#739",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_model_with_input_feed_tensor()",
        "snippet": "def test_model_with_input_feed_tensor():\n    \"\"\"We test building a model with a TF variable as input.\n    We should be able to call fit, evaluate, predict,\n    by only passing them data for the placeholder inputs\n    in the model.\n    \"\"\"\n    import tensorflow as tf\n\n    input_a_np = np.random.random((10, 3))\n    input_b_np = np.random.random((10, 3))\n\n    output_a_np = np.random.random((10, 4))\n    output_b_np = np.random.random((10, 3))\n\n    a = Input(tensor=tf.Variable(input_a_np, dtype=tf.float32))\n    b = Input(shape=(3,), name='input_b')\n\n    a_2 = Dense(4, name='dense_1')(a)\n    dp = Dropout(0.5, name='dropout')\n    b_2 = dp(b)\n\n    model = Model([a, b], [a_2, b_2])\n    model.summary()\n\n    optimizer = 'rmsprop'\n    loss = 'mse'\n    loss_weights = [1., 0.5]\n    model.compile(optimizer, loss, metrics=['mean_squared_error'],\n                  loss_weights=loss_weights,\n                  sample_weight_mode=None)\n\n    # test train_on_batch\n    out = model.train_on_batch(input_b_np,\n                               [output_a_np, output_b_np])\n    out = model.train_on_batch({'input_b': input_b_np},\n                               [output_a_np, output_b_np])\n    out = model.test_on_batch({'input_b': input_b_np},\n                              [output_a_np, output_b_np])\n    out = model.predict_on_batch({'input_b': input_b_np})\n\n    # test fit\n    out = model.fit({'input_b': input_b_np},\n                    [output_a_np, output_b_np], epochs=1, batch_size=10)\n    out = model.fit(input_b_np,\n                    [output_a_np, output_b_np], epochs=1, batch_size=10)\n\n    # test evaluate\n    out = model.evaluate({'input_b': input_b_np},\n                         [output_a_np, output_b_np], batch_size=10)\n    out = model.evaluate(input_b_np,\n                         [output_a_np, output_b_np], batch_size=10)\n\n    # test predict\n    out = model.predict({'input_b': input_b_np}, batch_size=10)\n    out = model.predict(input_b_np, batch_size=10)\n    assert len(out) == 2\n\n    # Now test a model with a single input\n    # i.e. we don't pass any data to fit the model.\n    a = Input(tensor=tf.Variable(input_a_np, dtype=tf.float32))\n    a_2 = Dense(4, name='dense_1')(a)\n    a_2 = Dropout(0.5, name='dropout')(a_2)\n    model = Model(a, a_2)\n    model.summary()\n\n    optimizer = 'rmsprop'\n    loss = 'mse'\n    model.compile(optimizer, loss, metrics=['mean_squared_error'])\n\n    # test train_on_batch\n    out = model.train_on_batch(None,\n                               output_a_np)\n    out = model.train_on_batch(None,\n                               output_a_np)\n    out = model.test_on_batch(None,\n                              output_a_np)\n    out = model.predict_on_batch(None)\n    out = model.train_on_batch([],\n                               output_a_np)\n    out = model.train_on_batch({},\n                               output_a_np)\n\n    # test fit\n    out = model.fit(None,\n                    output_a_np, epochs=1, batch_size=10)\n    out = model.fit(None,\n                    output_a_np, epochs=1, batch_size=10)\n\n    # test evaluate\n    out = model.evaluate(None,\n                         output_a_np, batch_size=10)\n    out = model.evaluate(None,\n                         output_a_np, batch_size=10)\n\n    # test predict\n    out = model.predict(None, steps=3)\n    out = model.predict(None, steps=3)\n    assert out.shape == (10 * 3, 4)\n\n    # Same, without learning phase\n    # i.e. we don't pass any data to fit the model.\n    a = Input(tensor=tf.Variable(input_a_np, dtype=tf.float32))\n    a_2 = Dense(4, name='dense_1')(a)\n    model = Model(a, a_2)\n    model.summary()\n\n    optimizer = 'rmsprop'\n    loss = 'mse'\n    model.compile(optimizer, loss, metrics=['mean_squared_error'])\n\n    # test train_on_batch\n    out = model.train_on_batch(None,\n                               output_a_np)\n    out = model.train_on_batch(None,\n                               output_a_np)\n    out = model.test_on_batch(None,\n                              output_a_np)\n    out = model.predict_on_batch(None)\n    out = model.train_on_batch([],\n                               output_a_np)\n    out = model.train_on_batch({},\n                               output_a_np)\n\n    # test fit\n    out = model.fit(None,\n                    output_a_np, epochs=1, batch_size=10)\n    out = model.fit(None,\n                    output_a_np, epochs=1, batch_size=10)\n\n    # test evaluate\n    out = model.evaluate(None,\n                         output_a_np, batch_size=10)\n    out = model.evaluate(None,\n                         output_a_np, batch_size=10)\n\n    # test predict\n    out = model.predict(None, steps=3)\n    out = model.predict(None, steps=3)\n    assert out.shape == (10 * 3, 4)",
        "begin_line": 739,
        "end_line": 877,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_model_with_partial_loss#880",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_model_with_partial_loss()",
        "snippet": "def test_model_with_partial_loss():\n    a = Input(shape=(3,), name='input_a')\n    a_2 = Dense(4, name='dense_1')(a)\n    dp = Dropout(0.5, name='dropout')\n    a_3 = dp(a_2)\n    model = Model(a, [a_2, a_3])\n\n    optimizer = 'rmsprop'\n    loss = {'dropout': 'mse'}\n    model.compile(optimizer, loss, metrics=['mae'])\n\n    input_a_np = np.random.random((10, 3))\n    output_a_np = np.random.random((10, 4))\n\n    # test train_on_batch\n    out = model.train_on_batch(input_a_np, output_a_np)\n    out = model.test_on_batch(input_a_np, output_a_np)\n    # fit\n    out = model.fit(input_a_np, [output_a_np])\n    # evaluate\n    out = model.evaluate(input_a_np, [output_a_np])\n\n    # Same without dropout.\n    a = Input(shape=(3,), name='input_a')\n    a_2 = Dense(4, name='dense_1')(a)\n    a_3 = Dense(4, name='dense_2')(a_2)\n    model = Model(a, [a_2, a_3])\n\n    optimizer = 'rmsprop'\n    loss = {'dense_2': 'mse'}\n    model.compile(optimizer, loss, metrics={'dense_1': 'mae'})\n\n    # test train_on_batch\n    out = model.train_on_batch(input_a_np, output_a_np)\n    out = model.test_on_batch(input_a_np, output_a_np)\n    # fit\n    out = model.fit(input_a_np, [output_a_np])\n    # evaluate\n    out = model.evaluate(input_a_np, [output_a_np])",
        "begin_line": 880,
        "end_line": 918,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_model_with_external_loss#923",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_model_with_external_loss()",
        "snippet": "def test_model_with_external_loss():\n    # None loss, only regularization loss.\n    a = Input(shape=(3,), name='input_a')\n    a_2 = Dense(4, name='dense_1',\n                kernel_regularizer='l1',\n                bias_regularizer='l2')(a)\n    dp = Dropout(0.5, name='dropout')\n    a_3 = dp(a_2)\n\n    model = Model(a, [a_2, a_3])\n\n    optimizer = 'rmsprop'\n    loss = None\n    model.compile(optimizer, loss, metrics=['mae'])\n\n    input_a_np = np.random.random((10, 3))\n\n    # test train_on_batch\n    out = model.train_on_batch(input_a_np, None)\n    out = model.test_on_batch(input_a_np, None)\n    # fit\n    out = model.fit(input_a_np, None)\n    # evaluate\n    out = model.evaluate(input_a_np, None)\n\n    # No dropout, external loss.\n    a = Input(shape=(3,), name='input_a')\n    a_2 = Dense(4, name='dense_1')(a)\n    a_3 = Dense(4, name='dense_2')(a)\n\n    model = Model(a, [a_2, a_3])\n    model.add_loss(K.mean(a_3 + a_2))\n\n    optimizer = 'rmsprop'\n    loss = None\n    model.compile(optimizer, loss, metrics=['mae'])\n\n    # test train_on_batch\n    out = model.train_on_batch(input_a_np, None)\n    out = model.test_on_batch(input_a_np, None)\n    # fit\n    out = model.fit(input_a_np, None)\n    # evaluate\n    out = model.evaluate(input_a_np, None)\n\n    # Test fit with no external data at all.\n    if K.backend() == 'tensorflow':\n        import tensorflow as tf\n\n        a = Input(tensor=tf.Variable(input_a_np, dtype=tf.float32))\n        a_2 = Dense(4, name='dense_1')(a)\n        a_2 = Dropout(0.5, name='dropout')(a_2)\n        model = Model(a, a_2)\n        model.add_loss(K.mean(a_2))\n\n        model.compile(optimizer='rmsprop',\n                      loss=None,\n                      metrics=['mean_squared_error'])\n\n        # test train_on_batch\n        out = model.train_on_batch(None, None)\n        out = model.test_on_batch(None, None)\n        out = model.predict_on_batch(None)\n\n        # test fit\n        with pytest.raises(ValueError):\n            out = model.fit(None, None, epochs=1, batch_size=10)\n        out = model.fit(None, None, epochs=1, steps_per_epoch=1)\n\n        # define a generator to produce x=None and y=None\n        @threadsafe_generator\n        def data_tensors_generator():\n            while True:\n                yield (None, None)\n\n        generator = data_tensors_generator()\n\n        # test fit_generator for framework-native data tensors\n        out = model.fit_generator(generator, epochs=1,\n                                  steps_per_epoch=3)\n\n        # test evaluate_generator for framework-native data tensors\n        out = model.evaluate_generator(generator, steps=3)\n\n        # test fit with validation data\n        with pytest.raises(ValueError):\n            out = model.fit(None, None,\n                            epochs=1,\n                            steps_per_epoch=None,\n                            validation_steps=2)\n        out = model.fit(None, None,\n                        epochs=1,\n                        steps_per_epoch=2,\n                        validation_steps=2)\n\n        # test evaluate\n        with pytest.raises(ValueError):\n            out = model.evaluate(None, None, batch_size=10)\n        out = model.evaluate(None, None, steps=3)\n\n        # test predict\n        with pytest.raises(ValueError):\n            out = model.predict(None, batch_size=10)\n        out = model.predict(None, steps=3)\n        assert out.shape == (10 * 3, 4)\n\n        # Test multi-output model without external data.\n        a = Input(tensor=tf.Variable(input_a_np, dtype=tf.float32))\n        a_1 = Dense(4, name='dense_1')(a)\n        a_2 = Dropout(0.5, name='dropout')(a_1)\n        model = Model(a, [a_1, a_2])\n        model.add_loss(K.mean(a_2))\n        model.compile(optimizer='rmsprop',\n                      loss=None,\n                      metrics=['mean_squared_error'])\n\n        # test train_on_batch\n        out = model.train_on_batch(None, None)\n        out = model.test_on_batch(None, None)\n        out = model.predict_on_batch(None)\n\n        # test fit\n        with pytest.raises(ValueError):\n            out = model.fit(None, None, epochs=1, batch_size=10)\n        out = model.fit(None, None, epochs=1, steps_per_epoch=1)\n\n        # test fit with validation data\n        with pytest.raises(ValueError):\n            out = model.fit(None, None,\n                            epochs=1,\n                            steps_per_epoch=None,\n                            validation_steps=2)\n        out = model.fit(None, None,\n                        epochs=1,\n                        steps_per_epoch=2,\n                        validation_steps=2)\n\n        # test evaluate\n        with pytest.raises(ValueError):\n            out = model.evaluate(None, None, batch_size=10)\n        out = model.evaluate(None, None, steps=3)\n\n        # test predict\n        with pytest.raises(ValueError):\n            out = model.predict(None, batch_size=10)\n        out = model.predict(None, steps=3)\n        assert len(out) == 2\n        assert out[0].shape == (10 * 3, 4)\n        assert out[1].shape == (10 * 3, 4)",
        "begin_line": 923,
        "end_line": 1071,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.data_tensors_generator#994",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.data_tensors_generator()",
        "snippet": "        def data_tensors_generator():\n            while True:\n                yield (None, None)",
        "begin_line": 994,
        "end_line": 996,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_target_tensors#1074",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_target_tensors()",
        "snippet": "def test_target_tensors():\n    # single-output, as list\n    model = keras.models.Sequential()\n    model.add(keras.layers.Dense(4, input_shape=(4,), name='dense'))\n    input_val = np.random.random((10, 4))\n    target_val = np.random.random((10, 4))\n    target = keras.backend.variable(target_val)\n    model.compile(optimizer='rmsprop', loss='mse', target_tensors=[target])\n    model.train_on_batch(input_val, None)\n\n    # single-output, as dict\n    model.compile(optimizer='rmsprop', loss='mse',\n                  target_tensors={'dense': target})\n    model.train_on_batch(input_val, None)\n\n    # single-output, as tensor\n    model.compile(optimizer='rmsprop', loss='mse',\n                  target_tensors=target)\n    model.train_on_batch(input_val, None)\n\n    # test invalid arguments\n    with pytest.raises(TypeError):\n        model.compile(optimizer='rmsprop', loss='mse',\n                      target_tensors=set())\n    with pytest.raises(ValueError):\n        model.compile(optimizer='rmsprop', loss='mse',\n                      target_tensors=[target, target])\n    with pytest.raises(ValueError):\n        model.compile(optimizer='rmsprop', loss='mse',\n                      target_tensors={'dense2': None})\n    with pytest.raises(ValueError):\n        model.compile(optimizer='rmsprop', loss='mse',\n                      target_tensors=[target])\n        model.train_on_batch(input_val, target_val)\n\n    # multi-output, as list\n    input_val = np.random.random((10, 4))\n    target_val_a = np.random.random((10, 4))\n    target_val_b = np.random.random((10, 4))\n    target_a = keras.backend.variable(target_val_a)\n    target_b = keras.backend.variable(target_val_b)\n\n    inputs = keras.layers.Input(shape=(4,))\n    output_a = keras.layers.Dense(4, name='dense_a')(inputs)\n    output_b = keras.layers.Dense(4, name='dense_b')(inputs)\n    model = keras.models.Model(inputs, [output_a, output_b])\n    model.compile(optimizer='rmsprop', loss='mse',\n                  target_tensors=[target_a, target_b])\n    model.train_on_batch(input_val, None)\n\n    # multi-output, as dict\n    model.compile(optimizer='rmsprop', loss='mse',\n                  target_tensors={'dense_a': target_a,\n                                  'dense_b': target_b})\n    model.train_on_batch(input_val, None)\n\n    # multi-output, not enough target tensors when `target_tensors` is not a dict\n    with pytest.raises(ValueError,\n                       match='When passing a list as `target_tensors`, it should '\n                             'have one entry per model output. The model has \\d '\n                             'outputs, but you passed target_tensors='):\n        model.compile(optimizer='rmsprop', loss='mse',\n                      target_tensors=[target_a])\n    with pytest.raises(ValueError,\n                       match='The model has \\d outputs, but you passed a single '\n                             'tensor as `target_tensors`. Expected a list or '\n                             'a dict of tensors.'):\n        model.compile(optimizer='rmsprop', loss='mse',\n                      target_tensors=target_a)\n\n    # test with sample weights\n    model.compile(optimizer='rmsprop', loss='mse',\n                  target_tensors=[target_a, target_b])\n    model.train_on_batch(input_val, None,\n                         sample_weight={'dense_a': np.random.random((10,))})",
        "begin_line": 1074,
        "end_line": 1148,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_model_custom_target_tensors#1151",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_model_custom_target_tensors()",
        "snippet": "def test_model_custom_target_tensors():\n    a = Input(shape=(3,), name='input_a')\n    b = Input(shape=(3,), name='input_b')\n\n    a_2 = Dense(4, name='dense_1')(a)\n    dp = Dropout(0.5, name='dropout')\n    b_2 = dp(b)\n\n    y = K.placeholder([10, 4], name='y')\n    y1 = K.placeholder([10, 3], name='y1')\n    y2 = K.placeholder([7, 5], name='y2')\n    model = Model([a, b], [a_2, b_2])\n\n    optimizer = 'rmsprop'\n    loss = 'mse'\n    loss_weights = [1., 0.5]\n\n    # test list of target tensors\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss, metrics=[], loss_weights=loss_weights,\n                      sample_weight_mode=None, target_tensors=[y, y1, y2])\n    model.compile(optimizer, loss, metrics=[], loss_weights=loss_weights,\n                  sample_weight_mode=None, target_tensors=[y, y1])\n    input_a_np = np.random.random((10, 3))\n    input_b_np = np.random.random((10, 3))\n\n    output_a_np = np.random.random((10, 4))\n    output_b_np = np.random.random((10, 3))\n\n    out = model.train_on_batch([input_a_np, input_b_np],\n                               [output_a_np, output_b_np],\n                               {y: np.random.random((10, 4)),\n                                y1: np.random.random((10, 3))})\n    # test dictionary of target_tensors\n    with pytest.raises(ValueError):\n        model.compile(optimizer, loss,\n                      metrics=[],\n                      loss_weights=loss_weights,\n                      sample_weight_mode=None,\n                      target_tensors={'does_not_exist': y2})\n    # test dictionary of target_tensors\n    model.compile(optimizer, loss,\n                  metrics=[],\n                  loss_weights=loss_weights,\n                  sample_weight_mode=None,\n                  target_tensors={'dense_1': y, 'dropout': y1})\n    out = model.train_on_batch([input_a_np, input_b_np],\n                               [output_a_np, output_b_np],\n                               {y: np.random.random((10, 4)),\n                                y1: np.random.random((10, 3))})\n\n    if K.backend() == 'tensorflow':\n        import tensorflow as tf\n        # test with custom TF placeholder as target\n        pl_target_a = tf.placeholder('float32', shape=(None, 4))\n        model.compile(optimizer='rmsprop', loss='mse',\n                      target_tensors={'dense_1': pl_target_a})\n        model.train_on_batch([input_a_np, input_b_np],\n                             [output_a_np, output_b_np])",
        "begin_line": 1151,
        "end_line": 1209,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_trainable_weights_count_consistency#1214",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_trainable_weights_count_consistency()",
        "snippet": "def test_trainable_weights_count_consistency():\n    \"\"\"Tests the trainable weights consistency check of Model.\n\n    This verifies that a warning is shown if model.trainable is modified\n    and the model is summarized/run without a new call to .compile()\n\n    Reproduce issue #8121\n    \"\"\"\n    a = Input(shape=(3,), name='input_a')\n    model1 = Model(inputs=a, outputs=Dense(1)(a))\n\n    model1.trainable = False\n    b = Input(shape=(3,), name='input_b')\n    y = model1(b)\n    model2 = Model(inputs=b, outputs=Dense(1)(y))\n\n    model2.compile(optimizer='adam', loss='mse')\n\n    model1.trainable = True\n\n    # Should warn on .summary()\n    with pytest.warns(UserWarning) as w:\n        model2.summary()\n    warning_raised = any(['Discrepancy' in str(w_.message) for w_ in w])\n    assert warning_raised, (\n        'No warning raised when trainable is modified without .compile.')\n\n    # And on .fit()\n    with pytest.warns(UserWarning) as w:\n        model2.fit(x=np.zeros((5, 3)), y=np.zeros((5, 1)))\n    warning_raised = any(['Discrepancy' in str(w_.message) for w_ in w])\n    assert warning_raised, (\n        'No warning raised when trainable is modified without .compile.')\n\n    # And shouldn't warn if we recompile\n    model2.compile(optimizer='adam', loss='mse')\n    with pytest.warns(None) as w:\n        model2.summary()\n    assert len(w) == 0, (\n        'Warning raised even when .compile() is called after modifying .trainable')",
        "begin_line": 1214,
        "end_line": 1253,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_pandas_dataframe#1256",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_pandas_dataframe()",
        "snippet": "def test_pandas_dataframe():\n    input_a = Input(shape=(3,), name='input_a')\n    input_b = Input(shape=(3,), name='input_b')\n\n    x = Dense(4, name='dense_1')(input_a)\n    y = Dense(3, name='desne_2')(input_b)\n\n    model_1 = Model(inputs=input_a, outputs=x)\n    model_2 = Model(inputs=[input_a, input_b], outputs=[x, y])\n\n    optimizer = 'rmsprop'\n    loss = 'mse'\n\n    model_1.compile(optimizer=optimizer, loss=loss)\n    model_2.compile(optimizer=optimizer, loss=loss)\n\n    input_a_df = pd.DataFrame(np.random.random((10, 3)))\n    input_b_df = pd.DataFrame(np.random.random((10, 3)))\n\n    output_a_df = pd.DataFrame(np.random.random((10, 4)))\n    output_b_df = pd.DataFrame(np.random.random((10, 3)))\n\n    model_1.fit(input_a_df,\n                output_a_df)\n    model_2.fit([input_a_df, input_b_df],\n                [output_a_df, output_b_df])\n    model_1.fit([input_a_df],\n                [output_a_df])\n    model_1.fit({'input_a': input_a_df},\n                output_a_df)\n    model_2.fit({'input_a': input_a_df, 'input_b': input_b_df},\n                [output_a_df, output_b_df])\n\n    model_1.predict(input_a_df)\n    model_2.predict([input_a_df, input_b_df])\n    model_1.predict([input_a_df])\n    model_1.predict({'input_a': input_a_df})\n    model_2.predict({'input_a': input_a_df, 'input_b': input_b_df})\n\n    model_1.predict_on_batch(input_a_df)\n    model_2.predict_on_batch([input_a_df, input_b_df])\n    model_1.predict_on_batch([input_a_df])\n    model_1.predict_on_batch({'input_a': input_a_df})\n    model_2.predict_on_batch({'input_a': input_a_df, 'input_b': input_b_df})\n\n    model_1.evaluate(input_a_df,\n                     output_a_df)\n    model_2.evaluate([input_a_df, input_b_df],\n                     [output_a_df, output_b_df])\n    model_1.evaluate([input_a_df],\n                     [output_a_df])\n    model_1.evaluate({'input_a': input_a_df},\n                     output_a_df)\n    model_2.evaluate({'input_a': input_a_df, 'input_b': input_b_df},\n                     [output_a_df, output_b_df])\n\n    model_1.train_on_batch(input_a_df,\n                           output_a_df)\n    model_2.train_on_batch([input_a_df, input_b_df],\n                           [output_a_df, output_b_df])\n    model_1.train_on_batch([input_a_df],\n                           [output_a_df])\n    model_1.train_on_batch({'input_a': input_a_df},\n                           output_a_df)\n    model_2.train_on_batch({'input_a': input_a_df, 'input_b': input_b_df},\n                           [output_a_df, output_b_df])\n\n    model_1.test_on_batch(input_a_df,\n                          output_a_df)\n    model_2.test_on_batch([input_a_df, input_b_df],\n                          [output_a_df, output_b_df])\n    model_1.test_on_batch([input_a_df],\n                          [output_a_df])\n    model_1.test_on_batch({'input_a': input_a_df},\n                          output_a_df)\n    model_2.test_on_batch({'input_a': input_a_df, 'input_b': input_b_df},\n                          [output_a_df, output_b_df])",
        "begin_line": 1256,
        "end_line": 1332,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_training_and_eval_methods_on_symbolic_tensors_single_io#1340",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_training_and_eval_methods_on_symbolic_tensors_single_io()",
        "snippet": "def test_training_and_eval_methods_on_symbolic_tensors_single_io():\n    x = keras.layers.Input(shape=(3,), name='input')\n    y = keras.layers.Dense(4, name='dense')(x)\n    model = keras.Model(x, y)\n\n    optimizer = 'rmsprop'\n    loss = 'mse'\n    metrics = ['mae']\n    model.compile(optimizer, loss, metrics=metrics)\n\n    inputs = keras.backend.zeros(shape=(10, 3))\n    targets = keras.backend.zeros(shape=(10, 4))\n\n    model.fit(inputs, targets, epochs=1, steps_per_epoch=2, verbose=0)\n    model.evaluate(inputs, targets, steps=2, verbose=0)\n    model.predict(inputs, steps=2)\n    model.train_on_batch(inputs, targets)\n    model.test_on_batch(inputs, targets)\n    model.fit(inputs, targets,\n              epochs=1, steps_per_epoch=2, verbose=1,\n              validation_data=(inputs, targets), validation_steps=2)",
        "begin_line": 1340,
        "end_line": 1360,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_training_and_eval_methods_on_symbolic_tensors_multi_io#1368",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_training_and_eval_methods_on_symbolic_tensors_multi_io()",
        "snippet": "def test_training_and_eval_methods_on_symbolic_tensors_multi_io():\n    a = keras.layers.Input(shape=(3,), name='input_a')\n    b = keras.layers.Input(shape=(3,), name='input_b')\n\n    dense = keras.layers.Dense(4, name='dense')\n    c = dense(a)\n    d = dense(b)\n    e = keras.layers.Dropout(0.5, name='dropout')(c)\n\n    model = keras.models.Model([a, b], [d, e])\n\n    optimizer = 'rmsprop'\n    loss = 'mse'\n    loss_weights = [1., 0.5]\n    metrics = ['mae']\n    model.compile(optimizer, loss, metrics=metrics, loss_weights=loss_weights)\n\n    input_a_tf = keras.backend.zeros(shape=(10, 3))\n    input_b_tf = keras.backend.zeros(shape=(10, 3))\n\n    output_d_tf = keras.backend.zeros(shape=(10, 4))\n    output_e_tf = keras.backend.zeros(shape=(10, 4))\n\n    model.fit(\n        [input_a_tf, input_b_tf], [output_d_tf, output_e_tf],\n        epochs=1,\n        steps_per_epoch=2,\n        verbose=0)\n    with pytest.raises(ValueError) as excinfo:\n        model.fit(\n            [input_a_tf, input_b_tf], [output_d_tf, output_e_tf],\n            epochs=1,\n            batch_size=5,\n            verbose=0)\n    assert 'should specify the `steps_per_epoch`' in str(excinfo.value)\n    model.train_on_batch([input_a_tf, input_b_tf], [output_d_tf, output_e_tf])\n\n    # Test with dictionary inputs\n    model.fit(\n        {'input_a': input_a_tf,\n         'input_b': input_b_tf},\n        {'dense': output_d_tf,\n         'dropout': output_e_tf},\n        epochs=1,\n        steps_per_epoch=2,\n        verbose=0)\n    model.fit(\n        {'input_a': input_a_tf,\n         'input_b': input_b_tf},\n        {'dense': output_d_tf,\n         'dropout': output_e_tf},\n        validation_data=({'input_a': input_a_tf,\n                          'input_b': input_b_tf},\n                         {'dense': output_d_tf,\n                          'dropout': output_e_tf}),\n        epochs=1,\n        steps_per_epoch=2,\n        validation_steps=2,\n        verbose=0)\n    model.train_on_batch(\n        {'input_a': input_a_tf,\n         'input_b': input_b_tf},\n        {'dense': output_d_tf,\n         'dropout': output_e_tf})\n\n    # Test with validation data\n    model.fit(\n        [input_a_tf, input_b_tf], [output_d_tf, output_e_tf],\n        validation_data=([input_a_tf, input_b_tf],\n                         [output_d_tf, output_e_tf]),\n        epochs=1,\n        steps_per_epoch=2,\n        validation_steps=2,\n        verbose=0)\n    # Test with validation split\n    with pytest.raises(ValueError) as excinfo:\n        model.fit(\n            [input_a_tf, input_b_tf], [output_d_tf, output_e_tf],\n            epochs=2,\n            steps_per_epoch=2,\n            verbose=0,\n            validation_split=0.2,\n            validation_steps=2)\n    assert 'you cannot use `validation_split`' in str(excinfo.value)\n\n    # Test evaluation / prediction methods\n    model.evaluate([input_a_tf, input_b_tf], [output_d_tf, output_e_tf],\n                   steps=2, verbose=0)\n    model.predict([input_a_tf, input_b_tf], steps=2)\n    model.test_on_batch([input_a_tf, input_b_tf], [output_d_tf, output_e_tf])",
        "begin_line": 1368,
        "end_line": 1457,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_model_with_crossentropy_losses_channels_first#1460",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_model_with_crossentropy_losses_channels_first()",
        "snippet": "def test_model_with_crossentropy_losses_channels_first():\n    \"\"\"Tests use of all crossentropy losses with `channels_first`.\n\n    Tests `sparse_categorical_crossentropy`, `categorical_crossentropy`,\n    and `binary_crossentropy`.\n    Verifies that evaluate gives the same result with either\n    `channels_first` or `channels_last` image_data_format.\n    Tests PR #9715.\n    \"\"\"\n\n    def prepare_simple_model(input_tensor, loss_name, target):\n        axis = 1 if K.image_data_format() == 'channels_first' else -1\n        if loss_name == 'sparse_categorical_crossentropy':\n            loss = lambda y_true, y_pred: K.sparse_categorical_crossentropy(\n                y_true, y_pred, axis=axis)\n            num_channels = np.amax(target) + 1\n            activation = 'softmax'\n        elif loss_name == 'categorical_crossentropy':\n            loss = lambda y_true, y_pred: K.categorical_crossentropy(\n                y_true, y_pred, axis=axis)\n            num_channels = target.shape[axis]\n            activation = 'softmax'\n        elif loss_name == 'binary_crossentropy':\n            loss = lambda y_true, y_pred: K.binary_crossentropy(y_true, y_pred)\n            num_channels = target.shape[axis]\n            activation = 'sigmoid'\n        predictions = Conv2D(num_channels, 1, activation=activation,\n                             kernel_initializer='ones',\n                             bias_initializer='ones')(input_tensor)\n        simple_model = Model(inputs=input_tensor, outputs=predictions)\n        simple_model.compile(optimizer='rmsprop', loss=loss)\n        return simple_model\n\n    losses_to_test = ['sparse_categorical_crossentropy',\n                      'categorical_crossentropy', 'binary_crossentropy']\n\n    data_channels_first = np.array([[[[8., 7.1, 0.], [4.5, 2.6, 0.55],\n                                      [0.9, 4.2, 11.2]]]], dtype=np.float32)\n    # Labels for testing 4-class sparse_categorical_crossentropy, 4-class\n    # categorical_crossentropy, and 2-class binary_crossentropy:\n    labels_channels_first = [np.array([[[[0, 1, 3], [2, 1, 0], [2, 2, 1]]]]),\n                             np.array([[[[0, 1, 0], [0, 1, 0], [0, 0, 0]],\n                                        [[1, 0, 0], [0, 0, 1], [0, 1, 0]],\n                                        [[0, 0, 0], [1, 0, 0], [0, 0, 1]],\n                                        [[0, 0, 1], [0, 0, 0], [1, 0, 0]]]]),\n                             np.array([[[[0, 1, 0], [0, 1, 0], [0, 0, 1]],\n                                        [[1, 0, 1], [1, 0, 1], [1, 1, 0]]]])]\n    # Compute one loss for each loss function in the list `losses_to_test`:\n    loss_channels_last = [0., 0., 0.]\n    loss_channels_first = [0., 0., 0.]\n\n    old_data_format = K.image_data_format()\n\n    # Evaluate a simple network with channels last, with all three loss\n    # functions:\n    K.set_image_data_format('channels_last')\n    data = np.moveaxis(data_channels_first, 1, -1)\n    for index, loss_function in enumerate(losses_to_test):\n        labels = np.moveaxis(labels_channels_first[index], 1, -1)\n        inputs = Input(shape=(3, 3, 1))\n        model = prepare_simple_model(inputs, loss_function, labels)\n        loss_channels_last[index] = model.evaluate(x=data, y=labels,\n                                                   batch_size=1, verbose=0)\n\n    # Evaluate the same network with channels first, with all three loss\n    # functions:\n    K.set_image_data_format('channels_first')\n    data = data_channels_first\n    for index, loss_function in enumerate(losses_to_test):\n        labels = labels_channels_first[index]\n        inputs = Input(shape=(1, 3, 3))\n        model = prepare_simple_model(inputs, loss_function, labels)\n        loss_channels_first[index] = model.evaluate(x=data, y=labels,\n                                                    batch_size=1, verbose=0)\n\n    K.set_image_data_format(old_data_format)\n\n    assert_allclose(loss_channels_first, loss_channels_last,\n                    err_msg='{}{}'.format('Computed different losses for ',\n                                          'channels_first and channels_last.'))",
        "begin_line": 1460,
        "end_line": 1539,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.prepare_simple_model#1470",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.prepare_simple_model(input_tensor, loss_name, target)",
        "snippet": "    def prepare_simple_model(input_tensor, loss_name, target):\n        axis = 1 if K.image_data_format() == 'channels_first' else -1\n        if loss_name == 'sparse_categorical_crossentropy':\n            loss = lambda y_true, y_pred: K.sparse_categorical_crossentropy(\n                y_true, y_pred, axis=axis)\n            num_channels = np.amax(target) + 1\n            activation = 'softmax'\n        elif loss_name == 'categorical_crossentropy':\n            loss = lambda y_true, y_pred: K.categorical_crossentropy(\n                y_true, y_pred, axis=axis)\n            num_channels = target.shape[axis]\n            activation = 'softmax'\n        elif loss_name == 'binary_crossentropy':\n            loss = lambda y_true, y_pred: K.binary_crossentropy(y_true, y_pred)\n            num_channels = target.shape[axis]\n            activation = 'sigmoid'\n        predictions = Conv2D(num_channels, 1, activation=activation,\n                             kernel_initializer='ones',\n                             bias_initializer='ones')(input_tensor)\n        simple_model = Model(inputs=input_tensor, outputs=predictions)\n        simple_model.compile(optimizer='rmsprop', loss=loss)\n        return simple_model",
        "begin_line": 1470,
        "end_line": 1491,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_dynamic_set_inputs#1542",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_dynamic_set_inputs()",
        "snippet": "def test_dynamic_set_inputs():\n    model = Sequential()\n    model.add(Dense(16, input_dim=32))\n    model.add(Activation('relu'))\n\n    model2 = Sequential()\n    model2.add(model.layers[-1])\n    model2.add(Dense(8))\n    preds2 = model2.predict([np.random.random((1, 32))])\n    assert preds2.shape == (1, 8)\n\n    model3 = Model(inputs=model.inputs, outputs=model.outputs)\n    with pytest.raises(ValueError):\n        model3._set_inputs(model.inputs)\n\n    model3.inputs = None\n    model3._set_inputs(model.inputs)\n    preds3 = model3.predict([np.random.random((1, 32))])\n    assert preds3.shape == (1, 16)\n\n    model3.inputs = None\n    model3._set_inputs(model.input)\n    preds3 = model3.predict(np.random.random((1, 32)))\n    assert preds3.shape == (1, 16)\n\n    aux_input = Input(shape=(5,), name='aux_input')\n    aux_model = Dense(3)(aux_input)\n    model4 = Model(inputs=model.inputs + [aux_input],\n                   outputs=Concatenate()(model.outputs + [aux_model]))\n    model4.inputs = None\n    model4._set_inputs(model.inputs + [aux_input])\n    preds4 = model4.predict([np.random.random((1, 32)),\n                             np.random.random((1, 5))])\n    assert preds4.shape == (1, 19)",
        "begin_line": 1542,
        "end_line": 1575,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.engine.test_training.test_sample_weights#1578",
        "src_path": "tests/keras/engine/test_training.py",
        "class_name": "tests.keras.engine.test_training",
        "signature": "tests.keras.engine.test_training.test_sample_weights()",
        "snippet": "def test_sample_weights():\n    y = np.array([0, 1, 0, 0, 2])\n    sample_weights = np.array([0.5, 1., 1., 0., 2.])\n    class_weights = {0: 0.5, 1: 1., 2: 1.5}\n\n    # Only `sample_weights`.\n    weights = training_utils.standardize_weights(y, sample_weights)\n    assert np.allclose(weights, sample_weights)\n\n    # Only `class_weights`.\n    weights = training_utils.standardize_weights(y, class_weight=class_weights)\n    assert np.allclose(weights, np.array([0.5, 1., 0.5, 0.5, 1.5]))\n\n    # Both 'sample_weights` and 'class_weights`.\n    weights = training_utils.standardize_weights(y, sample_weights,\n                                                 class_weights)\n    expected = sample_weights * np.array([0.5, 1., 0.5, 0.5, 1.5])\n    assert np.allclose(weights, expected)",
        "begin_line": 1578,
        "end_line": 1595,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.conftest.clear_session_after_test#6",
        "src_path": "tests/conftest.py",
        "class_name": "tests.conftest",
        "signature": "tests.conftest.clear_session_after_test()",
        "snippet": "def clear_session_after_test():\n    \"\"\"Test wrapper to clean up after TensorFlow and CNTK tests.\n\n    This wrapper runs for all the tests in the keras test suite.\n    \"\"\"\n    yield\n    if K.backend() == 'tensorflow' or K.backend() == 'cntk':\n        K.clear_session()",
        "begin_line": 6,
        "end_line": 13,
        "comment": "",
        "is_bug": false
    }
]