[
    {
        "name": "pandas.tests.io.excel.conftest.frame#9",
        "src_path": "pandas/tests/io/excel/conftest.py",
        "class_name": "pandas.tests.io.excel.conftest",
        "signature": "pandas.tests.io.excel.conftest.frame(float_frame)",
        "snippet": "def frame(float_frame):\n    return float_frame[:10]",
        "begin_line": 9,
        "end_line": 10,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.excel.conftest.tsframe#14",
        "src_path": "pandas/tests/io/excel/conftest.py",
        "class_name": "pandas.tests.io.excel.conftest",
        "signature": "pandas.tests.io.excel.conftest.tsframe()",
        "snippet": "def tsframe():\n    return tm.makeTimeDataFrame()[:5]",
        "begin_line": 14,
        "end_line": 15,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.excel.conftest.merge_cells#19",
        "src_path": "pandas/tests/io/excel/conftest.py",
        "class_name": "pandas.tests.io.excel.conftest",
        "signature": "pandas.tests.io.excel.conftest.merge_cells(request)",
        "snippet": "def merge_cells(request):\n    return request.param",
        "begin_line": 19,
        "end_line": 20,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.excel.conftest.df_ref#24",
        "src_path": "pandas/tests/io/excel/conftest.py",
        "class_name": "pandas.tests.io.excel.conftest",
        "signature": "pandas.tests.io.excel.conftest.df_ref()",
        "snippet": "def df_ref():\n    \"\"\"\n    Obtain the reference data from read_csv with the Python engine.\n    \"\"\"\n    df_ref = read_csv(\"test1.csv\", index_col=0, parse_dates=True, engine=\"python\")\n    return df_ref",
        "begin_line": 24,
        "end_line": 29,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.excel.conftest.read_ext#33",
        "src_path": "pandas/tests/io/excel/conftest.py",
        "class_name": "pandas.tests.io.excel.conftest",
        "signature": "pandas.tests.io.excel.conftest.read_ext(request)",
        "snippet": "def read_ext(request):\n    \"\"\"\n    Valid extensions for reading Excel files.\n    \"\"\"\n    return request.param",
        "begin_line": 33,
        "end_line": 37,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_gcs.test_is_gcs_url#14",
        "src_path": "pandas/tests/io/test_gcs.py",
        "class_name": "pandas.tests.io.test_gcs",
        "signature": "pandas.tests.io.test_gcs.test_is_gcs_url()",
        "snippet": "def test_is_gcs_url():\n    assert is_gcs_url(\"gcs://pandas/somethingelse.com\")\n    assert is_gcs_url(\"gs://pandas/somethingelse.com\")\n    assert not is_gcs_url(\"s3://pandas/somethingelse.com\")",
        "begin_line": 14,
        "end_line": 17,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_gcs.test_read_csv_gcs#21",
        "src_path": "pandas/tests/io/test_gcs.py",
        "class_name": "pandas.tests.io.test_gcs",
        "signature": "pandas.tests.io.test_gcs.test_read_csv_gcs(monkeypatch)",
        "snippet": "def test_read_csv_gcs(monkeypatch):\n    df1 = DataFrame(\n        {\n            \"int\": [1, 3],\n            \"float\": [2.0, np.nan],\n            \"str\": [\"t\", \"s\"],\n            \"dt\": date_range(\"2018-06-18\", periods=2),\n        }\n    )\n\n    class MockGCSFileSystem:\n        def open(*args):\n            return StringIO(df1.to_csv(index=False))\n\n    monkeypatch.setattr(\"gcsfs.GCSFileSystem\", MockGCSFileSystem)\n    df2 = read_csv(\"gs://test/test.csv\", parse_dates=[\"dt\"])\n\n    assert_frame_equal(df1, df2)",
        "begin_line": 21,
        "end_line": 38,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_gcs.MockGCSFileSystem.test_read_csv_gcs#21",
        "src_path": "pandas/tests/io/test_gcs.py",
        "class_name": "pandas.tests.io.test_gcs.MockGCSFileSystem",
        "signature": "pandas.tests.io.test_gcs.MockGCSFileSystem.test_read_csv_gcs(monkeypatch)",
        "snippet": "def test_read_csv_gcs(monkeypatch):\n    df1 = DataFrame(\n        {\n            \"int\": [1, 3],\n            \"float\": [2.0, np.nan],\n            \"str\": [\"t\", \"s\"],\n            \"dt\": date_range(\"2018-06-18\", periods=2),\n        }\n    )\n\n    class MockGCSFileSystem:\n        def open(*args):\n            return StringIO(df1.to_csv(index=False))\n\n    monkeypatch.setattr(\"gcsfs.GCSFileSystem\", MockGCSFileSystem)\n    df2 = read_csv(\"gs://test/test.csv\", parse_dates=[\"dt\"])\n\n    assert_frame_equal(df1, df2)",
        "begin_line": 21,
        "end_line": 38,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_gcs.MockGCSFileSystem.open#32",
        "src_path": "pandas/tests/io/test_gcs.py",
        "class_name": "pandas.tests.io.test_gcs.MockGCSFileSystem",
        "signature": "pandas.tests.io.test_gcs.MockGCSFileSystem.open(*args)",
        "snippet": "        def open(*args):\n            return StringIO(df1.to_csv(index=False))",
        "begin_line": 32,
        "end_line": 33,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_gcs.test_to_csv_gcs#42",
        "src_path": "pandas/tests/io/test_gcs.py",
        "class_name": "pandas.tests.io.test_gcs",
        "signature": "pandas.tests.io.test_gcs.test_to_csv_gcs(monkeypatch)",
        "snippet": "def test_to_csv_gcs(monkeypatch):\n    df1 = DataFrame(\n        {\n            \"int\": [1, 3],\n            \"float\": [2.0, np.nan],\n            \"str\": [\"t\", \"s\"],\n            \"dt\": date_range(\"2018-06-18\", periods=2),\n        }\n    )\n    s = StringIO()\n\n    class MockGCSFileSystem:\n        def open(*args):\n            return s\n\n    monkeypatch.setattr(\"gcsfs.GCSFileSystem\", MockGCSFileSystem)\n    df1.to_csv(\"gs://test/test.csv\", index=True)\n    df2 = read_csv(StringIO(s.getvalue()), parse_dates=[\"dt\"], index_col=0)\n\n    assert_frame_equal(df1, df2)",
        "begin_line": 42,
        "end_line": 61,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_gcs.MockGCSFileSystem.test_to_csv_gcs#42",
        "src_path": "pandas/tests/io/test_gcs.py",
        "class_name": "pandas.tests.io.test_gcs.MockGCSFileSystem",
        "signature": "pandas.tests.io.test_gcs.MockGCSFileSystem.test_to_csv_gcs(monkeypatch)",
        "snippet": "def test_to_csv_gcs(monkeypatch):\n    df1 = DataFrame(\n        {\n            \"int\": [1, 3],\n            \"float\": [2.0, np.nan],\n            \"str\": [\"t\", \"s\"],\n            \"dt\": date_range(\"2018-06-18\", periods=2),\n        }\n    )\n    s = StringIO()\n\n    class MockGCSFileSystem:\n        def open(*args):\n            return s\n\n    monkeypatch.setattr(\"gcsfs.GCSFileSystem\", MockGCSFileSystem)\n    df1.to_csv(\"gs://test/test.csv\", index=True)\n    df2 = read_csv(StringIO(s.getvalue()), parse_dates=[\"dt\"], index_col=0)\n\n    assert_frame_equal(df1, df2)",
        "begin_line": 42,
        "end_line": 61,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_gcs.MockGCSFileSystem.open#54",
        "src_path": "pandas/tests/io/test_gcs.py",
        "class_name": "pandas.tests.io.test_gcs.MockGCSFileSystem",
        "signature": "pandas.tests.io.test_gcs.MockGCSFileSystem.open(*args)",
        "snippet": "        def open(*args):\n            return s",
        "begin_line": 54,
        "end_line": 55,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_gcs.test_to_parquet_gcs_new_file#66",
        "src_path": "pandas/tests/io/test_gcs.py",
        "class_name": "pandas.tests.io.test_gcs",
        "signature": "pandas.tests.io.test_gcs.test_to_parquet_gcs_new_file(monkeypatch, tmpdir)",
        "snippet": "def test_to_parquet_gcs_new_file(monkeypatch, tmpdir):\n    \"\"\"Regression test for writing to a not-yet-existent GCS Parquet file.\"\"\"\n    df1 = DataFrame(\n        {\n            \"int\": [1, 3],\n            \"float\": [2.0, np.nan],\n            \"str\": [\"t\", \"s\"],\n            \"dt\": date_range(\"2018-06-18\", periods=2),\n        }\n    )\n\n    class MockGCSFileSystem:\n        def open(self, path, mode=\"r\", *args):\n            if \"w\" not in mode:\n                raise FileNotFoundError\n            return open(os.path.join(tmpdir, \"test.parquet\"), mode)\n\n    monkeypatch.setattr(\"gcsfs.GCSFileSystem\", MockGCSFileSystem)\n    df1.to_parquet(\n        \"gs://test/test.csv\", index=True, engine=\"fastparquet\", compression=None\n    )",
        "begin_line": 66,
        "end_line": 86,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_gcs.MockGCSFileSystem.test_to_parquet_gcs_new_file#66",
        "src_path": "pandas/tests/io/test_gcs.py",
        "class_name": "pandas.tests.io.test_gcs.MockGCSFileSystem",
        "signature": "pandas.tests.io.test_gcs.MockGCSFileSystem.test_to_parquet_gcs_new_file(monkeypatch, tmpdir)",
        "snippet": "def test_to_parquet_gcs_new_file(monkeypatch, tmpdir):\n    \"\"\"Regression test for writing to a not-yet-existent GCS Parquet file.\"\"\"\n    df1 = DataFrame(\n        {\n            \"int\": [1, 3],\n            \"float\": [2.0, np.nan],\n            \"str\": [\"t\", \"s\"],\n            \"dt\": date_range(\"2018-06-18\", periods=2),\n        }\n    )\n\n    class MockGCSFileSystem:\n        def open(self, path, mode=\"r\", *args):\n            if \"w\" not in mode:\n                raise FileNotFoundError\n            return open(os.path.join(tmpdir, \"test.parquet\"), mode)\n\n    monkeypatch.setattr(\"gcsfs.GCSFileSystem\", MockGCSFileSystem)\n    df1.to_parquet(\n        \"gs://test/test.csv\", index=True, engine=\"fastparquet\", compression=None\n    )",
        "begin_line": 66,
        "end_line": 86,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_gcs.MockGCSFileSystem.open#78",
        "src_path": "pandas/tests/io/test_gcs.py",
        "class_name": "pandas.tests.io.test_gcs.MockGCSFileSystem",
        "signature": "pandas.tests.io.test_gcs.MockGCSFileSystem.open(self, path, mode='r', *args)",
        "snippet": "        def open(self, path, mode=\"r\", *args):\n            if \"w\" not in mode:\n                raise FileNotFoundError\n            return open(os.path.join(tmpdir, \"test.parquet\"), mode)",
        "begin_line": 78,
        "end_line": 81,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_gcs.test_gcs_get_filepath_or_buffer#90",
        "src_path": "pandas/tests/io/test_gcs.py",
        "class_name": "pandas.tests.io.test_gcs",
        "signature": "pandas.tests.io.test_gcs.test_gcs_get_filepath_or_buffer(monkeypatch)",
        "snippet": "def test_gcs_get_filepath_or_buffer(monkeypatch):\n    df1 = DataFrame(\n        {\n            \"int\": [1, 3],\n            \"float\": [2.0, np.nan],\n            \"str\": [\"t\", \"s\"],\n            \"dt\": date_range(\"2018-06-18\", periods=2),\n        }\n    )\n\n    def mock_get_filepath_or_buffer(*args, **kwargs):\n        return (StringIO(df1.to_csv(index=False)), None, None, False)\n\n    monkeypatch.setattr(\n        \"pandas.io.gcs.get_filepath_or_buffer\", mock_get_filepath_or_buffer\n    )\n    df2 = read_csv(\"gs://test/test.csv\", parse_dates=[\"dt\"])\n\n    assert_frame_equal(df1, df2)",
        "begin_line": 90,
        "end_line": 108,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_gcs.mock_get_filepath_or_buffer#100",
        "src_path": "pandas/tests/io/test_gcs.py",
        "class_name": "pandas.tests.io.test_gcs",
        "signature": "pandas.tests.io.test_gcs.mock_get_filepath_or_buffer(*args, **kwargs)",
        "snippet": "    def mock_get_filepath_or_buffer(*args, **kwargs):\n        return (StringIO(df1.to_csv(index=False)), None, None, False)",
        "begin_line": 100,
        "end_line": 101,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.test_gcs.test_gcs_not_present_exception#114",
        "src_path": "pandas/tests/io/test_gcs.py",
        "class_name": "pandas.tests.io.test_gcs",
        "signature": "pandas.tests.io.test_gcs.test_gcs_not_present_exception()",
        "snippet": "def test_gcs_not_present_exception():\n    with pytest.raises(ImportError) as e:\n        read_csv(\"gs://test/test.csv\")\n        assert \"gcsfs library is required\" in str(e.value)",
        "begin_line": 114,
        "end_line": 117,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.conftest.salaries_table#23",
        "src_path": "pandas/tests/io/conftest.py",
        "class_name": "pandas.tests.io.conftest",
        "signature": "pandas.tests.io.conftest.salaries_table(datapath)",
        "snippet": "def salaries_table(datapath):\n    \"\"\"DataFrame with the salaries dataset\"\"\"\n    return read_csv(datapath(\"io\", \"parser\", \"data\", \"salaries.csv\"), sep=\"\\t\")",
        "begin_line": 23,
        "end_line": 25,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.BaseParser.update_kwargs#13",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest.BaseParser",
        "signature": "pandas.tests.io.parser.conftest.BaseParser.update_kwargs(self, kwargs)",
        "snippet": "    def update_kwargs(self, kwargs):\n        kwargs = kwargs.copy()\n        kwargs.update(dict(engine=self.engine, low_memory=self.low_memory))\n\n        return kwargs",
        "begin_line": 13,
        "end_line": 17,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.BaseParser.read_csv#19",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest.BaseParser",
        "signature": "pandas.tests.io.parser.conftest.BaseParser.read_csv(self, *args, **kwargs)",
        "snippet": "    def read_csv(self, *args, **kwargs):\n        kwargs = self.update_kwargs(kwargs)\n        return read_csv(*args, **kwargs)",
        "begin_line": 19,
        "end_line": 21,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.BaseParser.read_table#23",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest.BaseParser",
        "signature": "pandas.tests.io.parser.conftest.BaseParser.read_table(self, *args, **kwargs)",
        "snippet": "    def read_table(self, *args, **kwargs):\n        kwargs = self.update_kwargs(kwargs)\n        return read_table(*args, **kwargs)",
        "begin_line": 23,
        "end_line": 25,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.csv_dir_path#47",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest",
        "signature": "pandas.tests.io.parser.conftest.csv_dir_path(datapath)",
        "snippet": "def csv_dir_path(datapath):\n    return datapath(\"io\", \"parser\", \"data\")",
        "begin_line": 47,
        "end_line": 48,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.csv1#52",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest",
        "signature": "pandas.tests.io.parser.conftest.csv1(csv_dir_path)",
        "snippet": "def csv1(csv_dir_path):\n    return os.path.join(csv_dir_path, \"test1.csv\")",
        "begin_line": 52,
        "end_line": 53,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.all_parsers#70",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest",
        "signature": "pandas.tests.io.parser.conftest.all_parsers(request)",
        "snippet": "def all_parsers(request):\n    return request.param",
        "begin_line": 70,
        "end_line": 71,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.c_parser_only#75",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest",
        "signature": "pandas.tests.io.parser.conftest.c_parser_only(request)",
        "snippet": "def c_parser_only(request):\n    return request.param",
        "begin_line": 75,
        "end_line": 76,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.parser.conftest.python_parser_only#80",
        "src_path": "pandas/tests/io/parser/conftest.py",
        "class_name": "pandas.tests.io.parser.conftest",
        "signature": "pandas.tests.io.parser.conftest.python_parser_only(request)",
        "snippet": "def python_parser_only(request):\n    return request.param",
        "begin_line": 80,
        "end_line": 81,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.json.conftest.orient#5",
        "src_path": "pandas/tests/io/json/conftest.py",
        "class_name": "pandas.tests.io.json.conftest",
        "signature": "pandas.tests.io.json.conftest.orient(request)",
        "snippet": "def orient(request):\n    \"\"\"\n    Fixture for orients excluding the table format.\n    \"\"\"\n    return request.param",
        "begin_line": 5,
        "end_line": 9,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files._create_sp_series#97",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files._create_sp_series()",
        "snippet": "def _create_sp_series():\n    nan = np.nan\n\n    # nan-based\n    arr = np.arange(15, dtype=np.float64)\n    arr[7:12] = nan\n    arr[-1:] = nan\n\n    bseries = Series(SparseArray(arr, kind=\"block\"))\n    bseries.name = \"bseries\"\n    return bseries",
        "begin_line": 97,
        "end_line": 107,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files._create_sp_tsseries#110",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files._create_sp_tsseries()",
        "snippet": "def _create_sp_tsseries():\n    nan = np.nan\n\n    # nan-based\n    arr = np.arange(15, dtype=np.float64)\n    arr[7:12] = nan\n    arr[-1:] = nan\n\n    date_index = bdate_range(\"1/1/2011\", periods=len(arr))\n    bseries = Series(SparseArray(arr, kind=\"block\"), index=date_index)\n    bseries.name = \"btsseries\"\n    return bseries",
        "begin_line": 110,
        "end_line": 121,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files._create_sp_frame#124",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files._create_sp_frame()",
        "snippet": "def _create_sp_frame():\n    nan = np.nan\n\n    data = {\n        \"A\": [nan, nan, nan, 0, 1, 2, 3, 4, 5, 6],\n        \"B\": [0, 1, 2, nan, nan, nan, 3, 4, 5, 6],\n        \"C\": np.arange(10).astype(np.int64),\n        \"D\": [0, 1, 2, 3, 4, 5, nan, nan, nan, nan],\n    }\n\n    dates = bdate_range(\"1/1/2011\", periods=10)\n    return DataFrame(data, index=dates).apply(SparseArray)",
        "begin_line": 124,
        "end_line": 135,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files.create_data#138",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files.create_data()",
        "snippet": "def create_data():\n    \"\"\" create the pickle/msgpack data \"\"\"\n\n    data = {\n        \"A\": [0.0, 1.0, 2.0, 3.0, np.nan],\n        \"B\": [0, 1, 0, 1, 0],\n        \"C\": [\"foo1\", \"foo2\", \"foo3\", \"foo4\", \"foo5\"],\n        \"D\": date_range(\"1/1/2009\", periods=5),\n        \"E\": [0.0, 1, Timestamp(\"20100101\"), \"foo\", 2.0],\n    }\n\n    scalars = dict(timestamp=Timestamp(\"20130101\"), period=Period(\"2012\", \"M\"))\n\n    index = dict(\n        int=Index(np.arange(10)),\n        date=date_range(\"20130101\", periods=10),\n        period=period_range(\"2013-01-01\", freq=\"M\", periods=10),\n        float=Index(np.arange(10, dtype=np.float64)),\n        uint=Index(np.arange(10, dtype=np.uint64)),\n        timedelta=timedelta_range(\"00:00:00\", freq=\"30T\", periods=10),\n    )\n\n    index[\"range\"] = RangeIndex(10)\n\n    if _loose_version >= LooseVersion(\"0.21\"):\n        from pandas import interval_range\n\n        index[\"interval\"] = interval_range(0, periods=10)\n\n    mi = dict(\n        reg2=MultiIndex.from_tuples(\n            tuple(\n                zip(\n                    *[\n                        [\"bar\", \"bar\", \"baz\", \"baz\", \"foo\", \"foo\", \"qux\", \"qux\"],\n                        [\"one\", \"two\", \"one\", \"two\", \"one\", \"two\", \"one\", \"two\"],\n                    ]\n                )\n            ),\n            names=[\"first\", \"second\"],\n        )\n    )\n\n    series = dict(\n        float=Series(data[\"A\"]),\n        int=Series(data[\"B\"]),\n        mixed=Series(data[\"E\"]),\n        ts=Series(\n            np.arange(10).astype(np.int64), index=date_range(\"20130101\", periods=10)\n        ),\n        mi=Series(\n            np.arange(5).astype(np.float64),\n            index=MultiIndex.from_tuples(\n                tuple(zip(*[[1, 1, 2, 2, 2], [3, 4, 3, 4, 5]])), names=[\"one\", \"two\"]\n            ),\n        ),\n        dup=Series(np.arange(5).astype(np.float64), index=[\"A\", \"B\", \"C\", \"D\", \"A\"]),\n        cat=Series(Categorical([\"foo\", \"bar\", \"baz\"])),\n        dt=Series(date_range(\"20130101\", periods=5)),\n        dt_tz=Series(date_range(\"20130101\", periods=5, tz=\"US/Eastern\")),\n        period=Series([Period(\"2000Q1\")] * 5),\n    )\n\n    mixed_dup_df = DataFrame(data)\n    mixed_dup_df.columns = list(\"ABCDA\")\n    frame = dict(\n        float=DataFrame({\"A\": series[\"float\"], \"B\": series[\"float\"] + 1}),\n        int=DataFrame({\"A\": series[\"int\"], \"B\": series[\"int\"] + 1}),\n        mixed=DataFrame({k: data[k] for k in [\"A\", \"B\", \"C\", \"D\"]}),\n        mi=DataFrame(\n            {\"A\": np.arange(5).astype(np.float64), \"B\": np.arange(5).astype(np.int64)},\n            index=MultiIndex.from_tuples(\n                tuple(\n                    zip(\n                        *[\n                            [\"bar\", \"bar\", \"baz\", \"baz\", \"baz\"],\n                            [\"one\", \"two\", \"one\", \"two\", \"three\"],\n                        ]\n                    )\n                ),\n                names=[\"first\", \"second\"],\n            ),\n        ),\n        dup=DataFrame(\n            np.arange(15).reshape(5, 3).astype(np.float64), columns=[\"A\", \"B\", \"A\"]\n        ),\n        cat_onecol=DataFrame({\"A\": Categorical([\"foo\", \"bar\"])}),\n        cat_and_float=DataFrame(\n            {\n                \"A\": Categorical([\"foo\", \"bar\", \"baz\"]),\n                \"B\": np.arange(3).astype(np.int64),\n            }\n        ),\n        mixed_dup=mixed_dup_df,\n        dt_mixed_tzs=DataFrame(\n            {\n                \"A\": Timestamp(\"20130102\", tz=\"US/Eastern\"),\n                \"B\": Timestamp(\"20130603\", tz=\"CET\"),\n            },\n            index=range(5),\n        ),\n        dt_mixed2_tzs=DataFrame(\n            {\n                \"A\": Timestamp(\"20130102\", tz=\"US/Eastern\"),\n                \"B\": Timestamp(\"20130603\", tz=\"CET\"),\n                \"C\": Timestamp(\"20130603\", tz=\"UTC\"),\n            },\n            index=range(5),\n        ),\n    )\n\n    cat = dict(\n        int8=Categorical(list(\"abcdefg\")),\n        int16=Categorical(np.arange(1000)),\n        int32=Categorical(np.arange(10000)),\n    )\n\n    timestamp = dict(\n        normal=Timestamp(\"2011-01-01\"),\n        nat=NaT,\n        tz=Timestamp(\"2011-01-01\", tz=\"US/Eastern\"),\n    )\n\n    timestamp[\"freq\"] = Timestamp(\"2011-01-01\", freq=\"D\")\n    timestamp[\"both\"] = Timestamp(\"2011-01-01\", tz=\"Asia/Tokyo\", freq=\"M\")\n\n    off = {\n        \"DateOffset\": DateOffset(years=1),\n        \"DateOffset_h_ns\": DateOffset(hour=6, nanoseconds=5824),\n        \"BusinessDay\": BusinessDay(offset=timedelta(seconds=9)),\n        \"BusinessHour\": BusinessHour(normalize=True, n=6, end=\"15:14\"),\n        \"CustomBusinessDay\": CustomBusinessDay(weekmask=\"Mon Fri\"),\n        \"SemiMonthBegin\": SemiMonthBegin(day_of_month=9),\n        \"SemiMonthEnd\": SemiMonthEnd(day_of_month=24),\n        \"MonthBegin\": MonthBegin(1),\n        \"MonthEnd\": MonthEnd(1),\n        \"QuarterBegin\": QuarterBegin(1),\n        \"QuarterEnd\": QuarterEnd(1),\n        \"Day\": Day(1),\n        \"YearBegin\": YearBegin(1),\n        \"YearEnd\": YearEnd(1),\n        \"Week\": Week(1),\n        \"Week_Tues\": Week(2, normalize=False, weekday=1),\n        \"WeekOfMonth\": WeekOfMonth(week=3, weekday=4),\n        \"LastWeekOfMonth\": LastWeekOfMonth(n=1, weekday=3),\n        \"FY5253\": FY5253(n=2, weekday=6, startingMonth=7, variation=\"last\"),\n        \"Easter\": Easter(),\n        \"Hour\": Hour(1),\n        \"Minute\": Minute(1),\n    }\n\n    return dict(\n        series=series,\n        frame=frame,\n        index=index,\n        scalars=scalars,\n        mi=mi,\n        sp_series=dict(float=_create_sp_series(), ts=_create_sp_tsseries()),\n        sp_frame=dict(float=_create_sp_frame()),\n        cat=cat,\n        timestamp=timestamp,\n        offsets=off,\n    )",
        "begin_line": 138,
        "end_line": 300,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files.create_pickle_data#303",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files.create_pickle_data()",
        "snippet": "def create_pickle_data():\n    data = create_data()\n\n    return data",
        "begin_line": 303,
        "end_line": 306,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files._u#309",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files._u(x)",
        "snippet": "def _u(x):\n    return {k: _u(x[k]) for k in x} if isinstance(x, dict) else x",
        "begin_line": 309,
        "end_line": 310,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files.create_msgpack_data#313",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files.create_msgpack_data()",
        "snippet": "def create_msgpack_data():\n    data = create_data()\n    # Not supported\n    del data[\"sp_series\"]\n    del data[\"sp_frame\"]\n    del data[\"series\"][\"cat\"]\n    del data[\"series\"][\"period\"]\n    del data[\"frame\"][\"cat_onecol\"]\n    del data[\"frame\"][\"cat_and_float\"]\n    del data[\"scalars\"][\"period\"]\n    if _loose_version >= LooseVersion(\"0.21\") and (\n        _loose_version < LooseVersion(\"0.23.0\")\n    ):\n        del data[\"index\"][\"interval\"]\n    del data[\"offsets\"]\n    return _u(data)",
        "begin_line": 313,
        "end_line": 328,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files.platform_name#331",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files.platform_name()",
        "snippet": "def platform_name():\n    return \"_\".join(\n        [\n            str(pandas.__version__),\n            str(pl.machine()),\n            str(pl.system().lower()),\n            str(pl.python_version()),\n        ]\n    )",
        "begin_line": 331,
        "end_line": 339,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files.write_legacy_pickles#342",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files.write_legacy_pickles(output_dir)",
        "snippet": "def write_legacy_pickles(output_dir):\n\n    version = pandas.__version__\n\n    print(\n        \"This script generates a storage file for the current arch, system, \"\n        \"and python version\"\n    )\n    print(\"  pandas version: {0}\".format(version))\n    print(\"  output dir    : {0}\".format(output_dir))\n    print(\"  storage format: pickle\")\n\n    pth = \"{0}.pickle\".format(platform_name())\n\n    fh = open(os.path.join(output_dir, pth), \"wb\")\n    pickle.dump(create_pickle_data(), fh, pickle.HIGHEST_PROTOCOL)\n    fh.close()\n\n    print(\"created pickle file: {pth}\".format(pth=pth))",
        "begin_line": 342,
        "end_line": 360,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files.write_legacy_msgpack#363",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files.write_legacy_msgpack(output_dir, compress)",
        "snippet": "def write_legacy_msgpack(output_dir, compress):\n\n    version = pandas.__version__\n\n    print(\n        \"This script generates a storage file for the current arch, \"\n        \"system, and python version\"\n    )\n    print(\"  pandas version: {0}\".format(version))\n    print(\"  output dir    : {0}\".format(output_dir))\n    print(\"  storage format: msgpack\")\n    pth = \"{0}.msgpack\".format(platform_name())\n    to_msgpack(os.path.join(output_dir, pth), create_msgpack_data(), compress=compress)\n\n    print(\"created msgpack file: {pth}\".format(pth=pth))",
        "begin_line": 363,
        "end_line": 377,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "pandas.tests.io.generate_legacy_storage_files.write_legacy_file#380",
        "src_path": "pandas/tests/io/generate_legacy_storage_files.py",
        "class_name": "pandas.tests.io.generate_legacy_storage_files",
        "signature": "pandas.tests.io.generate_legacy_storage_files.write_legacy_file()",
        "snippet": "def write_legacy_file():\n    # force our cwd to be the first searched\n    sys.path.insert(0, \".\")\n\n    if not (3 <= len(sys.argv) <= 4):\n        exit(\n            \"Specify output directory and storage type: generate_legacy_\"\n            \"storage_files.py <output_dir> <storage_type> \"\n            \"<msgpack_compress_type>\"\n        )\n\n    output_dir = str(sys.argv[1])\n    storage_type = str(sys.argv[2])\n    try:\n        compress_type = str(sys.argv[3])\n    except IndexError:\n        compress_type = None\n\n    if storage_type == \"pickle\":\n        write_legacy_pickles(output_dir=output_dir)\n    elif storage_type == \"msgpack\":\n        write_legacy_msgpack(output_dir=output_dir, compress=compress_type)\n    else:\n        exit(\"storage_type must be one of {'pickle', 'msgpack'}\")",
        "begin_line": 380,
        "end_line": 403,
        "comment": "",
        "is_bug": false
    }
]