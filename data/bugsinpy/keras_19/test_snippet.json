[
    {
        "name": "tests.keras.backend.reference_operations.wrapper#12",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.wrapper(*args, **kwargs)",
        "snippet": "    def wrapper(*args, **kwargs):\n        x = args[0]\n        w = args[1]\n        if x.ndim == 3:\n            w = np.flipud(w)\n            w = np.transpose(w, (1, 2, 0))\n            if kwargs['data_format'] == 'channels_last':\n                x = np.transpose(x, (0, 2, 1))\n        elif x.ndim == 4:\n            w = np.fliplr(np.flipud(w))\n            w = np.transpose(w, (2, 3, 0, 1))\n            if kwargs['data_format'] == 'channels_last':\n                x = np.transpose(x, (0, 3, 1, 2))\n        else:\n            w = np.flip(np.fliplr(np.flipud(w)), axis=2)\n            w = np.transpose(w, (3, 4, 0, 1, 2))\n            if kwargs['data_format'] == 'channels_last':\n                x = np.transpose(x, (0, 4, 1, 2, 3))\n\n        y = func(x, w, **kwargs)\n\n        if kwargs['data_format'] == 'channels_last':\n            if y.ndim == 3:\n                y = np.transpose(y, (0, 2, 1))\n            elif y.ndim == 4:\n                y = np.transpose(y, (0, 2, 3, 1))\n            else:\n                y = np.transpose(y, (0, 2, 3, 4, 1))\n\n        return y",
        "begin_line": 12,
        "end_line": 41,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.conv#47",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.conv(x, w, padding, data_format)",
        "snippet": "def conv(x, w, padding, data_format):\n    y = []\n    for i in range(x.shape[0]):\n        _y = []\n        for j in range(w.shape[1]):\n            __y = []\n            for k in range(w.shape[0]):\n                __y.append(signal.convolve(x[i, k], w[k, j], mode=padding))\n            _y.append(np.sum(np.stack(__y, axis=-1), axis=-1))\n        y.append(_y)\n    y = np.array(y)\n    return y",
        "begin_line": 47,
        "end_line": 58,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.depthwise_conv#62",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.depthwise_conv(x, w, padding, data_format)",
        "snippet": "def depthwise_conv(x, w, padding, data_format):\n    y = []\n    for i in range(x.shape[0]):\n        _y = []\n        for j in range(w.shape[0]):\n            __y = []\n            for k in range(w.shape[1]):\n                __y.append(signal.convolve(x[i, j], w[j, k], mode=padding))\n            _y.append(np.stack(__y, axis=0))\n        y.append(np.concatenate(_y, axis=0))\n    y = np.array(y)\n    return y",
        "begin_line": 62,
        "end_line": 73,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.separable_conv#76",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.separable_conv(x, w1, w2, padding, data_format)",
        "snippet": "def separable_conv(x, w1, w2, padding, data_format):\n    x2 = depthwise_conv(x, w1, padding=padding, data_format=data_format)\n    return conv(x2, w2, padding=padding, data_format=data_format)",
        "begin_line": 76,
        "end_line": 78,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.pool#89",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.pool(x, pool_size, strides, padding, data_format, pool_mode)",
        "snippet": "def pool(x, pool_size, strides, padding, data_format, pool_mode):\n    if data_format == 'channels_last':\n        if x.ndim == 3:\n            x = np.transpose(x, (0, 2, 1))\n        elif x.ndim == 4:\n            x = np.transpose(x, (0, 3, 1, 2))\n        else:\n            x = np.transpose(x, (0, 4, 1, 2, 3))\n\n    if padding == 'same':\n        pad = [(0, 0), (0, 0)] + [(s // 2, s // 2) for s in pool_size]\n        x = np.pad(x, pad, 'constant', constant_values=-np.inf)\n\n    # indexing trick\n    x = np.pad(x, [(0, 0), (0, 0)] + [(0, 1) for _ in pool_size],\n               'constant', constant_values=0)\n\n    if x.ndim == 3:\n        y = [x[:, :, k:k1:strides[0]]\n             for (k, k1) in zip(range(pool_size[0]), range(-pool_size[0], 0))]\n    elif x.ndim == 4:\n        y = []\n        for (k, k1) in zip(range(pool_size[0]), range(-pool_size[0], 0)):\n            for (l, l1) in zip(range(pool_size[1]), range(-pool_size[1], 0)):\n                y.append(x[:, :, k:k1:strides[0], l:l1:strides[1]])\n    else:\n        y = []\n        for (k, k1) in zip(range(pool_size[0]), range(-pool_size[0], 0)):\n            for (l, l1) in zip(range(pool_size[1]), range(-pool_size[1], 0)):\n                for (m, m1) in zip(range(pool_size[2]), range(-pool_size[2], 0)):\n                    y.append(x[:,\n                               :,\n                               k:k1:strides[0],\n                               l:l1:strides[1],\n                               m:m1:strides[2]])\n    y = np.stack(y, axis=-1)\n    if pool_mode == 'avg':\n        y = np.mean(np.ma.masked_invalid(y), axis=-1).data\n    elif pool_mode == 'max':\n        y = np.max(y, axis=-1)\n\n    if data_format == 'channels_last':\n        if y.ndim == 3:\n            y = np.transpose(y, (0, 2, 1))\n        elif y.ndim == 4:\n            y = np.transpose(y, (0, 2, 3, 1))\n        else:\n            y = np.transpose(y, (0, 2, 3, 4, 1))\n\n    return y",
        "begin_line": 89,
        "end_line": 138,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.bias_add#145",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.bias_add(x, y, data_format)",
        "snippet": "def bias_add(x, y, data_format):\n    if data_format == 'channels_first':\n        if y.ndim > 1:\n            y = np.reshape(y, y.shape[::-1])\n        for _ in range(x.ndim - y.ndim - 1):\n            y = np.expand_dims(y, -1)\n    else:\n        for _ in range(x.ndim - y.ndim - 1):\n            y = np.expand_dims(y, 0)\n    return x + y",
        "begin_line": 145,
        "end_line": 154,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.rnn#157",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.rnn(x, w, init, go_backwards=False, mask=None, unroll=False, input_length=None)",
        "snippet": "def rnn(x, w, init, go_backwards=False, mask=None, unroll=False, input_length=None):\n    w_i, w_h, w_o = w\n    h = []\n    o = []\n\n    if go_backwards:\n        t_list = range(x.shape[1] - 1, -1, -1)\n    else:\n        t_list = range(x.shape[1])\n\n    if mask is not None:\n        from keras import backend as K\n        np_mask = K.eval(mask)\n    else:\n        np_mask = None\n\n    for (i, t) in enumerate(t_list):\n        h_t = np.dot(x[:, t], w_i)\n\n        if w_h is not None:\n            prev = h[i - 1] if i > 0 else init\n            h_t1 = np.dot(prev, w_h)\n            if np_mask is not None:\n                h_t1[np_mask[:, t] == 0] = prev[np_mask[:, t] == 0]\n        else:\n            h_t1 = 0\n\n        o_t = h_t + h_t1\n        if w_o is not None:\n            o_t = np.dot(o_t, w_o)\n        o.append(o_t)\n\n        if np_mask is not None:\n            h_t = h_t * np_mask[:, t].reshape(-1, 1)\n        h.append(h_t + h_t1)\n\n    return o[-1], np.stack(o, axis=1), np.stack(h, axis=1)",
        "begin_line": 157,
        "end_line": 193,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.in_train_phase#208",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.in_train_phase(x, alt, training=None)",
        "snippet": "def in_train_phase(x, alt, training=None):\n    if training is None:\n        training = learning_phase()\n\n    if training is 1 or training is True:\n        if callable(x):\n            return x()\n        else:\n            return x\n    else:\n        if callable(alt):\n            return alt()\n        else:\n            return alt",
        "begin_line": 208,
        "end_line": 221,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.in_test_phase#224",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.in_test_phase(x, alt, training=None)",
        "snippet": "def in_test_phase(x, alt, training=None):\n    return in_train_phase(alt, x, training=training)",
        "begin_line": 224,
        "end_line": 225,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.relu#228",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.relu(x, alpha=0.0, max_value=None)",
        "snippet": "def relu(x, alpha=0., max_value=None):\n    y = x * (x > 0) + alpha * x * (x < 0)\n    if max_value is not None:\n        y = np.minimum(y, max_value)\n    return y",
        "begin_line": 228,
        "end_line": 232,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.switch#235",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.switch(condition, then_expression, else_expression)",
        "snippet": "def switch(condition, then_expression, else_expression):\n    cond_float = condition.astype(floatx())\n    while cond_float.ndim < then_expression.ndim:\n        cond_float = cond_float[..., None]\n    return cond_float * then_expression + (1 - cond_float) * else_expression",
        "begin_line": 235,
        "end_line": 239,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.softplus#242",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.softplus(x)",
        "snippet": "def softplus(x):\n    return np.log(1. + np.exp(x))",
        "begin_line": 242,
        "end_line": 243,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.elu#246",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.elu(x, alpha=1.0)",
        "snippet": "def elu(x, alpha=1.):\n    return x * (x > 0) + alpha * (np.exp(x) - 1.) * (x < 0)",
        "begin_line": 246,
        "end_line": 247,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.sigmoid#250",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.sigmoid(x)",
        "snippet": "def sigmoid(x):\n    return 1. / (1. + np.exp(-x))",
        "begin_line": 250,
        "end_line": 251,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.hard_sigmoid#254",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.hard_sigmoid(x)",
        "snippet": "def hard_sigmoid(x):\n    y = 0.2 * x + 0.5\n    y = np.minimum(y, 1.)\n    y = np.maximum(y, 0.)\n    return y",
        "begin_line": 254,
        "end_line": 258,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.tanh#261",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.tanh(x)",
        "snippet": "def tanh(x):\n    return np.tanh(x)",
        "begin_line": 261,
        "end_line": 262,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.softmax#265",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.softmax(x, axis=-1)",
        "snippet": "def softmax(x, axis=-1):\n    y = np.exp(x - np.max(x, axis, keepdims=True))\n    return y / np.sum(y, axis, keepdims=True)",
        "begin_line": 265,
        "end_line": 267,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.l2_normalize#270",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.l2_normalize(x, axis=-1)",
        "snippet": "def l2_normalize(x, axis=-1):\n    y = np.max(np.sum(x ** 2, axis, keepdims=True), axis, keepdims=True)\n    return x / np.sqrt(y)",
        "begin_line": 270,
        "end_line": 272,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.binary_crossentropy#275",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.binary_crossentropy(target, output, from_logits=False)",
        "snippet": "def binary_crossentropy(target, output, from_logits=False):\n    if not from_logits:\n        output = np.clip(output, 1e-7, 1 - 1e-7)\n        output = np.log(output / (1 - output))\n    return (target * -np.log(sigmoid(output)) +\n            (1 - target) * -np.log(1 - sigmoid(output)))",
        "begin_line": 275,
        "end_line": 280,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.categorical_crossentropy#283",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.categorical_crossentropy(target, output, from_logits=False)",
        "snippet": "def categorical_crossentropy(target, output, from_logits=False):\n    if from_logits:\n        output = softmax(output)\n    else:\n        output /= output.sum(axis=-1, keepdims=True)\n    output = np.clip(output, 1e-7, 1 - 1e-7)\n    return np.sum(target * -np.log(output), axis=-1, keepdims=False)",
        "begin_line": 283,
        "end_line": 289,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.max#292",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.max(x, axis=None, keepdims=False)",
        "snippet": "def max(x, axis=None, keepdims=False):\n    if isinstance(axis, list):\n        for a in axis:\n            x = np.max(x, axis=a, keepdims=keepdims)\n        return x\n    else:\n        return np.max(x, axis=axis, keepdims=keepdims)",
        "begin_line": 292,
        "end_line": 298,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.min#301",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.min(x, axis=None, keepdims=False)",
        "snippet": "def min(x, axis=None, keepdims=False):\n    if isinstance(axis, list):\n        for a in axis:\n            x = np.min(x, axis=a, keepdims=keepdims)\n        return x\n    else:\n        return np.min(x, axis=axis, keepdims=keepdims)",
        "begin_line": 301,
        "end_line": 307,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.mean#310",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.mean(x, axis=None, keepdims=False)",
        "snippet": "def mean(x, axis=None, keepdims=False):\n    if isinstance(axis, list):\n        for a in axis:\n            x = np.mean(x, axis=a, keepdims=keepdims)\n        return x\n    else:\n        return np.mean(x, axis=axis, keepdims=keepdims)",
        "begin_line": 310,
        "end_line": 316,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.std#319",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.std(x, axis=None, keepdims=False)",
        "snippet": "def std(x, axis=None, keepdims=False):\n    if isinstance(axis, list):\n        for a in axis:\n            x = np.std(x, axis=a, keepdims=keepdims)\n        return x\n    else:\n        return np.std(x, axis=axis, keepdims=keepdims)",
        "begin_line": 319,
        "end_line": 325,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.prod#337",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.prod(x, axis=None, keepdims=False)",
        "snippet": "def prod(x, axis=None, keepdims=False):\n    if isinstance(axis, list):\n        for a in axis:\n            x = np.prod(x, axis=a, keepdims=keepdims)\n        return x\n    else:\n        return np.prod(x, axis=axis, keepdims=keepdims)",
        "begin_line": 337,
        "end_line": 343,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.cumsum#346",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.cumsum(x, axis=0)",
        "snippet": "def cumsum(x, axis=0):\n    return np.cumsum(x, axis=axis)",
        "begin_line": 346,
        "end_line": 347,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.cumprod#350",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.cumprod(x, axis=0)",
        "snippet": "def cumprod(x, axis=0):\n    return np.cumprod(x, axis=axis)",
        "begin_line": 350,
        "end_line": 351,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.any#354",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.any(x, axis=None, keepdims=False)",
        "snippet": "def any(x, axis=None, keepdims=False):\n    return np.any(x, axis=axis, keepdims=keepdims)",
        "begin_line": 354,
        "end_line": 355,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.all#358",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.all(x, axis=None, keepdims=False)",
        "snippet": "def all(x, axis=None, keepdims=False):\n    return np.all(x, axis=axis, keepdims=keepdims)",
        "begin_line": 358,
        "end_line": 359,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.argmax#362",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.argmax(x, axis=-1)",
        "snippet": "def argmax(x, axis=-1):\n    return np.argmax(x, axis=axis)",
        "begin_line": 362,
        "end_line": 363,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.argmin#366",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.argmin(x, axis=-1)",
        "snippet": "def argmin(x, axis=-1):\n    return np.argmin(x, axis=axis)",
        "begin_line": 366,
        "end_line": 367,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.sqrt#370",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.sqrt(x)",
        "snippet": "def sqrt(x):\n    y = np.sqrt(x)\n    y[np.isnan(y)] = 0.\n    return y",
        "begin_line": 370,
        "end_line": 373,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.pow#376",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.pow(x, a=1.0)",
        "snippet": "def pow(x, a=1.):\n    return np.power(x, a)",
        "begin_line": 376,
        "end_line": 377,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.clip#380",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.clip(x, min_value, max_value)",
        "snippet": "def clip(x, min_value, max_value):\n    return np.clip(x, min_value, max_value)",
        "begin_line": 380,
        "end_line": 381,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.concatenate#384",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.concatenate(tensors, axis=-1)",
        "snippet": "def concatenate(tensors, axis=-1):\n    return np.concatenate(tensors, axis)",
        "begin_line": 384,
        "end_line": 385,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.permute_dimensions#388",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.permute_dimensions(x, pattern)",
        "snippet": "def permute_dimensions(x, pattern):\n    return np.transpose(x, pattern)",
        "begin_line": 388,
        "end_line": 389,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.reshape#392",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.reshape(x, shape)",
        "snippet": "def reshape(x, shape):\n    return np.reshape(x, shape)",
        "begin_line": 392,
        "end_line": 393,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.repeat_elements#396",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.repeat_elements(x, rep, axis)",
        "snippet": "def repeat_elements(x, rep, axis):\n    return np.repeat(x, rep, axis=axis)",
        "begin_line": 396,
        "end_line": 397,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.repeat#400",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.repeat(x, n)",
        "snippet": "def repeat(x, n):\n    y = np.expand_dims(x, 1)\n    y = np.repeat(y, n, axis=1)\n    return y",
        "begin_line": 400,
        "end_line": 403,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.arange#406",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.arange(start, stop=None, step=1, dtype='int32')",
        "snippet": "def arange(start, stop=None, step=1, dtype='int32'):\n    return np.arange(start, stop, step, dtype)",
        "begin_line": 406,
        "end_line": 407,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.flatten#410",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.flatten(x)",
        "snippet": "def flatten(x):\n    return np.reshape(x, (-1,))",
        "begin_line": 410,
        "end_line": 411,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.batch_flatten#414",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.batch_flatten(x)",
        "snippet": "def batch_flatten(x):\n    return np.reshape(x, (x.shape[0], -1))",
        "begin_line": 414,
        "end_line": 415,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.eval#418",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.eval(x)",
        "snippet": "def eval(x):\n    return x",
        "begin_line": 418,
        "end_line": 419,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.dtype#422",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.dtype(x)",
        "snippet": "def dtype(x):\n    return x.dtype.name",
        "begin_line": 422,
        "end_line": 423,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.constant#426",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.constant(value, dtype=None, shape=None, name=None)",
        "snippet": "def constant(value, dtype=None, shape=None, name=None):\n    if dtype is None:\n        dtype = floatx()\n    if shape is None:\n        shape = ()\n    np_value = value * np.ones(shape)\n    np_value.astype(dtype)\n    return np_value",
        "begin_line": 426,
        "end_line": 433,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.print_tensor#436",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.print_tensor(x, message='')",
        "snippet": "def print_tensor(x, message=''):\n    print(x, message)\n    return x",
        "begin_line": 436,
        "end_line": 438,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.eye#441",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.eye(size, dtype=None, name=None)",
        "snippet": "def eye(size, dtype=None, name=None):\n    return np.eye(size, dtype=dtype)",
        "begin_line": 441,
        "end_line": 442,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.dot#445",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.dot(x, y)",
        "snippet": "def dot(x, y):\n    return np.dot(x, y)",
        "begin_line": 445,
        "end_line": 446,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.transpose#449",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.transpose(x)",
        "snippet": "def transpose(x):\n    return np.transpose(x)",
        "begin_line": 449,
        "end_line": 450,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.reverse#453",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.reverse(x, axes)",
        "snippet": "def reverse(x, axes):\n    if isinstance(axes, int):\n        axes = [axes]\n    for a in axes:\n        x = np.flip(x, a)\n    return x",
        "begin_line": 453,
        "end_line": 458,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.variable#461",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.variable(value, dtype=None, name=None, constraint=None)",
        "snippet": "def variable(value, dtype=None, name=None, constraint=None):\n    if constraint is not None:\n        raise TypeError(\"Constraint must be None when \"\n                        \"using the NumPy backend.\")\n    return np.array(value, dtype)",
        "begin_line": 461,
        "end_line": 465,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.equal#468",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.equal(x, y)",
        "snippet": "def equal(x, y):\n    return x == y",
        "begin_line": 468,
        "end_line": 469,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.not_equal#472",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.not_equal(x, y)",
        "snippet": "def not_equal(x, y):\n    return x != y",
        "begin_line": 472,
        "end_line": 473,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.greater#476",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.greater(x, y)",
        "snippet": "def greater(x, y):\n    return x > y",
        "begin_line": 476,
        "end_line": 477,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.greater_equal#480",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.greater_equal(x, y)",
        "snippet": "def greater_equal(x, y):\n    return x >= y",
        "begin_line": 480,
        "end_line": 481,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.less#484",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.less(x, y)",
        "snippet": "def less(x, y):\n    return x < y",
        "begin_line": 484,
        "end_line": 485,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.less_equal#488",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.less_equal(x, y)",
        "snippet": "def less_equal(x, y):\n    return x <= y",
        "begin_line": 488,
        "end_line": 489,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.maximum#492",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.maximum(x, y)",
        "snippet": "def maximum(x, y):\n    return np.maximum(x, y)",
        "begin_line": 492,
        "end_line": 493,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.minimum#496",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.minimum(x, y)",
        "snippet": "def minimum(x, y):\n    return np.minimum(x, y)",
        "begin_line": 496,
        "end_line": 497,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.random_uniform_variable#500",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.random_uniform_variable(shape, low, high, dtype=None, name=None, seed=None)",
        "snippet": "def random_uniform_variable(shape, low, high, dtype=None, name=None, seed=None):\n    return (high - low) * np.random.random(shape).astype(dtype) + low",
        "begin_line": 500,
        "end_line": 501,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.random_normal_variable#504",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.random_normal_variable(shape, mean, scale, dtype=None, name=None, seed=None)",
        "snippet": "def random_normal_variable(shape, mean, scale, dtype=None, name=None, seed=None):\n    return scale * np.random.randn(*shape).astype(dtype) + mean",
        "begin_line": 504,
        "end_line": 505,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.resize_images#508",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.resize_images(x, height_factor, width_factor, data_format)",
        "snippet": "def resize_images(x, height_factor, width_factor, data_format):\n    if data_format == 'channels_first':\n        x = repeat_elements(x, height_factor, axis=2)\n        x = repeat_elements(x, width_factor, axis=3)\n    elif data_format == 'channels_last':\n        x = repeat_elements(x, height_factor, axis=1)\n        x = repeat_elements(x, width_factor, axis=2)\n    return x",
        "begin_line": 508,
        "end_line": 515,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.backend.reference_operations.resize_volumes#518",
        "src_path": "tests/keras/backend/reference_operations.py",
        "class_name": "tests.keras.backend.reference_operations",
        "signature": "tests.keras.backend.reference_operations.resize_volumes(x, depth_factor, height_factor, width_factor, data_format)",
        "snippet": "def resize_volumes(x, depth_factor, height_factor, width_factor, data_format):\n    if data_format == 'channels_first':\n        x = repeat_elements(x, depth_factor, axis=2)\n        x = repeat_elements(x, height_factor, axis=3)\n        x = repeat_elements(x, width_factor, axis=4)\n    elif data_format == 'channels_last':\n        x = repeat_elements(x, depth_factor, axis=1)\n        x = repeat_elements(x, height_factor, axis=2)\n        x = repeat_elements(x, width_factor, axis=3)\n    return x",
        "begin_line": 518,
        "end_line": 527,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.rnn_test#22",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.rnn_test(f)",
        "snippet": "def rnn_test(f):\n    \"\"\"\n    All the recurrent layers share the same interface,\n    so we can run through them with a single function.\n    \"\"\"\n    f = keras_test(f)\n    return pytest.mark.parametrize('layer_class', [\n        recurrent.SimpleRNN,\n        recurrent.GRU,\n        recurrent.LSTM\n    ])(f)",
        "begin_line": 22,
        "end_line": 32,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.rnn_cell_test#36",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.rnn_cell_test(f)",
        "snippet": "def rnn_cell_test(f):\n    f = keras_test(f)\n    return pytest.mark.parametrize('cell_class', [\n        recurrent.SimpleRNNCell,\n        recurrent.GRUCell,\n        recurrent.LSTMCell\n    ])(f)",
        "begin_line": 36,
        "end_line": 42,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_return_sequences#46",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_return_sequences(layer_class)",
        "snippet": "def test_return_sequences(layer_class):\n    layer_test(layer_class,\n               kwargs={'units': units,\n                       'return_sequences': True},\n               input_shape=(num_samples, timesteps, embedding_dim))",
        "begin_line": 46,
        "end_line": 50,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_dynamic_behavior#54",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_dynamic_behavior(layer_class)",
        "snippet": "def test_dynamic_behavior(layer_class):\n    layer = layer_class(units, input_shape=(None, embedding_dim))\n    model = Sequential()\n    model.add(layer)\n    model.compile('sgd', 'mse')\n    x = np.random.random((num_samples, timesteps, embedding_dim))\n    y = np.random.random((num_samples, units))\n    model.train_on_batch(x, y)",
        "begin_line": 54,
        "end_line": 61,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_stateful_invalid_use#65",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_stateful_invalid_use(layer_class)",
        "snippet": "def test_stateful_invalid_use(layer_class):\n    layer = layer_class(units,\n                        stateful=True,\n                        batch_input_shape=(num_samples,\n                                           timesteps,\n                                           embedding_dim))\n    model = Sequential()\n    model.add(layer)\n    model.compile('sgd', 'mse')\n    x = np.random.random((num_samples * 2, timesteps, embedding_dim))\n    y = np.random.random((num_samples * 2, units))\n    with pytest.raises(ValueError):\n        model.fit(x, y)\n    with pytest.raises(ValueError):\n        model.predict(x, batch_size=num_samples + 1)",
        "begin_line": 65,
        "end_line": 79,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_dropout#85",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_dropout(layer_class)",
        "snippet": "def test_dropout(layer_class):\n    for unroll in [True, False]:\n        layer_test(layer_class,\n                   kwargs={'units': units,\n                           'dropout': 0.1,\n                           'recurrent_dropout': 0.1,\n                           'unroll': unroll},\n                   input_shape=(num_samples, timesteps, embedding_dim))\n\n        # Test that dropout is applied during training\n        x = K.ones((num_samples, timesteps, embedding_dim))\n        layer = layer_class(units, dropout=0.5, recurrent_dropout=0.5,\n                            input_shape=(timesteps, embedding_dim))\n        y = layer(x)\n        assert y._uses_learning_phase\n\n        y = layer(x, training=True)\n        assert not getattr(y, '_uses_learning_phase')\n\n        # Test that dropout is not applied during testing\n        x = np.random.random((num_samples, timesteps, embedding_dim))\n        layer = layer_class(units, dropout=0.5, recurrent_dropout=0.5,\n                            unroll=unroll,\n                            input_shape=(timesteps, embedding_dim))\n        model = Sequential([layer])\n        assert model.uses_learning_phase\n        y1 = model.predict(x)\n        y2 = model.predict(x)\n        assert_allclose(y1, y2)",
        "begin_line": 85,
        "end_line": 113,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_statefulness#117",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_statefulness(layer_class)",
        "snippet": "def test_statefulness(layer_class):\n    model = Sequential()\n    model.add(embeddings.Embedding(embedding_num, embedding_dim,\n                                   mask_zero=True,\n                                   input_length=timesteps,\n                                   batch_input_shape=(num_samples, timesteps)))\n    layer = layer_class(units, return_sequences=False,\n                        stateful=True,\n                        weights=None)\n    model.add(layer)\n    model.compile(optimizer='sgd', loss='mse')\n    out1 = model.predict(np.ones((num_samples, timesteps)))\n    assert(out1.shape == (num_samples, units))\n\n    # train once so that the states change\n    model.train_on_batch(np.ones((num_samples, timesteps)),\n                         np.ones((num_samples, units)))\n    out2 = model.predict(np.ones((num_samples, timesteps)))\n\n    # if the state is not reset, output should be different\n    assert(out1.max() != out2.max())\n\n    # check that output changes after states are reset\n    # (even though the model itself didn't change)\n    layer.reset_states()\n    out3 = model.predict(np.ones((num_samples, timesteps)))\n    assert(out2.max() != out3.max())\n\n    # check that container-level reset_states() works\n    model.reset_states()\n    out4 = model.predict(np.ones((num_samples, timesteps)))\n    assert_allclose(out3, out4, atol=1e-5)\n\n    # check that the call to `predict` updated the states\n    out5 = model.predict(np.ones((num_samples, timesteps)))\n    assert(out4.max() != out5.max())",
        "begin_line": 117,
        "end_line": 152,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_masking_correctness#156",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_masking_correctness(layer_class)",
        "snippet": "def test_masking_correctness(layer_class):\n    # Check masking: output with left padding and right padding\n    # should be the same.\n    model = Sequential()\n    model.add(embeddings.Embedding(embedding_num, embedding_dim,\n                                   mask_zero=True,\n                                   input_length=timesteps,\n                                   batch_input_shape=(num_samples, timesteps)))\n    layer = layer_class(units, return_sequences=False)\n    model.add(layer)\n    model.compile(optimizer='sgd', loss='mse')\n\n    left_padded_input = np.ones((num_samples, timesteps))\n    left_padded_input[0, :1] = 0\n    left_padded_input[1, :2] = 0\n    out6 = model.predict(left_padded_input)\n\n    right_padded_input = np.ones((num_samples, timesteps))\n    right_padded_input[0, -1:] = 0\n    right_padded_input[1, -2:] = 0\n    out7 = model.predict(right_padded_input)\n\n    assert_allclose(out7, out6, atol=1e-5)",
        "begin_line": 156,
        "end_line": 178,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_implementation_mode#182",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_implementation_mode(layer_class)",
        "snippet": "def test_implementation_mode(layer_class):\n    for mode in [1, 2]:\n        # Without dropout\n        layer_test(layer_class,\n                   kwargs={'units': units,\n                           'implementation': mode},\n                   input_shape=(num_samples, timesteps, embedding_dim))\n        # With dropout\n        layer_test(layer_class,\n                   kwargs={'units': units,\n                           'implementation': mode,\n                           'dropout': 0.1,\n                           'recurrent_dropout': 0.1},\n                   input_shape=(num_samples, timesteps, embedding_dim))\n        # Without bias\n        layer_test(layer_class,\n                   kwargs={'units': units,\n                           'implementation': mode,\n                           'use_bias': False},\n                   input_shape=(num_samples, timesteps, embedding_dim))",
        "begin_line": 182,
        "end_line": 201,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_regularizer#205",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_regularizer(layer_class)",
        "snippet": "def test_regularizer(layer_class):\n    layer = layer_class(units, return_sequences=False, weights=None,\n                        input_shape=(timesteps, embedding_dim),\n                        kernel_regularizer=regularizers.l1(0.01),\n                        recurrent_regularizer=regularizers.l1(0.01),\n                        bias_regularizer='l2')\n    layer.build((None, None, embedding_dim))\n    assert len(layer.losses) == 3\n    assert len(layer.cell.losses) == 3\n\n    layer = layer_class(units, return_sequences=False, weights=None,\n                        input_shape=(timesteps, embedding_dim),\n                        activity_regularizer='l2')\n    assert layer.activity_regularizer\n    x = K.variable(np.ones((num_samples, timesteps, embedding_dim)))\n    layer(x)\n    assert len(layer.cell.get_losses_for(x)) == 0\n    assert len(layer.get_losses_for(x)) == 1",
        "begin_line": 205,
        "end_line": 222,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_trainability#226",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_trainability(layer_class)",
        "snippet": "def test_trainability(layer_class):\n    layer = layer_class(units)\n    layer.build((None, None, embedding_dim))\n    assert len(layer.weights) == 3\n    assert len(layer.trainable_weights) == 3\n    assert len(layer.non_trainable_weights) == 0\n    layer.trainable = False\n    assert len(layer.weights) == 3\n    assert len(layer.trainable_weights) == 0\n    assert len(layer.non_trainable_weights) == 3\n    layer.trainable = True\n    assert len(layer.weights) == 3\n    assert len(layer.trainable_weights) == 3\n    assert len(layer.non_trainable_weights) == 0",
        "begin_line": 226,
        "end_line": 239,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_masking_layer#243",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_masking_layer()",
        "snippet": "def test_masking_layer():\n    ''' This test based on a previously failing issue here:\n    https://github.com/keras-team/keras/issues/1567\n    '''\n    inputs = np.random.random((6, 3, 4))\n    targets = np.abs(np.random.random((6, 3, 5)))\n    targets /= targets.sum(axis=-1, keepdims=True)\n\n    model = Sequential()\n    model.add(Masking(input_shape=(3, 4)))\n    model.add(recurrent.SimpleRNN(units=5, return_sequences=True, unroll=False))\n    model.compile(loss='categorical_crossentropy', optimizer='adam')\n    model.fit(inputs, targets, epochs=1, batch_size=100, verbose=1)\n\n    model = Sequential()\n    model.add(Masking(input_shape=(3, 4)))\n    model.add(recurrent.SimpleRNN(units=5, return_sequences=True, unroll=True))\n    model.compile(loss='categorical_crossentropy', optimizer='adam')\n    model.fit(inputs, targets, epochs=1, batch_size=100, verbose=1)",
        "begin_line": 243,
        "end_line": 261,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_from_config#265",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_from_config(layer_class)",
        "snippet": "def test_from_config(layer_class):\n    stateful_flags = (False, True)\n    for stateful in stateful_flags:\n        l1 = layer_class(units=1, stateful=stateful)\n        l2 = layer_class.from_config(l1.get_config())\n        assert l1.get_config() == l2.get_config()",
        "begin_line": 265,
        "end_line": 270,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_specify_initial_state_keras_tensor#274",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_specify_initial_state_keras_tensor(layer_class)",
        "snippet": "def test_specify_initial_state_keras_tensor(layer_class):\n    num_states = 2 if layer_class is recurrent.LSTM else 1\n\n    # Test with Keras tensor\n    inputs = Input((timesteps, embedding_dim))\n    initial_state = [Input((units,)) for _ in range(num_states)]\n    layer = layer_class(units)\n    if len(initial_state) == 1:\n        output = layer(inputs, initial_state=initial_state[0])\n    else:\n        output = layer(inputs, initial_state=initial_state)\n    assert initial_state[0] in layer._inbound_nodes[0].input_tensors\n\n    model = Model([inputs] + initial_state, output)\n    model.compile(loss='categorical_crossentropy', optimizer='adam')\n\n    inputs = np.random.random((num_samples, timesteps, embedding_dim))\n    initial_state = [np.random.random((num_samples, units))\n                     for _ in range(num_states)]\n    targets = np.random.random((num_samples, units))\n    model.fit([inputs] + initial_state, targets)",
        "begin_line": 274,
        "end_line": 294,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_specify_initial_state_non_keras_tensor#298",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_specify_initial_state_non_keras_tensor(layer_class)",
        "snippet": "def test_specify_initial_state_non_keras_tensor(layer_class):\n    num_states = 2 if layer_class is recurrent.LSTM else 1\n\n    # Test with non-Keras tensor\n    inputs = Input((timesteps, embedding_dim))\n    initial_state = [K.random_normal_variable((num_samples, units), 0, 1)\n                     for _ in range(num_states)]\n    layer = layer_class(units)\n    output = layer(inputs, initial_state=initial_state)\n\n    model = Model(inputs, output)\n    model.compile(loss='categorical_crossentropy', optimizer='adam')\n\n    inputs = np.random.random((num_samples, timesteps, embedding_dim))\n    targets = np.random.random((num_samples, units))\n    model.fit(inputs, targets)",
        "begin_line": 298,
        "end_line": 313,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_reset_states_with_values#317",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_reset_states_with_values(layer_class)",
        "snippet": "def test_reset_states_with_values(layer_class):\n    num_states = 2 if layer_class is recurrent.LSTM else 1\n\n    layer = layer_class(units, stateful=True)\n    layer.build((num_samples, timesteps, embedding_dim))\n    layer.reset_states()\n    assert len(layer.states) == num_states\n    assert layer.states[0] is not None\n    np.testing.assert_allclose(K.eval(layer.states[0]),\n                               np.zeros(K.int_shape(layer.states[0])),\n                               atol=1e-4)\n    state_shapes = [K.int_shape(state) for state in layer.states]\n    values = [np.ones(shape) for shape in state_shapes]\n    if len(values) == 1:\n        values = values[0]\n    layer.reset_states(values)\n    np.testing.assert_allclose(K.eval(layer.states[0]),\n                               np.ones(K.int_shape(layer.states[0])),\n                               atol=1e-4)\n\n    # Test fit with invalid data\n    with pytest.raises(ValueError):\n        layer.reset_states([1] * (len(layer.states) + 1))",
        "begin_line": 317,
        "end_line": 339,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_initial_states_as_other_inputs#343",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_initial_states_as_other_inputs(layer_class)",
        "snippet": "def test_initial_states_as_other_inputs(layer_class):\n    num_states = 2 if layer_class is recurrent.LSTM else 1\n\n    # Test with Keras tensor\n    main_inputs = Input((timesteps, embedding_dim))\n    initial_state = [Input((units,)) for _ in range(num_states)]\n    inputs = [main_inputs] + initial_state\n\n    layer = layer_class(units)\n    output = layer(inputs)\n    assert initial_state[0] in layer._inbound_nodes[0].input_tensors\n\n    model = Model(inputs, output)\n    model.compile(loss='categorical_crossentropy', optimizer='adam')\n\n    main_inputs = np.random.random((num_samples, timesteps, embedding_dim))\n    initial_state = [np.random.random((num_samples, units))\n                     for _ in range(num_states)]\n    targets = np.random.random((num_samples, units))\n    model.train_on_batch([main_inputs] + initial_state, targets)",
        "begin_line": 343,
        "end_line": 362,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_specify_state_with_masking#366",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_specify_state_with_masking(layer_class)",
        "snippet": "def test_specify_state_with_masking(layer_class):\n    ''' This test based on a previously failing issue here:\n    https://github.com/keras-team/keras/issues/1567\n    '''\n    num_states = 2 if layer_class is recurrent.LSTM else 1\n\n    inputs = Input((timesteps, embedding_dim))\n    _ = Masking()(inputs)\n    initial_state = [Input((units,)) for _ in range(num_states)]\n    output = layer_class(units)(inputs, initial_state=initial_state)\n\n    model = Model([inputs] + initial_state, output)\n    model.compile(loss='categorical_crossentropy', optimizer='adam')\n\n    inputs = np.random.random((num_samples, timesteps, embedding_dim))\n    initial_state = [np.random.random((num_samples, units))\n                     for _ in range(num_states)]\n    targets = np.random.random((num_samples, units))\n    model.fit([inputs] + initial_state, targets)",
        "begin_line": 366,
        "end_line": 384,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_return_state#388",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_return_state(layer_class)",
        "snippet": "def test_return_state(layer_class):\n    num_states = 2 if layer_class is recurrent.LSTM else 1\n\n    inputs = Input(batch_shape=(num_samples, timesteps, embedding_dim))\n    layer = layer_class(units, return_state=True, stateful=True)\n    outputs = layer(inputs)\n    output, state = outputs[0], outputs[1:]\n    assert len(state) == num_states\n    model = Model(inputs, state[0])\n\n    inputs = np.random.random((num_samples, timesteps, embedding_dim))\n    state = model.predict(inputs)\n    np.testing.assert_allclose(K.eval(layer.states[0]), state, atol=1e-4)",
        "begin_line": 388,
        "end_line": 400,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_state_reuse#404",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_state_reuse(layer_class)",
        "snippet": "def test_state_reuse(layer_class):\n    inputs = Input(batch_shape=(num_samples, timesteps, embedding_dim))\n    layer = layer_class(units, return_state=True, return_sequences=True)\n    outputs = layer(inputs)\n    output, state = outputs[0], outputs[1:]\n    output = layer_class(units)(output, initial_state=state)\n    model = Model(inputs, output)\n\n    inputs = np.random.random((num_samples, timesteps, embedding_dim))\n    outputs = model.predict(inputs)",
        "begin_line": 404,
        "end_line": 413,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_state_reuse_with_dropout#419",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_state_reuse_with_dropout(layer_class)",
        "snippet": "def test_state_reuse_with_dropout(layer_class):\n    input1 = Input(batch_shape=(num_samples, timesteps, embedding_dim))\n    layer = layer_class(units, return_state=True, return_sequences=True, dropout=0.2)\n    state = layer(input1)[1:]\n\n    input2 = Input(batch_shape=(num_samples, timesteps, embedding_dim))\n    output = layer_class(units)(input2, initial_state=state)\n    model = Model([input1, input2], output)\n\n    inputs = [np.random.random((num_samples, timesteps, embedding_dim)),\n              np.random.random((num_samples, timesteps, embedding_dim))]\n    outputs = model.predict(inputs)",
        "begin_line": 419,
        "end_line": 430,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_minimal_rnn_cell_non_layer#434",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_minimal_rnn_cell_non_layer()",
        "snippet": "def test_minimal_rnn_cell_non_layer():\n\n    class MinimalRNNCell(object):\n\n        def __init__(self, units, input_dim):\n            self.units = units\n            self.state_size = units\n            self.kernel = keras.backend.variable(\n                np.random.random((input_dim, units)))\n\n        def call(self, inputs, states):\n            prev_output = states[0]\n            output = keras.backend.dot(inputs, self.kernel) + prev_output\n            return output, [output]\n\n    # Basic test case.\n    cell = MinimalRNNCell(32, 5)\n    x = keras.Input((None, 5))\n    layer = recurrent.RNN(cell)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))\n\n    # Test stacking.\n    cells = [MinimalRNNCell(8, 5),\n             MinimalRNNCell(32, 8),\n             MinimalRNNCell(32, 32)]\n    layer = recurrent.RNN(cells)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))",
        "begin_line": 434,
        "end_line": 466,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.MinimalRNNCell.test_minimal_rnn_cell_non_layer#434",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.MinimalRNNCell",
        "signature": "tests.keras.layers.recurrent_test.MinimalRNNCell.test_minimal_rnn_cell_non_layer()",
        "snippet": "def test_minimal_rnn_cell_non_layer():\n\n    class MinimalRNNCell(object):\n\n        def __init__(self, units, input_dim):\n            self.units = units\n            self.state_size = units\n            self.kernel = keras.backend.variable(\n                np.random.random((input_dim, units)))\n\n        def call(self, inputs, states):\n            prev_output = states[0]\n            output = keras.backend.dot(inputs, self.kernel) + prev_output\n            return output, [output]\n\n    # Basic test case.\n    cell = MinimalRNNCell(32, 5)\n    x = keras.Input((None, 5))\n    layer = recurrent.RNN(cell)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))\n\n    # Test stacking.\n    cells = [MinimalRNNCell(8, 5),\n             MinimalRNNCell(32, 8),\n             MinimalRNNCell(32, 32)]\n    layer = recurrent.RNN(cells)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))",
        "begin_line": 434,
        "end_line": 466,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.MinimalRNNCell.__init__#438",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.MinimalRNNCell",
        "signature": "tests.keras.layers.recurrent_test.MinimalRNNCell.__init__(self, units, input_dim)",
        "snippet": "        def __init__(self, units, input_dim):\n            self.units = units\n            self.state_size = units\n            self.kernel = keras.backend.variable(\n                np.random.random((input_dim, units)))",
        "begin_line": 438,
        "end_line": 442,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.MinimalRNNCell.call#444",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.MinimalRNNCell",
        "signature": "tests.keras.layers.recurrent_test.MinimalRNNCell.call(self, inputs, states)",
        "snippet": "        def call(self, inputs, states):\n            prev_output = states[0]\n            output = keras.backend.dot(inputs, self.kernel) + prev_output\n            return output, [output]",
        "begin_line": 444,
        "end_line": 447,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_minimal_rnn_cell_non_layer_multiple_states#470",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_minimal_rnn_cell_non_layer_multiple_states()",
        "snippet": "def test_minimal_rnn_cell_non_layer_multiple_states():\n\n    class MinimalRNNCell(object):\n\n        def __init__(self, units, input_dim):\n            self.units = units\n            self.state_size = (units, units)\n            self.kernel = keras.backend.variable(\n                np.random.random((input_dim, units)))\n\n        def call(self, inputs, states):\n            prev_output_1 = states[0]\n            prev_output_2 = states[1]\n            output = keras.backend.dot(inputs, self.kernel)\n            output += prev_output_1\n            output -= prev_output_2\n            return output, [output * 2, output * 3]\n\n    # Basic test case.\n    cell = MinimalRNNCell(32, 5)\n    x = keras.Input((None, 5))\n    layer = recurrent.RNN(cell)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))\n\n    # Test stacking.\n    cells = [MinimalRNNCell(8, 5),\n             MinimalRNNCell(16, 8),\n             MinimalRNNCell(32, 16)]\n    layer = recurrent.RNN(cells)\n    assert layer.cell.state_size == (8, 8, 16, 16, 32, 32)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))",
        "begin_line": 470,
        "end_line": 506,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.MinimalRNNCell.test_minimal_rnn_cell_non_layer_multiple_states#470",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.MinimalRNNCell",
        "signature": "tests.keras.layers.recurrent_test.MinimalRNNCell.test_minimal_rnn_cell_non_layer_multiple_states()",
        "snippet": "def test_minimal_rnn_cell_non_layer_multiple_states():\n\n    class MinimalRNNCell(object):\n\n        def __init__(self, units, input_dim):\n            self.units = units\n            self.state_size = (units, units)\n            self.kernel = keras.backend.variable(\n                np.random.random((input_dim, units)))\n\n        def call(self, inputs, states):\n            prev_output_1 = states[0]\n            prev_output_2 = states[1]\n            output = keras.backend.dot(inputs, self.kernel)\n            output += prev_output_1\n            output -= prev_output_2\n            return output, [output * 2, output * 3]\n\n    # Basic test case.\n    cell = MinimalRNNCell(32, 5)\n    x = keras.Input((None, 5))\n    layer = recurrent.RNN(cell)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))\n\n    # Test stacking.\n    cells = [MinimalRNNCell(8, 5),\n             MinimalRNNCell(16, 8),\n             MinimalRNNCell(32, 16)]\n    layer = recurrent.RNN(cells)\n    assert layer.cell.state_size == (8, 8, 16, 16, 32, 32)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))",
        "begin_line": 470,
        "end_line": 506,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.MinimalRNNCell.__init__#474",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.MinimalRNNCell",
        "signature": "tests.keras.layers.recurrent_test.MinimalRNNCell.__init__(self, units, input_dim)",
        "snippet": "        def __init__(self, units, input_dim):\n            self.units = units\n            self.state_size = (units, units)\n            self.kernel = keras.backend.variable(\n                np.random.random((input_dim, units)))",
        "begin_line": 474,
        "end_line": 478,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.MinimalRNNCell.call#480",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.MinimalRNNCell",
        "signature": "tests.keras.layers.recurrent_test.MinimalRNNCell.call(self, inputs, states)",
        "snippet": "        def call(self, inputs, states):\n            prev_output_1 = states[0]\n            prev_output_2 = states[1]\n            output = keras.backend.dot(inputs, self.kernel)\n            output += prev_output_1\n            output -= prev_output_2\n            return output, [output * 2, output * 3]",
        "begin_line": 480,
        "end_line": 486,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_minimal_rnn_cell_layer#510",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_minimal_rnn_cell_layer()",
        "snippet": "def test_minimal_rnn_cell_layer():\n\n    class MinimalRNNCell(keras.layers.Layer):\n\n        def __init__(self, units, **kwargs):\n            self.units = units\n            self.state_size = units\n            super(MinimalRNNCell, self).__init__(**kwargs)\n\n        def build(self, input_shape):\n            # no time axis in the input shape passed to RNN cells\n            assert len(input_shape) == 2\n\n            self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n                                          initializer='uniform',\n                                          name='kernel')\n            self.recurrent_kernel = self.add_weight(\n                shape=(self.units, self.units),\n                initializer='uniform',\n                name='recurrent_kernel')\n            self.built = True\n\n        def call(self, inputs, states):\n            prev_output = states[0]\n            h = keras.backend.dot(inputs, self.kernel)\n            output = h + keras.backend.dot(prev_output, self.recurrent_kernel)\n            return output, [output]\n\n        def get_config(self):\n            config = {'units': self.units}\n            base_config = super(MinimalRNNCell, self).get_config()\n            return dict(list(base_config.items()) + list(config.items()))\n\n    # Test basic case.\n    x = keras.Input((None, 5))\n    cell = MinimalRNNCell(32)\n    layer = recurrent.RNN(cell)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))\n\n    # Test basic case serialization.\n    x_np = np.random.random((6, 5, 5))\n    y_np = model.predict(x_np)\n    weights = model.get_weights()\n    config = layer.get_config()\n    with keras.utils.CustomObjectScope({'MinimalRNNCell': MinimalRNNCell}):\n        layer = recurrent.RNN.from_config(config)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.set_weights(weights)\n    y_np_2 = model.predict(x_np)\n    assert_allclose(y_np, y_np_2, atol=1e-4)\n\n    # Test stacking.\n    cells = [MinimalRNNCell(8),\n             MinimalRNNCell(12),\n             MinimalRNNCell(32)]\n    layer = recurrent.RNN(cells)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))\n\n    # Test stacked RNN serialization.\n    x_np = np.random.random((6, 5, 5))\n    y_np = model.predict(x_np)\n    weights = model.get_weights()\n    config = layer.get_config()\n    with keras.utils.CustomObjectScope({'MinimalRNNCell': MinimalRNNCell}):\n        layer = recurrent.RNN.from_config(config)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.set_weights(weights)\n    y_np_2 = model.predict(x_np)\n    assert_allclose(y_np, y_np_2, atol=1e-4)",
        "begin_line": 510,
        "end_line": 586,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.MinimalRNNCell.test_minimal_rnn_cell_layer#510",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.MinimalRNNCell",
        "signature": "tests.keras.layers.recurrent_test.MinimalRNNCell.test_minimal_rnn_cell_layer()",
        "snippet": "def test_minimal_rnn_cell_layer():\n\n    class MinimalRNNCell(keras.layers.Layer):\n\n        def __init__(self, units, **kwargs):\n            self.units = units\n            self.state_size = units\n            super(MinimalRNNCell, self).__init__(**kwargs)\n\n        def build(self, input_shape):\n            # no time axis in the input shape passed to RNN cells\n            assert len(input_shape) == 2\n\n            self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n                                          initializer='uniform',\n                                          name='kernel')\n            self.recurrent_kernel = self.add_weight(\n                shape=(self.units, self.units),\n                initializer='uniform',\n                name='recurrent_kernel')\n            self.built = True\n\n        def call(self, inputs, states):\n            prev_output = states[0]\n            h = keras.backend.dot(inputs, self.kernel)\n            output = h + keras.backend.dot(prev_output, self.recurrent_kernel)\n            return output, [output]\n\n        def get_config(self):\n            config = {'units': self.units}\n            base_config = super(MinimalRNNCell, self).get_config()\n            return dict(list(base_config.items()) + list(config.items()))\n\n    # Test basic case.\n    x = keras.Input((None, 5))\n    cell = MinimalRNNCell(32)\n    layer = recurrent.RNN(cell)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))\n\n    # Test basic case serialization.\n    x_np = np.random.random((6, 5, 5))\n    y_np = model.predict(x_np)\n    weights = model.get_weights()\n    config = layer.get_config()\n    with keras.utils.CustomObjectScope({'MinimalRNNCell': MinimalRNNCell}):\n        layer = recurrent.RNN.from_config(config)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.set_weights(weights)\n    y_np_2 = model.predict(x_np)\n    assert_allclose(y_np, y_np_2, atol=1e-4)\n\n    # Test stacking.\n    cells = [MinimalRNNCell(8),\n             MinimalRNNCell(12),\n             MinimalRNNCell(32)]\n    layer = recurrent.RNN(cells)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))\n\n    # Test stacked RNN serialization.\n    x_np = np.random.random((6, 5, 5))\n    y_np = model.predict(x_np)\n    weights = model.get_weights()\n    config = layer.get_config()\n    with keras.utils.CustomObjectScope({'MinimalRNNCell': MinimalRNNCell}):\n        layer = recurrent.RNN.from_config(config)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.set_weights(weights)\n    y_np_2 = model.predict(x_np)\n    assert_allclose(y_np, y_np_2, atol=1e-4)",
        "begin_line": 510,
        "end_line": 586,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.MinimalRNNCell.__init__#514",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.MinimalRNNCell",
        "signature": "tests.keras.layers.recurrent_test.MinimalRNNCell.__init__(self, units, **kwargs)",
        "snippet": "        def __init__(self, units, **kwargs):\n            self.units = units\n            self.state_size = units\n            super(MinimalRNNCell, self).__init__(**kwargs)",
        "begin_line": 514,
        "end_line": 517,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.MinimalRNNCell.build#519",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.MinimalRNNCell",
        "signature": "tests.keras.layers.recurrent_test.MinimalRNNCell.build(self, input_shape)",
        "snippet": "        def build(self, input_shape):\n            # no time axis in the input shape passed to RNN cells\n            assert len(input_shape) == 2\n\n            self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n                                          initializer='uniform',\n                                          name='kernel')\n            self.recurrent_kernel = self.add_weight(\n                shape=(self.units, self.units),\n                initializer='uniform',\n                name='recurrent_kernel')\n            self.built = True",
        "begin_line": 519,
        "end_line": 530,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.MinimalRNNCell.call#532",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.MinimalRNNCell",
        "signature": "tests.keras.layers.recurrent_test.MinimalRNNCell.call(self, inputs, states)",
        "snippet": "        def call(self, inputs, states):\n            prev_output = states[0]\n            h = keras.backend.dot(inputs, self.kernel)\n            output = h + keras.backend.dot(prev_output, self.recurrent_kernel)\n            return output, [output]",
        "begin_line": 532,
        "end_line": 536,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.MinimalRNNCell.get_config#538",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.MinimalRNNCell",
        "signature": "tests.keras.layers.recurrent_test.MinimalRNNCell.get_config(self)",
        "snippet": "        def get_config(self):\n            config = {'units': self.units}\n            base_config = super(MinimalRNNCell, self).get_config()\n            return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 538,
        "end_line": 541,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_builtin_rnn_cell_layer#590",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_builtin_rnn_cell_layer(cell_class)",
        "snippet": "def test_builtin_rnn_cell_layer(cell_class):\n    # Test basic case.\n    x = keras.Input((None, 5))\n    cell = cell_class(32)\n    layer = recurrent.RNN(cell)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))\n\n    # Test basic case serialization.\n    x_np = np.random.random((6, 5, 5))\n    y_np = model.predict(x_np)\n    weights = model.get_weights()\n    config = layer.get_config()\n    layer = recurrent.RNN.from_config(config)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.set_weights(weights)\n    y_np_2 = model.predict(x_np)\n    assert_allclose(y_np, y_np_2, atol=1e-4)\n\n    # Test stacking.\n    cells = [cell_class(8),\n             cell_class(12),\n             cell_class(32)]\n    layer = recurrent.RNN(cells)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))\n\n    # Test stacked RNN serialization.\n    x_np = np.random.random((6, 5, 5))\n    y_np = model.predict(x_np)\n    weights = model.get_weights()\n    config = layer.get_config()\n    layer = recurrent.RNN.from_config(config)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.set_weights(weights)\n    y_np_2 = model.predict(x_np)\n    assert_allclose(y_np, y_np_2, atol=1e-4)",
        "begin_line": 590,
        "end_line": 632,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_stacked_rnn_dropout#638",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_stacked_rnn_dropout()",
        "snippet": "def test_stacked_rnn_dropout():\n    cells = [recurrent.LSTMCell(3, dropout=0.1, recurrent_dropout=0.1),\n             recurrent.LSTMCell(3, dropout=0.1, recurrent_dropout=0.1)]\n    layer = recurrent.RNN(cells)\n\n    x = keras.Input((None, 5))\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile('sgd', 'mse')\n    x_np = np.random.random((6, 5, 5))\n    y_np = np.random.random((6, 3))\n    model.train_on_batch(x_np, y_np)",
        "begin_line": 638,
        "end_line": 649,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_stacked_rnn_attributes#653",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_stacked_rnn_attributes()",
        "snippet": "def test_stacked_rnn_attributes():\n    cells = [recurrent.LSTMCell(3),\n             recurrent.LSTMCell(3, kernel_regularizer='l2')]\n    layer = recurrent.RNN(cells)\n    layer.build((None, None, 5))\n\n    # Test regularization losses\n    assert len(layer.losses) == 1\n\n    # Test weights\n    assert len(layer.trainable_weights) == 6\n    cells[0].trainable = False\n    assert len(layer.trainable_weights) == 3\n    assert len(layer.non_trainable_weights) == 3\n\n    # Test `get_losses_for`\n    x = keras.Input((None, 5))\n    y = K.sum(x)\n    cells[0].add_loss(y, inputs=x)\n    assert layer.get_losses_for(x) == [y]",
        "begin_line": 653,
        "end_line": 672,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_stacked_rnn_compute_output_shape#676",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_stacked_rnn_compute_output_shape()",
        "snippet": "def test_stacked_rnn_compute_output_shape():\n    cells = [recurrent.LSTMCell(3),\n             recurrent.LSTMCell(6)]\n    layer = recurrent.RNN(cells, return_state=True, return_sequences=True)\n    output_shape = layer.compute_output_shape((None, timesteps, embedding_dim))\n    expected_output_shape = [(None, timesteps, 6),\n                             (None, 3),\n                             (None, 3),\n                             (None, 6),\n                             (None, 6)]\n    assert output_shape == expected_output_shape\n\n    # Test reverse_state_order = True for stacked cell.\n    stacked_cell = recurrent.StackedRNNCells(\n        cells, reverse_state_order=True)\n    layer = recurrent.RNN(\n        stacked_cell, return_state=True, return_sequences=True)\n    output_shape = layer.compute_output_shape((None, timesteps, embedding_dim))\n    expected_output_shape = [(None, timesteps, 6),\n                             (None, 6),\n                             (None, 6),\n                             (None, 3),\n                             (None, 3)]\n    assert output_shape == expected_output_shape",
        "begin_line": 676,
        "end_line": 699,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_batch_size_equal_one#703",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_batch_size_equal_one(layer_class)",
        "snippet": "def test_batch_size_equal_one(layer_class):\n    inputs = Input(batch_shape=(1, timesteps, embedding_dim))\n    layer = layer_class(units)\n    outputs = layer(inputs)\n    model = Model(inputs, outputs)\n    model.compile('sgd', 'mse')\n    x = np.random.random((1, timesteps, embedding_dim))\n    y = np.random.random((1, units))\n    model.train_on_batch(x, y)",
        "begin_line": 703,
        "end_line": 711,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_rnn_cell_with_constants_layer#715",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_rnn_cell_with_constants_layer()",
        "snippet": "def test_rnn_cell_with_constants_layer():\n\n    class RNNCellWithConstants(keras.layers.Layer):\n\n        def __init__(self, units, **kwargs):\n            self.units = units\n            self.state_size = units\n            super(RNNCellWithConstants, self).__init__(**kwargs)\n\n        def build(self, input_shape):\n            if not isinstance(input_shape, list):\n                raise TypeError('expects constants shape')\n            [input_shape, constant_shape] = input_shape\n            # will (and should) raise if more than one constant passed\n\n            self.input_kernel = self.add_weight(\n                shape=(input_shape[-1], self.units),\n                initializer='uniform',\n                name='kernel')\n            self.recurrent_kernel = self.add_weight(\n                shape=(self.units, self.units),\n                initializer='uniform',\n                name='recurrent_kernel')\n            self.constant_kernel = self.add_weight(\n                shape=(constant_shape[-1], self.units),\n                initializer='uniform',\n                name='constant_kernel')\n            self.built = True\n\n        def call(self, inputs, states, constants):\n            [prev_output] = states\n            [constant] = constants\n            h_input = keras.backend.dot(inputs, self.input_kernel)\n            h_state = keras.backend.dot(prev_output, self.recurrent_kernel)\n            h_const = keras.backend.dot(constant, self.constant_kernel)\n            output = h_input + h_state + h_const\n            return output, [output]\n\n        def get_config(self):\n            config = {'units': self.units}\n            base_config = super(RNNCellWithConstants, self).get_config()\n            return dict(list(base_config.items()) + list(config.items()))\n\n    # Test basic case.\n    x = keras.Input((None, 5))\n    c = keras.Input((3,))\n    cell = RNNCellWithConstants(32)\n    layer = recurrent.RNN(cell)\n    y = layer(x, constants=c)\n    model = keras.models.Model([x, c], y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(\n        [np.zeros((6, 5, 5)), np.zeros((6, 3))],\n        np.zeros((6, 32))\n    )\n\n    # Test basic case serialization.\n    x_np = np.random.random((6, 5, 5))\n    c_np = np.random.random((6, 3))\n    y_np = model.predict([x_np, c_np])\n    weights = model.get_weights()\n    config = layer.get_config()\n    custom_objects = {'RNNCellWithConstants': RNNCellWithConstants}\n    with keras.utils.CustomObjectScope(custom_objects):\n        layer = recurrent.RNN.from_config(config.copy())\n    y = layer(x, constants=c)\n    model = keras.models.Model([x, c], y)\n    model.set_weights(weights)\n    y_np_2 = model.predict([x_np, c_np])\n    assert_allclose(y_np, y_np_2, atol=1e-4)\n\n    # test flat list inputs\n    with keras.utils.CustomObjectScope(custom_objects):\n        layer = recurrent.RNN.from_config(config.copy())\n    y = layer([x, c])\n    model = keras.models.Model([x, c], y)\n    model.set_weights(weights)\n    y_np_3 = model.predict([x_np, c_np])\n    assert_allclose(y_np, y_np_3, atol=1e-4)\n\n    # Test stacking.\n    cells = [recurrent.GRUCell(8),\n             RNNCellWithConstants(12),\n             RNNCellWithConstants(32)]\n    layer = recurrent.RNN(cells)\n    y = layer(x, constants=c)\n    model = keras.models.Model([x, c], y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(\n        [np.zeros((6, 5, 5)), np.zeros((6, 3))],\n        np.zeros((6, 32))\n    )\n\n    # Test stacked RNN serialization.\n    x_np = np.random.random((6, 5, 5))\n    c_np = np.random.random((6, 3))\n    y_np = model.predict([x_np, c_np])\n    weights = model.get_weights()\n    config = layer.get_config()\n    with keras.utils.CustomObjectScope(custom_objects):\n        layer = recurrent.RNN.from_config(config.copy())\n    y = layer(x, constants=c)\n    model = keras.models.Model([x, c], y)\n    model.set_weights(weights)\n    y_np_2 = model.predict([x_np, c_np])\n    assert_allclose(y_np, y_np_2, atol=1e-4)",
        "begin_line": 715,
        "end_line": 820,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.RNNCellWithConstants.test_rnn_cell_with_constants_layer#715",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.RNNCellWithConstants",
        "signature": "tests.keras.layers.recurrent_test.RNNCellWithConstants.test_rnn_cell_with_constants_layer()",
        "snippet": "def test_rnn_cell_with_constants_layer():\n\n    class RNNCellWithConstants(keras.layers.Layer):\n\n        def __init__(self, units, **kwargs):\n            self.units = units\n            self.state_size = units\n            super(RNNCellWithConstants, self).__init__(**kwargs)\n\n        def build(self, input_shape):\n            if not isinstance(input_shape, list):\n                raise TypeError('expects constants shape')\n            [input_shape, constant_shape] = input_shape\n            # will (and should) raise if more than one constant passed\n\n            self.input_kernel = self.add_weight(\n                shape=(input_shape[-1], self.units),\n                initializer='uniform',\n                name='kernel')\n            self.recurrent_kernel = self.add_weight(\n                shape=(self.units, self.units),\n                initializer='uniform',\n                name='recurrent_kernel')\n            self.constant_kernel = self.add_weight(\n                shape=(constant_shape[-1], self.units),\n                initializer='uniform',\n                name='constant_kernel')\n            self.built = True\n\n        def call(self, inputs, states, constants):\n            [prev_output] = states\n            [constant] = constants\n            h_input = keras.backend.dot(inputs, self.input_kernel)\n            h_state = keras.backend.dot(prev_output, self.recurrent_kernel)\n            h_const = keras.backend.dot(constant, self.constant_kernel)\n            output = h_input + h_state + h_const\n            return output, [output]\n\n        def get_config(self):\n            config = {'units': self.units}\n            base_config = super(RNNCellWithConstants, self).get_config()\n            return dict(list(base_config.items()) + list(config.items()))\n\n    # Test basic case.\n    x = keras.Input((None, 5))\n    c = keras.Input((3,))\n    cell = RNNCellWithConstants(32)\n    layer = recurrent.RNN(cell)\n    y = layer(x, constants=c)\n    model = keras.models.Model([x, c], y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(\n        [np.zeros((6, 5, 5)), np.zeros((6, 3))],\n        np.zeros((6, 32))\n    )\n\n    # Test basic case serialization.\n    x_np = np.random.random((6, 5, 5))\n    c_np = np.random.random((6, 3))\n    y_np = model.predict([x_np, c_np])\n    weights = model.get_weights()\n    config = layer.get_config()\n    custom_objects = {'RNNCellWithConstants': RNNCellWithConstants}\n    with keras.utils.CustomObjectScope(custom_objects):\n        layer = recurrent.RNN.from_config(config.copy())\n    y = layer(x, constants=c)\n    model = keras.models.Model([x, c], y)\n    model.set_weights(weights)\n    y_np_2 = model.predict([x_np, c_np])\n    assert_allclose(y_np, y_np_2, atol=1e-4)\n\n    # test flat list inputs\n    with keras.utils.CustomObjectScope(custom_objects):\n        layer = recurrent.RNN.from_config(config.copy())\n    y = layer([x, c])\n    model = keras.models.Model([x, c], y)\n    model.set_weights(weights)\n    y_np_3 = model.predict([x_np, c_np])\n    assert_allclose(y_np, y_np_3, atol=1e-4)\n\n    # Test stacking.\n    cells = [recurrent.GRUCell(8),\n             RNNCellWithConstants(12),\n             RNNCellWithConstants(32)]\n    layer = recurrent.RNN(cells)\n    y = layer(x, constants=c)\n    model = keras.models.Model([x, c], y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(\n        [np.zeros((6, 5, 5)), np.zeros((6, 3))],\n        np.zeros((6, 32))\n    )\n\n    # Test stacked RNN serialization.\n    x_np = np.random.random((6, 5, 5))\n    c_np = np.random.random((6, 3))\n    y_np = model.predict([x_np, c_np])\n    weights = model.get_weights()\n    config = layer.get_config()\n    with keras.utils.CustomObjectScope(custom_objects):\n        layer = recurrent.RNN.from_config(config.copy())\n    y = layer(x, constants=c)\n    model = keras.models.Model([x, c], y)\n    model.set_weights(weights)\n    y_np_2 = model.predict([x_np, c_np])\n    assert_allclose(y_np, y_np_2, atol=1e-4)",
        "begin_line": 715,
        "end_line": 820,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.RNNCellWithConstants.__init__#719",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.RNNCellWithConstants",
        "signature": "tests.keras.layers.recurrent_test.RNNCellWithConstants.__init__(self, units, **kwargs)",
        "snippet": "        def __init__(self, units, **kwargs):\n            self.units = units\n            self.state_size = units\n            super(RNNCellWithConstants, self).__init__(**kwargs)",
        "begin_line": 719,
        "end_line": 722,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.RNNCellWithConstants.build#724",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.RNNCellWithConstants",
        "signature": "tests.keras.layers.recurrent_test.RNNCellWithConstants.build(self, input_shape)",
        "snippet": "        def build(self, input_shape):\n            if not isinstance(input_shape, list):\n                raise TypeError('expects constants shape')\n            [input_shape, constant_shape] = input_shape\n            # will (and should) raise if more than one constant passed\n\n            self.input_kernel = self.add_weight(\n                shape=(input_shape[-1], self.units),\n                initializer='uniform',\n                name='kernel')\n            self.recurrent_kernel = self.add_weight(\n                shape=(self.units, self.units),\n                initializer='uniform',\n                name='recurrent_kernel')\n            self.constant_kernel = self.add_weight(\n                shape=(constant_shape[-1], self.units),\n                initializer='uniform',\n                name='constant_kernel')\n            self.built = True",
        "begin_line": 724,
        "end_line": 742,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.RNNCellWithConstants.call#744",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.RNNCellWithConstants",
        "signature": "tests.keras.layers.recurrent_test.RNNCellWithConstants.call(self, inputs, states, constants)",
        "snippet": "        def call(self, inputs, states, constants):\n            [prev_output] = states\n            [constant] = constants\n            h_input = keras.backend.dot(inputs, self.input_kernel)\n            h_state = keras.backend.dot(prev_output, self.recurrent_kernel)\n            h_const = keras.backend.dot(constant, self.constant_kernel)\n            output = h_input + h_state + h_const\n            return output, [output]",
        "begin_line": 744,
        "end_line": 751,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.RNNCellWithConstants.get_config#753",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.RNNCellWithConstants",
        "signature": "tests.keras.layers.recurrent_test.RNNCellWithConstants.get_config(self)",
        "snippet": "        def get_config(self):\n            config = {'units': self.units}\n            base_config = super(RNNCellWithConstants, self).get_config()\n            return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 753,
        "end_line": 756,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_rnn_cell_with_constants_layer_passing_initial_state#824",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_rnn_cell_with_constants_layer_passing_initial_state()",
        "snippet": "def test_rnn_cell_with_constants_layer_passing_initial_state():\n\n    class RNNCellWithConstants(keras.layers.Layer):\n\n        def __init__(self, units, **kwargs):\n            self.units = units\n            self.state_size = units\n            super(RNNCellWithConstants, self).__init__(**kwargs)\n\n        def build(self, input_shape):\n            if not isinstance(input_shape, list):\n                raise TypeError('expects constants shape')\n            [input_shape, constant_shape] = input_shape\n            # will (and should) raise if more than one constant passed\n\n            self.input_kernel = self.add_weight(\n                shape=(input_shape[-1], self.units),\n                initializer='uniform',\n                name='kernel')\n            self.recurrent_kernel = self.add_weight(\n                shape=(self.units, self.units),\n                initializer='uniform',\n                name='recurrent_kernel')\n            self.constant_kernel = self.add_weight(\n                shape=(constant_shape[-1], self.units),\n                initializer='uniform',\n                name='constant_kernel')\n            self.built = True\n\n        def call(self, inputs, states, constants):\n            [prev_output] = states\n            [constant] = constants\n            h_input = keras.backend.dot(inputs, self.input_kernel)\n            h_state = keras.backend.dot(prev_output, self.recurrent_kernel)\n            h_const = keras.backend.dot(constant, self.constant_kernel)\n            output = h_input + h_state + h_const\n            return output, [output]\n\n        def get_config(self):\n            config = {'units': self.units}\n            base_config = super(RNNCellWithConstants, self).get_config()\n            return dict(list(base_config.items()) + list(config.items()))\n\n    # Test basic case.\n    x = keras.Input((None, 5))\n    c = keras.Input((3,))\n    s = keras.Input((32,))\n    cell = RNNCellWithConstants(32)\n    layer = recurrent.RNN(cell)\n    y = layer(x, initial_state=s, constants=c)\n    model = keras.models.Model([x, s, c], y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(\n        [np.zeros((6, 5, 5)), np.zeros((6, 32)), np.zeros((6, 3))],\n        np.zeros((6, 32))\n    )\n\n    # Test basic case serialization.\n    x_np = np.random.random((6, 5, 5))\n    s_np = np.random.random((6, 32))\n    c_np = np.random.random((6, 3))\n    y_np = model.predict([x_np, s_np, c_np])\n    weights = model.get_weights()\n    config = layer.get_config()\n    custom_objects = {'RNNCellWithConstants': RNNCellWithConstants}\n    with keras.utils.CustomObjectScope(custom_objects):\n        layer = recurrent.RNN.from_config(config.copy())\n    y = layer(x, initial_state=s, constants=c)\n    model = keras.models.Model([x, s, c], y)\n    model.set_weights(weights)\n    y_np_2 = model.predict([x_np, s_np, c_np])\n    assert_allclose(y_np, y_np_2, atol=1e-4)\n\n    # verify that state is used\n    y_np_2_different_s = model.predict([x_np, s_np + 10., c_np])\n    with pytest.raises(AssertionError):\n        assert_allclose(y_np, y_np_2_different_s, atol=1e-4)\n\n    # test flat list inputs\n    with keras.utils.CustomObjectScope(custom_objects):\n        layer = recurrent.RNN.from_config(config.copy())\n    y = layer([x, s, c])\n    model = keras.models.Model([x, s, c], y)\n    model.set_weights(weights)\n    y_np_3 = model.predict([x_np, s_np, c_np])\n    assert_allclose(y_np, y_np_3, atol=1e-4)",
        "begin_line": 824,
        "end_line": 909,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.RNNCellWithConstants.test_rnn_cell_with_constants_layer_passing_initial_state#824",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.RNNCellWithConstants",
        "signature": "tests.keras.layers.recurrent_test.RNNCellWithConstants.test_rnn_cell_with_constants_layer_passing_initial_state()",
        "snippet": "def test_rnn_cell_with_constants_layer_passing_initial_state():\n\n    class RNNCellWithConstants(keras.layers.Layer):\n\n        def __init__(self, units, **kwargs):\n            self.units = units\n            self.state_size = units\n            super(RNNCellWithConstants, self).__init__(**kwargs)\n\n        def build(self, input_shape):\n            if not isinstance(input_shape, list):\n                raise TypeError('expects constants shape')\n            [input_shape, constant_shape] = input_shape\n            # will (and should) raise if more than one constant passed\n\n            self.input_kernel = self.add_weight(\n                shape=(input_shape[-1], self.units),\n                initializer='uniform',\n                name='kernel')\n            self.recurrent_kernel = self.add_weight(\n                shape=(self.units, self.units),\n                initializer='uniform',\n                name='recurrent_kernel')\n            self.constant_kernel = self.add_weight(\n                shape=(constant_shape[-1], self.units),\n                initializer='uniform',\n                name='constant_kernel')\n            self.built = True\n\n        def call(self, inputs, states, constants):\n            [prev_output] = states\n            [constant] = constants\n            h_input = keras.backend.dot(inputs, self.input_kernel)\n            h_state = keras.backend.dot(prev_output, self.recurrent_kernel)\n            h_const = keras.backend.dot(constant, self.constant_kernel)\n            output = h_input + h_state + h_const\n            return output, [output]\n\n        def get_config(self):\n            config = {'units': self.units}\n            base_config = super(RNNCellWithConstants, self).get_config()\n            return dict(list(base_config.items()) + list(config.items()))\n\n    # Test basic case.\n    x = keras.Input((None, 5))\n    c = keras.Input((3,))\n    s = keras.Input((32,))\n    cell = RNNCellWithConstants(32)\n    layer = recurrent.RNN(cell)\n    y = layer(x, initial_state=s, constants=c)\n    model = keras.models.Model([x, s, c], y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(\n        [np.zeros((6, 5, 5)), np.zeros((6, 32)), np.zeros((6, 3))],\n        np.zeros((6, 32))\n    )\n\n    # Test basic case serialization.\n    x_np = np.random.random((6, 5, 5))\n    s_np = np.random.random((6, 32))\n    c_np = np.random.random((6, 3))\n    y_np = model.predict([x_np, s_np, c_np])\n    weights = model.get_weights()\n    config = layer.get_config()\n    custom_objects = {'RNNCellWithConstants': RNNCellWithConstants}\n    with keras.utils.CustomObjectScope(custom_objects):\n        layer = recurrent.RNN.from_config(config.copy())\n    y = layer(x, initial_state=s, constants=c)\n    model = keras.models.Model([x, s, c], y)\n    model.set_weights(weights)\n    y_np_2 = model.predict([x_np, s_np, c_np])\n    assert_allclose(y_np, y_np_2, atol=1e-4)\n\n    # verify that state is used\n    y_np_2_different_s = model.predict([x_np, s_np + 10., c_np])\n    with pytest.raises(AssertionError):\n        assert_allclose(y_np, y_np_2_different_s, atol=1e-4)\n\n    # test flat list inputs\n    with keras.utils.CustomObjectScope(custom_objects):\n        layer = recurrent.RNN.from_config(config.copy())\n    y = layer([x, s, c])\n    model = keras.models.Model([x, s, c], y)\n    model.set_weights(weights)\n    y_np_3 = model.predict([x_np, s_np, c_np])\n    assert_allclose(y_np, y_np_3, atol=1e-4)",
        "begin_line": 824,
        "end_line": 909,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.RNNCellWithConstants.__init__#828",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.RNNCellWithConstants",
        "signature": "tests.keras.layers.recurrent_test.RNNCellWithConstants.__init__(self, units, **kwargs)",
        "snippet": "        def __init__(self, units, **kwargs):\n            self.units = units\n            self.state_size = units\n            super(RNNCellWithConstants, self).__init__(**kwargs)",
        "begin_line": 828,
        "end_line": 831,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.RNNCellWithConstants.build#833",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.RNNCellWithConstants",
        "signature": "tests.keras.layers.recurrent_test.RNNCellWithConstants.build(self, input_shape)",
        "snippet": "        def build(self, input_shape):\n            if not isinstance(input_shape, list):\n                raise TypeError('expects constants shape')\n            [input_shape, constant_shape] = input_shape\n            # will (and should) raise if more than one constant passed\n\n            self.input_kernel = self.add_weight(\n                shape=(input_shape[-1], self.units),\n                initializer='uniform',\n                name='kernel')\n            self.recurrent_kernel = self.add_weight(\n                shape=(self.units, self.units),\n                initializer='uniform',\n                name='recurrent_kernel')\n            self.constant_kernel = self.add_weight(\n                shape=(constant_shape[-1], self.units),\n                initializer='uniform',\n                name='constant_kernel')\n            self.built = True",
        "begin_line": 833,
        "end_line": 851,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.RNNCellWithConstants.call#853",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.RNNCellWithConstants",
        "signature": "tests.keras.layers.recurrent_test.RNNCellWithConstants.call(self, inputs, states, constants)",
        "snippet": "        def call(self, inputs, states, constants):\n            [prev_output] = states\n            [constant] = constants\n            h_input = keras.backend.dot(inputs, self.input_kernel)\n            h_state = keras.backend.dot(prev_output, self.recurrent_kernel)\n            h_const = keras.backend.dot(constant, self.constant_kernel)\n            output = h_input + h_state + h_const\n            return output, [output]",
        "begin_line": 853,
        "end_line": 860,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.RNNCellWithConstants.get_config#862",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.RNNCellWithConstants",
        "signature": "tests.keras.layers.recurrent_test.RNNCellWithConstants.get_config(self)",
        "snippet": "        def get_config(self):\n            config = {'units': self.units}\n            base_config = super(RNNCellWithConstants, self).get_config()\n            return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 862,
        "end_line": 865,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_rnn_cell_identity_initializer#913",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_rnn_cell_identity_initializer(layer_class)",
        "snippet": "def test_rnn_cell_identity_initializer(layer_class):\n    inputs = Input(shape=(timesteps, embedding_dim))\n    layer = layer_class(units, recurrent_initializer='identity')\n    layer(inputs)\n    recurrent_kernel = layer.get_weights()[1]\n    num_kernels = recurrent_kernel.shape[1] // recurrent_kernel.shape[0]\n    assert np.array_equal(recurrent_kernel,\n                          np.concatenate([np.identity(units)] * num_kernels, axis=1))",
        "begin_line": 913,
        "end_line": 920,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_inconsistent_output_state_size#925",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_inconsistent_output_state_size()",
        "snippet": "def test_inconsistent_output_state_size():\n\n    class PlusOneRNNCell(keras.layers.Layer):\n        \"\"\"Add one to the input and state.\n\n        This cell is used for testing state_size and output_size.\"\"\"\n\n        def __init__(self, num_unit, **kwargs):\n            self.state_size = num_unit\n            super(PlusOneRNNCell, self).__init__(**kwargs)\n\n        def build(self, input_shape):\n            self.output_size = input_shape[-1]\n\n        def call(self, inputs, states):\n            return inputs + 1, [states[0] + 1]\n\n    batch = 32\n    time_step = 4\n    state_size = 5\n    input_size = 6\n    cell = PlusOneRNNCell(state_size)\n    x = keras.Input((None, input_size))\n    layer = recurrent.RNN(cell)\n    y = layer(x)\n\n    assert cell.state_size == state_size\n    init_state = layer.get_initial_state(x)\n    assert len(init_state) == 1\n    if K.backend() != 'theano':\n        # theano does not support static shape inference.\n        assert K.int_shape(init_state[0]) == (None, state_size)\n\n    model = keras.models.Model(x, y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(\n        np.zeros((batch, time_step, input_size)),\n        np.zeros((batch, input_size)))\n    assert model.output_shape == (None, input_size)",
        "begin_line": 925,
        "end_line": 963,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.PlusOneRNNCell.test_inconsistent_output_state_size#925",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.PlusOneRNNCell",
        "signature": "tests.keras.layers.recurrent_test.PlusOneRNNCell.test_inconsistent_output_state_size()",
        "snippet": "def test_inconsistent_output_state_size():\n\n    class PlusOneRNNCell(keras.layers.Layer):\n        \"\"\"Add one to the input and state.\n\n        This cell is used for testing state_size and output_size.\"\"\"\n\n        def __init__(self, num_unit, **kwargs):\n            self.state_size = num_unit\n            super(PlusOneRNNCell, self).__init__(**kwargs)\n\n        def build(self, input_shape):\n            self.output_size = input_shape[-1]\n\n        def call(self, inputs, states):\n            return inputs + 1, [states[0] + 1]\n\n    batch = 32\n    time_step = 4\n    state_size = 5\n    input_size = 6\n    cell = PlusOneRNNCell(state_size)\n    x = keras.Input((None, input_size))\n    layer = recurrent.RNN(cell)\n    y = layer(x)\n\n    assert cell.state_size == state_size\n    init_state = layer.get_initial_state(x)\n    assert len(init_state) == 1\n    if K.backend() != 'theano':\n        # theano does not support static shape inference.\n        assert K.int_shape(init_state[0]) == (None, state_size)\n\n    model = keras.models.Model(x, y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(\n        np.zeros((batch, time_step, input_size)),\n        np.zeros((batch, input_size)))\n    assert model.output_shape == (None, input_size)",
        "begin_line": 925,
        "end_line": 963,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.PlusOneRNNCell.__init__#932",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.PlusOneRNNCell",
        "signature": "tests.keras.layers.recurrent_test.PlusOneRNNCell.__init__(self, num_unit, **kwargs)",
        "snippet": "        def __init__(self, num_unit, **kwargs):\n            self.state_size = num_unit\n            super(PlusOneRNNCell, self).__init__(**kwargs)",
        "begin_line": 932,
        "end_line": 934,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.PlusOneRNNCell.build#936",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.PlusOneRNNCell",
        "signature": "tests.keras.layers.recurrent_test.PlusOneRNNCell.build(self, input_shape)",
        "snippet": "        def build(self, input_shape):\n            self.output_size = input_shape[-1]",
        "begin_line": 936,
        "end_line": 937,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.PlusOneRNNCell.call#939",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.PlusOneRNNCell",
        "signature": "tests.keras.layers.recurrent_test.PlusOneRNNCell.call(self, inputs, states)",
        "snippet": "        def call(self, inputs, states):\n            return inputs + 1, [states[0] + 1]",
        "begin_line": 939,
        "end_line": 940,
        "comment": "",
        "is_bug": false
    }
]