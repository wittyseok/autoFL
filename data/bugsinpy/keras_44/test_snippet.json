[
    {
        "name": "tests.keras.layers.recurrent_test.rnn_test#22",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.rnn_test(f)",
        "snippet": "def rnn_test(f):\n    \"\"\"\n    All the recurrent layers share the same interface,\n    so we can run through them with a single function.\n    \"\"\"\n    f = keras_test(f)\n    return pytest.mark.parametrize('layer_class', [\n        recurrent.SimpleRNN,\n        recurrent.GRU,\n        recurrent.LSTM\n    ])(f)",
        "begin_line": 22,
        "end_line": 32,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_return_sequences#36",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_return_sequences(layer_class)",
        "snippet": "def test_return_sequences(layer_class):\n    layer_test(layer_class,\n               kwargs={'units': units,\n                       'return_sequences': True},\n               input_shape=(num_samples, timesteps, embedding_dim))",
        "begin_line": 36,
        "end_line": 40,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_dynamic_behavior#44",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_dynamic_behavior(layer_class)",
        "snippet": "def test_dynamic_behavior(layer_class):\n    layer = layer_class(units, input_shape=(None, embedding_dim))\n    model = Sequential()\n    model.add(layer)\n    model.compile('sgd', 'mse')\n    x = np.random.random((num_samples, timesteps, embedding_dim))\n    y = np.random.random((num_samples, units))\n    model.train_on_batch(x, y)",
        "begin_line": 44,
        "end_line": 51,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_stateful_invalid_use#55",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_stateful_invalid_use(layer_class)",
        "snippet": "def test_stateful_invalid_use(layer_class):\n    layer = layer_class(units,\n                        stateful=True,\n                        batch_input_shape=(num_samples,\n                                           timesteps,\n                                           embedding_dim))\n    model = Sequential()\n    model.add(layer)\n    model.compile('sgd', 'mse')\n    x = np.random.random((num_samples * 2, timesteps, embedding_dim))\n    y = np.random.random((num_samples * 2, units))\n    with pytest.raises(ValueError):\n        model.fit(x, y)\n    with pytest.raises(ValueError):\n        model.predict(x, batch_size=num_samples + 1)",
        "begin_line": 55,
        "end_line": 69,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_dropout#75",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_dropout(layer_class)",
        "snippet": "def test_dropout(layer_class):\n    for unroll in [True, False]:\n        layer_test(layer_class,\n                   kwargs={'units': units,\n                           'dropout': 0.1,\n                           'recurrent_dropout': 0.1,\n                           'unroll': unroll},\n                   input_shape=(num_samples, timesteps, embedding_dim))\n\n        # Test that dropout is applied during training\n        x = K.ones((num_samples, timesteps, embedding_dim))\n        layer = layer_class(units, dropout=0.5, recurrent_dropout=0.5,\n                            input_shape=(timesteps, embedding_dim))\n        y = layer(x)\n        assert y._uses_learning_phase\n\n        y = layer(x, training=True)\n        assert not getattr(y, '_uses_learning_phase')\n\n        # Test that dropout is not applied during testing\n        x = np.random.random((num_samples, timesteps, embedding_dim))\n        layer = layer_class(units, dropout=0.5, recurrent_dropout=0.5,\n                            unroll=unroll,\n                            input_shape=(timesteps, embedding_dim))\n        model = Sequential([layer])\n        assert model.uses_learning_phase\n        y1 = model.predict(x)\n        y2 = model.predict(x)\n        assert_allclose(y1, y2)",
        "begin_line": 75,
        "end_line": 103,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_statefulness#107",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_statefulness(layer_class)",
        "snippet": "def test_statefulness(layer_class):\n    model = Sequential()\n    model.add(embeddings.Embedding(embedding_num, embedding_dim,\n                                   mask_zero=True,\n                                   input_length=timesteps,\n                                   batch_input_shape=(num_samples, timesteps)))\n    layer = layer_class(units, return_sequences=False,\n                        stateful=True,\n                        weights=None)\n    model.add(layer)\n    model.compile(optimizer='sgd', loss='mse')\n    out1 = model.predict(np.ones((num_samples, timesteps)))\n    assert(out1.shape == (num_samples, units))\n\n    # train once so that the states change\n    model.train_on_batch(np.ones((num_samples, timesteps)),\n                         np.ones((num_samples, units)))\n    out2 = model.predict(np.ones((num_samples, timesteps)))\n\n    # if the state is not reset, output should be different\n    assert(out1.max() != out2.max())\n\n    # check that output changes after states are reset\n    # (even though the model itself didn't change)\n    layer.reset_states()\n    out3 = model.predict(np.ones((num_samples, timesteps)))\n    assert(out2.max() != out3.max())\n\n    # check that container-level reset_states() works\n    model.reset_states()\n    out4 = model.predict(np.ones((num_samples, timesteps)))\n    assert_allclose(out3, out4, atol=1e-5)\n\n    # check that the call to `predict` updated the states\n    out5 = model.predict(np.ones((num_samples, timesteps)))\n    assert(out4.max() != out5.max())",
        "begin_line": 107,
        "end_line": 142,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_masking_correctness#146",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_masking_correctness(layer_class)",
        "snippet": "def test_masking_correctness(layer_class):\n    # Check masking: output with left padding and right padding\n    # should be the same.\n    model = Sequential()\n    model.add(embeddings.Embedding(embedding_num, embedding_dim,\n                                   mask_zero=True,\n                                   input_length=timesteps,\n                                   batch_input_shape=(num_samples, timesteps)))\n    layer = layer_class(units, return_sequences=False)\n    model.add(layer)\n    model.compile(optimizer='sgd', loss='mse')\n\n    left_padded_input = np.ones((num_samples, timesteps))\n    left_padded_input[0, :1] = 0\n    left_padded_input[1, :2] = 0\n    out6 = model.predict(left_padded_input)\n\n    right_padded_input = np.ones((num_samples, timesteps))\n    right_padded_input[0, -1:] = 0\n    right_padded_input[1, -2:] = 0\n    out7 = model.predict(right_padded_input)\n\n    assert_allclose(out7, out6, atol=1e-5)",
        "begin_line": 146,
        "end_line": 168,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_implementation_mode#172",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_implementation_mode(layer_class)",
        "snippet": "def test_implementation_mode(layer_class):\n    for mode in [1, 2]:\n        # Without dropout\n        layer_test(layer_class,\n                   kwargs={'units': units,\n                           'implementation': mode},\n                   input_shape=(num_samples, timesteps, embedding_dim))\n        # With dropout\n        layer_test(layer_class,\n                   kwargs={'units': units,\n                           'implementation': mode,\n                           'dropout': 0.1,\n                           'recurrent_dropout': 0.1},\n                   input_shape=(num_samples, timesteps, embedding_dim))\n        # Without bias\n        layer_test(layer_class,\n                   kwargs={'units': units,\n                           'implementation': mode,\n                           'use_bias': False},\n                   input_shape=(num_samples, timesteps, embedding_dim))",
        "begin_line": 172,
        "end_line": 191,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_regularizer#195",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_regularizer(layer_class)",
        "snippet": "def test_regularizer(layer_class):\n    layer = layer_class(units, return_sequences=False, weights=None,\n                        input_shape=(timesteps, embedding_dim),\n                        kernel_regularizer=regularizers.l1(0.01),\n                        recurrent_regularizer=regularizers.l1(0.01),\n                        bias_regularizer='l2')\n    layer.build((None, None, embedding_dim))\n    assert len(layer.losses) == 3\n    assert len(layer.cell.losses) == 3\n\n    layer = layer_class(units, return_sequences=False, weights=None,\n                        input_shape=(timesteps, embedding_dim),\n                        activity_regularizer='l2')\n    assert layer.activity_regularizer\n    x = K.variable(np.ones((num_samples, timesteps, embedding_dim)))\n    layer(x)\n    assert len(layer.cell.get_losses_for(x)) == 0\n    assert len(layer.get_losses_for(x)) == 1",
        "begin_line": 195,
        "end_line": 212,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_trainability#216",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_trainability(layer_class)",
        "snippet": "def test_trainability(layer_class):\n    layer = layer_class(units)\n    layer.build((None, None, embedding_dim))\n    assert len(layer.weights) == 3\n    assert len(layer.trainable_weights) == 3\n    assert len(layer.non_trainable_weights) == 0\n    layer.trainable = False\n    assert len(layer.weights) == 3\n    assert len(layer.trainable_weights) == 0\n    assert len(layer.non_trainable_weights) == 3\n    layer.trainable = True\n    assert len(layer.weights) == 3\n    assert len(layer.trainable_weights) == 3\n    assert len(layer.non_trainable_weights) == 0",
        "begin_line": 216,
        "end_line": 229,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_masking_layer#233",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_masking_layer()",
        "snippet": "def test_masking_layer():\n    ''' This test based on a previously failing issue here:\n    https://github.com/fchollet/keras/issues/1567\n    '''\n    inputs = np.random.random((6, 3, 4))\n    targets = np.abs(np.random.random((6, 3, 5)))\n    targets /= targets.sum(axis=-1, keepdims=True)\n\n    model = Sequential()\n    model.add(Masking(input_shape=(3, 4)))\n    model.add(recurrent.SimpleRNN(units=5, return_sequences=True, unroll=False))\n    model.compile(loss='categorical_crossentropy', optimizer='adam')\n    model.fit(inputs, targets, epochs=1, batch_size=100, verbose=1)\n\n    model = Sequential()\n    model.add(Masking(input_shape=(3, 4)))\n    model.add(recurrent.SimpleRNN(units=5, return_sequences=True, unroll=True))\n    model.compile(loss='categorical_crossentropy', optimizer='adam')\n    model.fit(inputs, targets, epochs=1, batch_size=100, verbose=1)",
        "begin_line": 233,
        "end_line": 251,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_from_config#255",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_from_config(layer_class)",
        "snippet": "def test_from_config(layer_class):\n    stateful_flags = (False, True)\n    for stateful in stateful_flags:\n        l1 = layer_class(units=1, stateful=stateful)\n        l2 = layer_class.from_config(l1.get_config())\n        assert l1.get_config() == l2.get_config()",
        "begin_line": 255,
        "end_line": 260,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_specify_initial_state_keras_tensor#264",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_specify_initial_state_keras_tensor(layer_class)",
        "snippet": "def test_specify_initial_state_keras_tensor(layer_class):\n    num_states = 2 if layer_class is recurrent.LSTM else 1\n\n    # Test with Keras tensor\n    inputs = Input((timesteps, embedding_dim))\n    initial_state = [Input((units,)) for _ in range(num_states)]\n    layer = layer_class(units)\n    if len(initial_state) == 1:\n        output = layer(inputs, initial_state=initial_state[0])\n    else:\n        output = layer(inputs, initial_state=initial_state)\n    assert initial_state[0] in layer.inbound_nodes[0].input_tensors\n\n    model = Model([inputs] + initial_state, output)\n    model.compile(loss='categorical_crossentropy', optimizer='adam')\n\n    inputs = np.random.random((num_samples, timesteps, embedding_dim))\n    initial_state = [np.random.random((num_samples, units))\n                     for _ in range(num_states)]\n    targets = np.random.random((num_samples, units))\n    model.fit([inputs] + initial_state, targets)",
        "begin_line": 264,
        "end_line": 284,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_specify_initial_state_non_keras_tensor#288",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_specify_initial_state_non_keras_tensor(layer_class)",
        "snippet": "def test_specify_initial_state_non_keras_tensor(layer_class):\n    num_states = 2 if layer_class is recurrent.LSTM else 1\n\n    # Test with non-Keras tensor\n    inputs = Input((timesteps, embedding_dim))\n    initial_state = [K.random_normal_variable((num_samples, units), 0, 1)\n                     for _ in range(num_states)]\n    layer = layer_class(units)\n    output = layer(inputs, initial_state=initial_state)\n\n    model = Model(inputs, output)\n    model.compile(loss='categorical_crossentropy', optimizer='adam')\n\n    inputs = np.random.random((num_samples, timesteps, embedding_dim))\n    targets = np.random.random((num_samples, units))\n    model.fit(inputs, targets)",
        "begin_line": 288,
        "end_line": 303,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_reset_states_with_values#307",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_reset_states_with_values(layer_class)",
        "snippet": "def test_reset_states_with_values(layer_class):\n    num_states = 2 if layer_class is recurrent.LSTM else 1\n\n    layer = layer_class(units, stateful=True)\n    layer.build((num_samples, timesteps, embedding_dim))\n    layer.reset_states()\n    assert len(layer.states) == num_states\n    assert layer.states[0] is not None\n    np.testing.assert_allclose(K.eval(layer.states[0]),\n                               np.zeros(K.int_shape(layer.states[0])),\n                               atol=1e-4)\n    state_shapes = [K.int_shape(state) for state in layer.states]\n    values = [np.ones(shape) for shape in state_shapes]\n    if len(values) == 1:\n        values = values[0]\n    layer.reset_states(values)\n    np.testing.assert_allclose(K.eval(layer.states[0]),\n                               np.ones(K.int_shape(layer.states[0])),\n                               atol=1e-4)\n\n    # Test fit with invalid data\n    with pytest.raises(ValueError):\n        layer.reset_states([1] * (len(layer.states) + 1))",
        "begin_line": 307,
        "end_line": 329,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_initial_states_as_other_inputs#333",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_initial_states_as_other_inputs(layer_class)",
        "snippet": "def test_initial_states_as_other_inputs(layer_class):\n    num_states = 2 if layer_class is recurrent.LSTM else 1\n\n    # Test with Keras tensor\n    main_inputs = Input((timesteps, embedding_dim))\n    initial_state = [Input((units,)) for _ in range(num_states)]\n    inputs = [main_inputs] + initial_state\n\n    layer = layer_class(units)\n    output = layer(inputs)\n    assert initial_state[0] in layer.inbound_nodes[0].input_tensors\n\n    model = Model(inputs, output)\n    model.compile(loss='categorical_crossentropy', optimizer='adam')\n\n    main_inputs = np.random.random((num_samples, timesteps, embedding_dim))\n    initial_state = [np.random.random((num_samples, units))\n                     for _ in range(num_states)]\n    targets = np.random.random((num_samples, units))\n    model.train_on_batch([main_inputs] + initial_state, targets)",
        "begin_line": 333,
        "end_line": 352,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_specify_state_with_masking#356",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_specify_state_with_masking(layer_class)",
        "snippet": "def test_specify_state_with_masking(layer_class):\n    ''' This test based on a previously failing issue here:\n    https://github.com/fchollet/keras/issues/1567\n    '''\n    num_states = 2 if layer_class is recurrent.LSTM else 1\n\n    inputs = Input((timesteps, embedding_dim))\n    _ = Masking()(inputs)\n    initial_state = [Input((units,)) for _ in range(num_states)]\n    output = layer_class(units)(inputs, initial_state=initial_state)\n\n    model = Model([inputs] + initial_state, output)\n    model.compile(loss='categorical_crossentropy', optimizer='adam')\n\n    inputs = np.random.random((num_samples, timesteps, embedding_dim))\n    initial_state = [np.random.random((num_samples, units))\n                     for _ in range(num_states)]\n    targets = np.random.random((num_samples, units))\n    model.fit([inputs] + initial_state, targets)",
        "begin_line": 356,
        "end_line": 374,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_return_state#378",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_return_state(layer_class)",
        "snippet": "def test_return_state(layer_class):\n    num_states = 2 if layer_class is recurrent.LSTM else 1\n\n    inputs = Input(batch_shape=(num_samples, timesteps, embedding_dim))\n    layer = layer_class(units, return_state=True, stateful=True)\n    outputs = layer(inputs)\n    output, state = outputs[0], outputs[1:]\n    assert len(state) == num_states\n    model = Model(inputs, state[0])\n\n    inputs = np.random.random((num_samples, timesteps, embedding_dim))\n    state = model.predict(inputs)\n    np.testing.assert_allclose(K.eval(layer.states[0]), state, atol=1e-4)",
        "begin_line": 378,
        "end_line": 390,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_state_reuse#394",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_state_reuse(layer_class)",
        "snippet": "def test_state_reuse(layer_class):\n    inputs = Input(batch_shape=(num_samples, timesteps, embedding_dim))\n    layer = layer_class(units, return_state=True, return_sequences=True)\n    outputs = layer(inputs)\n    output, state = outputs[0], outputs[1:]\n    output = layer_class(units)(output, initial_state=state)\n    model = Model(inputs, output)\n\n    inputs = np.random.random((num_samples, timesteps, embedding_dim))\n    outputs = model.predict(inputs)",
        "begin_line": 394,
        "end_line": 403,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_minimal_rnn_cell_non_layer#407",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_minimal_rnn_cell_non_layer()",
        "snippet": "def test_minimal_rnn_cell_non_layer():\n\n    class MinimalRNNCell(object):\n\n        def __init__(self, units, input_dim):\n            self.units = units\n            self.state_size = units\n            self.kernel = keras.backend.variable(\n                np.random.random((input_dim, units)))\n\n        def call(self, inputs, states):\n            prev_output = states[0]\n            output = keras.backend.dot(inputs, self.kernel) + prev_output\n            return output, [output]\n\n    # Basic test case.\n    cell = MinimalRNNCell(32, 5)\n    x = keras.Input((None, 5))\n    layer = recurrent.RNN(cell)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))\n\n    # Test stacking.\n    cells = [MinimalRNNCell(8, 5),\n             MinimalRNNCell(32, 8),\n             MinimalRNNCell(32, 32)]\n    layer = recurrent.RNN(cells)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))",
        "begin_line": 407,
        "end_line": 439,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.MinimalRNNCell.test_minimal_rnn_cell_non_layer#407",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.MinimalRNNCell",
        "signature": "tests.keras.layers.recurrent_test.MinimalRNNCell.test_minimal_rnn_cell_non_layer()",
        "snippet": "def test_minimal_rnn_cell_non_layer():\n\n    class MinimalRNNCell(object):\n\n        def __init__(self, units, input_dim):\n            self.units = units\n            self.state_size = units\n            self.kernel = keras.backend.variable(\n                np.random.random((input_dim, units)))\n\n        def call(self, inputs, states):\n            prev_output = states[0]\n            output = keras.backend.dot(inputs, self.kernel) + prev_output\n            return output, [output]\n\n    # Basic test case.\n    cell = MinimalRNNCell(32, 5)\n    x = keras.Input((None, 5))\n    layer = recurrent.RNN(cell)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))\n\n    # Test stacking.\n    cells = [MinimalRNNCell(8, 5),\n             MinimalRNNCell(32, 8),\n             MinimalRNNCell(32, 32)]\n    layer = recurrent.RNN(cells)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))",
        "begin_line": 407,
        "end_line": 439,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.MinimalRNNCell.__init__#411",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.MinimalRNNCell",
        "signature": "tests.keras.layers.recurrent_test.MinimalRNNCell.__init__(self, units, input_dim)",
        "snippet": "        def __init__(self, units, input_dim):\n            self.units = units\n            self.state_size = units\n            self.kernel = keras.backend.variable(\n                np.random.random((input_dim, units)))",
        "begin_line": 411,
        "end_line": 415,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.MinimalRNNCell.call#417",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.MinimalRNNCell",
        "signature": "tests.keras.layers.recurrent_test.MinimalRNNCell.call(self, inputs, states)",
        "snippet": "        def call(self, inputs, states):\n            prev_output = states[0]\n            output = keras.backend.dot(inputs, self.kernel) + prev_output\n            return output, [output]",
        "begin_line": 417,
        "end_line": 420,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_minimal_rnn_cell_non_layer_multiple_states#443",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_minimal_rnn_cell_non_layer_multiple_states()",
        "snippet": "def test_minimal_rnn_cell_non_layer_multiple_states():\n\n    class MinimalRNNCell(object):\n\n        def __init__(self, units, input_dim):\n            self.units = units\n            self.state_size = (units, units)\n            self.kernel = keras.backend.variable(\n                np.random.random((input_dim, units)))\n\n        def call(self, inputs, states):\n            prev_output_1 = states[0]\n            prev_output_2 = states[1]\n            output = keras.backend.dot(inputs, self.kernel)\n            output += prev_output_1\n            output -= prev_output_2\n            return output, [output * 2, output * 3]\n\n    # Basic test case.\n    cell = MinimalRNNCell(32, 5)\n    x = keras.Input((None, 5))\n    layer = recurrent.RNN(cell)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))\n\n    # Test stacking.\n    cells = [MinimalRNNCell(8, 5),\n             MinimalRNNCell(16, 8),\n             MinimalRNNCell(32, 16)]\n    layer = recurrent.RNN(cells)\n    assert layer.cell.state_size == (32, 32, 16, 16, 8, 8)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))",
        "begin_line": 443,
        "end_line": 479,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.MinimalRNNCell.test_minimal_rnn_cell_non_layer_multiple_states#443",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.MinimalRNNCell",
        "signature": "tests.keras.layers.recurrent_test.MinimalRNNCell.test_minimal_rnn_cell_non_layer_multiple_states()",
        "snippet": "def test_minimal_rnn_cell_non_layer_multiple_states():\n\n    class MinimalRNNCell(object):\n\n        def __init__(self, units, input_dim):\n            self.units = units\n            self.state_size = (units, units)\n            self.kernel = keras.backend.variable(\n                np.random.random((input_dim, units)))\n\n        def call(self, inputs, states):\n            prev_output_1 = states[0]\n            prev_output_2 = states[1]\n            output = keras.backend.dot(inputs, self.kernel)\n            output += prev_output_1\n            output -= prev_output_2\n            return output, [output * 2, output * 3]\n\n    # Basic test case.\n    cell = MinimalRNNCell(32, 5)\n    x = keras.Input((None, 5))\n    layer = recurrent.RNN(cell)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))\n\n    # Test stacking.\n    cells = [MinimalRNNCell(8, 5),\n             MinimalRNNCell(16, 8),\n             MinimalRNNCell(32, 16)]\n    layer = recurrent.RNN(cells)\n    assert layer.cell.state_size == (32, 32, 16, 16, 8, 8)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))",
        "begin_line": 443,
        "end_line": 479,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.MinimalRNNCell.__init__#447",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.MinimalRNNCell",
        "signature": "tests.keras.layers.recurrent_test.MinimalRNNCell.__init__(self, units, input_dim)",
        "snippet": "        def __init__(self, units, input_dim):\n            self.units = units\n            self.state_size = (units, units)\n            self.kernel = keras.backend.variable(\n                np.random.random((input_dim, units)))",
        "begin_line": 447,
        "end_line": 451,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.MinimalRNNCell.call#453",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.MinimalRNNCell",
        "signature": "tests.keras.layers.recurrent_test.MinimalRNNCell.call(self, inputs, states)",
        "snippet": "        def call(self, inputs, states):\n            prev_output_1 = states[0]\n            prev_output_2 = states[1]\n            output = keras.backend.dot(inputs, self.kernel)\n            output += prev_output_1\n            output -= prev_output_2\n            return output, [output * 2, output * 3]",
        "begin_line": 453,
        "end_line": 459,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_minimal_rnn_cell_layer#483",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_minimal_rnn_cell_layer()",
        "snippet": "def test_minimal_rnn_cell_layer():\n\n    class MinimalRNNCell(keras.layers.Layer):\n\n        def __init__(self, units, **kwargs):\n            self.units = units\n            self.state_size = units\n            super(MinimalRNNCell, self).__init__(**kwargs)\n\n        def build(self, input_shape):\n            self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n                                          initializer='uniform',\n                                          name='kernel')\n            self.recurrent_kernel = self.add_weight(\n                shape=(self.units, self.units),\n                initializer='uniform',\n                name='recurrent_kernel')\n            self.built = True\n\n        def call(self, inputs, states):\n            prev_output = states[0]\n            h = keras.backend.dot(inputs, self.kernel)\n            output = h + keras.backend.dot(prev_output, self.recurrent_kernel)\n            return output, [output]\n\n        def get_config(self):\n            config = {'units': self.units}\n            base_config = super(MinimalRNNCell, self).get_config()\n            return dict(list(base_config.items()) + list(config.items()))\n\n    # Test basic case.\n    x = keras.Input((None, 5))\n    cell = MinimalRNNCell(32)\n    layer = recurrent.RNN(cell)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))\n\n    # Test basic case serialization.\n    x_np = np.random.random((6, 5, 5))\n    y_np = model.predict(x_np)\n    weights = model.get_weights()\n    config = layer.get_config()\n    with keras.utils.CustomObjectScope({'MinimalRNNCell': MinimalRNNCell}):\n        layer = recurrent.RNN.from_config(config)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.set_weights(weights)\n    y_np_2 = model.predict(x_np)\n    assert_allclose(y_np, y_np_2, atol=1e-4)\n\n    # Test stacking.\n    cells = [MinimalRNNCell(8),\n             MinimalRNNCell(12),\n             MinimalRNNCell(32)]\n    layer = recurrent.RNN(cells)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))\n\n    # Test stacked RNN serialization.\n    x_np = np.random.random((6, 5, 5))\n    y_np = model.predict(x_np)\n    weights = model.get_weights()\n    config = layer.get_config()\n    with keras.utils.CustomObjectScope({'MinimalRNNCell': MinimalRNNCell}):\n        layer = recurrent.RNN.from_config(config)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.set_weights(weights)\n    y_np_2 = model.predict(x_np)\n    assert_allclose(y_np, y_np_2, atol=1e-4)",
        "begin_line": 483,
        "end_line": 556,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.MinimalRNNCell.test_minimal_rnn_cell_layer#483",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.MinimalRNNCell",
        "signature": "tests.keras.layers.recurrent_test.MinimalRNNCell.test_minimal_rnn_cell_layer()",
        "snippet": "def test_minimal_rnn_cell_layer():\n\n    class MinimalRNNCell(keras.layers.Layer):\n\n        def __init__(self, units, **kwargs):\n            self.units = units\n            self.state_size = units\n            super(MinimalRNNCell, self).__init__(**kwargs)\n\n        def build(self, input_shape):\n            self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n                                          initializer='uniform',\n                                          name='kernel')\n            self.recurrent_kernel = self.add_weight(\n                shape=(self.units, self.units),\n                initializer='uniform',\n                name='recurrent_kernel')\n            self.built = True\n\n        def call(self, inputs, states):\n            prev_output = states[0]\n            h = keras.backend.dot(inputs, self.kernel)\n            output = h + keras.backend.dot(prev_output, self.recurrent_kernel)\n            return output, [output]\n\n        def get_config(self):\n            config = {'units': self.units}\n            base_config = super(MinimalRNNCell, self).get_config()\n            return dict(list(base_config.items()) + list(config.items()))\n\n    # Test basic case.\n    x = keras.Input((None, 5))\n    cell = MinimalRNNCell(32)\n    layer = recurrent.RNN(cell)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))\n\n    # Test basic case serialization.\n    x_np = np.random.random((6, 5, 5))\n    y_np = model.predict(x_np)\n    weights = model.get_weights()\n    config = layer.get_config()\n    with keras.utils.CustomObjectScope({'MinimalRNNCell': MinimalRNNCell}):\n        layer = recurrent.RNN.from_config(config)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.set_weights(weights)\n    y_np_2 = model.predict(x_np)\n    assert_allclose(y_np, y_np_2, atol=1e-4)\n\n    # Test stacking.\n    cells = [MinimalRNNCell(8),\n             MinimalRNNCell(12),\n             MinimalRNNCell(32)]\n    layer = recurrent.RNN(cells)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))\n\n    # Test stacked RNN serialization.\n    x_np = np.random.random((6, 5, 5))\n    y_np = model.predict(x_np)\n    weights = model.get_weights()\n    config = layer.get_config()\n    with keras.utils.CustomObjectScope({'MinimalRNNCell': MinimalRNNCell}):\n        layer = recurrent.RNN.from_config(config)\n    y = layer(x)\n    model = keras.models.Model(x, y)\n    model.set_weights(weights)\n    y_np_2 = model.predict(x_np)\n    assert_allclose(y_np, y_np_2, atol=1e-4)",
        "begin_line": 483,
        "end_line": 556,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.MinimalRNNCell.__init__#487",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.MinimalRNNCell",
        "signature": "tests.keras.layers.recurrent_test.MinimalRNNCell.__init__(self, units, **kwargs)",
        "snippet": "        def __init__(self, units, **kwargs):\n            self.units = units\n            self.state_size = units\n            super(MinimalRNNCell, self).__init__(**kwargs)",
        "begin_line": 487,
        "end_line": 490,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.MinimalRNNCell.build#492",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.MinimalRNNCell",
        "signature": "tests.keras.layers.recurrent_test.MinimalRNNCell.build(self, input_shape)",
        "snippet": "        def build(self, input_shape):\n            self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n                                          initializer='uniform',\n                                          name='kernel')\n            self.recurrent_kernel = self.add_weight(\n                shape=(self.units, self.units),\n                initializer='uniform',\n                name='recurrent_kernel')\n            self.built = True",
        "begin_line": 492,
        "end_line": 500,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.MinimalRNNCell.call#502",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.MinimalRNNCell",
        "signature": "tests.keras.layers.recurrent_test.MinimalRNNCell.call(self, inputs, states)",
        "snippet": "        def call(self, inputs, states):\n            prev_output = states[0]\n            h = keras.backend.dot(inputs, self.kernel)\n            output = h + keras.backend.dot(prev_output, self.recurrent_kernel)\n            return output, [output]",
        "begin_line": 502,
        "end_line": 506,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.MinimalRNNCell.get_config#508",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.MinimalRNNCell",
        "signature": "tests.keras.layers.recurrent_test.MinimalRNNCell.get_config(self)",
        "snippet": "        def get_config(self):\n            config = {'units': self.units}\n            base_config = super(MinimalRNNCell, self).get_config()\n            return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 508,
        "end_line": 511,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_stacked_rnn_attributes#560",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_stacked_rnn_attributes()",
        "snippet": "def test_stacked_rnn_attributes():\n    cells = [recurrent.LSTMCell(3),\n             recurrent.LSTMCell(3, kernel_regularizer='l2')]\n    layer = recurrent.RNN(cells)\n    layer.build((None, None, 5))\n\n    # Test regularization losses\n    assert len(layer.losses) == 1\n\n    # Test weights\n    assert len(layer.trainable_weights) == 6\n    cells[0].trainable = False\n    assert len(layer.trainable_weights) == 3\n    assert len(layer.non_trainable_weights) == 3\n\n    # Test `get_losses_for`\n    x = keras.Input((None, 5))\n    y = K.sum(x)\n    cells[0].add_loss(y, inputs=x)\n    assert layer.get_losses_for(x) == [y]",
        "begin_line": 560,
        "end_line": 579,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_batch_size_equal_one#583",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_batch_size_equal_one(layer_class)",
        "snippet": "def test_batch_size_equal_one(layer_class):\n    inputs = Input(batch_shape=(1, timesteps, embedding_dim))\n    layer = layer_class(units)\n    outputs = layer(inputs)\n    model = Model(inputs, outputs)\n    model.compile('sgd', 'mse')\n    x = np.random.random((1, timesteps, embedding_dim))\n    y = np.random.random((1, units))\n    model.train_on_batch(x, y)",
        "begin_line": 583,
        "end_line": 591,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_rnn_cell_with_constants_layer#594",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_rnn_cell_with_constants_layer()",
        "snippet": "def test_rnn_cell_with_constants_layer():\n\n    class RNNCellWithConstants(keras.layers.Layer):\n\n        def __init__(self, units, **kwargs):\n            self.units = units\n            self.state_size = units\n            super(RNNCellWithConstants, self).__init__(**kwargs)\n\n        def build(self, input_shape):\n            if not isinstance(input_shape, list):\n                raise TypeError('expects constants shape')\n            [input_shape, constant_shape] = input_shape\n            # will (and should) raise if more than one constant passed\n\n            self.input_kernel = self.add_weight(\n                shape=(input_shape[-1], self.units),\n                initializer='uniform',\n                name='kernel')\n            self.recurrent_kernel = self.add_weight(\n                shape=(self.units, self.units),\n                initializer='uniform',\n                name='recurrent_kernel')\n            self.constant_kernel = self.add_weight(\n                shape=(constant_shape[-1], self.units),\n                initializer='uniform',\n                name='constant_kernel')\n            self.built = True\n\n        def call(self, inputs, states, constants):\n            [prev_output] = states\n            [constant] = constants\n            h_input = keras.backend.dot(inputs, self.input_kernel)\n            h_state = keras.backend.dot(prev_output, self.recurrent_kernel)\n            h_const = keras.backend.dot(constant, self.constant_kernel)\n            output = h_input + h_state + h_const\n            return output, [output]\n\n        def get_config(self):\n            config = {'units': self.units}\n            base_config = super(RNNCellWithConstants, self).get_config()\n            return dict(list(base_config.items()) + list(config.items()))\n\n    # Test basic case.\n    x = keras.Input((None, 5))\n    c = keras.Input((3,))\n    cell = RNNCellWithConstants(32)\n    layer = recurrent.RNN(cell)\n    y = layer(x, constants=c)\n    model = keras.models.Model([x, c], y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(\n        [np.zeros((6, 5, 5)), np.zeros((6, 3))],\n        np.zeros((6, 32))\n    )\n\n    # Test basic case serialization.\n    x_np = np.random.random((6, 5, 5))\n    c_np = np.random.random((6, 3))\n    y_np = model.predict([x_np, c_np])\n    weights = model.get_weights()\n    config = layer.get_config()\n    custom_objects = {'RNNCellWithConstants': RNNCellWithConstants}\n    with keras.utils.CustomObjectScope(custom_objects):\n        layer = recurrent.RNN.from_config(config.copy())\n    y = layer(x, constants=c)\n    model = keras.models.Model([x, c], y)\n    model.set_weights(weights)\n    y_np_2 = model.predict([x_np, c_np])\n    assert_allclose(y_np, y_np_2, atol=1e-4)\n\n    # test flat list inputs\n    with keras.utils.CustomObjectScope(custom_objects):\n        layer = recurrent.RNN.from_config(config.copy())\n    y = layer([x, c])\n    model = keras.models.Model([x, c], y)\n    model.set_weights(weights)\n    y_np_3 = model.predict([x_np, c_np])\n    assert_allclose(y_np, y_np_3, atol=1e-4)",
        "begin_line": 594,
        "end_line": 672,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.RNNCellWithConstants.test_rnn_cell_with_constants_layer#594",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.RNNCellWithConstants",
        "signature": "tests.keras.layers.recurrent_test.RNNCellWithConstants.test_rnn_cell_with_constants_layer()",
        "snippet": "def test_rnn_cell_with_constants_layer():\n\n    class RNNCellWithConstants(keras.layers.Layer):\n\n        def __init__(self, units, **kwargs):\n            self.units = units\n            self.state_size = units\n            super(RNNCellWithConstants, self).__init__(**kwargs)\n\n        def build(self, input_shape):\n            if not isinstance(input_shape, list):\n                raise TypeError('expects constants shape')\n            [input_shape, constant_shape] = input_shape\n            # will (and should) raise if more than one constant passed\n\n            self.input_kernel = self.add_weight(\n                shape=(input_shape[-1], self.units),\n                initializer='uniform',\n                name='kernel')\n            self.recurrent_kernel = self.add_weight(\n                shape=(self.units, self.units),\n                initializer='uniform',\n                name='recurrent_kernel')\n            self.constant_kernel = self.add_weight(\n                shape=(constant_shape[-1], self.units),\n                initializer='uniform',\n                name='constant_kernel')\n            self.built = True\n\n        def call(self, inputs, states, constants):\n            [prev_output] = states\n            [constant] = constants\n            h_input = keras.backend.dot(inputs, self.input_kernel)\n            h_state = keras.backend.dot(prev_output, self.recurrent_kernel)\n            h_const = keras.backend.dot(constant, self.constant_kernel)\n            output = h_input + h_state + h_const\n            return output, [output]\n\n        def get_config(self):\n            config = {'units': self.units}\n            base_config = super(RNNCellWithConstants, self).get_config()\n            return dict(list(base_config.items()) + list(config.items()))\n\n    # Test basic case.\n    x = keras.Input((None, 5))\n    c = keras.Input((3,))\n    cell = RNNCellWithConstants(32)\n    layer = recurrent.RNN(cell)\n    y = layer(x, constants=c)\n    model = keras.models.Model([x, c], y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(\n        [np.zeros((6, 5, 5)), np.zeros((6, 3))],\n        np.zeros((6, 32))\n    )\n\n    # Test basic case serialization.\n    x_np = np.random.random((6, 5, 5))\n    c_np = np.random.random((6, 3))\n    y_np = model.predict([x_np, c_np])\n    weights = model.get_weights()\n    config = layer.get_config()\n    custom_objects = {'RNNCellWithConstants': RNNCellWithConstants}\n    with keras.utils.CustomObjectScope(custom_objects):\n        layer = recurrent.RNN.from_config(config.copy())\n    y = layer(x, constants=c)\n    model = keras.models.Model([x, c], y)\n    model.set_weights(weights)\n    y_np_2 = model.predict([x_np, c_np])\n    assert_allclose(y_np, y_np_2, atol=1e-4)\n\n    # test flat list inputs\n    with keras.utils.CustomObjectScope(custom_objects):\n        layer = recurrent.RNN.from_config(config.copy())\n    y = layer([x, c])\n    model = keras.models.Model([x, c], y)\n    model.set_weights(weights)\n    y_np_3 = model.predict([x_np, c_np])\n    assert_allclose(y_np, y_np_3, atol=1e-4)",
        "begin_line": 594,
        "end_line": 672,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.RNNCellWithConstants.__init__#598",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.RNNCellWithConstants",
        "signature": "tests.keras.layers.recurrent_test.RNNCellWithConstants.__init__(self, units, **kwargs)",
        "snippet": "        def __init__(self, units, **kwargs):\n            self.units = units\n            self.state_size = units\n            super(RNNCellWithConstants, self).__init__(**kwargs)",
        "begin_line": 598,
        "end_line": 601,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.RNNCellWithConstants.build#603",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.RNNCellWithConstants",
        "signature": "tests.keras.layers.recurrent_test.RNNCellWithConstants.build(self, input_shape)",
        "snippet": "        def build(self, input_shape):\n            if not isinstance(input_shape, list):\n                raise TypeError('expects constants shape')\n            [input_shape, constant_shape] = input_shape\n            # will (and should) raise if more than one constant passed\n\n            self.input_kernel = self.add_weight(\n                shape=(input_shape[-1], self.units),\n                initializer='uniform',\n                name='kernel')\n            self.recurrent_kernel = self.add_weight(\n                shape=(self.units, self.units),\n                initializer='uniform',\n                name='recurrent_kernel')\n            self.constant_kernel = self.add_weight(\n                shape=(constant_shape[-1], self.units),\n                initializer='uniform',\n                name='constant_kernel')\n            self.built = True",
        "begin_line": 603,
        "end_line": 621,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.RNNCellWithConstants.call#623",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.RNNCellWithConstants",
        "signature": "tests.keras.layers.recurrent_test.RNNCellWithConstants.call(self, inputs, states, constants)",
        "snippet": "        def call(self, inputs, states, constants):\n            [prev_output] = states\n            [constant] = constants\n            h_input = keras.backend.dot(inputs, self.input_kernel)\n            h_state = keras.backend.dot(prev_output, self.recurrent_kernel)\n            h_const = keras.backend.dot(constant, self.constant_kernel)\n            output = h_input + h_state + h_const\n            return output, [output]",
        "begin_line": 623,
        "end_line": 630,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.RNNCellWithConstants.get_config#632",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.RNNCellWithConstants",
        "signature": "tests.keras.layers.recurrent_test.RNNCellWithConstants.get_config(self)",
        "snippet": "        def get_config(self):\n            config = {'units': self.units}\n            base_config = super(RNNCellWithConstants, self).get_config()\n            return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 632,
        "end_line": 635,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.test_rnn_cell_with_constants_layer_passing_initial_state#675",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test",
        "signature": "tests.keras.layers.recurrent_test.test_rnn_cell_with_constants_layer_passing_initial_state()",
        "snippet": "def test_rnn_cell_with_constants_layer_passing_initial_state():\n\n    class RNNCellWithConstants(keras.layers.Layer):\n\n        def __init__(self, units, **kwargs):\n            self.units = units\n            self.state_size = units\n            super(RNNCellWithConstants, self).__init__(**kwargs)\n\n        def build(self, input_shape):\n            if not isinstance(input_shape, list):\n                raise TypeError('expects constants shape')\n            [input_shape, constant_shape] = input_shape\n            # will (and should) raise if more than one constant passed\n\n            self.input_kernel = self.add_weight(\n                shape=(input_shape[-1], self.units),\n                initializer='uniform',\n                name='kernel')\n            self.recurrent_kernel = self.add_weight(\n                shape=(self.units, self.units),\n                initializer='uniform',\n                name='recurrent_kernel')\n            self.constant_kernel = self.add_weight(\n                shape=(constant_shape[-1], self.units),\n                initializer='uniform',\n                name='constant_kernel')\n            self.built = True\n\n        def call(self, inputs, states, constants):\n            [prev_output] = states\n            [constant] = constants\n            h_input = keras.backend.dot(inputs, self.input_kernel)\n            h_state = keras.backend.dot(prev_output, self.recurrent_kernel)\n            h_const = keras.backend.dot(constant, self.constant_kernel)\n            output = h_input + h_state + h_const\n            return output, [output]\n\n        def get_config(self):\n            config = {'units': self.units}\n            base_config = super(RNNCellWithConstants, self).get_config()\n            return dict(list(base_config.items()) + list(config.items()))\n\n    # Test basic case.\n    x = keras.Input((None, 5))\n    c = keras.Input((3,))\n    s = keras.Input((32,))\n    cell = RNNCellWithConstants(32)\n    layer = recurrent.RNN(cell)\n    y = layer(x, initial_state=s, constants=c)\n    model = keras.models.Model([x, s, c], y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(\n        [np.zeros((6, 5, 5)), np.zeros((6, 32)), np.zeros((6, 3))],\n        np.zeros((6, 32))\n    )\n\n    # Test basic case serialization.\n    x_np = np.random.random((6, 5, 5))\n    s_np = np.random.random((6, 32))\n    c_np = np.random.random((6, 3))\n    y_np = model.predict([x_np, s_np, c_np])\n    weights = model.get_weights()\n    config = layer.get_config()\n    custom_objects = {'RNNCellWithConstants': RNNCellWithConstants}\n    with keras.utils.CustomObjectScope(custom_objects):\n        layer = recurrent.RNN.from_config(config.copy())\n    y = layer(x, initial_state=s, constants=c)\n    model = keras.models.Model([x, s, c], y)\n    model.set_weights(weights)\n    y_np_2 = model.predict([x_np, s_np, c_np])\n    assert_allclose(y_np, y_np_2, atol=1e-4)\n\n    # verify that state is used\n    y_np_2_different_s = model.predict([x_np, s_np + 10., c_np])\n    with pytest.raises(AssertionError):\n        assert_allclose(y_np, y_np_2_different_s, atol=1e-4)\n\n    # test flat list inputs\n    with keras.utils.CustomObjectScope(custom_objects):\n        layer = recurrent.RNN.from_config(config.copy())\n    y = layer([x, s, c])\n    model = keras.models.Model([x, s, c], y)\n    model.set_weights(weights)\n    y_np_3 = model.predict([x_np, s_np, c_np])\n    assert_allclose(y_np, y_np_3, atol=1e-4)",
        "begin_line": 675,
        "end_line": 760,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.RNNCellWithConstants.test_rnn_cell_with_constants_layer_passing_initial_state#675",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.RNNCellWithConstants",
        "signature": "tests.keras.layers.recurrent_test.RNNCellWithConstants.test_rnn_cell_with_constants_layer_passing_initial_state()",
        "snippet": "def test_rnn_cell_with_constants_layer_passing_initial_state():\n\n    class RNNCellWithConstants(keras.layers.Layer):\n\n        def __init__(self, units, **kwargs):\n            self.units = units\n            self.state_size = units\n            super(RNNCellWithConstants, self).__init__(**kwargs)\n\n        def build(self, input_shape):\n            if not isinstance(input_shape, list):\n                raise TypeError('expects constants shape')\n            [input_shape, constant_shape] = input_shape\n            # will (and should) raise if more than one constant passed\n\n            self.input_kernel = self.add_weight(\n                shape=(input_shape[-1], self.units),\n                initializer='uniform',\n                name='kernel')\n            self.recurrent_kernel = self.add_weight(\n                shape=(self.units, self.units),\n                initializer='uniform',\n                name='recurrent_kernel')\n            self.constant_kernel = self.add_weight(\n                shape=(constant_shape[-1], self.units),\n                initializer='uniform',\n                name='constant_kernel')\n            self.built = True\n\n        def call(self, inputs, states, constants):\n            [prev_output] = states\n            [constant] = constants\n            h_input = keras.backend.dot(inputs, self.input_kernel)\n            h_state = keras.backend.dot(prev_output, self.recurrent_kernel)\n            h_const = keras.backend.dot(constant, self.constant_kernel)\n            output = h_input + h_state + h_const\n            return output, [output]\n\n        def get_config(self):\n            config = {'units': self.units}\n            base_config = super(RNNCellWithConstants, self).get_config()\n            return dict(list(base_config.items()) + list(config.items()))\n\n    # Test basic case.\n    x = keras.Input((None, 5))\n    c = keras.Input((3,))\n    s = keras.Input((32,))\n    cell = RNNCellWithConstants(32)\n    layer = recurrent.RNN(cell)\n    y = layer(x, initial_state=s, constants=c)\n    model = keras.models.Model([x, s, c], y)\n    model.compile(optimizer='rmsprop', loss='mse')\n    model.train_on_batch(\n        [np.zeros((6, 5, 5)), np.zeros((6, 32)), np.zeros((6, 3))],\n        np.zeros((6, 32))\n    )\n\n    # Test basic case serialization.\n    x_np = np.random.random((6, 5, 5))\n    s_np = np.random.random((6, 32))\n    c_np = np.random.random((6, 3))\n    y_np = model.predict([x_np, s_np, c_np])\n    weights = model.get_weights()\n    config = layer.get_config()\n    custom_objects = {'RNNCellWithConstants': RNNCellWithConstants}\n    with keras.utils.CustomObjectScope(custom_objects):\n        layer = recurrent.RNN.from_config(config.copy())\n    y = layer(x, initial_state=s, constants=c)\n    model = keras.models.Model([x, s, c], y)\n    model.set_weights(weights)\n    y_np_2 = model.predict([x_np, s_np, c_np])\n    assert_allclose(y_np, y_np_2, atol=1e-4)\n\n    # verify that state is used\n    y_np_2_different_s = model.predict([x_np, s_np + 10., c_np])\n    with pytest.raises(AssertionError):\n        assert_allclose(y_np, y_np_2_different_s, atol=1e-4)\n\n    # test flat list inputs\n    with keras.utils.CustomObjectScope(custom_objects):\n        layer = recurrent.RNN.from_config(config.copy())\n    y = layer([x, s, c])\n    model = keras.models.Model([x, s, c], y)\n    model.set_weights(weights)\n    y_np_3 = model.predict([x_np, s_np, c_np])\n    assert_allclose(y_np, y_np_3, atol=1e-4)",
        "begin_line": 675,
        "end_line": 760,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.RNNCellWithConstants.__init__#679",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.RNNCellWithConstants",
        "signature": "tests.keras.layers.recurrent_test.RNNCellWithConstants.__init__(self, units, **kwargs)",
        "snippet": "        def __init__(self, units, **kwargs):\n            self.units = units\n            self.state_size = units\n            super(RNNCellWithConstants, self).__init__(**kwargs)",
        "begin_line": 679,
        "end_line": 682,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.RNNCellWithConstants.build#684",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.RNNCellWithConstants",
        "signature": "tests.keras.layers.recurrent_test.RNNCellWithConstants.build(self, input_shape)",
        "snippet": "        def build(self, input_shape):\n            if not isinstance(input_shape, list):\n                raise TypeError('expects constants shape')\n            [input_shape, constant_shape] = input_shape\n            # will (and should) raise if more than one constant passed\n\n            self.input_kernel = self.add_weight(\n                shape=(input_shape[-1], self.units),\n                initializer='uniform',\n                name='kernel')\n            self.recurrent_kernel = self.add_weight(\n                shape=(self.units, self.units),\n                initializer='uniform',\n                name='recurrent_kernel')\n            self.constant_kernel = self.add_weight(\n                shape=(constant_shape[-1], self.units),\n                initializer='uniform',\n                name='constant_kernel')\n            self.built = True",
        "begin_line": 684,
        "end_line": 702,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.RNNCellWithConstants.call#704",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.RNNCellWithConstants",
        "signature": "tests.keras.layers.recurrent_test.RNNCellWithConstants.call(self, inputs, states, constants)",
        "snippet": "        def call(self, inputs, states, constants):\n            [prev_output] = states\n            [constant] = constants\n            h_input = keras.backend.dot(inputs, self.input_kernel)\n            h_state = keras.backend.dot(prev_output, self.recurrent_kernel)\n            h_const = keras.backend.dot(constant, self.constant_kernel)\n            output = h_input + h_state + h_const\n            return output, [output]",
        "begin_line": 704,
        "end_line": 711,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.layers.recurrent_test.RNNCellWithConstants.get_config#713",
        "src_path": "tests/keras/layers/recurrent_test.py",
        "class_name": "tests.keras.layers.recurrent_test.RNNCellWithConstants",
        "signature": "tests.keras.layers.recurrent_test.RNNCellWithConstants.get_config(self)",
        "snippet": "        def get_config(self):\n            config = {'units': self.units}\n            base_config = super(RNNCellWithConstants, self).get_config()\n            return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 713,
        "end_line": 716,
        "comment": "",
        "is_bug": false
    }
]