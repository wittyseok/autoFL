[
    {
        "name": "keras.layers.noise.GaussianNoise.__init__#34",
        "src_path": "keras/layers/noise.py",
        "class_name": "keras.layers.noise.GaussianNoise",
        "signature": "keras.layers.noise.GaussianNoise.__init__(self, stddev, **kwargs)",
        "snippet": "    def __init__(self, stddev, **kwargs):\n        super(GaussianNoise, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.stddev = stddev",
        "begin_line": 34,
        "end_line": 37,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.noise.GaussianNoise.call#39",
        "src_path": "keras/layers/noise.py",
        "class_name": "keras.layers.noise.GaussianNoise",
        "signature": "keras.layers.noise.GaussianNoise.call(self, inputs, training=None)",
        "snippet": "    def call(self, inputs, training=None):\n        def noised():\n            return inputs + K.random_normal(shape=K.shape(inputs),\n                                            mean=0.,\n                                            stddev=self.stddev)\n        return K.in_train_phase(noised, inputs, training=training)",
        "begin_line": 39,
        "end_line": 44,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.noise.GaussianNoise.noised#40",
        "src_path": "keras/layers/noise.py",
        "class_name": "keras.layers.noise.GaussianNoise",
        "signature": "keras.layers.noise.GaussianNoise.noised()",
        "snippet": "        def noised():\n            return inputs + K.random_normal(shape=K.shape(inputs),\n                                            mean=0.,\n                                            stddev=self.stddev)",
        "begin_line": 40,
        "end_line": 43,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.noise.GaussianNoise.get_config#46",
        "src_path": "keras/layers/noise.py",
        "class_name": "keras.layers.noise.GaussianNoise",
        "signature": "keras.layers.noise.GaussianNoise.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'stddev': self.stddev}\n        base_config = super(GaussianNoise, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 46,
        "end_line": 49,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.noise.GaussianDropout.__init__#75",
        "src_path": "keras/layers/noise.py",
        "class_name": "keras.layers.noise.GaussianDropout",
        "signature": "keras.layers.noise.GaussianDropout.__init__(self, rate, **kwargs)",
        "snippet": "    def __init__(self, rate, **kwargs):\n        super(GaussianDropout, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.rate = rate",
        "begin_line": 75,
        "end_line": 78,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.noise.GaussianDropout.call#80",
        "src_path": "keras/layers/noise.py",
        "class_name": "keras.layers.noise.GaussianDropout",
        "signature": "keras.layers.noise.GaussianDropout.call(self, inputs, training=None)",
        "snippet": "    def call(self, inputs, training=None):\n        if 0 < self.rate < 1:\n            def noised():\n                stddev = np.sqrt(self.rate / (1.0 - self.rate))\n                return inputs * K.random_normal(shape=K.shape(inputs),\n                                                mean=1.0,\n                                                stddev=stddev)\n            return K.in_train_phase(noised, inputs, training=training)\n        return inputs",
        "begin_line": 80,
        "end_line": 88,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.noise.GaussianDropout.noised#82",
        "src_path": "keras/layers/noise.py",
        "class_name": "keras.layers.noise.GaussianDropout",
        "signature": "keras.layers.noise.GaussianDropout.noised()",
        "snippet": "            def noised():\n                stddev = np.sqrt(self.rate / (1.0 - self.rate))\n                return inputs * K.random_normal(shape=K.shape(inputs),\n                                                mean=1.0,\n                                                stddev=stddev)",
        "begin_line": 82,
        "end_line": 86,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.noise.GaussianDropout.get_config#90",
        "src_path": "keras/layers/noise.py",
        "class_name": "keras.layers.noise.GaussianDropout",
        "signature": "keras.layers.noise.GaussianDropout.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'rate': self.rate}\n        base_config = super(GaussianDropout, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 90,
        "end_line": 93,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.noise.AlphaDropout.__init__#122",
        "src_path": "keras/layers/noise.py",
        "class_name": "keras.layers.noise.AlphaDropout",
        "signature": "keras.layers.noise.AlphaDropout.__init__(self, rate, noise_shape=None, seed=None, **kwargs)",
        "snippet": "    def __init__(self, rate, noise_shape=None, seed=None, **kwargs):\n        super(AlphaDropout, self).__init__(**kwargs)\n        self.rate = rate\n        self.noise_shape = noise_shape\n        self.seed = seed\n        self.supports_masking = True",
        "begin_line": 122,
        "end_line": 127,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.noise.AlphaDropout._get_noise_shape#129",
        "src_path": "keras/layers/noise.py",
        "class_name": "keras.layers.noise.AlphaDropout",
        "signature": "keras.layers.noise.AlphaDropout._get_noise_shape(self, inputs)",
        "snippet": "    def _get_noise_shape(self, inputs):\n        return self.noise_shape if self.noise_shape else K.shape(inputs)",
        "begin_line": 129,
        "end_line": 130,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.noise.AlphaDropout.call#132",
        "src_path": "keras/layers/noise.py",
        "class_name": "keras.layers.noise.AlphaDropout",
        "signature": "keras.layers.noise.AlphaDropout.call(self, inputs, training=None)",
        "snippet": "    def call(self, inputs, training=None):\n        if 0. < self.rate < 1.:\n            noise_shape = self._get_noise_shape(inputs)\n\n            def dropped_inputs(inputs=inputs, rate=self.rate, seed=self.seed):\n                alpha = 1.6732632423543772848170429916717\n                scale = 1.0507009873554804934193349852946\n                alpha_p = -alpha * scale\n\n                kept_idx = K.greater_equal(K.random_uniform(noise_shape, seed=seed), rate)\n                kept_idx = K.cast(kept_idx, K.floatx())\n\n                # Get affine transformation params\n                a = ((1 - rate) * (1 + rate * alpha_p ** 2)) ** -0.5\n                b = -a * alpha_p * rate\n\n                # Apply mask\n                x = inputs * kept_idx + alpha_p * (1 - kept_idx)\n\n                # Do affine transformation\n                return a * x + b\n\n            return K.in_train_phase(dropped_inputs, inputs, training=training)\n        return inputs",
        "begin_line": 132,
        "end_line": 155,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.noise.AlphaDropout.dropped_inputs#136",
        "src_path": "keras/layers/noise.py",
        "class_name": "keras.layers.noise.AlphaDropout",
        "signature": "keras.layers.noise.AlphaDropout.dropped_inputs(inputs=inputs, rate=self.rate, seed=self.seed)",
        "snippet": "            def dropped_inputs(inputs=inputs, rate=self.rate, seed=self.seed):\n                alpha = 1.6732632423543772848170429916717\n                scale = 1.0507009873554804934193349852946\n                alpha_p = -alpha * scale\n\n                kept_idx = K.greater_equal(K.random_uniform(noise_shape, seed=seed), rate)\n                kept_idx = K.cast(kept_idx, K.floatx())\n\n                # Get affine transformation params\n                a = ((1 - rate) * (1 + rate * alpha_p ** 2)) ** -0.5\n                b = -a * alpha_p * rate\n\n                # Apply mask\n                x = inputs * kept_idx + alpha_p * (1 - kept_idx)\n\n                # Do affine transformation\n                return a * x + b",
        "begin_line": 136,
        "end_line": 152,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.noise.AlphaDropout.get_config#157",
        "src_path": "keras/layers/noise.py",
        "class_name": "keras.layers.noise.AlphaDropout",
        "signature": "keras.layers.noise.AlphaDropout.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'rate': self.rate}\n        base_config = super(AlphaDropout, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 157,
        "end_line": 160,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.applications.resnet50.identity_block#40",
        "src_path": "keras/applications/resnet50.py",
        "class_name": "keras.applications.resnet50",
        "signature": "keras.applications.resnet50.identity_block(input_tensor, kernel_size, filters, stage, block)",
        "snippet": "def identity_block(input_tensor, kernel_size, filters, stage, block):\n    \"\"\"The identity block is the block that has no conv layer at shortcut.\n\n    # Arguments\n        input_tensor: input tensor\n        kernel_size: default 3, the kernel size of middle conv layer at main path\n        filters: list of integers, the filters of 3 conv layer at main path\n        stage: integer, current stage label, used for generating layer names\n        block: 'a','b'..., current block label, used for generating layer names\n\n    # Returns\n        Output tensor for the block.\n    \"\"\"\n    filters1, filters2, filters3 = filters\n    if K.image_data_format() == 'channels_last':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n\n    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(filters2, kernel_size,\n               padding='same', name=conv_name_base + '2b')(x)\n    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n\n    x = layers.add([x, input_tensor])\n    x = Activation('relu')(x)\n    return x",
        "begin_line": 40,
        "end_line": 75,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.applications.resnet50.conv_block#78",
        "src_path": "keras/applications/resnet50.py",
        "class_name": "keras.applications.resnet50",
        "signature": "keras.applications.resnet50.conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2))",
        "snippet": "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n    \"\"\"A block that has a conv layer at shortcut.\n\n    # Arguments\n        input_tensor: input tensor\n        kernel_size: default 3, the kernel size of middle conv layer at main path\n        filters: list of integers, the filters of 3 conv layer at main path\n        stage: integer, current stage label, used for generating layer names\n        block: 'a','b'..., current block label, used for generating layer names\n\n    # Returns\n        Output tensor for the block.\n\n    Note that from stage 3, the first conv layer at main path is with strides=(2,2)\n    And the shortcut should have strides=(2,2) as well\n    \"\"\"\n    filters1, filters2, filters3 = filters\n    if K.image_data_format() == 'channels_last':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n\n    x = Conv2D(filters1, (1, 1), strides=strides,\n               name=conv_name_base + '2a')(input_tensor)\n    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(filters2, kernel_size, padding='same',\n               name=conv_name_base + '2b')(x)\n    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n\n    shortcut = Conv2D(filters3, (1, 1), strides=strides,\n                      name=conv_name_base + '1')(input_tensor)\n    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n\n    x = layers.add([x, shortcut])\n    x = Activation('relu')(x)\n    return x",
        "begin_line": 78,
        "end_line": 121,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.applications.resnet50.ResNet50#124",
        "src_path": "keras/applications/resnet50.py",
        "class_name": "keras.applications.resnet50",
        "signature": "keras.applications.resnet50.ResNet50(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)",
        "snippet": "def ResNet50(include_top=True, weights='imagenet',\n             input_tensor=None, input_shape=None,\n             pooling=None,\n             classes=1000):\n    \"\"\"Instantiates the ResNet50 architecture.\n\n    Optionally loads weights pre-trained\n    on ImageNet. Note that when using TensorFlow,\n    for best performance you should set\n    `image_data_format='channels_last'` in your Keras config\n    at ~/.keras/keras.json.\n\n    The model and the weights are compatible with both\n    TensorFlow and Theano. The data format\n    convention used by the model is the one\n    specified in your Keras config file.\n\n    # Arguments\n        include_top: whether to include the fully-connected\n            layer at the top of the network.\n        weights: one of `None` (random initialization)\n            or 'imagenet' (pre-training on ImageNet).\n        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n            to use as image input for the model.\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(224, 224, 3)` (with `channels_last` data format)\n            or `(3, 224, 224)` (with `channels_first` data format).\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 197.\n            E.g. `(200, 200, 3)` would be one valid value.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model will be\n                the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a 2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n\n    # Returns\n        A Keras model instance.\n\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n    \"\"\"\n    if weights not in {'imagenet', None}:\n        raise ValueError('The `weights` argument should be either '\n                         '`None` (random initialization) or `imagenet` '\n                         '(pre-training on ImageNet).')\n\n    if weights == 'imagenet' and include_top and classes != 1000:\n        raise ValueError('If using `weights` as imagenet with `include_top`'\n                         ' as true, `classes` should be 1000')\n\n    # Determine proper input shape\n    input_shape = _obtain_input_shape(input_shape,\n                                      default_size=224,\n                                      min_size=197,\n                                      data_format=K.image_data_format(),\n                                      require_flatten=include_top,\n                                      weights=weights)\n\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n    if K.image_data_format() == 'channels_last':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n\n    x = Conv2D(\n        64, (7, 7), strides=(2, 2), padding='same', name='conv1')(img_input)\n    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n\n    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n\n    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n\n    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n\n    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n\n    x = AveragePooling2D((7, 7), name='avg_pool')(x)\n\n    if include_top:\n        x = Flatten()(x)\n        x = Dense(classes, activation='softmax', name='fc1000')(x)\n    else:\n        if pooling == 'avg':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling == 'max':\n            x = GlobalMaxPooling2D()(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n    # Create model.\n    model = Model(inputs, x, name='resnet50')\n\n    # load weights\n    if weights == 'imagenet':\n        if include_top:\n            weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels.h5',\n                                    WEIGHTS_PATH,\n                                    cache_subdir='models',\n                                    md5_hash='a7b3fe01876f51b976af0dea6bc144eb')\n        else:\n            weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n                                    WEIGHTS_PATH_NO_TOP,\n                                    cache_subdir='models',\n                                    md5_hash='a268eb855778b3df3c7506639542a6af')\n        model.load_weights(weights_path)\n        if K.backend() == 'theano':\n            layer_utils.convert_all_kernels_in_model(model)\n            if include_top:\n                maxpool = model.get_layer(name='avg_pool')\n                shape = maxpool.output_shape[1:]\n                dense = model.get_layer(name='fc1000')\n                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n\n        if K.image_data_format() == 'channels_first' and K.backend() == 'tensorflow':\n            warnings.warn('You are using the TensorFlow backend, yet you '\n                          'are using the Theano '\n                          'image data format convention '\n                          '(`image_data_format=\"channels_first\"`). '\n                          'For best performance, set '\n                          '`image_data_format=\"channels_last\"` in '\n                          'your Keras config '\n                          'at ~/.keras/keras.json.')\n    return model",
        "begin_line": 124,
        "end_line": 282,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.save_model#31",
        "src_path": "keras/models.py",
        "class_name": "keras.models",
        "signature": "keras.models.save_model(model, filepath, overwrite=True, include_optimizer=True)",
        "snippet": "def save_model(model, filepath, overwrite=True, include_optimizer=True):\n    \"\"\"Save a model to a HDF5 file.\n\n    The saved model contains:\n        - the model's configuration (topology)\n        - the model's weights\n        - the model's optimizer's state (if any)\n\n    Thus the saved model can be reinstantiated in\n    the exact same state, without any of the code\n    used for model definition or training.\n\n    # Arguments\n        model: Keras model instance to be saved.\n        filepath: String, path where to save the model.\n        overwrite: Whether we should overwrite any existing\n            model at the target location, or instead\n            ask the user with a manual prompt.\n        include_optimizer: If True, save optimizer's state together.\n\n    # Raises\n        ImportError: if h5py is not available.\n    \"\"\"\n\n    if h5py is None:\n        raise ImportError('`save_model` requires h5py.')\n\n    def get_json_type(obj):\n        \"\"\"Serialize any object to a JSON-serializable structure.\n\n        # Arguments\n            obj: the object to serialize\n\n        # Returns\n            JSON-serializable structure representing `obj`.\n\n        # Raises\n            TypeError: if `obj` cannot be serialized.\n        \"\"\"\n        # if obj is a serializable Keras class instance\n        # e.g. optimizer, layer\n        if hasattr(obj, 'get_config'):\n            return {'class_name': obj.__class__.__name__,\n                    'config': obj.get_config()}\n\n        # if obj is any numpy type\n        if type(obj).__module__ == np.__name__:\n            if isinstance(obj, np.ndarray):\n                return {'type': type(obj),\n                        'value': obj.tolist()}\n            else:\n                return obj.item()\n\n        # misc functions (e.g. loss function)\n        if callable(obj):\n            return obj.__name__\n\n        # if obj is a python 'type'\n        if type(obj).__name__ == type.__name__:\n            return obj.__name__\n\n        raise TypeError('Not JSON Serializable:', obj)\n\n    from . import __version__ as keras_version\n\n    # If file exists and should not be overwritten.\n    if not overwrite and os.path.isfile(filepath):\n        proceed = ask_to_proceed_with_overwrite(filepath)\n        if not proceed:\n            return\n\n    with h5py.File(filepath, mode='w') as f:\n        f.attrs['keras_version'] = str(keras_version).encode('utf8')\n        f.attrs['backend'] = K.backend().encode('utf8')\n        f.attrs['model_config'] = json.dumps({\n            'class_name': model.__class__.__name__,\n            'config': model.get_config()\n        }, default=get_json_type).encode('utf8')\n\n        model_weights_group = f.create_group('model_weights')\n        if legacy_models.needs_legacy_support(model):\n            model_layers = legacy_models.legacy_sequential_layers(model)\n        else:\n            model_layers = model.layers\n        topology.save_weights_to_hdf5_group(model_weights_group, model_layers)\n\n        if include_optimizer and hasattr(model, 'optimizer'):\n            if isinstance(model.optimizer, optimizers.TFOptimizer):\n                warnings.warn(\n                    'TensorFlow optimizers do not '\n                    'make it possible to access '\n                    'optimizer attributes or optimizer state '\n                    'after instantiation. '\n                    'As a result, we cannot save the optimizer '\n                    'as part of the model save file.'\n                    'You will have to compile your model again '\n                    'after loading it. '\n                    'Prefer using a Keras optimizer instead '\n                    '(see keras.io/optimizers).')\n            else:\n                f.attrs['training_config'] = json.dumps({\n                    'optimizer_config': {\n                        'class_name': model.optimizer.__class__.__name__,\n                        'config': model.optimizer.get_config()\n                    },\n                    'loss': model.loss,\n                    'metrics': model.metrics,\n                    'sample_weight_mode': model.sample_weight_mode,\n                    'loss_weights': model.loss_weights,\n                }, default=get_json_type).encode('utf8')\n\n                # Save optimizer weights.\n                symbolic_weights = getattr(model.optimizer, 'weights')\n                if symbolic_weights:\n                    optimizer_weights_group = f.create_group('optimizer_weights')\n                    weight_values = K.batch_get_value(symbolic_weights)\n                    weight_names = []\n                    for i, (w, val) in enumerate(zip(symbolic_weights,\n                                                     weight_values)):\n                        # Default values of symbolic_weights is /variable\n                        # for theano and cntk\n                        if K.backend() == 'theano' or K.backend() == 'cntk':\n                            if hasattr(w, 'name'):\n                                if w.name.split('/')[-1] == 'variable':\n                                    name = str(w.name) + '_' + str(i)\n                                else:\n                                    name = str(w.name)\n                            else:\n                                name = 'param_' + str(i)\n                        else:\n                            if hasattr(w, 'name') and w.name:\n                                name = str(w.name)\n                            else:\n                                name = 'param_' + str(i)\n                        weight_names.append(name.encode('utf8'))\n                    optimizer_weights_group.attrs['weight_names'] = weight_names\n                    for name, val in zip(weight_names, weight_values):\n                        param_dset = optimizer_weights_group.create_dataset(\n                            name,\n                            val.shape,\n                            dtype=val.dtype)\n                        if not val.shape:\n                            # scalar\n                            param_dset[()] = val\n                        else:\n                            param_dset[:] = val\n        f.flush()",
        "begin_line": 31,
        "end_line": 177,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.get_json_type#58",
        "src_path": "keras/models.py",
        "class_name": "keras.models",
        "signature": "keras.models.get_json_type(obj)",
        "snippet": "    def get_json_type(obj):\n        \"\"\"Serialize any object to a JSON-serializable structure.\n\n        # Arguments\n            obj: the object to serialize\n\n        # Returns\n            JSON-serializable structure representing `obj`.\n\n        # Raises\n            TypeError: if `obj` cannot be serialized.\n        \"\"\"\n        # if obj is a serializable Keras class instance\n        # e.g. optimizer, layer\n        if hasattr(obj, 'get_config'):\n            return {'class_name': obj.__class__.__name__,\n                    'config': obj.get_config()}\n\n        # if obj is any numpy type\n        if type(obj).__module__ == np.__name__:\n            if isinstance(obj, np.ndarray):\n                return {'type': type(obj),\n                        'value': obj.tolist()}\n            else:\n                return obj.item()\n\n        # misc functions (e.g. loss function)\n        if callable(obj):\n            return obj.__name__\n\n        # if obj is a python 'type'\n        if type(obj).__name__ == type.__name__:\n            return obj.__name__\n\n        raise TypeError('Not JSON Serializable:', obj)",
        "begin_line": 58,
        "end_line": 92,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.load_model#180",
        "src_path": "keras/models.py",
        "class_name": "keras.models",
        "signature": "keras.models.load_model(filepath, custom_objects=None, compile=True)",
        "snippet": "def load_model(filepath, custom_objects=None, compile=True):\n    \"\"\"Loads a model saved via `save_model`.\n\n    # Arguments\n        filepath: String, path to the saved model.\n        custom_objects: Optional dictionary mapping names\n            (strings) to custom classes or functions to be\n            considered during deserialization.\n        compile: Boolean, whether to compile the model\n            after loading.\n\n    # Returns\n        A Keras model instance. If an optimizer was found\n        as part of the saved model, the model is already\n        compiled. Otherwise, the model is uncompiled and\n        a warning will be displayed. When `compile` is set\n        to False, the compilation is omitted without any\n        warning.\n\n    # Raises\n        ImportError: if h5py is not available.\n        ValueError: In case of an invalid savefile.\n    \"\"\"\n    if h5py is None:\n        raise ImportError('`load_model` requires h5py.')\n\n    if not custom_objects:\n        custom_objects = {}\n\n    def convert_custom_objects(obj):\n        \"\"\"Handles custom object lookup.\n\n        # Arguments\n            obj: object, dict, or list.\n\n        # Returns\n            The same structure, where occurrences\n                of a custom object name have been replaced\n                with the custom object.\n        \"\"\"\n        if isinstance(obj, list):\n            deserialized = []\n            for value in obj:\n                deserialized.append(convert_custom_objects(value))\n            return deserialized\n        if isinstance(obj, dict):\n            deserialized = {}\n            for key, value in obj.items():\n                deserialized[key] = convert_custom_objects(value)\n            return deserialized\n        if obj in custom_objects:\n            return custom_objects[obj]\n        return obj\n    with h5py.File(filepath, mode='r') as f:\n        # instantiate model\n        model_config = f.attrs.get('model_config')\n        if model_config is None:\n            raise ValueError('No model found in config file.')\n        model_config = json.loads(model_config.decode('utf-8'))\n        model = model_from_config(model_config, custom_objects=custom_objects)\n\n        # set weights\n        topology.load_weights_from_hdf5_group(f['model_weights'], model.layers)\n\n        # Early return if compilation is not required.\n        if not compile:\n            return model\n\n        # instantiate optimizer\n        training_config = f.attrs.get('training_config')\n        if training_config is None:\n            warnings.warn('No training configuration found in save file: '\n                          'the model was *not* compiled. Compile it manually.')\n            return model\n        training_config = json.loads(training_config.decode('utf-8'))\n        optimizer_config = training_config['optimizer_config']\n        optimizer = optimizers.deserialize(optimizer_config,\n                                           custom_objects=custom_objects)\n\n        # Recover loss functions and metrics.\n        loss = convert_custom_objects(training_config['loss'])\n        metrics = convert_custom_objects(training_config['metrics'])\n        sample_weight_mode = training_config['sample_weight_mode']\n        loss_weights = training_config['loss_weights']\n\n        # Compile model.\n        model.compile(optimizer=optimizer,\n                      loss=loss,\n                      metrics=metrics,\n                      loss_weights=loss_weights,\n                      sample_weight_mode=sample_weight_mode)\n\n        # Set optimizer weights.\n        if 'optimizer_weights' in f:\n            # Build train function (to get weight updates).\n            if isinstance(model, Sequential):\n                model.model._make_train_function()\n            else:\n                model._make_train_function()\n            optimizer_weights_group = f['optimizer_weights']\n            optimizer_weight_names = [n.decode('utf8') for n in\n                                      optimizer_weights_group.attrs['weight_names']]\n            optimizer_weight_values = [optimizer_weights_group[n] for n in\n                                       optimizer_weight_names]\n            try:\n                model.optimizer.set_weights(optimizer_weight_values)\n            except ValueError:\n                warnings.warn('Error in loading the saved optimizer '\n                              'state. As a result, your model is '\n                              'starting with a freshly initialized '\n                              'optimizer.')\n    return model",
        "begin_line": 180,
        "end_line": 291,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.convert_custom_objects#209",
        "src_path": "keras/models.py",
        "class_name": "keras.models",
        "signature": "keras.models.convert_custom_objects(obj)",
        "snippet": "    def convert_custom_objects(obj):\n        \"\"\"Handles custom object lookup.\n\n        # Arguments\n            obj: object, dict, or list.\n\n        # Returns\n            The same structure, where occurrences\n                of a custom object name have been replaced\n                with the custom object.\n        \"\"\"\n        if isinstance(obj, list):\n            deserialized = []\n            for value in obj:\n                deserialized.append(convert_custom_objects(value))\n            return deserialized\n        if isinstance(obj, dict):\n            deserialized = {}\n            for key, value in obj.items():\n                deserialized[key] = convert_custom_objects(value)\n            return deserialized\n        if obj in custom_objects:\n            return custom_objects[obj]\n        return obj",
        "begin_line": 209,
        "end_line": 232,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.model_from_config#294",
        "src_path": "keras/models.py",
        "class_name": "keras.models",
        "signature": "keras.models.model_from_config(config, custom_objects=None)",
        "snippet": "def model_from_config(config, custom_objects=None):\n    \"\"\"Instantiates a Keras model from its config.\n\n    # Arguments\n        config: Configuration dictionary.\n        custom_objects: Optional dictionary mapping names\n            (strings) to custom classes or functions to be\n            considered during deserialization.\n\n    # Returns\n        A Keras model instance (uncompiled).\n\n    # Raises\n        TypeError: if `config` is not a dictionary.\n    \"\"\"\n    if isinstance(config, list):\n        raise TypeError('`model_from_config` expects a dictionary, not a list. '\n                        'Maybe you meant to use '\n                        '`Sequential.from_config(config)`?')\n    return layer_module.deserialize(config, custom_objects=custom_objects)",
        "begin_line": 294,
        "end_line": 313,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011059500110595002,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.model_from_yaml#316",
        "src_path": "keras/models.py",
        "class_name": "keras.models",
        "signature": "keras.models.model_from_yaml(yaml_string, custom_objects=None)",
        "snippet": "def model_from_yaml(yaml_string, custom_objects=None):\n    \"\"\"Parses a yaml model configuration file and returns a model instance.\n\n    # Arguments\n        yaml_string: YAML string encoding a model configuration.\n        custom_objects: Optional dictionary mapping names\n            (strings) to custom classes or functions to be\n            considered during deserialization.\n\n    # Returns\n        A Keras model instance (uncompiled).\n    \"\"\"\n    config = yaml.load(yaml_string)\n    return layer_module.deserialize(config, custom_objects=custom_objects)",
        "begin_line": 316,
        "end_line": 329,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0033112582781456954,
            "pseudo_dstar_susp": 0.0015408320493066256,
            "pseudo_tarantula_susp": 0.003816793893129771,
            "pseudo_op2_susp": 0.0015408320493066256,
            "pseudo_barinel_susp": 0.003816793893129771
        }
    },
    {
        "name": "keras.models.model_from_json#332",
        "src_path": "keras/models.py",
        "class_name": "keras.models",
        "signature": "keras.models.model_from_json(json_string, custom_objects=None)",
        "snippet": "def model_from_json(json_string, custom_objects=None):\n    \"\"\"Parses a JSON model configuration file and returns a model instance.\n\n    # Arguments\n        json_string: JSON string encoding a model configuration.\n        custom_objects: Optional dictionary mapping names\n            (strings) to custom classes or functions to be\n            considered during deserialization.\n\n    # Returns\n        A Keras model instance (uncompiled).\n    \"\"\"\n    config = json.loads(json_string)\n    return layer_module.deserialize(config, custom_objects=custom_objects)",
        "begin_line": 332,
        "end_line": 345,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002304147465437788,
            "pseudo_dstar_susp": 0.0014577259475218659,
            "pseudo_tarantula_susp": 0.003289473684210526,
            "pseudo_op2_susp": 0.0014577259475218659,
            "pseudo_barinel_susp": 0.003289473684210526
        }
    },
    {
        "name": "keras.models.Sequential.__init__#385",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.__init__(self, layers=None, name=None)",
        "snippet": "    def __init__(self, layers=None, name=None):\n        self.layers = []  # Stack of layers.\n        self.model = None  # Internal Model instance.\n        self.inputs = []  # List of input tensors\n        self.outputs = []  # List of length 1: the output tensor (unique).\n        self._trainable = True\n        self._initial_weights = None\n\n        # Model attributes.\n        self.inbound_nodes = []\n        self.outbound_nodes = []\n        self.built = False\n\n        # Set model name.\n        if not name:\n            prefix = 'sequential_'\n            name = prefix + str(K.get_uid(prefix))\n        self.name = name\n\n        # Add to the model any layers passed to the constructor.\n        if layers:\n            for layer in layers:\n                self.add(layer)",
        "begin_line": 385,
        "end_line": 407,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001026694045174538,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.add#409",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.add(self, layer)",
        "snippet": "    def add(self, layer):\n        \"\"\"Adds a layer instance on top of the layer stack.\n\n        # Arguments\n            layer: layer instance.\n\n        # Raises\n            TypeError: If `layer` is not a layer instance.\n            ValueError: In case the `layer` argument does not\n                know its input shape.\n            ValueError: In case the `layer` argument has\n                multiple output tensors, or is already connected\n                somewhere else (forbidden in `Sequential` models).\n        \"\"\"\n        if not isinstance(layer, Layer):\n            raise TypeError('The added layer must be '\n                            'an instance of class Layer. '\n                            'Found: ' + str(layer))\n        if not self.outputs:\n            # first layer in model: check that it is an input layer\n            if not layer.inbound_nodes:\n                # create an input layer\n                if not hasattr(layer, 'batch_input_shape'):\n                    raise ValueError('The first layer in a '\n                                     'Sequential model must '\n                                     'get an `input_shape` or '\n                                     '`batch_input_shape` argument.')\n                # Instantiate the input layer.\n                x = Input(batch_shape=layer.batch_input_shape,\n                          dtype=layer.dtype, name=layer.name + '_input')\n                # This will build the current layer\n                # and create the node connecting the current layer\n                # to the input layer we just created.\n                layer(x)\n\n            if len(layer.inbound_nodes) != 1:\n                raise ValueError('A layer added to a Sequential model must '\n                                 'not already be connected somewhere else. '\n                                 'Model received layer ' + layer.name +\n                                 ' which has ' +\n                                 str(len(layer.inbound_nodes)) +\n                                 ' pre-existing inbound connections.')\n\n            if len(layer.inbound_nodes[0].output_tensors) != 1:\n                raise ValueError('All layers in a Sequential model '\n                                 'should have a single output tensor. '\n                                 'For multi-output layers, '\n                                 'use the functional API.')\n\n            self.outputs = [layer.inbound_nodes[0].output_tensors[0]]\n            self.inputs = topology.get_source_inputs(self.outputs[0])\n\n            # We create an input node, which we will keep updated\n            # as we add more layers\n            topology.Node(outbound_layer=self,\n                          inbound_layers=[],\n                          node_indices=[],\n                          tensor_indices=[],\n                          input_tensors=self.inputs,\n                          output_tensors=self.outputs,\n                          # no model-level masking for now\n                          input_masks=[None for _ in self.inputs],\n                          output_masks=[None],\n                          input_shapes=[x._keras_shape for x in self.inputs],\n                          output_shapes=[self.outputs[0]._keras_shape])\n        else:\n            output_tensor = layer(self.outputs[0])\n            if isinstance(output_tensor, list):\n                raise TypeError('All layers in a Sequential model '\n                                'should have a single output tensor. '\n                                'For multi-output layers, '\n                                'use the functional API.')\n            self.outputs = [output_tensor]\n            # update self.inbound_nodes\n            self.inbound_nodes[0].output_tensors = self.outputs\n            self.inbound_nodes[0].output_shapes = [self.outputs[0]._keras_shape]\n\n        self.layers.append(layer)\n        self.built = False",
        "begin_line": 409,
        "end_line": 487,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.344047841524949e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.pop#489",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.pop(self)",
        "snippet": "    def pop(self):\n        \"\"\"Removes the last layer in the model.\n\n        # Raises\n            TypeError: if there are no layers in the model.\n        \"\"\"\n        if not self.layers:\n            raise TypeError('There are no layers in the model.')\n\n        self.layers.pop()\n        if not self.layers:\n            self.outputs = []\n            self.inbound_nodes = []\n            self.outbound_nodes = []\n        else:\n            self.layers[-1].outbound_nodes = []\n            self.outputs = [self.layers[-1].output]\n            # update self.inbound_nodes\n            self.inbound_nodes[0].output_tensors = self.outputs\n            self.inbound_nodes[0].output_shapes = [self.outputs[0]._keras_shape]\n        self.built = False",
        "begin_line": 489,
        "end_line": 509,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.get_layer#511",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.get_layer(self, name=None, index=None)",
        "snippet": "    def get_layer(self, name=None, index=None):\n        \"\"\"Retrieve a layer that is part of the model.\n\n        Returns a layer based on either its name (unique)\n        or its index in the graph. Indices are based on\n        order of horizontal graph traversal (bottom-up).\n\n        # Arguments\n            name: string, name of layer.\n            index: integer, index of layer.\n\n        # Returns\n            A layer instance.\n        \"\"\"\n        if not self.built:\n            self.build()\n        return self.model.get_layer(name, index)",
        "begin_line": 511,
        "end_line": 527,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.call#529",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.call(self, inputs, mask=None)",
        "snippet": "    def call(self, inputs, mask=None):\n        if not self.built:\n            self.build()\n        return self.model.call(inputs, mask)",
        "begin_line": 529,
        "end_line": 532,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00012818869375721061,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.build#534",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.build(self, input_shape=None)",
        "snippet": "    def build(self, input_shape=None):\n        if not self.inputs or not self.outputs:\n            raise TypeError('Sequential model cannot be built: model is empty.'\n                            ' Add some layers first.')\n        # actually create the model\n        self.model = Model(self.inputs, self.outputs[0],\n                           name=self.name + '_model')\n        self.model.trainable = self.trainable\n\n        # mirror model attributes\n        self.supports_masking = self.model.supports_masking\n        self._output_mask_cache = self.model._output_mask_cache\n        self._output_tensor_cache = self.model._output_tensor_cache\n        self._output_shape_cache = self.model._output_shape_cache\n        self.input_layers = self.model.input_layers\n        self.input_layers_node_indices = self.model.input_layers_node_indices\n        self.input_layers_tensor_indices = self.model.input_layers_tensor_indices\n        self.output_layers = self.model.output_layers\n        self.output_layers_node_indices = self.model.output_layers_node_indices\n        self.output_layers_tensor_indices = self.model.output_layers_tensor_indices\n        self.nodes_by_depth = self.model.nodes_by_depth\n        self.container_nodes = self.model.container_nodes\n        self.output_names = self.model.output_names\n        self.input_names = self.model.input_names\n        self._feed_input_names = self.model._feed_input_names\n        self._feed_inputs = self.model._feed_inputs\n\n        # Make sure child model callbacks\n        # will call the parent Sequential model.\n        self.model.callback_model = self\n        self.built = True",
        "begin_line": 534,
        "end_line": 564,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.010632546404758e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.uses_learning_phase#567",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.uses_learning_phase(self)",
        "snippet": "    def uses_learning_phase(self):\n        if not self.built:\n            self.build()\n        return self.model.uses_learning_phase",
        "begin_line": 567,
        "end_line": 570,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential._flattened_layers#573",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential._flattened_layers(self)",
        "snippet": "    def _flattened_layers(self):\n        layers = []\n        if self.layers:\n            # Support for legacy models\n            if isinstance(self.layers[0], legacy_layers.Merge):\n                merge = self.layers[0]\n                for layer in merge.layers:\n                    if hasattr(layer, '_flattened_layers'):\n                        for sublayer in layer._flattened_layers:\n                            if sublayer not in layers:\n                                layers.append(sublayer)\n                    elif hasattr(layer, 'layers'):\n                        for sublayer in layer.layers:\n                            if sublayer not in layers:\n                                layers.append(sublayer)\n                    else:\n                        if layer not in layers:\n                            layers.append(layer)\n            else:\n                if self.layers[0] not in layers:\n                    layers.append(self.layers[0])\n            for layer in self.layers[1:]:\n                if layer not in layers:\n                    layers.append(layer)\n        return layers",
        "begin_line": 573,
        "end_line": 597,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential._gather_list_attr#599",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential._gather_list_attr(self, attr)",
        "snippet": "    def _gather_list_attr(self, attr):\n        all_attrs = []\n        for layer in self._flattened_layers:\n            all_attrs += getattr(layer, attr, [])\n        return all_attrs",
        "begin_line": 599,
        "end_line": 603,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.311853990129435e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.trainable#606",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.trainable(self)",
        "snippet": "    def trainable(self):\n        return self._trainable",
        "begin_line": 606,
        "end_line": 607,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.000900090009e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.trainable#610",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.trainable(self, value)",
        "snippet": "    def trainable(self, value):\n        if self.model:\n            self.model.trainable = value\n        self._trainable = value",
        "begin_line": 610,
        "end_line": 613,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.trainable_weights#616",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.trainable_weights(self)",
        "snippet": "    def trainable_weights(self):\n        if not self.trainable:\n            return []\n        # Support for legacy behavior\n        return self._gather_list_attr('trainable_weights')",
        "begin_line": 616,
        "end_line": 620,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.non_trainable_weights#623",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.non_trainable_weights(self)",
        "snippet": "    def non_trainable_weights(self):\n        # Support for legacy behavior\n        weights = self._gather_list_attr('non_trainable_weights')\n        if not self.trainable:\n            trainable_weights = self._gather_list_attr('trainable_weights')\n            return trainable_weights + weights\n        return weights",
        "begin_line": 623,
        "end_line": 629,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.updates#632",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.updates(self)",
        "snippet": "    def updates(self):\n        if not self.built:\n            self.build()\n        return self.model.updates",
        "begin_line": 632,
        "end_line": 635,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.get_updates_for#643",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.get_updates_for(self, inputs)",
        "snippet": "    def get_updates_for(self, inputs):\n        if not self.built:\n            self.build()\n        return self.model.get_updates_for(inputs)",
        "begin_line": 643,
        "end_line": 646,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.losses#649",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.losses(self)",
        "snippet": "    def losses(self):\n        if not self.built:\n            self.build()\n        return self.model.losses",
        "begin_line": 649,
        "end_line": 652,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.get_losses_for#654",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.get_losses_for(self, inputs)",
        "snippet": "    def get_losses_for(self, inputs):\n        if not self.built:\n            self.build()\n        return self.model.get_losses_for(inputs)",
        "begin_line": 654,
        "end_line": 657,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.get_weights#665",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.get_weights(self)",
        "snippet": "    def get_weights(self):\n        \"\"\"Retrieves the weights of the model.\n\n        # Returns\n            A flat list of Numpy arrays\n            (one array per model weight).\n        \"\"\"\n        # Legacy support\n        if legacy_models.needs_legacy_support(self):\n            layers = legacy_models.legacy_sequential_layers(self)\n            weights = []\n            for layer in layers:\n                weights.append(layer.get_weights())\n            return weights\n\n        if not self.built:\n            self.build()\n        return self.model.get_weights()",
        "begin_line": 665,
        "end_line": 682,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.set_weights#684",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.set_weights(self, weights)",
        "snippet": "    def set_weights(self, weights):\n        \"\"\"Sets the weights of the model.\n\n        # Arguments\n            weights: Should be a list\n                of Numpy arrays with shapes and types matching\n                the output of `model.get_weights()`.\n        \"\"\"\n        # Legacy support\n        if legacy_models.needs_legacy_support(self):\n            layers = legacy_models.legacy_sequential_layers(self)\n            for layer in layers:\n                nb_param = len(layer.weights)\n                layer.set_weights(weights[:nb_param])\n                weights = weights[nb_param:]\n\n        if not self.built:\n            self.build()\n        self.model.set_weights(weights)",
        "begin_line": 684,
        "end_line": 702,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001016260162601626,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.load_weights#704",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.load_weights(self, filepath, by_name=False)",
        "snippet": "    def load_weights(self, filepath, by_name=False):\n        if h5py is None:\n            raise ImportError('`load_weights` requires h5py.')\n        f = h5py.File(filepath, mode='r')\n        if 'layer_names' not in f.attrs and 'model_weights' in f:\n            f = f['model_weights']\n\n        # Legacy support\n        if legacy_models.needs_legacy_support(self):\n            layers = legacy_models.legacy_sequential_layers(self)\n        else:\n            layers = self.layers\n        if by_name:\n            topology.load_weights_from_hdf5_group_by_name(f, layers)\n        else:\n            topology.load_weights_from_hdf5_group(f, layers)\n        if hasattr(f, 'close'):\n            f.close()",
        "begin_line": 704,
        "end_line": 721,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.save_weights#723",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.save_weights(self, filepath, overwrite=True)",
        "snippet": "    def save_weights(self, filepath, overwrite=True):\n        if h5py is None:\n            raise ImportError('`save_weights` requires h5py.')\n        # If file exists and should not be overwritten:\n        if not overwrite and os.path.isfile(filepath):\n            proceed = ask_to_proceed_with_overwrite(filepath)\n            if not proceed:\n                return\n        # Legacy support\n        if legacy_models.needs_legacy_support(self):\n            layers = legacy_models.legacy_sequential_layers(self)\n        else:\n            layers = self.layers\n\n        f = h5py.File(filepath, 'w')\n        topology.save_weights_to_hdf5_group(f, layers)\n        f.flush()\n        f.close()",
        "begin_line": 723,
        "end_line": 740,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.compile#742",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.compile(self, optimizer, loss, metrics=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None, **kwargs)",
        "snippet": "    def compile(self, optimizer, loss,\n                metrics=None,\n                sample_weight_mode=None,\n                weighted_metrics=None,\n                target_tensors=None,\n                **kwargs):\n        \"\"\"Configures the model for training.\n\n        # Arguments\n            optimizer: String (name of optimizer) or optimizer object.\n                See [optimizers](/optimizers).\n            loss: String (name of objective function) or objective function.\n                See [losses](/losses).\n                If the model has multiple outputs, you can use a different loss\n                on each output by passing a dictionary or a list of losses.\n                The loss value that will be minimized by the model\n                will then be the sum of all individual losses.\n            metrics: List of metrics to be evaluated by the model\n                during training and testing.\n                Typically you will use `metrics=['accuracy']`.\n                To specify different metrics for different outputs of a\n                multi-output model, you could also pass a dictionary,\n                such as `metrics={'output_a': 'accuracy'}`.\n            sample_weight_mode: If you need to do timestep-wise\n                sample weighting (2D weights), set this to `\"temporal\"`.\n                `None` defaults to sample-wise weights (1D).\n                If the model has multiple outputs, you can use a different\n                `sample_weight_mode` on each output by passing a\n                dictionary or a list of modes.\n            weighted_metrics: List of metrics to be evaluated and weighted\n                by sample_weight or class_weight during training and testing.\n            target_tensors: By default, Keras will create placeholders for the\n                model's target, which will be fed with the target data during\n                training. If instead you would like to use your own\n                target tensors (in turn, Keras will not expect external\n                Numpy data for these targets at training time), you\n                can specify them via the `target_tensors` argument. It can be\n                a single tensor (for a single-output model), a list of tensors,\n                or a dict mapping output names to target tensors.\n            **kwargs: When using the Theano/CNTK backends, these arguments\n                are passed into K.function. When using the TensorFlow backend,\n                these arguments are passed into `tf.Session.run`.\n\n        # Raises\n            ValueError: In case of invalid arguments for\n\n        # Example\n            ```python\n                model = Sequential()\n                model.add(Dense(32, input_shape=(500,)))\n                model.add(Dense(10, activation='softmax'))\n                model.compile(optimizer='rmsprop',\n                              loss='categorical_crossentropy',\n                              metrics=['accuracy'])\n            ```\n        \"\"\"\n        # create the underlying model\n        self.build()\n        # call compile method of Model class\n        self.model.compile(optimizer, loss,\n                           metrics=metrics,\n                           sample_weight_mode=sample_weight_mode,\n                           weighted_metrics=weighted_metrics,\n                           target_tensors=target_tensors,\n                           **kwargs)\n        self.optimizer = self.model.optimizer\n        self.loss = self.model.loss\n        self.metrics = self.model.metrics\n        self.loss_weights = self.model.loss_weights\n        self.sample_weight_mode = self.model.sample_weight_mode\n        self.weighted_metrics = self.model.weighted_metrics\n        self.targets = self.model.targets\n        self.metrics_tensors = self.model.metrics_tensors\n        self.metrics_names = self.model.metrics_names\n        self.sample_weights = self.model.sample_weights\n        self.total_loss = self.model.total_loss",
        "begin_line": 742,
        "end_line": 817,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.035872413481521e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.fit#819",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.fit(self, x, y, batch_size=32, epochs=10, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, **kwargs)",
        "snippet": "    def fit(self, x, y, batch_size=32, epochs=10, verbose=1, callbacks=None,\n            validation_split=0., validation_data=None, shuffle=True,\n            class_weight=None, sample_weight=None, initial_epoch=0, **kwargs):\n        \"\"\"Trains the model for a fixed number of epochs.\n\n        # Arguments\n            x: input data, as a Numpy array or list of Numpy arrays\n                (if the model has multiple inputs).\n            y: labels, as a Numpy array.\n            batch_size: integer. Number of samples per gradient update.\n            epochs: integer. Number of epochs to train the model.\n                Note that in conjunction with initial_epoch, the parameter\n                epochs is to be understood as \"final epoch\". The model is\n                not trained for a number of steps given by epochs, but\n                until the epoch epochs is reached.\n            verbose: 0 for no logging to stdout,\n                1 for progress bar logging, 2 for one log line per epoch.\n            callbacks: list of `keras.callbacks.Callback` instances.\n                List of callbacks to apply during training.\n                See [callbacks](/callbacks).\n            validation_split: float (0. < x < 1).\n                Fraction of the data to use as held-out validation data.\n            validation_data: tuple (x_val, y_val) or tuple\n                (x_val, y_val, val_sample_weights) to be used as held-out\n                validation data. Will override validation_split.\n            shuffle: boolean or str (for 'batch').\n                Whether to shuffle the samples at each epoch.\n                'batch' is a special option for dealing with the\n                limitations of HDF5 data; it shuffles in batch-sized chunks.\n            class_weight: dictionary mapping classes to a weight value,\n                used for scaling the loss function (during training only).\n            sample_weight: Numpy array of weights for\n                the training samples, used for scaling the loss function\n                (during training only). You can either pass a flat (1D)\n                Numpy array with the same length as the input samples\n                (1:1 mapping between weights and samples),\n                or in the case of temporal data,\n                you can pass a 2D array with shape (samples, sequence_length),\n                to apply a different weight to every timestep of every sample.\n                In this case you should make sure to specify\n                sample_weight_mode=\"temporal\" in compile().\n            initial_epoch: Epoch at which to start training\n                (useful for resuming a previous training run).\n\n        # Returns\n            A `History` object. Its `History.history` attribute is\n            a record of training loss values and metrics values\n            at successive epochs, as well as validation loss values\n            and validation metrics values (if applicable).\n\n        # Raises\n            RuntimeError: if the model was never compiled.\n        \"\"\"\n        # Legacy support\n        if 'nb_epoch' in kwargs:\n            warnings.warn('The `nb_epoch` argument in `fit` '\n                          'has been renamed `epochs`.')\n            epochs = kwargs.pop('nb_epoch')\n        if kwargs:\n            raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\n\n        if not self.built:\n            raise RuntimeError('The model needs to be compiled '\n                               'before being used.')\n        return self.model.fit(x, y,\n                              batch_size=batch_size,\n                              epochs=epochs,\n                              verbose=verbose,\n                              callbacks=callbacks,\n                              validation_split=validation_split,\n                              validation_data=validation_data,\n                              shuffle=shuffle,\n                              class_weight=class_weight,\n                              sample_weight=sample_weight,\n                              initial_epoch=initial_epoch)",
        "begin_line": 819,
        "end_line": 893,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.411764705882353e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.evaluate#895",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.evaluate(self, x, y, batch_size=32, verbose=1, sample_weight=None)",
        "snippet": "    def evaluate(self, x, y, batch_size=32, verbose=1,\n                 sample_weight=None):\n        \"\"\"Computes the loss on some input data, batch by batch.\n\n        # Arguments\n            x: input data, as a Numpy array or list of Numpy arrays\n                (if the model has multiple inputs).\n            y: labels, as a Numpy array.\n            batch_size: integer. Number of samples per gradient update.\n            verbose: verbosity mode, 0 or 1.\n            sample_weight: sample weights, as a Numpy array.\n\n        # Returns\n            Scalar test loss (if the model has no metrics)\n            or list of scalars (if the model computes other metrics).\n            The attribute `model.metrics_names` will give you\n            the display labels for the scalar outputs.\n\n        # Raises\n            RuntimeError: if the model was never compiled.\n        \"\"\"\n        if not self.built:\n            raise RuntimeError('The model needs to be compiled '\n                               'before being used.')\n        return self.model.evaluate(x, y,\n                                   batch_size=batch_size,\n                                   verbose=verbose,\n                                   sample_weight=sample_weight)",
        "begin_line": 895,
        "end_line": 922,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010421008753647353,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.predict#924",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.predict(self, x, batch_size=32, verbose=0)",
        "snippet": "    def predict(self, x, batch_size=32, verbose=0):\n        \"\"\"Generates output predictions for the input samples.\n\n        The input samples are processed batch by batch.\n\n        # Arguments\n            x: the input data, as a Numpy array.\n            batch_size: integer.\n            verbose: verbosity mode, 0 or 1.\n\n        # Returns\n            A Numpy array of predictions.\n        \"\"\"\n        if not self.built:\n            self.build()\n        return self.model.predict(x, batch_size=batch_size, verbose=verbose)",
        "begin_line": 924,
        "end_line": 939,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.473285335354301e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.train_on_batch#955",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.train_on_batch(self, x, y, class_weight=None, sample_weight=None)",
        "snippet": "    def train_on_batch(self, x, y, class_weight=None,\n                       sample_weight=None):\n        \"\"\"Single gradient update over one batch of samples.\n\n        # Arguments\n            x: input data, as a Numpy array or list of Numpy arrays\n                (if the model has multiple inputs).\n            y: labels, as a Numpy array.\n            class_weight: dictionary mapping classes to a weight value,\n                used for scaling the loss function (during training only).\n            sample_weight: sample weights, as a Numpy array.\n\n        # Returns\n            Scalar training loss (if the model has no metrics)\n            or list of scalars (if the model computes other metrics).\n            The attribute `model.metrics_names` will give you\n            the display labels for the scalar outputs.\n\n        # Raises\n            RuntimeError: if the model was never compiled.\n        \"\"\"\n        if not self.built:\n            raise RuntimeError('The model needs to be compiled '\n                               'before being used.')\n        return self.model.train_on_batch(x, y,\n                                         sample_weight=sample_weight,\n                                         class_weight=class_weight)",
        "begin_line": 955,
        "end_line": 981,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.153318077803204e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.test_on_batch#983",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.test_on_batch(self, x, y, sample_weight=None)",
        "snippet": "    def test_on_batch(self, x, y,\n                      sample_weight=None):\n        \"\"\"Evaluates the model over a single batch of samples.\n\n        # Arguments\n            x: input data, as a Numpy array or list of Numpy arrays\n                (if the model has multiple inputs).\n            y: labels, as a Numpy array.\n            sample_weight: sample weights, as a Numpy array.\n\n        # Returns\n            Scalar test loss (if the model has no metrics)\n            or list of scalars (if the model computes other metrics).\n            The attribute `model.metrics_names` will give you\n            the display labels for the scalar outputs.\n\n        # Raises\n            RuntimeError: if the model was never compiled.\n        \"\"\"\n        if not self.built:\n            raise RuntimeError('The model needs to be compiled '\n                               'before being used.')\n        return self.model.test_on_batch(x, y,\n                                        sample_weight=sample_weight)",
        "begin_line": 983,
        "end_line": 1006,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.predict_proba#1008",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.predict_proba(self, x, batch_size=32, verbose=1)",
        "snippet": "    def predict_proba(self, x, batch_size=32, verbose=1):\n        \"\"\"Generates class probability predictions for the input samples.\n\n        The input samples are processed batch by batch.\n\n        # Arguments\n            x: input data, as a Numpy array or list of Numpy arrays\n                (if the model has multiple inputs).\n            batch_size: integer.\n            verbose: verbosity mode, 0 or 1.\n\n        # Returns\n            A Numpy array of probability predictions.\n        \"\"\"\n        preds = self.predict(x, batch_size, verbose)\n        if preds.min() < 0. or preds.max() > 1.:\n            warnings.warn('Network returning invalid probability values. '\n                          'The last layer might not normalize predictions '\n                          'into probabilities '\n                          '(like softmax or sigmoid would).')\n        return preds",
        "begin_line": 1008,
        "end_line": 1028,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011301989150090416,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.predict_classes#1030",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.predict_classes(self, x, batch_size=32, verbose=1)",
        "snippet": "    def predict_classes(self, x, batch_size=32, verbose=1):\n        \"\"\"Generate class predictions for the input samples.\n\n        The input samples are processed batch by batch.\n\n        # Arguments\n            x: input data, as a Numpy array or list of Numpy arrays\n                (if the model has multiple inputs).\n            batch_size: integer.\n            verbose: verbosity mode, 0 or 1.\n\n        # Returns\n            A numpy array of class predictions.\n        \"\"\"\n        proba = self.predict(x, batch_size=batch_size, verbose=verbose)\n        if proba.shape[-1] > 1:\n            return proba.argmax(axis=-1)\n        else:\n            return (proba > 0.5).astype('int32')",
        "begin_line": 1030,
        "end_line": 1048,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011301989150090416,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.fit_generator#1051",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.fit_generator(self, generator, steps_per_epoch, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)",
        "snippet": "    def fit_generator(self, generator,\n                      steps_per_epoch,\n                      epochs=1,\n                      verbose=1,\n                      callbacks=None,\n                      validation_data=None,\n                      validation_steps=None,\n                      class_weight=None,\n                      max_queue_size=10,\n                      workers=1,\n                      use_multiprocessing=False,\n                      shuffle=True,\n                      initial_epoch=0):\n        \"\"\"Fits the model on data generated batch-by-batch by a Python generator.\n\n        The generator is run in parallel to the model, for efficiency.\n        For instance, this allows you to do real-time data augmentation\n        on images on CPU in parallel to training your model on GPU.\n\n        # Arguments\n            generator: A generator.\n                The output of the generator must be either\n                - a tuple (inputs, targets)\n                - a tuple (inputs, targets, sample_weights).\n                All arrays should contain the same number of samples.\n                The generator is expected to loop over its data\n                indefinitely. An epoch finishes when `steps_per_epoch`\n                batches have been seen by the model.\n            steps_per_epoch: Total number of steps (batches of samples)\n                to yield from `generator` before declaring one epoch\n                finished and starting the next epoch. It should typically\n                be equal to the number of unique samples of your dataset\n                divided by the batch size.\n            epochs: Integer, total number of iterations on the data.\n                Note that in conjunction with initial_epoch, the parameter\n                epochs is to be understood as \"final epoch\". The model is\n                not trained for n steps given by epochs, but until the\n                epoch epochs is reached.\n            verbose: Verbosity mode, 0, 1, or 2.\n            callbacks: List of callbacks to be called during training.\n            validation_data: This can be either\n                - A generator for the validation data\n                - A tuple (inputs, targets)\n                - A tuple (inputs, targets, sample_weights).\n            validation_steps: Only relevant if `validation_data`\n                is a generator.\n                Number of steps to yield from validation generator\n                at the end of every epoch. It should typically\n                be equal to the number of unique samples of your\n                validation dataset divided by the batch size.\n            class_weight: Dictionary mapping class indices to a weight\n                for the class.\n            max_queue_size: Maximum size for the generator queue\n            workers: Maximum number of processes to spin up\n            use_multiprocessing: if True, use process based threading.\n                Note that because\n                this implementation relies on multiprocessing,\n                you should not pass\n                non picklable arguments to the generator\n                as they can't be passed\n                easily to children processes.\n            shuffle: Whether to shuffle the order of the batches at\n                the beginning of each epoch. Only used with instances\n                of `Sequence` (keras.utils.Sequence).\n            initial_epoch: Epoch at which to start training\n                (useful for resuming a previous training run).\n\n        # Returns\n            A `History` object.\n\n        # Raises\n            RuntimeError: if the model was never compiled.\n\n        # Example\n\n        ```python\n            def generate_arrays_from_file(path):\n                while 1:\n                    f = open(path)\n                    for line in f:\n                        # create Numpy arrays of input data\n                        # and labels, from each line in the file\n                        x, y = process_line(line)\n                        yield (x, y)\n                    f.close()\n\n            model.fit_generator(generate_arrays_from_file('/my_file.txt'),\n                                steps_per_epoch=1000, epochs=10)\n        ```\n        \"\"\"\n        if not self.built:\n            raise RuntimeError('The model needs to be compiled '\n                               'before being used.')\n        return self.model.fit_generator(generator,\n                                        steps_per_epoch,\n                                        epochs,\n                                        verbose=verbose,\n                                        callbacks=callbacks,\n                                        validation_data=validation_data,\n                                        validation_steps=validation_steps,\n                                        class_weight=class_weight,\n                                        max_queue_size=max_queue_size,\n                                        workers=workers,\n                                        use_multiprocessing=use_multiprocessing,\n                                        shuffle=shuffle,\n                                        initial_epoch=initial_epoch)",
        "begin_line": 1051,
        "end_line": 1156,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.evaluate_generator#1159",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.evaluate_generator(self, generator, steps, max_queue_size=10, workers=1, use_multiprocessing=False)",
        "snippet": "    def evaluate_generator(self, generator, steps,\n                           max_queue_size=10, workers=1,\n                           use_multiprocessing=False):\n        \"\"\"Evaluates the model on a data generator.\n\n        The generator should return the same kind of data\n        as accepted by `test_on_batch`.\n\n        # Arguments\n            generator: Generator yielding tuples (inputs, targets)\n                or (inputs, targets, sample_weights)\n            steps: Total number of steps (batches of samples)\n                to yield from `generator` before stopping.\n            max_queue_size: maximum size for the generator queue\n            workers: maximum number of processes to spin up\n            use_multiprocessing: if True, use process based threading.\n                Note that because this implementation\n                relies on multiprocessing, you should not pass\n                non picklable arguments to the generator\n                as they can't be passed easily to children processes.\n\n        # Returns\n            Scalar test loss (if the model has no metrics)\n            or list of scalars (if the model computes other metrics).\n            The attribute `model.metrics_names` will give you\n            the display labels for the scalar outputs.\n\n        # Raises\n            RuntimeError: if the model was never compiled.\n        \"\"\"\n        if not self.built:\n            raise RuntimeError('The model needs to be compiled '\n                               'before being used.')\n        return self.model.evaluate_generator(generator,\n                                             steps,\n                                             max_queue_size=max_queue_size,\n                                             workers=workers,\n                                             use_multiprocessing=use_multiprocessing)",
        "begin_line": 1159,
        "end_line": 1196,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.predict_generator#1199",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.predict_generator(self, generator, steps, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)",
        "snippet": "    def predict_generator(self, generator, steps,\n                          max_queue_size=10, workers=1,\n                          use_multiprocessing=False, verbose=0):\n        \"\"\"Generates predictions for the input samples from a data generator.\n\n        The generator should return the same kind of data as accepted by\n        `predict_on_batch`.\n\n        # Arguments\n            generator: generator yielding batches of input samples.\n            steps: Total number of steps (batches of samples)\n                to yield from `generator` before stopping.\n            max_queue_size: maximum size for the generator queue\n            workers: maximum number of processes to spin up\n            use_multiprocessing: if True, use process based threading.\n                Note that because this implementation\n                relies on multiprocessing, you should not pass\n                non picklable arguments to the generator\n                as they can't be passed easily to children processes.\n            verbose: verbosity mode, 0 or 1.\n\n        # Returns\n            A Numpy array of predictions.\n        \"\"\"\n        if not self.built:\n            self.build()\n        return self.model.predict_generator(generator, steps,\n                                            max_queue_size=max_queue_size,\n                                            workers=workers,\n                                            use_multiprocessing=use_multiprocessing,\n                                            verbose=verbose)",
        "begin_line": 1199,
        "end_line": 1229,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.get_config#1231",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.get_config(self)",
        "snippet": "    def get_config(self):\n        if isinstance(self.layers[0], legacy_layers.Merge):\n            return self.legacy_get_config()\n\n        config = []\n        for layer in self.layers:\n            config.append({'class_name': layer.__class__.__name__,\n                           'config': layer.get_config()})\n        return copy.deepcopy(config)",
        "begin_line": 1231,
        "end_line": 1239,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00012818869375721061,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.from_config#1242",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.from_config(cls, config, custom_objects=None)",
        "snippet": "    def from_config(cls, config, custom_objects=None):\n        if 'class_name' not in config[0] or config[0]['class_name'] == 'Merge':\n            return cls.legacy_from_config(config)\n\n        model = cls()\n        for conf in config:\n            layer = layer_module.deserialize(conf, custom_objects=custom_objects)\n            model.add(layer)\n        return model",
        "begin_line": 1242,
        "end_line": 1250,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.legacy_get_config#1252",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.legacy_get_config(self)",
        "snippet": "    def legacy_get_config(self):\n        \"\"\"Retrieves the model configuration as a Python list.\n\n        # Returns\n            A list of dicts (each dict is a layer config).\n        \"\"\"\n        config = []\n        if isinstance(self.layers[0], legacy_layers.Merge):\n            assert hasattr(self.layers[0], 'layers')\n            layers = []\n            for layer in self.layers[0].layers:\n                layer_config = {'class_name': layer.__class__.__name__,\n                                'config': layer.get_config()}\n                layers.append(layer_config)\n            merge_config = self.layers[0].get_config()\n            merge_config['layers'] = layers\n            config.append({'class_name': 'Merge', 'config': merge_config})\n        else:\n            config.append({'class_name': self.layers[0].__class__.__name__,\n                           'config': self.layers[0].get_config()})\n        for layer in self.layers[1:]:\n            config.append({'class_name': layer.__class__.__name__,\n                           'config': layer.get_config()})\n        return copy.deepcopy(config)",
        "begin_line": 1252,
        "end_line": 1275,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00012818869375721061,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.legacy_from_config#1278",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.legacy_from_config(cls, config, layer_cache=None)",
        "snippet": "    def legacy_from_config(cls, config, layer_cache=None):\n        \"\"\"Load a model from a legacy configuration.\n\n        # Arguments\n            config: dictionary with configuration.\n            layer_cache: cache to draw pre-existing layer.\n\n        # Returns\n            The loaded Model.\n        \"\"\"\n        if not layer_cache:\n            layer_cache = {}\n\n        def normalize_legacy_config(conf):\n            if 'class_name' not in conf:\n                class_name = conf['name']\n                name = conf.get('custom_name')\n                conf['name'] = name\n                return {'class_name': class_name,\n                        'config': conf}\n            return conf\n\n        # the model we will return\n        model = cls()\n\n        def get_or_create_layer(layer_data):\n            name = layer_data['config'].get('name')\n            if name in layer_cache:\n                return layer_cache[name]\n            layer = layer_module.deserialize(layer_data)\n            layer_cache[name] = layer\n            return layer\n\n        first_layer = config[0]\n        first_layer = normalize_legacy_config(first_layer)\n        if first_layer['class_name'] == 'Merge':\n            merge_inputs = []\n            first_layer_config = first_layer['config']\n            for merge_input_config in first_layer_config.pop('layers'):\n                merge_input = layer_module.deserialize(merge_input_config)\n                merge_inputs.append(merge_input)\n            first_layer_config['layers'] = merge_inputs\n            merge = legacy_layers.Merge.from_config(first_layer_config)\n            model.add(merge)\n        else:\n            layer = get_or_create_layer(first_layer)\n            model.add(layer)\n\n        for conf in config[1:]:\n            conf = normalize_legacy_config(conf)\n            layer = get_or_create_layer(conf)\n            model.add(layer)\n        return model",
        "begin_line": 1278,
        "end_line": 1330,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.normalize_legacy_config#1291",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.normalize_legacy_config(conf)",
        "snippet": "        def normalize_legacy_config(conf):\n            if 'class_name' not in conf:\n                class_name = conf['name']\n                name = conf.get('custom_name')\n                conf['name'] = name\n                return {'class_name': class_name,\n                        'config': conf}\n            return conf",
        "begin_line": 1291,
        "end_line": 1298,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.Sequential.get_or_create_layer#1303",
        "src_path": "keras/models.py",
        "class_name": "keras.models.Sequential",
        "signature": "keras.models.Sequential.get_or_create_layer(layer_data)",
        "snippet": "        def get_or_create_layer(layer_data):\n            name = layer_data['config'].get('name')\n            if name in layer_cache:\n                return layer_cache[name]\n            layer = layer_module.deserialize(layer_data)\n            layer_cache[name] = layer\n            return layer",
        "begin_line": 1303,
        "end_line": 1309,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models._clone_functional_model#1333",
        "src_path": "keras/models.py",
        "class_name": "keras.models",
        "signature": "keras.models._clone_functional_model(model, input_tensors=None)",
        "snippet": "def _clone_functional_model(model, input_tensors=None):\n    \"\"\"Clone a functional `Model` instance.\n\n    Model cloning is similar to calling a model on new inputs,\n    except that it creates new layers (and thus new weights) instead\n    of sharing the weights of the existing layers.\n\n    # Arguments\n        model: Instance of `Model`.\n        input_tensors: optional list of input tensors\n            to build the model upon. If not provided,\n            placeholders will be created.\n\n    # Returns\n        An instance of `Model` reproducing the behavior\n        of the original model, on top of new inputs tensors,\n        using newly instantiated weights.\n\n    # Raises\n        ValueError: in case of invalid `model` argument value.\n    \"\"\"\n    if not isinstance(model, Model):\n        raise ValueError('Expected `model` argument '\n                         'to be a `Model` instance, got ', model)\n    if isinstance(model, Sequential):\n        raise ValueError('Expected `model` argument '\n                         'to be a functional `Model` instance, '\n                         'got a `Sequential` instance instead:', model)\n\n    layer_map = {}  # Cache for created layers.\n    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}\n    if input_tensors is None:\n        # Create placeholders to build the model on top of.\n        input_layers = []\n        input_tensors = []\n        for layer in model.input_layers:\n            input_tensor = Input(batch_shape=layer.batch_input_shape,\n                                 dtype=layer.dtype,\n                                 sparse=layer.sparse,\n                                 name=layer.name)\n            input_tensors.append(input_tensor)\n            # Cache newly created input layer.\n            newly_created_input_layer = input_tensor._keras_history[0]\n            layer_map[layer] = newly_created_input_layer\n        for original_input_layer, cloned_input_layer in zip(model.input_layers, input_layers):\n            layer_map[original_input_layer] = cloned_input_layer\n    else:\n        # Make sure that all input tensors come from a Keras layer.\n        # If tensor comes from an input layer: cache the input layer.\n        input_tensors = topology._to_list(input_tensors)\n        _input_tensors = []\n        for i, x in enumerate(input_tensors):\n            if not K.is_keras_tensor(x):\n                name = model.input_layers[i].name\n                input_tensor = Input(tensor=x,\n                                     name='input_wrapper_for_' + name)\n                _input_tensors.append(input_tensor)\n                # Cache newly created input layer.\n                original_input_layer = x._keras_history[0]\n                newly_created_input_layer = input_tensor._keras_history[0]\n                layer_map[original_input_layer] = newly_created_input_layer\n            else:\n                _input_tensors.append(x)\n        input_tensors = _input_tensors\n\n    for x, y in zip(model.inputs, input_tensors):\n        tensor_map[x] = (y, None)  # tensor, mask\n\n    # Iterated over every node in the reference model, in depth order.\n    depth_keys = list(model.nodes_by_depth.keys())\n    depth_keys.sort(reverse=True)\n    for depth in depth_keys:\n        nodes = model.nodes_by_depth[depth]\n        for node in nodes:\n            # Recover the corresponding layer.\n            layer = node.outbound_layer\n\n            # Get or create layer.\n            if layer not in layer_map:\n                # Clone layer.\n                new_layer = layer.__class__.from_config(layer.get_config())\n                layer_map[layer] = new_layer\n                layer = new_layer\n            else:\n                # Reuse previously cloned layer.\n                layer = layer_map[layer]\n                # Don't call InputLayer multiple times.\n                if isinstance(layer, topology.InputLayer):\n                    continue\n\n            # Gather inputs to call the new layer.\n            reference_input_tensors = node.input_tensors\n            reference_output_tensors = node.output_tensors\n\n            # If all previous input tensors are available in tensor_map,\n            # then call node.inbound_layer on them.\n            computed_data = []  # List of tuples (input, mask).\n            for x in reference_input_tensors:\n                if x in tensor_map:\n                    computed_data.append(tensor_map[x])\n\n            if len(computed_data) == len(reference_input_tensors):\n                # Call layer.\n                if node.arguments:\n                    kwargs = node.arguments\n                else:\n                    kwargs = {}\n                if len(computed_data) == 1:\n                    computed_tensor, computed_mask = computed_data[0]\n                    if has_arg(layer.call, 'mask'):\n                        if 'mask' not in kwargs:\n                            kwargs['mask'] = computed_mask\n                    output_tensors = topology._to_list(\n                        layer(computed_tensor, **kwargs))\n                    output_masks = topology._to_list(\n                        layer.compute_mask(computed_tensor,\n                                           computed_mask))\n                    computed_tensors = [computed_tensor]\n                    computed_masks = [computed_mask]\n                else:\n                    computed_tensors = [x[0] for x in computed_data]\n                    computed_masks = [x[1] for x in computed_data]\n                    if has_arg(layer.call, 'mask'):\n                        if 'mask' not in kwargs:\n                            kwargs['mask'] = computed_masks\n                    output_tensors = topology._to_list(\n                        layer(computed_tensors, **kwargs))\n                    output_masks = topology._to_list(\n                        layer.compute_mask(computed_tensors,\n                                           computed_masks))\n                # Update tensor_map.\n                for x, y, mask in zip(reference_output_tensors,\n                                      output_tensors,\n                                      output_masks):\n                    tensor_map[x] = (y, mask)\n\n    # Check that we did compute the model outputs,\n    # then instantiate a new model from inputs and outputs.\n    output_tensors = []\n    for x in model.outputs:\n        assert x in tensor_map, 'Could not compute output ' + str(x)\n        tensor, _ = tensor_map[x]\n        output_tensors.append(tensor)\n    return Model(input_tensors, output_tensors, name=model.name)",
        "begin_line": 1333,
        "end_line": 1476,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models._clone_sequential_model#1479",
        "src_path": "keras/models.py",
        "class_name": "keras.models",
        "signature": "keras.models._clone_sequential_model(model, input_tensors=None)",
        "snippet": "def _clone_sequential_model(model, input_tensors=None):\n    \"\"\"Clone a `Sequential` model instance.\n\n    Model cloning is similar to calling a model on new inputs,\n    except that it creates new layers (and thus new weights) instead\n    of sharing the weights of the existing layers.\n\n    # Arguments\n        model: Instance of `Sequential`.\n        input_tensors: optional list of input tensors\n            to build the model upon. If not provided,\n            placeholders will be created.\n\n    # Returns\n        An instance of `Sequential` reproducing the behavior\n        of the original model, on top of new inputs tensors,\n        using newly instantiated weights.\n\n    # Raises\n        ValueError: in case of invalid `model` argument value.\n    \"\"\"\n    if not isinstance(model, Sequential):\n        raise ValueError('Expected `model` argument '\n                         'to be a `Sequential` model instance, '\n                         'but got:', model)\n\n    def clone(layer):\n        return layer.__class__.from_config(layer.get_config())\n\n    layers = [clone(layer) for layer in model.layers]\n    if input_tensors is None:\n        return Sequential(layers=layers, name=model.name)\n    else:\n        if len(topology._to_list(input_tensors)) != 1:\n            raise ValueError('To clone a `Sequential` model, we expect '\n                             ' at most one tensor '\n                             'as part of `input_tensors`.')\n        x = topology._to_list(input_tensors)[0]\n        if K.is_keras_tensor(x):\n            origin_layer = x._keras_history[0]\n            if isinstance(origin_layer, topology.InputLayer):\n                return Sequential(layers=[origin_layer] + layers,\n                                  name=model.name)\n            else:\n                raise ValueError('Cannot clone a `Sequential` model on top '\n                                 'of a tensor that comes from a Keras layer '\n                                 'other than an `InputLayer`. '\n                                 'Use the functional API instead.')\n        input_tensor = Input(tensor=x,\n                             name='input_wrapper_for_' + str(x.name))\n        input_layer = input_tensor._keras_history[0]\n        return Sequential(layers=[input_layer] + layers, name=model.name)",
        "begin_line": 1479,
        "end_line": 1530,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.clone#1505",
        "src_path": "keras/models.py",
        "class_name": "keras.models",
        "signature": "keras.models.clone(layer)",
        "snippet": "    def clone(layer):\n        return layer.__class__.from_config(layer.get_config())",
        "begin_line": 1505,
        "end_line": 1506,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.models.clone_model#1533",
        "src_path": "keras/models.py",
        "class_name": "keras.models",
        "signature": "keras.models.clone_model(model, input_tensors=None)",
        "snippet": "def clone_model(model, input_tensors=None):\n    \"\"\"Clone any `Model` instance.\n\n    Model cloning is similar to calling a model on new inputs,\n    except that it creates new layers (and thus new weights) instead\n    of sharing the weights of the existing layers.\n\n    # Arguments\n        model: Instance of `Model`\n            (could be a functional model or a Sequential model).\n        input_tensors: optional list of input tensors\n            to build the model upon. If not provided,\n            placeholders will be created.\n\n    # Returns\n        An instance of `Model` reproducing the behavior\n        of the original model, on top of new inputs tensors,\n        using newly instantiated weights.\n\n    # Raises\n        ValueError: in case of invalid `model` argument value.\n    \"\"\"\n    if isinstance(model, Sequential):\n        return _clone_sequential_model(model, input_tensors=input_tensors)\n    else:\n        return _clone_functional_model(model, input_tensors=input_tensors)",
        "begin_line": 1533,
        "end_line": 1558,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.layers.Merge.__init__#62",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Merge",
        "signature": "keras.legacy.layers.Merge.__init__(self, layers=None, mode='sum', concat_axis=-1, dot_axes=-1, output_shape=None, output_mask=None, arguments=None, node_indices=None, tensor_indices=None, name=None)",
        "snippet": "    def __init__(self, layers=None, mode='sum', concat_axis=-1,\n                 dot_axes=-1, output_shape=None, output_mask=None,\n                 arguments=None, node_indices=None, tensor_indices=None,\n                 name=None):\n        warnings.warn('The `Merge` layer is deprecated '\n                      'and will be removed after 08/2017. '\n                      'Use instead layers from `keras.layers.merge`, '\n                      'e.g. `add`, `concatenate`, etc.', stacklevel=2)\n        self.layers = layers\n        self.mode = mode\n        self.concat_axis = concat_axis\n        self.dot_axes = dot_axes\n        self._output_shape = output_shape\n        self.node_indices = node_indices\n        self._output_mask = output_mask\n        self.arguments = arguments if arguments else {}\n        self._initial_weights = None\n        self._updates = []\n        self._losses = []\n        self._per_input_updates = {}\n        self._per_input_losses = {}\n\n        # Layer parameters.\n        self.inbound_nodes = []\n        self.outbound_nodes = []\n        self.constraints = {}\n        self._trainable_weights = []\n        self._non_trainable_weights = []\n        self.supports_masking = True\n        self.uses_learning_phase = False\n        self.input_spec = None  # Compatible with anything.\n        if not name:\n            prefix = self.__class__.__name__.lower()\n            name = prefix + '_' + str(K.get_uid(prefix))\n        self.name = name\n\n        if layers:\n            # This exists for backwards compatibility.\n            # equivalent to:\n            # merge = Merge(layers=None)\n            # output = merge([input_tensor_1, input_tensor_2])\n            if not node_indices:\n                # By default we connect to\n                # the 1st output stream in the input layer.\n                node_indices = [0 for _ in range(len(layers))]\n            if not tensor_indices:\n                tensor_indices = [0 for _ in range(len(layers))]\n            self._arguments_validation(layers, mode,\n                                       concat_axis, dot_axes,\n                                       node_indices, tensor_indices)\n            self.built = True\n            input_tensors = []\n            input_masks = []\n            for i, layer in enumerate(layers):\n                node_index = node_indices[i]\n                tensor_index = tensor_indices[i]\n                inbound_node = layer.inbound_nodes[node_index]\n                input_tensors.append(inbound_node.output_tensors[tensor_index])\n                input_masks.append(inbound_node.output_masks[tensor_index])\n            self(input_tensors, mask=input_masks)\n        else:\n            self.built = False",
        "begin_line": 62,
        "end_line": 123,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.layers.Merge._arguments_validation#125",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Merge",
        "signature": "keras.legacy.layers.Merge._arguments_validation(self, layers, mode, concat_axis, dot_axes, node_indices, tensor_indices)",
        "snippet": "    def _arguments_validation(self, layers, mode, concat_axis, dot_axes,\n                              node_indices, tensor_indices):\n        \"\"\"Validates user-passed arguments and raises exceptions\n        as appropriate.\n        \"\"\"\n        if not callable(mode):\n            if mode not in {'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'}:\n                raise ValueError('Invalid merge mode: ' + str(mode))\n        if not isinstance(layers, (list, tuple)) or len(layers) < 2:\n            raise TypeError('A Merge should only be applied to a list of '\n                            'layers with at least 2 elements. Found: ' +\n                            str(layers))\n\n        if tensor_indices is None:\n            tensor_indices = [None for _ in range(len(layers))]\n\n        input_shapes = []\n        for i, layer in enumerate(layers):\n            layer_output_shape = layer.get_output_shape_at(node_indices[i])\n            if isinstance(layer_output_shape, list):\n                # Case: the layer has multiple output tensors\n                # and we only need a specific one.\n                layer_output_shape = layer_output_shape[tensor_indices[i]]\n            input_shapes.append(layer_output_shape)\n\n        if mode in {'sum', 'mul', 'ave', 'cos', 'max'}:\n            input_shapes_set = set(input_shapes)\n            if len(input_shapes_set) > 1:\n                raise ValueError('Only layers of same output shape can '\n                                 'be merged using ' + mode + ' mode. ' +\n                                 'Layer shapes: %s' % input_shapes)\n        if mode in {'cos', 'dot'}:\n            if len(layers) > 2:\n                raise ValueError(mode + ' merge takes exactly 2 layers')\n            shape1 = input_shapes[0]\n            shape2 = input_shapes[1]\n            n1 = len(shape1)\n            n2 = len(shape2)\n            if isinstance(dot_axes, int):\n                if dot_axes < 0:\n                    self.dot_axes = [dot_axes % n1, dot_axes % n2]\n                else:\n                    self.dot_axes = [dot_axes, ] * 2\n            if not isinstance(self.dot_axes, (list, tuple)):\n                raise TypeError('Invalid type for dot_axes - '\n                                'should be a list.')\n            if len(self.dot_axes) != 2:\n                raise ValueError('Invalid format for dot_axes - '\n                                 'should contain two elements.')\n            if not isinstance(self.dot_axes[0], int) or not isinstance(self.dot_axes[1], int):\n                raise ValueError('Invalid format for dot_axes - '\n                                 'list elements should be \"int\".')\n            if shape1[self.dot_axes[0]] != shape2[self.dot_axes[1]]:\n                raise ValueError('Dimension incompatibility using dot mode: '\n                                 '%s != %s. ' % (shape1[self.dot_axes[0]], shape2[self.dot_axes[1]]) +\n                                 'Layer shapes: %s, %s' % (shape1, shape2))\n        elif mode == 'concat':\n            reduced_inputs_shapes = [list(shape) for shape in input_shapes]\n            shape_set = set()\n            for i in range(len(reduced_inputs_shapes)):\n                del reduced_inputs_shapes[i][self.concat_axis]\n                shape_set.add(tuple(reduced_inputs_shapes[i]))\n            if len(shape_set) > 1:\n                raise ValueError('\"concat\" mode can only merge '\n                                 'layers with matching '\n                                 'output shapes except for the concat axis. '\n                                 'Layer shapes: %s' % (input_shapes))",
        "begin_line": 125,
        "end_line": 191,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.layers.Merge.call#193",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Merge",
        "signature": "keras.legacy.layers.Merge.call(self, inputs, mask=None)",
        "snippet": "    def call(self, inputs, mask=None):\n        if not isinstance(inputs, list) or len(inputs) <= 1:\n            raise TypeError('Merge must be called on a list of tensors '\n                            '(at least 2). Got: ' + str(inputs))\n        # Case: \"mode\" is a lambda or function.\n        if callable(self.mode):\n            arguments = self.arguments\n            if has_arg(self.mode, 'mask'):\n                arguments['mask'] = mask\n            return self.mode(inputs, **arguments)\n\n        if self.mode == 'sum' or self.mode == 'ave':\n            s = inputs[0]\n            for i in range(1, len(inputs)):\n                s += inputs[i]\n            if self.mode == 'ave':\n                s /= len(inputs)\n            return s\n\n        elif self.mode == 'concat':\n            return K.concatenate(inputs, axis=self.concat_axis)\n\n        elif self.mode == 'mul':\n            s = inputs[0]\n            for i in range(1, len(inputs)):\n                s *= inputs[i]\n            return s\n        elif self.mode == 'max':\n            s = inputs[0]\n            for i in range(1, len(inputs)):\n                s = K.maximum(s, inputs[i])\n            return s\n        elif self.mode == 'dot':\n            l1 = inputs[0]\n            l2 = inputs[1]\n            output = K.batch_dot(l1, l2, self.dot_axes)\n            return output\n\n        elif self.mode == 'cos':\n            l1 = inputs[0]\n            l2 = inputs[1]\n            denominator = K.sqrt(K.batch_dot(l1, l1, self.dot_axes) *\n                                 K.batch_dot(l2, l2, self.dot_axes))\n            denominator = K.maximum(denominator, K.epsilon())\n            output = K.batch_dot(l1, l2, self.dot_axes) / denominator\n            output = K.expand_dims(output, 1)\n            return output\n        else:\n            raise ValueError('Unknown merge mode.')",
        "begin_line": 193,
        "end_line": 241,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.layers.Merge.compute_output_shape#243",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Merge",
        "signature": "keras.legacy.layers.Merge.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        # Must have multiple input shape tuples.\n        assert isinstance(input_shape, list)\n        # Case: callable self._output_shape.\n        if callable(self.mode):\n            if callable(self._output_shape):\n                output_shape = self._output_shape(input_shape)\n                return output_shape\n            elif self._output_shape is not None:\n                return (input_shape[0][0],) + tuple(self._output_shape)\n            else:\n                raise ValueError('The Merge layer ' + self.name +\n                                 ' has a callable `mode` argument, '\n                                 'and we cannot infer its output shape '\n                                 'because no `output_shape` '\n                                 'argument was provided. '\n                                 'Make sure to pass a shape tuple '\n                                 '(or callable) '\n                                 '`output_shape` to Merge.')\n        # Pre-defined merge modes.\n        input_shapes = input_shape\n        if self.mode in ['sum', 'mul', 'ave', 'max']:\n            # All tuples in input_shapes should be the same.\n            return input_shapes[0]\n        elif self.mode == 'concat':\n            output_shape = list(input_shapes[0])\n            for shape in input_shapes[1:]:\n                if output_shape[self.concat_axis] is None or shape[self.concat_axis] is None:\n                    output_shape[self.concat_axis] = None\n                    break\n                output_shape[self.concat_axis] += shape[self.concat_axis]\n            return tuple(output_shape)\n        elif self.mode in ['dot', 'cos']:\n            shape1 = list(input_shapes[0])\n            shape2 = list(input_shapes[1])\n            shape1.pop(self.dot_axes[0])\n            shape2.pop(self.dot_axes[1])\n            shape2.pop(0)\n            output_shape = shape1 + shape2\n            if len(output_shape) == 1:\n                output_shape += [1]\n            return tuple(output_shape)",
        "begin_line": 243,
        "end_line": 284,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.layers.Merge.compute_mask#286",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Merge",
        "signature": "keras.legacy.layers.Merge.compute_mask(self, inputs, mask=None)",
        "snippet": "    def compute_mask(self, inputs, mask=None):\n        if mask is None or all([m is None for m in mask]):\n            return None\n\n        assert hasattr(mask, '__len__') and len(mask) == len(inputs)\n\n        if self.mode in ['sum', 'mul', 'ave', 'max']:\n            masks = [K.expand_dims(m, 0) for m in mask if m is not None]\n            return K.all(K.concatenate(masks, axis=0), axis=0, keepdims=False)\n        elif self.mode == 'concat':\n            # Make a list of masks while making sure\n            # the dimensionality of each mask\n            # is the same as the corresponding input.\n            masks = []\n            for input_i, mask_i in zip(inputs, mask):\n                if mask_i is None:\n                    # Input is unmasked. Append all 1s to masks,\n                    masks.append(K.ones_like(input_i, dtype='bool'))\n                elif K.ndim(mask_i) < K.ndim(input_i):\n                    # Mask is smaller than the input, expand it\n                    masks.append(K.expand_dims(mask_i))\n                else:\n                    masks.append(mask_i)\n            concatenated = K.concatenate(masks, axis=self.concat_axis)\n            return K.all(concatenated, axis=-1, keepdims=False)\n        elif self.mode in ['cos', 'dot']:\n            return None\n        elif callable(self.mode):\n            if callable(self._output_mask):\n                return self._output_mask(mask)\n            else:\n                return self._output_mask\n        else:\n            # This should have been caught earlier.\n            raise ValueError('Invalid merge mode: {}'.format(self.mode))",
        "begin_line": 286,
        "end_line": 320,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.layers.Merge.get_config#322",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Merge",
        "signature": "keras.legacy.layers.Merge.get_config(self)",
        "snippet": "    def get_config(self):\n        if isinstance(self.mode, python_types.LambdaType):\n            mode = func_dump(self.mode)\n            mode_type = 'lambda'\n        elif callable(self.mode):\n            mode = self.mode.__name__\n            mode_type = 'function'\n        else:\n            mode = self.mode\n            mode_type = 'raw'\n\n        if isinstance(self._output_shape, python_types.LambdaType):\n            output_shape = func_dump(self._output_shape)\n            output_shape_type = 'lambda'\n        elif callable(self._output_shape):\n            output_shape = self._output_shape.__name__\n            output_shape_type = 'function'\n        else:\n            output_shape = self._output_shape\n            output_shape_type = 'raw'\n\n        if isinstance(self._output_mask, python_types.LambdaType):\n            output_mask = func_dump(self._output_mask)\n            output_mask_type = 'lambda'\n        elif callable(self._output_mask):\n            output_mask = self._output_mask.__name__\n            output_mask_type = 'function'\n        else:\n            output_mask = self._output_mask\n            output_mask_type = 'raw'\n\n        return {'name': self.name,\n                'mode': mode,\n                'mode_type': mode_type,\n                'concat_axis': self.concat_axis,\n                'dot_axes': self.dot_axes,\n                'output_shape': output_shape,\n                'output_shape_type': output_shape_type,\n                'output_mask': output_mask,\n                'output_mask_type': output_mask_type,\n                'arguments': self.arguments}",
        "begin_line": 322,
        "end_line": 362,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.layers.Merge.from_config#365",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Merge",
        "signature": "keras.legacy.layers.Merge.from_config(cls, config)",
        "snippet": "    def from_config(cls, config):\n        config = config.copy()\n        mode_type = config.pop('mode_type')\n        if mode_type == 'function':\n            mode = globals()[config['mode']]\n        elif mode_type == 'lambda':\n            mode = func_load(config['mode'], globs=globals())\n        else:\n            mode = config['mode']\n\n        output_shape_type = config.pop('output_shape_type', None)\n        if output_shape_type == 'function':\n            output_shape = globals()[config['output_shape']]\n        elif output_shape_type == 'lambda':\n            output_shape = func_load(config['output_shape'],\n                                     globs=globals())\n        else:\n            output_shape = config.get('output_shape')\n\n        output_mask_type = config.pop('output_mask_type', None)\n        if output_mask_type == 'function':\n            output_mask = globals()[config['output_mask']]\n        elif output_mask_type == 'lambda':\n            output_mask = func_load(config['output_mask'],\n                                    globs=globals())\n        else:\n            output_mask = config.get('output_mask')\n\n        config['mode'] = mode\n        config['output_shape'] = output_shape\n        config['output_mask'] = output_mask\n        return super(Merge, cls).from_config(config)",
        "begin_line": 365,
        "end_line": 396,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.layers.merge#399",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers",
        "signature": "keras.legacy.layers.merge(inputs, mode='sum', concat_axis=-1, dot_axes=-1, output_shape=None, output_mask=None, arguments=None, name=None)",
        "snippet": "def merge(inputs, mode='sum', concat_axis=-1,\n          dot_axes=-1, output_shape=None, output_mask=None,\n          arguments=None, name=None):\n    \"\"\"Functional merge, to apply to Keras tensors (NOT layers).\n    Returns a Keras tensor.\n    # Example\n    ```python\n    tensor_a = Input(shape=(32,))\n    tensor_b = Input(shape=(32,))\n    merged_tensor = merge([tensor_a, tensor_b], mode='concat', concat_axis=1)\n    ```\n    # Arguments\n        mode: String or lambda/function. If string, must be one\n            of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'.\n            If lambda/function, it should take as input a list of tensors\n            and return a single tensor.\n        concat_axis: Integer, axis to use in mode `concat`.\n        dot_axes: Integer or tuple of integers,\n            axes to use in mode `dot` or `cos`.\n        output_shape: Shape tuple (tuple of integers), or lambda/function\n            to compute output_shape (only if merge mode is a lambda/function).\n            If the latter case, it should take as input a list of shape tuples\n            (1:1 mapping to input tensors) and return a single shape tuple,\n            including the batch size\n            (same convention as the `compute_output_shape` method of layers).\n        node_indices: Optional list of integers containing\n            the output node index for each input layer\n            (in case some input layers have multiple output nodes).\n            will default to an array of 0s if not provided.\n        tensor_indices: Optional list of indices of output tensors\n            to consider for merging\n            (in case some input layer node returns multiple tensors).\n    \"\"\"\n    warnings.warn('The `merge` function is deprecated '\n                  'and will be removed after 08/2017. '\n                  'Use instead layers from `keras.layers.merge`, '\n                  'e.g. `add`, `concatenate`, etc.', stacklevel=2)\n    all_keras_tensors = True\n    for x in inputs:\n        if not hasattr(x, '_keras_history'):\n            all_keras_tensors = False\n            break\n    if all_keras_tensors:\n        input_layers = []\n        node_indices = []\n        tensor_indices = []\n        for x in inputs:\n            input_layer, node_index, tensor_index = x._keras_history\n            input_layers.append(input_layer)\n            node_indices.append(node_index)\n            tensor_indices.append(tensor_index)\n        merge_layer = Merge(input_layers, mode=mode,\n                            concat_axis=concat_axis,\n                            dot_axes=dot_axes,\n                            output_shape=output_shape,\n                            output_mask=output_mask,\n                            arguments=arguments,\n                            node_indices=node_indices,\n                            tensor_indices=tensor_indices,\n                            name=name)\n        return merge_layer.inbound_nodes[0].output_tensors[0]\n    else:\n        merge_layer = Merge(mode=mode,\n                            concat_axis=concat_axis,\n                            dot_axes=dot_axes,\n                            output_shape=output_shape,\n                            output_mask=output_mask,\n                            arguments=arguments,\n                            name=name)\n        return merge_layer(inputs)",
        "begin_line": 399,
        "end_line": 468,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.layers.MaxoutDense.__init__#515",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.MaxoutDense",
        "signature": "keras.legacy.layers.MaxoutDense.__init__(self, output_dim, nb_feature=4, init='glorot_uniform', weights=None, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True, input_dim=None, **kwargs)",
        "snippet": "    def __init__(self, output_dim,\n                 nb_feature=4,\n                 init='glorot_uniform',\n                 weights=None,\n                 W_regularizer=None,\n                 b_regularizer=None,\n                 activity_regularizer=None,\n                 W_constraint=None,\n                 b_constraint=None,\n                 bias=True,\n                 input_dim=None,\n                 **kwargs):\n        warnings.warn('The `MaxoutDense` layer is deprecated '\n                      'and will be removed after 06/2017.')\n        self.output_dim = output_dim\n        self.nb_feature = nb_feature\n        self.init = initializers.get(init)\n\n        self.W_regularizer = regularizers.get(W_regularizer)\n        self.b_regularizer = regularizers.get(b_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n\n        self.W_constraint = constraints.get(W_constraint)\n        self.b_constraint = constraints.get(b_constraint)\n\n        self.bias = bias\n        self.initial_weights = weights\n        self.input_spec = InputSpec(ndim=2)\n\n        self.input_dim = input_dim\n        if self.input_dim:\n            kwargs['input_shape'] = (self.input_dim,)\n        super(MaxoutDense, self).__init__(**kwargs)",
        "begin_line": 515,
        "end_line": 547,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.layers.MaxoutDense.build#549",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.MaxoutDense",
        "signature": "keras.legacy.layers.MaxoutDense.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        input_dim = input_shape[1]\n        self.input_spec = InputSpec(dtype=K.floatx(),\n                                    shape=(None, input_dim))\n\n        self.W = self.add_weight((self.nb_feature, input_dim, self.output_dim),\n                                 initializer=self.init,\n                                 name='W',\n                                 regularizer=self.W_regularizer,\n                                 constraint=self.W_constraint)\n        if self.bias:\n            self.b = self.add_weight((self.nb_feature, self.output_dim,),\n                                     initializer='zero',\n                                     name='b',\n                                     regularizer=self.b_regularizer,\n                                     constraint=self.b_constraint)\n        else:\n            self.b = None\n\n        if self.initial_weights is not None:\n            self.set_weights(self.initial_weights)\n            del self.initial_weights\n        self.built = True",
        "begin_line": 549,
        "end_line": 571,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.layers.MaxoutDense.compute_output_shape#573",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.MaxoutDense",
        "signature": "keras.legacy.layers.MaxoutDense.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        assert input_shape and len(input_shape) == 2\n        return (input_shape[0], self.output_dim)",
        "begin_line": 573,
        "end_line": 575,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.layers.MaxoutDense.call#577",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.MaxoutDense",
        "signature": "keras.legacy.layers.MaxoutDense.call(self, x)",
        "snippet": "    def call(self, x):\n        # no activation, this layer is only linear.\n        output = K.dot(x, self.W)\n        if self.bias:\n            output += self.b\n        output = K.max(output, axis=1)\n        return output",
        "begin_line": 577,
        "end_line": 583,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.layers.MaxoutDense.get_config#585",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.MaxoutDense",
        "signature": "keras.legacy.layers.MaxoutDense.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'output_dim': self.output_dim,\n                  'init': initializers.serialize(self.init),\n                  'nb_feature': self.nb_feature,\n                  'W_regularizer': regularizers.serialize(self.W_regularizer),\n                  'b_regularizer': regularizers.serialize(self.b_regularizer),\n                  'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n                  'W_constraint': constraints.serialize(self.W_constraint),\n                  'b_constraint': constraints.serialize(self.b_constraint),\n                  'bias': self.bias,\n                  'input_dim': self.input_dim}\n        base_config = super(MaxoutDense, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 585,
        "end_line": 597,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.layers.Highway.__init__#640",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Highway",
        "signature": "keras.legacy.layers.Highway.__init__(self, init='glorot_uniform', activation=None, weights=None, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True, input_dim=None, **kwargs)",
        "snippet": "    def __init__(self,\n                 init='glorot_uniform',\n                 activation=None,\n                 weights=None,\n                 W_regularizer=None,\n                 b_regularizer=None,\n                 activity_regularizer=None,\n                 W_constraint=None,\n                 b_constraint=None,\n                 bias=True,\n                 input_dim=None,\n                 **kwargs):\n        warnings.warn('The `Highway` layer is deprecated '\n                      'and will be removed after 06/2017.')\n        if 'transform_bias' in kwargs:\n            kwargs.pop('transform_bias')\n            warnings.warn('`transform_bias` argument is deprecated and '\n                          'has been removed.')\n        self.init = initializers.get(init)\n        self.activation = activations.get(activation)\n\n        self.W_regularizer = regularizers.get(W_regularizer)\n        self.b_regularizer = regularizers.get(b_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n\n        self.W_constraint = constraints.get(W_constraint)\n        self.b_constraint = constraints.get(b_constraint)\n\n        self.bias = bias\n        self.initial_weights = weights\n        self.input_spec = InputSpec(ndim=2)\n\n        self.input_dim = input_dim\n        if self.input_dim:\n            kwargs['input_shape'] = (self.input_dim,)\n        super(Highway, self).__init__(**kwargs)",
        "begin_line": 640,
        "end_line": 675,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.layers.Highway.build#677",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Highway",
        "signature": "keras.legacy.layers.Highway.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        input_dim = input_shape[1]\n        self.input_spec = InputSpec(dtype=K.floatx(),\n                                    shape=(None, input_dim))\n\n        self.W = self.add_weight((input_dim, input_dim),\n                                 initializer=self.init,\n                                 name='W',\n                                 regularizer=self.W_regularizer,\n                                 constraint=self.W_constraint)\n        self.W_carry = self.add_weight((input_dim, input_dim),\n                                       initializer=self.init,\n                                       name='W_carry')\n        if self.bias:\n            self.b = self.add_weight((input_dim,),\n                                     initializer='zero',\n                                     name='b',\n                                     regularizer=self.b_regularizer,\n                                     constraint=self.b_constraint)\n            self.b_carry = self.add_weight((input_dim,),\n                                           initializer='one',\n                                           name='b_carry')\n        else:\n            self.b_carry = None\n\n        if self.initial_weights is not None:\n            self.set_weights(self.initial_weights)\n            del self.initial_weights\n        self.built = True",
        "begin_line": 677,
        "end_line": 705,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.layers.Highway.call#707",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Highway",
        "signature": "keras.legacy.layers.Highway.call(self, x)",
        "snippet": "    def call(self, x):\n        y = K.dot(x, self.W_carry)\n        if self.bias:\n            y += self.b_carry\n        transform_weight = activations.sigmoid(y)\n        y = K.dot(x, self.W)\n        if self.bias:\n            y += self.b\n        act = self.activation(y)\n        act *= transform_weight\n        output = act + (1 - transform_weight) * x\n        return output",
        "begin_line": 707,
        "end_line": 718,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.layers.Highway.get_config#720",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Highway",
        "signature": "keras.legacy.layers.Highway.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'init': initializers.serialize(self.init),\n                  'activation': activations.serialize(self.activation),\n                  'W_regularizer': regularizers.serialize(self.W_regularizer),\n                  'b_regularizer': regularizers.serialize(self.b_regularizer),\n                  'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n                  'W_constraint': constraints.serialize(self.W_constraint),\n                  'b_constraint': constraints.serialize(self.b_constraint),\n                  'bias': self.bias,\n                  'input_dim': self.input_dim}\n        base_config = super(Highway, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 720,
        "end_line": 731,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.layers.AtrousConvolution1D#734",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers",
        "signature": "keras.legacy.layers.AtrousConvolution1D(*args, **kwargs)",
        "snippet": "def AtrousConvolution1D(*args, **kwargs):\n    from ..layers import Conv1D\n    if 'atrous_rate' in kwargs:\n        rate = kwargs.pop('atrous_rate')\n    else:\n        rate = 1\n    kwargs['dilation_rate'] = rate\n    warnings.warn('The `AtrousConvolution1D` layer '\n                  ' has been deprecated. Use instead '\n                  'the `Conv1D` layer with the `dilation_rate` '\n                  'argument.')\n    return Conv1D(*args, **kwargs)",
        "begin_line": 734,
        "end_line": 745,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.layers.AtrousConvolution2D#748",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers",
        "signature": "keras.legacy.layers.AtrousConvolution2D(*args, **kwargs)",
        "snippet": "def AtrousConvolution2D(*args, **kwargs):\n    from ..layers import Conv2D\n    if 'atrous_rate' in kwargs:\n        rate = kwargs.pop('atrous_rate')\n    else:\n        rate = 1\n    kwargs['dilation_rate'] = rate\n    warnings.warn('The `AtrousConvolution2D` layer '\n                  ' has been deprecated. Use instead '\n                  'the `Conv2D` layer with the `dilation_rate` '\n                  'argument.')\n    return Conv2D(*args, **kwargs)",
        "begin_line": 748,
        "end_line": 759,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.layers.Recurrent.__init__#884",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Recurrent",
        "signature": "keras.legacy.layers.Recurrent.__init__(self, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False, implementation=0, **kwargs)",
        "snippet": "    def __init__(self, return_sequences=False,\n                 return_state=False,\n                 go_backwards=False,\n                 stateful=False,\n                 unroll=False,\n                 implementation=0,\n                 **kwargs):\n        super(Recurrent, self).__init__(**kwargs)\n        self.return_sequences = return_sequences\n        self.return_state = return_state\n        self.go_backwards = go_backwards\n\n        self.stateful = stateful\n        self.unroll = unroll\n        self.implementation = implementation\n        self.supports_masking = True\n        self.input_spec = [InputSpec(ndim=3)]\n        self.state_spec = None\n        self.dropout = 0\n        self.recurrent_dropout = 0",
        "begin_line": 884,
        "end_line": 903,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.layers.Recurrent.compute_mask#920",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Recurrent",
        "signature": "keras.legacy.layers.Recurrent.compute_mask(self, inputs, mask)",
        "snippet": "    def compute_mask(self, inputs, mask):\n        if isinstance(mask, list):\n            mask = mask[0]\n        output_mask = mask if self.return_sequences else None\n        if self.return_state:\n            state_mask = [None for _ in self.states]\n            return [output_mask] + state_mask\n        else:\n            return output_mask",
        "begin_line": 920,
        "end_line": 928,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.layers.Recurrent.preprocess_input#945",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Recurrent",
        "signature": "keras.legacy.layers.Recurrent.preprocess_input(self, inputs, training=None)",
        "snippet": "    def preprocess_input(self, inputs, training=None):\n        return inputs",
        "begin_line": 945,
        "end_line": 946,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.layers.Recurrent.__call__#948",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Recurrent",
        "signature": "keras.legacy.layers.Recurrent.__call__(self, inputs, initial_state=None, **kwargs)",
        "snippet": "    def __call__(self, inputs, initial_state=None, **kwargs):\n\n        # If there are multiple inputs, then\n        # they should be the main input and `initial_state`\n        # e.g. when loading model from file\n        if isinstance(inputs, (list, tuple)) and len(inputs) > 1 and initial_state is None:\n            initial_state = inputs[1:]\n            inputs = inputs[0]\n\n        # If `initial_state` is specified,\n        # and if it a Keras tensor,\n        # then add it to the inputs and temporarily\n        # modify the input spec to include the state.\n        if initial_state is None:\n            return super(Recurrent, self).__call__(inputs, **kwargs)\n\n        if not isinstance(initial_state, (list, tuple)):\n            initial_state = [initial_state]\n\n        is_keras_tensor = hasattr(initial_state[0], '_keras_history')\n        for tensor in initial_state:\n            if hasattr(tensor, '_keras_history') != is_keras_tensor:\n                raise ValueError('The initial state of an RNN layer cannot be'\n                                 ' specified with a mix of Keras tensors and'\n                                 ' non-Keras tensors')\n\n        if is_keras_tensor:\n            # Compute the full input spec, including state\n            input_spec = self.input_spec\n            state_spec = self.state_spec\n            if not isinstance(input_spec, list):\n                input_spec = [input_spec]\n            if not isinstance(state_spec, list):\n                state_spec = [state_spec]\n            self.input_spec = input_spec + state_spec\n\n            # Compute the full inputs, including state\n            inputs = [inputs] + list(initial_state)\n\n            # Perform the call\n            output = super(Recurrent, self).__call__(inputs, **kwargs)\n\n            # Restore original input spec\n            self.input_spec = input_spec\n            return output\n        else:\n            kwargs['initial_state'] = initial_state\n            return super(Recurrent, self).__call__(inputs, **kwargs)",
        "begin_line": 948,
        "end_line": 995,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.layers.Recurrent.call#997",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Recurrent",
        "signature": "keras.legacy.layers.Recurrent.call(self, inputs, mask=None, training=None, initial_state=None)",
        "snippet": "    def call(self, inputs, mask=None, training=None, initial_state=None):\n        # input shape: `(samples, time (padded with zeros), input_dim)`\n        # note that the .build() method of subclasses MUST define\n        # self.input_spec and self.state_spec with complete input shapes.\n        if isinstance(inputs, list):\n            initial_state = inputs[1:]\n            inputs = inputs[0]\n        elif initial_state is not None:\n            pass\n        elif self.stateful:\n            initial_state = self.states\n        else:\n            initial_state = self.get_initial_state(inputs)\n\n        if isinstance(mask, list):\n            mask = mask[0]\n\n        if len(initial_state) != len(self.states):\n            raise ValueError('Layer has ' + str(len(self.states)) +\n                             ' states but was passed ' +\n                             str(len(initial_state)) +\n                             ' initial states.')\n        input_shape = K.int_shape(inputs)\n        timesteps = input_shape[1]\n        if self.unroll and timesteps in [None, 1]:\n            raise ValueError('Cannot unroll a RNN if the '\n                             'time dimension is undefined or equal to 1. \\n'\n                             '- If using a Sequential model, '\n                             'specify the time dimension by passing '\n                             'an `input_shape` or `batch_input_shape` '\n                             'argument to your first layer. If your '\n                             'first layer is an Embedding, you can '\n                             'also use the `input_length` argument.\\n'\n                             '- If using the functional API, specify '\n                             'the time dimension by passing a `shape` '\n                             'or `batch_shape` argument to your Input layer.')\n        constants = self.get_constants(inputs, training=None)\n        preprocessed_input = self.preprocess_input(inputs, training=None)\n        last_output, outputs, states = K.rnn(self.step,\n                                             preprocessed_input,\n                                             initial_state,\n                                             go_backwards=self.go_backwards,\n                                             mask=mask,\n                                             constants=constants,\n                                             unroll=self.unroll,\n                                             input_length=timesteps)\n        if self.stateful:\n            updates = []\n            for i in range(len(states)):\n                updates.append((self.states[i], states[i]))\n            self.add_update(updates, inputs)\n\n        # Properly set learning phase\n        if 0 < self.dropout + self.recurrent_dropout:\n            last_output._uses_learning_phase = True\n            outputs._uses_learning_phase = True\n\n        if self.return_sequences:\n            output = outputs\n        else:\n            output = last_output\n\n        if self.return_state:\n            if not isinstance(states, (list, tuple)):\n                states = [states]\n            else:\n                states = list(states)\n            return [output] + states\n        else:\n            return output",
        "begin_line": 997,
        "end_line": 1066,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.layers.Recurrent.get_config#1108",
        "src_path": "keras/legacy/layers.py",
        "class_name": "keras.legacy.layers.Recurrent",
        "signature": "keras.legacy.layers.Recurrent.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'return_sequences': self.return_sequences,\n                  'return_state': self.return_state,\n                  'go_backwards': self.go_backwards,\n                  'stateful': self.stateful,\n                  'unroll': self.unroll,\n                  'implementation': self.implementation}\n        base_config = super(Recurrent, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 1108,
        "end_line": 1116,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvRecurrent2D.__init__#88",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvRecurrent2D",
        "signature": "keras.layers.convolutional_recurrent.ConvRecurrent2D.__init__(self, filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), return_sequences=False, go_backwards=False, stateful=False, **kwargs)",
        "snippet": "    def __init__(self, filters,\n                 kernel_size,\n                 strides=(1, 1),\n                 padding='valid',\n                 data_format=None,\n                 dilation_rate=(1, 1),\n                 return_sequences=False,\n                 go_backwards=False,\n                 stateful=False,\n                 **kwargs):\n        super(ConvRecurrent2D, self).__init__(**kwargs)\n        self.filters = filters\n        self.kernel_size = conv_utils.normalize_tuple(kernel_size, 2, 'kernel_size')\n        self.strides = conv_utils.normalize_tuple(strides, 2, 'strides')\n        self.padding = conv_utils.normalize_padding(padding)\n        self.data_format = conv_utils.normalize_data_format(data_format)\n        self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, 2, 'dilation_rate')\n        self.return_sequences = return_sequences\n        self.go_backwards = go_backwards\n        self.stateful = stateful\n        self.input_spec = [InputSpec(ndim=5)]\n        self.state_spec = None",
        "begin_line": 88,
        "end_line": 109,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvRecurrent2D.compute_output_shape#111",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvRecurrent2D",
        "signature": "keras.layers.convolutional_recurrent.ConvRecurrent2D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n        if self.data_format == 'channels_first':\n            rows = input_shape[3]\n            cols = input_shape[4]\n        elif self.data_format == 'channels_last':\n            rows = input_shape[2]\n            cols = input_shape[3]\n        rows = conv_utils.conv_output_length(rows,\n                                             self.kernel_size[0],\n                                             padding=self.padding,\n                                             stride=self.strides[0],\n                                             dilation=self.dilation_rate[0])\n        cols = conv_utils.conv_output_length(cols,\n                                             self.kernel_size[1],\n                                             padding=self.padding,\n                                             stride=self.strides[1],\n                                             dilation=self.dilation_rate[1])\n        if self.return_sequences:\n            if self.data_format == 'channels_first':\n                output_shape = (input_shape[0], input_shape[1],\n                                self.filters, rows, cols)\n            elif self.data_format == 'channels_last':\n                output_shape = (input_shape[0], input_shape[1],\n                                rows, cols, self.filters)\n        else:\n            if self.data_format == 'channels_first':\n                output_shape = (input_shape[0], self.filters, rows, cols)\n            elif self.data_format == 'channels_last':\n                output_shape = (input_shape[0], rows, cols, self.filters)\n\n        if self.return_state:\n            if self.data_format == 'channels_first':\n                output_shape = [output_shape] + [(input_shape[0], self.filters, rows, cols) for _ in range(2)]\n            elif self.data_format == 'channels_last':\n                output_shape = [output_shape] + [(input_shape[0], rows, cols, self.filters) for _ in range(2)]\n\n        return output_shape",
        "begin_line": 111,
        "end_line": 149,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvRecurrent2D.get_config#151",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvRecurrent2D",
        "signature": "keras.layers.convolutional_recurrent.ConvRecurrent2D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'filters': self.filters,\n                  'kernel_size': self.kernel_size,\n                  'strides': self.strides,\n                  'padding': self.padding,\n                  'data_format': self.data_format,\n                  'dilation_rate': self.dilation_rate,\n                  'return_sequences': self.return_sequences,\n                  'go_backwards': self.go_backwards,\n                  'stateful': self.stateful}\n        base_config = super(ConvRecurrent2D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 151,
        "end_line": 162,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.__init__#286",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.__init__(self, filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, return_sequences=False, go_backwards=False, stateful=False, dropout=0.0, recurrent_dropout=0.0, **kwargs)",
        "snippet": "    def __init__(self, filters,\n                 kernel_size,\n                 strides=(1, 1),\n                 padding='valid',\n                 data_format=None,\n                 dilation_rate=(1, 1),\n                 activation='tanh',\n                 recurrent_activation='hard_sigmoid',\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 recurrent_initializer='orthogonal',\n                 bias_initializer='zeros',\n                 unit_forget_bias=True,\n                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 recurrent_constraint=None,\n                 bias_constraint=None,\n                 return_sequences=False,\n                 go_backwards=False,\n                 stateful=False,\n                 dropout=0.,\n                 recurrent_dropout=0.,\n                 **kwargs):\n        super(ConvLSTM2D, self).__init__(filters,\n                                         kernel_size,\n                                         strides=strides,\n                                         padding=padding,\n                                         data_format=data_format,\n                                         dilation_rate=dilation_rate,\n                                         return_sequences=return_sequences,\n                                         go_backwards=go_backwards,\n                                         stateful=stateful,\n                                         **kwargs)\n        self.activation = activations.get(activation)\n        self.recurrent_activation = activations.get(recurrent_activation)\n        self.use_bias = use_bias\n\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.recurrent_initializer = initializers.get(recurrent_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.unit_forget_bias = unit_forget_bias\n\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.recurrent_constraint = constraints.get(recurrent_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n\n        self.dropout = min(1., max(0., dropout))\n        self.recurrent_dropout = min(1., max(0., recurrent_dropout))\n        self.state_spec = [InputSpec(ndim=4), InputSpec(ndim=4)]",
        "begin_line": 286,
        "end_line": 342,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.build#344",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n        batch_size = input_shape[0] if self.stateful else None\n        self.input_spec[0] = InputSpec(shape=(batch_size, None) + input_shape[2:])\n        if self.stateful:\n            self.reset_states()\n        else:\n            # initial states: 2 all-zero tensor of shape (filters)\n            self.states = [None, None]\n\n        if self.data_format == 'channels_first':\n            channel_axis = 2\n        else:\n            channel_axis = -1\n        if input_shape[channel_axis] is None:\n            raise ValueError('The channel dimension of the inputs '\n                             'should be defined. Found `None`.')\n        input_dim = input_shape[channel_axis]\n        state_shape = [None] * 4\n        state_shape[channel_axis] = input_dim\n        state_shape = tuple(state_shape)\n        self.state_spec = [InputSpec(shape=state_shape), InputSpec(shape=state_shape)]\n        kernel_shape = self.kernel_size + (input_dim, self.filters * 4)\n        self.kernel_shape = kernel_shape\n        recurrent_kernel_shape = self.kernel_size + (self.filters, self.filters * 4)\n\n        self.kernel = self.add_weight(shape=kernel_shape,\n                                      initializer=self.kernel_initializer,\n                                      name='kernel',\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        self.recurrent_kernel = self.add_weight(\n            shape=recurrent_kernel_shape,\n            initializer=self.recurrent_initializer,\n            name='recurrent_kernel',\n            regularizer=self.recurrent_regularizer,\n            constraint=self.recurrent_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(self.filters * 4,),\n                                        initializer=self.bias_initializer,\n                                        name='bias',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n            if self.unit_forget_bias:\n                bias_value = np.zeros((self.filters * 4,))\n                bias_value[self.filters: self.filters * 2] = 1.\n                K.set_value(self.bias, bias_value)\n        else:\n            self.bias = None\n\n        self.kernel_i = self.kernel[:, :, :, :self.filters]\n        self.recurrent_kernel_i = self.recurrent_kernel[:, :, :, :self.filters]\n        self.kernel_f = self.kernel[:, :, :, self.filters: self.filters * 2]\n        self.recurrent_kernel_f = self.recurrent_kernel[:, :, :, self.filters: self.filters * 2]\n        self.kernel_c = self.kernel[:, :, :, self.filters * 2: self.filters * 3]\n        self.recurrent_kernel_c = self.recurrent_kernel[:, :, :, self.filters * 2: self.filters * 3]\n        self.kernel_o = self.kernel[:, :, :, self.filters * 3:]\n        self.recurrent_kernel_o = self.recurrent_kernel[:, :, :, self.filters * 3:]\n\n        if self.use_bias:\n            self.bias_i = self.bias[:self.filters]\n            self.bias_f = self.bias[self.filters: self.filters * 2]\n            self.bias_c = self.bias[self.filters * 2: self.filters * 3]\n            self.bias_o = self.bias[self.filters * 3:]\n        else:\n            self.bias_i = None\n            self.bias_f = None\n            self.bias_c = None\n            self.bias_o = None\n        self.built = True",
        "begin_line": 344,
        "end_line": 414,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.get_initial_state#416",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.get_initial_state(self, inputs)",
        "snippet": "    def get_initial_state(self, inputs):\n        # (samples, timesteps, rows, cols, filters)\n        initial_state = K.zeros_like(inputs)\n        # (samples, rows, cols, filters)\n        initial_state = K.sum(initial_state, axis=1)\n        shape = list(self.kernel_shape)\n        shape[-1] = self.filters\n        initial_state = self.input_conv(initial_state,\n                                        K.zeros(tuple(shape)),\n                                        padding=self.padding)\n\n        initial_states = [initial_state for _ in range(2)]\n        return initial_states",
        "begin_line": 416,
        "end_line": 428,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.reset_states#430",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.reset_states(self)",
        "snippet": "    def reset_states(self):\n        if not self.stateful:\n            raise RuntimeError('Layer must be stateful.')\n        input_shape = self.input_spec[0].shape\n        output_shape = self.compute_output_shape(input_shape)\n        if not input_shape[0]:\n            raise ValueError('If a RNN is stateful, a complete '\n                             'input_shape must be provided '\n                             '(including batch size). '\n                             'Got input shape: ' + str(input_shape))\n        if self.return_sequences:\n            if self.return_state:\n                output_shape = output_shape[1]\n            else:\n                output_shape = (input_shape[0],) + output_shape[2:]\n        else:\n            if self.return_state:\n                output_shape = output_shape[1]\n            else:\n                output_shape = (input_shape[0],) + output_shape[1:]\n\n        if hasattr(self, 'states'):\n            K.set_value(self.states[0],\n                        np.zeros(output_shape))\n            K.set_value(self.states[1],\n                        np.zeros(output_shape))\n        else:\n            self.states = [K.zeros(output_shape),\n                           K.zeros(output_shape)]",
        "begin_line": 430,
        "end_line": 458,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.get_constants#460",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.get_constants(self, inputs, training=None)",
        "snippet": "    def get_constants(self, inputs, training=None):\n        constants = []\n        if self.implementation == 0 and 0 < self.dropout < 1:\n            ones = K.zeros_like(inputs)\n            ones = K.sum(ones, axis=1)\n            ones += 1\n\n            def dropped_inputs():\n                return K.dropout(ones, self.dropout)\n\n            dp_mask = [K.in_train_phase(dropped_inputs,\n                                        ones,\n                                        training=training) for _ in range(4)]\n            constants.append(dp_mask)\n        else:\n            constants.append([K.cast_to_floatx(1.) for _ in range(4)])\n\n        if 0 < self.recurrent_dropout < 1:\n            shape = list(self.kernel_shape)\n            shape[-1] = self.filters\n            ones = K.zeros_like(inputs)\n            ones = K.sum(ones, axis=1)\n            ones = self.input_conv(ones, K.zeros(shape),\n                                   padding=self.padding)\n            ones += 1.\n\n            def dropped_inputs():\n                return K.dropout(ones, self.recurrent_dropout)\n            rec_dp_mask = [K.in_train_phase(dropped_inputs,\n                                            ones,\n                                            training=training) for _ in range(4)]\n            constants.append(rec_dp_mask)\n        else:\n            constants.append([K.cast_to_floatx(1.) for _ in range(4)])\n        return constants",
        "begin_line": 460,
        "end_line": 494,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.dropped_inputs#467",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.dropped_inputs()",
        "snippet": "            def dropped_inputs():\n                return K.dropout(ones, self.dropout)",
        "begin_line": 467,
        "end_line": 468,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.dropped_inputs#486",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.dropped_inputs()",
        "snippet": "            def dropped_inputs():\n                return K.dropout(ones, self.recurrent_dropout)",
        "begin_line": 486,
        "end_line": 487,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.input_conv#496",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.input_conv(self, x, w, b=None, padding='valid')",
        "snippet": "    def input_conv(self, x, w, b=None, padding='valid'):\n        conv_out = K.conv2d(x, w, strides=self.strides,\n                            padding=padding,\n                            data_format=self.data_format,\n                            dilation_rate=self.dilation_rate)\n        if b is not None:\n            conv_out = K.bias_add(conv_out, b,\n                                  data_format=self.data_format)\n        return conv_out",
        "begin_line": 496,
        "end_line": 504,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.recurrent_conv#506",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.recurrent_conv(self, x, w)",
        "snippet": "    def recurrent_conv(self, x, w):\n        conv_out = K.conv2d(x, w, strides=(1, 1),\n                            padding='same',\n                            data_format=self.data_format)\n        return conv_out",
        "begin_line": 506,
        "end_line": 510,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.step#512",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.step(self, inputs, states)",
        "snippet": "    def step(self, inputs, states):\n        assert len(states) == 4\n        h_tm1 = states[0]\n        c_tm1 = states[1]\n        dp_mask = states[2]\n        rec_dp_mask = states[3]\n\n        x_i = self.input_conv(inputs * dp_mask[0], self.kernel_i, self.bias_i,\n                              padding=self.padding)\n        x_f = self.input_conv(inputs * dp_mask[1], self.kernel_f, self.bias_f,\n                              padding=self.padding)\n        x_c = self.input_conv(inputs * dp_mask[2], self.kernel_c, self.bias_c,\n                              padding=self.padding)\n        x_o = self.input_conv(inputs * dp_mask[3], self.kernel_o, self.bias_o,\n                              padding=self.padding)\n        h_i = self.recurrent_conv(h_tm1 * rec_dp_mask[0],\n                                  self.recurrent_kernel_i)\n        h_f = self.recurrent_conv(h_tm1 * rec_dp_mask[1],\n                                  self.recurrent_kernel_f)\n        h_c = self.recurrent_conv(h_tm1 * rec_dp_mask[2],\n                                  self.recurrent_kernel_c)\n        h_o = self.recurrent_conv(h_tm1 * rec_dp_mask[3],\n                                  self.recurrent_kernel_o)\n\n        i = self.recurrent_activation(x_i + h_i)\n        f = self.recurrent_activation(x_f + h_f)\n        c = f * c_tm1 + i * self.activation(x_c + h_c)\n        o = self.recurrent_activation(x_o + h_o)\n        h = o * self.activation(c)\n        return h, [h, c]",
        "begin_line": 512,
        "end_line": 541,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional_recurrent.ConvLSTM2D.get_config#543",
        "src_path": "keras/layers/convolutional_recurrent.py",
        "class_name": "keras.layers.convolutional_recurrent.ConvLSTM2D",
        "signature": "keras.layers.convolutional_recurrent.ConvLSTM2D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'activation': activations.serialize(self.activation),\n                  'recurrent_activation': activations.serialize(self.recurrent_activation),\n                  'use_bias': self.use_bias,\n                  'kernel_initializer': initializers.serialize(self.kernel_initializer),\n                  'recurrent_initializer': initializers.serialize(self.recurrent_initializer),\n                  'bias_initializer': initializers.serialize(self.bias_initializer),\n                  'unit_forget_bias': self.unit_forget_bias,\n                  'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n                  'recurrent_regularizer': regularizers.serialize(self.recurrent_regularizer),\n                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n                  'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n                  'recurrent_constraint': constraints.serialize(self.recurrent_constraint),\n                  'bias_constraint': constraints.serialize(self.bias_constraint),\n                  'dropout': self.dropout,\n                  'recurrent_dropout': self.recurrent_dropout}\n        base_config = super(ConvLSTM2D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 543,
        "end_line": 561,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.models.needs_legacy_support#4",
        "src_path": "keras/legacy/models.py",
        "class_name": "keras.legacy.models",
        "signature": "keras.legacy.models.needs_legacy_support(model)",
        "snippet": "def needs_legacy_support(model):\n    return isinstance(model.layers[0], Merge)",
        "begin_line": 4,
        "end_line": 5,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.69649956365752e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.models.legacy_sequential_layers#8",
        "src_path": "keras/legacy/models.py",
        "class_name": "keras.legacy.models",
        "signature": "keras.legacy.models.legacy_sequential_layers(model)",
        "snippet": "def legacy_sequential_layers(model):\n    layers = []\n    if model.layers:\n        if isinstance(model.layers[0], Merge):\n            merge = model.layers[0]\n            for layer in merge.layers:\n                if hasattr(layer, 'layers'):\n                    for sublayer in layer.layers:\n                        if sublayer not in layers:\n                            layers.append(sublayer)\n                else:\n                    if layer not in layers:\n                        layers.append(layer)\n        else:\n            if model.layers[0] not in layers:\n                layers.append(model.layers[0])\n        for layer in model.layers[1:]:\n            if layer not in layers:\n                layers.append(layer)\n    return layers",
        "begin_line": 8,
        "end_line": 27,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.__init__#23",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.__init__(self, layer, **kwargs)",
        "snippet": "    def __init__(self, layer, **kwargs):\n        self.layer = layer\n        # Tracks mapping of Wrapper inputs to inner layer inputs. Useful when\n        # the inner layer has update ops that depend on its inputs (as opposed\n        # to the inputs to the Wrapper layer).\n        self._input_map = {}\n        super(Wrapper, self).__init__(**kwargs)",
        "begin_line": 23,
        "end_line": 29,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011301989150090416,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.build#31",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.build(self, input_shape=None)",
        "snippet": "    def build(self, input_shape=None):\n        self.built = True",
        "begin_line": 31,
        "end_line": 32,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001152604887044721,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.activity_regularizer#35",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.activity_regularizer(self)",
        "snippet": "    def activity_regularizer(self):\n        if hasattr(self.layer, 'activity_regularizer'):\n            return self.layer.activity_regularizer\n        else:\n            return None",
        "begin_line": 35,
        "end_line": 39,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.trainable_weights#42",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.trainable_weights(self)",
        "snippet": "    def trainable_weights(self):\n        return self.layer.trainable_weights",
        "begin_line": 42,
        "end_line": 43,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.non_trainable_weights#46",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.non_trainable_weights(self)",
        "snippet": "    def non_trainable_weights(self):\n        return self.layer.non_trainable_weights",
        "begin_line": 46,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.updates#50",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.updates(self)",
        "snippet": "    def updates(self):\n        if hasattr(self.layer, 'updates'):\n            return self.layer.updates\n        return []",
        "begin_line": 50,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00012818869375721061,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.get_updates_for#55",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.get_updates_for(self, inputs=None)",
        "snippet": "    def get_updates_for(self, inputs=None):\n        # If the wrapper modifies the inputs, use the modified inputs to\n        # get the updates from the inner layer.\n        inner_inputs = inputs\n        if inputs is not None:\n            uid = _object_list_uid(inputs)\n            if uid in self._input_map:\n                inner_inputs = self._input_map[uid]\n\n        updates = self.layer.get_updates_for(inner_inputs)\n        updates += super(Wrapper, self).get_updates_for(inputs)\n        return updates",
        "begin_line": 55,
        "end_line": 66,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00012818869375721061,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.losses#69",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.losses(self)",
        "snippet": "    def losses(self):\n        if hasattr(self.layer, 'losses'):\n            return self.layer.losses\n        return []",
        "begin_line": 69,
        "end_line": 72,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.get_losses_for#74",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.get_losses_for(self, inputs=None)",
        "snippet": "    def get_losses_for(self, inputs=None):\n        if inputs is None:\n            losses = self.layer.get_losses_for(None)\n            return losses + super(Wrapper, self).get_losses_for(None)\n        return super(Wrapper, self).get_losses_for(inputs)",
        "begin_line": 74,
        "end_line": 78,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.get_weights#80",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.get_weights(self)",
        "snippet": "    def get_weights(self):\n        return self.layer.get_weights()",
        "begin_line": 80,
        "end_line": 81,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.set_weights#83",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.set_weights(self, weights)",
        "snippet": "    def set_weights(self, weights):\n        self.layer.set_weights(weights)",
        "begin_line": 83,
        "end_line": 84,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.get_config#86",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'layer': {'class_name': self.layer.__class__.__name__,\n                            'config': self.layer.get_config()}}\n        base_config = super(Wrapper, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 86,
        "end_line": 90,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.from_config#93",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.from_config(cls, config, custom_objects=None)",
        "snippet": "    def from_config(cls, config, custom_objects=None):\n        from . import deserialize as deserialize_layer\n        layer = deserialize_layer(config.pop('layer'),\n                                  custom_objects=custom_objects)\n        return cls(layer, **config)",
        "begin_line": 93,
        "end_line": 97,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.wrappers.TimeDistributed.__init__#145",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.TimeDistributed",
        "signature": "keras.layers.wrappers.TimeDistributed.__init__(self, layer, **kwargs)",
        "snippet": "    def __init__(self, layer, **kwargs):\n        super(TimeDistributed, self).__init__(layer, **kwargs)\n        self.supports_masking = True",
        "begin_line": 145,
        "end_line": 147,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001152604887044721,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.wrappers.TimeDistributed.build#149",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.TimeDistributed",
        "signature": "keras.layers.wrappers.TimeDistributed.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        assert len(input_shape) >= 3\n        self.input_spec = InputSpec(shape=input_shape)\n        child_input_shape = (input_shape[0],) + input_shape[2:]\n        if not self.layer.built:\n            self.layer.build(child_input_shape)\n            self.layer.built = True\n        super(TimeDistributed, self).build()",
        "begin_line": 149,
        "end_line": 156,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001152604887044721,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.wrappers.TimeDistributed.compute_output_shape#158",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.TimeDistributed",
        "signature": "keras.layers.wrappers.TimeDistributed.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        child_input_shape = (input_shape[0],) + input_shape[2:]\n        child_output_shape = self.layer.compute_output_shape(child_input_shape)\n        timesteps = input_shape[1]\n        return (child_output_shape[0], timesteps) + child_output_shape[1:]",
        "begin_line": 158,
        "end_line": 162,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001152604887044721,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.wrappers.TimeDistributed.call#164",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.TimeDistributed",
        "signature": "keras.layers.wrappers.TimeDistributed.call(self, inputs, training=None, mask=None)",
        "snippet": "    def call(self, inputs, training=None, mask=None):\n        kwargs = {}\n        if has_arg(self.layer.call, 'training'):\n            kwargs['training'] = training\n        uses_learning_phase = False\n\n        input_shape = K.int_shape(inputs)\n        if input_shape[0]:\n            # batch size matters, use rnn-based implementation\n            def step(x, _):\n                global uses_learning_phase\n                output = self.layer.call(x, **kwargs)\n                if hasattr(output, '_uses_learning_phase'):\n                    uses_learning_phase = (output._uses_learning_phase or\n                                           uses_learning_phase)\n                return output, []\n\n            _, outputs, _ = K.rnn(step, inputs,\n                                  initial_states=[],\n                                  input_length=input_shape[1],\n                                  unroll=False)\n            y = outputs\n        else:\n            # No batch size specified, therefore the layer will be able\n            # to process batches of any size.\n            # We can go with reshape-based implementation for performance.\n            input_length = input_shape[1]\n            if not input_length:\n                input_length = K.shape(inputs)[1]\n            # Shape: (num_samples * timesteps, ...). And track the\n            # transformation in self._input_map.\n            input_uid = _object_list_uid(inputs)\n            inputs = K.reshape(inputs, (-1,) + input_shape[2:])\n            self._input_map[input_uid] = inputs\n            # (num_samples * timesteps, ...)\n            y = self.layer.call(inputs, **kwargs)\n            if hasattr(y, '_uses_learning_phase'):\n                uses_learning_phase = y._uses_learning_phase\n            # Shape: (num_samples, timesteps, ...)\n            output_shape = self.compute_output_shape(input_shape)\n            y = K.reshape(y, (-1, input_length) + output_shape[2:])\n\n        # Apply activity regularizer if any:\n        if (hasattr(self.layer, 'activity_regularizer') and\n           self.layer.activity_regularizer is not None):\n            regularization_loss = self.layer.activity_regularizer(y)\n            self.add_loss(regularization_loss, inputs)\n\n        if uses_learning_phase:\n            y._uses_learning_phase = True\n        return y",
        "begin_line": 164,
        "end_line": 214,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.wrappers.TimeDistributed.step#173",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.TimeDistributed",
        "signature": "keras.layers.wrappers.TimeDistributed.step(x, _)",
        "snippet": "            def step(x, _):\n                global uses_learning_phase\n                output = self.layer.call(x, **kwargs)\n                if hasattr(output, '_uses_learning_phase'):\n                    uses_learning_phase = (output._uses_learning_phase or\n                                           uses_learning_phase)\n                return output, []",
        "begin_line": 173,
        "end_line": 179,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.wrappers.Bidirectional.__init__#244",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Bidirectional",
        "signature": "keras.layers.wrappers.Bidirectional.__init__(self, layer, merge_mode='concat', weights=None, **kwargs)",
        "snippet": "    def __init__(self, layer, merge_mode='concat', weights=None, **kwargs):\n        super(Bidirectional, self).__init__(layer, **kwargs)\n        if merge_mode not in ['sum', 'mul', 'ave', 'concat', None]:\n            raise ValueError('Invalid merge mode. '\n                             'Merge mode should be one of '\n                             '{\"sum\", \"mul\", \"ave\", \"concat\", None}')\n        self.forward_layer = copy.copy(layer)\n        config = layer.get_config()\n        config['go_backwards'] = not config['go_backwards']\n        self.backward_layer = layer.__class__.from_config(config)\n        self.forward_layer.name = 'forward_' + self.forward_layer.name\n        self.backward_layer.name = 'backward_' + self.backward_layer.name\n        self.merge_mode = merge_mode\n        if weights:\n            nw = len(weights)\n            self.forward_layer.initial_weights = weights[:nw // 2]\n            self.backward_layer.initial_weights = weights[nw // 2:]\n        self.stateful = layer.stateful\n        self.return_sequences = layer.return_sequences\n        self.supports_masking = True",
        "begin_line": 244,
        "end_line": 263,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.wrappers.Bidirectional.compute_output_shape#273",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Bidirectional",
        "signature": "keras.layers.wrappers.Bidirectional.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self.merge_mode in ['sum', 'ave', 'mul']:\n            return self.forward_layer.compute_output_shape(input_shape)\n        elif self.merge_mode == 'concat':\n            shape = list(self.forward_layer.compute_output_shape(input_shape))\n            shape[-1] *= 2\n            return tuple(shape)\n        elif self.merge_mode is None:\n            return [self.forward_layer.compute_output_shape(input_shape)] * 2",
        "begin_line": 273,
        "end_line": 281,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.wrappers.Bidirectional.call#283",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Bidirectional",
        "signature": "keras.layers.wrappers.Bidirectional.call(self, inputs, training=None, mask=None)",
        "snippet": "    def call(self, inputs, training=None, mask=None):\n        kwargs = {}\n        if has_arg(self.layer.call, 'training'):\n            kwargs['training'] = training\n        if has_arg(self.layer.call, 'mask'):\n            kwargs['mask'] = mask\n\n        y = self.forward_layer.call(inputs, **kwargs)\n        y_rev = self.backward_layer.call(inputs, **kwargs)\n        if self.return_sequences:\n            y_rev = K.reverse(y_rev, 1)\n        if self.merge_mode == 'concat':\n            output = K.concatenate([y, y_rev])\n        elif self.merge_mode == 'sum':\n            output = y + y_rev\n        elif self.merge_mode == 'ave':\n            output = (y + y_rev) / 2\n        elif self.merge_mode == 'mul':\n            output = y * y_rev\n        elif self.merge_mode is None:\n            output = [y, y_rev]\n\n        # Properly set learning phase\n        if 0 < self.layer.dropout + self.layer.recurrent_dropout:\n            if self.merge_mode is None:\n                for out in output:\n                    out._uses_learning_phase = True\n            else:\n                output._uses_learning_phase = True\n        return output",
        "begin_line": 283,
        "end_line": 312,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.wrappers.Bidirectional.build#318",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Bidirectional",
        "signature": "keras.layers.wrappers.Bidirectional.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        with K.name_scope(self.forward_layer.name):\n            self.forward_layer.build(input_shape)\n        with K.name_scope(self.backward_layer.name):\n            self.backward_layer.build(input_shape)\n        self.built = True",
        "begin_line": 318,
        "end_line": 323,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.wrappers.Bidirectional.compute_mask#325",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Bidirectional",
        "signature": "keras.layers.wrappers.Bidirectional.compute_mask(self, inputs, mask)",
        "snippet": "    def compute_mask(self, inputs, mask):\n        if self.return_sequences:\n            if not self.merge_mode:\n                return [mask, mask]\n            else:\n                return mask\n        else:\n            return None",
        "begin_line": 325,
        "end_line": 332,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.wrappers.Bidirectional.trainable_weights#335",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Bidirectional",
        "signature": "keras.layers.wrappers.Bidirectional.trainable_weights(self)",
        "snippet": "    def trainable_weights(self):\n        if hasattr(self.forward_layer, 'trainable_weights'):\n            return (self.forward_layer.trainable_weights +\n                    self.backward_layer.trainable_weights)\n        return []",
        "begin_line": 335,
        "end_line": 339,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.wrappers.Bidirectional.non_trainable_weights#342",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Bidirectional",
        "signature": "keras.layers.wrappers.Bidirectional.non_trainable_weights(self)",
        "snippet": "    def non_trainable_weights(self):\n        if hasattr(self.forward_layer, 'non_trainable_weights'):\n            return (self.forward_layer.non_trainable_weights +\n                    self.backward_layer.non_trainable_weights)\n        return []",
        "begin_line": 342,
        "end_line": 346,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.wrappers.Bidirectional.updates#349",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Bidirectional",
        "signature": "keras.layers.wrappers.Bidirectional.updates(self)",
        "snippet": "    def updates(self):\n        if hasattr(self.forward_layer, 'updates'):\n            return self.forward_layer.updates + self.backward_layer.updates\n        return []",
        "begin_line": 349,
        "end_line": 352,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.wrappers.Bidirectional.losses#355",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Bidirectional",
        "signature": "keras.layers.wrappers.Bidirectional.losses(self)",
        "snippet": "    def losses(self):\n        if hasattr(self.forward_layer, 'losses'):\n            return self.forward_layer.losses + self.backward_layer.losses\n        return []",
        "begin_line": 355,
        "end_line": 358,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.wrappers.Bidirectional.get_config#368",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Bidirectional",
        "signature": "keras.layers.wrappers.Bidirectional.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'merge_mode': self.merge_mode}\n        base_config = super(Bidirectional, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 368,
        "end_line": 371,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.applications.inception_v3.conv2d_bn#41",
        "src_path": "keras/applications/inception_v3.py",
        "class_name": "keras.applications.inception_v3",
        "signature": "keras.applications.inception_v3.conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1), name=None)",
        "snippet": "def conv2d_bn(x,\n              filters,\n              num_row,\n              num_col,\n              padding='same',\n              strides=(1, 1),\n              name=None):\n    \"\"\"Utility function to apply conv + BN.\n\n    # Arguments\n        x: input tensor.\n        filters: filters in `Conv2D`.\n        num_row: height of the convolution kernel.\n        num_col: width of the convolution kernel.\n        padding: padding mode in `Conv2D`.\n        strides: strides in `Conv2D`.\n        name: name of the ops; will become `name + '_conv'`\n            for the convolution and `name + '_bn'` for the\n            batch norm layer.\n\n    # Returns\n        Output tensor after applying `Conv2D` and `BatchNormalization`.\n    \"\"\"\n    if name is not None:\n        bn_name = name + '_bn'\n        conv_name = name + '_conv'\n    else:\n        bn_name = None\n        conv_name = None\n    if K.image_data_format() == 'channels_first':\n        bn_axis = 1\n    else:\n        bn_axis = 3\n    x = Conv2D(\n        filters, (num_row, num_col),\n        strides=strides,\n        padding=padding,\n        use_bias=False,\n        name=conv_name)(x)\n    x = BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n    x = Activation('relu', name=name)(x)\n    return x",
        "begin_line": 41,
        "end_line": 82,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.applications.inception_v3.InceptionV3#85",
        "src_path": "keras/applications/inception_v3.py",
        "class_name": "keras.applications.inception_v3",
        "signature": "keras.applications.inception_v3.InceptionV3(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)",
        "snippet": "def InceptionV3(include_top=True,\n                weights='imagenet',\n                input_tensor=None,\n                input_shape=None,\n                pooling=None,\n                classes=1000):\n    \"\"\"Instantiates the Inception v3 architecture.\n\n    Optionally loads weights pre-trained\n    on ImageNet. Note that when using TensorFlow,\n    for best performance you should set\n    `image_data_format='channels_last'` in your Keras config\n    at ~/.keras/keras.json.\n    The model and the weights are compatible with both\n    TensorFlow and Theano. The data format\n    convention used by the model is the one\n    specified in your Keras config file.\n    Note that the default input image size for this model is 299x299.\n\n    # Arguments\n        include_top: whether to include the fully-connected\n            layer at the top of the network.\n        weights: one of `None` (random initialization)\n            or 'imagenet' (pre-training on ImageNet).\n        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n            to use as image input for the model.\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(299, 299, 3)` (with `channels_last` data format)\n            or `(3, 299, 299)` (with `channels_first` data format).\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 139.\n            E.g. `(150, 150, 3)` would be one valid value.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model will be\n                the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a 2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n\n    # Returns\n        A Keras model instance.\n\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n    \"\"\"\n    if weights not in {'imagenet', None}:\n        raise ValueError('The `weights` argument should be either '\n                         '`None` (random initialization) or `imagenet` '\n                         '(pre-training on ImageNet).')\n\n    if weights == 'imagenet' and include_top and classes != 1000:\n        raise ValueError('If using `weights` as imagenet with `include_top`'\n                         ' as true, `classes` should be 1000')\n\n    # Determine proper input shape\n    input_shape = _obtain_input_shape(\n        input_shape,\n        default_size=299,\n        min_size=139,\n        data_format=K.image_data_format(),\n        require_flatten=False,\n        weights=weights)\n\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n\n    if K.image_data_format() == 'channels_first':\n        channel_axis = 1\n    else:\n        channel_axis = 3\n\n    x = conv2d_bn(img_input, 32, 3, 3, strides=(2, 2), padding='valid')\n    x = conv2d_bn(x, 32, 3, 3, padding='valid')\n    x = conv2d_bn(x, 64, 3, 3)\n    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n\n    x = conv2d_bn(x, 80, 1, 1, padding='valid')\n    x = conv2d_bn(x, 192, 3, 3, padding='valid')\n    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n\n    # mixed 0, 1, 2: 35 x 35 x 256\n    branch1x1 = conv2d_bn(x, 64, 1, 1)\n\n    branch5x5 = conv2d_bn(x, 48, 1, 1)\n    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n\n    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n\n    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n    branch_pool = conv2d_bn(branch_pool, 32, 1, 1)\n    x = layers.concatenate(\n        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n        axis=channel_axis,\n        name='mixed0')\n\n    # mixed 1: 35 x 35 x 256\n    branch1x1 = conv2d_bn(x, 64, 1, 1)\n\n    branch5x5 = conv2d_bn(x, 48, 1, 1)\n    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n\n    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n\n    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n    branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n    x = layers.concatenate(\n        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n        axis=channel_axis,\n        name='mixed1')\n\n    # mixed 2: 35 x 35 x 256\n    branch1x1 = conv2d_bn(x, 64, 1, 1)\n\n    branch5x5 = conv2d_bn(x, 48, 1, 1)\n    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n\n    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n\n    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n    branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n    x = layers.concatenate(\n        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n        axis=channel_axis,\n        name='mixed2')\n\n    # mixed 3: 17 x 17 x 768\n    branch3x3 = conv2d_bn(x, 384, 3, 3, strides=(2, 2), padding='valid')\n\n    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n    branch3x3dbl = conv2d_bn(\n        branch3x3dbl, 96, 3, 3, strides=(2, 2), padding='valid')\n\n    branch_pool = MaxPooling2D((3, 3), strides=(2, 2))(x)\n    x = layers.concatenate(\n        [branch3x3, branch3x3dbl, branch_pool], axis=channel_axis, name='mixed3')\n\n    # mixed 4: 17 x 17 x 768\n    branch1x1 = conv2d_bn(x, 192, 1, 1)\n\n    branch7x7 = conv2d_bn(x, 128, 1, 1)\n    branch7x7 = conv2d_bn(branch7x7, 128, 1, 7)\n    branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n\n    branch7x7dbl = conv2d_bn(x, 128, 1, 1)\n    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 1, 7)\n    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n\n    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n    branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n    x = layers.concatenate(\n        [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n        axis=channel_axis,\n        name='mixed4')\n\n    # mixed 5, 6: 17 x 17 x 768\n    for i in range(2):\n        branch1x1 = conv2d_bn(x, 192, 1, 1)\n\n        branch7x7 = conv2d_bn(x, 160, 1, 1)\n        branch7x7 = conv2d_bn(branch7x7, 160, 1, 7)\n        branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n\n        branch7x7dbl = conv2d_bn(x, 160, 1, 1)\n        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 1, 7)\n        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n        branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n\n        branch_pool = AveragePooling2D(\n            (3, 3), strides=(1, 1), padding='same')(x)\n        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n        x = layers.concatenate(\n            [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n            axis=channel_axis,\n            name='mixed' + str(5 + i))\n\n    # mixed 7: 17 x 17 x 768\n    branch1x1 = conv2d_bn(x, 192, 1, 1)\n\n    branch7x7 = conv2d_bn(x, 192, 1, 1)\n    branch7x7 = conv2d_bn(branch7x7, 192, 1, 7)\n    branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n\n    branch7x7dbl = conv2d_bn(x, 192, 1, 1)\n    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n\n    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n    branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n    x = layers.concatenate(\n        [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n        axis=channel_axis,\n        name='mixed7')\n\n    # mixed 8: 8 x 8 x 1280\n    branch3x3 = conv2d_bn(x, 192, 1, 1)\n    branch3x3 = conv2d_bn(branch3x3, 320, 3, 3,\n                          strides=(2, 2), padding='valid')\n\n    branch7x7x3 = conv2d_bn(x, 192, 1, 1)\n    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 1, 7)\n    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 7, 1)\n    branch7x7x3 = conv2d_bn(\n        branch7x7x3, 192, 3, 3, strides=(2, 2), padding='valid')\n\n    branch_pool = MaxPooling2D((3, 3), strides=(2, 2))(x)\n    x = layers.concatenate(\n        [branch3x3, branch7x7x3, branch_pool], axis=channel_axis, name='mixed8')\n\n    # mixed 9: 8 x 8 x 2048\n    for i in range(2):\n        branch1x1 = conv2d_bn(x, 320, 1, 1)\n\n        branch3x3 = conv2d_bn(x, 384, 1, 1)\n        branch3x3_1 = conv2d_bn(branch3x3, 384, 1, 3)\n        branch3x3_2 = conv2d_bn(branch3x3, 384, 3, 1)\n        branch3x3 = layers.concatenate(\n            [branch3x3_1, branch3x3_2], axis=channel_axis, name='mixed9_' + str(i))\n\n        branch3x3dbl = conv2d_bn(x, 448, 1, 1)\n        branch3x3dbl = conv2d_bn(branch3x3dbl, 384, 3, 3)\n        branch3x3dbl_1 = conv2d_bn(branch3x3dbl, 384, 1, 3)\n        branch3x3dbl_2 = conv2d_bn(branch3x3dbl, 384, 3, 1)\n        branch3x3dbl = layers.concatenate(\n            [branch3x3dbl_1, branch3x3dbl_2], axis=channel_axis)\n\n        branch_pool = AveragePooling2D(\n            (3, 3), strides=(1, 1), padding='same')(x)\n        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n        x = layers.concatenate(\n            [branch1x1, branch3x3, branch3x3dbl, branch_pool],\n            axis=channel_axis,\n            name='mixed' + str(9 + i))\n    if include_top:\n        # Classification block\n        x = GlobalAveragePooling2D(name='avg_pool')(x)\n        x = Dense(classes, activation='softmax', name='predictions')(x)\n    else:\n        if pooling == 'avg':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling == 'max':\n            x = GlobalMaxPooling2D()(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n    # Create model.\n    model = Model(inputs, x, name='inception_v3')\n\n    # load weights\n    if weights == 'imagenet':\n        if K.image_data_format() == 'channels_first':\n            if K.backend() == 'tensorflow':\n                warnings.warn('You are using the TensorFlow backend, yet you '\n                              'are using the Theano '\n                              'image data format convention '\n                              '(`image_data_format=\"channels_first\"`). '\n                              'For best performance, set '\n                              '`image_data_format=\"channels_last\"` in '\n                              'your Keras config '\n                              'at ~/.keras/keras.json.')\n        if include_top:\n            weights_path = get_file(\n                'inception_v3_weights_tf_dim_ordering_tf_kernels.h5',\n                WEIGHTS_PATH,\n                cache_subdir='models',\n                file_hash='9a0d58056eeedaa3f26cb7ebd46da564')\n        else:\n            weights_path = get_file(\n                'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5',\n                WEIGHTS_PATH_NO_TOP,\n                cache_subdir='models',\n                file_hash='bcbd6486424b2319ff4ef7d526e38f63')\n        model.load_weights(weights_path)\n    return model",
        "begin_line": 85,
        "end_line": 388,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.io_utils.HDF5Matrix.__init__#43",
        "src_path": "keras/utils/io_utils.py",
        "class_name": "keras.utils.io_utils.HDF5Matrix",
        "signature": "keras.utils.io_utils.HDF5Matrix.__init__(self, datapath, dataset, start=0, end=None, normalizer=None)",
        "snippet": "    def __init__(self, datapath, dataset, start=0, end=None, normalizer=None):\n        if h5py is None:\n            raise ImportError('The use of HDF5Matrix requires '\n                              'HDF5 and h5py installed.')\n\n        if datapath not in list(self.refs.keys()):\n            f = h5py.File(datapath)\n            self.refs[datapath] = f\n        else:\n            f = self.refs[datapath]\n        self.data = f[dataset]\n        self.start = start\n        if end is None:\n            self.end = self.data.shape[0]\n        else:\n            self.end = end\n        self.normalizer = normalizer",
        "begin_line": 43,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.io_utils.HDF5Matrix.__len__#61",
        "src_path": "keras/utils/io_utils.py",
        "class_name": "keras.utils.io_utils.HDF5Matrix",
        "signature": "keras.utils.io_utils.HDF5Matrix.__len__(self)",
        "snippet": "    def __len__(self):\n        return self.end - self.start",
        "begin_line": 61,
        "end_line": 62,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.io_utils.HDF5Matrix.__getitem__#64",
        "src_path": "keras/utils/io_utils.py",
        "class_name": "keras.utils.io_utils.HDF5Matrix",
        "signature": "keras.utils.io_utils.HDF5Matrix.__getitem__(self, key)",
        "snippet": "    def __getitem__(self, key):\n        if isinstance(key, slice):\n            start, stop = key.start, key.stop\n            if start is None:\n                start = 0\n            if stop is None:\n                stop = self.shape[0]\n            if stop + self.start <= self.end:\n                idx = slice(start + self.start, stop + self.start)\n            else:\n                raise IndexError\n        elif isinstance(key, (int, np.integer)):\n            if key + self.start < self.end:\n                idx = key + self.start\n            else:\n                raise IndexError\n        elif isinstance(key, np.ndarray):\n            if np.max(key) + self.start < self.end:\n                idx = (self.start + key).tolist()\n            else:\n                raise IndexError\n        elif isinstance(key, list):\n            if max(key) + self.start < self.end:\n                idx = [x + self.start for x in key]\n            else:\n                raise IndexError\n        else:\n            raise IndexError\n        if self.normalizer is not None:\n            return self.normalizer(self.data[idx])\n        else:\n            return self.data[idx]",
        "begin_line": 64,
        "end_line": 95,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.io_utils.HDF5Matrix.shape#98",
        "src_path": "keras/utils/io_utils.py",
        "class_name": "keras.utils.io_utils.HDF5Matrix",
        "signature": "keras.utils.io_utils.HDF5Matrix.shape(self)",
        "snippet": "    def shape(self):\n        \"\"\"Gets a numpy-style shape tuple giving the dataset dimensions.\n\n        # Returns\n            A numpy-style shape tuple.\n        \"\"\"\n        return (self.end - self.start,) + self.data.shape[1:]",
        "begin_line": 98,
        "end_line": 104,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.io_utils.HDF5Matrix.dtype#107",
        "src_path": "keras/utils/io_utils.py",
        "class_name": "keras.utils.io_utils.HDF5Matrix",
        "signature": "keras.utils.io_utils.HDF5Matrix.dtype(self)",
        "snippet": "    def dtype(self):\n        \"\"\"Gets the datatype of the dataset.\n\n        # Returns\n            A numpy dtype string.\n        \"\"\"\n        return self.data.dtype",
        "begin_line": 107,
        "end_line": 113,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.io_utils.HDF5Matrix.ndim#116",
        "src_path": "keras/utils/io_utils.py",
        "class_name": "keras.utils.io_utils.HDF5Matrix",
        "signature": "keras.utils.io_utils.HDF5Matrix.ndim(self)",
        "snippet": "    def ndim(self):\n        \"\"\"Gets the number of dimensions (rank) of the dataset.\n\n        # Returns\n            An integer denoting the number of dimensions (rank) of the dataset.\n        \"\"\"\n        return self.data.ndim",
        "begin_line": 116,
        "end_line": 122,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.io_utils.HDF5Matrix.size#125",
        "src_path": "keras/utils/io_utils.py",
        "class_name": "keras.utils.io_utils.HDF5Matrix",
        "signature": "keras.utils.io_utils.HDF5Matrix.size(self)",
        "snippet": "    def size(self):\n        \"\"\"Gets the total dataset size (number of elements).\n\n        # Returns\n            An integer denoting the number of elements in the dataset.\n        \"\"\"\n        return np.prod(self.shape)",
        "begin_line": 125,
        "end_line": 131,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.layer_utils.count_params#8",
        "src_path": "keras/utils/layer_utils.py",
        "class_name": "keras.utils.layer_utils",
        "signature": "keras.utils.layer_utils.count_params(weights)",
        "snippet": "def count_params(weights):\n    \"\"\"Count the total number of scalars composing the weights.\n\n    # Arguments\n        weights: An iterable containing the weights on which to compute params\n\n    # Returns\n        The total number of scalars composing the weights\n    \"\"\"\n    return int(np.sum([K.count_params(p) for p in set(weights)]))",
        "begin_line": 8,
        "end_line": 17,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00078064012490242,
            "pseudo_dstar_susp": 0.0026109660574412533,
            "pseudo_tarantula_susp": 0.0007331378299120235,
            "pseudo_op2_susp": 0.0026109660574412533,
            "pseudo_barinel_susp": 0.0007331378299120235
        }
    },
    {
        "name": "keras.utils.layer_utils.print_summary#20",
        "src_path": "keras/utils/layer_utils.py",
        "class_name": "keras.utils.layer_utils",
        "signature": "keras.utils.layer_utils.print_summary(model, line_length=None, positions=None, print_fn=print)",
        "snippet": "def print_summary(model, line_length=None, positions=None, print_fn=print):\n    \"\"\"Prints a summary of a model.\n\n    # Arguments\n        model: Keras model instance.\n        line_length: Total length of printed lines\n            (e.g. set this to adapt the display to different\n            terminal window sizes).\n        positions: Relative or absolute positions of log elements in each line.\n            If not provided, defaults to `[.33, .55, .67, 1.]`.\n        print_fn: Print function to use.\n            It will be called on each line of the summary.\n            You can set it to a custom function\n            in order to capture the string summary.\n    \"\"\"\n    if model.__class__.__name__ == 'Sequential':\n        sequential_like = True\n    else:\n        sequential_like = True\n        nodes_by_depth = model.nodes_by_depth.values()\n        nodes = []\n        for v in nodes_by_depth:\n            if (len(v) > 1) or (len(v) == 1 and len(v[0].inbound_layers) > 1):\n                # if the model has multiple nodes or if the nodes have multiple inbound_layers\n                # the model is no longer sequential\n                sequential_like = False\n                break\n            nodes += v\n        if sequential_like:\n            # search for shared layers\n            for layer in model.layers:\n                flag = False\n                for node in layer.inbound_nodes:\n                    if node in nodes:\n                        if flag:\n                            sequential_like = False\n                            break\n                        else:\n                            flag = True\n                if not sequential_like:\n                    break\n\n    if sequential_like:\n        line_length = line_length or 65\n        positions = positions or [.45, .85, 1.]\n        if positions[-1] <= 1:\n            positions = [int(line_length * p) for p in positions]\n        # header names for the different log elements\n        to_display = ['Layer (type)', 'Output Shape', 'Param #']\n    else:\n        line_length = line_length or 98\n        positions = positions or [.33, .55, .67, 1.]\n        if positions[-1] <= 1:\n            positions = [int(line_length * p) for p in positions]\n        # header names for the different log elements\n        to_display = ['Layer (type)', 'Output Shape', 'Param #', 'Connected to']\n        relevant_nodes = []\n        for v in model.nodes_by_depth.values():\n            relevant_nodes += v\n\n    def print_row(fields, positions):\n        line = ''\n        for i in range(len(fields)):\n            if i > 0:\n                line = line[:-1] + ' '\n            line += str(fields[i])\n            line = line[:positions[i]]\n            line += ' ' * (positions[i] - len(line))\n        print_fn(line)\n\n    print_fn('_' * line_length)\n    print_row(to_display, positions)\n    print_fn('=' * line_length)\n\n    def print_layer_summary(layer):\n        try:\n            output_shape = layer.output_shape\n        except AttributeError:\n            output_shape = 'multiple'\n        name = layer.name\n        cls_name = layer.__class__.__name__\n        fields = [name + ' (' + cls_name + ')', output_shape, layer.count_params()]\n        print_row(fields, positions)\n\n    def print_layer_summary_with_connections(layer):\n        \"\"\"Prints a summary for a single layer.\n\n        # Arguments\n            layer: target layer.\n        \"\"\"\n        try:\n            output_shape = layer.output_shape\n        except AttributeError:\n            output_shape = 'multiple'\n        connections = []\n        for node in layer.inbound_nodes:\n            if relevant_nodes and node not in relevant_nodes:\n                # node is not part of the current network\n                continue\n            for i in range(len(node.inbound_layers)):\n                inbound_layer = node.inbound_layers[i].name\n                inbound_node_index = node.node_indices[i]\n                inbound_tensor_index = node.tensor_indices[i]\n                connections.append(inbound_layer + '[' + str(inbound_node_index) + '][' + str(inbound_tensor_index) + ']')\n\n        name = layer.name\n        cls_name = layer.__class__.__name__\n        if not connections:\n            first_connection = ''\n        else:\n            first_connection = connections[0]\n        fields = [name + ' (' + cls_name + ')', output_shape, layer.count_params(), first_connection]\n        print_row(fields, positions)\n        if len(connections) > 1:\n            for i in range(1, len(connections)):\n                fields = ['', '', '', connections[i]]\n                print_row(fields, positions)\n\n    layers = model.layers\n    for i in range(len(layers)):\n        if sequential_like:\n            print_layer_summary(layers[i])\n        else:\n            print_layer_summary_with_connections(layers[i])\n        if i == len(layers) - 1:\n            print_fn('=' * line_length)\n        else:\n            print_fn('_' * line_length)\n\n    model._check_trainable_weights_consistency()\n    if hasattr(model, '_collected_trainable_weights'):\n        trainable_count = count_params(model._collected_trainable_weights)\n    else:\n        trainable_count = count_params(model.trainable_weights)\n\n    non_trainable_count = int(\n        np.sum([K.count_params(p) for p in set(model.non_trainable_weights)]))\n\n    print_fn('Total params: {:,}'.format(trainable_count + non_trainable_count))\n    print_fn('Trainable params: {:,}'.format(trainable_count))\n    print_fn('Non-trainable params: {:,}'.format(non_trainable_count))\n    print_fn('_' * line_length)",
        "begin_line": 20,
        "end_line": 161,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02127659574468085,
            "pseudo_dstar_susp": 0.0029239766081871343,
            "pseudo_tarantula_susp": 0.00847457627118644,
            "pseudo_op2_susp": 0.0029239766081871343,
            "pseudo_barinel_susp": 0.00847457627118644
        }
    },
    {
        "name": "keras.utils.layer_utils.print_row#80",
        "src_path": "keras/utils/layer_utils.py",
        "class_name": "keras.utils.layer_utils",
        "signature": "keras.utils.layer_utils.print_row(fields, positions)",
        "snippet": "    def print_row(fields, positions):\n        line = ''\n        for i in range(len(fields)):\n            if i > 0:\n                line = line[:-1] + ' '\n            line += str(fields[i])\n            line = line[:positions[i]]\n            line += ' ' * (positions[i] - len(line))\n        print_fn(line)",
        "begin_line": 80,
        "end_line": 88,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002793296089385475,
            "pseudo_dstar_susp": 0.0027548209366391185,
            "pseudo_tarantula_susp": 0.0022172949002217295,
            "pseudo_op2_susp": 0.0027548209366391185,
            "pseudo_barinel_susp": 0.0022172949002217295
        }
    },
    {
        "name": "keras.utils.layer_utils.print_layer_summary#94",
        "src_path": "keras/utils/layer_utils.py",
        "class_name": "keras.utils.layer_utils",
        "signature": "keras.utils.layer_utils.print_layer_summary(layer)",
        "snippet": "    def print_layer_summary(layer):\n        try:\n            output_shape = layer.output_shape\n        except AttributeError:\n            output_shape = 'multiple'\n        name = layer.name\n        cls_name = layer.__class__.__name__\n        fields = [name + ' (' + cls_name + ')', output_shape, layer.count_params()]\n        print_row(fields, positions)",
        "begin_line": 94,
        "end_line": 102,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009578544061302681,
            "pseudo_dstar_susp": 0.0009285051067780873,
            "pseudo_tarantula_susp": 0.001282051282051282,
            "pseudo_op2_susp": 0.0009285051067780873,
            "pseudo_barinel_susp": 0.001282051282051282
        }
    },
    {
        "name": "keras.utils.layer_utils.print_layer_summary_with_connections#104",
        "src_path": "keras/utils/layer_utils.py",
        "class_name": "keras.utils.layer_utils",
        "signature": "keras.utils.layer_utils.print_layer_summary_with_connections(layer)",
        "snippet": "    def print_layer_summary_with_connections(layer):\n        \"\"\"Prints a summary for a single layer.\n\n        # Arguments\n            layer: target layer.\n        \"\"\"\n        try:\n            output_shape = layer.output_shape\n        except AttributeError:\n            output_shape = 'multiple'\n        connections = []\n        for node in layer.inbound_nodes:\n            if relevant_nodes and node not in relevant_nodes:\n                # node is not part of the current network\n                continue\n            for i in range(len(node.inbound_layers)):\n                inbound_layer = node.inbound_layers[i].name\n                inbound_node_index = node.node_indices[i]\n                inbound_tensor_index = node.tensor_indices[i]\n                connections.append(inbound_layer + '[' + str(inbound_node_index) + '][' + str(inbound_tensor_index) + ']')\n\n        name = layer.name\n        cls_name = layer.__class__.__name__\n        if not connections:\n            first_connection = ''\n        else:\n            first_connection = connections[0]\n        fields = [name + ' (' + cls_name + ')', output_shape, layer.count_params(), first_connection]\n        print_row(fields, positions)\n        if len(connections) > 1:\n            for i in range(1, len(connections)):\n                fields = ['', '', '', connections[i]]\n                print_row(fields, positions)",
        "begin_line": 104,
        "end_line": 136,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02127659574468085,
            "pseudo_dstar_susp": 0.002857142857142857,
            "pseudo_tarantula_susp": 0.023255813953488372,
            "pseudo_op2_susp": 0.002857142857142857,
            "pseudo_barinel_susp": 0.023255813953488372
        }
    },
    {
        "name": "keras.utils.layer_utils.convert_all_kernels_in_model#164",
        "src_path": "keras/utils/layer_utils.py",
        "class_name": "keras.utils.layer_utils",
        "signature": "keras.utils.layer_utils.convert_all_kernels_in_model(model)",
        "snippet": "def convert_all_kernels_in_model(model):\n    \"\"\"Converts all convolution kernels in a model from Theano to TensorFlow.\n\n    Also works from TensorFlow to Theano.\n\n    # Arguments\n        model: target model for the conversion.\n    \"\"\"\n    # Note: SeparableConvolution not included\n    # since only supported by TF.\n    conv_classes = {\n        'Conv1D',\n        'Conv2D',\n        'Conv3D',\n        'Conv2DTranspose',\n    }\n    to_assign = []\n    for layer in model.layers:\n        if layer.__class__.__name__ in conv_classes:\n            original_kernel = K.get_value(layer.kernel)\n            converted_kernel = convert_kernel(original_kernel)\n            to_assign.append((layer.kernel, converted_kernel))\n    K.batch_set_value(to_assign)",
        "begin_line": 164,
        "end_line": 186,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.layer_utils.convert_dense_weights_data_format#189",
        "src_path": "keras/utils/layer_utils.py",
        "class_name": "keras.utils.layer_utils",
        "signature": "keras.utils.layer_utils.convert_dense_weights_data_format(dense, previous_feature_map_shape, target_data_format='channels_first')",
        "snippet": "def convert_dense_weights_data_format(dense,\n                                      previous_feature_map_shape,\n                                      target_data_format='channels_first'):\n    \"\"\"Utility useful when changing a convnet's `data_format`.\n\n    When porting the weights of a convnet from one data format to the other,\n    if the convnet includes a `Flatten` layer\n    (applied to the last convolutional feature map)\n    followed by a `Dense` layer, the weights of that `Dense` layer\n    should be updated to reflect the new dimension ordering.\n\n    # Arguments\n        dense: The target `Dense` layer.\n        previous_feature_map_shape: A shape tuple of 3 integers,\n            e.g. `(512, 7, 7)`. The shape of the convolutional\n            feature map right before the `Flatten` layer that\n            came before the target `Dense` layer.\n        target_data_format: One of \"channels_last\", \"channels_first\".\n            Set it \"channels_last\"\n            if converting a \"channels_first\" model to \"channels_last\",\n            or reciprocally.\n    \"\"\"\n    assert target_data_format in {'channels_last', 'channels_first'}\n    kernel, bias = dense.get_weights()\n    for i in range(kernel.shape[1]):\n        if target_data_format == 'channels_first':\n            c, h, w = previous_feature_map_shape\n            original_fm_shape = (h, w, c)\n            ki = kernel[:, i].reshape(original_fm_shape)\n            ki = np.transpose(ki, (2, 0, 1))  # last -> first\n        else:\n            h, w, c = previous_feature_map_shape\n            original_fm_shape = (c, h, w)\n            ki = kernel[:, i].reshape(original_fm_shape)\n            ki = np.transpose(ki, (1, 2, 0))  # first -> last\n        kernel[:, i] = np.reshape(ki, (np.prod(previous_feature_map_shape),))\n    dense.set_weights([kernel, bias])",
        "begin_line": 189,
        "end_line": 225,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.__init__.backend#88",
        "src_path": "keras/backend/__init__.py",
        "class_name": "keras.backend.__init__",
        "signature": "keras.backend.__init__.backend()",
        "snippet": "def backend():\n    \"\"\"Publicly accessible method\n    for determining the current backend.\n\n    # Returns\n        String, the name of the backend Keras is currently using.\n\n    # Example\n    ```python\n        >>> keras.backend.backend()\n        'tensorflow'\n    ```\n    \"\"\"\n    return _BACKEND",
        "begin_line": 88,
        "end_line": 101,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0034482758620689655,
            "pseudo_dstar_susp": 0.047619047619047616,
            "pseudo_tarantula_susp": 0.001199040767386091,
            "pseudo_op2_susp": 0.047619047619047616,
            "pseudo_barinel_susp": 0.001199040767386091
        }
    },
    {
        "name": "keras.losses.mean_squared_error#8",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.mean_squared_error(y_true, y_pred)",
        "snippet": "def mean_squared_error(y_true, y_pred):\n    return K.mean(K.square(y_pred - y_true), axis=-1)",
        "begin_line": 8,
        "end_line": 9,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.048136083966703e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.losses.mean_absolute_error#12",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.mean_absolute_error(y_true, y_pred)",
        "snippet": "def mean_absolute_error(y_true, y_pred):\n    return K.mean(K.abs(y_pred - y_true), axis=-1)",
        "begin_line": 12,
        "end_line": 13,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011301989150090416,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.losses.mean_absolute_percentage_error#16",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.mean_absolute_percentage_error(y_true, y_pred)",
        "snippet": "def mean_absolute_percentage_error(y_true, y_pred):\n    diff = K.abs((y_true - y_pred) / K.clip(K.abs(y_true),\n                                            K.epsilon(),\n                                            None))\n    return 100. * K.mean(diff, axis=-1)",
        "begin_line": 16,
        "end_line": 20,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.losses.mean_squared_logarithmic_error#23",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.mean_squared_logarithmic_error(y_true, y_pred)",
        "snippet": "def mean_squared_logarithmic_error(y_true, y_pred):\n    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n    return K.mean(K.square(first_log - second_log), axis=-1)",
        "begin_line": 23,
        "end_line": 26,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.losses.squared_hinge#29",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.squared_hinge(y_true, y_pred)",
        "snippet": "def squared_hinge(y_true, y_pred):\n    return K.mean(K.square(K.maximum(1. - y_true * y_pred, 0.)), axis=-1)",
        "begin_line": 29,
        "end_line": 30,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.losses.hinge#33",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.hinge(y_true, y_pred)",
        "snippet": "def hinge(y_true, y_pred):\n    return K.mean(K.maximum(1. - y_true * y_pred, 0.), axis=-1)",
        "begin_line": 33,
        "end_line": 34,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.losses.categorical_hinge#37",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.categorical_hinge(y_true, y_pred)",
        "snippet": "def categorical_hinge(y_true, y_pred):\n    pos = K.sum(y_true * y_pred, axis=-1)\n    neg = K.max((1. - y_true) * y_pred, axis=-1)\n    return K.maximum(0., neg - pos + 1.)",
        "begin_line": 37,
        "end_line": 40,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.losses.logcosh#43",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.logcosh(y_true, y_pred)",
        "snippet": "def logcosh(y_true, y_pred):\n    def cosh(x):\n        return (K.exp(x) + K.exp(-x)) / 2\n    return K.mean(K.log(cosh(y_pred - y_true)), axis=-1)",
        "begin_line": 43,
        "end_line": 46,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.losses.cosh#44",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.cosh(x)",
        "snippet": "    def cosh(x):\n        return (K.exp(x) + K.exp(-x)) / 2",
        "begin_line": 44,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.losses.categorical_crossentropy#49",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.categorical_crossentropy(y_true, y_pred)",
        "snippet": "def categorical_crossentropy(y_true, y_pred):\n    return K.categorical_crossentropy(y_true, y_pred)",
        "begin_line": 49,
        "end_line": 50,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.502090459901178e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.losses.sparse_categorical_crossentropy#53",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.sparse_categorical_crossentropy(y_true, y_pred)",
        "snippet": "def sparse_categorical_crossentropy(y_true, y_pred):\n    return K.sparse_categorical_crossentropy(y_true, y_pred)",
        "begin_line": 53,
        "end_line": 54,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00012818869375721061,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.losses.binary_crossentropy#57",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.binary_crossentropy(y_true, y_pred)",
        "snippet": "def binary_crossentropy(y_true, y_pred):\n    return K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1)",
        "begin_line": 57,
        "end_line": 58,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.losses.kullback_leibler_divergence#61",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.kullback_leibler_divergence(y_true, y_pred)",
        "snippet": "def kullback_leibler_divergence(y_true, y_pred):\n    y_true = K.clip(y_true, K.epsilon(), 1)\n    y_pred = K.clip(y_pred, K.epsilon(), 1)\n    return K.sum(y_true * K.log(y_true / y_pred), axis=-1)",
        "begin_line": 61,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.losses.poisson#67",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.poisson(y_true, y_pred)",
        "snippet": "def poisson(y_true, y_pred):\n    return K.mean(y_pred - y_true * K.log(y_pred + K.epsilon()), axis=-1)",
        "begin_line": 67,
        "end_line": 68,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.losses.cosine_proximity#71",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.cosine_proximity(y_true, y_pred)",
        "snippet": "def cosine_proximity(y_true, y_pred):\n    y_true = K.l2_normalize(y_true, axis=-1)\n    y_pred = K.l2_normalize(y_pred, axis=-1)\n    return -K.sum(y_true * y_pred, axis=-1)",
        "begin_line": 71,
        "end_line": 74,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.losses.deserialize#91",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.deserialize(name, custom_objects=None)",
        "snippet": "def deserialize(name, custom_objects=None):\n    return deserialize_keras_object(name,\n                                    module_objects=globals(),\n                                    custom_objects=custom_objects,\n                                    printable_module_name='loss function')",
        "begin_line": 91,
        "end_line": 95,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 8.818342151675486e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.losses.get#98",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.get(identifier)",
        "snippet": "def get(identifier):\n    if identifier is None:\n        return None\n    if isinstance(identifier, six.string_types):\n        identifier = str(identifier)\n        return deserialize(identifier)\n    elif callable(identifier):\n        return identifier\n    else:\n        raise ValueError('Could not interpret '\n                         'loss function identifier:', identifier)",
        "begin_line": 98,
        "end_line": 108,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.text.text_to_word_sequence#25",
        "src_path": "keras/preprocessing/text.py",
        "class_name": "keras.preprocessing.text",
        "signature": "keras.preprocessing.text.text_to_word_sequence(text, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ')",
        "snippet": "def text_to_word_sequence(text,\n                          filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n                          lower=True, split=\" \"):\n    \"\"\"Converts a text to a sequence of words (or tokens).\n\n    # Arguments\n        text: Input text (string).\n        filters: Sequence of characters to filter out.\n        lower: Whether to convert the input to lowercase.\n        split: Sentence split marker (string).\n\n    # Returns\n        A list of words (or tokens).\n    \"\"\"\n    if lower:\n        text = text.lower()\n\n    if sys.version_info < (3,) and isinstance(text, unicode):\n        translate_map = dict((ord(c), unicode(split)) for c in filters)\n    else:\n        translate_map = maketrans(filters, split * len(filters))\n\n    text = text.translate(translate_map)\n    seq = text.split(split)\n    return [i for i in seq if i]",
        "begin_line": 25,
        "end_line": 49,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.text.one_hot#52",
        "src_path": "keras/preprocessing/text.py",
        "class_name": "keras.preprocessing.text",
        "signature": "keras.preprocessing.text.one_hot(text, n, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ')",
        "snippet": "def one_hot(text, n,\n            filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n            lower=True,\n            split=' '):\n    \"\"\"One-hot encodes a text into a list of word indexes of size n.\n\n    This is a wrapper to the `hashing_trick` function using `hash` as the\n    hashing function, unicity of word to index mapping non-guaranteed.\n    \"\"\"\n    return hashing_trick(text, n,\n                         hash_function=hash,\n                         filters=filters,\n                         lower=lower,\n                         split=split)",
        "begin_line": 52,
        "end_line": 65,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.text.hashing_trick#68",
        "src_path": "keras/preprocessing/text.py",
        "class_name": "keras.preprocessing.text",
        "signature": "keras.preprocessing.text.hashing_trick(text, n, hash_function=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ')",
        "snippet": "def hashing_trick(text, n,\n                  hash_function=None,\n                  filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n                  lower=True,\n                  split=' '):\n    \"\"\"Converts a text to a sequence of indexes in a fixed-size hashing space.\n\n    # Arguments\n        text: Input text (string).\n        n: Dimension of the hashing space.\n        hash_function: if `None` uses python `hash` function, can be 'md5' or\n            any function that takes in input a string and returns a int.\n            Note that `hash` is not a stable hashing function, so\n            it is not consistent across different runs, while 'md5'\n            is a stable hashing function.\n        filters: Sequence of characters to filter out.\n        lower: Whether to convert the input to lowercase.\n        split: Sentence split marker (string).\n\n    # Returns\n        A list of integer word indices (unicity non-guaranteed).\n\n    `0` is a reserved index that won't be assigned to any word.\n\n    Two or more words may be assigned to the same index, due to possible\n    collisions by the hashing function.\n    The [probability](https://en.wikipedia.org/wiki/Birthday_problem#Probability_table)\n    of a collision is in relation to the dimension of the hashing space and\n    the number of distinct objects.\n    \"\"\"\n    if hash_function is None:\n        hash_function = hash\n    elif hash_function == 'md5':\n        hash_function = lambda w: int(md5(w.encode()).hexdigest(), 16)\n\n    seq = text_to_word_sequence(text,\n                                filters=filters,\n                                lower=lower,\n                                split=split)\n    return [(hash_function(w) % (n - 1) + 1) for w in seq]",
        "begin_line": 68,
        "end_line": 107,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.text.Tokenizer.__init__#137",
        "src_path": "keras/preprocessing/text.py",
        "class_name": "keras.preprocessing.text.Tokenizer",
        "signature": "keras.preprocessing.text.Tokenizer.__init__(self, num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, **kwargs)",
        "snippet": "    def __init__(self, num_words=None,\n                 filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n                 lower=True,\n                 split=' ',\n                 char_level=False,\n                 **kwargs):\n        # Legacy support\n        if 'nb_words' in kwargs:\n            warnings.warn('The `nb_words` argument in `Tokenizer` '\n                          'has been renamed `num_words`.')\n            num_words = kwargs.pop('nb_words')\n        if kwargs:\n            raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\n\n        self.word_counts = OrderedDict()\n        self.word_docs = {}\n        self.filters = filters\n        self.split = split\n        self.lower = lower\n        self.num_words = num_words\n        self.document_count = 0\n        self.char_level = char_level",
        "begin_line": 137,
        "end_line": 158,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.text.Tokenizer.fit_on_texts#160",
        "src_path": "keras/preprocessing/text.py",
        "class_name": "keras.preprocessing.text.Tokenizer",
        "signature": "keras.preprocessing.text.Tokenizer.fit_on_texts(self, texts)",
        "snippet": "    def fit_on_texts(self, texts):\n        \"\"\"Updates internal vocabulary based on a list of texts.\n\n        Required before using `texts_to_sequences` or `texts_to_matrix`.\n\n        # Arguments\n            texts: can be a list of strings,\n                or a generator of strings (for memory-efficiency)\n        \"\"\"\n        self.document_count = 0\n        for text in texts:\n            self.document_count += 1\n            seq = text if self.char_level else text_to_word_sequence(text,\n                                                                     self.filters,\n                                                                     self.lower,\n                                                                     self.split)\n            for w in seq:\n                if w in self.word_counts:\n                    self.word_counts[w] += 1\n                else:\n                    self.word_counts[w] = 1\n            for w in set(seq):\n                if w in self.word_docs:\n                    self.word_docs[w] += 1\n                else:\n                    self.word_docs[w] = 1\n\n        wcounts = list(self.word_counts.items())\n        wcounts.sort(key=lambda x: x[1], reverse=True)\n        sorted_voc = [wc[0] for wc in wcounts]\n        # note that index 0 is reserved, never assigned to an existing word\n        self.word_index = dict(list(zip(sorted_voc, list(range(1, len(sorted_voc) + 1)))))\n\n        self.index_docs = {}\n        for w, c in list(self.word_docs.items()):\n            self.index_docs[self.word_index[w]] = c",
        "begin_line": 160,
        "end_line": 195,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.text.Tokenizer.fit_on_sequences#197",
        "src_path": "keras/preprocessing/text.py",
        "class_name": "keras.preprocessing.text.Tokenizer",
        "signature": "keras.preprocessing.text.Tokenizer.fit_on_sequences(self, sequences)",
        "snippet": "    def fit_on_sequences(self, sequences):\n        \"\"\"Updates internal vocabulary based on a list of sequences.\n\n        Required before using `sequences_to_matrix`\n        (if `fit_on_texts` was never called).\n\n        # Arguments\n            sequences: A list of sequence.\n                A \"sequence\" is a list of integer word indices.\n        \"\"\"\n        self.document_count = len(sequences)\n        self.index_docs = {}\n        for seq in sequences:\n            seq = set(seq)\n            for i in seq:\n                if i not in self.index_docs:\n                    self.index_docs[i] = 1\n                else:\n                    self.index_docs[i] += 1",
        "begin_line": 197,
        "end_line": 215,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.text.Tokenizer.texts_to_sequences#217",
        "src_path": "keras/preprocessing/text.py",
        "class_name": "keras.preprocessing.text.Tokenizer",
        "signature": "keras.preprocessing.text.Tokenizer.texts_to_sequences(self, texts)",
        "snippet": "    def texts_to_sequences(self, texts):\n        \"\"\"Transforms each text in texts in a sequence of integers.\n\n        Only top \"num_words\" most frequent words will be taken into account.\n        Only words known by the tokenizer will be taken into account.\n\n        # Arguments\n            texts: A list of texts (strings).\n\n        # Returns\n            A list of sequences.\n        \"\"\"\n        res = []\n        for vect in self.texts_to_sequences_generator(texts):\n            res.append(vect)\n        return res",
        "begin_line": 217,
        "end_line": 232,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.text.Tokenizer.texts_to_sequences_generator#234",
        "src_path": "keras/preprocessing/text.py",
        "class_name": "keras.preprocessing.text.Tokenizer",
        "signature": "keras.preprocessing.text.Tokenizer.texts_to_sequences_generator(self, texts)",
        "snippet": "    def texts_to_sequences_generator(self, texts):\n        \"\"\"Transforms each text in texts in a sequence of integers.\n\n        Only top \"num_words\" most frequent words will be taken into account.\n        Only words known by the tokenizer will be taken into account.\n\n        # Arguments\n            texts: A list of texts (strings).\n\n        # Yields\n            Yields individual sequences.\n        \"\"\"\n        num_words = self.num_words\n        for text in texts:\n            seq = text if self.char_level else text_to_word_sequence(text,\n                                                                     self.filters,\n                                                                     self.lower,\n                                                                     self.split)\n            vect = []\n            for w in seq:\n                i = self.word_index.get(w)\n                if i is not None:\n                    if num_words and i >= num_words:\n                        continue\n                    else:\n                        vect.append(i)\n            yield vect",
        "begin_line": 234,
        "end_line": 260,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.text.Tokenizer.texts_to_matrix#262",
        "src_path": "keras/preprocessing/text.py",
        "class_name": "keras.preprocessing.text.Tokenizer",
        "signature": "keras.preprocessing.text.Tokenizer.texts_to_matrix(self, texts, mode='binary')",
        "snippet": "    def texts_to_matrix(self, texts, mode='binary'):\n        \"\"\"Convert a list of texts to a Numpy matrix.\n\n        # Arguments\n            texts: list of strings.\n            mode: one of \"binary\", \"count\", \"tfidf\", \"freq\".\n\n        # Returns\n            A Numpy matrix.\n        \"\"\"\n        sequences = self.texts_to_sequences(texts)\n        return self.sequences_to_matrix(sequences, mode=mode)",
        "begin_line": 262,
        "end_line": 273,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.text.Tokenizer.sequences_to_matrix#275",
        "src_path": "keras/preprocessing/text.py",
        "class_name": "keras.preprocessing.text.Tokenizer",
        "signature": "keras.preprocessing.text.Tokenizer.sequences_to_matrix(self, sequences, mode='binary')",
        "snippet": "    def sequences_to_matrix(self, sequences, mode='binary'):\n        \"\"\"Converts a list of sequences into a Numpy matrix.\n\n        # Arguments\n            sequences: list of sequences\n                (a sequence is a list of integer word indices).\n            mode: one of \"binary\", \"count\", \"tfidf\", \"freq\"\n\n        # Returns\n            A Numpy matrix.\n\n        # Raises\n            ValueError: In case of invalid `mode` argument,\n                or if the Tokenizer requires to be fit to sample data.\n        \"\"\"\n        if not self.num_words:\n            if self.word_index:\n                num_words = len(self.word_index) + 1\n            else:\n                raise ValueError('Specify a dimension (num_words argument), '\n                                 'or fit on some text data first.')\n        else:\n            num_words = self.num_words\n\n        if mode == 'tfidf' and not self.document_count:\n            raise ValueError('Fit the Tokenizer on some data '\n                             'before using tfidf mode.')\n\n        x = np.zeros((len(sequences), num_words))\n        for i, seq in enumerate(sequences):\n            if not seq:\n                continue\n            counts = {}\n            for j in seq:\n                if j >= num_words:\n                    continue\n                if j not in counts:\n                    counts[j] = 1.\n                else:\n                    counts[j] += 1\n            for j, c in list(counts.items()):\n                if mode == 'count':\n                    x[i][j] = c\n                elif mode == 'freq':\n                    x[i][j] = c / len(seq)\n                elif mode == 'binary':\n                    x[i][j] = 1\n                elif mode == 'tfidf':\n                    # Use weighting scheme 2 in\n                    # https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n                    tf = 1 + np.log(c)\n                    idf = np.log(1 + self.document_count /\n                                 (1 + self.index_docs.get(j, 0)))\n                    x[i][j] = tf * idf\n                else:\n                    raise ValueError('Unknown vectorization mode:', mode)\n        return x",
        "begin_line": 275,
        "end_line": 331,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.normalization.BatchNormalization.__init__#56",
        "src_path": "keras/layers/normalization.py",
        "class_name": "keras.layers.normalization.BatchNormalization",
        "signature": "keras.layers.normalization.BatchNormalization.__init__(self, axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None, **kwargs)",
        "snippet": "    def __init__(self,\n                 axis=-1,\n                 momentum=0.99,\n                 epsilon=1e-3,\n                 center=True,\n                 scale=True,\n                 beta_initializer='zeros',\n                 gamma_initializer='ones',\n                 moving_mean_initializer='zeros',\n                 moving_variance_initializer='ones',\n                 beta_regularizer=None,\n                 gamma_regularizer=None,\n                 beta_constraint=None,\n                 gamma_constraint=None,\n                 **kwargs):\n        super(BatchNormalization, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.axis = axis\n        self.momentum = momentum\n        self.epsilon = epsilon\n        self.center = center\n        self.scale = scale\n        self.beta_initializer = initializers.get(beta_initializer)\n        self.gamma_initializer = initializers.get(gamma_initializer)\n        self.moving_mean_initializer = initializers.get(moving_mean_initializer)\n        self.moving_variance_initializer = initializers.get(moving_variance_initializer)\n        self.beta_regularizer = regularizers.get(beta_regularizer)\n        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n        self.beta_constraint = constraints.get(beta_constraint)\n        self.gamma_constraint = constraints.get(gamma_constraint)",
        "begin_line": 56,
        "end_line": 85,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010002000400080016,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.normalization.BatchNormalization.build#87",
        "src_path": "keras/layers/normalization.py",
        "class_name": "keras.layers.normalization.BatchNormalization",
        "signature": "keras.layers.normalization.BatchNormalization.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        dim = input_shape[self.axis]\n        if dim is None:\n            raise ValueError('Axis ' + str(self.axis) + ' of '\n                             'input tensor should have a defined dimension '\n                             'but the layer received an input with shape ' +\n                             str(input_shape) + '.')\n        self.input_spec = InputSpec(ndim=len(input_shape),\n                                    axes={self.axis: dim})\n        shape = (dim,)\n\n        if self.scale:\n            self.gamma = self.add_weight(shape=shape,\n                                         name='gamma',\n                                         initializer=self.gamma_initializer,\n                                         regularizer=self.gamma_regularizer,\n                                         constraint=self.gamma_constraint)\n        else:\n            self.gamma = None\n        if self.center:\n            self.beta = self.add_weight(shape=shape,\n                                        name='beta',\n                                        initializer=self.beta_initializer,\n                                        regularizer=self.beta_regularizer,\n                                        constraint=self.beta_constraint)\n        else:\n            self.beta = None\n        self.moving_mean = self.add_weight(\n            shape=shape,\n            name='moving_mean',\n            initializer=self.moving_mean_initializer,\n            trainable=False)\n        self.moving_variance = self.add_weight(\n            shape=shape,\n            name='moving_variance',\n            initializer=self.moving_variance_initializer,\n            trainable=False)\n        self.built = True",
        "begin_line": 87,
        "end_line": 124,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001152604887044721,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.normalization.BatchNormalization.call#126",
        "src_path": "keras/layers/normalization.py",
        "class_name": "keras.layers.normalization.BatchNormalization",
        "signature": "keras.layers.normalization.BatchNormalization.call(self, inputs, training=None)",
        "snippet": "    def call(self, inputs, training=None):\n        input_shape = K.int_shape(inputs)\n        # Prepare broadcasting shape.\n        ndim = len(input_shape)\n        reduction_axes = list(range(len(input_shape)))\n        del reduction_axes[self.axis]\n        broadcast_shape = [1] * len(input_shape)\n        broadcast_shape[self.axis] = input_shape[self.axis]\n\n        # Determines whether broadcasting is needed.\n        needs_broadcasting = (sorted(reduction_axes) != list(range(ndim))[:-1])\n\n        def normalize_inference():\n            if needs_broadcasting:\n                # In this case we must explicitly broadcast all parameters.\n                broadcast_moving_mean = K.reshape(self.moving_mean,\n                                                  broadcast_shape)\n                broadcast_moving_variance = K.reshape(self.moving_variance,\n                                                      broadcast_shape)\n                if self.center:\n                    broadcast_beta = K.reshape(self.beta, broadcast_shape)\n                else:\n                    broadcast_beta = None\n                if self.scale:\n                    broadcast_gamma = K.reshape(self.gamma,\n                                                broadcast_shape)\n                else:\n                    broadcast_gamma = None\n                return K.batch_normalization(\n                    inputs,\n                    broadcast_moving_mean,\n                    broadcast_moving_variance,\n                    broadcast_beta,\n                    broadcast_gamma,\n                    epsilon=self.epsilon)\n            else:\n                return K.batch_normalization(\n                    inputs,\n                    self.moving_mean,\n                    self.moving_variance,\n                    self.beta,\n                    self.gamma,\n                    epsilon=self.epsilon)\n\n        # If the learning phase is *static* and set to inference:\n        if training in {0, False}:\n            return normalize_inference()\n\n        # If the learning is either dynamic, or set to training:\n        normed_training, mean, variance = K.normalize_batch_in_training(\n            inputs, self.gamma, self.beta, reduction_axes,\n            epsilon=self.epsilon)\n\n        self.add_update([K.moving_average_update(self.moving_mean,\n                                                 mean,\n                                                 self.momentum),\n                         K.moving_average_update(self.moving_variance,\n                                                 variance,\n                                                 self.momentum)],\n                        inputs)\n\n        # Pick the normalized form corresponding to the training phase.\n        return K.in_train_phase(normed_training,\n                                normalize_inference,\n                                training=training)",
        "begin_line": 126,
        "end_line": 190,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.normalization.BatchNormalization.normalize_inference#138",
        "src_path": "keras/layers/normalization.py",
        "class_name": "keras.layers.normalization.BatchNormalization",
        "signature": "keras.layers.normalization.BatchNormalization.normalize_inference()",
        "snippet": "        def normalize_inference():\n            if needs_broadcasting:\n                # In this case we must explicitly broadcast all parameters.\n                broadcast_moving_mean = K.reshape(self.moving_mean,\n                                                  broadcast_shape)\n                broadcast_moving_variance = K.reshape(self.moving_variance,\n                                                      broadcast_shape)\n                if self.center:\n                    broadcast_beta = K.reshape(self.beta, broadcast_shape)\n                else:\n                    broadcast_beta = None\n                if self.scale:\n                    broadcast_gamma = K.reshape(self.gamma,\n                                                broadcast_shape)\n                else:\n                    broadcast_gamma = None\n                return K.batch_normalization(\n                    inputs,\n                    broadcast_moving_mean,\n                    broadcast_moving_variance,\n                    broadcast_beta,\n                    broadcast_gamma,\n                    epsilon=self.epsilon)\n            else:\n                return K.batch_normalization(\n                    inputs,\n                    self.moving_mean,\n                    self.moving_variance,\n                    self.beta,\n                    self.gamma,\n                    epsilon=self.epsilon)",
        "begin_line": 138,
        "end_line": 168,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.normalization.BatchNormalization.get_config#192",
        "src_path": "keras/layers/normalization.py",
        "class_name": "keras.layers.normalization.BatchNormalization",
        "signature": "keras.layers.normalization.BatchNormalization.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {\n            'axis': self.axis,\n            'momentum': self.momentum,\n            'epsilon': self.epsilon,\n            'center': self.center,\n            'scale': self.scale,\n            'beta_initializer': initializers.serialize(self.beta_initializer),\n            'gamma_initializer': initializers.serialize(self.gamma_initializer),\n            'moving_mean_initializer': initializers.serialize(self.moving_mean_initializer),\n            'moving_variance_initializer': initializers.serialize(self.moving_variance_initializer),\n            'beta_regularizer': regularizers.serialize(self.beta_regularizer),\n            'gamma_regularizer': regularizers.serialize(self.gamma_regularizer),\n            'beta_constraint': constraints.serialize(self.beta_constraint),\n            'gamma_constraint': constraints.serialize(self.gamma_constraint)\n        }\n        base_config = super(BatchNormalization, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 192,
        "end_line": 209,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.advanced_activations.LeakyReLU.__init__#35",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.LeakyReLU",
        "signature": "keras.layers.advanced_activations.LeakyReLU.__init__(self, alpha=0.3, **kwargs)",
        "snippet": "    def __init__(self, alpha=0.3, **kwargs):\n        super(LeakyReLU, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.alpha = K.cast_to_floatx(alpha)",
        "begin_line": 35,
        "end_line": 38,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.advanced_activations.LeakyReLU.call#40",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.LeakyReLU",
        "signature": "keras.layers.advanced_activations.LeakyReLU.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        return K.relu(inputs, alpha=self.alpha)",
        "begin_line": 40,
        "end_line": 41,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.advanced_activations.LeakyReLU.get_config#43",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.LeakyReLU",
        "signature": "keras.layers.advanced_activations.LeakyReLU.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'alpha': float(self.alpha)}\n        base_config = super(LeakyReLU, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 43,
        "end_line": 46,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.advanced_activations.PReLU.__init__#83",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.PReLU",
        "signature": "keras.layers.advanced_activations.PReLU.__init__(self, alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=None, **kwargs)",
        "snippet": "    def __init__(self, alpha_initializer='zeros',\n                 alpha_regularizer=None,\n                 alpha_constraint=None,\n                 shared_axes=None,\n                 **kwargs):\n        super(PReLU, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.alpha_initializer = initializers.get(alpha_initializer)\n        self.alpha_regularizer = regularizers.get(alpha_regularizer)\n        self.alpha_constraint = constraints.get(alpha_constraint)\n        if shared_axes is None:\n            self.shared_axes = None\n        elif not isinstance(shared_axes, (list, tuple)):\n            self.shared_axes = [shared_axes]\n        else:\n            self.shared_axes = list(shared_axes)",
        "begin_line": 83,
        "end_line": 98,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.advanced_activations.PReLU.build#100",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.PReLU",
        "signature": "keras.layers.advanced_activations.PReLU.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        param_shape = list(input_shape[1:])\n        self.param_broadcast = [False] * len(param_shape)\n        if self.shared_axes is not None:\n            for i in self.shared_axes:\n                param_shape[i - 1] = 1\n                self.param_broadcast[i - 1] = True\n        self.alpha = self.add_weight(shape=param_shape,\n                                     name='alpha',\n                                     initializer=self.alpha_initializer,\n                                     regularizer=self.alpha_regularizer,\n                                     constraint=self.alpha_constraint)\n        # Set input spec\n        axes = {}\n        if self.shared_axes:\n            for i in range(1, len(input_shape)):\n                if i not in self.shared_axes:\n                    axes[i] = input_shape[i]\n        self.input_spec = InputSpec(ndim=len(input_shape), axes=axes)\n        self.built = True",
        "begin_line": 100,
        "end_line": 119,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.advanced_activations.PReLU.call#121",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.PReLU",
        "signature": "keras.layers.advanced_activations.PReLU.call(self, inputs, mask=None)",
        "snippet": "    def call(self, inputs, mask=None):\n        pos = K.relu(inputs)\n        if K.backend() == 'theano':\n            neg = (K.pattern_broadcast(self.alpha, self.param_broadcast) *\n                   (inputs - K.abs(inputs)) * 0.5)\n        else:\n            neg = -self.alpha * K.relu(-inputs)\n        return pos + neg",
        "begin_line": 121,
        "end_line": 128,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.advanced_activations.PReLU.get_config#130",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.PReLU",
        "signature": "keras.layers.advanced_activations.PReLU.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {\n            'alpha_initializer': initializers.serialize(self.alpha_initializer),\n            'alpha_regularizer': regularizers.serialize(self.alpha_regularizer),\n            'alpha_constraint': constraints.serialize(self.alpha_constraint),\n            'shared_axes': self.shared_axes\n        }\n        base_config = super(PReLU, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 130,
        "end_line": 138,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.advanced_activations.ELU.__init__#163",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.ELU",
        "signature": "keras.layers.advanced_activations.ELU.__init__(self, alpha=1.0, **kwargs)",
        "snippet": "    def __init__(self, alpha=1.0, **kwargs):\n        super(ELU, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.alpha = K.cast_to_floatx(alpha)",
        "begin_line": 163,
        "end_line": 166,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.advanced_activations.ELU.call#168",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.ELU",
        "signature": "keras.layers.advanced_activations.ELU.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        return K.elu(inputs, self.alpha)",
        "begin_line": 168,
        "end_line": 169,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.advanced_activations.ELU.get_config#171",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.ELU",
        "signature": "keras.layers.advanced_activations.ELU.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'alpha': float(self.alpha)}\n        base_config = super(ELU, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 171,
        "end_line": 174,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.advanced_activations.ThresholdedReLU.__init__#199",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.ThresholdedReLU",
        "signature": "keras.layers.advanced_activations.ThresholdedReLU.__init__(self, theta=1.0, **kwargs)",
        "snippet": "    def __init__(self, theta=1.0, **kwargs):\n        super(ThresholdedReLU, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.theta = K.cast_to_floatx(theta)",
        "begin_line": 199,
        "end_line": 202,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.advanced_activations.ThresholdedReLU.call#204",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.ThresholdedReLU",
        "signature": "keras.layers.advanced_activations.ThresholdedReLU.call(self, inputs, mask=None)",
        "snippet": "    def call(self, inputs, mask=None):\n        return inputs * K.cast(K.greater(inputs, self.theta), K.floatx())",
        "begin_line": 204,
        "end_line": 205,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.advanced_activations.ThresholdedReLU.get_config#207",
        "src_path": "keras/layers/advanced_activations.py",
        "class_name": "keras.layers.advanced_activations.ThresholdedReLU",
        "signature": "keras.layers.advanced_activations.ThresholdedReLU.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'theta': float(self.theta)}\n        base_config = super(ThresholdedReLU, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 207,
        "end_line": 210,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.sequence.pad_sequences#9",
        "src_path": "keras/preprocessing/sequence.py",
        "class_name": "keras.preprocessing.sequence",
        "signature": "keras.preprocessing.sequence.pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', truncating='pre', value=0.0)",
        "snippet": "def pad_sequences(sequences, maxlen=None, dtype='int32',\n                  padding='pre', truncating='pre', value=0.):\n    \"\"\"Pads each sequence to the same length (length of the longest sequence).\n\n    If maxlen is provided, any sequence longer\n    than maxlen is truncated to maxlen.\n    Truncation happens off either the beginning (default) or\n    the end of the sequence.\n\n    Supports post-padding and pre-padding (default).\n\n    # Arguments\n        sequences: list of lists where each element is a sequence\n        maxlen: int, maximum length\n        dtype: type to cast the resulting sequence.\n        padding: 'pre' or 'post', pad either before or after each sequence.\n        truncating: 'pre' or 'post', remove values from sequences larger than\n            maxlen either in the beginning or in the end of the sequence\n        value: float, value to pad the sequences to the desired value.\n\n    # Returns\n        x: numpy array with dimensions (number_of_sequences, maxlen)\n\n    # Raises\n        ValueError: in case of invalid values for `truncating` or `padding`,\n            or in case of invalid shape for a `sequences` entry.\n    \"\"\"\n    if not hasattr(sequences, '__len__'):\n        raise ValueError('`sequences` must be iterable.')\n    lengths = []\n    for x in sequences:\n        if not hasattr(x, '__len__'):\n            raise ValueError('`sequences` must be a list of iterables. '\n                             'Found non-iterable: ' + str(x))\n        lengths.append(len(x))\n\n    num_samples = len(sequences)\n    if maxlen is None:\n        maxlen = np.max(lengths)\n\n    # take the sample shape from the first non empty sequence\n    # checking for consistency in the main loop below.\n    sample_shape = tuple()\n    for s in sequences:\n        if len(s) > 0:\n            sample_shape = np.asarray(s).shape[1:]\n            break\n\n    x = (np.ones((num_samples, maxlen) + sample_shape) * value).astype(dtype)\n    for idx, s in enumerate(sequences):\n        if not len(s):\n            continue  # empty list/array was found\n        if truncating == 'pre':\n            trunc = s[-maxlen:]\n        elif truncating == 'post':\n            trunc = s[:maxlen]\n        else:\n            raise ValueError('Truncating type \"%s\" not understood' % truncating)\n\n        # check `trunc` has expected shape\n        trunc = np.asarray(trunc, dtype=dtype)\n        if trunc.shape[1:] != sample_shape:\n            raise ValueError('Shape of sample %s of sequence at position %s is different from expected shape %s' %\n                             (trunc.shape[1:], idx, sample_shape))\n\n        if padding == 'post':\n            x[idx, :len(trunc)] = trunc\n        elif padding == 'pre':\n            x[idx, -len(trunc):] = trunc\n        else:\n            raise ValueError('Padding type \"%s\" not understood' % padding)\n    return x",
        "begin_line": 9,
        "end_line": 80,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.sequence.make_sampling_table#83",
        "src_path": "keras/preprocessing/sequence.py",
        "class_name": "keras.preprocessing.sequence",
        "signature": "keras.preprocessing.sequence.make_sampling_table(size, sampling_factor=1e-05)",
        "snippet": "def make_sampling_table(size, sampling_factor=1e-5):\n    \"\"\"Generates a word rank-based probabilistic sampling table.\n\n    This generates an array where the ith element\n    is the probability that a word of rank i would be sampled,\n    according to the sampling distribution used in word2vec.\n\n    The word2vec formula is:\n        p(word) = min(1, sqrt(word.frequency/sampling_factor) / (word.frequency/sampling_factor))\n\n    We assume that the word frequencies follow Zipf's law (s=1) to derive\n    a numerical approximation of frequency(rank):\n       frequency(rank) ~ 1/(rank * (log(rank) + gamma) + 1/2 - 1/(12*rank))\n        where gamma is the Euler-Mascheroni constant.\n\n    # Arguments\n        size: int, number of possible words to sample.\n        sampling_factor: the sampling factor in the word2vec formula.\n\n    # Returns\n        A 1D Numpy array of length `size` where the ith entry\n        is the probability that a word of rank i should be sampled.\n    \"\"\"\n    gamma = 0.577\n    rank = np.arange(size)\n    rank[0] = 1\n    inv_fq = rank * (np.log(rank) + gamma) + 0.5 - 1. / (12. * rank)\n    f = sampling_factor * inv_fq\n\n    return np.minimum(1., f / np.sqrt(f))",
        "begin_line": 83,
        "end_line": 112,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.sequence.skipgrams#115",
        "src_path": "keras/preprocessing/sequence.py",
        "class_name": "keras.preprocessing.sequence",
        "signature": "keras.preprocessing.sequence.skipgrams(sequence, vocabulary_size, window_size=4, negative_samples=1.0, shuffle=True, categorical=False, sampling_table=None, seed=None)",
        "snippet": "def skipgrams(sequence, vocabulary_size,\n              window_size=4, negative_samples=1., shuffle=True,\n              categorical=False, sampling_table=None, seed=None):\n    \"\"\"Generates skipgram word pairs.\n\n    Takes a sequence (list of indexes of words),\n    returns couples of [word_index, other_word index] and labels (1s or 0s),\n    where label = 1 if 'other_word' belongs to the context of 'word',\n    and label=0 if 'other_word' is randomly sampled\n\n    # Arguments\n        sequence: a word sequence (sentence), encoded as a list\n            of word indices (integers). If using a `sampling_table`,\n            word indices are expected to match the rank\n            of the words in a reference dataset (e.g. 10 would encode\n            the 10-th most frequently occurring token).\n            Note that index 0 is expected to be a non-word and will be skipped.\n        vocabulary_size: int. maximum possible word index + 1\n        window_size: int. actually half-window.\n            The window of a word wi will be [i-window_size, i+window_size+1]\n        negative_samples: float >= 0. 0 for no negative (=random) samples.\n            1 for same number as positive samples. etc.\n        shuffle: whether to shuffle the word couples before returning them.\n        categorical: bool. if False, labels will be\n            integers (eg. [0, 1, 1 .. ]),\n            if True labels will be categorical eg. [[1,0],[0,1],[0,1] .. ]\n        sampling_table: 1D array of size `vocabulary_size` where the entry i\n            encodes the probability to sample a word of rank i.\n        seed: random seed.\n\n    # Returns\n        couples, labels: where `couples` are int pairs and\n            `labels` are either 0 or 1.\n\n    # Note\n        By convention, index 0 in the vocabulary is\n        a non-word and will be skipped.\n    \"\"\"\n    couples = []\n    labels = []\n    for i, wi in enumerate(sequence):\n        if not wi:\n            continue\n        if sampling_table is not None:\n            if sampling_table[wi] < random.random():\n                continue\n\n        window_start = max(0, i - window_size)\n        window_end = min(len(sequence), i + window_size + 1)\n        for j in range(window_start, window_end):\n            if j != i:\n                wj = sequence[j]\n                if not wj:\n                    continue\n                couples.append([wi, wj])\n                if categorical:\n                    labels.append([0, 1])\n                else:\n                    labels.append(1)\n\n    if negative_samples > 0:\n        num_negative_samples = int(len(labels) * negative_samples)\n        words = [c[0] for c in couples]\n        random.shuffle(words)\n\n        couples += [[words[i % len(words)],\n                    random.randint(1, vocabulary_size - 1)] for i in range(num_negative_samples)]\n        if categorical:\n            labels += [[1, 0]] * num_negative_samples\n        else:\n            labels += [0] * num_negative_samples\n\n    if shuffle:\n        if seed is None:\n            seed = random.randint(0, 10e6)\n        random.seed(seed)\n        random.shuffle(couples)\n        random.seed(seed)\n        random.shuffle(labels)\n\n    return couples, labels",
        "begin_line": 115,
        "end_line": 195,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.applications.vgg19.VGG19#35",
        "src_path": "keras/applications/vgg19.py",
        "class_name": "keras.applications.vgg19",
        "signature": "keras.applications.vgg19.VGG19(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)",
        "snippet": "def VGG19(include_top=True, weights='imagenet',\n          input_tensor=None, input_shape=None,\n          pooling=None,\n          classes=1000):\n    \"\"\"Instantiates the VGG19 architecture.\n\n    Optionally loads weights pre-trained\n    on ImageNet. Note that when using TensorFlow,\n    for best performance you should set\n    `image_data_format='channels_last'` in your Keras config\n    at ~/.keras/keras.json.\n\n    The model and the weights are compatible with both\n    TensorFlow and Theano. The data format\n    convention used by the model is the one\n    specified in your Keras config file.\n\n    # Arguments\n        include_top: whether to include the 3 fully-connected\n            layers at the top of the network.\n        weights: one of `None` (random initialization)\n            or 'imagenet' (pre-training on ImageNet).\n        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n            to use as image input for the model.\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(224, 224, 3)` (with `channels_last` data format)\n            or `(3, 224, 224)` (with `channels_first` data format).\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 48.\n            E.g. `(200, 200, 3)` would be one valid value.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model will be\n                the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a 2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n\n    # Returns\n        A Keras model instance.\n\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n    \"\"\"\n    if weights not in {'imagenet', None}:\n        raise ValueError('The `weights` argument should be either '\n                         '`None` (random initialization) or `imagenet` '\n                         '(pre-training on ImageNet).')\n\n    if weights == 'imagenet' and include_top and classes != 1000:\n        raise ValueError('If using `weights` as imagenet with `include_top`'\n                         ' as true, `classes` should be 1000')\n    # Determine proper input shape\n    input_shape = _obtain_input_shape(input_shape,\n                                      default_size=224,\n                                      min_size=48,\n                                      data_format=K.image_data_format(),\n                                      require_flatten=include_top,\n                                      weights=weights)\n\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n    # Block 1\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n\n    # Block 2\n    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n\n    # Block 3\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv4')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n\n    # Block 4\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv4')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n\n    # Block 5\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv4')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n\n    if include_top:\n        # Classification block\n        x = Flatten(name='flatten')(x)\n        x = Dense(4096, activation='relu', name='fc1')(x)\n        x = Dense(4096, activation='relu', name='fc2')(x)\n        x = Dense(classes, activation='softmax', name='predictions')(x)\n    else:\n        if pooling == 'avg':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling == 'max':\n            x = GlobalMaxPooling2D()(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n    # Create model.\n    model = Model(inputs, x, name='vgg19')\n\n    # load weights\n    if weights == 'imagenet':\n        if include_top:\n            weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels.h5',\n                                    WEIGHTS_PATH,\n                                    cache_subdir='models',\n                                    file_hash='cbe5617147190e668d6c5d5026f83318')\n        else:\n            weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5',\n                                    WEIGHTS_PATH_NO_TOP,\n                                    cache_subdir='models',\n                                    file_hash='253f8cb515780f3b799900260a226db6')\n        model.load_weights(weights_path)\n        if K.backend() == 'theano':\n            layer_utils.convert_all_kernels_in_model(model)\n\n        if K.image_data_format() == 'channels_first':\n            if include_top:\n                maxpool = model.get_layer(name='block5_pool')\n                shape = maxpool.output_shape[1:]\n                dense = model.get_layer(name='fc1')\n                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n\n            if K.backend() == 'tensorflow':\n                warnings.warn('You are using the TensorFlow backend, yet you '\n                              'are using the Theano '\n                              'image data format convention '\n                              '(`image_data_format=\"channels_first\"`). '\n                              'For best performance, set '\n                              '`image_data_format=\"channels_last\"` in '\n                              'your Keras config '\n                              'at ~/.keras/keras.json.')\n    return model",
        "begin_line": 35,
        "end_line": 195,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.interfaces.legacy_support#22",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.legacy_support(func)",
        "snippet": "    def legacy_support(func):\n        @six.wraps(func)\n        def wrapper(*args, **kwargs):\n            if object_type == 'class':\n                object_name = args[0].__class__.__name__\n            else:\n                object_name = func.__name__\n            if preprocessor:\n                args, kwargs, converted = preprocessor(args, kwargs)\n            else:\n                converted = []\n            if check_positional_args:\n                if len(args) > len(allowed_positional_args) + 1:\n                    raise TypeError('`' + object_name +\n                                    '` can accept only ' +\n                                    str(len(allowed_positional_args)) +\n                                    ' positional arguments ' +\n                                    str(tuple(allowed_positional_args)) +\n                                    ', but you passed the following '\n                                    'positional arguments: ' +\n                                    str(list(args[1:])))\n            for key in value_conversions:\n                if key in kwargs:\n                    old_value = kwargs[key]\n                    if old_value in value_conversions[key]:\n                        kwargs[key] = value_conversions[key][old_value]\n            for old_name, new_name in conversions:\n                if old_name in kwargs:\n                    value = kwargs.pop(old_name)\n                    if new_name in kwargs:\n                        raise_duplicate_arg_error(old_name, new_name)\n                    kwargs[new_name] = value\n                    converted.append((new_name, old_name))\n            if converted:\n                signature = '`' + object_name + '('\n                for i, value in enumerate(args[1:]):\n                    if isinstance(value, six.string_types):\n                        signature += '\"' + value + '\"'\n                    else:\n                        if isinstance(value, np.ndarray):\n                            str_val = 'array'\n                        else:\n                            str_val = str(value)\n                        if len(str_val) > 10:\n                            str_val = str_val[:10] + '...'\n                        signature += str_val\n                    if i < len(args[1:]) - 1 or kwargs:\n                        signature += ', '\n                for i, (name, value) in enumerate(kwargs.items()):\n                    signature += name + '='\n                    if isinstance(value, six.string_types):\n                        signature += '\"' + value + '\"'\n                    else:\n                        if isinstance(value, np.ndarray):\n                            str_val = 'array'\n                        else:\n                            str_val = str(value)\n                        if len(str_val) > 10:\n                            str_val = str_val[:10] + '...'\n                        signature += str_val\n                    if i < len(kwargs) - 1:\n                        signature += ', '\n                signature += ')`'\n                warnings.warn('Update your `' + object_name +\n                              '` call to the Keras 2 API: ' + signature, stacklevel=2)\n            return func(*args, **kwargs)\n        wrapper._original_function = func\n        return wrapper",
        "begin_line": 22,
        "end_line": 89,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0012106537530266344,
            "pseudo_dstar_susp": 0.003875968992248062,
            "pseudo_tarantula_susp": 0.0008130081300813008,
            "pseudo_op2_susp": 0.003875968992248062,
            "pseudo_barinel_susp": 0.0008130081300813008
        }
    },
    {
        "name": "keras.legacy.interfaces.wrapper#24",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.wrapper(*args, **kwargs)",
        "snippet": "        def wrapper(*args, **kwargs):\n            if object_type == 'class':\n                object_name = args[0].__class__.__name__\n            else:\n                object_name = func.__name__\n            if preprocessor:\n                args, kwargs, converted = preprocessor(args, kwargs)\n            else:\n                converted = []\n            if check_positional_args:\n                if len(args) > len(allowed_positional_args) + 1:\n                    raise TypeError('`' + object_name +\n                                    '` can accept only ' +\n                                    str(len(allowed_positional_args)) +\n                                    ' positional arguments ' +\n                                    str(tuple(allowed_positional_args)) +\n                                    ', but you passed the following '\n                                    'positional arguments: ' +\n                                    str(list(args[1:])))\n            for key in value_conversions:\n                if key in kwargs:\n                    old_value = kwargs[key]\n                    if old_value in value_conversions[key]:\n                        kwargs[key] = value_conversions[key][old_value]\n            for old_name, new_name in conversions:\n                if old_name in kwargs:\n                    value = kwargs.pop(old_name)\n                    if new_name in kwargs:\n                        raise_duplicate_arg_error(old_name, new_name)\n                    kwargs[new_name] = value\n                    converted.append((new_name, old_name))\n            if converted:\n                signature = '`' + object_name + '('\n                for i, value in enumerate(args[1:]):\n                    if isinstance(value, six.string_types):\n                        signature += '\"' + value + '\"'\n                    else:\n                        if isinstance(value, np.ndarray):\n                            str_val = 'array'\n                        else:\n                            str_val = str(value)\n                        if len(str_val) > 10:\n                            str_val = str_val[:10] + '...'\n                        signature += str_val\n                    if i < len(args[1:]) - 1 or kwargs:\n                        signature += ', '\n                for i, (name, value) in enumerate(kwargs.items()):\n                    signature += name + '='\n                    if isinstance(value, six.string_types):\n                        signature += '\"' + value + '\"'\n                    else:\n                        if isinstance(value, np.ndarray):\n                            str_val = 'array'\n                        else:\n                            str_val = str(value)\n                        if len(str_val) > 10:\n                            str_val = str_val[:10] + '...'\n                        signature += str_val\n                    if i < len(kwargs) - 1:\n                        signature += ', '\n                signature += ')`'\n                warnings.warn('Update your `' + object_name +\n                              '` call to the Keras 2 API: ' + signature, stacklevel=2)\n            return func(*args, **kwargs)",
        "begin_line": 24,
        "end_line": 87,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0014367816091954023,
            "pseudo_dstar_susp": 0.005714285714285714,
            "pseudo_tarantula_susp": 0.0011560693641618498,
            "pseudo_op2_susp": 0.005714285714285714,
            "pseudo_barinel_susp": 0.0011560693641618498
        }
    },
    {
        "name": "keras.legacy.interfaces.embedding_kwargs_preprocessor#120",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.embedding_kwargs_preprocessor(args, kwargs)",
        "snippet": "def embedding_kwargs_preprocessor(args, kwargs):\n    converted = []\n    if 'dropout' in kwargs:\n        kwargs.pop('dropout')\n        warnings.warn('The `dropout` argument is no longer support in `Embedding`. '\n                      'You can apply a `keras.layers.SpatialDropout1D` layer '\n                      'right after the `Embedding` layer to get the same behavior.', stacklevel=3)\n    return args, kwargs, converted",
        "begin_line": 120,
        "end_line": 127,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.interfaces.recurrent_args_preprocessor#152",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.recurrent_args_preprocessor(args, kwargs)",
        "snippet": "def recurrent_args_preprocessor(args, kwargs):\n    converted = []\n    if 'forget_bias_init' in kwargs:\n        if kwargs['forget_bias_init'] == 'one':\n            kwargs.pop('forget_bias_init')\n            kwargs['unit_forget_bias'] = True\n            converted.append(('forget_bias_init', 'unit_forget_bias'))\n        else:\n            kwargs.pop('forget_bias_init')\n            warnings.warn('The `forget_bias_init` argument '\n                          'has been ignored. Use `unit_forget_bias=True` '\n                          'instead to initialize with ones.', stacklevel=3)\n    if 'input_dim' in kwargs:\n        input_length = kwargs.pop('input_length', None)\n        input_dim = kwargs.pop('input_dim')\n        input_shape = (input_length, input_dim)\n        kwargs['input_shape'] = input_shape\n        converted.append(('input_dim', 'input_shape'))\n        warnings.warn('The `input_dim` and `input_length` arguments '\n                      'in recurrent layers are deprecated. '\n                      'Use `input_shape` instead.', stacklevel=3)\n    return args, kwargs, converted",
        "begin_line": 152,
        "end_line": 173,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0028328611898017,
            "pseudo_dstar_susp": 0.0035211267605633804,
            "pseudo_tarantula_susp": 0.0016863406408094434,
            "pseudo_op2_susp": 0.0035211267605633804,
            "pseudo_barinel_susp": 0.0016863406408094434
        }
    },
    {
        "name": "keras.legacy.interfaces.conv1d_args_preprocessor#237",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.conv1d_args_preprocessor(args, kwargs)",
        "snippet": "def conv1d_args_preprocessor(args, kwargs):\n    converted = []\n    if 'input_dim' in kwargs:\n        if 'input_length' in kwargs:\n            length = kwargs.pop('input_length')\n        else:\n            length = None\n        input_shape = (length, kwargs.pop('input_dim'))\n        kwargs['input_shape'] = input_shape\n        converted.append(('input_shape', 'input_dim'))\n    return args, kwargs, converted",
        "begin_line": 237,
        "end_line": 247,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.interfaces.conv2d_args_preprocessor#264",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.conv2d_args_preprocessor(args, kwargs)",
        "snippet": "def conv2d_args_preprocessor(args, kwargs):\n    converted = []\n    if len(args) > 4:\n        raise TypeError('Layer can receive at most 3 positional arguments.')\n    if len(args) == 4:\n        if isinstance(args[2], int) and isinstance(args[3], int):\n            new_keywords = ['padding', 'strides', 'data_format']\n            for kwd in new_keywords:\n                if kwd in kwargs:\n                    raise ValueError(\n                        'It seems that you are using the Keras 2 '\n                        'and you are passing both `kernel_size` and `strides` '\n                        'as integer positional arguments. For safety reasons, '\n                        'this is disallowed. Pass `strides` '\n                        'as a keyword argument instead.')\n            kernel_size = (args[2], args[3])\n            args = [args[0], args[1], kernel_size]\n            converted.append(('kernel_size', 'nb_row/nb_col'))\n    elif len(args) == 3 and isinstance(args[2], int):\n        if 'nb_col' in kwargs:\n            kernel_size = (args[2], kwargs.pop('nb_col'))\n            args = [args[0], args[1], kernel_size]\n            converted.append(('kernel_size', 'nb_row/nb_col'))\n    elif len(args) == 2:\n        if 'nb_row' in kwargs and 'nb_col' in kwargs:\n            kernel_size = (kwargs.pop('nb_row'), kwargs.pop('nb_col'))\n            args = [args[0], args[1], kernel_size]\n            converted.append(('kernel_size', 'nb_row/nb_col'))\n    elif len(args) == 1:\n        if 'nb_row' in kwargs and 'nb_col' in kwargs:\n            kernel_size = (kwargs.pop('nb_row'), kwargs.pop('nb_col'))\n            kwargs['kernel_size'] = kernel_size\n            converted.append(('kernel_size', 'nb_row/nb_col'))\n    return args, kwargs, converted",
        "begin_line": 264,
        "end_line": 297,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.interfaces.separable_conv2d_args_preprocessor#317",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.separable_conv2d_args_preprocessor(args, kwargs)",
        "snippet": "def separable_conv2d_args_preprocessor(args, kwargs):\n    converted = []\n    if 'init' in kwargs:\n        init = kwargs.pop('init')\n        kwargs['depthwise_initializer'] = init\n        kwargs['pointwise_initializer'] = init\n        converted.append(('init', 'depthwise_initializer/pointwise_initializer'))\n    args, kwargs, _converted = conv2d_args_preprocessor(args, kwargs)\n    return args, kwargs, converted + _converted",
        "begin_line": 317,
        "end_line": 325,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.interfaces.deconv2d_args_preprocessor#342",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.deconv2d_args_preprocessor(args, kwargs)",
        "snippet": "def deconv2d_args_preprocessor(args, kwargs):\n    converted = []\n    if len(args) == 5:\n        if isinstance(args[4], tuple):\n            args = args[:-1]\n            converted.append(('output_shape', None))\n    if 'output_shape' in kwargs:\n        kwargs.pop('output_shape')\n        converted.append(('output_shape', None))\n    args, kwargs, _converted = conv2d_args_preprocessor(args, kwargs)\n    return args, kwargs, converted + _converted",
        "begin_line": 342,
        "end_line": 352,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.interfaces.conv3d_args_preprocessor#372",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.conv3d_args_preprocessor(args, kwargs)",
        "snippet": "def conv3d_args_preprocessor(args, kwargs):\n    converted = []\n    if len(args) > 5:\n        raise TypeError('Layer can receive at most 4 positional arguments.')\n    if len(args) == 5:\n        if isinstance(args[2], int) and isinstance(args[3], int) and isinstance(args[4], int):\n            kernel_size = (args[2], args[3], args[4])\n            args = [args[0], args[1], kernel_size]\n            converted.append(('kernel_size', 'kernel_dim*'))\n    elif len(args) == 4 and isinstance(args[3], int):\n        if isinstance(args[2], int) and isinstance(args[3], int):\n            new_keywords = ['padding', 'strides', 'data_format']\n            for kwd in new_keywords:\n                if kwd in kwargs:\n                    raise ValueError(\n                        'It seems that you are using the Keras 2 '\n                        'and you are passing both `kernel_size` and `strides` '\n                        'as integer positional arguments. For safety reasons, '\n                        'this is disallowed. Pass `strides` '\n                        'as a keyword argument instead.')\n        if 'kernel_dim3' in kwargs:\n            kernel_size = (args[2], args[3], kwargs.pop('kernel_dim3'))\n            args = [args[0], args[1], kernel_size]\n            converted.append(('kernel_size', 'kernel_dim*'))\n    elif len(args) == 3:\n        if 'kernel_dim2' in kwargs and 'kernel_dim3' in kwargs:\n            kernel_size = (args[2],\n                           kwargs.pop('kernel_dim2'),\n                           kwargs.pop('kernel_dim3'))\n            args = [args[0], args[1], kernel_size]\n            converted.append(('kernel_size', 'kernel_dim*'))\n    elif len(args) == 2:\n        if 'kernel_dim1' in kwargs and 'kernel_dim2' in kwargs and 'kernel_dim3' in kwargs:\n            kernel_size = (kwargs.pop('kernel_dim1'),\n                           kwargs.pop('kernel_dim2'),\n                           kwargs.pop('kernel_dim3'))\n            args = [args[0], args[1], kernel_size]\n            converted.append(('kernel_size', 'kernel_dim*'))\n    elif len(args) == 1:\n        if 'kernel_dim1' in kwargs and 'kernel_dim2' in kwargs and 'kernel_dim3' in kwargs:\n            kernel_size = (kwargs.pop('kernel_dim1'),\n                           kwargs.pop('kernel_dim2'),\n                           kwargs.pop('kernel_dim3'))\n            kwargs['kernel_size'] = kernel_size\n            converted.append(('kernel_size', 'nb_row/nb_col'))\n    return args, kwargs, converted",
        "begin_line": 372,
        "end_line": 417,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.interfaces.batchnorm_args_preprocessor#437",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.batchnorm_args_preprocessor(args, kwargs)",
        "snippet": "def batchnorm_args_preprocessor(args, kwargs):\n    converted = []\n    if len(args) > 1:\n        raise TypeError('The `BatchNormalization` layer '\n                        'does not accept positional arguments. '\n                        'Use keyword arguments instead.')\n    if 'mode' in kwargs:\n        value = kwargs.pop('mode')\n        if value != 0:\n            raise TypeError('The `mode` argument of `BatchNormalization` '\n                            'no longer exists. `mode=1` and `mode=2` '\n                            'are no longer supported.')\n        converted.append(('mode', None))\n    return args, kwargs, converted",
        "begin_line": 437,
        "end_line": 450,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.interfaces.convlstm2d_args_preprocessor#453",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.convlstm2d_args_preprocessor(args, kwargs)",
        "snippet": "def convlstm2d_args_preprocessor(args, kwargs):\n    converted = []\n    if 'forget_bias_init' in kwargs:\n        value = kwargs.pop('forget_bias_init')\n        if value == 'one':\n            kwargs['unit_forget_bias'] = True\n            converted.append(('forget_bias_init', 'unit_forget_bias'))\n        else:\n            warnings.warn('The `forget_bias_init` argument '\n                          'has been ignored. Use `unit_forget_bias=True` '\n                          'instead to initialize with ones.', stacklevel=3)\n    args, kwargs, _converted = conv2d_args_preprocessor(args, kwargs)\n    return args, kwargs, converted + _converted",
        "begin_line": 453,
        "end_line": 465,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.interfaces.zeropadding2d_args_preprocessor#494",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.zeropadding2d_args_preprocessor(args, kwargs)",
        "snippet": "def zeropadding2d_args_preprocessor(args, kwargs):\n    converted = []\n    if 'padding' in kwargs and isinstance(kwargs['padding'], dict):\n        if set(kwargs['padding'].keys()) <= {'top_pad', 'bottom_pad',\n                                             'left_pad', 'right_pad'}:\n            top_pad = kwargs['padding'].get('top_pad', 0)\n            bottom_pad = kwargs['padding'].get('bottom_pad', 0)\n            left_pad = kwargs['padding'].get('left_pad', 0)\n            right_pad = kwargs['padding'].get('right_pad', 0)\n            kwargs['padding'] = ((top_pad, bottom_pad), (left_pad, right_pad))\n            warnings.warn('The `padding` argument in the Keras 2 API no longer'\n                          'accepts dict types. You can now input argument as: '\n                          '`padding=(top_pad, bottom_pad, left_pad, right_pad)`.', stacklevel=3)\n    elif len(args) == 2 and isinstance(args[1], dict):\n        if set(args[1].keys()) <= {'top_pad', 'bottom_pad',\n                                   'left_pad', 'right_pad'}:\n            top_pad = args[1].get('top_pad', 0)\n            bottom_pad = args[1].get('bottom_pad', 0)\n            left_pad = args[1].get('left_pad', 0)\n            right_pad = args[1].get('right_pad', 0)\n            args = (args[0], ((top_pad, bottom_pad), (left_pad, right_pad)))\n            warnings.warn('The `padding` argument in the Keras 2 API no longer'\n                          'accepts dict types. You can now input argument as: '\n                          '`padding=((top_pad, bottom_pad), (left_pad, right_pad))`', stacklevel=3)\n    return args, kwargs, converted",
        "begin_line": 494,
        "end_line": 518,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.interfaces.generator_methods_args_preprocessor#567",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.generator_methods_args_preprocessor(args, kwargs)",
        "snippet": "def generator_methods_args_preprocessor(args, kwargs):\n    converted = []\n    if len(args) < 3:\n        if 'samples_per_epoch' in kwargs:\n            samples_per_epoch = kwargs.pop('samples_per_epoch')\n            if len(args) > 1:\n                generator = args[1]\n            else:\n                generator = kwargs['generator']\n            if hasattr(generator, 'batch_size'):\n                kwargs['steps_per_epoch'] = samples_per_epoch // generator.batch_size\n            else:\n                kwargs['steps_per_epoch'] = samples_per_epoch\n            converted.append(('samples_per_epoch', 'steps_per_epoch'))\n\n    keras1_args = {'samples_per_epoch', 'val_samples', 'nb_epoch', 'nb_val_samples', 'nb_worker'}\n    if keras1_args.intersection(kwargs.keys()):\n        warnings.warn('The semantics of the Keras 2 argument '\n                      '`steps_per_epoch` is not the same as the '\n                      'Keras 1 argument `samples_per_epoch`. '\n                      '`steps_per_epoch` is the number of batches '\n                      'to draw from the generator at each epoch. '\n                      'Basically steps_per_epoch = samples_per_epoch/batch_size. '\n                      'Similarly `nb_val_samples`->`validation_steps` and '\n                      '`val_samples`->`steps` arguments have changed. '\n                      'Update your method calls accordingly.', stacklevel=3)\n\n    return args, kwargs, converted",
        "begin_line": 567,
        "end_line": 594,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.legacy.interfaces.add_weight_args_preprocessing#619",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.add_weight_args_preprocessing(args, kwargs)",
        "snippet": "def add_weight_args_preprocessing(args, kwargs):\n    if len(args) > 1:\n        if isinstance(args[1], (tuple, list)):\n            kwargs['shape'] = args[1]\n            args = (args[0],) + args[2:]\n            if len(args) > 1:\n                if isinstance(args[1], six.string_types):\n                    kwargs['name'] = args[1]\n                    args = (args[0],) + args[2:]\n    return args, kwargs, []",
        "begin_line": 619,
        "end_line": 628,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001652892561983471,
            "pseudo_dstar_susp": 0.00909090909090909,
            "pseudo_tarantula_susp": 0.0010787486515641855,
            "pseudo_op2_susp": 0.00909090909090909,
            "pseudo_barinel_susp": 0.0010787486515641855
        }
    },
    {
        "name": "keras.legacy.interfaces.get_updates_arg_preprocessing#636",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.get_updates_arg_preprocessing(args, kwargs)",
        "snippet": "def get_updates_arg_preprocessing(args, kwargs):\n    # Old interface: (params, constraints, loss)\n    # New interface: (loss, params)\n    if len(args) > 4:\n        raise TypeError('`get_update` call received more arguments '\n                        'than expected.')\n    elif len(args) == 4:\n        # Assuming old interface.\n        opt, params, _, loss = args\n        kwargs['loss'] = loss\n        kwargs['params'] = params\n        return [opt], kwargs, []\n    elif len(args) == 3:\n        if isinstance(args[1], (list, tuple)):\n            assert isinstance(args[2], dict)\n            assert 'loss' in kwargs\n            opt, params, _ = args\n            kwargs['params'] = params\n            return [opt], kwargs, []\n    return args, kwargs, []",
        "begin_line": 636,
        "end_line": 655,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.get_uid#53",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.get_uid(prefix='')",
        "snippet": "def get_uid(prefix=''):\n    \"\"\"Get the uid for the default graph.\n\n    # Arguments\n        prefix: An optional prefix of the graph.\n\n    # Returns\n        A unique identifier for the graph.\n    \"\"\"\n    global _GRAPH_UID_DICTS\n    graph = tf.get_default_graph()\n    if graph not in _GRAPH_UID_DICTS:\n        _GRAPH_UID_DICTS[graph] = defaultdict(int)\n    _GRAPH_UID_DICTS[graph][prefix] += 1\n    return _GRAPH_UID_DICTS[graph][prefix]",
        "begin_line": 53,
        "end_line": 67,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0013908205841446453,
            "pseudo_dstar_susp": 0.00546448087431694,
            "pseudo_tarantula_susp": 0.000975609756097561,
            "pseudo_op2_susp": 0.00546448087431694,
            "pseudo_barinel_susp": 0.000975609756097561
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.reset_uids#70",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.reset_uids()",
        "snippet": "def reset_uids():\n    \"\"\"Reset graph identifiers.\"\"\"\n    global _GRAPH_UID_DICTS\n    _GRAPH_UID_DICTS = {}",
        "begin_line": 70,
        "end_line": 73,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011976047904191617,
            "pseudo_dstar_susp": 0.003745318352059925,
            "pseudo_tarantula_susp": 0.0008058017727639,
            "pseudo_op2_susp": 0.003745318352059925,
            "pseudo_barinel_susp": 0.0008058017727639
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.clear_session#76",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.clear_session()",
        "snippet": "def clear_session():\n    \"\"\"Destroys the current TF graph and creates a new one.\n\n    Useful to avoid clutter from old models / layers.\n    \"\"\"\n    global _SESSION\n    global _GRAPH_LEARNING_PHASES\n    tf.reset_default_graph()\n    reset_uids()\n    _SESSION = None\n    phase = tf.placeholder(dtype='bool', name='keras_learning_phase')\n    _GRAPH_LEARNING_PHASES = {}\n    _GRAPH_LEARNING_PHASES[tf.get_default_graph()] = phase",
        "begin_line": 76,
        "end_line": 88,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0011976047904191617,
            "pseudo_dstar_susp": 0.003745318352059925,
            "pseudo_tarantula_susp": 0.0008058017727639,
            "pseudo_op2_susp": 0.003745318352059925,
            "pseudo_barinel_susp": 0.0008058017727639
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.learning_phase#107",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.learning_phase()",
        "snippet": "def learning_phase():\n    \"\"\"Returns the learning phase flag.\n\n    The learning phase flag is a bool tensor (0 = test, 1 = train)\n    to be passed as input to any Keras function\n    that uses a different behavior at train time and test time.\n\n    # Returns\n        Learning phase (scalar integer tensor or Python integer).\n    \"\"\"\n    graph = tf.get_default_graph()\n    if graph not in _GRAPH_LEARNING_PHASES:\n        phase = tf.placeholder(dtype='bool',\n                               name='keras_learning_phase')\n        _GRAPH_LEARNING_PHASES[graph] = phase\n    return _GRAPH_LEARNING_PHASES[graph]",
        "begin_line": 107,
        "end_line": 122,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.645061728395061e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.set_learning_phase#125",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.set_learning_phase(value)",
        "snippet": "def set_learning_phase(value):\n    \"\"\"Sets the learning phase to a fixed value.\n\n    # Arguments\n        value: Learning phase value, either 0 or 1 (integers).\n\n    # Raises\n        ValueError: if `value` is neither `0` nor `1`.\n    \"\"\"\n    global _GRAPH_LEARNING_PHASES\n    if value not in {0, 1}:\n        raise ValueError('Expected learning phase to be '\n                         '0 or 1.')\n    _GRAPH_LEARNING_PHASES[tf.get_default_graph()] = value",
        "begin_line": 125,
        "end_line": 138,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.get_session#141",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.get_session()",
        "snippet": "def get_session():\n    \"\"\"Returns the TF session to be used by the backend.\n\n    If a default TensorFlow session is available, we will return it.\n\n    Else, we will return the global Keras session.\n\n    If no global Keras session exists at this point:\n    we will create a new global session.\n\n    Note that you can manually set the global session\n    via `K.set_session(sess)`.\n\n    # Returns\n        A TensorFlow session.\n    \"\"\"\n    global _SESSION\n    if tf.get_default_session() is not None:\n        session = tf.get_default_session()\n    else:\n        if _SESSION is None:\n            if not os.environ.get('OMP_NUM_THREADS'):\n                config = tf.ConfigProto(allow_soft_placement=True)\n            else:\n                num_thread = int(os.environ.get('OMP_NUM_THREADS'))\n                config = tf.ConfigProto(intra_op_parallelism_threads=num_thread,\n                                        allow_soft_placement=True)\n            _SESSION = tf.Session(config=config)\n        session = _SESSION\n    if not _MANUAL_VAR_INIT:\n        with session.graph.as_default():\n            variables = tf.global_variables()\n            candidate_vars = []\n            for v in variables:\n                if not getattr(v, '_keras_initialized', False):\n                    candidate_vars.append(v)\n            # This step is expensive, so we only run it on variables\n            # not already marked as initialized.\n            is_initialized = session.run(\n                [tf.is_variable_initialized(v) for v in candidate_vars])\n            uninitialized_vars = []\n            for flag, v in zip(is_initialized, candidate_vars):\n                if not flag:\n                    uninitialized_vars.append(v)\n                v._keras_initialized = True\n            if uninitialized_vars:\n                session.run(tf.variables_initializer(uninitialized_vars))\n    return session",
        "begin_line": 141,
        "end_line": 188,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.005405405405405406,
            "pseudo_dstar_susp": 1.0,
            "pseudo_tarantula_susp": 0.0012224938875305623,
            "pseudo_op2_susp": 1.0,
            "pseudo_barinel_susp": 0.0012224938875305623
        }
    },
    {
        "name": "keras.backend.tensorflow_backend._TfDeviceCaptureOp.__init__#206",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend._TfDeviceCaptureOp",
        "signature": "keras.backend.tensorflow_backend._TfDeviceCaptureOp.__init__(self)",
        "snippet": "    def __init__(self):\n        self.device = None",
        "begin_line": 206,
        "end_line": 207,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010733068584308254,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend._get_current_tf_device#214",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend._get_current_tf_device()",
        "snippet": "def _get_current_tf_device():\n    \"\"\"Return explicit device of current context, otherwise returns `None`.\n\n    # Returns\n        If the current device scope is explicitly set, it returns a string with\n        the device (`CPU` or `GPU`). If the scope is not explicitly set, it will\n        return `None`.\n    \"\"\"\n    g = tf.get_default_graph()\n    op = _TfDeviceCaptureOp()\n    g._apply_device_functions(op)\n    return op.device",
        "begin_line": 214,
        "end_line": 225,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010733068584308254,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend._is_current_explicit_device#228",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend._is_current_explicit_device(device_type)",
        "snippet": "def _is_current_explicit_device(device_type):\n    \"\"\"Check if the current device is explicitly set on the device type specified.\n\n    # Arguments\n        device_type: A string containing `GPU` or `CPU` (case-insensitive).\n\n    # Returns\n        A boolean indicating if the current device scope is explicitly set on the device type.\n\n    # Raises\n        ValueError: If the `device_type` string indicates an unsupported device.\n    \"\"\"\n    device_type = device_type.upper()\n    if device_type not in ['CPU', 'GPU']:\n        raise ValueError('device_type should be either \"CPU\" or \"GPU\".')\n    device = _get_current_tf_device()\n    return (device is not None and device.device_type == device_type.upper())",
        "begin_line": 228,
        "end_line": 244,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010733068584308254,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend._get_available_gpus#247",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend._get_available_gpus()",
        "snippet": "def _get_available_gpus():\n    \"\"\"Get a list of available gpu devices (formatted as strings).\n\n    # Returns\n        A list of available GPU devices.\n    \"\"\"\n    return [x.name for x in _LOCAL_DEVICES if x.device_type == 'GPU']",
        "begin_line": 247,
        "end_line": 253,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010733068584308254,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend._has_nchw_support#256",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend._has_nchw_support()",
        "snippet": "def _has_nchw_support():\n    \"\"\"Check whether the current scope supports NCHW ops.\n\n    Tensorflow does not support NCHW on CPU. Therefore we check if we are not explicitly put on\n    CPU, and have GPUs available. In this case there will be soft-placing on the GPU device.\n\n    # Returns\n        bool: if the current scope device placement would support nchw\n    \"\"\"\n    explicitly_on_cpu = _is_current_explicit_device('CPU')\n    gpus_available = len(_get_available_gpus()) > 0\n    return (not explicitly_on_cpu and gpus_available)",
        "begin_line": 256,
        "end_line": 267,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010733068584308254,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend._to_tensor#272",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend._to_tensor(x, dtype)",
        "snippet": "def _to_tensor(x, dtype):\n    \"\"\"Convert the input `x` to a tensor of type `dtype`.\n\n    # Arguments\n        x: An object to be converted (numpy array, list, tensors).\n        dtype: The destination type.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.convert_to_tensor(x, dtype=dtype)",
        "begin_line": 272,
        "end_line": 282,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007288629737609329,
            "pseudo_dstar_susp": 0.0007288629737609329,
            "pseudo_tarantula_susp": 0.0007380073800738007,
            "pseudo_op2_susp": 0.0007288629737609329,
            "pseudo_barinel_susp": 0.0007380073800738007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.is_sparse#285",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.is_sparse(tensor)",
        "snippet": "def is_sparse(tensor):\n    \"\"\"Returns whether a tensor is a sparse tensor.\n\n    # Arguments\n        tensor: A tensor instance.\n\n    # Returns\n        A boolean.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> a = K.placeholder((2, 2), sparse=False)\n        >>> print(K.is_sparse(a))\n        False\n        >>> b = K.placeholder((2, 2), sparse=True)\n        >>> print(K.is_sparse(b))\n        True\n    ```\n    \"\"\"\n    return isinstance(tensor, tf.SparseTensor)",
        "begin_line": 285,
        "end_line": 305,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.003472222222222222,
            "pseudo_dstar_susp": 0.05263157894736842,
            "pseudo_tarantula_susp": 0.0012195121951219512,
            "pseudo_op2_susp": 0.05263157894736842,
            "pseudo_barinel_susp": 0.0012195121951219512
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.to_dense#308",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.to_dense(tensor)",
        "snippet": "def to_dense(tensor):\n    \"\"\"Converts a sparse tensor into a dense tensor and returns it.\n\n    # Arguments\n        tensor: A tensor instance (potentially sparse).\n\n    # Returns\n        A dense tensor.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> b = K.placeholder((2, 2), sparse=True)\n        >>> print(K.is_sparse(b))\n        True\n        >>> c = K.to_dense(b)\n        >>> print(K.is_sparse(c))\n        False\n    ```\n    \"\"\"\n    if is_sparse(tensor):\n        return tf.sparse_tensor_to_dense(tensor)\n    else:\n        return tensor",
        "begin_line": 308,
        "end_line": 331,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.006369426751592357,
            "pseudo_dstar_susp": 0.058823529411764705,
            "pseudo_tarantula_susp": 0.002109704641350211,
            "pseudo_op2_susp": 0.058823529411764705,
            "pseudo_barinel_susp": 0.002109704641350211
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.variable#337",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.variable(value, dtype=None, name=None, constraint=None)",
        "snippet": "def variable(value, dtype=None, name=None, constraint=None):\n    \"\"\"Instantiates a variable and returns it.\n\n    # Arguments\n        value: Numpy array, initial value of the tensor.\n        dtype: Tensor type.\n        name: Optional name string for the tensor.\n        constraint: Optional projection function to be\n            applied to the variable after an optimizer update.\n\n    # Returns\n        A variable instance (with Keras metadata included).\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> val = np.array([[1, 2], [3, 4]])\n        >>> kvar = K.variable(value=val, dtype='float64', name='example_var')\n        >>> K.dtype(kvar)\n        'float64'\n        >>> print(kvar)\n        example_var\n        >>> kvar.eval()\n        array([[ 1.,  2.],\n               [ 3.,  4.]])\n    ```\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if hasattr(value, 'tocoo'):\n        sparse_coo = value.tocoo()\n        indices = np.concatenate((np.expand_dims(sparse_coo.row, 1),\n                                  np.expand_dims(sparse_coo.col, 1)), 1)\n        v = tf.SparseTensor(indices=indices,\n                            values=sparse_coo.data,\n                            dense_shape=sparse_coo.shape)\n        v._keras_shape = sparse_coo.shape\n        v._uses_learning_phase = False\n        return v\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n    if isinstance(value, np.ndarray):\n        v._keras_shape = value.shape\n    elif hasattr(value, 'get_shape'):\n        v._keras_shape = int_shape(value)\n    v._uses_learning_phase = False\n    # TODO: move to Variable constructor when supported in public release.\n    try:\n        v.constraint = constraint\n    except AttributeError:\n        v._constraint = constraint\n    return v",
        "begin_line": 337,
        "end_line": 387,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.010309278350515464,
            "pseudo_dstar_susp": 0.14285714285714285,
            "pseudo_tarantula_susp": 0.0021008403361344537,
            "pseudo_op2_susp": 0.14285714285714285,
            "pseudo_barinel_susp": 0.0021008403361344537
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.constant#390",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.constant(value, dtype=None, shape=None, name=None)",
        "snippet": "def constant(value, dtype=None, shape=None, name=None):\n    \"\"\"Creates a constant tensor.\n\n    # Arguments\n        value: A constant value (or list)\n        dtype: The type of the elements of the resulting tensor.\n        shape: Optional dimensions of resulting tensor.\n        name: Optional name for the tensor.\n\n    # Returns\n        A Constant Tensor.\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    return tf.constant(value, dtype=dtype, shape=shape, name=name)",
        "begin_line": 390,
        "end_line": 404,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001652892561983471,
            "pseudo_dstar_susp": 0.00909090909090909,
            "pseudo_tarantula_susp": 0.0010787486515641855,
            "pseudo_op2_susp": 0.00909090909090909,
            "pseudo_barinel_susp": 0.0010787486515641855
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.is_keras_tensor#407",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.is_keras_tensor(x)",
        "snippet": "def is_keras_tensor(x):\n    \"\"\"Returns whether `x` is a Keras tensor.\n\n    A \"Keras tensor\" is a tensor that was returned by a Keras layer,\n    (`Layer` class) or by `Input`.\n\n    # Arguments\n        x: A candidate tensor.\n\n    # Returns\n        A boolean: Whether the argument is a Keras tensor.\n\n    # Raises\n        ValueError: In case `x` is not a symbolic tensor.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> from keras.layers import Input, Dense\n        >>> np_var = numpy.array([1, 2])\n        >>> K.is_keras_tensor(np_var) # A numpy array is not a symbolic tensor.\n        ValueError\n        >>> k_var = tf.placeholder('float32', shape=(1,1))\n        >>> K.is_keras_tensor(k_var) # A variable indirectly created outside of keras is not a Keras tensor.\n        False\n        >>> keras_var = K.variable(np_var)\n        >>> K.is_keras_tensor(keras_var)  # A variable created with the keras backend is not a Keras tensor.\n        False\n        >>> keras_placeholder = K.placeholder(shape=(2, 4, 5))\n        >>> K.is_keras_tensor(keras_placeholder)  # A placeholder is not a Keras tensor.\n        False\n        >>> keras_input = Input([10])\n        >>> K.is_keras_tensor(keras_input) # An Input is a Keras tensor.\n        True\n        >>> keras_layer_output = Dense(10)(keras_input)\n        >>> K.is_keras_tensor(keras_layer_output) # Any Keras layer output is a Keras tensor.\n        True\n    ```\n    \"\"\"\n    if not isinstance(x, (tf.Tensor,\n                          tf_variables.Variable,\n                          tf.SparseTensor)):\n        raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) + '`. '\n                         'Expected a symbolic tensor instance.')\n    return hasattr(x, '_keras_history')",
        "begin_line": 407,
        "end_line": 451,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005652911249293386,
            "pseudo_dstar_susp": 0.0005652911249293386,
            "pseudo_tarantula_susp": 0.0005652911249293386,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.0005652911249293386
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.placeholder#454",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.placeholder(shape=None, ndim=None, dtype=None, sparse=False, name=None)",
        "snippet": "def placeholder(shape=None, ndim=None, dtype=None, sparse=False, name=None):\n    \"\"\"Instantiates a placeholder tensor and returns it.\n\n    # Arguments\n        shape: Shape of the placeholder\n            (integer tuple, may include `None` entries).\n        ndim: Number of axes of the tensor.\n            At least one of {`shape`, `ndim`} must be specified.\n            If both are specified, `shape` is used.\n        dtype: Placeholder type.\n        sparse: Boolean, whether the placeholder should have a sparse type.\n        name: Optional name string for the placeholder.\n\n    # Returns\n        Tensor instance (with Keras metadata included).\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> input_ph = K.placeholder(shape=(2, 4, 5))\n        >>> input_ph._keras_shape\n        (2, 4, 5)\n        >>> input_ph\n        <tf.Tensor 'Placeholder_4:0' shape=(2, 4, 5) dtype=float32>\n    ```\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if not shape:\n        if ndim:\n            shape = tuple([None for _ in range(ndim)])\n    if sparse:\n        x = tf.sparse_placeholder(dtype, shape=shape, name=name)\n    else:\n        x = tf.placeholder(dtype, shape=shape, name=name)\n    x._keras_shape = shape\n    x._uses_learning_phase = False\n    return x",
        "begin_line": 454,
        "end_line": 491,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005515719801434088,
            "pseudo_dstar_susp": 0.0005515719801434088,
            "pseudo_tarantula_susp": 0.0005515719801434088,
            "pseudo_op2_susp": 0.0005515719801434088,
            "pseudo_barinel_susp": 0.0005515719801434088
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.is_placeholder#494",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.is_placeholder(x)",
        "snippet": "def is_placeholder(x):\n    \"\"\"Returns whether `x` is a placeholder.\n\n    # Arguments\n        x: A candidate placeholder.\n\n    # Returns\n        Boolean.\n    \"\"\"\n    try:\n        return x.op.type == 'Placeholder'\n    except AttributeError:\n        return False",
        "begin_line": 494,
        "end_line": 506,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.shape#509",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.shape(x)",
        "snippet": "def shape(x):\n    \"\"\"Returns the symbolic shape of a tensor or variable.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A symbolic shape (which is itself a tensor).\n\n    # Examples\n    ```python\n        # TensorFlow example\n        >>> from keras import backend as K\n        >>> tf_session = K.get_session()\n        >>> val = np.array([[1, 2], [3, 4]])\n        >>> kvar = K.variable(value=val)\n        >>> inputs = keras.backend.placeholder(shape=(2, 4, 5))\n        >>> K.shape(kvar)\n        <tf.Tensor 'Shape_8:0' shape=(2,) dtype=int32>\n        >>> K.shape(inputs)\n        <tf.Tensor 'Shape_9:0' shape=(3,) dtype=int32>\n        # To get integer shape (Instead, you can use K.int_shape(x))\n        >>> K.shape(kvar).eval(session=tf_session)\n        array([2, 2], dtype=int32)\n        >>> K.shape(inputs).eval(session=tf_session)\n        array([2, 4, 5], dtype=int32)\n    ```\n    \"\"\"\n    return tf.shape(x)",
        "begin_line": 509,
        "end_line": 537,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010630381630700542,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.int_shape#540",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.int_shape(x)",
        "snippet": "def int_shape(x):\n    \"\"\"Returns the shape of tensor or variable as a tuple of int or None entries.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tuple of integers (or None entries).\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> inputs = K.placeholder(shape=(2, 4, 5))\n        >>> K.int_shape(inputs)\n        (2, 4, 5)\n        >>> val = np.array([[1, 2], [3, 4]])\n        >>> kvar = K.variable(value=val)\n        >>> K.int_shape(kvar)\n        (2, 2)\n    ```\n    \"\"\"\n    if hasattr(x, '_keras_shape'):\n        return x._keras_shape\n    try:\n        return tuple(x.get_shape().as_list())\n    except ValueError:\n        return None",
        "begin_line": 540,
        "end_line": 566,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02127659574468085,
            "pseudo_dstar_susp": 0.019230769230769232,
            "pseudo_tarantula_susp": 0.023255813953488372,
            "pseudo_op2_susp": 0.019230769230769232,
            "pseudo_barinel_susp": 0.023255813953488372
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.ndim#569",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.ndim(x)",
        "snippet": "def ndim(x):\n    \"\"\"Returns the number of axes in a tensor, as an integer.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        Integer (scalar), number of axes.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> inputs = K.placeholder(shape=(2, 4, 5))\n        >>> val = np.array([[1, 2], [3, 4]])\n        >>> kvar = K.variable(value=val)\n        >>> K.ndim(inputs)\n        3\n        >>> K.ndim(kvar)\n        2\n    ```\n    \"\"\"\n    dims = x.get_shape()._dims\n    if dims is not None:\n        return len(dims)\n    return None",
        "begin_line": 569,
        "end_line": 593,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009442870632672333,
            "pseudo_dstar_susp": 0.0029850746268656717,
            "pseudo_tarantula_susp": 0.001152073732718894,
            "pseudo_op2_susp": 0.0029850746268656717,
            "pseudo_barinel_susp": 0.001152073732718894
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.dtype#596",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.dtype(x)",
        "snippet": "def dtype(x):\n    \"\"\"Returns the dtype of a Keras tensor or variable, as a string.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        String, dtype of `x`.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> K.dtype(K.placeholder(shape=(2,4,5)))\n        'float32'\n        >>> K.dtype(K.placeholder(shape=(2,4,5), dtype='float32'))\n        'float32'\n        >>> K.dtype(K.placeholder(shape=(2,4,5), dtype='float64'))\n        'float64'\n        # Keras variable\n        >>> kvar = K.variable(np.array([[1, 2], [3, 4]]))\n        >>> K.dtype(kvar)\n        'float32_ref'\n        >>> kvar = K.variable(np.array([[1, 2], [3, 4]]), dtype='float32')\n        >>> K.dtype(kvar)\n        'float32_ref'\n    ```\n    \"\"\"\n    return x.dtype.base_dtype.name",
        "begin_line": 596,
        "end_line": 623,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006816632583503749,
            "pseudo_dstar_susp": 0.0006816632583503749,
            "pseudo_tarantula_susp": 0.0006872852233676976,
            "pseudo_op2_susp": 0.0006816632583503749,
            "pseudo_barinel_susp": 0.0006872852233676976
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.eval#626",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.eval(x)",
        "snippet": "def eval(x):\n    \"\"\"Evaluates the value of a variable.\n\n    # Arguments\n        x: A variable.\n\n    # Returns\n        A Numpy array.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.variable(np.array([[1, 2], [3, 4]]), dtype='float32')\n        >>> K.eval(kvar)\n        array([[ 1.,  2.],\n               [ 3.,  4.]], dtype=float32)\n    ```\n    \"\"\"\n    return to_dense(x).eval(session=get_session())",
        "begin_line": 626,
        "end_line": 644,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.006289308176100629,
            "pseudo_dstar_susp": 0.023255813953488372,
            "pseudo_tarantula_susp": 0.002320185614849188,
            "pseudo_op2_susp": 0.023255813953488372,
            "pseudo_barinel_susp": 0.002320185614849188
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.zeros#647",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.zeros(shape, dtype=None, name=None)",
        "snippet": "def zeros(shape, dtype=None, name=None):\n    \"\"\"Instantiates an all-zeros variable and returns it.\n\n    # Arguments\n        shape: Tuple of integers, shape of returned Keras variable\n        dtype: String, data type of returned Keras variable\n        name: String, name of returned Keras variable\n\n    # Returns\n        A variable (including Keras metadata), filled with `0.0`.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.zeros((3,4))\n        >>> K.eval(kvar)\n        array([[ 0.,  0.,  0.,  0.],\n               [ 0.,  0.,  0.,  0.],\n               [ 0.,  0.,  0.,  0.]], dtype=float32)\n    ```\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    tf_dtype = tf.as_dtype(dtype)\n    return variable(tf.constant_initializer(0., dtype=tf_dtype)(shape),\n                    dtype, name)",
        "begin_line": 647,
        "end_line": 672,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.411764705882353e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.ones#675",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.ones(shape, dtype=None, name=None)",
        "snippet": "def ones(shape, dtype=None, name=None):\n    \"\"\"Instantiates an all-ones tensor variable and returns it.\n\n    # Arguments\n        shape: Tuple of integers, shape of returned Keras variable.\n        dtype: String, data type of returned Keras variable.\n        name: String, name of returned Keras variable.\n\n    # Returns\n        A Keras variable, filled with `1.0`.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.ones((3,4))\n        >>> K.eval(kvar)\n        array([[ 1.,  1.,  1.,  1.],\n               [ 1.,  1.,  1.,  1.],\n               [ 1.,  1.,  1.,  1.]], dtype=float32)\n    ```\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    tf_dtype = tf.as_dtype(dtype)\n    return variable(tf.constant_initializer(1., dtype=tf_dtype)(shape),\n                    dtype, name)",
        "begin_line": 675,
        "end_line": 700,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.eye#703",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.eye(size, dtype=None, name=None)",
        "snippet": "def eye(size, dtype=None, name=None):\n    \"\"\"Instantiate an identity matrix and returns it.\n\n    # Arguments\n        size: Integer, number of rows/columns.\n        dtype: String, data type of returned Keras variable.\n        name: String, name of returned Keras variable.\n\n    # Returns\n        A Keras variable, an identity matrix.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.eye(3)\n        >>> K.eval(kvar)\n        array([[ 1.,  0.,  0.],\n               [ 0.,  1.,  0.],\n               [ 0.,  0.,  1.]], dtype=float32)\n    ```\n\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    tf_dtype = tf.as_dtype(dtype)\n    return variable(tf.eye(size, dtype=tf_dtype), dtype, name)",
        "begin_line": 703,
        "end_line": 728,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.zeros_like#731",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.zeros_like(x, dtype=None, name=None)",
        "snippet": "def zeros_like(x, dtype=None, name=None):\n    \"\"\"Instantiates an all-zeros variable of the same shape as another tensor.\n\n    # Arguments\n        x: Keras variable or Keras tensor.\n        dtype: String, dtype of returned Keras variable.\n             None uses the dtype of x.\n        name: String, name for the variable to create.\n\n    # Returns\n        A Keras variable with the shape of x filled with zeros.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.variable(np.random.random((2,3)))\n        >>> kvar_zeros = K.zeros_like(kvar)\n        >>> K.eval(kvar_zeros)\n        array([[ 0.,  0.,  0.],\n               [ 0.,  0.,  0.]], dtype=float32)\n    ```\n    \"\"\"\n    return tf.zeros_like(x, dtype=dtype, name=name)",
        "begin_line": 731,
        "end_line": 753,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.784735812133073e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.ones_like#756",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.ones_like(x, dtype=None, name=None)",
        "snippet": "def ones_like(x, dtype=None, name=None):\n    \"\"\"Instantiates an all-ones variable of the same shape as another tensor.\n\n    # Arguments\n        x: Keras variable or tensor.\n        dtype: String, dtype of returned Keras variable.\n             None uses the dtype of x.\n        name: String, name for the variable to create.\n\n    # Returns\n        A Keras variable with the shape of x filled with ones.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.variable(np.random.random((2,3)))\n        >>> kvar_ones = K.ones_like(kvar)\n        >>> K.eval(kvar_ones)\n        array([[ 1.,  1.,  1.],\n               [ 1.,  1.,  1.]], dtype=float32)\n    ```\n    \"\"\"\n    return tf.ones_like(x, dtype=dtype, name=name)",
        "begin_line": 756,
        "end_line": 778,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001152604887044721,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.identity#781",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.identity(x, name=None)",
        "snippet": "def identity(x, name=None):\n    \"\"\"Returns a tensor with the same content as the input tensor.\n\n    # Arguments\n        x: The input tensor.\n        name: String, name for the variable to create.\n\n    # Returns\n        A tensor of the same shape, type and content.\n    \"\"\"\n    return tf.identity(x, name)",
        "begin_line": 781,
        "end_line": 791,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00012818869375721061,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.random_uniform_variable#794",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.random_uniform_variable(shape, low, high, dtype=None, name=None, seed=None)",
        "snippet": "def random_uniform_variable(shape, low, high, dtype=None,\n                            name=None, seed=None):\n    \"\"\"Instantiates a variable with values drawn from a uniform distribution.\n\n    # Arguments\n        shape: Tuple of integers, shape of returned Keras variable.\n        low: Float, lower boundary of the output interval.\n        high: Float, upper boundary of the output interval.\n        dtype: String, dtype of returned Keras variable.\n        name: String, name of returned Keras variable.\n        seed: Integer, random seed.\n\n    # Returns\n        A Keras variable, filled with drawn samples.\n\n    # Example\n    ```python\n        # TensorFlow example\n        >>> kvar = K.random_uniform_variable((2,3), 0, 1)\n        >>> kvar\n        <tensorflow.python.ops.variables.Variable object at 0x10ab40b10>\n        >>> K.eval(kvar)\n        array([[ 0.10940075,  0.10047495,  0.476143  ],\n               [ 0.66137183,  0.00869417,  0.89220798]], dtype=float32)\n    ```\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    tf_dtype = tf.as_dtype(dtype)\n    if seed is None:\n        # ensure that randomness is conditioned by the Numpy RNG\n        seed = np.random.randint(10e8)\n    value = tf.random_uniform_initializer(\n        low, high, dtype=tf_dtype, seed=seed)(shape)\n    return variable(value, dtype=dtype, name=name)",
        "begin_line": 794,
        "end_line": 828,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.random_normal_variable#831",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.random_normal_variable(shape, mean, scale, dtype=None, name=None, seed=None)",
        "snippet": "def random_normal_variable(shape, mean, scale, dtype=None,\n                           name=None, seed=None):\n    \"\"\"Instantiates a variable with values drawn from a normal distribution.\n\n    # Arguments\n        shape: Tuple of integers, shape of returned Keras variable.\n        mean: Float, mean of the normal distribution.\n        scale: Float, standard deviation of the normal distribution.\n        dtype: String, dtype of returned Keras variable.\n        name: String, name of returned Keras variable.\n        seed: Integer, random seed.\n\n    # Returns\n        A Keras variable, filled with drawn samples.\n\n    # Example\n    ```python\n        # TensorFlow example\n        >>> kvar = K.random_normal_variable((2,3), 0, 1)\n        >>> kvar\n        <tensorflow.python.ops.variables.Variable object at 0x10ab12dd0>\n        >>> K.eval(kvar)\n        array([[ 1.19591331,  0.68685907, -0.63814116],\n               [ 0.92629528,  0.28055015,  1.70484698]], dtype=float32)\n    ```\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    tf_dtype = tf.as_dtype(dtype)\n    if seed is None:\n        # ensure that randomness is conditioned by the Numpy RNG\n        seed = np.random.randint(10e8)\n    value = tf.random_normal_initializer(\n        mean, scale, dtype=tf_dtype, seed=seed)(shape)\n    return variable(value, dtype=dtype, name=name)",
        "begin_line": 831,
        "end_line": 865,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.count_params#868",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.count_params(x)",
        "snippet": "def count_params(x):\n    \"\"\"Returns the static number of elements in a Keras variable or tensor.\n\n    # Arguments\n        x: Keras variable or tensor.\n\n    # Returns\n        Integer, the number of elements in `x`, i.e., the product of the\n        array's static dimensions.\n\n    # Example\n    ```python\n        >>> kvar = K.zeros((2,3))\n        >>> K.count_params(kvar)\n        6\n        >>> K.eval(kvar)\n        array([[ 0.,  0.,  0.],\n               [ 0.,  0.,  0.]], dtype=float32)\n    ```\n    \"\"\"\n    return np.prod(get_variable_shape(x))",
        "begin_line": 868,
        "end_line": 888,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007336757153338225,
            "pseudo_dstar_susp": 0.0007336757153338225,
            "pseudo_tarantula_susp": 0.0007429420505200594,
            "pseudo_op2_susp": 0.0007336757153338225,
            "pseudo_barinel_susp": 0.0007429420505200594
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.cast#891",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.cast(x, dtype)",
        "snippet": "def cast(x, dtype):\n    \"\"\"Casts a tensor to a different dtype and returns it.\n\n    You can cast a Keras variable but it still returns a Keras tensor.\n\n    # Arguments\n        x: Keras tensor (or variable).\n        dtype: String, either (`'float16'`, `'float32'`, or `'float64'`).\n\n    # Returns\n        Keras tensor with dtype `dtype`.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> input = K.placeholder((2, 3), dtype='float32')\n        >>> input\n        <tf.Tensor 'Placeholder_2:0' shape=(2, 3) dtype=float32>\n        # It doesn't work in-place as below.\n        >>> K.cast(input, dtype='float16')\n        <tf.Tensor 'Cast_1:0' shape=(2, 3) dtype=float16>\n        >>> input\n        <tf.Tensor 'Placeholder_2:0' shape=(2, 3) dtype=float32>\n        # you need to assign it.\n        >>> input = K.cast(input, dtype='float16')\n        >>> input\n        <tf.Tensor 'Cast_2:0' shape=(2, 3) dtype=float16>\n    ```\n    \"\"\"\n    return tf.cast(x, dtype)",
        "begin_line": 891,
        "end_line": 920,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 8.703977717817043e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.update#926",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.update(x, new_x)",
        "snippet": "def update(x, new_x):\n    \"\"\"Update the value of `x` to `new_x`.\n\n    # Arguments\n        x: A `Variable`.\n        new_x: A tensor of same shape as `x`.\n\n    # Returns\n        The variable `x` updated.\n    \"\"\"\n    return tf.assign(x, new_x)",
        "begin_line": 926,
        "end_line": 936,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.044862518089724e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.update_add#939",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.update_add(x, increment)",
        "snippet": "def update_add(x, increment):\n    \"\"\"Update the value of `x` by adding `increment`.\n\n    # Arguments\n        x: A `Variable`.\n        increment: A tensor of same shape as `x`.\n\n    # Returns\n        The variable `x` updated.\n    \"\"\"\n    return tf.assign_add(x, increment)",
        "begin_line": 939,
        "end_line": 949,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 8.901548869503294e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.moving_average_update#965",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.moving_average_update(x, value, momentum)",
        "snippet": "def moving_average_update(x, value, momentum):\n    \"\"\"Compute the moving average of a variable.\n\n    # Arguments\n        x: A `Variable`.\n        value: A tensor with the same shape as `x`.\n        momentum: The moving average momentum.\n\n    # Returns\n        An operation to update the variable.\n    \"\"\"\n    return moving_averages.assign_moving_average(\n        x, value, momentum, zero_debias=False)",
        "begin_line": 965,
        "end_line": 977,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001006947940791461,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.dot#982",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.dot(x, y)",
        "snippet": "def dot(x, y):\n    \"\"\"Multiplies 2 tensors (and/or variables) and returns a *tensor*.\n\n    When attempting to multiply a nD tensor\n    with a nD tensor, it reproduces the Theano behavior.\n    (e.g. `(2, 3) * (4, 3, 5) -> (2, 4, 5)`)\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A tensor, dot product of `x` and `y`.\n\n    # Examples\n    ```python\n        # dot product between tensors\n        >>> x = K.placeholder(shape=(2, 3))\n        >>> y = K.placeholder(shape=(3, 4))\n        >>> xy = K.dot(x, y)\n        >>> xy\n        <tf.Tensor 'MatMul_9:0' shape=(2, 4) dtype=float32>\n    ```\n\n    ```python\n        # dot product between tensors\n        >>> x = K.placeholder(shape=(32, 28, 3))\n        >>> y = K.placeholder(shape=(3, 4))\n        >>> xy = K.dot(x, y)\n        >>> xy\n        <tf.Tensor 'MatMul_9:0' shape=(32, 28, 4) dtype=float32>\n    ```\n\n    ```python\n        # Theano-like behavior example\n        >>> x = K.random_uniform_variable(shape=(2, 3), low=0, high=1)\n        >>> y = K.ones((4, 3, 5))\n        >>> xy = K.dot(x, y)\n        >>> K.int_shape(xy)\n        (2, 4, 5)\n    ```\n    \"\"\"\n    if ndim(x) is not None and (ndim(x) > 2 or ndim(y) > 2):\n        x_shape = []\n        for i, s in zip(int_shape(x), tf.unstack(tf.shape(x))):\n            if i is not None:\n                x_shape.append(i)\n            else:\n                x_shape.append(s)\n        x_shape = tuple(x_shape)\n        y_shape = []\n        for i, s in zip(int_shape(y), tf.unstack(tf.shape(y))):\n            if i is not None:\n                y_shape.append(i)\n            else:\n                y_shape.append(s)\n        y_shape = tuple(y_shape)\n        y_permute_dim = list(range(ndim(y)))\n        y_permute_dim = [y_permute_dim.pop(-2)] + y_permute_dim\n        xt = tf.reshape(x, [-1, x_shape[-1]])\n        yt = tf.reshape(tf.transpose(y, perm=y_permute_dim), [y_shape[-2], -1])\n        return tf.reshape(tf.matmul(xt, yt),\n                          x_shape[:-1] + y_shape[:-2] + y_shape[-1:])\n    if is_sparse(x):\n        out = tf.sparse_tensor_dense_matmul(x, y)\n    else:\n        out = tf.matmul(x, y)\n    return out",
        "begin_line": 982,
        "end_line": 1049,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.003663003663003663,
            "pseudo_dstar_susp": 0.00267379679144385,
            "pseudo_tarantula_susp": 0.00411522633744856,
            "pseudo_op2_susp": 0.00267379679144385,
            "pseudo_barinel_susp": 0.00411522633744856
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.batch_dot#1052",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.batch_dot(x, y, axes=None)",
        "snippet": "def batch_dot(x, y, axes=None):\n    \"\"\"Batchwise dot product.\n\n    `batch_dot` is used to compute dot product of `x` and `y` when\n    `x` and `y` are data in batch, i.e. in a shape of\n    `(batch_size, :)`.\n    `batch_dot` results in a tensor or variable with less dimensions\n    than the input. If the number of dimensions is reduced to 1,\n    we use `expand_dims` to make sure that ndim is at least 2.\n\n    # Arguments\n        x: Keras tensor or variable with `ndim >= 2`.\n        y: Keras tensor or variable with `ndim >= 2`.\n        axes: list of (or single) int with target dimensions.\n            The lengths of `axes[0]` and `axes[1]` should be the same.\n\n    # Returns\n        A tensor with shape equal to the concatenation of `x`'s shape\n        (less the dimension that was summed over) and `y`'s shape\n        (less the batch dimension and the dimension that was summed over).\n        If the final rank is 1, we reshape it to `(batch_size, 1)`.\n\n    # Examples\n        Assume `x = [[1, 2], [3, 4]]` and `y = [[5, 6], [7, 8]]`\n        `batch_dot(x, y, axes=1) = [[17, 53]]` which is the main diagonal\n        of `x.dot(y.T)`, although we never have to calculate the off-diagonal\n        elements.\n\n        Shape inference:\n        Let `x`'s shape be `(100, 20)` and `y`'s shape be `(100, 30, 20)`.\n        If `axes` is (1, 2), to find the output shape of resultant tensor,\n            loop through each dimension in `x`'s shape and `y`'s shape:\n\n        * `x.shape[0]` : 100 : append to output shape\n        * `x.shape[1]` : 20 : do not append to output shape,\n            dimension 1 of `x` has been summed over. (`dot_axes[0]` = 1)\n        * `y.shape[0]` : 100 : do not append to output shape,\n            always ignore first dimension of `y`\n        * `y.shape[1]` : 30 : append to output shape\n        * `y.shape[2]` : 20 : do not append to output shape,\n            dimension 2 of `y` has been summed over. (`dot_axes[1]` = 2)\n        `output_shape` = `(100, 30)`\n\n    ```python\n        >>> x_batch = K.ones(shape=(32, 20, 1))\n        >>> y_batch = K.ones(shape=(32, 30, 20))\n        >>> xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])\n        >>> K.int_shape(xy_batch_dot)\n        (32, 1, 30)\n    ```\n    \"\"\"\n    if isinstance(axes, int):\n        axes = (axes, axes)\n    x_ndim = ndim(x)\n    y_ndim = ndim(y)\n    if x_ndim > y_ndim:\n        diff = x_ndim - y_ndim\n        y = tf.reshape(y, tf.concat([tf.shape(y), [1] * (diff)], axis=0))\n    elif y_ndim > x_ndim:\n        diff = y_ndim - x_ndim\n        x = tf.reshape(x, tf.concat([tf.shape(x), [1] * (diff)], axis=0))\n    else:\n        diff = 0\n    if ndim(x) == 2 and ndim(y) == 2:\n        if axes[0] == axes[1]:\n            out = tf.reduce_sum(tf.multiply(x, y), axes[0])\n        else:\n            out = tf.reduce_sum(tf.multiply(tf.transpose(x, [1, 0]), y), axes[1])\n    else:\n        if axes is not None:\n            adj_x = None if axes[0] == ndim(x) - 1 else True\n            adj_y = True if axes[1] == ndim(y) - 1 else None\n        else:\n            adj_x = None\n            adj_y = None\n        out = tf.matmul(x, y, adjoint_a=adj_x, adjoint_b=adj_y)\n    if diff:\n        if x_ndim > y_ndim:\n            idx = x_ndim + y_ndim - 3\n        else:\n            idx = x_ndim - 1\n        out = tf.squeeze(out, list(range(idx, idx + diff)))\n    if ndim(out) == 1:\n        out = expand_dims(out, 1)\n    return out",
        "begin_line": 1052,
        "end_line": 1136,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02127659574468085,
            "pseudo_dstar_susp": 0.0022675736961451248,
            "pseudo_tarantula_susp": 0.023255813953488372,
            "pseudo_op2_susp": 0.0022675736961451248,
            "pseudo_barinel_susp": 0.023255813953488372
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.transpose#1139",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.transpose(x)",
        "snippet": "def transpose(x):\n    \"\"\"Transposes a tensor and returns it.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n\n    # Examples\n    ```python\n        >>> var = K.variable([[1, 2, 3], [4, 5, 6]])\n        >>> K.eval(var)\n        array([[ 1.,  2.,  3.],\n               [ 4.,  5.,  6.]], dtype=float32)\n        >>> var_transposed = K.transpose(var)\n        >>> K.eval(var_transposed)\n        array([[ 1.,  4.],\n               [ 2.,  5.],\n               [ 3.,  6.]], dtype=float32)\n    ```\n\n    ```python\n        >>> inputs = K.placeholder((2, 3))\n        >>> inputs\n        <tf.Tensor 'Placeholder_11:0' shape=(2, 3) dtype=float32>\n        >>> input_transposed = K.transpose(inputs)\n        >>> input_transposed\n        <tf.Tensor 'transpose_4:0' shape=(3, 2) dtype=float32>\n\n    ```\n    \"\"\"\n    return tf.transpose(x)",
        "begin_line": 1139,
        "end_line": 1171,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02127659574468085,
            "pseudo_dstar_susp": 0.0022675736961451248,
            "pseudo_tarantula_susp": 0.023255813953488372,
            "pseudo_op2_susp": 0.0022675736961451248,
            "pseudo_barinel_susp": 0.023255813953488372
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.gather#1174",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.gather(reference, indices)",
        "snippet": "def gather(reference, indices):\n    \"\"\"Retrieves the elements of indices `indices` in the tensor `reference`.\n\n    # Arguments\n        reference: A tensor.\n        indices: An integer tensor of indices.\n\n    # Returns\n        A tensor of same type as `reference`.\n    \"\"\"\n    return tf.gather(reference, indices)",
        "begin_line": 1174,
        "end_line": 1184,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010793308148947653,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.max#1190",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.max(x, axis=None, keepdims=False)",
        "snippet": "def max(x, axis=None, keepdims=False):\n    \"\"\"Maximum value in a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to find maximum values.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with maximum values of `x`.\n    \"\"\"\n    return tf.reduce_max(x, axis=axis, keep_dims=keepdims)",
        "begin_line": 1190,
        "end_line": 1204,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0014144271570014145,
            "pseudo_dstar_susp": 0.0011904761904761906,
            "pseudo_tarantula_susp": 0.0020964360587002098,
            "pseudo_op2_susp": 0.0011904761904761906,
            "pseudo_barinel_susp": 0.0020964360587002098
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.min#1207",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.min(x, axis=None, keepdims=False)",
        "snippet": "def min(x, axis=None, keepdims=False):\n    \"\"\"Minimum value in a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to find minimum values.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with miminum values of `x`.\n    \"\"\"\n    return tf.reduce_min(x, axis=axis, keep_dims=keepdims)",
        "begin_line": 1207,
        "end_line": 1221,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02127659574468085,
            "pseudo_dstar_susp": 0.0022675736961451248,
            "pseudo_tarantula_susp": 0.023255813953488372,
            "pseudo_op2_susp": 0.0022675736961451248,
            "pseudo_barinel_susp": 0.023255813953488372
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.sum#1224",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.sum(x, axis=None, keepdims=False)",
        "snippet": "def sum(x, axis=None, keepdims=False):\n    \"\"\"Sum of the values in a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to sum over.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with sum of `x`.\n    \"\"\"\n    return tf.reduce_sum(x, axis=axis, keep_dims=keepdims)",
        "begin_line": 1224,
        "end_line": 1238,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.311853990129435e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.prod#1241",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.prod(x, axis=None, keepdims=False)",
        "snippet": "def prod(x, axis=None, keepdims=False):\n    \"\"\"Multiplies the values in a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to compute the product.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with the product of elements of `x`.\n    \"\"\"\n    return tf.reduce_prod(x, axis=axis, keep_dims=keepdims)",
        "begin_line": 1241,
        "end_line": 1255,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0025575447570332483,
            "pseudo_dstar_susp": 0.0014992503748125937,
            "pseudo_tarantula_susp": 0.0035335689045936395,
            "pseudo_op2_susp": 0.0014992503748125937,
            "pseudo_barinel_susp": 0.0035335689045936395
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.cumsum#1258",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.cumsum(x, axis=0)",
        "snippet": "def cumsum(x, axis=0):\n    \"\"\"Cumulative sum of the values in a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to compute the sum.\n\n    # Returns\n        A tensor of the cumulative sum of values of `x` along `axis`.\n    \"\"\"\n    return tf.cumsum(x, axis=axis)",
        "begin_line": 1258,
        "end_line": 1268,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02127659574468085,
            "pseudo_dstar_susp": 0.0022675736961451248,
            "pseudo_tarantula_susp": 0.023255813953488372,
            "pseudo_op2_susp": 0.0022675736961451248,
            "pseudo_barinel_susp": 0.023255813953488372
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.var#1284",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.var(x, axis=None, keepdims=False)",
        "snippet": "def var(x, axis=None, keepdims=False):\n    \"\"\"Variance of a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to compute the variance.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with the variance of elements of `x`.\n    \"\"\"\n    if x.dtype.base_dtype == tf.bool:\n        x = tf.cast(x, floatx())\n    m = tf.reduce_mean(x, axis=axis, keep_dims=True)\n    devs_squared = tf.square(x - m)\n    return tf.reduce_mean(devs_squared,\n                          axis=axis,\n                          keep_dims=keepdims)",
        "begin_line": 1284,
        "end_line": 1304,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02127659574468085,
            "pseudo_dstar_susp": 0.0022675736961451248,
            "pseudo_tarantula_susp": 0.023255813953488372,
            "pseudo_op2_susp": 0.0022675736961451248,
            "pseudo_barinel_susp": 0.023255813953488372
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.std#1307",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.std(x, axis=None, keepdims=False)",
        "snippet": "def std(x, axis=None, keepdims=False):\n    \"\"\"Standard deviation of a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to compute the standard deviation.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with the standard deviation of elements of `x`.\n    \"\"\"\n    return tf.sqrt(var(x, axis=axis, keepdims=keepdims))",
        "begin_line": 1307,
        "end_line": 1321,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02127659574468085,
            "pseudo_dstar_susp": 0.0022675736961451248,
            "pseudo_tarantula_susp": 0.023255813953488372,
            "pseudo_op2_susp": 0.0022675736961451248,
            "pseudo_barinel_susp": 0.023255813953488372
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.mean#1324",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.mean(x, axis=None, keepdims=False)",
        "snippet": "def mean(x, axis=None, keepdims=False):\n    \"\"\"Mean of a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: A list of integer. Axes to compute the mean.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1 for each entry in `axis`. If `keep_dims` is `True`,\n            the reduced dimensions are retained with length 1.\n\n    # Returns\n        A tensor with the mean of elements of `x`.\n    \"\"\"\n    if x.dtype.base_dtype == tf.bool:\n        x = tf.cast(x, floatx())\n    return tf.reduce_mean(x, axis=axis, keep_dims=keepdims)",
        "begin_line": 1324,
        "end_line": 1340,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007042253521126761,
            "pseudo_dstar_susp": 0.0007042253521126761,
            "pseudo_tarantula_susp": 0.0007107320540156361,
            "pseudo_op2_susp": 0.0007042253521126761,
            "pseudo_barinel_susp": 0.0007107320540156361
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.any#1343",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.any(x, axis=None, keepdims=False)",
        "snippet": "def any(x, axis=None, keepdims=False):\n    \"\"\"Bitwise reduction (logical OR).\n\n    # Arguments\n        x: Tensor or variable.\n        axis: axis along which to perform the reduction.\n        keepdims: whether the drop or broadcast the reduction axes.\n\n    # Returns\n        A uint8 tensor (0s and 1s).\n    \"\"\"\n    x = tf.cast(x, tf.bool)\n    return tf.reduce_any(x, axis=axis, keep_dims=keepdims)",
        "begin_line": 1343,
        "end_line": 1355,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001152604887044721,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.all#1358",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.all(x, axis=None, keepdims=False)",
        "snippet": "def all(x, axis=None, keepdims=False):\n    \"\"\"Bitwise reduction (logical AND).\n\n    # Arguments\n        x: Tensor or variable.\n        axis: axis along which to perform the reduction.\n        keepdims: whether the drop or broadcast the reduction axes.\n\n    # Returns\n        A uint8 tensor (0s and 1s).\n    \"\"\"\n    x = tf.cast(x, tf.bool)\n    return tf.reduce_all(x, axis=axis, keep_dims=keepdims)",
        "begin_line": 1358,
        "end_line": 1370,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00012818869375721061,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.argmax#1373",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.argmax(x, axis=-1)",
        "snippet": "def argmax(x, axis=-1):\n    \"\"\"Returns the index of the maximum value along an axis.\n\n    # Arguments\n        x: Tensor or variable.\n        axis: axis along which to perform the reduction.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.argmax(x, axis)",
        "begin_line": 1373,
        "end_line": 1383,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.770395701025892e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.square#1399",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.square(x)",
        "snippet": "def square(x):\n    \"\"\"Element-wise square.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.square(x)",
        "begin_line": 1399,
        "end_line": 1408,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 8.843296781039972e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.abs#1411",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.abs(x)",
        "snippet": "def abs(x):\n    \"\"\"Element-wise absolute value.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.abs(x)",
        "begin_line": 1411,
        "end_line": 1420,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010191602119853241,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.sqrt#1423",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.sqrt(x)",
        "snippet": "def sqrt(x):\n    \"\"\"Element-wise square root.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    zero = _to_tensor(0., x.dtype.base_dtype)\n    inf = _to_tensor(np.inf, x.dtype.base_dtype)\n    x = tf.clip_by_value(x, zero, inf)\n    return tf.sqrt(x)",
        "begin_line": 1423,
        "end_line": 1435,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.119927040583675e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.exp#1438",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.exp(x)",
        "snippet": "def exp(x):\n    \"\"\"Element-wise exponential.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.exp(x)",
        "begin_line": 1438,
        "end_line": 1447,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001152604887044721,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.log#1450",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.log(x)",
        "snippet": "def log(x):\n    \"\"\"Element-wise log.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.log(x)",
        "begin_line": 1450,
        "end_line": 1459,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.logsumexp#1462",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.logsumexp(x, axis=None, keepdims=False)",
        "snippet": "def logsumexp(x, axis=None, keepdims=False):\n    \"\"\"Computes log(sum(exp(elements across dimensions of a tensor))).\n\n    This function is more numerically stable than log(sum(exp(x))).\n    It avoids overflows caused by taking the exp of large inputs and\n    underflows caused by taking the log of small inputs.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer, the axis to reduce over.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`, the reduced dimension is\n            retained with length 1.\n\n    # Returns\n        The reduced tensor.\n    \"\"\"\n    return tf.reduce_logsumexp(x, axis=axis, keep_dims=keepdims)",
        "begin_line": 1462,
        "end_line": 1480,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010793308148947653,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.round#1483",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.round(x)",
        "snippet": "def round(x):\n    \"\"\"Element-wise rounding to the closest integer.\n\n    In case of tie, the rounding mode used is \"half to even\".\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.round(x)",
        "begin_line": 1483,
        "end_line": 1494,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.pow#1509",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.pow(x, a)",
        "snippet": "def pow(x, a):\n    \"\"\"Element-wise exponentiation.\n\n    # Arguments\n        x: Tensor or variable.\n        a: Python integer.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.pow(x, a)",
        "begin_line": 1509,
        "end_line": 1519,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001026694045174538,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.clip#1522",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.clip(x, min_value, max_value)",
        "snippet": "def clip(x, min_value, max_value):\n    \"\"\"Element-wise value clipping.\n\n    # Arguments\n        x: Tensor or variable.\n        min_value: Python float or integer.\n        max_value: Python float or integer.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if max_value is not None and max_value < min_value:\n        max_value = min_value\n    if max_value is None:\n        max_value = np.inf\n    min_value = _to_tensor(min_value, x.dtype.base_dtype)\n    max_value = _to_tensor(max_value, x.dtype.base_dtype)\n    return tf.clip_by_value(x, min_value, max_value)",
        "begin_line": 1522,
        "end_line": 1539,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.equal#1542",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.equal(x, y)",
        "snippet": "def equal(x, y):\n    \"\"\"Element-wise equality between two tensors.\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n    \"\"\"\n    return tf.equal(x, y)",
        "begin_line": 1542,
        "end_line": 1552,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.699321047526673e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.not_equal#1555",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.not_equal(x, y)",
        "snippet": "def not_equal(x, y):\n    \"\"\"Element-wise inequality between two tensors.\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n    \"\"\"\n    return tf.not_equal(x, y)",
        "begin_line": 1555,
        "end_line": 1565,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 8.791981712678038e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.greater#1568",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.greater(x, y)",
        "snippet": "def greater(x, y):\n    \"\"\"Element-wise truth value of (x > y).\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n    \"\"\"\n    return tf.greater(x, y)",
        "begin_line": 1568,
        "end_line": 1578,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.greater_equal#1581",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.greater_equal(x, y)",
        "snippet": "def greater_equal(x, y):\n    \"\"\"Element-wise truth value of (x >= y).\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n    \"\"\"\n    return tf.greater_equal(x, y)",
        "begin_line": 1581,
        "end_line": 1591,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.maximum#1620",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.maximum(x, y)",
        "snippet": "def maximum(x, y):\n    \"\"\"Element-wise maximum of two tensors.\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.maximum(x, y)",
        "begin_line": 1620,
        "end_line": 1630,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010984182776801405,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.minimum#1633",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.minimum(x, y)",
        "snippet": "def minimum(x, y):\n    \"\"\"Element-wise minimum of two tensors.\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.minimum(x, y)",
        "begin_line": 1633,
        "end_line": 1643,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.cos#1658",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.cos(x)",
        "snippet": "def cos(x):\n    \"\"\"Computes cos of x element-wise.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.cos(x)",
        "begin_line": 1658,
        "end_line": 1667,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.normalize_batch_in_training#1670",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.normalize_batch_in_training(x, gamma, beta, reduction_axes, epsilon=0.001)",
        "snippet": "def normalize_batch_in_training(x, gamma, beta,\n                                reduction_axes, epsilon=1e-3):\n    \"\"\"Computes mean and std for batch then apply batch_normalization on batch.\n\n    # Arguments\n        x: Input tensor or variable.\n        gamma: Tensor by which to scale the input.\n        beta: Tensor with which to center the input.\n        reduction_axes: iterable of integers,\n            axes over which to normalize.\n        epsilon: Fuzz factor.\n\n    # Returns\n        A tuple length of 3, `(normalized_tensor, mean, variance)`.\n    \"\"\"\n    mean, var = tf.nn.moments(x, reduction_axes,\n                              shift=None, name=None, keep_dims=False)\n    if sorted(reduction_axes) == list(range(ndim(x)))[:-1]:\n        normed = tf.nn.batch_normalization(x, mean, var,\n                                           beta, gamma,\n                                           epsilon)\n    else:\n        # need broadcasting\n        target_shape = []\n        for axis in range(ndim(x)):\n            if axis in reduction_axes:\n                target_shape.append(1)\n            else:\n                target_shape.append(tf.shape(x)[axis])\n        target_shape = tf.stack(target_shape)\n\n        broadcast_mean = tf.reshape(mean, target_shape)\n        broadcast_var = tf.reshape(var, target_shape)\n        if gamma is None:\n            broadcast_gamma = None\n        else:\n            broadcast_gamma = tf.reshape(gamma, target_shape)\n        if beta is None:\n            broadcast_beta = None\n        else:\n            broadcast_beta = tf.reshape(beta, target_shape)\n        normed = tf.nn.batch_normalization(x, broadcast_mean, broadcast_var,\n                                           broadcast_beta, broadcast_gamma,\n                                           epsilon)\n    return normed, mean, var",
        "begin_line": 1670,
        "end_line": 1714,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.batch_normalization#1717",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.batch_normalization(x, mean, var, beta, gamma, epsilon=0.001)",
        "snippet": "def batch_normalization(x, mean, var, beta, gamma, epsilon=1e-3):\n    \"\"\"Applies batch normalization on x given mean, var, beta and gamma.\n\n    I.e. returns:\n    `output = (x - mean) / (sqrt(var) + epsilon) * gamma + beta`\n\n    # Arguments\n        x: Input tensor or variable.\n        mean: Mean of batch.\n        var: Variance of batch.\n        beta: Tensor with which to center the input.\n        gamma: Tensor by which to scale the input.\n        epsilon: Fuzz factor.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.batch_normalization(x, mean, var, beta, gamma, epsilon)",
        "begin_line": 1717,
        "end_line": 1734,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001006947940791461,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.concatenate#1739",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.concatenate(tensors, axis=-1)",
        "snippet": "def concatenate(tensors, axis=-1):\n    \"\"\"Concatenates a list of tensors alongside the specified axis.\n\n    # Arguments\n        tensors: list of tensors to concatenate.\n        axis: concatenation axis.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if axis < 0:\n        rank = ndim(tensors[0])\n        if rank:\n            axis %= rank\n        else:\n            axis = 0\n\n    if py_all([is_sparse(x) for x in tensors]):\n        return tf.sparse_concat(axis, tensors)\n    else:\n        return tf.concat([to_dense(x) for x in tensors], axis)",
        "begin_line": 1739,
        "end_line": 1759,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02127659574468085,
            "pseudo_dstar_susp": 0.021739130434782608,
            "pseudo_tarantula_susp": 0.023255813953488372,
            "pseudo_op2_susp": 0.021739130434782608,
            "pseudo_barinel_susp": 0.023255813953488372
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.reshape#1762",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.reshape(x, shape)",
        "snippet": "def reshape(x, shape):\n    \"\"\"Reshapes a tensor to the specified shape.\n\n    # Arguments\n        x: Tensor or variable.\n        shape: Target shape tuple.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.reshape(x, shape)",
        "begin_line": 1762,
        "end_line": 1772,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.870693909781858e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.permute_dimensions#1775",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.permute_dimensions(x, pattern)",
        "snippet": "def permute_dimensions(x, pattern):\n    \"\"\"Permutes axes in a tensor.\n\n    # Arguments\n        x: Tensor or variable.\n        pattern: A tuple of\n            dimension indices, e.g. `(0, 2, 1)`.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.transpose(x, perm=pattern)",
        "begin_line": 1775,
        "end_line": 1786,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.resize_images#1789",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.resize_images(x, height_factor, width_factor, data_format)",
        "snippet": "def resize_images(x, height_factor, width_factor, data_format):\n    \"\"\"Resizes the images contained in a 4D tensor.\n\n    # Arguments\n        x: Tensor or variable to resize.\n        height_factor: Positive integer.\n        width_factor: Positive integer.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n    \"\"\"\n    if data_format == 'channels_first':\n        original_shape = int_shape(x)\n        new_shape = tf.shape(x)[2:]\n        new_shape *= tf.constant(np.array([height_factor, width_factor]).astype('int32'))\n        x = permute_dimensions(x, [0, 2, 3, 1])\n        x = tf.image.resize_nearest_neighbor(x, new_shape)\n        x = permute_dimensions(x, [0, 3, 1, 2])\n        x.set_shape((None, None, original_shape[2] * height_factor if original_shape[2] is not None else None,\n                     original_shape[3] * width_factor if original_shape[3] is not None else None))\n        return x\n    elif data_format == 'channels_last':\n        original_shape = int_shape(x)\n        new_shape = tf.shape(x)[1:3]\n        new_shape *= tf.constant(np.array([height_factor, width_factor]).astype('int32'))\n        x = tf.image.resize_nearest_neighbor(x, new_shape)\n        x.set_shape((None, original_shape[1] * height_factor if original_shape[1] is not None else None,\n                     original_shape[2] * width_factor if original_shape[2] is not None else None, None))\n        return x\n    else:\n        raise ValueError('Invalid data_format:', data_format)",
        "begin_line": 1789,
        "end_line": 1823,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.resize_volumes#1826",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.resize_volumes(x, depth_factor, height_factor, width_factor, data_format)",
        "snippet": "def resize_volumes(x, depth_factor, height_factor, width_factor, data_format):\n    \"\"\"Resizes the volume contained in a 5D tensor.\n\n    # Arguments\n        x: Tensor or variable to resize.\n        depth_factor: Positive integer.\n        height_factor: Positive integer.\n        width_factor: Positive integer.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n    \"\"\"\n    if data_format == 'channels_first':\n        output = repeat_elements(x, depth_factor, axis=2)\n        output = repeat_elements(output, height_factor, axis=3)\n        output = repeat_elements(output, width_factor, axis=4)\n        return output\n    elif data_format == 'channels_last':\n        output = repeat_elements(x, depth_factor, axis=1)\n        output = repeat_elements(output, height_factor, axis=2)\n        output = repeat_elements(output, width_factor, axis=3)\n        return output\n    else:\n        raise ValueError('Invalid data_format:', data_format)",
        "begin_line": 1826,
        "end_line": 1853,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.repeat_elements#1856",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.repeat_elements(x, rep, axis)",
        "snippet": "def repeat_elements(x, rep, axis):\n    \"\"\"Repeats the elements of a tensor along an axis, like `np.repeat`.\n\n    If `x` has shape `(s1, s2, s3)` and `axis` is `1`, the output\n    will have shape `(s1, s2 * rep, s3)`.\n\n    # Arguments\n        x: Tensor or variable.\n        rep: Python integer, number of times to repeat.\n        axis: Axis along which to repeat.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    x_shape = x.get_shape().as_list()\n    # For static axis\n    if x_shape[axis] is not None:\n        # slices along the repeat axis\n        splits = tf.split(value=x, num_or_size_splits=x_shape[axis], axis=axis)\n        # repeat each slice the given number of reps\n        x_rep = [s for s in splits for _ in range(rep)]\n        return concatenate(x_rep, axis)\n\n    # Here we use tf.tile to mimic behavior of np.repeat so that\n    # we can handle dynamic shapes (that include None).\n    # To do that, we need an auxiliary axis to repeat elements along\n    # it and then merge them along the desired axis.\n\n    # Repeating\n    auxiliary_axis = axis + 1\n    x_shape = tf.shape(x)\n    x_rep = tf.expand_dims(x, axis=auxiliary_axis)\n    reps = np.ones(len(x.get_shape()) + 1)\n    reps[auxiliary_axis] = rep\n    x_rep = tf.tile(x_rep, reps)\n\n    # Merging\n    reps = np.delete(reps, auxiliary_axis)\n    reps[axis] = rep\n    reps = tf.constant(reps, dtype='int32')\n    x_shape = x_shape * reps\n    x_rep = tf.reshape(x_rep, x_shape)\n\n    # Fix shape representation\n    x_shape = x.get_shape().as_list()\n    x_rep.set_shape(x_shape)\n    x_rep._keras_shape = tuple(x_shape)\n    return x_rep",
        "begin_line": 1856,
        "end_line": 1903,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.repeat#1906",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.repeat(x, n)",
        "snippet": "def repeat(x, n):\n    \"\"\"Repeats a 2D tensor.\n\n    if `x` has shape (samples, dim) and `n` is `2`,\n    the output will have shape `(samples, 2, dim)`.\n\n    # Arguments\n        x: Tensor or variable.\n        n: Python integer, number of times to repeat.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    assert ndim(x) == 2\n    x = tf.expand_dims(x, 1)\n    pattern = tf.stack([1, n, 1])\n    return tf.tile(x, pattern)",
        "begin_line": 1906,
        "end_line": 1922,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.arange#1925",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.arange(start, stop=None, step=1, dtype='int32')",
        "snippet": "def arange(start, stop=None, step=1, dtype='int32'):\n    \"\"\"Creates a 1D tensor containing a sequence of integers.\n\n    The function arguments use the same convention as\n    Theano's arange: if only one argument is provided,\n    it is in fact the \"stop\" argument.\n\n    The default type of the returned tensor is `'int32'` to\n    match TensorFlow's default.\n\n    # Arguments\n        start: Start value.\n        stop: Stop value.\n        step: Difference between two successive values.\n        dtype: Integer dtype to use.\n\n    # Returns\n        An integer tensor.\n\n    \"\"\"\n    # Match the behavior of numpy and Theano by returning an empty seqence.\n    if stop is None and start < 0:\n        start = 0\n    result = tf.range(start, limit=stop, delta=step, name='arange')\n    if dtype != 'int32':\n        result = cast(result, dtype)\n    return result",
        "begin_line": 1925,
        "end_line": 1951,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.tile#1954",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.tile(x, n)",
        "snippet": "def tile(x, n):\n    \"\"\"Creates a tensor by tiling `x` by `n`.\n\n    # Arguments\n        x: A tensor or variable\n        n: A list of integer. The length must be the same as the number of\n            dimensions in `x`.\n\n    # Returns\n        A tiled tensor.\n    \"\"\"\n    if isinstance(n, int):\n        n = [n]\n    return tf.tile(x, n)",
        "begin_line": 1954,
        "end_line": 1967,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.853187506158242e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.flatten#1970",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.flatten(x)",
        "snippet": "def flatten(x):\n    \"\"\"Flatten a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor, reshaped into 1-D\n    \"\"\"\n    return tf.reshape(x, [-1])",
        "begin_line": 1970,
        "end_line": 1979,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.batch_flatten#1982",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.batch_flatten(x)",
        "snippet": "def batch_flatten(x):\n    \"\"\"Turn a nD tensor into a 2D tensor with same 0th dimension.\n\n    In other words, it flattens each data samples of a batch.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    x = tf.reshape(x, tf.stack([-1, prod(shape(x)[1:])]))\n    return x",
        "begin_line": 1982,
        "end_line": 1994,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.expand_dims#1997",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.expand_dims(x, axis=-1)",
        "snippet": "def expand_dims(x, axis=-1):\n    \"\"\"Adds a 1-sized dimension at index \"axis\".\n\n    # Arguments\n        x: A tensor or variable.\n        axis: Position where to add a new axis.\n\n    # Returns\n        A tensor with expanded dimensions.\n    \"\"\"\n    return tf.expand_dims(x, axis)",
        "begin_line": 1997,
        "end_line": 2007,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009182736455463728,
            "pseudo_dstar_susp": 0.0009009009009009009,
            "pseudo_tarantula_susp": 0.001148105625717566,
            "pseudo_op2_susp": 0.0009009009009009009,
            "pseudo_barinel_susp": 0.001148105625717566
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.squeeze#2010",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.squeeze(x, axis)",
        "snippet": "def squeeze(x, axis):\n    \"\"\"Removes a 1-dimension from the tensor at index \"axis\".\n\n    # Arguments\n        x: A tensor or variable.\n        axis: Axis to drop.\n\n    # Returns\n        A tensor with the same data as `x` but reduced dimensions.\n    \"\"\"\n    return tf.squeeze(x, [axis])",
        "begin_line": 2010,
        "end_line": 2020,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011147029316687103,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.temporal_padding#2023",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.temporal_padding(x, padding=(1, 1))",
        "snippet": "def temporal_padding(x, padding=(1, 1)):\n    \"\"\"Pads the middle dimension of a 3D tensor.\n\n    # Arguments\n        x: Tensor or variable.\n        padding: Tuple of 2 integers, how many zeros to\n            add at the start and end of dim 1.\n\n    # Returns\n        A padded 3D tensor.\n    \"\"\"\n    assert len(padding) == 2\n    pattern = [[0, 0], [padding[0], padding[1]], [0, 0]]\n    return tf.pad(x, pattern)",
        "begin_line": 2023,
        "end_line": 2036,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.spatial_2d_padding#2039",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None)",
        "snippet": "def spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None):\n    \"\"\"Pads the 2nd and 3rd dimensions of a 4D tensor.\n\n    # Arguments\n        x: Tensor or variable.\n        padding: Tuple of 2 tuples, padding pattern.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A padded 4D tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n    \"\"\"\n    assert len(padding) == 2\n    assert len(padding[0]) == 2\n    assert len(padding[1]) == 2\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format ' + str(data_format))\n\n    if data_format == 'channels_first':\n        pattern = [[0, 0],\n                   [0, 0],\n                   list(padding[0]),\n                   list(padding[1])]\n    else:\n        pattern = [[0, 0],\n                   list(padding[0]), list(padding[1]),\n                   [0, 0]]\n    return tf.pad(x, pattern)",
        "begin_line": 2039,
        "end_line": 2070,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.spatial_3d_padding#2073",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None)",
        "snippet": "def spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None):\n    \"\"\"Pads 5D tensor with zeros along the depth, height, width dimensions.\n\n    Pads these dimensions with respectively\n    \"padding[0]\", \"padding[1]\" and \"padding[2]\" zeros left and right.\n\n    For 'channels_last' data_format,\n    the 2nd, 3rd and 4th dimension will be padded.\n    For 'channels_first' data_format,\n    the 3rd, 4th and 5th dimension will be padded.\n\n    # Arguments\n        x: Tensor or variable.\n        padding: Tuple of 3 tuples, padding pattern.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A padded 5D tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n\n    \"\"\"\n    assert len(padding) == 3\n    assert len(padding[0]) == 2\n    assert len(padding[1]) == 2\n    assert len(padding[2]) == 2\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format ' + str(data_format))\n\n    if data_format == 'channels_first':\n        pattern = [\n            [0, 0],\n            [0, 0],\n            [padding[0][0], padding[0][1]],\n            [padding[1][0], padding[1][1]],\n            [padding[2][0], padding[2][1]]\n        ]\n    else:\n        pattern = [\n            [0, 0],\n            [padding[0][0], padding[0][1]],\n            [padding[1][0], padding[1][1]],\n            [padding[2][0], padding[2][1]],\n            [0, 0]\n        ]\n    return tf.pad(x, pattern)",
        "begin_line": 2073,
        "end_line": 2121,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.stack#2124",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.stack(x, axis=0)",
        "snippet": "def stack(x, axis=0):\n    \"\"\"Stacks a list of rank `R` tensors into a rank `R+1` tensor.\n\n    # Arguments\n        x: List of tensors.\n        axis: Axis along which to perform stacking.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.stack(x, axis=axis)",
        "begin_line": 2124,
        "end_line": 2134,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.one_hot#2137",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.one_hot(indices, num_classes)",
        "snippet": "def one_hot(indices, num_classes):\n    \"\"\"Computes the one-hot representation of an integer tensor.\n\n    # Arguments\n        indices: nD integer tensor of shape\n            `(batch_size, dim1, dim2, ... dim(n-1))`\n        num_classes: Integer, number of classes to consider.\n\n    # Returns\n        (n + 1)D one hot representation of the input\n        with shape `(batch_size, dim1, dim2, ... dim(n-1), num_classes)`\n    \"\"\"\n    return tf.one_hot(indices, depth=num_classes, axis=-1)",
        "begin_line": 2137,
        "end_line": 2149,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.reverse#2152",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.reverse(x, axes)",
        "snippet": "def reverse(x, axes):\n    \"\"\"Reverse a tensor along the specified axes.\n\n    # Arguments\n        x: Tensor to reverse.\n        axes: Integer or iterable of integers.\n            Axes to reverse.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if isinstance(axes, int):\n        axes = [axes]\n    return tf.reverse(x, axes)",
        "begin_line": 2152,
        "end_line": 2165,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.010638297872340425,
            "pseudo_dstar_susp": 0.002881844380403458,
            "pseudo_tarantula_susp": 0.006578947368421052,
            "pseudo_op2_susp": 0.002881844380403458,
            "pseudo_barinel_susp": 0.006578947368421052
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.get_value#2171",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.get_value(x)",
        "snippet": "def get_value(x):\n    \"\"\"Returns the value of a variable.\n\n    # Arguments\n        x: input variable.\n\n    # Returns\n        A Numpy array.\n    \"\"\"\n    return x.eval(session=get_session())",
        "begin_line": 2171,
        "end_line": 2180,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.69649956365752e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.batch_get_value#2183",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.batch_get_value(ops)",
        "snippet": "def batch_get_value(ops):\n    \"\"\"Returns the value of more than one tensor variable.\n\n    # Arguments\n        ops: list of ops to run.\n\n    # Returns\n        A list of Numpy arrays.\n    \"\"\"\n    if ops:\n        return get_session().run(ops)\n    else:\n        return []",
        "begin_line": 2183,
        "end_line": 2195,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.376465072667604e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.set_value#2198",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.set_value(x, value)",
        "snippet": "def set_value(x, value):\n    \"\"\"Sets the value of a variable, from a Numpy array.\n\n    # Arguments\n        x: Tensor to set to a new value.\n        value: Value to set the tensor to, as a Numpy array\n            (of the same shape).\n    \"\"\"\n    value = np.asarray(value, dtype=dtype(x))\n    tf_dtype = tf.as_dtype(x.dtype.name.split('_')[0])\n    if hasattr(x, '_assign_placeholder'):\n        assign_placeholder = x._assign_placeholder\n        assign_op = x._assign_op\n    else:\n        assign_placeholder = tf.placeholder(tf_dtype, shape=value.shape)\n        assign_op = x.assign(assign_placeholder)\n        x._assign_placeholder = assign_placeholder\n        x._assign_op = assign_op\n    get_session().run(assign_op, feed_dict={assign_placeholder: value})",
        "begin_line": 2198,
        "end_line": 2216,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001152604887044721,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.batch_set_value#2219",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.batch_set_value(tuples)",
        "snippet": "def batch_set_value(tuples):\n    \"\"\"Sets the values of many tensor variables at once.\n\n    # Arguments\n        tuples: a list of tuples `(tensor, value)`.\n            `value` should be a Numpy array.\n    \"\"\"\n    if tuples:\n        assign_ops = []\n        feed_dict = {}\n        for x, value in tuples:\n            value = np.asarray(value, dtype=dtype(x))\n            tf_dtype = tf.as_dtype(x.dtype.name.split('_')[0])\n            if hasattr(x, '_assign_placeholder'):\n                assign_placeholder = x._assign_placeholder\n                assign_op = x._assign_op\n            else:\n                assign_placeholder = tf.placeholder(tf_dtype,\n                                                    shape=value.shape)\n                assign_op = x.assign(assign_placeholder)\n                x._assign_placeholder = assign_placeholder\n                x._assign_op = assign_op\n            assign_ops.append(assign_op)\n            feed_dict[assign_placeholder] = value\n        get_session().run(assign_ops, feed_dict=feed_dict)",
        "begin_line": 2219,
        "end_line": 2243,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.get_variable_shape#2246",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.get_variable_shape(x)",
        "snippet": "def get_variable_shape(x):\n    \"\"\"Returns the shape of a variable.\n\n    # Arguments\n        x: A variable.\n\n    # Returns\n        A tuple of integers.\n    \"\"\"\n    return int_shape(x)",
        "begin_line": 2246,
        "end_line": 2255,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007336757153338225,
            "pseudo_dstar_susp": 0.0007336757153338225,
            "pseudo_tarantula_susp": 0.0007429420505200594,
            "pseudo_op2_susp": 0.0007336757153338225,
            "pseudo_barinel_susp": 0.0007429420505200594
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.print_tensor#2258",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.print_tensor(x, message='')",
        "snippet": "def print_tensor(x, message=''):\n    \"\"\"Prints `message` and the tensor value when evaluated.\n\n     Note that `print_tensor` returns a new tensor identical to `x`\n     which should be used in the following code. Otherwise the\n     print operation is not taken into account during evaluation.\n\n     # Example\n     ```python\n         >>> x = K.print_tensor(x, message=\"x is: \")\n     ```\n\n    # Arguments\n        x: Tensor to print.\n        message: Message to print jointly with the tensor.\n\n    # Returns\n        The same tensor `x`, unchanged.\n    \"\"\"\n    return tf.Print(x, [x], message)",
        "begin_line": 2258,
        "end_line": 2277,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.Function.__init__#2302",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend.Function",
        "signature": "keras.backend.tensorflow_backend.Function.__init__(self, inputs, outputs, updates=None, name=None, **session_kwargs)",
        "snippet": "    def __init__(self, inputs, outputs, updates=None, name=None, **session_kwargs):\n        updates = updates or []\n        if not isinstance(inputs, (list, tuple)):\n            raise TypeError('`inputs` to a TensorFlow backend function '\n                            'should be a list or tuple.')\n        if not isinstance(outputs, (list, tuple)):\n            raise TypeError('`outputs` of a TensorFlow backend function '\n                            'should be a list or tuple.')\n        if not isinstance(updates, (list, tuple)):\n            raise TypeError('`updates` in a TensorFlow backend function '\n                            'should be a list or tuple.')\n        self.inputs = list(inputs)\n        self.outputs = list(outputs)\n        with tf.control_dependencies(self.outputs):\n            updates_ops = []\n            for update in updates:\n                if isinstance(update, tuple):\n                    p, new_p = update\n                    updates_ops.append(tf.assign(p, new_p))\n                else:\n                    # assumed already an op\n                    updates_ops.append(update)\n            self.updates_op = tf.group(*updates_ops)\n        self.name = name\n        # additional tensor substitutions\n        self.feed_dict = session_kwargs.pop('feed_dict', {})\n        # additional operations\n        self.fetches = session_kwargs.pop('fetches', [])\n        if not isinstance(self.fetches, list):\n            self.fetches = [self.fetches]\n        self.session_kwargs = session_kwargs",
        "begin_line": 2302,
        "end_line": 2332,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006934812760055479,
            "pseudo_dstar_susp": 0.0006934812760055479,
            "pseudo_tarantula_susp": 0.0006997900629811056,
            "pseudo_op2_susp": 0.0006934812760055479,
            "pseudo_barinel_susp": 0.0006997900629811056
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.Function.__call__#2334",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend.Function",
        "signature": "keras.backend.tensorflow_backend.Function.__call__(self, inputs)",
        "snippet": "    def __call__(self, inputs):\n        if not isinstance(inputs, (list, tuple)):\n            raise TypeError('`inputs` should be a list or tuple.')\n        feed_dict = self.feed_dict.copy()\n        for tensor, value in zip(self.inputs, inputs):\n            if is_sparse(tensor):\n                sparse_coo = value.tocoo()\n                indices = np.concatenate((np.expand_dims(sparse_coo.row, 1),\n                                          np.expand_dims(sparse_coo.col, 1)), 1)\n                value = (indices, sparse_coo.data, sparse_coo.shape)\n            feed_dict[tensor] = value\n        fetches = self.outputs + [self.updates_op] + self.fetches\n        session = get_session()\n        updated = session.run(fetches=fetches, feed_dict=feed_dict,\n                              **self.session_kwargs)\n        return updated[:len(self.outputs)]",
        "begin_line": 2334,
        "end_line": 2349,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.000700770847932726,
            "pseudo_dstar_susp": 0.000700770847932726,
            "pseudo_tarantula_susp": 0.0007072135785007072,
            "pseudo_op2_susp": 0.000700770847932726,
            "pseudo_barinel_susp": 0.0007072135785007072
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.function#2352",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.function(inputs, outputs, updates=None, **kwargs)",
        "snippet": "def function(inputs, outputs, updates=None, **kwargs):\n    \"\"\"Instantiates a Keras function.\n\n    # Arguments\n        inputs: List of placeholder tensors.\n        outputs: List of output tensors.\n        updates: List of update ops.\n        **kwargs: Passed to `tf.Session.run`.\n\n    # Returns\n        Output values as Numpy arrays.\n\n    # Raises\n        ValueError: if invalid kwargs are passed in.\n    \"\"\"\n    if kwargs:\n        for key in kwargs:\n            if not (has_arg(tf.Session.run, key, True) or has_arg(Function.__init__, key, True)):\n                msg = 'Invalid argument \"%s\" passed to K.function with TensorFlow backend' % key\n                raise ValueError(msg)\n    return Function(inputs, outputs, updates=updates, **kwargs)",
        "begin_line": 2352,
        "end_line": 2372,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006934812760055479,
            "pseudo_dstar_susp": 0.0006934812760055479,
            "pseudo_tarantula_susp": 0.0006997900629811056,
            "pseudo_op2_susp": 0.0006934812760055479,
            "pseudo_barinel_susp": 0.0006997900629811056
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.gradients#2375",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.gradients(loss, variables)",
        "snippet": "def gradients(loss, variables):\n    \"\"\"Returns the gradients of `variables` w.r.t. `loss`.\n\n    # Arguments\n        loss: Scalar tensor to minimize.\n        variables: List of variables.\n\n    # Returns\n        A gradients tensor.\n    \"\"\"\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)",
        "begin_line": 2375,
        "end_line": 2385,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 8.92140244446427e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.stop_gradient#2388",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.stop_gradient(variables)",
        "snippet": "def stop_gradient(variables):\n    \"\"\"Returns `variables` but with zero gradient w.r.t. every other variable.\n\n    # Arguments\n        variables: tensor or list of tensors to consider constant with respect\n            to any other variable.\n\n    # Returns\n        A single tensor or a list of tensors (depending on the passed argument)\n            that has constant gradient with respect to any other variable.\n    \"\"\"\n    if isinstance(variables, (list, tuple)):\n        return map(tf.stop_gradient, variables)\n    else:\n        return tf.stop_gradient(variables)",
        "begin_line": 2388,
        "end_line": 2402,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.rnn#2407",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.rnn(step_function, inputs, initial_states, go_backwards=False, mask=None, constants=None, unroll=False, input_length=None)",
        "snippet": "def rnn(step_function, inputs, initial_states,\n        go_backwards=False, mask=None, constants=None,\n        unroll=False, input_length=None):\n    \"\"\"Iterates over the time dimension of a tensor.\n\n    # Arguments\n        step_function: RNN step function.\n            Parameters:\n                inputs: tensor with shape `(samples, ...)` (no time dimension),\n                    representing input for the batch of samples at a certain\n                    time step.\n                states: list of tensors.\n            Returns:\n                outputs: tensor with shape `(samples, output_dim)`\n                    (no time dimension).\n                new_states: list of tensors, same length and shapes\n                    as 'states'. The first state in the list must be the\n                    output tensor at the previous timestep.\n        inputs: tensor of temporal data of shape `(samples, time, ...)`\n            (at least 3D).\n        initial_states: tensor with shape (samples, output_dim)\n            (no time dimension),\n            containing the initial values for the states used in\n            the step function.\n        go_backwards: boolean. If True, do the iteration over the time\n            dimension in reverse order and return the reversed sequence.\n        mask: binary tensor with shape `(samples, time, 1)`,\n            with a zero for every element that is masked.\n        constants: a list of constant values passed at each step.\n        unroll: whether to unroll the RNN or to use a symbolic loop (`while_loop` or `scan` depending on backend).\n        input_length: not relevant in the TensorFlow implementation.\n            Must be specified if using unrolling with Theano.\n\n    # Returns\n        A tuple, `(last_output, outputs, new_states)`.\n\n            last_output: the latest output of the rnn, of shape `(samples, ...)`\n            outputs: tensor with shape `(samples, time, ...)` where each\n                entry `outputs[s, t]` is the output of the step function\n                at time `t` for sample `s`.\n            new_states: list of tensors, latest states returned by\n                the step function, of shape `(samples, ...)`.\n\n    # Raises\n        ValueError: if input dimension is less than 3.\n        ValueError: if `unroll` is `True` but input timestep is not a fixed number.\n        ValueError: if `mask` is provided (not `None`) but states is not provided\n            (`len(states)` == 0).\n    \"\"\"\n    ndim = len(inputs.get_shape())\n    if ndim < 3:\n        raise ValueError('Input should be at least 3D.')\n    axes = [1, 0] + list(range(2, ndim))\n    inputs = tf.transpose(inputs, (axes))\n\n    if mask is not None:\n        if mask.dtype != tf.bool:\n            mask = tf.cast(mask, tf.bool)\n        if len(mask.get_shape()) == ndim - 1:\n            mask = expand_dims(mask)\n        mask = tf.transpose(mask, axes)\n\n    if constants is None:\n        constants = []\n\n    global uses_learning_phase\n    uses_learning_phase = False\n\n    if unroll:\n        if not inputs.get_shape()[0]:\n            raise ValueError('Unrolling requires a '\n                             'fixed number of timesteps.')\n        states = initial_states\n        successive_states = []\n        successive_outputs = []\n\n        input_list = tf.unstack(inputs)\n        if go_backwards:\n            input_list.reverse()\n\n        if mask is not None:\n            mask_list = tf.unstack(mask)\n            if go_backwards:\n                mask_list.reverse()\n\n            for inp, mask_t in zip(input_list, mask_list):\n                output, new_states = step_function(inp, states + constants)\n                if getattr(output, '_uses_learning_phase', False):\n                    uses_learning_phase = True\n\n                # tf.where needs its condition tensor\n                # to be the same shape as its two\n                # result tensors, but in our case\n                # the condition (mask) tensor is\n                # (nsamples, 1), and A and B are (nsamples, ndimensions).\n                # So we need to\n                # broadcast the mask to match the shape of A and B.\n                # That's what the tile call does,\n                # it just repeats the mask along its second dimension\n                # n times.\n                tiled_mask_t = tf.tile(mask_t,\n                                       tf.stack([1, tf.shape(output)[1]]))\n\n                if not successive_outputs:\n                    prev_output = zeros_like(output)\n                else:\n                    prev_output = successive_outputs[-1]\n\n                output = tf.where(tiled_mask_t, output, prev_output)\n\n                return_states = []\n                for state, new_state in zip(states, new_states):\n                    # (see earlier comment for tile explanation)\n                    tiled_mask_t = tf.tile(mask_t,\n                                           tf.stack([1, tf.shape(new_state)[1]]))\n                    return_states.append(tf.where(tiled_mask_t,\n                                                  new_state,\n                                                  state))\n                states = return_states\n                successive_outputs.append(output)\n                successive_states.append(states)\n            last_output = successive_outputs[-1]\n            new_states = successive_states[-1]\n            outputs = tf.stack(successive_outputs)\n        else:\n            for inp in input_list:\n                output, states = step_function(inp, states + constants)\n                if getattr(output, '_uses_learning_phase', False):\n                    uses_learning_phase = True\n                successive_outputs.append(output)\n                successive_states.append(states)\n            last_output = successive_outputs[-1]\n            new_states = successive_states[-1]\n            outputs = tf.stack(successive_outputs)\n\n    else:\n        if go_backwards:\n            inputs = reverse(inputs, 0)\n\n        states = tuple(initial_states)\n\n        time_steps = tf.shape(inputs)[0]\n        outputs, _ = step_function(inputs[0], initial_states + constants)\n        output_ta = tensor_array_ops.TensorArray(\n            dtype=outputs.dtype,\n            size=time_steps,\n            tensor_array_name='output_ta')\n        input_ta = tensor_array_ops.TensorArray(\n            dtype=inputs.dtype,\n            size=time_steps,\n            tensor_array_name='input_ta')\n        input_ta = input_ta.unstack(inputs)\n        time = tf.constant(0, dtype='int32', name='time')\n\n        if mask is not None:\n            if not states:\n                raise ValueError('No initial states provided! '\n                                 'When using masking in an RNN, you should '\n                                 'provide initial states '\n                                 '(and your step function should return '\n                                 'as its first state at time `t` '\n                                 'the output at time `t-1`).')\n            if go_backwards:\n                mask = reverse(mask, 0)\n\n            mask_ta = tensor_array_ops.TensorArray(\n                dtype=tf.bool,\n                size=time_steps,\n                tensor_array_name='mask_ta')\n            mask_ta = mask_ta.unstack(mask)\n\n            def _step(time, output_ta_t, *states):\n                \"\"\"RNN step function.\n\n                # Arguments\n                    time: Current timestep value.\n                    output_ta_t: TensorArray.\n                    *states: List of states.\n\n                # Returns\n                    Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\n                \"\"\"\n                current_input = input_ta.read(time)\n                mask_t = mask_ta.read(time)\n                output, new_states = step_function(current_input,\n                                                   tuple(states) +\n                                                   tuple(constants))\n                if getattr(output, '_uses_learning_phase', False):\n                    global uses_learning_phase\n                    uses_learning_phase = True\n                for state, new_state in zip(states, new_states):\n                    new_state.set_shape(state.get_shape())\n                tiled_mask_t = tf.tile(mask_t,\n                                       tf.stack([1, tf.shape(output)[1]]))\n                output = tf.where(tiled_mask_t, output, states[0])\n                new_states = [tf.where(tiled_mask_t, new_states[i], states[i]) for i in range(len(states))]\n                output_ta_t = output_ta_t.write(time, output)\n                return (time + 1, output_ta_t) + tuple(new_states)\n        else:\n            def _step(time, output_ta_t, *states):\n                \"\"\"RNN step function.\n\n                # Arguments\n                    time: Current timestep value.\n                    output_ta_t: TensorArray.\n                    *states: List of states.\n\n                # Returns\n                    Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\n                \"\"\"\n                current_input = input_ta.read(time)\n                output, new_states = step_function(current_input,\n                                                   tuple(states) +\n                                                   tuple(constants))\n                if getattr(output, '_uses_learning_phase', False):\n                    global uses_learning_phase\n                    uses_learning_phase = True\n                for state, new_state in zip(states, new_states):\n                    new_state.set_shape(state.get_shape())\n                output_ta_t = output_ta_t.write(time, output)\n                return (time + 1, output_ta_t) + tuple(new_states)\n\n        final_outputs = control_flow_ops.while_loop(\n            cond=lambda time, *_: time < time_steps,\n            body=_step,\n            loop_vars=(time, output_ta) + states,\n            parallel_iterations=32,\n            swap_memory=True)\n        last_time = final_outputs[0]\n        output_ta = final_outputs[1]\n        new_states = final_outputs[2:]\n\n        outputs = output_ta.stack()\n        last_output = output_ta.read(last_time - 1)\n\n    axes = [1, 0] + list(range(2, len(outputs.get_shape())))\n    outputs = tf.transpose(outputs, axes)\n    last_output._uses_learning_phase = uses_learning_phase\n    return last_output, outputs, new_states",
        "begin_line": 2407,
        "end_line": 2645,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend._step#2578",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend._step(time, output_ta_t, *states)",
        "snippet": "            def _step(time, output_ta_t, *states):\n                \"\"\"RNN step function.\n\n                # Arguments\n                    time: Current timestep value.\n                    output_ta_t: TensorArray.\n                    *states: List of states.\n\n                # Returns\n                    Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\n                \"\"\"\n                current_input = input_ta.read(time)\n                mask_t = mask_ta.read(time)\n                output, new_states = step_function(current_input,\n                                                   tuple(states) +\n                                                   tuple(constants))\n                if getattr(output, '_uses_learning_phase', False):\n                    global uses_learning_phase\n                    uses_learning_phase = True\n                for state, new_state in zip(states, new_states):\n                    new_state.set_shape(state.get_shape())\n                tiled_mask_t = tf.tile(mask_t,\n                                       tf.stack([1, tf.shape(output)[1]]))\n                output = tf.where(tiled_mask_t, output, states[0])\n                new_states = [tf.where(tiled_mask_t, new_states[i], states[i]) for i in range(len(states))]\n                output_ta_t = output_ta_t.write(time, output)\n                return (time + 1, output_ta_t) + tuple(new_states)",
        "begin_line": 2578,
        "end_line": 2604,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend._step#2606",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend._step(time, output_ta_t, *states)",
        "snippet": "            def _step(time, output_ta_t, *states):\n                \"\"\"RNN step function.\n\n                # Arguments\n                    time: Current timestep value.\n                    output_ta_t: TensorArray.\n                    *states: List of states.\n\n                # Returns\n                    Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\n                \"\"\"\n                current_input = input_ta.read(time)\n                output, new_states = step_function(current_input,\n                                                   tuple(states) +\n                                                   tuple(constants))\n                if getattr(output, '_uses_learning_phase', False):\n                    global uses_learning_phase\n                    uses_learning_phase = True\n                for state, new_state in zip(states, new_states):\n                    new_state.set_shape(state.get_shape())\n                output_ta_t = output_ta_t.write(time, output)\n                return (time + 1, output_ta_t) + tuple(new_states)",
        "begin_line": 2606,
        "end_line": 2627,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.switch#2648",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.switch(condition, then_expression, else_expression)",
        "snippet": "def switch(condition, then_expression, else_expression):\n    \"\"\"Switches between two operations depending on a scalar value.\n\n    Note that both `then_expression` and `else_expression`\n    should be symbolic tensors of the *same shape*.\n\n    # Arguments\n        condition: tensor (`int` or `bool`).\n        then_expression: either a tensor, or a callable that returns a tensor.\n        else_expression: either a tensor, or a callable that returns a tensor.\n\n    # Returns\n        The selected tensor.\n\n    # Raises\n        ValueError: If rank of `condition` is greater than rank of expressions.\n    \"\"\"\n    if condition.dtype != tf.bool:\n        condition = tf.cast(condition, 'bool')\n    cond_ndim = ndim(condition)\n    if not cond_ndim:\n        if not callable(then_expression):\n            def then_expression_fn():\n                return then_expression\n        else:\n            then_expression_fn = then_expression\n        if not callable(else_expression):\n            def else_expression_fn():\n                return else_expression\n        else:\n            else_expression_fn = else_expression\n        x = tf.cond(condition,\n                    then_expression_fn,\n                    else_expression_fn)\n    else:\n        # tf.where needs its condition tensor\n        # to be the same shape as its two\n        # result tensors\n        if callable(then_expression):\n            then_expression = then_expression()\n        if callable(else_expression):\n            else_expression = else_expression()\n        expr_ndim = ndim(then_expression)\n        if cond_ndim > expr_ndim:\n            raise ValueError('Rank of `condition` should be less than or'\n                             ' equal to rank of `then_expression` and '\n                             '`else_expression`. ndim(condition)=' +\n                             str(cond_ndim) + ', ndim(then_expression)'\n                             '=' + str(expr_ndim))\n        if cond_ndim > 1:\n            ndim_diff = expr_ndim - cond_ndim\n            cond_shape = tf.concat([tf.shape(condition), [1] * ndim_diff], axis=0)\n            condition = tf.reshape(condition, cond_shape)\n            expr_shape = tf.shape(then_expression)\n            shape_diff = expr_shape - cond_shape\n            tile_shape = tf.where(shape_diff > 0, expr_shape, tf.ones_like(expr_shape))\n            condition = tf.tile(condition, tile_shape)\n        x = tf.where(condition, then_expression, else_expression)\n    return x",
        "begin_line": 2648,
        "end_line": 2706,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.then_expression_fn#2670",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.then_expression_fn()",
        "snippet": "            def then_expression_fn():\n                return then_expression",
        "begin_line": 2670,
        "end_line": 2671,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001006947940791461,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.else_expression_fn#2675",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.else_expression_fn()",
        "snippet": "            def else_expression_fn():\n                return else_expression",
        "begin_line": 2675,
        "end_line": 2676,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001016260162601626,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.in_train_phase#2709",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.in_train_phase(x, alt, training=None)",
        "snippet": "def in_train_phase(x, alt, training=None):\n    \"\"\"Selects `x` in train phase, and `alt` otherwise.\n\n    Note that `alt` should have the *same shape* as `x`.\n\n    # Arguments\n        x: What to return in train phase\n            (tensor or callable that returns a tensor).\n        alt: What to return otherwise\n            (tensor or callable that returns a tensor).\n        training: Optional scalar tensor\n            (or Python boolean, or Python integer)\n            specifying the learning phase.\n\n    # Returns\n        Either `x` or `alt` based on the `training` flag.\n        the `training` flag defaults to `K.learning_phase()`.\n    \"\"\"\n    if training is None:\n        training = learning_phase()\n        uses_learning_phase = True\n    else:\n        uses_learning_phase = False\n\n    if training is 1 or training is True:\n        if callable(x):\n            return x()\n        else:\n            return x\n\n    elif training is 0 or training is False:\n        if callable(alt):\n            return alt()\n        else:\n            return alt\n\n    # else: assume learning phase is a placeholder tensor.\n    x = switch(training, x, alt)\n    if uses_learning_phase:\n        x._uses_learning_phase = True\n    return x",
        "begin_line": 2709,
        "end_line": 2749,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.relu#2774",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.relu(x, alpha=0.0, max_value=None)",
        "snippet": "def relu(x, alpha=0., max_value=None):\n    \"\"\"Rectified linear unit.\n\n    With default values, it returns element-wise `max(x, 0)`.\n\n    # Arguments\n        x: A tensor or variable.\n        alpha: A scalar, slope of negative section (default=`0.`).\n        max_value: Saturation threshold.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if alpha != 0.:\n        negative_part = tf.nn.relu(-x)\n    x = tf.nn.relu(x)\n    if max_value is not None:\n        max_value = _to_tensor(max_value, x.dtype.base_dtype)\n        zero = _to_tensor(0., x.dtype.base_dtype)\n        x = tf.clip_by_value(x, zero, max_value)\n    if alpha != 0.:\n        alpha = _to_tensor(alpha, x.dtype.base_dtype)\n        x -= alpha * negative_part\n    return x",
        "begin_line": 2774,
        "end_line": 2797,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.007936507936507936,
            "pseudo_dstar_susp": 0.001953125,
            "pseudo_tarantula_susp": 0.00847457627118644,
            "pseudo_op2_susp": 0.001953125,
            "pseudo_barinel_susp": 0.00847457627118644
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.elu#2800",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.elu(x, alpha=1.0)",
        "snippet": "def elu(x, alpha=1.):\n    \"\"\"Exponential linear unit.\n\n    # Arguments\n        x: A tensor or variable to compute the activation function for.\n        alpha: A scalar, slope of positive section.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    res = tf.nn.elu(x)\n    if alpha == 1:\n        return res\n    else:\n        return tf.where(x > 0, res, alpha * res)",
        "begin_line": 2800,
        "end_line": 2814,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004405286343612335,
            "pseudo_dstar_susp": 0.001694915254237288,
            "pseudo_tarantula_susp": 0.0049261083743842365,
            "pseudo_op2_susp": 0.001694915254237288,
            "pseudo_barinel_susp": 0.0049261083743842365
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.softmax#2817",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.softmax(x)",
        "snippet": "def softmax(x):\n    \"\"\"Softmax of a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.softmax(x)",
        "begin_line": 2817,
        "end_line": 2826,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009208103130755065,
            "pseudo_dstar_susp": 0.0009033423667570009,
            "pseudo_tarantula_susp": 0.001152073732718894,
            "pseudo_op2_susp": 0.0009033423667570009,
            "pseudo_barinel_susp": 0.001152073732718894
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.softplus#2829",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.softplus(x)",
        "snippet": "def softplus(x):\n    \"\"\"Softplus of a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.softplus(x)",
        "begin_line": 2829,
        "end_line": 2838,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.007936507936507936,
            "pseudo_dstar_susp": 0.001953125,
            "pseudo_tarantula_susp": 0.00847457627118644,
            "pseudo_op2_susp": 0.001953125,
            "pseudo_barinel_susp": 0.00847457627118644
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.softsign#2841",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.softsign(x)",
        "snippet": "def softsign(x):\n    \"\"\"Softsign of a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.softsign(x)",
        "begin_line": 2841,
        "end_line": 2850,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.categorical_crossentropy#2853",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.categorical_crossentropy(target, output, from_logits=False)",
        "snippet": "def categorical_crossentropy(target, output, from_logits=False):\n    \"\"\"Categorical crossentropy between an output tensor and a target tensor.\n\n    # Arguments\n        target: A tensor of the same shape as `output`.\n        output: A tensor resulting from a softmax\n            (unless `from_logits` is True, in which\n            case `output` is expected to be the logits).\n        from_logits: Boolean, whether `output` is the\n            result of a softmax, or is a tensor of logits.\n\n    # Returns\n        Output tensor.\n    \"\"\"\n    # Note: tf.nn.softmax_cross_entropy_with_logits\n    # expects logits, Keras expects probabilities.\n    if not from_logits:\n        # scale preds so that the class probas of each sample sum to 1\n        output /= tf.reduce_sum(output,\n                                axis=len(output.get_shape()) - 1,\n                                keep_dims=True)\n        # manual computation of crossentropy\n        _epsilon = _to_tensor(epsilon(), output.dtype.base_dtype)\n        output = tf.clip_by_value(output, _epsilon, 1. - _epsilon)\n        return - tf.reduce_sum(target * tf.log(output),\n                               axis=len(output.get_shape()) - 1)\n    else:\n        return tf.nn.softmax_cross_entropy_with_logits(labels=target,\n                                                       logits=output)",
        "begin_line": 2853,
        "end_line": 2881,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.490367277213628e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.sparse_categorical_crossentropy#2884",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.sparse_categorical_crossentropy(target, output, from_logits=False)",
        "snippet": "def sparse_categorical_crossentropy(target, output, from_logits=False):\n    \"\"\"Categorical crossentropy with integer targets.\n\n    # Arguments\n        target: An integer tensor.\n        output: A tensor resulting from a softmax\n            (unless `from_logits` is True, in which\n            case `output` is expected to be the logits).\n        from_logits: Boolean, whether `output` is the\n            result of a softmax, or is a tensor of logits.\n\n    # Returns\n        Output tensor.\n    \"\"\"\n    # Note: tf.nn.sparse_softmax_cross_entropy_with_logits\n    # expects logits, Keras expects probabilities.\n    if not from_logits:\n        _epsilon = _to_tensor(epsilon(), output.dtype.base_dtype)\n        output = tf.clip_by_value(output, _epsilon, 1 - _epsilon)\n        output = tf.log(output)\n\n    output_shape = output.get_shape()\n    targets = cast(flatten(target), 'int64')\n    logits = tf.reshape(output, [-1, int(output_shape[-1])])\n    res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n        labels=targets,\n        logits=logits)\n    if len(output_shape) == 3:\n        # if our output includes timesteps we need to reshape\n        return tf.reshape(res, tf.shape(output)[:-1])\n    else:\n        return res",
        "begin_line": 2884,
        "end_line": 2915,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.binary_crossentropy#2918",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.binary_crossentropy(target, output, from_logits=False)",
        "snippet": "def binary_crossentropy(target, output, from_logits=False):\n    \"\"\"Binary crossentropy between an output tensor and a target tensor.\n\n    # Arguments\n        target: A tensor with the same shape as `output`.\n        output: A tensor.\n        from_logits: Whether `output` is expected to be a logits tensor.\n            By default, we consider that `output`\n            encodes a probability distribution.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    # Note: tf.nn.sigmoid_cross_entropy_with_logits\n    # expects logits, Keras expects probabilities.\n    if not from_logits:\n        # transform back to logits\n        _epsilon = _to_tensor(epsilon(), output.dtype.base_dtype)\n        output = tf.clip_by_value(output, _epsilon, 1 - _epsilon)\n        output = tf.log(output / (1 - output))\n\n    return tf.nn.sigmoid_cross_entropy_with_logits(labels=target,\n                                                   logits=output)",
        "begin_line": 2918,
        "end_line": 2940,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0025575447570332483,
            "pseudo_dstar_susp": 0.0014992503748125937,
            "pseudo_tarantula_susp": 0.0035335689045936395,
            "pseudo_op2_susp": 0.0014992503748125937,
            "pseudo_barinel_susp": 0.0035335689045936395
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.sigmoid#2943",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.sigmoid(x)",
        "snippet": "def sigmoid(x):\n    \"\"\"Element-wise sigmoid.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.sigmoid(x)",
        "begin_line": 2943,
        "end_line": 2952,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.003663003663003663,
            "pseudo_dstar_susp": 0.0015873015873015873,
            "pseudo_tarantula_susp": 0.00411522633744856,
            "pseudo_op2_susp": 0.0015873015873015873,
            "pseudo_barinel_susp": 0.00411522633744856
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.hard_sigmoid#2955",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.hard_sigmoid(x)",
        "snippet": "def hard_sigmoid(x):\n    \"\"\"Segment-wise linear approximation of sigmoid.\n\n    Faster than sigmoid.\n    Returns `0.` if `x < -2.5`, `1.` if `x > 2.5`.\n    In `-2.5 <= x <= 2.5`, returns `0.2 * x + 0.5`.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    x = (0.2 * x) + 0.5\n    zero = _to_tensor(0., x.dtype.base_dtype)\n    one = _to_tensor(1., x.dtype.base_dtype)\n    x = tf.clip_by_value(x, zero, one)\n    return x",
        "begin_line": 2955,
        "end_line": 2972,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009319664492078285,
            "pseudo_dstar_susp": 0.0009099181073703367,
            "pseudo_tarantula_susp": 0.0012135922330097086,
            "pseudo_op2_susp": 0.0009099181073703367,
            "pseudo_barinel_susp": 0.0012135922330097086
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.tanh#2975",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.tanh(x)",
        "snippet": "def tanh(x):\n    \"\"\"Element-wise tanh.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.tanh(x)",
        "begin_line": 2975,
        "end_line": 2984,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008984725965858042,
            "pseudo_dstar_susp": 0.0008833922261484099,
            "pseudo_tarantula_susp": 0.0010214504596527069,
            "pseudo_op2_susp": 0.0008833922261484099,
            "pseudo_barinel_susp": 0.0010214504596527069
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.dropout#2987",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.dropout(x, level, noise_shape=None, seed=None)",
        "snippet": "def dropout(x, level, noise_shape=None, seed=None):\n    \"\"\"Sets entries in `x` to zero at random, while scaling the entire tensor.\n\n    # Arguments\n        x: tensor\n        level: fraction of the entries in the tensor\n            that will be set to 0.\n        noise_shape: shape for randomly generated keep/drop flags,\n            must be broadcastable to the shape of `x`\n        seed: random seed to ensure determinism.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    retain_prob = 1. - level\n    if seed is None:\n        seed = np.random.randint(10e6)\n    # the dummy 1. works around a TF bug\n    # (float32_ref vs. float32 incompatibility)\n    return tf.nn.dropout(x * 1., retain_prob, noise_shape, seed=seed)",
        "begin_line": 2987,
        "end_line": 3006,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010178117048346055,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.l2_normalize#3009",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.l2_normalize(x, axis=None)",
        "snippet": "def l2_normalize(x, axis=None):\n    \"\"\"Normalizes a tensor wrt the L2 norm alongside the specified axis.\n\n    # Arguments\n        x: Tensor or variable.\n        axis: axis along which to perform normalization.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.nn.l2_normalize(x, dim=axis)",
        "begin_line": 3009,
        "end_line": 3019,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.in_top_k#3022",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.in_top_k(predictions, targets, k)",
        "snippet": "def in_top_k(predictions, targets, k):\n    \"\"\"Returns whether the `targets` are in the top `k` `predictions`.\n\n    # Arguments\n        predictions: A tensor of shape `(batch_size, classes)` and type `float32`.\n        targets: A 1D tensor of length `batch_size` and type `int32` or `int64`.\n        k: An `int`, number of top elements to consider.\n\n    # Returns\n        A 1D tensor of length `batch_size` and type `bool`.\n        `output[i]` is `True` if `predictions[i, targets[i]]` is within top-`k`\n        values of `predictions[i]`.\n    \"\"\"\n    return tf.nn.in_top_k(predictions, targets, k)",
        "begin_line": 3022,
        "end_line": 3035,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend._preprocess_conv2d_input#3041",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend._preprocess_conv2d_input(x, data_format)",
        "snippet": "def _preprocess_conv2d_input(x, data_format):\n    \"\"\"Transpose and cast the input before the conv2d.\n\n    # Arguments\n        x: input tensor.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if dtype(x) == 'float64':\n        x = tf.cast(x, 'float32')\n    tf_data_format = 'NHWC'\n    if data_format == 'channels_first':\n        if not _has_nchw_support():\n            x = tf.transpose(x, (0, 2, 3, 1))  # NCHW -> NHWC\n        else:\n            tf_data_format = 'NCHW'\n    return x, tf_data_format",
        "begin_line": 3041,
        "end_line": 3059,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011059500110595002,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend._preprocess_conv3d_input#3062",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend._preprocess_conv3d_input(x, data_format)",
        "snippet": "def _preprocess_conv3d_input(x, data_format):\n    \"\"\"Transpose and cast the input before the conv3d.\n\n    # Arguments\n        x: input tensor.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if dtype(x) == 'float64':\n        x = tf.cast(x, 'float32')\n    tf_data_format = 'NDHWC'\n    if data_format == 'channels_first':\n        if not _has_nchw_support():\n            x = tf.transpose(x, (0, 2, 3, 4, 1))\n        else:\n            tf_data_format = 'NCDHW'\n    return x, tf_data_format",
        "begin_line": 3062,
        "end_line": 3080,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002898550724637681,
            "pseudo_dstar_susp": 0.0015105740181268882,
            "pseudo_tarantula_susp": 0.0036363636363636364,
            "pseudo_op2_susp": 0.0015105740181268882,
            "pseudo_barinel_susp": 0.0036363636363636364
        }
    },
    {
        "name": "keras.backend.tensorflow_backend._preprocess_padding#3083",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend._preprocess_padding(padding)",
        "snippet": "def _preprocess_padding(padding):\n    \"\"\"Convert keras' padding to tensorflow's padding.\n\n    # Arguments\n        padding: string, `\"same\"` or `\"valid\"`.\n\n    # Returns\n        a string, `\"SAME\"` or `\"VALID\"`.\n\n    # Raises\n        ValueError: if `padding` is invalid.\n    \"\"\"\n    if padding == 'same':\n        padding = 'SAME'\n    elif padding == 'valid':\n        padding = 'VALID'\n    else:\n        raise ValueError('Invalid padding:', padding)\n    return padding",
        "begin_line": 3083,
        "end_line": 3101,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009182736455463728,
            "pseudo_dstar_susp": 0.0009009009009009009,
            "pseudo_tarantula_susp": 0.001148105625717566,
            "pseudo_op2_susp": 0.0009009009009009009,
            "pseudo_barinel_susp": 0.001148105625717566
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.conv1d#3104",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.conv1d(x, kernel, strides=1, padding='valid', data_format=None, dilation_rate=1)",
        "snippet": "def conv1d(x, kernel, strides=1, padding='valid',\n           data_format=None, dilation_rate=1):\n    \"\"\"1D convolution.\n\n    # Arguments\n        x: Tensor or variable.\n        kernel: kernel tensor.\n        strides: stride integer.\n        padding: string, `\"same\"`, `\"causal\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        dilation_rate: integer dilate rate.\n\n    # Returns\n        A tensor, result of 1D convolution.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format ' + str(data_format))\n\n    kernel_shape = kernel.get_shape().as_list()\n    if padding == 'causal':\n        # causal (dilated) convolution:\n        left_pad = dilation_rate * (kernel_shape[0] - 1)\n        x = temporal_padding(x, (left_pad, 0))\n        padding = 'valid'\n    padding = _preprocess_padding(padding)\n    if data_format == 'channels_last':\n        tf_data_format = 'NWC'\n    else:\n        tf_data_format = 'NCW'\n    x = tf.nn.convolution(\n        input=x,\n        filter=kernel,\n        dilation_rate=(dilation_rate,),\n        strides=(strides,),\n        padding=padding,\n        data_format=tf_data_format)\n    return x",
        "begin_line": 3104,
        "end_line": 3145,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.conv2d#3148",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.conv2d(x, kernel, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1))",
        "snippet": "def conv2d(x, kernel, strides=(1, 1), padding='valid',\n           data_format=None, dilation_rate=(1, 1)):\n    \"\"\"2D convolution.\n\n    # Arguments\n        x: Tensor or variable.\n        kernel: kernel tensor.\n        strides: strides tuple.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n            Whether to use Theano or TensorFlow/CNTK data format\n            for inputs/kernels/outputs.\n        dilation_rate: tuple of 2 integers.\n\n    # Returns\n        A tensor, result of 2D convolution.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format ' + str(data_format))\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n\n    padding = _preprocess_padding(padding)\n    x = tf.nn.convolution(\n        input=x,\n        filter=kernel,\n        dilation_rate=dilation_rate,\n        strides=strides,\n        padding=padding,\n        data_format=tf_data_format)\n\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x",
        "begin_line": 3148,
        "end_line": 3186,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.conv2d_transpose#3189",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.conv2d_transpose(x, kernel, output_shape, strides=(1, 1), padding='valid', data_format=None)",
        "snippet": "def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n                     padding='valid', data_format=None):\n    \"\"\"2D deconvolution (i.e. transposed convolution).\n\n    # Arguments\n        x: Tensor or variable.\n        kernel: kernel tensor.\n        output_shape: 1D int tensor for the output shape.\n        strides: strides tuple.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n            Whether to use Theano or TensorFlow/CNTK data format\n            for inputs/kernels/outputs.\n\n    # Returns\n        A tensor, result of transposed 2D convolution.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format ' + str(data_format))\n    if isinstance(output_shape, (tuple, list)):\n        output_shape = tf.stack(output_shape)\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        output_shape = (output_shape[0],\n                        output_shape[2],\n                        output_shape[3],\n                        output_shape[1])\n    if output_shape[0] is None:\n        output_shape = (tf.shape(x)[0],) + tuple(output_shape[1:])\n        output_shape = tf.stack(list(output_shape))\n\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NHWC':\n        strides = (1,) + strides + (1,)\n    else:\n        strides = (1, 1) + strides\n\n    x = tf.nn.conv2d_transpose(x, kernel, output_shape, strides,\n                               padding=padding,\n                               data_format=tf_data_format)\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x",
        "begin_line": 3189,
        "end_line": 3238,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.separable_conv2d#3241",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1))",
        "snippet": "def separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1),\n                     padding='valid', data_format=None, dilation_rate=(1, 1)):\n    \"\"\"2D convolution with separable filters.\n\n    # Arguments\n        x: input tensor\n        depthwise_kernel: convolution kernel for the depthwise convolution.\n        pointwise_kernel: kernel for the 1x1 convolution.\n        strides: strides tuple (length 2).\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        dilation_rate: tuple of integers,\n            dilation rates for the separable convolution.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format ' + str(data_format))\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NHWC':\n        strides = (1,) + strides + (1,)\n    else:\n        strides = (1, 1) + strides\n\n    x = tf.nn.separable_conv2d(x, depthwise_kernel, pointwise_kernel,\n                               strides=strides,\n                               padding=padding,\n                               rate=dilation_rate,\n                               data_format=tf_data_format)\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x",
        "begin_line": 3241,
        "end_line": 3280,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.depthwise_conv2d#3283",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.depthwise_conv2d(x, depthwise_kernel, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1))",
        "snippet": "def depthwise_conv2d(x, depthwise_kernel, strides=(1, 1), padding='valid',\n                     data_format=None, dilation_rate=(1, 1)):\n    \"\"\"2D convolution with separable filters.\n\n    # Arguments\n        x: input tensor\n        depthwise_kernel: convolution kernel for the depthwise convolution.\n        strides: strides tuple (length 2).\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        dilation_rate: tuple of integers,\n            dilation rates for the separable convolution.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format ' + str(data_format))\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NHWC':\n        strides = (1,) + strides + (1,)\n    else:\n        strides = (1, 1) + strides\n\n    x = tf.nn.depthwise_conv2d(x, depthwise_kernel,\n                               strides=strides,\n                               padding=padding,\n                               rate=dilation_rate,\n                               data_format=tf_data_format)\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x",
        "begin_line": 3283,
        "end_line": 3321,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.conv3d#3324",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.conv3d(x, kernel, strides=(1, 1, 1), padding='valid', data_format=None, dilation_rate=(1, 1, 1))",
        "snippet": "def conv3d(x, kernel, strides=(1, 1, 1), padding='valid',\n           data_format=None, dilation_rate=(1, 1, 1)):\n    \"\"\"3D convolution.\n\n    # Arguments\n        x: Tensor or variable.\n        kernel: kernel tensor.\n        strides: strides tuple.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n            Whether to use Theano or TensorFlow/CNTK data format\n            for inputs/kernels/outputs.\n        dilation_rate: tuple of 3 integers.\n\n    # Returns\n        A tensor, result of 3D convolution.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format ' + str(data_format))\n\n    x, tf_data_format = _preprocess_conv3d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    x = tf.nn.convolution(\n        input=x,\n        filter=kernel,\n        dilation_rate=dilation_rate,\n        strides=strides,\n        padding=padding,\n        data_format=tf_data_format)\n    if data_format == 'channels_first' and tf_data_format == 'NDHWC':\n        x = tf.transpose(x, (0, 4, 1, 2, 3))\n    return x",
        "begin_line": 3324,
        "end_line": 3360,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.conv3d_transpose#3363",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.conv3d_transpose(x, kernel, output_shape, strides=(1, 1, 1), padding='valid', data_format=None)",
        "snippet": "def conv3d_transpose(x, kernel, output_shape, strides=(1, 1, 1),\n                     padding='valid', data_format=None):\n    \"\"\"3D deconvolution (i.e. transposed convolution).\n\n    # Arguments\n        x: input tensor.\n        kernel: kernel tensor.\n        output_shape: 1D int tensor for the output shape.\n        strides: strides tuple.\n        padding: string, \"same\" or \"valid\".\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n            Whether to use Theano or TensorFlow/CNTK data format\n            for inputs/kernels/outputs.\n\n    # Returns\n        A tensor, result of transposed 3D convolution.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format ' + str(data_format))\n    if isinstance(output_shape, (tuple, list)):\n        output_shape = tf.stack(output_shape)\n\n    x, tf_data_format = _preprocess_conv3d_input(x, data_format)\n\n    if data_format == 'channels_first' and tf_data_format == 'NDHWC':\n        output_shape = (output_shape[0],\n                        output_shape[2],\n                        output_shape[3],\n                        output_shape[4],\n                        output_shape[1])\n    if output_shape[0] is None:\n        output_shape = (tf.shape(x)[0],) + tuple(output_shape[1:])\n        output_shape = tf.stack(list(output_shape))\n\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NDHWC':\n        strides = (1,) + strides + (1,)\n    else:\n        strides = (1, 1) + strides\n\n    x = tf.nn.conv3d_transpose(x, kernel, output_shape, strides,\n                               padding=padding,\n                               data_format=tf_data_format)\n    if data_format == 'channels_first' and tf_data_format == 'NDHWC':\n        x = tf.transpose(x, (0, 4, 1, 2, 3))\n    return x",
        "begin_line": 3363,
        "end_line": 3413,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.pool2d#3416",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.pool2d(x, pool_size, strides=(1, 1), padding='valid', data_format=None, pool_mode='max')",
        "snippet": "def pool2d(x, pool_size, strides=(1, 1),\n           padding='valid', data_format=None,\n           pool_mode='max'):\n    \"\"\"2D Pooling.\n\n    # Arguments\n        x: Tensor or variable.\n        pool_size: tuple of 2 integers.\n        strides: tuple of 2 integers.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        pool_mode: string, `\"max\"` or `\"avg\"`.\n\n    # Returns\n        A tensor, result of 2D pooling.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n        ValueError: if `pool_mode` is neither `\"max\"` or `\"avg\"`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format ' + str(data_format))\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NHWC':\n        strides = (1,) + strides + (1,)\n        pool_size = (1,) + pool_size + (1,)\n    else:\n        strides = (1, 1) + strides\n        pool_size = (1, 1) + pool_size\n\n    if pool_mode == 'max':\n        x = tf.nn.max_pool(x, pool_size, strides,\n                           padding=padding,\n                           data_format=tf_data_format)\n    elif pool_mode == 'avg':\n        x = tf.nn.avg_pool(x, pool_size, strides,\n                           padding=padding,\n                           data_format=tf_data_format)\n    else:\n        raise ValueError('Invalid pooling mode:', pool_mode)\n\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x",
        "begin_line": 3416,
        "end_line": 3463,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.pool3d#3466",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.pool3d(x, pool_size, strides=(1, 1, 1), padding='valid', data_format=None, pool_mode='max')",
        "snippet": "def pool3d(x, pool_size, strides=(1, 1, 1), padding='valid',\n           data_format=None, pool_mode='max'):\n    \"\"\"3D Pooling.\n\n    # Arguments\n        x: Tensor or variable.\n        pool_size: tuple of 3 integers.\n        strides: tuple of 3 integers.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        pool_mode: string, `\"max\"` or `\"avg\"`.\n\n    # Returns\n        A tensor, result of 3D pooling.\n\n    # Raises\n        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n        ValueError: if `pool_mode` is neither `\"max\"` or `\"avg\"`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format ' + str(data_format))\n\n    x, tf_data_format = _preprocess_conv3d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NDHWC':\n        strides = (1,) + strides + (1,)\n        pool_size = (1,) + pool_size + (1,)\n    else:\n        strides = (1, 1) + strides\n        pool_size = (1, 1) + pool_size\n\n    if pool_mode == 'max':\n        x = tf.nn.max_pool3d(x, pool_size, strides,\n                             padding=padding,\n                             data_format=tf_data_format)\n    elif pool_mode == 'avg':\n        x = tf.nn.avg_pool3d(x, pool_size, strides,\n                             padding=padding,\n                             data_format=tf_data_format)\n    else:\n        raise ValueError('Invalid pooling mode:', pool_mode)\n\n    if data_format == 'channels_first' and tf_data_format == 'NDHWC':\n        x = tf.transpose(x, (0, 4, 1, 2, 3))\n    return x",
        "begin_line": 3466,
        "end_line": 3512,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.007936507936507936,
            "pseudo_dstar_susp": 0.001953125,
            "pseudo_tarantula_susp": 0.00847457627118644,
            "pseudo_op2_susp": 0.001953125,
            "pseudo_barinel_susp": 0.00847457627118644
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.bias_add#3515",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.bias_add(x, bias, data_format=None)",
        "snippet": "def bias_add(x, bias, data_format=None):\n    \"\"\"Adds a bias vector to a tensor.\n\n    # Arguments\n        x: Tensor or variable.\n        bias: Bias tensor to add.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: In one of the two cases below:\n                    1. invalid `data_format` argument.\n                    2. invalid bias shape.\n                       the bias should be either a vector or\n                       a tensor with ndim(x) - 1 dimension\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format ' + str(data_format))\n    bias_shape = int_shape(bias)\n    if len(bias_shape) != 1 and len(bias_shape) != ndim(x) - 1:\n        raise ValueError('Unexpected bias dimensions %d, expect to be 1 or %d dimensions'\n                         % (len(bias_shape), ndim(x)))\n    if ndim(x) == 5:\n        if data_format == 'channels_first':\n            if len(bias_shape) == 1:\n                x += reshape(bias, (1, bias_shape[0], 1, 1, 1))\n            else:\n                x += reshape(bias, (1, bias_shape[3]) + bias_shape[:3])\n        elif data_format == 'channels_last':\n            if len(bias_shape) == 1:\n                x += reshape(bias, (1, 1, 1, bias_shape[0]))\n            else:\n                x += reshape(bias, (1,) + bias_shape)\n    elif ndim(x) == 4:\n        if data_format == 'channels_first':\n            if len(bias_shape) == 1:\n                x += reshape(bias, (1, bias_shape[0], 1, 1))\n            else:\n                x += reshape(bias, (1, bias_shape[2]) + bias_shape[:2])\n        elif data_format == 'channels_last':\n            if len(bias_shape) == 1:\n                x = tf.nn.bias_add(x, bias,\n                                   data_format='NHWC')\n            else:\n                x += reshape(bias, (1,) + bias_shape)\n    elif ndim(x) == 3:\n        if data_format == 'channels_first':\n            if len(bias_shape) == 1:\n                x += reshape(bias, (1, bias_shape[0], 1))\n            else:\n                x += reshape(bias, (1, bias_shape[1], bias_shape[0]))\n        elif data_format == 'channels_last':\n            if len(bias_shape) == 1:\n                x += reshape(bias, (1, 1, bias_shape[0]))\n            else:\n                x += reshape(bias, (1, ) + bias_shape)\n    else:\n        x = tf.nn.bias_add(x, bias)\n    return x",
        "begin_line": 3515,
        "end_line": 3577,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007267441860465116,
            "pseudo_dstar_susp": 0.0007267441860465116,
            "pseudo_tarantula_susp": 0.0007358351729212656,
            "pseudo_op2_susp": 0.0007267441860465116,
            "pseudo_barinel_susp": 0.0007358351729212656
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.random_normal#3582",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.random_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None)",
        "snippet": "def random_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n    \"\"\"Returns a tensor with normal distribution of values.\n\n    # Arguments\n        shape: A tuple of integers, the shape of tensor to create.\n        mean: A float, mean of the normal distribution to draw samples.\n        stddev: A float, standard deviation of the normal distribution\n            to draw samples.\n        dtype: String, dtype of returned tensor.\n        seed: Integer, random seed.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(10e6)\n    return tf.random_normal(shape, mean=mean, stddev=stddev,\n                            dtype=dtype, seed=seed)",
        "begin_line": 3582,
        "end_line": 3601,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00012818869375721061,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.random_uniform#3604",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.random_uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None)",
        "snippet": "def random_uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None):\n    \"\"\"Returns a tensor with uniform distribution of values.\n\n    # Arguments\n        shape: A tuple of integers, the shape of tensor to create.\n        minval: A float, lower boundary of the uniform distribution\n            to draw samples.\n        maxval: A float, upper boundary of the uniform distribution\n            to draw samples.\n        dtype: String, dtype of returned tensor.\n        seed: Integer, random seed.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(10e6)\n    return tf.random_uniform(shape, minval=minval, maxval=maxval,\n                             dtype=dtype, seed=seed)",
        "begin_line": 3604,
        "end_line": 3624,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001652892561983471,
            "pseudo_dstar_susp": 0.00909090909090909,
            "pseudo_tarantula_susp": 0.0010787486515641855,
            "pseudo_op2_susp": 0.00909090909090909,
            "pseudo_barinel_susp": 0.0010787486515641855
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.random_binomial#3627",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.random_binomial(shape, p=0.0, dtype=None, seed=None)",
        "snippet": "def random_binomial(shape, p=0.0, dtype=None, seed=None):\n    \"\"\"Returns a tensor with random binomial distribution of values.\n\n    # Arguments\n        shape: A tuple of integers, the shape of tensor to create.\n        p: A float, `0. <= p <= 1`, probability of binomial distribution.\n        dtype: String, dtype of returned tensor.\n        seed: Integer, random seed.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(10e6)\n    return tf.where(tf.random_uniform(shape, dtype=dtype, seed=seed) <= p,\n                    tf.ones(shape, dtype=dtype),\n                    tf.zeros(shape, dtype=dtype))",
        "begin_line": 3627,
        "end_line": 3645,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.truncated_normal#3648",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None)",
        "snippet": "def truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n    \"\"\"Returns a tensor with truncated random normal distribution of values.\n\n    The generated values follow a normal distribution\n    with specified mean and standard deviation,\n    except that values whose magnitude is more than\n    two standard deviations from the mean are dropped and re-picked.\n\n    # Arguments\n        shape: A tuple of integers, the shape of tensor to create.\n        mean: Mean of the values.\n        stddev: Standard deviation of the values.\n        dtype: String, dtype of returned tensor.\n        seed: Integer, random seed.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(10e6)\n    return tf.truncated_normal(shape, mean, stddev, dtype=dtype, seed=seed)",
        "begin_line": 3648,
        "end_line": 3670,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001152604887044721,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.ctc_label_dense_to_sparse#3680",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.ctc_label_dense_to_sparse(labels, label_lengths)",
        "snippet": "def ctc_label_dense_to_sparse(labels, label_lengths):\n    \"\"\"Converts CTC labels from dense to sparse.\n\n    # Arguments\n        labels: dense CTC labels.\n        label_lengths: length of the labels.\n\n    # Returns\n        A sparse tensor representation of the labels.\n    \"\"\"\n    label_shape = tf.shape(labels)\n    num_batches_tns = tf.stack([label_shape[0]])\n    max_num_labels_tns = tf.stack([label_shape[1]])\n\n    def range_less_than(_, current_input):\n        return tf.expand_dims(tf.range(label_shape[1]), 0) < tf.fill(\n            max_num_labels_tns, current_input)\n\n    init = tf.cast(tf.fill([1, label_shape[1]], 0), tf.bool)\n    dense_mask = functional_ops.scan(range_less_than, label_lengths,\n                                     initializer=init, parallel_iterations=1)\n    dense_mask = dense_mask[:, 0, :]\n\n    label_array = tf.reshape(tf.tile(tf.range(label_shape[1]), num_batches_tns),\n                             label_shape)\n    label_ind = tf.boolean_mask(label_array, dense_mask)\n\n    batch_array = tf.transpose(tf.reshape(tf.tile(tf.range(label_shape[0]),\n                                                  max_num_labels_tns), reverse(label_shape, 0)))\n    batch_ind = tf.boolean_mask(batch_array, dense_mask)\n    indices = tf.transpose(tf.reshape(concatenate([batch_ind, label_ind], axis=0), [2, -1]))\n\n    vals_sparse = tf.gather_nd(labels, indices)\n\n    return tf.SparseTensor(tf.to_int64(indices), vals_sparse, tf.to_int64(label_shape))",
        "begin_line": 3680,
        "end_line": 3714,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02127659574468085,
            "pseudo_dstar_susp": 0.0022675736961451248,
            "pseudo_tarantula_susp": 0.023255813953488372,
            "pseudo_op2_susp": 0.0022675736961451248,
            "pseudo_barinel_susp": 0.023255813953488372
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.range_less_than#3694",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.range_less_than(_, current_input)",
        "snippet": "    def range_less_than(_, current_input):\n        return tf.expand_dims(tf.range(label_shape[1]), 0) < tf.fill(\n            max_num_labels_tns, current_input)",
        "begin_line": 3694,
        "end_line": 3696,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 1.0,
            "pseudo_dstar_susp": 0.0029585798816568047,
            "pseudo_tarantula_susp": 0.023255813953488372,
            "pseudo_op2_susp": 0.0029585798816568047,
            "pseudo_barinel_susp": 0.023255813953488372
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.ctc_batch_cost#3717",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)",
        "snippet": "def ctc_batch_cost(y_true, y_pred, input_length, label_length):\n    \"\"\"Runs CTC loss algorithm on each batch element.\n\n    # Arguments\n        y_true: tensor `(samples, max_string_length)`\n            containing the truth labels.\n        y_pred: tensor `(samples, time_steps, num_categories)`\n            containing the prediction, or output of the softmax.\n        input_length: tensor `(samples, 1)` containing the sequence length for\n            each batch item in `y_pred`.\n        label_length: tensor `(samples, 1)` containing the sequence length for\n            each batch item in `y_true`.\n\n    # Returns\n        Tensor with shape (samples,1) containing the\n            CTC loss of each element.\n    \"\"\"\n    label_length = tf.to_int32(tf.squeeze(label_length))\n    input_length = tf.to_int32(tf.squeeze(input_length))\n    sparse_labels = tf.to_int32(ctc_label_dense_to_sparse(y_true, label_length))\n\n    y_pred = tf.log(tf.transpose(y_pred, perm=[1, 0, 2]) + 1e-8)\n\n    return tf.expand_dims(ctc.ctc_loss(inputs=y_pred,\n                                       labels=sparse_labels,\n                                       sequence_length=input_length), 1)",
        "begin_line": 3717,
        "end_line": 3742,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02127659574468085,
            "pseudo_dstar_susp": 0.0022675736961451248,
            "pseudo_tarantula_susp": 0.023255813953488372,
            "pseudo_op2_susp": 0.0022675736961451248,
            "pseudo_barinel_susp": 0.023255813953488372
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.ctc_decode#3745",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.ctc_decode(y_pred, input_length, greedy=True, beam_width=100, top_paths=1)",
        "snippet": "def ctc_decode(y_pred, input_length, greedy=True, beam_width=100,\n               top_paths=1):\n    \"\"\"Decodes the output of a softmax.\n\n    Can use either greedy search (also known as best path)\n    or a constrained dictionary search.\n\n    # Arguments\n        y_pred: tensor `(samples, time_steps, num_categories)`\n            containing the prediction, or output of the softmax.\n        input_length: tensor `(samples, )` containing the sequence length for\n            each batch item in `y_pred`.\n        greedy: perform much faster best-path search if `true`.\n            This does not use a dictionary.\n        beam_width: if `greedy` is `false`: a beam search decoder will be used\n            with a beam of this width.\n        top_paths: if `greedy` is `false`,\n            how many of the most probable paths will be returned.\n\n    # Returns\n        Tuple:\n            List: if `greedy` is `true`, returns a list of one element that\n                contains the decoded sequence.\n                If `false`, returns the `top_paths` most probable\n                decoded sequences.\n                Important: blank labels are returned as `-1`.\n            Tensor `(top_paths, )` that contains\n                the log probability of each decoded sequence.\n    \"\"\"\n    y_pred = tf.log(tf.transpose(y_pred, perm=[1, 0, 2]) + 1e-8)\n    input_length = tf.to_int32(input_length)\n\n    if greedy:\n        (decoded, log_prob) = ctc.ctc_greedy_decoder(\n            inputs=y_pred,\n            sequence_length=input_length)\n    else:\n        (decoded, log_prob) = ctc.ctc_beam_search_decoder(\n            inputs=y_pred,\n            sequence_length=input_length, beam_width=beam_width,\n            top_paths=top_paths)\n\n    decoded_dense = [tf.sparse_to_dense(st.indices, st.dense_shape, st.values, default_value=-1)\n                     for st in decoded]\n    return (decoded_dense, log_prob)",
        "begin_line": 3745,
        "end_line": 3789,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02127659574468085,
            "pseudo_dstar_susp": 0.0029239766081871343,
            "pseudo_tarantula_susp": 0.023255813953488372,
            "pseudo_op2_susp": 0.0029239766081871343,
            "pseudo_barinel_susp": 0.023255813953488372
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.map_fn#3794",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.map_fn(fn, elems, name=None, dtype=None)",
        "snippet": "def map_fn(fn, elems, name=None, dtype=None):\n    \"\"\"Map the function fn over the elements elems and return the outputs.\n\n    # Arguments\n        fn: Callable that will be called upon each element in elems\n        elems: tensor\n        name: A string name for the map node in the graph\n        dtype: Output data type.\n\n    # Returns\n        Tensor with dtype `dtype`.\n    \"\"\"\n    return tf.map_fn(fn, elems, name=name, dtype=dtype)",
        "begin_line": 3794,
        "end_line": 3806,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.foldl#3809",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.foldl(fn, elems, initializer=None, name=None)",
        "snippet": "def foldl(fn, elems, initializer=None, name=None):\n    \"\"\"Reduce elems using fn to combine them from left to right.\n\n    # Arguments\n        fn: Callable that will be called upon each element in elems and an\n            accumulator, for instance `lambda acc, x: acc + x`\n        elems: tensor\n        initializer: The first value used (`elems[0]` in case of None)\n        name: A string name for the foldl node in the graph\n\n    # Returns\n        Tensor with same type and shape as `initializer`.\n    \"\"\"\n    return tf.foldl(fn, elems, initializer=initializer, name=name)",
        "begin_line": 3809,
        "end_line": 3822,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.foldr#3825",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.foldr(fn, elems, initializer=None, name=None)",
        "snippet": "def foldr(fn, elems, initializer=None, name=None):\n    \"\"\"Reduce elems using fn to combine them from right to left.\n\n    # Arguments\n        fn: Callable that will be called upon each element in elems and an\n            accumulator, for instance `lambda acc, x: acc + x`\n        elems: tensor\n        initializer: The first value used (`elems[-1]` in case of None)\n        name: A string name for the foldr node in the graph\n\n    # Returns\n        Tensor with same type and shape as `initializer`.\n    \"\"\"\n    return tf.foldr(fn, elems, initializer=initializer, name=name)",
        "begin_line": 3825,
        "end_line": 3838,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.local_conv1d#3841",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.local_conv1d(inputs, kernel, kernel_size, strides, data_format=None)",
        "snippet": "def local_conv1d(inputs, kernel, kernel_size, strides, data_format=None):\n    \"\"\"Apply 1D conv with un-shared weights.\n\n    # Arguments\n        inputs: 3D tensor with shape: (batch_size, steps, input_dim)\n        kernel: the unshared weight for convolution,\n                with shape (output_length, feature_dim, filters)\n        kernel_size: a tuple of a single integer,\n                     specifying the length of the 1D convolution window\n        strides: a tuple of a single integer,\n                 specifying the stride length of the convolution\n        data_format: the data format, channels_first or channels_last\n\n    # Returns\n        the tensor after 1d conv with un-shared weights, with shape (batch_size, output_length, filters)\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format ' + str(data_format))\n\n    stride = strides[0]\n    kernel_shape = int_shape(kernel)\n    output_length, feature_dim, filters = kernel_shape\n\n    xs = []\n    for i in range(output_length):\n        slice_length = slice(i * stride,\n                             i * stride + kernel_size[0])\n        xs.append(reshape(inputs[:, slice_length, :],\n                          (1, -1, feature_dim)))\n    x_aggregate = concatenate(xs, axis=0)\n    # Shape: `(output_length, batch_size, filters)`.\n    output = batch_dot(x_aggregate, kernel)\n    return permute_dimensions(output, (1, 0, 2))",
        "begin_line": 3841,
        "end_line": 3878,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.local_conv2d#3881",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.local_conv2d(inputs, kernel, kernel_size, strides, output_shape, data_format=None)",
        "snippet": "def local_conv2d(inputs, kernel, kernel_size, strides, output_shape, data_format=None):\n    \"\"\"Apply 2D conv with un-shared weights.\n\n    # Arguments\n        inputs: 4D tensor with shape:\n                (batch_size, filters, new_rows, new_cols)\n                if data_format='channels_first'\n                or 4D tensor with shape:\n                (batch_size, new_rows, new_cols, filters)\n                if data_format='channels_last'.\n        kernel: the unshared weight for convolution,\n                with shape (output_items, feature_dim, filters)\n        kernel_size: a tuple of 2 integers, specifying the\n                     width and height of the 2D convolution window.\n        strides: a tuple of 2 integers, specifying the strides\n                 of the convolution along the width and height.\n        output_shape: a tuple with (output_row, output_col)\n        data_format: the data format, channels_first or channels_last\n\n    # Returns\n        A 4d tensor with shape:\n        (batch_size, filters, new_rows, new_cols)\n        if data_format='channels_first'\n        or 4D tensor with shape:\n        (batch_size, new_rows, new_cols, filters)\n        if data_format='channels_last'.\n\n    # Raises\n        ValueError: if `data_format` is neither\n                    `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format ' + str(data_format))\n\n    stride_row, stride_col = strides\n    output_row, output_col = output_shape\n    kernel_shape = int_shape(kernel)\n    _, feature_dim, filters = kernel_shape\n\n    xs = []\n    for i in range(output_row):\n        for j in range(output_col):\n            slice_row = slice(i * stride_row,\n                              i * stride_row + kernel_size[0])\n            slice_col = slice(j * stride_col,\n                              j * stride_col + kernel_size[1])\n            if data_format == 'channels_first':\n                xs.append(reshape(inputs[:, :, slice_row, slice_col],\n                                  (1, -1, feature_dim)))\n            else:\n                xs.append(reshape(inputs[:, slice_row, slice_col, :],\n                                  (1, -1, feature_dim)))\n\n    x_aggregate = concatenate(xs, axis=0)\n    output = batch_dot(x_aggregate, kernel)\n    output = reshape(output,\n                     (output_row, output_col, -1, filters))\n\n    if data_format == 'channels_first':\n        output = permute_dimensions(output, (2, 3, 0, 1))\n    else:\n        output = permute_dimensions(output, (2, 0, 1, 3))\n    return output",
        "begin_line": 3881,
        "end_line": 3945,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.applications.inception_resnet_v2.conv2d_bn#56",
        "src_path": "keras/applications/inception_resnet_v2.py",
        "class_name": "keras.applications.inception_resnet_v2",
        "signature": "keras.applications.inception_resnet_v2.conv2d_bn(x, filters, kernel_size, strides=1, padding='same', activation='relu', use_bias=False, name=None)",
        "snippet": "def conv2d_bn(x,\n              filters,\n              kernel_size,\n              strides=1,\n              padding='same',\n              activation='relu',\n              use_bias=False,\n              name=None):\n    \"\"\"Utility function to apply conv + BN.\n\n    # Arguments\n        x: input tensor.\n        filters: filters in `Conv2D`.\n        kernel_size: kernel size as in `Conv2D`.\n        strides: strides in `Conv2D`.\n        padding: padding mode in `Conv2D`.\n        activation: activation in `Conv2D`.\n        use_bias: whether to use a bias in `Conv2D`.\n        name: name of the ops; will become `name + '_ac'` for the activation\n            and `name + '_bn'` for the batch norm layer.\n\n    # Returns\n        Output tensor after applying `Conv2D` and `BatchNormalization`.\n    \"\"\"\n    x = Conv2D(filters,\n               kernel_size,\n               strides=strides,\n               padding=padding,\n               use_bias=use_bias,\n               name=name)(x)\n    if not use_bias:\n        bn_axis = 1 if K.image_data_format() == 'channels_first' else 3\n        bn_name = None if name is None else name + '_bn'\n        x = BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n    if activation is not None:\n        ac_name = None if name is None else name + '_ac'\n        x = Activation(activation, name=ac_name)(x)\n    return x",
        "begin_line": 56,
        "end_line": 93,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.applications.inception_resnet_v2.inception_resnet_block#96",
        "src_path": "keras/applications/inception_resnet_v2.py",
        "class_name": "keras.applications.inception_resnet_v2",
        "signature": "keras.applications.inception_resnet_v2.inception_resnet_block(x, scale, block_type, block_idx, activation='relu')",
        "snippet": "def inception_resnet_block(x, scale, block_type, block_idx, activation='relu'):\n    \"\"\"Adds a Inception-ResNet block.\n\n    This function builds 3 types of Inception-ResNet blocks mentioned\n    in the paper, controlled by the `block_type` argument (which is the\n    block name used in the official TF-slim implementation):\n        - Inception-ResNet-A: `block_type='block35'`\n        - Inception-ResNet-B: `block_type='block17'`\n        - Inception-ResNet-C: `block_type='block8'`\n\n    # Arguments\n        x: input tensor.\n        scale: scaling factor to scale the residuals (i.e., the output of\n            passing `x` through an inception module) before adding them\n            to the shortcut branch. Let `r` be the output from the residual branch,\n            the output of this block will be `x + scale * r`.\n        block_type: `'block35'`, `'block17'` or `'block8'`, determines\n            the network structure in the residual branch.\n        block_idx: an `int` used for generating layer names. The Inception-ResNet blocks\n            are repeated many times in this network. We use `block_idx` to identify\n            each of the repetitions. For example, the first Inception-ResNet-A block\n            will have `block_type='block35', block_idx=0`, ane the layer names will have\n            a common prefix `'block35_0'`.\n        activation: activation function to use at the end of the block\n            (see [activations](../activations.md)).\n            When `activation=None`, no activation is applied\n            (i.e., \"linear\" activation: `a(x) = x`).\n\n    # Returns\n        Output tensor for the block.\n\n    # Raises\n        ValueError: if `block_type` is not one of `'block35'`,\n            `'block17'` or `'block8'`.\n    \"\"\"\n    if block_type == 'block35':\n        branch_0 = conv2d_bn(x, 32, 1)\n        branch_1 = conv2d_bn(x, 32, 1)\n        branch_1 = conv2d_bn(branch_1, 32, 3)\n        branch_2 = conv2d_bn(x, 32, 1)\n        branch_2 = conv2d_bn(branch_2, 48, 3)\n        branch_2 = conv2d_bn(branch_2, 64, 3)\n        branches = [branch_0, branch_1, branch_2]\n    elif block_type == 'block17':\n        branch_0 = conv2d_bn(x, 192, 1)\n        branch_1 = conv2d_bn(x, 128, 1)\n        branch_1 = conv2d_bn(branch_1, 160, [1, 7])\n        branch_1 = conv2d_bn(branch_1, 192, [7, 1])\n        branches = [branch_0, branch_1]\n    elif block_type == 'block8':\n        branch_0 = conv2d_bn(x, 192, 1)\n        branch_1 = conv2d_bn(x, 192, 1)\n        branch_1 = conv2d_bn(branch_1, 224, [1, 3])\n        branch_1 = conv2d_bn(branch_1, 256, [3, 1])\n        branches = [branch_0, branch_1]\n    else:\n        raise ValueError('Unknown Inception-ResNet block type. '\n                         'Expects \"block35\", \"block17\" or \"block8\", '\n                         'but got: ' + str(block_type))\n\n    block_name = block_type + '_' + str(block_idx)\n    channel_axis = 1 if K.image_data_format() == 'channels_first' else 3\n    mixed = Concatenate(axis=channel_axis, name=block_name + '_mixed')(branches)\n    up = conv2d_bn(mixed,\n                   K.int_shape(x)[channel_axis],\n                   1,\n                   activation=None,\n                   use_bias=True,\n                   name=block_name + '_conv')\n\n    x = Lambda(lambda inputs, scale: inputs[0] + inputs[1] * scale,\n               output_shape=K.int_shape(x)[1:],\n               arguments={'scale': scale},\n               name=block_name)([x, up])\n    if activation is not None:\n        x = Activation(activation, name=block_name + '_ac')(x)\n    return x",
        "begin_line": 96,
        "end_line": 172,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.applications.inception_resnet_v2.InceptionResNetV2#175",
        "src_path": "keras/applications/inception_resnet_v2.py",
        "class_name": "keras.applications.inception_resnet_v2",
        "signature": "keras.applications.inception_resnet_v2.InceptionResNetV2(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)",
        "snippet": "def InceptionResNetV2(include_top=True,\n                      weights='imagenet',\n                      input_tensor=None,\n                      input_shape=None,\n                      pooling=None,\n                      classes=1000):\n    \"\"\"Instantiates the Inception-ResNet v2 architecture.\n\n    Optionally loads weights pre-trained on ImageNet.\n    Note that when using TensorFlow, for best performance you should\n    set `\"image_data_format\": \"channels_last\"` in your Keras config\n    at `~/.keras/keras.json`.\n\n    The model and the weights are compatible with TensorFlow, Theano and\n    CNTK backends. The data format convention used by the model is\n    the one specified in your Keras config file.\n\n    Note that the default input image size for this model is 299x299, instead\n    of 224x224 as in the VGG16 and ResNet models. Also, the input preprocessing\n    function is different (i.e., do not use `imagenet_utils.preprocess_input()`\n    with this model. Use `preprocess_input()` defined in this module instead).\n\n    # Arguments\n        include_top: whether to include the fully-connected\n            layer at the top of the network.\n        weights: one of `None` (random initialization)\n            or `'imagenet'` (pre-training on ImageNet).\n        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n            to use as image input for the model.\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is `False` (otherwise the input shape\n            has to be `(299, 299, 3)` (with `'channels_last'` data format)\n            or `(3, 299, 299)` (with `'channels_first'` data format).\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 139.\n            E.g. `(150, 150, 3)` would be one valid value.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model will be\n                the 4D tensor output of the last convolutional layer.\n            - `'avg'` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a 2D tensor.\n            - `'max'` means that global max pooling will be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is `True`, and\n            if no `weights` argument is specified.\n\n    # Returns\n        A Keras `Model` instance.\n\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n    \"\"\"\n    if weights not in {'imagenet', None}:\n        raise ValueError('The `weights` argument should be either '\n                         '`None` (random initialization) or `imagenet` '\n                         '(pre-training on ImageNet).')\n\n    if weights == 'imagenet' and include_top and classes != 1000:\n        raise ValueError('If using `weights` as imagenet with `include_top`'\n                         ' as true, `classes` should be 1000')\n\n    # Determine proper input shape\n    input_shape = _obtain_input_shape(\n        input_shape,\n        default_size=299,\n        min_size=139,\n        data_format=K.image_data_format(),\n        require_flatten=False,\n        weights=weights)\n\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n\n    # Stem block: 35 x 35 x 192\n    x = conv2d_bn(img_input, 32, 3, strides=2, padding='valid')\n    x = conv2d_bn(x, 32, 3, padding='valid')\n    x = conv2d_bn(x, 64, 3)\n    x = MaxPooling2D(3, strides=2)(x)\n    x = conv2d_bn(x, 80, 1, padding='valid')\n    x = conv2d_bn(x, 192, 3, padding='valid')\n    x = MaxPooling2D(3, strides=2)(x)\n\n    # Mixed 5b (Inception-A block): 35 x 35 x 320\n    branch_0 = conv2d_bn(x, 96, 1)\n    branch_1 = conv2d_bn(x, 48, 1)\n    branch_1 = conv2d_bn(branch_1, 64, 5)\n    branch_2 = conv2d_bn(x, 64, 1)\n    branch_2 = conv2d_bn(branch_2, 96, 3)\n    branch_2 = conv2d_bn(branch_2, 96, 3)\n    branch_pool = AveragePooling2D(3, strides=1, padding='same')(x)\n    branch_pool = conv2d_bn(branch_pool, 64, 1)\n    branches = [branch_0, branch_1, branch_2, branch_pool]\n    channel_axis = 1 if K.image_data_format() == 'channels_first' else 3\n    x = Concatenate(axis=channel_axis, name='mixed_5b')(branches)\n\n    # 10x block35 (Inception-ResNet-A block): 35 x 35 x 320\n    for block_idx in range(1, 11):\n        x = inception_resnet_block(x,\n                                   scale=0.17,\n                                   block_type='block35',\n                                   block_idx=block_idx)\n\n    # Mixed 6a (Reduction-A block): 17 x 17 x 1088\n    branch_0 = conv2d_bn(x, 384, 3, strides=2, padding='valid')\n    branch_1 = conv2d_bn(x, 256, 1)\n    branch_1 = conv2d_bn(branch_1, 256, 3)\n    branch_1 = conv2d_bn(branch_1, 384, 3, strides=2, padding='valid')\n    branch_pool = MaxPooling2D(3, strides=2, padding='valid')(x)\n    branches = [branch_0, branch_1, branch_pool]\n    x = Concatenate(axis=channel_axis, name='mixed_6a')(branches)\n\n    # 20x block17 (Inception-ResNet-B block): 17 x 17 x 1088\n    for block_idx in range(1, 21):\n        x = inception_resnet_block(x,\n                                   scale=0.1,\n                                   block_type='block17',\n                                   block_idx=block_idx)\n\n    # Mixed 7a (Reduction-B block): 8 x 8 x 2080\n    branch_0 = conv2d_bn(x, 256, 1)\n    branch_0 = conv2d_bn(branch_0, 384, 3, strides=2, padding='valid')\n    branch_1 = conv2d_bn(x, 256, 1)\n    branch_1 = conv2d_bn(branch_1, 288, 3, strides=2, padding='valid')\n    branch_2 = conv2d_bn(x, 256, 1)\n    branch_2 = conv2d_bn(branch_2, 288, 3)\n    branch_2 = conv2d_bn(branch_2, 320, 3, strides=2, padding='valid')\n    branch_pool = MaxPooling2D(3, strides=2, padding='valid')(x)\n    branches = [branch_0, branch_1, branch_2, branch_pool]\n    x = Concatenate(axis=channel_axis, name='mixed_7a')(branches)\n\n    # 10x block8 (Inception-ResNet-C block): 8 x 8 x 2080\n    for block_idx in range(1, 10):\n        x = inception_resnet_block(x,\n                                   scale=0.2,\n                                   block_type='block8',\n                                   block_idx=block_idx)\n    x = inception_resnet_block(x,\n                               scale=1.,\n                               activation=None,\n                               block_type='block8',\n                               block_idx=10)\n\n    # Final convolution block: 8 x 8 x 1536\n    x = conv2d_bn(x, 1536, 1, name='conv_7b')\n\n    if include_top:\n        # Classification block\n        x = GlobalAveragePooling2D(name='avg_pool')(x)\n        x = Dense(classes, activation='softmax', name='predictions')(x)\n    else:\n        if pooling == 'avg':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling == 'max':\n            x = GlobalMaxPooling2D()(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n\n    # Create model\n    model = Model(inputs, x, name='inception_resnet_v2')\n\n    # Load weights\n    if weights == 'imagenet':\n        if K.image_data_format() == 'channels_first':\n            if K.backend() == 'tensorflow':\n                warnings.warn('You are using the TensorFlow backend, yet you '\n                              'are using the Theano '\n                              'image data format convention '\n                              '(`image_data_format=\"channels_first\"`). '\n                              'For best performance, set '\n                              '`image_data_format=\"channels_last\"` in '\n                              'your Keras config '\n                              'at ~/.keras/keras.json.')\n        if include_top:\n            weights_filename = 'inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5'\n            weights_path = get_file(weights_filename,\n                                    BASE_WEIGHT_URL + weights_filename,\n                                    cache_subdir='models',\n                                    file_hash='e693bd0210a403b3192acc6073ad2e96')\n        else:\n            weights_filename = 'inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5'\n            weights_path = get_file(weights_filename,\n                                    BASE_WEIGHT_URL + weights_filename,\n                                    cache_subdir='models',\n                                    file_hash='d19885ff4a710c122648d3b5c3b684e4')\n        model.load_weights(weights_path)\n\n    return model",
        "begin_line": 175,
        "end_line": 375,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.conv_utils.normalize_tuple#6",
        "src_path": "keras/utils/conv_utils.py",
        "class_name": "keras.utils.conv_utils",
        "signature": "keras.utils.conv_utils.normalize_tuple(value, n, name)",
        "snippet": "def normalize_tuple(value, n, name):\n    \"\"\"Transforms a single int or iterable of ints into an int tuple.\n\n    # Arguments\n        value: The value to validate and convert. Could an int, or any iterable\n          of ints.\n        n: The size of the tuple to be returned.\n        name: The name of the argument being validated, e.g. \"strides\" or\n          \"kernel_size\". This is only used to format error messages.\n\n    # Returns\n        A tuple of n integers.\n\n    # Raises\n        ValueError: If something else than an int/long or iterable thereof was\n        passed.\n    \"\"\"\n    if isinstance(value, int):\n        return (value,) * n\n    else:\n        try:\n            value_tuple = tuple(value)\n        except TypeError:\n            raise ValueError('The `' + name + '` argument must be a tuple of ' +\n                             str(n) + ' integers. Received: ' + str(value))\n        if len(value_tuple) != n:\n            raise ValueError('The `' + name + '` argument must be a tuple of ' +\n                             str(n) + ' integers. Received: ' + str(value))\n        for single_value in value_tuple:\n            try:\n                int(single_value)\n            except ValueError:\n                raise ValueError('The `' + name + '` argument must be a tuple of ' +\n                                 str(n) + ' integers. Received: ' + str(value) + ' '\n                                 'including element ' + str(single_value) + ' of type' +\n                                 ' ' + str(type(single_value)))\n    return value_tuple",
        "begin_line": 6,
        "end_line": 42,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.92950054612253e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.conv_utils.normalize_data_format#45",
        "src_path": "keras/utils/conv_utils.py",
        "class_name": "keras.utils.conv_utils",
        "signature": "keras.utils.conv_utils.normalize_data_format(value)",
        "snippet": "def normalize_data_format(value):\n    if value is None:\n        value = K.image_data_format()\n    data_format = value.lower()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('The `data_format` argument must be one of '\n                         '\"channels_first\", \"channels_last\". Received: ' +\n                         str(value))\n    return data_format",
        "begin_line": 45,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.458948164964057e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.conv_utils.normalize_padding#56",
        "src_path": "keras/utils/conv_utils.py",
        "class_name": "keras.utils.conv_utils",
        "signature": "keras.utils.conv_utils.normalize_padding(value)",
        "snippet": "def normalize_padding(value):\n    padding = value.lower()\n    allowed = {'valid', 'same', 'causal'}\n    if K.backend() == 'theano':\n        allowed.add('full')\n    if padding not in allowed:\n        raise ValueError('The `padding` argument must be one of \"valid\", \"same\" (or \"causal\" for Conv1D). '\n                         'Received: ' + str(padding))\n    return padding",
        "begin_line": 56,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.396729937981582e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.conv_utils.convert_kernel#67",
        "src_path": "keras/utils/conv_utils.py",
        "class_name": "keras.utils.conv_utils",
        "signature": "keras.utils.conv_utils.convert_kernel(kernel)",
        "snippet": "def convert_kernel(kernel):\n    \"\"\"Converts a Numpy kernel matrix from Theano format to TensorFlow format.\n\n    Also works reciprocally, since the transformation is its own inverse.\n\n    # Arguments\n        kernel: Numpy array (3D, 4D or 5D).\n\n    # Returns\n        The converted kernel.\n\n    # Raises\n        ValueError: in case of invalid kernel shape or invalid data_format.\n    \"\"\"\n    kernel = np.asarray(kernel)\n    if not 3 <= kernel.ndim <= 5:\n        raise ValueError('Invalid kernel shape:', kernel.shape)\n    slices = [slice(None, None, -1) for _ in range(kernel.ndim)]\n    no_flip = (slice(None, None), slice(None, None))\n    slices[-2:] = no_flip\n    return np.copy(kernel[slices])",
        "begin_line": 67,
        "end_line": 87,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.conv_utils.conv_output_length#90",
        "src_path": "keras/utils/conv_utils.py",
        "class_name": "keras.utils.conv_utils",
        "signature": "keras.utils.conv_utils.conv_output_length(input_length, filter_size, padding, stride, dilation=1)",
        "snippet": "def conv_output_length(input_length, filter_size,\n                       padding, stride, dilation=1):\n    \"\"\"Determines output length of a convolution given input length.\n\n    # Arguments\n        input_length: integer.\n        filter_size: integer.\n        padding: one of \"same\", \"valid\", \"full\".\n        stride: integer.\n        dilation: dilation rate, integer.\n\n    # Returns\n        The output length (integer).\n    \"\"\"\n    if input_length is None:\n        return None\n    assert padding in {'same', 'valid', 'full', 'causal'}\n    dilated_filter_size = filter_size + (filter_size - 1) * (dilation - 1)\n    if padding == 'same':\n        output_length = input_length\n    elif padding == 'valid':\n        output_length = input_length - dilated_filter_size + 1\n    elif padding == 'causal':\n        output_length = input_length\n    elif padding == 'full':\n        output_length = input_length + dilated_filter_size - 1\n    return (output_length + stride - 1) // stride",
        "begin_line": 90,
        "end_line": 116,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.conv_utils.deconv_length#143",
        "src_path": "keras/utils/conv_utils.py",
        "class_name": "keras.utils.conv_utils",
        "signature": "keras.utils.conv_utils.deconv_length(dim_size, stride_size, kernel_size, padding)",
        "snippet": "def deconv_length(dim_size, stride_size, kernel_size, padding):\n    if dim_size is None:\n        return None\n    if padding == 'valid':\n        dim_size = dim_size * stride_size + max(kernel_size - stride_size, 0)\n    elif padding == 'full':\n        dim_size = dim_size * stride_size - (stride_size + kernel_size - 2)\n    elif padding == 'same':\n        dim_size = dim_size * stride_size\n    return dim_size",
        "begin_line": 143,
        "end_line": 152,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.data_utils._extract_archive#74",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils",
        "signature": "keras.utils.data_utils._extract_archive(file_path, path='.', archive_format='auto')",
        "snippet": "def _extract_archive(file_path, path='.', archive_format='auto'):\n    \"\"\"Extracts an archive if it matches tar, tar.gz, tar.bz, or zip formats.\n\n    # Arguments\n        file_path: path to the archive file\n        path: path to extract the archive file\n        archive_format: Archive format to try for extracting the file.\n            Options are 'auto', 'tar', 'zip', and None.\n            'tar' includes tar, tar.gz, and tar.bz files.\n            The default 'auto' is ['tar', 'zip'].\n            None or an empty list will return no matches found.\n\n    # Returns\n        True if a match was found and an archive extraction was completed,\n        False otherwise.\n    \"\"\"\n    if archive_format is None:\n        return False\n    if archive_format is 'auto':\n        archive_format = ['tar', 'zip']\n    if isinstance(archive_format, six.string_types):\n        archive_format = [archive_format]\n\n    for archive_type in archive_format:\n        if archive_type is 'tar':\n            open_fn = tarfile.open\n            is_match_fn = tarfile.is_tarfile\n        if archive_type is 'zip':\n            open_fn = zipfile.ZipFile\n            is_match_fn = zipfile.is_zipfile\n\n        if is_match_fn(file_path):\n            with open_fn(file_path) as archive:\n                try:\n                    archive.extractall(path)\n                except (tarfile.TarError, RuntimeError,\n                        KeyboardInterrupt):\n                    if os.path.exists(path):\n                        if os.path.isfile(path):\n                            os.remove(path)\n                        else:\n                            shutil.rmtree(path)\n                    raise\n            return True\n    return False",
        "begin_line": 74,
        "end_line": 118,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.data_utils.get_file#121",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils",
        "signature": "keras.utils.data_utils.get_file(fname, origin, untar=False, md5_hash=None, file_hash=None, cache_subdir='datasets', hash_algorithm='auto', extract=False, archive_format='auto', cache_dir=None)",
        "snippet": "def get_file(fname,\n             origin,\n             untar=False,\n             md5_hash=None,\n             file_hash=None,\n             cache_subdir='datasets',\n             hash_algorithm='auto',\n             extract=False,\n             archive_format='auto',\n             cache_dir=None):\n    \"\"\"Downloads a file from a URL if it not already in the cache.\n\n    By default the file at the url `origin` is downloaded to the\n    cache_dir `~/.keras`, placed in the cache_subdir `datasets`,\n    and given the filename `fname`. The final location of a file\n    `example.txt` would therefore be `~/.keras/datasets/example.txt`.\n\n    Files in tar, tar.gz, tar.bz, and zip formats can also be extracted.\n    Passing a hash will verify the file after download. The command line\n    programs `shasum` and `sha256sum` can compute the hash.\n\n    # Arguments\n        fname: Name of the file. If an absolute path `/path/to/file.txt` is\n            specified the file will be saved at that location.\n        origin: Original URL of the file.\n        untar: Deprecated in favor of 'extract'.\n            boolean, whether the file should be decompressed\n        md5_hash: Deprecated in favor of 'file_hash'.\n            md5 hash of the file for verification\n        file_hash: The expected hash string of the file after download.\n            The sha256 and md5 hash algorithms are both supported.\n        cache_subdir: Subdirectory under the Keras cache dir where the file is\n            saved. If an absolute path `/path/to/folder` is\n            specified the file will be saved at that location.\n        hash_algorithm: Select the hash algorithm to verify the file.\n            options are 'md5', 'sha256', and 'auto'.\n            The default 'auto' detects the hash algorithm in use.\n        extract: True tries extracting the file as an Archive, like tar or zip.\n        archive_format: Archive format to try for extracting the file.\n            Options are 'auto', 'tar', 'zip', and None.\n            'tar' includes tar, tar.gz, and tar.bz files.\n            The default 'auto' is ['tar', 'zip'].\n            None or an empty list will return no matches found.\n        cache_dir: Location to store cached files, when None it\n            defaults to the [Keras Directory](/faq/#where-is-the-keras-configuration-filed-stored).\n\n    # Returns\n        Path to the downloaded file\n    \"\"\"\n    if cache_dir is None:\n        cache_dir = os.path.expanduser(os.path.join('~', '.keras'))\n    if md5_hash is not None and file_hash is None:\n        file_hash = md5_hash\n        hash_algorithm = 'md5'\n    datadir_base = os.path.expanduser(cache_dir)\n    if not os.access(datadir_base, os.W_OK):\n        datadir_base = os.path.join('/tmp', '.keras')\n    datadir = os.path.join(datadir_base, cache_subdir)\n    if not os.path.exists(datadir):\n        os.makedirs(datadir)\n\n    if untar:\n        untar_fpath = os.path.join(datadir, fname)\n        fpath = untar_fpath + '.tar.gz'\n    else:\n        fpath = os.path.join(datadir, fname)\n\n    download = False\n    if os.path.exists(fpath):\n        # File found; verify integrity if a hash was provided.\n        if file_hash is not None:\n            if not validate_file(fpath, file_hash, algorithm=hash_algorithm):\n                print('A local file was found, but it seems to be '\n                      'incomplete or outdated because the ' + hash_algorithm +\n                      ' file hash does not match the original value of ' +\n                      file_hash + ' so we will re-download the data.')\n                download = True\n    else:\n        download = True\n\n    if download:\n        print('Downloading data from', origin)\n\n        class ProgressTracker(object):\n            # Maintain progbar for the lifetime of download.\n            # This design was chosen for Python 2.7 compatibility.\n            progbar = None\n\n        def dl_progress(count, block_size, total_size):\n            if ProgressTracker.progbar is None:\n                if total_size is -1:\n                    total_size = None\n                ProgressTracker.progbar = Progbar(total_size)\n            else:\n                ProgressTracker.progbar.update(count * block_size)\n\n        error_msg = 'URL fetch failure on {}: {} -- {}'\n        try:\n            try:\n                urlretrieve(origin, fpath, dl_progress)\n            except URLError as e:\n                raise Exception(error_msg.format(origin, e.errno, e.reason))\n            except HTTPError as e:\n                raise Exception(error_msg.format(origin, e.code, e.msg))\n        except (Exception, KeyboardInterrupt) as e:\n            if os.path.exists(fpath):\n                os.remove(fpath)\n            raise\n        ProgressTracker.progbar = None\n\n    if untar:\n        if not os.path.exists(untar_fpath):\n            _extract_archive(fpath, datadir, archive_format='tar')\n        return untar_fpath\n\n    if extract:\n        _extract_archive(fpath, datadir, archive_format)\n\n    return fpath",
        "begin_line": 121,
        "end_line": 239,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.data_utils.ProgressTracker.get_file#121",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.ProgressTracker",
        "signature": "keras.utils.data_utils.ProgressTracker.get_file(fname, origin, untar=False, md5_hash=None, file_hash=None, cache_subdir='datasets', hash_algorithm='auto', extract=False, archive_format='auto', cache_dir=None)",
        "snippet": "def get_file(fname,\n             origin,\n             untar=False,\n             md5_hash=None,\n             file_hash=None,\n             cache_subdir='datasets',\n             hash_algorithm='auto',\n             extract=False,\n             archive_format='auto',\n             cache_dir=None):\n    \"\"\"Downloads a file from a URL if it not already in the cache.\n\n    By default the file at the url `origin` is downloaded to the\n    cache_dir `~/.keras`, placed in the cache_subdir `datasets`,\n    and given the filename `fname`. The final location of a file\n    `example.txt` would therefore be `~/.keras/datasets/example.txt`.\n\n    Files in tar, tar.gz, tar.bz, and zip formats can also be extracted.\n    Passing a hash will verify the file after download. The command line\n    programs `shasum` and `sha256sum` can compute the hash.\n\n    # Arguments\n        fname: Name of the file. If an absolute path `/path/to/file.txt` is\n            specified the file will be saved at that location.\n        origin: Original URL of the file.\n        untar: Deprecated in favor of 'extract'.\n            boolean, whether the file should be decompressed\n        md5_hash: Deprecated in favor of 'file_hash'.\n            md5 hash of the file for verification\n        file_hash: The expected hash string of the file after download.\n            The sha256 and md5 hash algorithms are both supported.\n        cache_subdir: Subdirectory under the Keras cache dir where the file is\n            saved. If an absolute path `/path/to/folder` is\n            specified the file will be saved at that location.\n        hash_algorithm: Select the hash algorithm to verify the file.\n            options are 'md5', 'sha256', and 'auto'.\n            The default 'auto' detects the hash algorithm in use.\n        extract: True tries extracting the file as an Archive, like tar or zip.\n        archive_format: Archive format to try for extracting the file.\n            Options are 'auto', 'tar', 'zip', and None.\n            'tar' includes tar, tar.gz, and tar.bz files.\n            The default 'auto' is ['tar', 'zip'].\n            None or an empty list will return no matches found.\n        cache_dir: Location to store cached files, when None it\n            defaults to the [Keras Directory](/faq/#where-is-the-keras-configuration-filed-stored).\n\n    # Returns\n        Path to the downloaded file\n    \"\"\"\n    if cache_dir is None:\n        cache_dir = os.path.expanduser(os.path.join('~', '.keras'))\n    if md5_hash is not None and file_hash is None:\n        file_hash = md5_hash\n        hash_algorithm = 'md5'\n    datadir_base = os.path.expanduser(cache_dir)\n    if not os.access(datadir_base, os.W_OK):\n        datadir_base = os.path.join('/tmp', '.keras')\n    datadir = os.path.join(datadir_base, cache_subdir)\n    if not os.path.exists(datadir):\n        os.makedirs(datadir)\n\n    if untar:\n        untar_fpath = os.path.join(datadir, fname)\n        fpath = untar_fpath + '.tar.gz'\n    else:\n        fpath = os.path.join(datadir, fname)\n\n    download = False\n    if os.path.exists(fpath):\n        # File found; verify integrity if a hash was provided.\n        if file_hash is not None:\n            if not validate_file(fpath, file_hash, algorithm=hash_algorithm):\n                print('A local file was found, but it seems to be '\n                      'incomplete or outdated because the ' + hash_algorithm +\n                      ' file hash does not match the original value of ' +\n                      file_hash + ' so we will re-download the data.')\n                download = True\n    else:\n        download = True\n\n    if download:\n        print('Downloading data from', origin)\n\n        class ProgressTracker(object):\n            # Maintain progbar for the lifetime of download.\n            # This design was chosen for Python 2.7 compatibility.\n            progbar = None\n\n        def dl_progress(count, block_size, total_size):\n            if ProgressTracker.progbar is None:\n                if total_size is -1:\n                    total_size = None\n                ProgressTracker.progbar = Progbar(total_size)\n            else:\n                ProgressTracker.progbar.update(count * block_size)\n\n        error_msg = 'URL fetch failure on {}: {} -- {}'\n        try:\n            try:\n                urlretrieve(origin, fpath, dl_progress)\n            except URLError as e:\n                raise Exception(error_msg.format(origin, e.errno, e.reason))\n            except HTTPError as e:\n                raise Exception(error_msg.format(origin, e.code, e.msg))\n        except (Exception, KeyboardInterrupt) as e:\n            if os.path.exists(fpath):\n                os.remove(fpath)\n            raise\n        ProgressTracker.progbar = None\n\n    if untar:\n        if not os.path.exists(untar_fpath):\n            _extract_archive(fpath, datadir, archive_format='tar')\n        return untar_fpath\n\n    if extract:\n        _extract_archive(fpath, datadir, archive_format)\n\n    return fpath",
        "begin_line": 121,
        "end_line": 239,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.data_utils.dl_progress#209",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils",
        "signature": "keras.utils.data_utils.dl_progress(count, block_size, total_size)",
        "snippet": "        def dl_progress(count, block_size, total_size):\n            if ProgressTracker.progbar is None:\n                if total_size is -1:\n                    total_size = None\n                ProgressTracker.progbar = Progbar(total_size)\n            else:\n                ProgressTracker.progbar.update(count * block_size)",
        "begin_line": 209,
        "end_line": 215,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.data_utils._hash_file#242",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils",
        "signature": "keras.utils.data_utils._hash_file(fpath, algorithm='sha256', chunk_size=65535)",
        "snippet": "def _hash_file(fpath, algorithm='sha256', chunk_size=65535):\n    \"\"\"Calculates a file sha256 or md5 hash.\n\n    # Example\n\n    ```python\n        >>> from keras.data_utils import _hash_file\n        >>> _hash_file('/path/to/file.zip')\n        'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855'\n    ```\n\n    # Arguments\n        fpath: path to the file being validated\n        algorithm: hash algorithm, one of 'auto', 'sha256', or 'md5'.\n            The default 'auto' detects the hash algorithm in use.\n        chunk_size: Bytes to read at a time, important for large files.\n\n    # Returns\n        The file hash\n    \"\"\"\n    if (algorithm is 'sha256') or (algorithm is 'auto' and len(hash) is 64):\n        hasher = hashlib.sha256()\n    else:\n        hasher = hashlib.md5()\n\n    with open(fpath, 'rb') as fpath_file:\n        for chunk in iter(lambda: fpath_file.read(chunk_size), b''):\n            hasher.update(chunk)\n\n    return hasher.hexdigest()",
        "begin_line": 242,
        "end_line": 271,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.data_utils.validate_file#274",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils",
        "signature": "keras.utils.data_utils.validate_file(fpath, file_hash, algorithm='auto', chunk_size=65535)",
        "snippet": "def validate_file(fpath, file_hash, algorithm='auto', chunk_size=65535):\n    \"\"\"Validates a file against a sha256 or md5 hash.\n\n    # Arguments\n        fpath: path to the file being validated\n        file_hash:  The expected hash string of the file.\n            The sha256 and md5 hash algorithms are both supported.\n        algorithm: Hash algorithm, one of 'auto', 'sha256', or 'md5'.\n            The default 'auto' detects the hash algorithm in use.\n        chunk_size: Bytes to read at a time, important for large files.\n\n    # Returns\n        Whether the file is valid\n    \"\"\"\n    if ((algorithm is 'sha256') or\n            (algorithm is 'auto' and len(file_hash) is 64)):\n        hasher = 'sha256'\n    else:\n        hasher = 'md5'\n\n    if str(_hash_file(fpath, hasher, chunk_size)) == str(file_hash):\n        return True\n    else:\n        return False",
        "begin_line": 274,
        "end_line": 297,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.data_utils.get_index#375",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils",
        "signature": "keras.utils.data_utils.get_index(uid, i)",
        "snippet": "def get_index(uid, i):\n    \"\"\"Get the value from the Sequence `uid` at index `i`.\n\n    To allow multiple Sequences to be used at the same time, we use `uid` to\n    get a specific one. A single Sequence would cause the validation to\n    overwrite the training Sequence.\n\n    # Arguments\n        uid: int, Sequence identifier\n        i: index\n\n    # Returns\n        The value at index `i`.\n    \"\"\"\n    global _SHARED_SEQUENCES\n    return _SHARED_SEQUENCES[uid][i]",
        "begin_line": 375,
        "end_line": 390,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011147029316687103,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.data_utils.OrderedEnqueuer.__init__#465",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.OrderedEnqueuer",
        "signature": "keras.utils.data_utils.OrderedEnqueuer.__init__(self, sequence, use_multiprocessing=False, shuffle=False)",
        "snippet": "    def __init__(self, sequence,\n                 use_multiprocessing=False,\n                 shuffle=False):\n        global _SEQUENCE_COUNTER\n        self.sequence = sequence\n\n        # Doing Multiprocessing.Value += x is not process-safe.\n        with _SEQUENCE_COUNTER.get_lock():\n            self.uid = _SEQUENCE_COUNTER.value\n            _SEQUENCE_COUNTER.value += 1\n        self.use_multiprocessing = use_multiprocessing\n        self.shuffle = shuffle\n        self.workers = 0\n        self.executor = None\n        self.queue = None\n        self.run_thread = None\n        self.stop_signal = None",
        "begin_line": 465,
        "end_line": 481,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011147029316687103,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.data_utils.OrderedEnqueuer.is_running#483",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.OrderedEnqueuer",
        "signature": "keras.utils.data_utils.OrderedEnqueuer.is_running(self)",
        "snippet": "    def is_running(self):\n        return self.stop_signal is not None and not self.stop_signal.is_set()",
        "begin_line": 483,
        "end_line": 484,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011147029316687103,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.data_utils.OrderedEnqueuer.start#486",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.OrderedEnqueuer",
        "signature": "keras.utils.data_utils.OrderedEnqueuer.start(self, workers=1, max_queue_size=10)",
        "snippet": "    def start(self, workers=1, max_queue_size=10):\n        \"\"\"Start the handler's workers.\n\n        # Arguments\n            workers: number of worker threads\n            max_queue_size: queue size\n                (when full, workers could block on `put()`)\n        \"\"\"\n        if self.use_multiprocessing:\n            self.executor = multiprocessing.Pool(workers)\n        else:\n            self.executor = ThreadPool(workers)\n        self.workers = workers\n        self.queue = queue.Queue(max_queue_size)\n        self.stop_signal = threading.Event()\n        self.run_thread = threading.Thread(target=self._run)\n        self.run_thread.daemon = True\n        self.run_thread.start()",
        "begin_line": 486,
        "end_line": 503,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00012818869375721061,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.data_utils.OrderedEnqueuer._wait_queue#505",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.OrderedEnqueuer",
        "signature": "keras.utils.data_utils.OrderedEnqueuer._wait_queue(self)",
        "snippet": "    def _wait_queue(self):\n        \"\"\"Wait for the queue to be empty.\"\"\"\n        while True:\n            time.sleep(0.1)\n            if self.queue.unfinished_tasks == 0 or self.stop_signal.is_set():\n                return",
        "begin_line": 505,
        "end_line": 510,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001152604887044721,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.data_utils.OrderedEnqueuer._run#512",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.OrderedEnqueuer",
        "signature": "keras.utils.data_utils.OrderedEnqueuer._run(self)",
        "snippet": "    def _run(self):\n        \"\"\"Function to submit request to the executor and queue the `Future` objects.\"\"\"\n        sequence = list(range(len(self.sequence)))\n        self._send_sequence()  # Share the initial sequence\n        while True:\n            if self.shuffle:\n                random.shuffle(sequence)\n            for i in sequence:\n                if self.stop_signal.is_set():\n                    return\n                self.queue.put(\n                    self.executor.apply_async(get_index, (self.uid, i)), block=True)\n\n            # Done with the current epoch, waiting for the final batches\n            self._wait_queue()\n\n            if self.stop_signal.is_set():\n                # We're done\n                return\n\n            # Call the internal on epoch end.\n            self.sequence.on_epoch_end()\n            self._send_sequence()  # Update the pool",
        "begin_line": 512,
        "end_line": 534,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.data_utils.OrderedEnqueuer.get#536",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.OrderedEnqueuer",
        "signature": "keras.utils.data_utils.OrderedEnqueuer.get(self)",
        "snippet": "    def get(self):\n        \"\"\"Creates a generator to extract data from the queue.\n\n        Skip the data if it is `None`.\n\n        # Returns\n            Generator yielding tuples (inputs, targets)\n                or (inputs, targets, sample_weights)\n        \"\"\"\n        try:\n            while self.is_running():\n                inputs = self.queue.get(block=True).get()\n                self.queue.task_done()\n                if inputs is not None:\n                    yield inputs\n        except Exception as e:\n            self.stop()\n            raise StopIteration(e)",
        "begin_line": 536,
        "end_line": 553,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.data_utils.OrderedEnqueuer._send_sequence#555",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.OrderedEnqueuer",
        "signature": "keras.utils.data_utils.OrderedEnqueuer._send_sequence(self)",
        "snippet": "    def _send_sequence(self):\n        \"\"\"Send current Sequence to all workers.\"\"\"\n        global _SHARED_SEQUENCES\n        _SHARED_SEQUENCES[self.uid] = self.sequence  # For new processes that may spawn\n\n        self._close_pool()\n        if self.use_multiprocessing:\n            self.executor = multiprocessing.Pool(self.workers)\n        else:\n            self.executor = ThreadPool(self.workers)",
        "begin_line": 555,
        "end_line": 564,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00012818869375721061,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.data_utils.OrderedEnqueuer.stop#566",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.OrderedEnqueuer",
        "signature": "keras.utils.data_utils.OrderedEnqueuer.stop(self, timeout=None)",
        "snippet": "    def stop(self, timeout=None):\n        \"\"\"Stops running threads and wait for them to exit, if necessary.\n\n        Should be called by the same thread which called `start()`.\n\n        # Arguments\n            timeout: maximum time to wait on `thread.join()`\n        \"\"\"\n        global _SHARED_SEQUENCES\n        self.stop_signal.set()\n        with self.queue.mutex:\n            self.queue.queue.clear()\n            self.queue.unfinished_tasks = 0\n            self.queue.not_full.notify()\n        self._close_pool()\n        self.run_thread.join(timeout)\n        _SHARED_SEQUENCES[self.uid] = None",
        "begin_line": 566,
        "end_line": 582,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011147029316687103,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.data_utils.OrderedEnqueuer._close_pool#584",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.OrderedEnqueuer",
        "signature": "keras.utils.data_utils.OrderedEnqueuer._close_pool(self)",
        "snippet": "    def _close_pool(self):\n        self.executor.close()\n        self.executor.join()",
        "begin_line": 584,
        "end_line": 586,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011147029316687103,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.data_utils.GeneratorEnqueuer.__init__#605",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.GeneratorEnqueuer",
        "signature": "keras.utils.data_utils.GeneratorEnqueuer.__init__(self, generator, use_multiprocessing=False, wait_time=0.05, seed=None)",
        "snippet": "    def __init__(self, generator,\n                 use_multiprocessing=False,\n                 wait_time=0.05,\n                 seed=None):\n        self.wait_time = wait_time\n        self._generator = generator\n        self._use_multiprocessing = use_multiprocessing\n        self._threads = []\n        self._stop_event = None\n        self.queue = None\n        self.seed = seed",
        "begin_line": 605,
        "end_line": 615,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010219724067450178,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.data_utils.GeneratorEnqueuer.start#617",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.GeneratorEnqueuer",
        "signature": "keras.utils.data_utils.GeneratorEnqueuer.start(self, workers=1, max_queue_size=10)",
        "snippet": "    def start(self, workers=1, max_queue_size=10):\n        \"\"\"Kicks off threads which add data from the generator into the queue.\n\n        # Arguments\n            workers: number of worker threads\n            max_queue_size: queue size\n                (when full, threads could block on `put()`)\n        \"\"\"\n\n        def data_generator_task():\n            while not self._stop_event.is_set():\n                try:\n                    if self._use_multiprocessing or self.queue.qsize() < max_queue_size:\n                        generator_output = next(self._generator)\n                        self.queue.put(generator_output)\n                    else:\n                        time.sleep(self.wait_time)\n                except StopIteration:\n                    break\n                except Exception:\n                    self._stop_event.set()\n                    raise\n\n        try:\n            if self._use_multiprocessing:\n                self.queue = multiprocessing.Queue(maxsize=max_queue_size)\n                self._stop_event = multiprocessing.Event()\n            else:\n                self.queue = queue.Queue()\n                self._stop_event = threading.Event()\n\n            for _ in range(workers):\n                if self._use_multiprocessing:\n                    # Reset random seed else all children processes\n                    # share the same seed\n                    np.random.seed(self.seed)\n                    thread = multiprocessing.Process(target=data_generator_task)\n                    thread.daemon = True\n                    if self.seed is not None:\n                        self.seed += 1\n                else:\n                    thread = threading.Thread(target=data_generator_task)\n                self._threads.append(thread)\n                thread.start()\n        except:\n            self.stop()\n            raise",
        "begin_line": 617,
        "end_line": 663,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010984182776801405,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.data_utils.GeneratorEnqueuer.data_generator_task#626",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.GeneratorEnqueuer",
        "signature": "keras.utils.data_utils.GeneratorEnqueuer.data_generator_task()",
        "snippet": "        def data_generator_task():\n            while not self._stop_event.is_set():\n                try:\n                    if self._use_multiprocessing or self.queue.qsize() < max_queue_size:\n                        generator_output = next(self._generator)\n                        self.queue.put(generator_output)\n                    else:\n                        time.sleep(self.wait_time)\n                except StopIteration:\n                    break\n                except Exception:\n                    self._stop_event.set()\n                    raise",
        "begin_line": 626,
        "end_line": 638,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.data_utils.GeneratorEnqueuer.is_running#665",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.GeneratorEnqueuer",
        "signature": "keras.utils.data_utils.GeneratorEnqueuer.is_running(self)",
        "snippet": "    def is_running(self):\n        return self._stop_event is not None and not self._stop_event.is_set()",
        "begin_line": 665,
        "end_line": 666,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010219724067450178,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.data_utils.GeneratorEnqueuer.stop#668",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.GeneratorEnqueuer",
        "signature": "keras.utils.data_utils.GeneratorEnqueuer.stop(self, timeout=None)",
        "snippet": "    def stop(self, timeout=None):\n        \"\"\"Stops running threads and wait for them to exit, if necessary.\n\n        Should be called by the same thread which called `start()`.\n\n        # Arguments\n            timeout: maximum time to wait on `thread.join()`.\n        \"\"\"\n        if self.is_running():\n            self._stop_event.set()\n\n        for thread in self._threads:\n            if thread.is_alive():\n                if self._use_multiprocessing:\n                    thread.terminate()\n                else:\n                    thread.join(timeout)\n\n        if self._use_multiprocessing:\n            if self.queue is not None:\n                self.queue.close()\n\n        self._threads = []\n        self._stop_event = None\n        self.queue = None",
        "begin_line": 668,
        "end_line": 692,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011147029316687103,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.data_utils.GeneratorEnqueuer.get#694",
        "src_path": "keras/utils/data_utils.py",
        "class_name": "keras.utils.data_utils.GeneratorEnqueuer",
        "signature": "keras.utils.data_utils.GeneratorEnqueuer.get(self)",
        "snippet": "    def get(self):\n        \"\"\"Creates a generator to extract data from the queue.\n\n        Skip the data if it is `None`.\n\n        # Returns\n            A generator\n        \"\"\"\n        while self.is_running():\n            if not self.queue.empty():\n                inputs = self.queue.get()\n                if inputs is not None:\n                    yield inputs\n            else:\n                all_finished = all([not thread.is_alive() for thread in self._threads])\n                if all_finished and self.queue.empty():\n                    raise StopIteration()\n                else:\n                    time.sleep(self.wait_time)",
        "begin_line": 694,
        "end_line": 712,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.common.epsilon#9",
        "src_path": "keras/backend/common.py",
        "class_name": "keras.backend.common",
        "signature": "keras.backend.common.epsilon()",
        "snippet": "def epsilon():\n    \"\"\"Returns the value of the fuzz factor used in numeric expressions.\n\n    # Returns\n        A float.\n\n    # Example\n    ```python\n        >>> keras.backend.epsilon()\n        1e-08\n    ```\n    \"\"\"\n    return _EPSILON",
        "begin_line": 9,
        "end_line": 21,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.256687957048968e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.common.floatx#44",
        "src_path": "keras/backend/common.py",
        "class_name": "keras.backend.common",
        "signature": "keras.backend.common.floatx()",
        "snippet": "def floatx():\n    \"\"\"Returns the default float type, as a string.\n    (e.g. 'float16', 'float32', 'float64').\n\n    # Returns\n        String, the current default float type.\n\n    # Example\n    ```python\n        >>> keras.backend.floatx()\n        'float32'\n    ```\n    \"\"\"\n    return _FLOATX",
        "begin_line": 44,
        "end_line": 57,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0034965034965034965,
            "pseudo_dstar_susp": 0.07142857142857142,
            "pseudo_tarantula_susp": 0.0011961722488038277,
            "pseudo_op2_susp": 0.07142857142857142,
            "pseudo_barinel_susp": 0.0011961722488038277
        }
    },
    {
        "name": "keras.backend.common.set_floatx#60",
        "src_path": "keras/backend/common.py",
        "class_name": "keras.backend.common",
        "signature": "keras.backend.common.set_floatx(floatx)",
        "snippet": "def set_floatx(floatx):\n    \"\"\"Sets the default float type.\n\n    # Arguments\n        floatx: String, 'float16', 'float32', or 'float64'.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> K.floatx()\n        'float32'\n        >>> K.set_floatx('float16')\n        >>> K.floatx()\n        'float16'\n    ```\n    \"\"\"\n    global _FLOATX\n    if floatx not in {'float16', 'float32', 'float64'}:\n        raise ValueError('Unknown floatx type: ' + str(floatx))\n    _FLOATX = str(floatx)",
        "begin_line": 60,
        "end_line": 79,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.common.cast_to_floatx#82",
        "src_path": "keras/backend/common.py",
        "class_name": "keras.backend.common",
        "signature": "keras.backend.common.cast_to_floatx(x)",
        "snippet": "def cast_to_floatx(x):\n    \"\"\"Cast a Numpy array to the default Keras float type.\n\n    # Arguments\n        x: Numpy array.\n\n    # Returns\n        The same Numpy array, cast to its new type.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> K.floatx()\n        'float32'\n        >>> arr = numpy.array([1.0, 2.0], dtype='float64')\n        >>> arr.dtype\n        dtype('float64')\n        >>> new_arr = K.cast_to_floatx(arr)\n        >>> new_arr\n        array([ 1.,  2.], dtype=float32)\n        >>> new_arr.dtype\n        dtype('float32')\n    ```\n    \"\"\"\n    return np.asarray(x, dtype=_FLOATX)",
        "begin_line": 82,
        "end_line": 106,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.770395701025892e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.backend.common.image_data_format#109",
        "src_path": "keras/backend/common.py",
        "class_name": "keras.backend.common",
        "signature": "keras.backend.common.image_data_format()",
        "snippet": "def image_data_format():\n    \"\"\"Returns the default image data format convention ('channels_first' or 'channels_last').\n\n    # Returns\n        A string, either `'channels_first'` or `'channels_last'`\n\n    # Example\n    ```python\n        >>> keras.backend.image_data_format()\n        'channels_first'\n    ```\n    \"\"\"\n    return _IMAGE_DATA_FORMAT",
        "begin_line": 109,
        "end_line": 121,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009057971014492754,
            "pseudo_dstar_susp": 0.002638522427440633,
            "pseudo_tarantula_susp": 0.000778816199376947,
            "pseudo_op2_susp": 0.002638522427440633,
            "pseudo_barinel_susp": 0.000778816199376947
        }
    },
    {
        "name": "keras.backend.common.set_image_data_format#124",
        "src_path": "keras/backend/common.py",
        "class_name": "keras.backend.common",
        "signature": "keras.backend.common.set_image_data_format(data_format)",
        "snippet": "def set_image_data_format(data_format):\n    \"\"\"Sets the value of the data format convention.\n\n    # Arguments\n        data_format: string. `'channels_first'` or `'channels_last'`.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> K.image_data_format()\n        'channels_first'\n        >>> K.set_image_data_format('channels_last')\n        >>> K.image_data_format()\n        'channels_last'\n    ```\n    \"\"\"\n    global _IMAGE_DATA_FORMAT\n    if data_format not in {'channels_last', 'channels_first'}:\n        raise ValueError('Unknown data_format:', data_format)\n    _IMAGE_DATA_FORMAT = str(data_format)",
        "begin_line": 124,
        "end_line": 143,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.StackedRNNCells.__init__#42",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.StackedRNNCells",
        "signature": "keras.layers.recurrent.StackedRNNCells.__init__(self, cells, **kwargs)",
        "snippet": "    def __init__(self, cells, **kwargs):\n        for cell in cells:\n            if not hasattr(cell, 'call'):\n                raise ValueError('All cells must have a `call` method. '\n                                 'received cells:', cells)\n            if not hasattr(cell, 'state_size'):\n                raise ValueError('All cells must have a '\n                                 '`state_size` attribute. '\n                                 'received cells:', cells)\n        self.cells = cells\n        super(StackedRNNCells, self).__init__(**kwargs)",
        "begin_line": 42,
        "end_line": 52,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.StackedRNNCells.state_size#55",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.StackedRNNCells",
        "signature": "keras.layers.recurrent.StackedRNNCells.state_size(self)",
        "snippet": "    def state_size(self):\n        # States are a flat list\n        # in reverse order of the cell stack.\n        # This allows to preserve the requirement\n        # `stack.state_size[0] == output_dim`.\n        # e.g. states of a 2-layer LSTM would be\n        # `[h2, c2, h1, c1]`\n        # (assuming one LSTM has states [h, c])\n        state_size = []\n        for cell in self.cells[::-1]:\n            if hasattr(cell.state_size, '__len__'):\n                state_size += list(cell.state_size)\n            else:\n                state_size.append(cell.state_size)\n        return tuple(state_size)",
        "begin_line": 55,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.StackedRNNCells.call#71",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.StackedRNNCells",
        "signature": "keras.layers.recurrent.StackedRNNCells.call(self, inputs, states, **kwargs)",
        "snippet": "    def call(self, inputs, states, **kwargs):\n        # Recover per-cell states.\n        nested_states = []\n        for cell in self.cells[::-1]:\n            if hasattr(cell.state_size, '__len__'):\n                nested_states.append(states[:len(cell.state_size)])\n                states = states[len(cell.state_size):]\n            else:\n                nested_states.append([states[0]])\n                states = states[1:]\n        nested_states = nested_states[::-1]\n\n        # Call the cells in order and store the returned states.\n        new_nested_states = []\n        for cell, states in zip(self.cells, nested_states):\n            inputs, states = cell.call(inputs, states, **kwargs)\n            new_nested_states.append(states)\n\n        # Format the new states as a flat list\n        # in reverse cell order.\n        states = []\n        for cell_states in new_nested_states[::-1]:\n            states += cell_states\n        return inputs, states",
        "begin_line": 71,
        "end_line": 94,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.StackedRNNCells.build#96",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.StackedRNNCells",
        "signature": "keras.layers.recurrent.StackedRNNCells.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        for cell in self.cells:\n            if isinstance(cell, Layer):\n                cell.build(input_shape)\n            if hasattr(cell.state_size, '__len__'):\n                output_dim = cell.state_size[0]\n            else:\n                output_dim = cell.state_size\n            input_shape = (input_shape[0], input_shape[1], output_dim)\n        self.built = True",
        "begin_line": 96,
        "end_line": 105,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.StackedRNNCells.get_config#107",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.StackedRNNCells",
        "signature": "keras.layers.recurrent.StackedRNNCells.get_config(self)",
        "snippet": "    def get_config(self):\n        cells = []\n        for cell in self.cells:\n            cells.append({'class_name': cell.__class__.__name__,\n                          'config': cell.get_config()})\n        config = {'cells': cells}\n        base_config = super(StackedRNNCells, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 107,
        "end_line": 114,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.StackedRNNCells.from_config#117",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.StackedRNNCells",
        "signature": "keras.layers.recurrent.StackedRNNCells.from_config(cls, config, custom_objects=None)",
        "snippet": "    def from_config(cls, config, custom_objects=None):\n        from . import deserialize as deserialize_layer\n        cells = []\n        for cell_config in config.pop('cells'):\n            cells.append(deserialize_layer(cell_config,\n                                           custom_objects=custom_objects))\n        return cls(cells, **config)",
        "begin_line": 117,
        "end_line": 123,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.StackedRNNCells.trainable_weights#126",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.StackedRNNCells",
        "signature": "keras.layers.recurrent.StackedRNNCells.trainable_weights(self)",
        "snippet": "    def trainable_weights(self):\n        if not self.trainable:\n            return []\n        weights = []\n        for cell in self.cells:\n            if isinstance(cell, Layer):\n                weights += cell.trainable_weights\n        return weights",
        "begin_line": 126,
        "end_line": 133,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.StackedRNNCells.non_trainable_weights#136",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.StackedRNNCells",
        "signature": "keras.layers.recurrent.StackedRNNCells.non_trainable_weights(self)",
        "snippet": "    def non_trainable_weights(self):\n        weights = []\n        for cell in self.cells:\n            if isinstance(cell, Layer):\n                weights += cell.non_trainable_weights\n        if not self.trainable:\n            trainable_weights = []\n            for cell in self.cells:\n                if isinstance(cell, Layer):\n                    trainable_weights += cell.trainable_weights\n            return trainable_weights + weights\n        return weights",
        "begin_line": 136,
        "end_line": 147,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.StackedRNNCells.losses#179",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.StackedRNNCells",
        "signature": "keras.layers.recurrent.StackedRNNCells.losses(self)",
        "snippet": "    def losses(self):\n        losses = []\n        for cell in self.cells:\n            if isinstance(cell, Layer):\n                cell_losses = cell.losses\n                losses += cell_losses\n        return losses",
        "begin_line": 179,
        "end_line": 185,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.StackedRNNCells.get_losses_for#187",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.StackedRNNCells",
        "signature": "keras.layers.recurrent.StackedRNNCells.get_losses_for(self, inputs=None)",
        "snippet": "    def get_losses_for(self, inputs=None):\n        losses = []\n        for cell in self.cells:\n            if isinstance(cell, Layer):\n                cell_losses = cell.get_losses_for(inputs)\n                losses += cell_losses\n        return losses",
        "begin_line": 187,
        "end_line": 193,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.__init__#347",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.__init__(self, cell, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False, **kwargs)",
        "snippet": "    def __init__(self, cell,\n                 return_sequences=False,\n                 return_state=False,\n                 go_backwards=False,\n                 stateful=False,\n                 unroll=False,\n                 **kwargs):\n        if isinstance(cell, (list, tuple)):\n            cell = StackedRNNCells(cell)\n        if not hasattr(cell, 'call'):\n            raise ValueError('`cell` should have a `call` method. '\n                             'The RNN was passed:', cell)\n        if not hasattr(cell, 'state_size'):\n            raise ValueError('The RNN cell should have '\n                             'an attribute `state_size` '\n                             '(tuple of integers, '\n                             'one integer per RNN state).')\n        super(RNN, self).__init__(**kwargs)\n        self.cell = cell\n        self.return_sequences = return_sequences\n        self.return_state = return_state\n        self.go_backwards = go_backwards\n        self.stateful = stateful\n        self.unroll = unroll\n\n        self.supports_masking = True\n        self.input_spec = [InputSpec(ndim=3)]\n        self.state_spec = None\n        self._states = None\n        self.constants_spec = None\n        self._num_constants = None",
        "begin_line": 347,
        "end_line": 377,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0024752475247524753,
            "pseudo_dstar_susp": 0.003115264797507788,
            "pseudo_tarantula_susp": 0.001303780964797914,
            "pseudo_op2_susp": 0.003115264797507788,
            "pseudo_barinel_susp": 0.001303780964797914
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.states#380",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.states(self)",
        "snippet": "    def states(self):\n        if self._states is None:\n            if isinstance(self.cell.state_size, int):\n                num_states = 1\n            else:\n                num_states = len(self.cell.state_size)\n            return [None for _ in range(num_states)]\n        return self._states",
        "begin_line": 380,
        "end_line": 387,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010882576994232234,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.states#390",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.states(self, states)",
        "snippet": "    def states(self, states):\n        self._states = states",
        "begin_line": 390,
        "end_line": 391,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010882576994232234,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.compute_output_shape#393",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n\n        if hasattr(self.cell.state_size, '__len__'):\n            output_dim = self.cell.state_size[0]\n        else:\n            output_dim = self.cell.state_size\n\n        if self.return_sequences:\n            output_shape = (input_shape[0], input_shape[1], output_dim)\n        else:\n            output_shape = (input_shape[0], output_dim)\n\n        if self.return_state:\n            state_shape = [(input_shape[0], output_dim) for _ in self.states]\n            return [output_shape] + state_shape\n        else:\n            return output_shape",
        "begin_line": 393,
        "end_line": 411,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.compute_mask#413",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.compute_mask(self, inputs, mask)",
        "snippet": "    def compute_mask(self, inputs, mask):\n        if isinstance(mask, list):\n            mask = mask[0]\n        output_mask = mask if self.return_sequences else None\n        if self.return_state:\n            state_mask = [None for _ in self.states]\n            return [output_mask] + state_mask\n        else:\n            return output_mask",
        "begin_line": 413,
        "end_line": 421,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.build#423",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        # Note input_shape will be list of shapes of initial states and\n        # constants if these are passed in __call__.\n        if self._num_constants is not None:\n            constants_shape = input_shape[-self._num_constants:]\n        else:\n            constants_shape = None\n\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n\n        batch_size = input_shape[0] if self.stateful else None\n        input_dim = input_shape[-1]\n        self.input_spec[0] = InputSpec(shape=(batch_size, None, input_dim))\n\n        # allow cell (if layer) to build before we set or validate state_spec\n        if isinstance(self.cell, Layer):\n            step_input_shape = (input_shape[0],) + input_shape[2:]\n            if constants_shape is not None:\n                self.cell.build([step_input_shape] + constants_shape)\n            else:\n                self.cell.build(step_input_shape)\n\n        # set or validate state_spec\n        if hasattr(self.cell.state_size, '__len__'):\n            state_size = list(self.cell.state_size)\n        else:\n            state_size = [self.cell.state_size]\n\n        if self.state_spec is not None:\n            # initial_state was passed in call, check compatibility\n            if not [spec.shape[-1] for spec in self.state_spec] == state_size:\n                raise ValueError(\n                    'An initial_state was passed that is not compatible with '\n                    '`cell.state_size`. Received `state_spec`={}; '\n                    'However `cell.state_size` is '\n                    '{}'.format(self.state_spec, self.cell.state_size))\n        else:\n            self.state_spec = [InputSpec(shape=(None, dim))\n                               for dim in state_size]\n        if self.stateful:\n            self.reset_states()",
        "begin_line": 423,
        "end_line": 464,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00546448087431694,
            "pseudo_dstar_susp": 0.021739130434782608,
            "pseudo_tarantula_susp": 0.002066115702479339,
            "pseudo_op2_susp": 0.021739130434782608,
            "pseudo_barinel_susp": 0.002066115702479339
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.get_initial_state#466",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.get_initial_state(self, inputs)",
        "snippet": "    def get_initial_state(self, inputs):\n        # build an all-zero tensor of shape (samples, output_dim)\n        initial_state = K.zeros_like(inputs)  # (samples, timesteps, input_dim)\n        initial_state = K.sum(initial_state, axis=(1, 2))  # (samples,)\n        initial_state = K.expand_dims(initial_state)  # (samples, 1)\n        if hasattr(self.cell.state_size, '__len__'):\n            return [K.tile(initial_state, [1, dim])\n                    for dim in self.cell.state_size]\n        else:\n            return [K.tile(initial_state, [1, self.cell.state_size])]",
        "begin_line": 466,
        "end_line": 475,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010733068584308254,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.__call__#477",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.__call__(self, inputs, initial_state=None, constants=None, **kwargs)",
        "snippet": "    def __call__(self, inputs, initial_state=None, constants=None, **kwargs):\n        inputs, initial_state, constants = self._standardize_args(\n            inputs, initial_state, constants)\n\n        if initial_state is None and constants is None:\n            return super(RNN, self).__call__(inputs, **kwargs)\n\n        # If any of `initial_state` or `constants` are specified and are Keras\n        # tensors, then add them to the inputs and temporarily modify the\n        # input_spec to include them.\n\n        additional_inputs = []\n        additional_specs = []\n        if initial_state is not None:\n            kwargs['initial_state'] = initial_state\n            additional_inputs += initial_state\n            self.state_spec = [InputSpec(shape=K.int_shape(state))\n                               for state in initial_state]\n            additional_specs += self.state_spec\n        if constants is not None:\n            kwargs['constants'] = constants\n            additional_inputs += constants\n            self.constants_spec = [InputSpec(shape=K.int_shape(constant))\n                                   for constant in constants]\n            self._num_constants = len(constants)\n            additional_specs += self.constants_spec\n        # at this point additional_inputs cannot be empty\n        is_keras_tensor = hasattr(additional_inputs[0], '_keras_history')\n        for tensor in additional_inputs:\n            if hasattr(tensor, '_keras_history') != is_keras_tensor:\n                raise ValueError('The initial state or constants of an RNN'\n                                 ' layer cannot be specified with a mix of'\n                                 ' Keras tensors and non-Keras tensors')\n\n        if is_keras_tensor:\n            # Compute the full input spec, including state and constants\n            full_input = [inputs] + additional_inputs\n            full_input_spec = self.input_spec + additional_specs\n            # Perform the call with temporarily replaced input_spec\n            original_input_spec = self.input_spec\n            self.input_spec = full_input_spec\n            output = super(RNN, self).__call__(full_input, **kwargs)\n            self.input_spec = original_input_spec\n            return output\n        else:\n            return super(RNN, self).__call__(inputs, **kwargs)",
        "begin_line": 477,
        "end_line": 522,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.call#524",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.call(self, inputs, mask=None, training=None, initial_state=None, constants=None)",
        "snippet": "    def call(self,\n             inputs,\n             mask=None,\n             training=None,\n             initial_state=None,\n             constants=None):\n        # input shape: `(samples, time (padded with zeros), input_dim)`\n        # note that the .build() method of subclasses MUST define\n        # self.input_spec and self.state_spec with complete input shapes.\n        if isinstance(inputs, list):\n            inputs = inputs[0]\n        if initial_state is not None:\n            pass\n        elif self.stateful:\n            initial_state = self.states\n        else:\n            initial_state = self.get_initial_state(inputs)\n\n        if isinstance(mask, list):\n            mask = mask[0]\n\n        if len(initial_state) != len(self.states):\n            raise ValueError('Layer has ' + str(len(self.states)) +\n                             ' states but was passed ' +\n                             str(len(initial_state)) +\n                             ' initial states.')\n        input_shape = K.int_shape(inputs)\n        timesteps = input_shape[1]\n        if self.unroll and timesteps in [None, 1]:\n            raise ValueError('Cannot unroll a RNN if the '\n                             'time dimension is undefined or equal to 1. \\n'\n                             '- If using a Sequential model, '\n                             'specify the time dimension by passing '\n                             'an `input_shape` or `batch_input_shape` '\n                             'argument to your first layer. If your '\n                             'first layer is an Embedding, you can '\n                             'also use the `input_length` argument.\\n'\n                             '- If using the functional API, specify '\n                             'the time dimension by passing a `shape` '\n                             'or `batch_shape` argument to your Input layer.')\n\n        kwargs = {}\n        if has_arg(self.cell.call, 'training'):\n            kwargs['training'] = training\n\n        if constants:\n            if not has_arg(self.cell.call, 'constants'):\n                raise ValueError('RNN cell does not support constants')\n\n            def step(inputs, states):\n                constants = states[-self._num_constants:]\n                states = states[:-self._num_constants]\n                return self.cell.call(inputs, states, constants=constants,\n                                      **kwargs)\n        else:\n            def step(inputs, states):\n                return self.cell.call(inputs, states, **kwargs)\n\n        last_output, outputs, states = K.rnn(step,\n                                             inputs,\n                                             initial_state,\n                                             constants=constants,\n                                             go_backwards=self.go_backwards,\n                                             mask=mask,\n                                             unroll=self.unroll,\n                                             input_length=timesteps)\n        if self.stateful:\n            updates = []\n            for i in range(len(states)):\n                updates.append((self.states[i], states[i]))\n            self.add_update(updates, inputs)\n\n        if self.return_sequences:\n            output = outputs\n        else:\n            output = last_output\n\n        # Properly set learning phase\n        if getattr(last_output, '_uses_learning_phase', False):\n            output._uses_learning_phase = True\n\n        if self.return_state:\n            if not isinstance(states, (list, tuple)):\n                states = [states]\n            else:\n                states = list(states)\n            return [output] + states\n        else:\n            return output",
        "begin_line": 524,
        "end_line": 612,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.step#573",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.step(inputs, states)",
        "snippet": "            def step(inputs, states):\n                constants = states[-self._num_constants:]\n                states = states[:-self._num_constants]\n                return self.cell.call(inputs, states, constants=constants,\n                                      **kwargs)",
        "begin_line": 573,
        "end_line": 577,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.step#579",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.step(inputs, states)",
        "snippet": "            def step(inputs, states):\n                return self.cell.call(inputs, states, **kwargs)",
        "begin_line": 579,
        "end_line": 580,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.RNN._standardize_args#614",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN._standardize_args(self, inputs, initial_state, constants)",
        "snippet": "    def _standardize_args(self, inputs, initial_state, constants):\n        \"\"\"Brings the arguments of `__call__` that can contain input tensors to\n        standard format.\n\n        When running a model loaded from file, the input tensors\n        `initial_state` and `constants` can be passed to `RNN.__call__` as part\n        of `inputs` instead of by the dedicated keyword arguments. This method\n        makes sure the arguments are separated and that `initial_state` and\n        `constants` are lists of tensors (or None).\n\n        # Arguments\n            inputs: tensor or list/tuple of tensors\n            initial_state: tensor or list of tensors or None\n            constants: tensor or list of tensors or None\n\n        # Returns\n            inputs: tensor\n            initial_state: list of tensors or None\n            constants: list of tensors or None\n        \"\"\"\n        if isinstance(inputs, list):\n            assert initial_state is None and constants is None\n            if self._num_constants is not None:\n                constants = inputs[-self._num_constants:]\n                inputs = inputs[:-self._num_constants]\n            if len(inputs) > 1:\n                initial_state = inputs[1:]\n            inputs = inputs[0]\n\n        def to_list_or_none(x):\n            if x is None or isinstance(x, list):\n                return x\n            if isinstance(x, tuple):\n                return list(x)\n            return [x]\n\n        initial_state = to_list_or_none(initial_state)\n        constants = to_list_or_none(constants)\n\n        return inputs, initial_state, constants",
        "begin_line": 614,
        "end_line": 653,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.to_list_or_none#643",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.to_list_or_none(x)",
        "snippet": "        def to_list_or_none(x):\n            if x is None or isinstance(x, list):\n                return x\n            if isinstance(x, tuple):\n                return list(x)\n            return [x]",
        "begin_line": 643,
        "end_line": 648,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.reset_states#655",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.reset_states(self, states=None)",
        "snippet": "    def reset_states(self, states=None):\n        if not self.stateful:\n            raise AttributeError('Layer must be stateful.')\n        batch_size = self.input_spec[0].shape[0]\n        if not batch_size:\n            raise ValueError('If a RNN is stateful, it needs to know '\n                             'its batch size. Specify the batch size '\n                             'of your input tensors: \\n'\n                             '- If using a Sequential model, '\n                             'specify the batch size by passing '\n                             'a `batch_input_shape` '\n                             'argument to your first layer.\\n'\n                             '- If using the functional API, specify '\n                             'the time dimension by passing a '\n                             '`batch_shape` argument to your Input layer.')\n        # initialize state if None\n        if self.states[0] is None:\n            if hasattr(self.cell.state_size, '__len__'):\n                self.states = [K.zeros((batch_size, dim))\n                               for dim in self.cell.state_size]\n            else:\n                self.states = [K.zeros((batch_size, self.cell.state_size))]\n        elif states is None:\n            if hasattr(self.cell.state_size, '__len__'):\n                for state, dim in zip(self.states, self.cell.state_size):\n                    K.set_value(state, np.zeros((batch_size, dim)))\n            else:\n                K.set_value(self.states[0],\n                            np.zeros((batch_size, self.cell.state_size)))\n        else:\n            if not isinstance(states, (list, tuple)):\n                states = [states]\n            if len(states) != len(self.states):\n                raise ValueError('Layer ' + self.name + ' expects ' +\n                                 str(len(self.states)) + ' states, '\n                                 'but it received ' + str(len(states)) +\n                                 ' state values. Input received: ' +\n                                 str(states))\n            for index, (value, state) in enumerate(zip(states, self.states)):\n                if hasattr(self.cell.state_size, '__len__'):\n                    dim = self.cell.state_size[index]\n                else:\n                    dim = self.cell.state_size\n                if value.shape != (batch_size, dim):\n                    raise ValueError('State ' + str(index) +\n                                     ' is incompatible with layer ' +\n                                     self.name + ': expected shape=' +\n                                     str((batch_size, dim)) +\n                                     ', found shape=' + str(value.shape))\n                # TODO: consider batch calls to `set_value`.\n                K.set_value(state, value)",
        "begin_line": 655,
        "end_line": 705,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.get_config#707",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'return_sequences': self.return_sequences,\n                  'return_state': self.return_state,\n                  'go_backwards': self.go_backwards,\n                  'stateful': self.stateful,\n                  'unroll': self.unroll}\n        if self._num_constants is not None:\n            config['num_constants'] = self._num_constants\n\n        cell_config = self.cell.get_config()\n        config['cell'] = {'class_name': self.cell.__class__.__name__,\n                          'config': cell_config}\n        base_config = super(RNN, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 707,
        "end_line": 720,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.from_config#723",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.from_config(cls, config, custom_objects=None)",
        "snippet": "    def from_config(cls, config, custom_objects=None):\n        from . import deserialize as deserialize_layer\n        cell = deserialize_layer(config.pop('cell'),\n                                 custom_objects=custom_objects)\n        num_constants = config.pop('num_constants', None)\n        layer = cls(cell, **config)\n        layer._num_constants = num_constants\n        return layer",
        "begin_line": 723,
        "end_line": 730,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.trainable_weights#733",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.trainable_weights(self)",
        "snippet": "    def trainable_weights(self):\n        if isinstance(self.cell, Layer):\n            return self.cell.trainable_weights\n        return []",
        "begin_line": 733,
        "end_line": 736,
        "comment": "",
        "is_bug": true,
        "susp": {
            "pseudo_ochiai_susp": 0.0030959752321981426,
            "pseudo_dstar_susp": 0.0035842293906810036,
            "pseudo_tarantula_susp": 0.002044989775051125,
            "pseudo_op2_susp": 0.0035842293906810036,
            "pseudo_barinel_susp": 0.002044989775051125
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.non_trainable_weights#739",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.non_trainable_weights(self)",
        "snippet": "    def non_trainable_weights(self):\n        if isinstance(self.cell, Layer):\n            return self.cell.non_trainable_weights\n        return []",
        "begin_line": 739,
        "end_line": 742,
        "comment": "",
        "is_bug": true,
        "susp": {
            "pseudo_ochiai_susp": 0.006172839506172839,
            "pseudo_dstar_susp": 0.003663003663003663,
            "pseudo_tarantula_susp": 0.0035842293906810036,
            "pseudo_op2_susp": 0.003663003663003663,
            "pseudo_barinel_susp": 0.0035842293906810036
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.losses#745",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.losses(self)",
        "snippet": "    def losses(self):\n        if isinstance(self.cell, Layer):\n            return self.cell.losses\n        return []",
        "begin_line": 745,
        "end_line": 748,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.get_losses_for#750",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.get_losses_for(self, inputs=None)",
        "snippet": "    def get_losses_for(self, inputs=None):\n        if isinstance(self.cell, Layer):\n            cell_losses = self.cell.get_losses_for(inputs)\n            return cell_losses + super(RNN, self).get_losses_for(inputs)\n        return super(RNN, self).get_losses_for(inputs)",
        "begin_line": 750,
        "end_line": 754,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNNCell.__init__#800",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNNCell",
        "signature": "keras.layers.recurrent.SimpleRNNCell.__init__(self, units, activation='tanh', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, **kwargs)",
        "snippet": "    def __init__(self, units,\n                 activation='tanh',\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 recurrent_initializer='orthogonal',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n                 kernel_constraint=None,\n                 recurrent_constraint=None,\n                 bias_constraint=None,\n                 dropout=0.,\n                 recurrent_dropout=0.,\n                 **kwargs):\n        super(SimpleRNNCell, self).__init__(**kwargs)\n        self.units = units\n        self.activation = activations.get(activation)\n        self.use_bias = use_bias\n\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.recurrent_initializer = initializers.get(recurrent_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.recurrent_constraint = constraints.get(recurrent_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n\n        self.dropout = min(1., max(0., dropout))\n        self.recurrent_dropout = min(1., max(0., recurrent_dropout))\n        self.state_size = self.units\n        self._dropout_mask = None\n        self._recurrent_dropout_mask = None",
        "begin_line": 800,
        "end_line": 836,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0010384215991692627,
            "pseudo_dstar_susp": 0.0010030090270812437,
            "pseudo_tarantula_susp": 0.0015015015015015015,
            "pseudo_op2_susp": 0.0010030090270812437,
            "pseudo_barinel_susp": 0.0015015015015015015
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNNCell.build#838",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNNCell",
        "signature": "keras.layers.recurrent.SimpleRNNCell.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n                                      name='kernel',\n                                      initializer=self.kernel_initializer,\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        self.recurrent_kernel = self.add_weight(\n            shape=(self.units, self.units),\n            name='recurrent_kernel',\n            initializer=self.recurrent_initializer,\n            regularizer=self.recurrent_regularizer,\n            constraint=self.recurrent_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(self.units,),\n                                        name='bias',\n                                        initializer=self.bias_initializer,\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        self.built = True",
        "begin_line": 838,
        "end_line": 858,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001145475372279496,
            "pseudo_dstar_susp": 0.0011025358324145535,
            "pseudo_tarantula_susp": 0.0017985611510791368,
            "pseudo_op2_susp": 0.0011025358324145535,
            "pseudo_barinel_susp": 0.0017985611510791368
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNNCell._generate_dropout_mask#860",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNNCell",
        "signature": "keras.layers.recurrent.SimpleRNNCell._generate_dropout_mask(self, inputs, training=None)",
        "snippet": "    def _generate_dropout_mask(self, inputs, training=None):\n        if 0 < self.dropout < 1:\n            ones = K.ones_like(K.squeeze(inputs[:, 0:1, :], axis=1))\n\n            def dropped_inputs():\n                return K.dropout(ones, self.dropout)\n\n            self._dropout_mask = K.in_train_phase(\n                dropped_inputs,\n                ones,\n                training=training)\n        else:\n            self._dropout_mask = None",
        "begin_line": 860,
        "end_line": 872,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNNCell.dropped_inputs#864",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNNCell",
        "signature": "keras.layers.recurrent.SimpleRNNCell.dropped_inputs()",
        "snippet": "            def dropped_inputs():\n                return K.dropout(ones, self.dropout)",
        "begin_line": 864,
        "end_line": 865,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNNCell._generate_recurrent_dropout_mask#874",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNNCell",
        "signature": "keras.layers.recurrent.SimpleRNNCell._generate_recurrent_dropout_mask(self, inputs, training=None)",
        "snippet": "    def _generate_recurrent_dropout_mask(self, inputs, training=None):\n        if 0 < self.recurrent_dropout < 1:\n            ones = K.ones_like(K.reshape(inputs[:, 0, 0], (-1, 1)))\n            ones = K.tile(ones, (1, self.units))\n\n            def dropped_inputs():\n                return K.dropout(ones, self.dropout)\n\n            self._recurrent_dropout_mask = K.in_train_phase(\n                dropped_inputs,\n                ones,\n                training=training)\n        else:\n            self._recurrent_dropout_mask = None",
        "begin_line": 874,
        "end_line": 887,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNNCell.dropped_inputs#879",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNNCell",
        "signature": "keras.layers.recurrent.SimpleRNNCell.dropped_inputs()",
        "snippet": "            def dropped_inputs():\n                return K.dropout(ones, self.dropout)",
        "begin_line": 879,
        "end_line": 880,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNNCell.call#889",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNNCell",
        "signature": "keras.layers.recurrent.SimpleRNNCell.call(self, inputs, states, training=None)",
        "snippet": "    def call(self, inputs, states, training=None):\n        prev_output = states[0]\n        dp_mask = self._dropout_mask\n        rec_dp_mask = self._recurrent_dropout_mask\n\n        if dp_mask is not None:\n            h = K.dot(inputs * dp_mask, self.kernel)\n        else:\n            h = K.dot(inputs, self.kernel)\n        if self.bias is not None:\n            h = K.bias_add(h, self.bias)\n\n        if rec_dp_mask is not None:\n            prev_output *= rec_dp_mask\n        output = h + K.dot(prev_output, self.recurrent_kernel)\n        if self.activation is not None:\n            output = self.activation(output)\n\n        # Properly set learning phase on output tensor.\n        if 0 < self.dropout + self.recurrent_dropout:\n            if training is None:\n                output._uses_learning_phase = True\n        return output, [output]",
        "begin_line": 889,
        "end_line": 911,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.__init__#977",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.__init__(self, units, activation='tanh', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False, **kwargs)",
        "snippet": "    def __init__(self, units,\n                 activation='tanh',\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 recurrent_initializer='orthogonal',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 recurrent_constraint=None,\n                 bias_constraint=None,\n                 dropout=0.,\n                 recurrent_dropout=0.,\n                 return_sequences=False,\n                 return_state=False,\n                 go_backwards=False,\n                 stateful=False,\n                 unroll=False,\n                 **kwargs):\n        if 'implementation' in kwargs:\n            kwargs.pop('implementation')\n            warnings.warn('The `implementation` argument '\n                          'in `SimpleRNN` has been deprecated. '\n                          'Please remove it from your layer call.')\n        if K.backend() == 'cntk':\n            if not kwargs.get('unroll') and (dropout > 0 or recurrent_dropout > 0):\n                warnings.warn(\n                    'RNN dropout is not supported with the CNTK backend '\n                    'when using dynamic RNNs (i.e. non-unrolled). '\n                    'You can either set `unroll=True`, '\n                    'set `dropout` and `recurrent_dropout` to 0, '\n                    'or use a different backend.')\n                dropout = 0.\n                recurrent_dropout = 0.\n\n        cell = SimpleRNNCell(units,\n                             activation=activation,\n                             use_bias=use_bias,\n                             kernel_initializer=kernel_initializer,\n                             recurrent_initializer=recurrent_initializer,\n                             bias_initializer=bias_initializer,\n                             kernel_regularizer=kernel_regularizer,\n                             recurrent_regularizer=recurrent_regularizer,\n                             bias_regularizer=bias_regularizer,\n                             kernel_constraint=kernel_constraint,\n                             recurrent_constraint=recurrent_constraint,\n                             bias_constraint=bias_constraint,\n                             dropout=dropout,\n                             recurrent_dropout=recurrent_dropout)\n        super(SimpleRNN, self).__init__(cell,\n                                        return_sequences=return_sequences,\n                                        return_state=return_state,\n                                        go_backwards=go_backwards,\n                                        stateful=stateful,\n                                        unroll=unroll,\n                                        **kwargs)\n        self.activity_regularizer = regularizers.get(activity_regularizer)",
        "begin_line": 977,
        "end_line": 1035,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0010384215991692627,
            "pseudo_dstar_susp": 0.0010030090270812437,
            "pseudo_tarantula_susp": 0.0015015015015015015,
            "pseudo_op2_susp": 0.0010030090270812437,
            "pseudo_barinel_susp": 0.0015015015015015015
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.call#1037",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.call(self, inputs, mask=None, training=None, initial_state=None)",
        "snippet": "    def call(self, inputs, mask=None, training=None, initial_state=None):\n        self.cell._generate_dropout_mask(inputs, training=training)\n        self.cell._generate_recurrent_dropout_mask(inputs, training=training)\n        return super(SimpleRNN, self).call(inputs,\n                                           mask=mask,\n                                           training=training,\n                                           initial_state=initial_state)",
        "begin_line": 1037,
        "end_line": 1043,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010421008753647353,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.units#1046",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.units(self)",
        "snippet": "    def units(self):\n        return self.cell.units",
        "begin_line": 1046,
        "end_line": 1047,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.activation#1050",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.activation(self)",
        "snippet": "    def activation(self):\n        return self.cell.activation",
        "begin_line": 1050,
        "end_line": 1051,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.use_bias#1054",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.use_bias(self)",
        "snippet": "    def use_bias(self):\n        return self.cell.use_bias",
        "begin_line": 1054,
        "end_line": 1055,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.kernel_initializer#1058",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.kernel_initializer(self)",
        "snippet": "    def kernel_initializer(self):\n        return self.cell.kernel_initializer",
        "begin_line": 1058,
        "end_line": 1059,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.recurrent_initializer#1062",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.recurrent_initializer(self)",
        "snippet": "    def recurrent_initializer(self):\n        return self.cell.recurrent_initializer",
        "begin_line": 1062,
        "end_line": 1063,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.bias_initializer#1066",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.bias_initializer(self)",
        "snippet": "    def bias_initializer(self):\n        return self.cell.bias_initializer",
        "begin_line": 1066,
        "end_line": 1067,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.kernel_regularizer#1070",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.kernel_regularizer(self)",
        "snippet": "    def kernel_regularizer(self):\n        return self.cell.kernel_regularizer",
        "begin_line": 1070,
        "end_line": 1071,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.recurrent_regularizer#1074",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.recurrent_regularizer(self)",
        "snippet": "    def recurrent_regularizer(self):\n        return self.cell.recurrent_regularizer",
        "begin_line": 1074,
        "end_line": 1075,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.bias_regularizer#1078",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.bias_regularizer(self)",
        "snippet": "    def bias_regularizer(self):\n        return self.cell.bias_regularizer",
        "begin_line": 1078,
        "end_line": 1079,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.kernel_constraint#1082",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.kernel_constraint(self)",
        "snippet": "    def kernel_constraint(self):\n        return self.cell.kernel_constraint",
        "begin_line": 1082,
        "end_line": 1083,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.recurrent_constraint#1086",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.recurrent_constraint(self)",
        "snippet": "    def recurrent_constraint(self):\n        return self.cell.recurrent_constraint",
        "begin_line": 1086,
        "end_line": 1087,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.bias_constraint#1090",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.bias_constraint(self)",
        "snippet": "    def bias_constraint(self):\n        return self.cell.bias_constraint",
        "begin_line": 1090,
        "end_line": 1091,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.dropout#1094",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.dropout(self)",
        "snippet": "    def dropout(self):\n        return self.cell.dropout",
        "begin_line": 1094,
        "end_line": 1095,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.recurrent_dropout#1098",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.recurrent_dropout(self)",
        "snippet": "    def recurrent_dropout(self):\n        return self.cell.recurrent_dropout",
        "begin_line": 1098,
        "end_line": 1099,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.get_config#1101",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'units': self.units,\n                  'activation': activations.serialize(self.activation),\n                  'use_bias': self.use_bias,\n                  'kernel_initializer': initializers.serialize(self.kernel_initializer),\n                  'recurrent_initializer': initializers.serialize(self.recurrent_initializer),\n                  'bias_initializer': initializers.serialize(self.bias_initializer),\n                  'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n                  'recurrent_regularizer': regularizers.serialize(self.recurrent_regularizer),\n                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n                  'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n                  'recurrent_constraint': constraints.serialize(self.recurrent_constraint),\n                  'bias_constraint': constraints.serialize(self.bias_constraint),\n                  'dropout': self.dropout,\n                  'recurrent_dropout': self.recurrent_dropout}\n        base_config = super(SimpleRNN, self).get_config()\n        del base_config['cell']\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 1101,
        "end_line": 1119,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.SimpleRNN.from_config#1122",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.SimpleRNN",
        "signature": "keras.layers.recurrent.SimpleRNN.from_config(cls, config)",
        "snippet": "    def from_config(cls, config):\n        if 'implementation' in config:\n            config.pop('implementation')\n        return cls(**config)",
        "begin_line": 1122,
        "end_line": 1125,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00012818869375721061,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.GRUCell.__init__#1175",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRUCell",
        "signature": "keras.layers.recurrent.GRUCell.__init__(self, units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, **kwargs)",
        "snippet": "    def __init__(self, units,\n                 activation='tanh',\n                 recurrent_activation='hard_sigmoid',\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 recurrent_initializer='orthogonal',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n                 kernel_constraint=None,\n                 recurrent_constraint=None,\n                 bias_constraint=None,\n                 dropout=0.,\n                 recurrent_dropout=0.,\n                 implementation=1,\n                 **kwargs):\n        super(GRUCell, self).__init__(**kwargs)\n        self.units = units\n        self.activation = activations.get(activation)\n        self.recurrent_activation = activations.get(recurrent_activation)\n        self.use_bias = use_bias\n\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.recurrent_initializer = initializers.get(recurrent_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.recurrent_constraint = constraints.get(recurrent_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n\n        self.dropout = min(1., max(0., dropout))\n        self.recurrent_dropout = min(1., max(0., recurrent_dropout))\n        self.implementation = implementation\n        self.state_size = self.units\n        self._dropout_mask = None\n        self._recurrent_dropout_mask = None",
        "begin_line": 1175,
        "end_line": 1215,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001145475372279496,
            "pseudo_dstar_susp": 0.0011025358324145535,
            "pseudo_tarantula_susp": 0.0017985611510791368,
            "pseudo_op2_susp": 0.0011025358324145535,
            "pseudo_barinel_susp": 0.0017985611510791368
        }
    },
    {
        "name": "keras.layers.recurrent.GRUCell.build#1217",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRUCell",
        "signature": "keras.layers.recurrent.GRUCell.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        input_dim = input_shape[-1]\n        self.kernel = self.add_weight(shape=(input_dim, self.units * 3),\n                                      name='kernel',\n                                      initializer=self.kernel_initializer,\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        self.recurrent_kernel = self.add_weight(\n            shape=(self.units, self.units * 3),\n            name='recurrent_kernel',\n            initializer=self.recurrent_initializer,\n            regularizer=self.recurrent_regularizer,\n            constraint=self.recurrent_constraint)\n\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(self.units * 3,),\n                                        name='bias',\n                                        initializer=self.bias_initializer,\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n\n        self.kernel_z = self.kernel[:, :self.units]\n        self.recurrent_kernel_z = self.recurrent_kernel[:, :self.units]\n        self.kernel_r = self.kernel[:, self.units: self.units * 2]\n        self.recurrent_kernel_r = self.recurrent_kernel[:,\n                                                        self.units:\n                                                        self.units * 2]\n        self.kernel_h = self.kernel[:, self.units * 2:]\n        self.recurrent_kernel_h = self.recurrent_kernel[:, self.units * 2:]\n\n        if self.use_bias:\n            self.bias_z = self.bias[:self.units]\n            self.bias_r = self.bias[self.units: self.units * 2]\n            self.bias_h = self.bias[self.units * 2:]\n        else:\n            self.bias_z = None\n            self.bias_r = None\n            self.bias_h = None\n        self.built = True",
        "begin_line": 1217,
        "end_line": 1257,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001288659793814433,
            "pseudo_dstar_susp": 0.0011668611435239206,
            "pseudo_tarantula_susp": 0.001976284584980237,
            "pseudo_op2_susp": 0.0011668611435239206,
            "pseudo_barinel_susp": 0.001976284584980237
        }
    },
    {
        "name": "keras.layers.recurrent.GRUCell._generate_dropout_mask#1259",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRUCell",
        "signature": "keras.layers.recurrent.GRUCell._generate_dropout_mask(self, inputs, training=None)",
        "snippet": "    def _generate_dropout_mask(self, inputs, training=None):\n        if 0 < self.dropout < 1:\n            ones = K.ones_like(K.squeeze(inputs[:, 0:1, :], axis=1))\n\n            def dropped_inputs():\n                return K.dropout(ones, self.dropout)\n\n            self._dropout_mask = [K.in_train_phase(\n                dropped_inputs,\n                ones,\n                training=training)\n                for _ in range(3)]\n        else:\n            self._dropout_mask = None",
        "begin_line": 1259,
        "end_line": 1272,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.GRUCell.dropped_inputs#1263",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRUCell",
        "signature": "keras.layers.recurrent.GRUCell.dropped_inputs()",
        "snippet": "            def dropped_inputs():\n                return K.dropout(ones, self.dropout)",
        "begin_line": 1263,
        "end_line": 1264,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.GRUCell._generate_recurrent_dropout_mask#1274",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRUCell",
        "signature": "keras.layers.recurrent.GRUCell._generate_recurrent_dropout_mask(self, inputs, training=None)",
        "snippet": "    def _generate_recurrent_dropout_mask(self, inputs, training=None):\n        if 0 < self.recurrent_dropout < 1:\n            ones = K.ones_like(K.reshape(inputs[:, 0, 0], (-1, 1)))\n            ones = K.tile(ones, (1, self.units))\n\n            def dropped_inputs():\n                return K.dropout(ones, self.dropout)\n\n            self._recurrent_dropout_mask = [K.in_train_phase(\n                dropped_inputs,\n                ones,\n                training=training)\n                for _ in range(3)]\n        else:\n            self._recurrent_dropout_mask = None",
        "begin_line": 1274,
        "end_line": 1288,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.GRUCell.dropped_inputs#1279",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRUCell",
        "signature": "keras.layers.recurrent.GRUCell.dropped_inputs()",
        "snippet": "            def dropped_inputs():\n                return K.dropout(ones, self.dropout)",
        "begin_line": 1279,
        "end_line": 1280,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.GRUCell.call#1290",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRUCell",
        "signature": "keras.layers.recurrent.GRUCell.call(self, inputs, states, training=None)",
        "snippet": "    def call(self, inputs, states, training=None):\n        h_tm1 = states[0]  # previous memory\n\n        # dropout matrices for input units\n        dp_mask = self._dropout_mask\n        # dropout matrices for recurrent units\n        rec_dp_mask = self._recurrent_dropout_mask\n\n        if self.implementation == 1:\n            if 0. < self.dropout < 1.:\n                inputs_z = inputs * dp_mask[0]\n                inputs_r = inputs * dp_mask[1]\n                inputs_h = inputs * dp_mask[2]\n            else:\n                inputs_z = inputs\n                inputs_r = inputs\n                inputs_h = inputs\n            x_z = K.dot(inputs_z, self.kernel_z)\n            x_r = K.dot(inputs_r, self.kernel_r)\n            x_h = K.dot(inputs_h, self.kernel_h)\n            if self.use_bias:\n                x_z = K.bias_add(x_z, self.bias_z)\n                x_r = K.bias_add(x_r, self.bias_r)\n                x_h = K.bias_add(x_h, self.bias_h)\n\n            if 0. < self.recurrent_dropout < 1.:\n                h_tm1_z = h_tm1 * rec_dp_mask[0]\n                h_tm1_r = h_tm1 * rec_dp_mask[1]\n                h_tm1_h = h_tm1 * rec_dp_mask[2]\n            else:\n                h_tm1_z = h_tm1\n                h_tm1_r = h_tm1\n                h_tm1_h = h_tm1\n            z = self.recurrent_activation(x_z + K.dot(h_tm1_z,\n                                                      self.recurrent_kernel_z))\n            r = self.recurrent_activation(x_r + K.dot(h_tm1_r,\n                                                      self.recurrent_kernel_r))\n\n            hh = self.activation(x_h + K.dot(r * h_tm1_h,\n                                             self.recurrent_kernel_h))\n        else:\n            if 0. < self.dropout < 1.:\n                inputs *= dp_mask[0]\n            matrix_x = K.dot(inputs, self.kernel)\n            if self.use_bias:\n                matrix_x = K.bias_add(matrix_x, self.bias)\n            if 0. < self.recurrent_dropout < 1.:\n                h_tm1 *= rec_dp_mask[0]\n            matrix_inner = K.dot(h_tm1,\n                                 self.recurrent_kernel[:, :2 * self.units])\n\n            x_z = matrix_x[:, :self.units]\n            x_r = matrix_x[:, self.units: 2 * self.units]\n            recurrent_z = matrix_inner[:, :self.units]\n            recurrent_r = matrix_inner[:, self.units: 2 * self.units]\n\n            z = self.recurrent_activation(x_z + recurrent_z)\n            r = self.recurrent_activation(x_r + recurrent_r)\n\n            x_h = matrix_x[:, 2 * self.units:]\n            recurrent_h = K.dot(r * h_tm1,\n                                self.recurrent_kernel[:, 2 * self.units:])\n            hh = self.activation(x_h + recurrent_h)\n        h = z * h_tm1 + (1 - z) * hh\n        if 0 < self.dropout + self.recurrent_dropout:\n            if training is None:\n                h._uses_learning_phase = True\n        return h, [h]",
        "begin_line": 1290,
        "end_line": 1357,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.__init__#1432",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.__init__(self, units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False, **kwargs)",
        "snippet": "    def __init__(self, units,\n                 activation='tanh',\n                 recurrent_activation='hard_sigmoid',\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 recurrent_initializer='orthogonal',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 recurrent_constraint=None,\n                 bias_constraint=None,\n                 dropout=0.,\n                 recurrent_dropout=0.,\n                 implementation=1,\n                 return_sequences=False,\n                 return_state=False,\n                 go_backwards=False,\n                 stateful=False,\n                 unroll=False,\n                 **kwargs):\n        if implementation == 0:\n            warnings.warn('`implementation=0` has been deprecated, '\n                          'and now defaults to `implementation=1`.'\n                          'Please update your layer call.')\n        if K.backend() == 'cntk':\n            if not kwargs.get('unroll') and (dropout > 0 or recurrent_dropout > 0):\n                warnings.warn(\n                    'RNN dropout is not supported with the CNTK backend '\n                    'when using dynamic RNNs (i.e. non-unrolled). '\n                    'You can either set `unroll=True`, '\n                    'set `dropout` and `recurrent_dropout` to 0, '\n                    'or use a different backend.')\n                dropout = 0.\n                recurrent_dropout = 0.\n\n        cell = GRUCell(units,\n                       activation=activation,\n                       recurrent_activation=recurrent_activation,\n                       use_bias=use_bias,\n                       kernel_initializer=kernel_initializer,\n                       recurrent_initializer=recurrent_initializer,\n                       bias_initializer=bias_initializer,\n                       kernel_regularizer=kernel_regularizer,\n                       recurrent_regularizer=recurrent_regularizer,\n                       bias_regularizer=bias_regularizer,\n                       kernel_constraint=kernel_constraint,\n                       recurrent_constraint=recurrent_constraint,\n                       bias_constraint=bias_constraint,\n                       dropout=dropout,\n                       recurrent_dropout=recurrent_dropout,\n                       implementation=implementation)\n        super(GRU, self).__init__(cell,\n                                  return_sequences=return_sequences,\n                                  return_state=return_state,\n                                  go_backwards=go_backwards,\n                                  stateful=stateful,\n                                  unroll=unroll,\n                                  **kwargs)\n        self.activity_regularizer = regularizers.get(activity_regularizer)",
        "begin_line": 1432,
        "end_line": 1493,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001145475372279496,
            "pseudo_dstar_susp": 0.0011025358324145535,
            "pseudo_tarantula_susp": 0.0017985611510791368,
            "pseudo_op2_susp": 0.0011025358324145535,
            "pseudo_barinel_susp": 0.0017985611510791368
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.call#1495",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.call(self, inputs, mask=None, training=None, initial_state=None)",
        "snippet": "    def call(self, inputs, mask=None, training=None, initial_state=None):\n        self.cell._generate_dropout_mask(inputs, training=training)\n        self.cell._generate_recurrent_dropout_mask(inputs, training=training)\n        return super(GRU, self).call(inputs,\n                                     mask=mask,\n                                     training=training,\n                                     initial_state=initial_state)",
        "begin_line": 1495,
        "end_line": 1501,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010520778537611783,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.units#1504",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.units(self)",
        "snippet": "    def units(self):\n        return self.cell.units",
        "begin_line": 1504,
        "end_line": 1505,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.activation#1508",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.activation(self)",
        "snippet": "    def activation(self):\n        return self.cell.activation",
        "begin_line": 1508,
        "end_line": 1509,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.recurrent_activation#1512",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.recurrent_activation(self)",
        "snippet": "    def recurrent_activation(self):\n        return self.cell.recurrent_activation",
        "begin_line": 1512,
        "end_line": 1513,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.use_bias#1516",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.use_bias(self)",
        "snippet": "    def use_bias(self):\n        return self.cell.use_bias",
        "begin_line": 1516,
        "end_line": 1517,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.kernel_initializer#1520",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.kernel_initializer(self)",
        "snippet": "    def kernel_initializer(self):\n        return self.cell.kernel_initializer",
        "begin_line": 1520,
        "end_line": 1521,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.recurrent_initializer#1524",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.recurrent_initializer(self)",
        "snippet": "    def recurrent_initializer(self):\n        return self.cell.recurrent_initializer",
        "begin_line": 1524,
        "end_line": 1525,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.bias_initializer#1528",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.bias_initializer(self)",
        "snippet": "    def bias_initializer(self):\n        return self.cell.bias_initializer",
        "begin_line": 1528,
        "end_line": 1529,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.kernel_regularizer#1532",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.kernel_regularizer(self)",
        "snippet": "    def kernel_regularizer(self):\n        return self.cell.kernel_regularizer",
        "begin_line": 1532,
        "end_line": 1533,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.recurrent_regularizer#1536",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.recurrent_regularizer(self)",
        "snippet": "    def recurrent_regularizer(self):\n        return self.cell.recurrent_regularizer",
        "begin_line": 1536,
        "end_line": 1537,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.bias_regularizer#1540",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.bias_regularizer(self)",
        "snippet": "    def bias_regularizer(self):\n        return self.cell.bias_regularizer",
        "begin_line": 1540,
        "end_line": 1541,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.kernel_constraint#1544",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.kernel_constraint(self)",
        "snippet": "    def kernel_constraint(self):\n        return self.cell.kernel_constraint",
        "begin_line": 1544,
        "end_line": 1545,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.recurrent_constraint#1548",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.recurrent_constraint(self)",
        "snippet": "    def recurrent_constraint(self):\n        return self.cell.recurrent_constraint",
        "begin_line": 1548,
        "end_line": 1549,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.bias_constraint#1552",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.bias_constraint(self)",
        "snippet": "    def bias_constraint(self):\n        return self.cell.bias_constraint",
        "begin_line": 1552,
        "end_line": 1553,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.dropout#1556",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.dropout(self)",
        "snippet": "    def dropout(self):\n        return self.cell.dropout",
        "begin_line": 1556,
        "end_line": 1557,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.recurrent_dropout#1560",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.recurrent_dropout(self)",
        "snippet": "    def recurrent_dropout(self):\n        return self.cell.recurrent_dropout",
        "begin_line": 1560,
        "end_line": 1561,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.implementation#1564",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.implementation(self)",
        "snippet": "    def implementation(self):\n        return self.cell.implementation",
        "begin_line": 1564,
        "end_line": 1565,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.get_config#1567",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'units': self.units,\n                  'activation': activations.serialize(self.activation),\n                  'recurrent_activation': activations.serialize(self.recurrent_activation),\n                  'use_bias': self.use_bias,\n                  'kernel_initializer': initializers.serialize(self.kernel_initializer),\n                  'recurrent_initializer': initializers.serialize(self.recurrent_initializer),\n                  'bias_initializer': initializers.serialize(self.bias_initializer),\n                  'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n                  'recurrent_regularizer': regularizers.serialize(self.recurrent_regularizer),\n                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n                  'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n                  'recurrent_constraint': constraints.serialize(self.recurrent_constraint),\n                  'bias_constraint': constraints.serialize(self.bias_constraint),\n                  'dropout': self.dropout,\n                  'recurrent_dropout': self.recurrent_dropout,\n                  'implementation': self.implementation}\n        base_config = super(GRU, self).get_config()\n        del base_config['cell']\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 1567,
        "end_line": 1587,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.from_config#1590",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.from_config(cls, config)",
        "snippet": "    def from_config(cls, config):\n        if 'implementation' in config and config['implementation'] == 0:\n            config['implementation'] = 1\n        return cls(**config)",
        "begin_line": 1590,
        "end_line": 1593,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00012818869375721061,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.LSTMCell.__init__#1647",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTMCell",
        "signature": "keras.layers.recurrent.LSTMCell.__init__(self, units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, **kwargs)",
        "snippet": "    def __init__(self, units,\n                 activation='tanh',\n                 recurrent_activation='hard_sigmoid',\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 recurrent_initializer='orthogonal',\n                 bias_initializer='zeros',\n                 unit_forget_bias=True,\n                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n                 kernel_constraint=None,\n                 recurrent_constraint=None,\n                 bias_constraint=None,\n                 dropout=0.,\n                 recurrent_dropout=0.,\n                 implementation=1,\n                 **kwargs):\n        super(LSTMCell, self).__init__(**kwargs)\n        self.units = units\n        self.activation = activations.get(activation)\n        self.recurrent_activation = activations.get(recurrent_activation)\n        self.use_bias = use_bias\n\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.recurrent_initializer = initializers.get(recurrent_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.unit_forget_bias = unit_forget_bias\n\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.recurrent_constraint = constraints.get(recurrent_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n\n        self.dropout = min(1., max(0., dropout))\n        self.recurrent_dropout = min(1., max(0., recurrent_dropout))\n        self.implementation = implementation\n        self.state_size = (self.units, self.units)\n        self._dropout_mask = None\n        self._recurrent_dropout_mask = None",
        "begin_line": 1647,
        "end_line": 1689,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.000970873786407767,
            "pseudo_dstar_susp": 0.0009398496240601503,
            "pseudo_tarantula_susp": 0.0013404825737265416,
            "pseudo_op2_susp": 0.0009398496240601503,
            "pseudo_barinel_susp": 0.0013404825737265416
        }
    },
    {
        "name": "keras.layers.recurrent.LSTMCell.build#1691",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTMCell",
        "signature": "keras.layers.recurrent.LSTMCell.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        input_dim = input_shape[-1]\n        self.kernel = self.add_weight(shape=(input_dim, self.units * 4),\n                                      name='kernel',\n                                      initializer=self.kernel_initializer,\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        self.recurrent_kernel = self.add_weight(\n            shape=(self.units, self.units * 4),\n            name='recurrent_kernel',\n            initializer=self.recurrent_initializer,\n            regularizer=self.recurrent_regularizer,\n            constraint=self.recurrent_constraint)\n\n        if self.use_bias:\n            if self.unit_forget_bias:\n                def bias_initializer(shape, *args, **kwargs):\n                    return K.concatenate([\n                        self.bias_initializer((self.units,), *args, **kwargs),\n                        initializers.Ones()((self.units,), *args, **kwargs),\n                        self.bias_initializer((self.units * 2,), *args, **kwargs),\n                    ])\n            else:\n                bias_initializer = self.bias_initializer\n            self.bias = self.add_weight(shape=(self.units * 4,),\n                                        name='bias',\n                                        initializer=bias_initializer,\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n\n        self.kernel_i = self.kernel[:, :self.units]\n        self.kernel_f = self.kernel[:, self.units: self.units * 2]\n        self.kernel_c = self.kernel[:, self.units * 2: self.units * 3]\n        self.kernel_o = self.kernel[:, self.units * 3:]\n\n        self.recurrent_kernel_i = self.recurrent_kernel[:, :self.units]\n        self.recurrent_kernel_f = self.recurrent_kernel[:, self.units: self.units * 2]\n        self.recurrent_kernel_c = self.recurrent_kernel[:, self.units * 2: self.units * 3]\n        self.recurrent_kernel_o = self.recurrent_kernel[:, self.units * 3:]\n\n        if self.use_bias:\n            self.bias_i = self.bias[:self.units]\n            self.bias_f = self.bias[self.units: self.units * 2]\n            self.bias_c = self.bias[self.units * 2: self.units * 3]\n            self.bias_o = self.bias[self.units * 3:]\n        else:\n            self.bias_i = None\n            self.bias_f = None\n            self.bias_c = None\n            self.bias_o = None\n        self.built = True",
        "begin_line": 1691,
        "end_line": 1743,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0010384215991692627,
            "pseudo_dstar_susp": 0.0010030090270812437,
            "pseudo_tarantula_susp": 0.0015015015015015015,
            "pseudo_op2_susp": 0.0010030090270812437,
            "pseudo_barinel_susp": 0.0015015015015015015
        }
    },
    {
        "name": "keras.layers.recurrent.LSTMCell.bias_initializer#1707",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTMCell",
        "signature": "keras.layers.recurrent.LSTMCell.bias_initializer(shape, *args, **kwargs)",
        "snippet": "                def bias_initializer(shape, *args, **kwargs):\n                    return K.concatenate([\n                        self.bias_initializer((self.units,), *args, **kwargs),\n                        initializers.Ones()((self.units,), *args, **kwargs),\n                        self.bias_initializer((self.units * 2,), *args, **kwargs),\n                    ])",
        "begin_line": 1707,
        "end_line": 1712,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0019193857965451055,
            "pseudo_dstar_susp": 0.0027100271002710027,
            "pseudo_tarantula_susp": 0.0015015015015015015,
            "pseudo_op2_susp": 0.0027100271002710027,
            "pseudo_barinel_susp": 0.0015015015015015015
        }
    },
    {
        "name": "keras.layers.recurrent.LSTMCell._generate_dropout_mask#1745",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTMCell",
        "signature": "keras.layers.recurrent.LSTMCell._generate_dropout_mask(self, inputs, training=None)",
        "snippet": "    def _generate_dropout_mask(self, inputs, training=None):\n        if 0 < self.dropout < 1:\n            ones = K.ones_like(K.squeeze(inputs[:, 0:1, :], axis=1))\n\n            def dropped_inputs():\n                return K.dropout(ones, self.dropout)\n\n            self._dropout_mask = [K.in_train_phase(\n                dropped_inputs,\n                ones,\n                training=training)\n                for _ in range(4)]\n        else:\n            self._dropout_mask = None",
        "begin_line": 1745,
        "end_line": 1758,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.LSTMCell.dropped_inputs#1749",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTMCell",
        "signature": "keras.layers.recurrent.LSTMCell.dropped_inputs()",
        "snippet": "            def dropped_inputs():\n                return K.dropout(ones, self.dropout)",
        "begin_line": 1749,
        "end_line": 1750,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.LSTMCell._generate_recurrent_dropout_mask#1760",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTMCell",
        "signature": "keras.layers.recurrent.LSTMCell._generate_recurrent_dropout_mask(self, inputs, training=None)",
        "snippet": "    def _generate_recurrent_dropout_mask(self, inputs, training=None):\n        if 0 < self.recurrent_dropout < 1:\n            ones = K.ones_like(K.reshape(inputs[:, 0, 0], (-1, 1)))\n            ones = K.tile(ones, (1, self.units))\n\n            def dropped_inputs():\n                return K.dropout(ones, self.dropout)\n\n            self._recurrent_dropout_mask = [K.in_train_phase(\n                dropped_inputs,\n                ones,\n                training=training)\n                for _ in range(4)]\n        else:\n            self._recurrent_dropout_mask = None",
        "begin_line": 1760,
        "end_line": 1774,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.LSTMCell.dropped_inputs#1765",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTMCell",
        "signature": "keras.layers.recurrent.LSTMCell.dropped_inputs()",
        "snippet": "            def dropped_inputs():\n                return K.dropout(ones, self.dropout)",
        "begin_line": 1765,
        "end_line": 1766,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.LSTMCell.call#1776",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTMCell",
        "signature": "keras.layers.recurrent.LSTMCell.call(self, inputs, states, training=None)",
        "snippet": "    def call(self, inputs, states, training=None):\n        # dropout matrices for input units\n        dp_mask = self._dropout_mask\n        # dropout matrices for recurrent units\n        rec_dp_mask = self._recurrent_dropout_mask\n\n        h_tm1 = states[0]  # previous memory state\n        c_tm1 = states[1]  # previous carry state\n\n        if self.implementation == 1:\n            if 0 < self.dropout < 1.:\n                inputs_i = inputs * dp_mask[0]\n                inputs_f = inputs * dp_mask[1]\n                inputs_c = inputs * dp_mask[2]\n                inputs_o = inputs * dp_mask[3]\n            else:\n                inputs_i = inputs\n                inputs_f = inputs\n                inputs_c = inputs\n                inputs_o = inputs\n            x_i = K.dot(inputs_i, self.kernel_i)\n            x_f = K.dot(inputs_f, self.kernel_f)\n            x_c = K.dot(inputs_c, self.kernel_c)\n            x_o = K.dot(inputs_o, self.kernel_o)\n            if self.use_bias:\n                x_i = K.bias_add(x_i, self.bias_i)\n                x_f = K.bias_add(x_f, self.bias_f)\n                x_c = K.bias_add(x_c, self.bias_c)\n                x_o = K.bias_add(x_o, self.bias_o)\n\n            if 0 < self.recurrent_dropout < 1.:\n                h_tm1_i = h_tm1 * rec_dp_mask[0]\n                h_tm1_f = h_tm1 * rec_dp_mask[1]\n                h_tm1_c = h_tm1 * rec_dp_mask[2]\n                h_tm1_o = h_tm1 * rec_dp_mask[3]\n            else:\n                h_tm1_i = h_tm1\n                h_tm1_f = h_tm1\n                h_tm1_c = h_tm1\n                h_tm1_o = h_tm1\n            i = self.recurrent_activation(x_i + K.dot(h_tm1_i,\n                                                      self.recurrent_kernel_i))\n            f = self.recurrent_activation(x_f + K.dot(h_tm1_f,\n                                                      self.recurrent_kernel_f))\n            c = f * c_tm1 + i * self.activation(x_c + K.dot(h_tm1_c,\n                                                            self.recurrent_kernel_c))\n            o = self.recurrent_activation(x_o + K.dot(h_tm1_o,\n                                                      self.recurrent_kernel_o))\n        else:\n            if 0. < self.dropout < 1.:\n                inputs *= dp_mask[0]\n            z = K.dot(inputs, self.kernel)\n            if 0. < self.recurrent_dropout < 1.:\n                h_tm1 *= rec_dp_mask[0]\n            z += K.dot(h_tm1, self.recurrent_kernel)\n            if self.use_bias:\n                z = K.bias_add(z, self.bias)\n\n            z0 = z[:, :self.units]\n            z1 = z[:, self.units: 2 * self.units]\n            z2 = z[:, 2 * self.units: 3 * self.units]\n            z3 = z[:, 3 * self.units:]\n\n            i = self.recurrent_activation(z0)\n            f = self.recurrent_activation(z1)\n            c = f * c_tm1 + i * self.activation(z2)\n            o = self.recurrent_activation(z3)\n\n        h = o * self.activation(c)\n        if 0 < self.dropout + self.recurrent_dropout:\n            if training is None:\n                h._uses_learning_phase = True\n        return h, [h, c]",
        "begin_line": 1776,
        "end_line": 1848,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.__init__#1928",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.__init__(self, units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False, **kwargs)",
        "snippet": "    def __init__(self, units,\n                 activation='tanh',\n                 recurrent_activation='hard_sigmoid',\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 recurrent_initializer='orthogonal',\n                 bias_initializer='zeros',\n                 unit_forget_bias=True,\n                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 recurrent_constraint=None,\n                 bias_constraint=None,\n                 dropout=0.,\n                 recurrent_dropout=0.,\n                 implementation=1,\n                 return_sequences=False,\n                 return_state=False,\n                 go_backwards=False,\n                 stateful=False,\n                 unroll=False,\n                 **kwargs):\n        if implementation == 0:\n            warnings.warn('`implementation=0` has been deprecated, '\n                          'and now defaults to `implementation=1`.'\n                          'Please update your layer call.')\n        if K.backend() == 'cntk':\n            if not kwargs.get('unroll') and (dropout > 0 or recurrent_dropout > 0):\n                warnings.warn(\n                    'RNN dropout is not supported with the CNTK backend '\n                    'when using dynamic RNNs (i.e. non-unrolled). '\n                    'You can either set `unroll=True`, '\n                    'set `dropout` and `recurrent_dropout` to 0, '\n                    'or use a different backend.')\n                dropout = 0.\n                recurrent_dropout = 0.\n\n        cell = LSTMCell(units,\n                        activation=activation,\n                        recurrent_activation=recurrent_activation,\n                        use_bias=use_bias,\n                        kernel_initializer=kernel_initializer,\n                        recurrent_initializer=recurrent_initializer,\n                        unit_forget_bias=unit_forget_bias,\n                        bias_initializer=bias_initializer,\n                        kernel_regularizer=kernel_regularizer,\n                        recurrent_regularizer=recurrent_regularizer,\n                        bias_regularizer=bias_regularizer,\n                        kernel_constraint=kernel_constraint,\n                        recurrent_constraint=recurrent_constraint,\n                        bias_constraint=bias_constraint,\n                        dropout=dropout,\n                        recurrent_dropout=recurrent_dropout,\n                        implementation=implementation)\n        super(LSTM, self).__init__(cell,\n                                   return_sequences=return_sequences,\n                                   return_state=return_state,\n                                   go_backwards=go_backwards,\n                                   stateful=stateful,\n                                   unroll=unroll,\n                                   **kwargs)\n        self.activity_regularizer = regularizers.get(activity_regularizer)",
        "begin_line": 1928,
        "end_line": 1991,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0010384215991692627,
            "pseudo_dstar_susp": 0.0010030090270812437,
            "pseudo_tarantula_susp": 0.0015015015015015015,
            "pseudo_op2_susp": 0.0010030090270812437,
            "pseudo_barinel_susp": 0.0015015015015015015
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.call#1993",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.call(self, inputs, mask=None, training=None, initial_state=None)",
        "snippet": "    def call(self, inputs, mask=None, training=None, initial_state=None):\n        self.cell._generate_dropout_mask(inputs, training=training)\n        self.cell._generate_recurrent_dropout_mask(inputs, training=training)\n        return super(LSTM, self).call(inputs,\n                                      mask=mask,\n                                      training=training,\n                                      initial_state=initial_state)",
        "begin_line": 1993,
        "end_line": 1999,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010345541071798055,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.units#2002",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.units(self)",
        "snippet": "    def units(self):\n        return self.cell.units",
        "begin_line": 2002,
        "end_line": 2003,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.activation#2006",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.activation(self)",
        "snippet": "    def activation(self):\n        return self.cell.activation",
        "begin_line": 2006,
        "end_line": 2007,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.recurrent_activation#2010",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.recurrent_activation(self)",
        "snippet": "    def recurrent_activation(self):\n        return self.cell.recurrent_activation",
        "begin_line": 2010,
        "end_line": 2011,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.use_bias#2014",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.use_bias(self)",
        "snippet": "    def use_bias(self):\n        return self.cell.use_bias",
        "begin_line": 2014,
        "end_line": 2015,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.kernel_initializer#2018",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.kernel_initializer(self)",
        "snippet": "    def kernel_initializer(self):\n        return self.cell.kernel_initializer",
        "begin_line": 2018,
        "end_line": 2019,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.recurrent_initializer#2022",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.recurrent_initializer(self)",
        "snippet": "    def recurrent_initializer(self):\n        return self.cell.recurrent_initializer",
        "begin_line": 2022,
        "end_line": 2023,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.bias_initializer#2026",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.bias_initializer(self)",
        "snippet": "    def bias_initializer(self):\n        return self.cell.bias_initializer",
        "begin_line": 2026,
        "end_line": 2027,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.unit_forget_bias#2030",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.unit_forget_bias(self)",
        "snippet": "    def unit_forget_bias(self):\n        return self.cell.unit_forget_bias",
        "begin_line": 2030,
        "end_line": 2031,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.kernel_regularizer#2034",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.kernel_regularizer(self)",
        "snippet": "    def kernel_regularizer(self):\n        return self.cell.kernel_regularizer",
        "begin_line": 2034,
        "end_line": 2035,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.recurrent_regularizer#2038",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.recurrent_regularizer(self)",
        "snippet": "    def recurrent_regularizer(self):\n        return self.cell.recurrent_regularizer",
        "begin_line": 2038,
        "end_line": 2039,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.bias_regularizer#2042",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.bias_regularizer(self)",
        "snippet": "    def bias_regularizer(self):\n        return self.cell.bias_regularizer",
        "begin_line": 2042,
        "end_line": 2043,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.kernel_constraint#2046",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.kernel_constraint(self)",
        "snippet": "    def kernel_constraint(self):\n        return self.cell.kernel_constraint",
        "begin_line": 2046,
        "end_line": 2047,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.recurrent_constraint#2050",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.recurrent_constraint(self)",
        "snippet": "    def recurrent_constraint(self):\n        return self.cell.recurrent_constraint",
        "begin_line": 2050,
        "end_line": 2051,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.bias_constraint#2054",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.bias_constraint(self)",
        "snippet": "    def bias_constraint(self):\n        return self.cell.bias_constraint",
        "begin_line": 2054,
        "end_line": 2055,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.dropout#2058",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.dropout(self)",
        "snippet": "    def dropout(self):\n        return self.cell.dropout",
        "begin_line": 2058,
        "end_line": 2059,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.recurrent_dropout#2062",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.recurrent_dropout(self)",
        "snippet": "    def recurrent_dropout(self):\n        return self.cell.recurrent_dropout",
        "begin_line": 2062,
        "end_line": 2063,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.implementation#2066",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.implementation(self)",
        "snippet": "    def implementation(self):\n        return self.cell.implementation",
        "begin_line": 2066,
        "end_line": 2067,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.get_config#2069",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'units': self.units,\n                  'activation': activations.serialize(self.activation),\n                  'recurrent_activation': activations.serialize(self.recurrent_activation),\n                  'use_bias': self.use_bias,\n                  'kernel_initializer': initializers.serialize(self.kernel_initializer),\n                  'recurrent_initializer': initializers.serialize(self.recurrent_initializer),\n                  'bias_initializer': initializers.serialize(self.bias_initializer),\n                  'unit_forget_bias': self.unit_forget_bias,\n                  'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n                  'recurrent_regularizer': regularizers.serialize(self.recurrent_regularizer),\n                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n                  'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n                  'recurrent_constraint': constraints.serialize(self.recurrent_constraint),\n                  'bias_constraint': constraints.serialize(self.bias_constraint),\n                  'dropout': self.dropout,\n                  'recurrent_dropout': self.recurrent_dropout,\n                  'implementation': self.implementation}\n        base_config = super(LSTM, self).get_config()\n        del base_config['cell']\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 2069,
        "end_line": 2090,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.from_config#2093",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.from_config(cls, config)",
        "snippet": "    def from_config(cls, config):\n        if 'implementation' in config and config['implementation'] == 0:\n            config['implementation'] = 1\n        return cls(**config)",
        "begin_line": 2093,
        "end_line": 2096,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling._Pooling1D.__init__#15",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._Pooling1D",
        "signature": "keras.layers.pooling._Pooling1D.__init__(self, pool_size=2, strides=None, padding='valid', **kwargs)",
        "snippet": "    def __init__(self, pool_size=2, strides=None,\n                 padding='valid', **kwargs):\n        super(_Pooling1D, self).__init__(**kwargs)\n        if strides is None:\n            strides = pool_size\n        self.pool_size = conv_utils.normalize_tuple(pool_size, 1, 'pool_size')\n        self.strides = conv_utils.normalize_tuple(strides, 1, 'strides')\n        self.padding = conv_utils.normalize_padding(padding)\n        self.input_spec = InputSpec(ndim=3)",
        "begin_line": 15,
        "end_line": 23,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling._Pooling1D.compute_output_shape#25",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._Pooling1D",
        "signature": "keras.layers.pooling._Pooling1D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        length = conv_utils.conv_output_length(input_shape[1],\n                                               self.pool_size[0],\n                                               self.padding,\n                                               self.strides[0])\n        return (input_shape[0], length, input_shape[2])",
        "begin_line": 25,
        "end_line": 30,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling._Pooling1D.call#36",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._Pooling1D",
        "signature": "keras.layers.pooling._Pooling1D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        inputs = K.expand_dims(inputs, 2)   # add dummy last dimension\n        output = self._pooling_function(inputs=inputs,\n                                        pool_size=self.pool_size + (1,),\n                                        strides=self.strides + (1,),\n                                        padding=self.padding,\n                                        data_format='channels_last')\n        return K.squeeze(output, 2)  # remove dummy last dimension",
        "begin_line": 36,
        "end_line": 43,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling._Pooling1D.get_config#45",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._Pooling1D",
        "signature": "keras.layers.pooling._Pooling1D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'strides': self.strides,\n                  'pool_size': self.pool_size,\n                  'padding': self.padding}\n        base_config = super(_Pooling1D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 45,
        "end_line": 50,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling.MaxPooling1D.__init__#71",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.MaxPooling1D",
        "signature": "keras.layers.pooling.MaxPooling1D.__init__(self, pool_size=2, strides=None, padding='valid', **kwargs)",
        "snippet": "    def __init__(self, pool_size=2, strides=None,\n                 padding='valid', **kwargs):\n        super(MaxPooling1D, self).__init__(pool_size, strides,\n                                           padding, **kwargs)",
        "begin_line": 71,
        "end_line": 74,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling.MaxPooling1D._pooling_function#76",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.MaxPooling1D",
        "signature": "keras.layers.pooling.MaxPooling1D._pooling_function(self, inputs, pool_size, strides, padding, data_format)",
        "snippet": "    def _pooling_function(self, inputs, pool_size, strides,\n                          padding, data_format):\n        output = K.pool2d(inputs, pool_size, strides,\n                          padding, data_format, pool_mode='max')\n        return output",
        "begin_line": 76,
        "end_line": 80,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling.AveragePooling1D.__init__#101",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.AveragePooling1D",
        "signature": "keras.layers.pooling.AveragePooling1D.__init__(self, pool_size=2, strides=None, padding='valid', **kwargs)",
        "snippet": "    def __init__(self, pool_size=2, strides=None,\n                 padding='valid', **kwargs):\n        super(AveragePooling1D, self).__init__(pool_size, strides,\n                                               padding, **kwargs)",
        "begin_line": 101,
        "end_line": 104,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling.AveragePooling1D._pooling_function#106",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.AveragePooling1D",
        "signature": "keras.layers.pooling.AveragePooling1D._pooling_function(self, inputs, pool_size, strides, padding, data_format)",
        "snippet": "    def _pooling_function(self, inputs, pool_size, strides,\n                          padding, data_format):\n        output = K.pool2d(inputs, pool_size, strides,\n                          padding, data_format, pool_mode='avg')\n        return output",
        "begin_line": 106,
        "end_line": 110,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling._Pooling2D.__init__#117",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._Pooling2D",
        "signature": "keras.layers.pooling._Pooling2D.__init__(self, pool_size=(2, 2), strides=None, padding='valid', data_format=None, **kwargs)",
        "snippet": "    def __init__(self, pool_size=(2, 2), strides=None, padding='valid',\n                 data_format=None, **kwargs):\n        super(_Pooling2D, self).__init__(**kwargs)\n        data_format = conv_utils.normalize_data_format(data_format)\n        if strides is None:\n            strides = pool_size\n        self.pool_size = conv_utils.normalize_tuple(pool_size, 2, 'pool_size')\n        self.strides = conv_utils.normalize_tuple(strides, 2, 'strides')\n        self.padding = conv_utils.normalize_padding(padding)\n        self.data_format = conv_utils.normalize_data_format(data_format)\n        self.input_spec = InputSpec(ndim=4)",
        "begin_line": 117,
        "end_line": 127,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001152604887044721,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling._Pooling2D.compute_output_shape#129",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._Pooling2D",
        "signature": "keras.layers.pooling._Pooling2D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self.data_format == 'channels_first':\n            rows = input_shape[2]\n            cols = input_shape[3]\n        elif self.data_format == 'channels_last':\n            rows = input_shape[1]\n            cols = input_shape[2]\n        rows = conv_utils.conv_output_length(rows, self.pool_size[0],\n                                             self.padding, self.strides[0])\n        cols = conv_utils.conv_output_length(cols, self.pool_size[1],\n                                             self.padding, self.strides[1])\n        if self.data_format == 'channels_first':\n            return (input_shape[0], input_shape[1], rows, cols)\n        elif self.data_format == 'channels_last':\n            return (input_shape[0], rows, cols, input_shape[3])",
        "begin_line": 129,
        "end_line": 143,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling._Pooling2D.call#149",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._Pooling2D",
        "signature": "keras.layers.pooling._Pooling2D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        output = self._pooling_function(inputs=inputs,\n                                        pool_size=self.pool_size,\n                                        strides=self.strides,\n                                        padding=self.padding,\n                                        data_format=self.data_format)\n        return output",
        "begin_line": 149,
        "end_line": 155,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001006947940791461,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling._Pooling2D.get_config#157",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._Pooling2D",
        "signature": "keras.layers.pooling._Pooling2D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'pool_size': self.pool_size,\n                  'padding': self.padding,\n                  'strides': self.strides,\n                  'data_format': self.data_format}\n        base_config = super(_Pooling2D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 157,
        "end_line": 163,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00012818869375721061,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling.MaxPooling2D.__init__#208",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.MaxPooling2D",
        "signature": "keras.layers.pooling.MaxPooling2D.__init__(self, pool_size=(2, 2), strides=None, padding='valid', data_format=None, **kwargs)",
        "snippet": "    def __init__(self, pool_size=(2, 2), strides=None, padding='valid',\n                 data_format=None, **kwargs):\n        super(MaxPooling2D, self).__init__(pool_size, strides, padding,\n                                           data_format, **kwargs)",
        "begin_line": 208,
        "end_line": 211,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001006947940791461,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling.MaxPooling2D._pooling_function#213",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.MaxPooling2D",
        "signature": "keras.layers.pooling.MaxPooling2D._pooling_function(self, inputs, pool_size, strides, padding, data_format)",
        "snippet": "    def _pooling_function(self, inputs, pool_size, strides,\n                          padding, data_format):\n        output = K.pool2d(inputs, pool_size, strides,\n                          padding, data_format,\n                          pool_mode='max')\n        return output",
        "begin_line": 213,
        "end_line": 218,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010136847440446021,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling.AveragePooling2D.__init__#263",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.AveragePooling2D",
        "signature": "keras.layers.pooling.AveragePooling2D.__init__(self, pool_size=(2, 2), strides=None, padding='valid', data_format=None, **kwargs)",
        "snippet": "    def __init__(self, pool_size=(2, 2), strides=None, padding='valid',\n                 data_format=None, **kwargs):\n        super(AveragePooling2D, self).__init__(pool_size, strides, padding,\n                                               data_format, **kwargs)",
        "begin_line": 263,
        "end_line": 266,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010793308148947653,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling.AveragePooling2D._pooling_function#268",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.AveragePooling2D",
        "signature": "keras.layers.pooling.AveragePooling2D._pooling_function(self, inputs, pool_size, strides, padding, data_format)",
        "snippet": "    def _pooling_function(self, inputs, pool_size, strides,\n                          padding, data_format):\n        output = K.pool2d(inputs, pool_size, strides,\n                          padding, data_format, pool_mode='avg')\n        return output",
        "begin_line": 268,
        "end_line": 272,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010882576994232234,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling._Pooling3D.__init__#279",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._Pooling3D",
        "signature": "keras.layers.pooling._Pooling3D.__init__(self, pool_size=(2, 2, 2), strides=None, padding='valid', data_format=None, **kwargs)",
        "snippet": "    def __init__(self, pool_size=(2, 2, 2), strides=None, padding='valid',\n                 data_format=None, **kwargs):\n        super(_Pooling3D, self).__init__(**kwargs)\n        if strides is None:\n            strides = pool_size\n        self.pool_size = conv_utils.normalize_tuple(pool_size, 3, 'pool_size')\n        self.strides = conv_utils.normalize_tuple(strides, 3, 'strides')\n        self.padding = conv_utils.normalize_padding(padding)\n        self.data_format = conv_utils.normalize_data_format(data_format)\n        self.input_spec = InputSpec(ndim=5)",
        "begin_line": 279,
        "end_line": 288,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling._Pooling3D.compute_output_shape#290",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._Pooling3D",
        "signature": "keras.layers.pooling._Pooling3D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self.data_format == 'channels_first':\n            len_dim1 = input_shape[2]\n            len_dim2 = input_shape[3]\n            len_dim3 = input_shape[4]\n        elif self.data_format == 'channels_last':\n            len_dim1 = input_shape[1]\n            len_dim2 = input_shape[2]\n            len_dim3 = input_shape[3]\n        len_dim1 = conv_utils.conv_output_length(len_dim1, self.pool_size[0],\n                                                 self.padding, self.strides[0])\n        len_dim2 = conv_utils.conv_output_length(len_dim2, self.pool_size[1],\n                                                 self.padding, self.strides[1])\n        len_dim3 = conv_utils.conv_output_length(len_dim3, self.pool_size[2],\n                                                 self.padding, self.strides[2])\n        if self.data_format == 'channels_first':\n            return (input_shape[0],\n                    input_shape[1],\n                    len_dim1, len_dim2, len_dim3)\n        elif self.data_format == 'channels_last':\n            return (input_shape[0],\n                    len_dim1, len_dim2, len_dim3,\n                    input_shape[4])",
        "begin_line": 290,
        "end_line": 312,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling._Pooling3D.call#318",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._Pooling3D",
        "signature": "keras.layers.pooling._Pooling3D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        output = self._pooling_function(inputs=inputs,\n                                        pool_size=self.pool_size,\n                                        strides=self.strides,\n                                        padding=self.padding,\n                                        data_format=self.data_format)\n        return output",
        "begin_line": 318,
        "end_line": 324,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling._Pooling3D.get_config#326",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._Pooling3D",
        "signature": "keras.layers.pooling._Pooling3D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'pool_size': self.pool_size,\n                  'padding': self.padding,\n                  'strides': self.strides,\n                  'data_format': self.data_format}\n        base_config = super(_Pooling3D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 326,
        "end_line": 332,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling.MaxPooling3D.__init__#373",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.MaxPooling3D",
        "signature": "keras.layers.pooling.MaxPooling3D.__init__(self, pool_size=(2, 2, 2), strides=None, padding='valid', data_format=None, **kwargs)",
        "snippet": "    def __init__(self, pool_size=(2, 2, 2), strides=None, padding='valid',\n                 data_format=None, **kwargs):\n        super(MaxPooling3D, self).__init__(pool_size, strides, padding,\n                                           data_format, **kwargs)",
        "begin_line": 373,
        "end_line": 376,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling.MaxPooling3D._pooling_function#378",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.MaxPooling3D",
        "signature": "keras.layers.pooling.MaxPooling3D._pooling_function(self, inputs, pool_size, strides, padding, data_format)",
        "snippet": "    def _pooling_function(self, inputs, pool_size, strides,\n                          padding, data_format):\n        output = K.pool3d(inputs, pool_size, strides,\n                          padding, data_format, pool_mode='max')\n        return output",
        "begin_line": 378,
        "end_line": 382,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling.AveragePooling3D.__init__#423",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.AveragePooling3D",
        "signature": "keras.layers.pooling.AveragePooling3D.__init__(self, pool_size=(2, 2, 2), strides=None, padding='valid', data_format=None, **kwargs)",
        "snippet": "    def __init__(self, pool_size=(2, 2, 2), strides=None, padding='valid',\n                 data_format=None, **kwargs):\n        super(AveragePooling3D, self).__init__(pool_size, strides, padding,\n                                               data_format, **kwargs)",
        "begin_line": 423,
        "end_line": 426,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling.AveragePooling3D._pooling_function#428",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.AveragePooling3D",
        "signature": "keras.layers.pooling.AveragePooling3D._pooling_function(self, inputs, pool_size, strides, padding, data_format)",
        "snippet": "    def _pooling_function(self, inputs, pool_size, strides,\n                          padding, data_format):\n        output = K.pool3d(inputs, pool_size, strides,\n                          padding, data_format,\n                          pool_mode='avg')\n        return output",
        "begin_line": 428,
        "end_line": 433,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling._GlobalPooling1D.__init__#440",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._GlobalPooling1D",
        "signature": "keras.layers.pooling._GlobalPooling1D.__init__(self, **kwargs)",
        "snippet": "    def __init__(self, **kwargs):\n        super(_GlobalPooling1D, self).__init__(**kwargs)\n        self.input_spec = InputSpec(ndim=3)",
        "begin_line": 440,
        "end_line": 442,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling._GlobalPooling1D.compute_output_shape#444",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._GlobalPooling1D",
        "signature": "keras.layers.pooling._GlobalPooling1D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        return (input_shape[0], input_shape[2])",
        "begin_line": 444,
        "end_line": 445,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling.GlobalAveragePooling1D.call#462",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.GlobalAveragePooling1D",
        "signature": "keras.layers.pooling.GlobalAveragePooling1D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        return K.mean(inputs, axis=1)",
        "begin_line": 462,
        "end_line": 463,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling.GlobalMaxPooling1D.call#477",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.GlobalMaxPooling1D",
        "signature": "keras.layers.pooling.GlobalMaxPooling1D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        return K.max(inputs, axis=1)",
        "begin_line": 477,
        "end_line": 478,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling._GlobalPooling2D.__init__#486",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._GlobalPooling2D",
        "signature": "keras.layers.pooling._GlobalPooling2D.__init__(self, data_format=None, **kwargs)",
        "snippet": "    def __init__(self, data_format=None, **kwargs):\n        super(_GlobalPooling2D, self).__init__(**kwargs)\n        self.data_format = conv_utils.normalize_data_format(data_format)\n        self.input_spec = InputSpec(ndim=4)",
        "begin_line": 486,
        "end_line": 489,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010630381630700542,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling._GlobalPooling2D.compute_output_shape#491",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._GlobalPooling2D",
        "signature": "keras.layers.pooling._GlobalPooling2D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self.data_format == 'channels_last':\n            return (input_shape[0], input_shape[3])\n        else:\n            return (input_shape[0], input_shape[1])",
        "begin_line": 491,
        "end_line": 495,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling._GlobalPooling2D.get_config#500",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._GlobalPooling2D",
        "signature": "keras.layers.pooling._GlobalPooling2D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'data_format': self.data_format}\n        base_config = super(_GlobalPooling2D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 500,
        "end_line": 503,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling.GlobalAveragePooling2D.call#534",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.GlobalAveragePooling2D",
        "signature": "keras.layers.pooling.GlobalAveragePooling2D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        if self.data_format == 'channels_last':\n            return K.mean(inputs, axis=[1, 2])\n        else:\n            return K.mean(inputs, axis=[2, 3])",
        "begin_line": 534,
        "end_line": 538,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling.GlobalMaxPooling2D.call#569",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.GlobalMaxPooling2D",
        "signature": "keras.layers.pooling.GlobalMaxPooling2D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        if self.data_format == 'channels_last':\n            return K.max(inputs, axis=[1, 2])\n        else:\n            return K.max(inputs, axis=[2, 3])",
        "begin_line": 569,
        "end_line": 573,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling._GlobalPooling3D.__init__#581",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._GlobalPooling3D",
        "signature": "keras.layers.pooling._GlobalPooling3D.__init__(self, data_format=None, **kwargs)",
        "snippet": "    def __init__(self, data_format=None, **kwargs):\n        super(_GlobalPooling3D, self).__init__(**kwargs)\n        self.data_format = conv_utils.normalize_data_format(data_format)\n        self.input_spec = InputSpec(ndim=5)",
        "begin_line": 581,
        "end_line": 584,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling._GlobalPooling3D.compute_output_shape#586",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._GlobalPooling3D",
        "signature": "keras.layers.pooling._GlobalPooling3D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self.data_format == 'channels_last':\n            return (input_shape[0], input_shape[4])\n        else:\n            return (input_shape[0], input_shape[1])",
        "begin_line": 586,
        "end_line": 590,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling._GlobalPooling3D.get_config#595",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling._GlobalPooling3D",
        "signature": "keras.layers.pooling._GlobalPooling3D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'data_format': self.data_format}\n        base_config = super(_GlobalPooling3D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 595,
        "end_line": 598,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling.GlobalAveragePooling3D.call#629",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.GlobalAveragePooling3D",
        "signature": "keras.layers.pooling.GlobalAveragePooling3D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        if self.data_format == 'channels_last':\n            return K.mean(inputs, axis=[1, 2, 3])\n        else:\n            return K.mean(inputs, axis=[2, 3, 4])",
        "begin_line": 629,
        "end_line": 633,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.pooling.GlobalMaxPooling3D.call#664",
        "src_path": "keras/layers/pooling.py",
        "class_name": "keras.layers.pooling.GlobalMaxPooling3D",
        "signature": "keras.layers.pooling.GlobalMaxPooling3D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        if self.data_format == 'channels_last':\n            return K.max(inputs, axis=[1, 2, 3])\n        else:\n            return K.max(inputs, axis=[2, 3, 4])",
        "begin_line": 664,
        "end_line": 668,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.merge._Merge.__init__#14",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge._Merge",
        "signature": "keras.layers.merge._Merge.__init__(self, **kwargs)",
        "snippet": "    def __init__(self, **kwargs):\n        super(_Merge, self).__init__(**kwargs)\n        self.supports_masking = True",
        "begin_line": 14,
        "end_line": 16,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009407337723424271,
            "pseudo_dstar_susp": 0.0009157509157509158,
            "pseudo_tarantula_susp": 0.0012484394506866417,
            "pseudo_op2_susp": 0.0009157509157509158,
            "pseudo_barinel_susp": 0.0012484394506866417
        }
    },
    {
        "name": "keras.layers.merge._Merge._compute_elemwise_op_output_shape#21",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge._Merge",
        "signature": "keras.layers.merge._Merge._compute_elemwise_op_output_shape(self, shape1, shape2)",
        "snippet": "    def _compute_elemwise_op_output_shape(self, shape1, shape2):\n        \"\"\"Computes the shape of the resultant of an elementwise operation.\n\n        # Arguments\n            shape1: tuple or None. Shape of the first tensor\n            shape2: tuple or None. Shape of the second tensor\n\n        # Returns\n            expected output shape when an element-wise operation is\n            carried out on 2 tensors with shapes shape1 and shape2.\n            tuple or None.\n\n        # Raises\n            ValueError: if shape1 and shape2 are not compatible for\n                element-wise operations.\n        \"\"\"\n        if None in [shape1, shape2]:\n            return None\n        elif len(shape1) < len(shape2):\n            return self._compute_elemwise_op_output_shape(shape2, shape1)\n        elif len(shape2) == 0:\n            return shape1\n        output_shape = list(shape1[:-len(shape2)])\n        for i, j in zip(shape1[-len(shape2):], shape2):\n            if i is None or j is None:\n                output_shape.append(None)\n            elif i == 1:\n                output_shape.append(j)\n            elif j == 1:\n                output_shape.append(i)\n            else:\n                if i != j:\n                    raise ValueError('Operands could not be broadcast '\n                                     'together with shapes ' +\n                                     str(shape1) + ' ' + str(shape2))\n                output_shape.append(i)\n        return tuple(output_shape)",
        "begin_line": 21,
        "end_line": 57,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001152604887044721,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.merge._Merge.build#59",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge._Merge",
        "signature": "keras.layers.merge._Merge.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        # Used purely for shape validation.\n        if not isinstance(input_shape, list):\n            raise ValueError('A merge layer should be called '\n                             'on a list of inputs.')\n        if len(input_shape) < 2:\n            raise ValueError('A merge layer should be called '\n                             'on a list of at least 2 inputs. '\n                             'Got ' + str(len(input_shape)) + ' inputs.')\n        batch_sizes = [s[0] for s in input_shape if s is not None]\n        batch_sizes = set(batch_sizes)\n        batch_sizes -= set([None])\n        if len(batch_sizes) > 1:\n            raise ValueError('Can not merge tensors with different '\n                             'batch sizes. Got tensors with shapes : ' +\n                             str(input_shape))\n        if input_shape[0] is None:\n            output_shape = None\n        else:\n            output_shape = input_shape[0][1:]\n        for i in range(1, len(input_shape)):\n            if input_shape[i] is None:\n                shape = None\n            else:\n                shape = input_shape[i][1:]\n            output_shape = self._compute_elemwise_op_output_shape(output_shape, shape)\n        # If the inputs have different ranks, we have to reshape them\n        # to make them broadcastable.\n        if None not in input_shape and len(set(map(len, input_shape))) == 1:\n            self._reshape_required = False\n        else:\n            self._reshape_required = True",
        "begin_line": 59,
        "end_line": 90,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.merge._Merge.call#92",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge._Merge",
        "signature": "keras.layers.merge._Merge.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        if self._reshape_required:\n            reshaped_inputs = []\n            input_ndims = list(map(K.ndim, inputs))\n            if None not in input_ndims:\n                # If ranks of all inputs are available,\n                # we simply expand each of them at axis=1\n                # until all of them have the same rank.\n                max_ndim = max(input_ndims)\n                for x in inputs:\n                    x_ndim = K.ndim(x)\n                    for _ in range(max_ndim - x_ndim):\n                        x = K.expand_dims(x, 1)\n                    reshaped_inputs.append(x)\n                return self._merge_function(reshaped_inputs)\n            else:\n                # Transpose all inputs so that batch size is the last dimension.\n                # (batch_size, dim1, dim2, ... ) -> (dim1, dim2, ... , batch_size)\n                transposed = False\n                for x in inputs:\n                    x_ndim = K.ndim(x)\n                    if x_ndim is None:\n                        x_shape = K.shape(x)\n                        batch_size = x_shape[0]\n                        new_shape = K.concatenate([x_shape[1:], K.expand_dims(batch_size)])\n                        x_transposed = K.reshape(x, K.stack([batch_size, K.prod(x_shape[1:])]))\n                        x_transposed = K.permute_dimensions(x_transposed, (1, 0))\n                        x_transposed = K.reshape(x_transposed, new_shape)\n                        reshaped_inputs.append(x_transposed)\n                        transposed = True\n                    elif x_ndim > 1:\n                        dims = list(range(1, x_ndim)) + [0]\n                        reshaped_inputs.append(K.permute_dimensions(x, dims))\n                        transposed = True\n                    else:\n                        # We don't transpose inputs if they are 1D vectors or scalars.\n                        reshaped_inputs.append(x)\n                y = self._merge_function(reshaped_inputs)\n                y_ndim = K.ndim(y)\n                if transposed:\n                    # If inputs have been transposed, we have to transpose the output too.\n                    if y_ndim is None:\n                        y_shape = K.shape(y)\n                        y_ndim = K.shape(y_shape)[0]\n                        batch_size = y_shape[y_ndim - 1]\n                        new_shape = K.concatenate([K.expand_dims(batch_size), y_shape[:y_ndim - 1]])\n                        y = K.reshape(y, (-1, batch_size))\n                        y = K.permute_dimensions(y, (1, 0))\n                        y = K.reshape(y, new_shape)\n                    elif y_ndim > 1:\n                        dims = [y_ndim - 1] + list(range(y_ndim - 1))\n                        y = K.permute_dimensions(y, dims)\n                return y\n        else:\n            return self._merge_function(inputs)",
        "begin_line": 92,
        "end_line": 146,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.merge._Merge.compute_output_shape#148",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge._Merge",
        "signature": "keras.layers.merge._Merge.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if input_shape[0] is None:\n            output_shape = None\n        else:\n            output_shape = input_shape[0][1:]\n        for i in range(1, len(input_shape)):\n            if input_shape[i] is None:\n                shape = None\n            else:\n                shape = input_shape[i][1:]\n            output_shape = self._compute_elemwise_op_output_shape(output_shape, shape)\n        batch_sizes = [s[0] for s in input_shape if s is not None]\n        batch_sizes = set(batch_sizes)\n        batch_sizes -= set([None])\n        if len(batch_sizes) == 1:\n            output_shape = (list(batch_sizes)[0],) + output_shape\n        else:\n            output_shape = (None,) + output_shape\n        return output_shape",
        "begin_line": 148,
        "end_line": 166,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.merge._Merge.compute_mask#168",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge._Merge",
        "signature": "keras.layers.merge._Merge.compute_mask(self, inputs, mask=None)",
        "snippet": "    def compute_mask(self, inputs, mask=None):\n        if mask is None:\n            return None\n        if not isinstance(mask, list):\n            raise ValueError('`mask` should be a list.')\n        if not isinstance(inputs, list):\n            raise ValueError('`inputs` should be a list.')\n        if len(mask) != len(inputs):\n            raise ValueError('The lists `inputs` and `mask` '\n                             'should have the same length.')\n        if all([m is None for m in mask]):\n            return None\n        masks = [K.expand_dims(m, 0) for m in mask if m is not None]\n        return K.all(K.concatenate(masks, axis=0), axis=0, keepdims=False)",
        "begin_line": 168,
        "end_line": 181,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.merge.Add._merge_function#207",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Add",
        "signature": "keras.layers.merge.Add._merge_function(self, inputs)",
        "snippet": "    def _merge_function(self, inputs):\n        output = inputs[0]\n        for i in range(1, len(inputs)):\n            output += inputs[i]\n        return output",
        "begin_line": 207,
        "end_line": 211,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010984182776801405,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.merge.Subtract._merge_function#238",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Subtract",
        "signature": "keras.layers.merge.Subtract._merge_function(self, inputs)",
        "snippet": "    def _merge_function(self, inputs):\n        if len(inputs) != 2:\n            raise ValueError('`Subtract` layer should be called '\n                             'on exactly 2 inputs')\n        if inputs[0]._keras_shape != inputs[1]._keras_shape:\n            raise ValueError('`Subtract` layer should be called '\n                             'on inputs of the same shape')\n        return inputs[0] - inputs[1]",
        "begin_line": 238,
        "end_line": 245,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.merge.Multiply._merge_function#256",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Multiply",
        "signature": "keras.layers.merge.Multiply._merge_function(self, inputs)",
        "snippet": "    def _merge_function(self, inputs):\n        output = inputs[0]\n        for i in range(1, len(inputs)):\n            output *= inputs[i]\n        return output",
        "begin_line": 256,
        "end_line": 260,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.merge.Average._merge_function#271",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Average",
        "signature": "keras.layers.merge.Average._merge_function(self, inputs)",
        "snippet": "    def _merge_function(self, inputs):\n        output = inputs[0]\n        for i in range(1, len(inputs)):\n            output += inputs[i]\n        return output / len(inputs)",
        "begin_line": 271,
        "end_line": 275,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.merge.Maximum._merge_function#286",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Maximum",
        "signature": "keras.layers.merge.Maximum._merge_function(self, inputs)",
        "snippet": "    def _merge_function(self, inputs):\n        output = inputs[0]\n        for i in range(1, len(inputs)):\n            output = K.maximum(output, inputs[i])\n        return output",
        "begin_line": 286,
        "end_line": 290,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.merge.Minimum._merge_function#301",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Minimum",
        "signature": "keras.layers.merge.Minimum._merge_function(self, inputs)",
        "snippet": "    def _merge_function(self, inputs):\n        output = inputs[0]\n        for i in range(1, len(inputs)):\n            output = K.minimum(output, inputs[i])\n        return output",
        "begin_line": 301,
        "end_line": 305,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.merge.Concatenate.__init__#320",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Concatenate",
        "signature": "keras.layers.merge.Concatenate.__init__(self, axis=-1, **kwargs)",
        "snippet": "    def __init__(self, axis=-1, **kwargs):\n        super(Concatenate, self).__init__(**kwargs)\n        self.axis = axis\n        self.supports_masking = True",
        "begin_line": 320,
        "end_line": 323,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0017985611510791368,
            "pseudo_dstar_susp": 0.0012738853503184713,
            "pseudo_tarantula_susp": 0.002421307506053269,
            "pseudo_op2_susp": 0.0012738853503184713,
            "pseudo_barinel_susp": 0.002421307506053269
        }
    },
    {
        "name": "keras.layers.merge.Concatenate.build#325",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Concatenate",
        "signature": "keras.layers.merge.Concatenate.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        # Used purely for shape validation.\n        if not isinstance(input_shape, list):\n            raise ValueError('`Concatenate` layer should be called '\n                             'on a list of inputs')\n        if all([shape is None for shape in input_shape]):\n            return\n        reduced_inputs_shapes = [list(shape) for shape in input_shape]\n        shape_set = set()\n        for i in range(len(reduced_inputs_shapes)):\n            del reduced_inputs_shapes[i][self.axis]\n            shape_set.add(tuple(reduced_inputs_shapes[i]))\n        if len(shape_set) > 1:\n            raise ValueError('`Concatenate` layer requires '\n                             'inputs with matching shapes '\n                             'except for the concat axis. '\n                             'Got inputs shapes: %s' % (input_shape))",
        "begin_line": 325,
        "end_line": 341,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002898550724637681,
            "pseudo_dstar_susp": 0.002770083102493075,
            "pseudo_tarantula_susp": 0.002421307506053269,
            "pseudo_op2_susp": 0.002770083102493075,
            "pseudo_barinel_susp": 0.002421307506053269
        }
    },
    {
        "name": "keras.layers.merge.Concatenate.call#343",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Concatenate",
        "signature": "keras.layers.merge.Concatenate.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        if not isinstance(inputs, list):\n            raise ValueError('A `Concatenate` layer should be called '\n                             'on a list of inputs.')\n        return K.concatenate(inputs, axis=self.axis)",
        "begin_line": 343,
        "end_line": 347,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0017985611510791368,
            "pseudo_dstar_susp": 0.0012738853503184713,
            "pseudo_tarantula_susp": 0.002421307506053269,
            "pseudo_op2_susp": 0.0012738853503184713,
            "pseudo_barinel_susp": 0.002421307506053269
        }
    },
    {
        "name": "keras.layers.merge.Concatenate.compute_output_shape#349",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Concatenate",
        "signature": "keras.layers.merge.Concatenate.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if not isinstance(input_shape, list):\n            raise ValueError('A `Concatenate` layer should be called '\n                             'on a list of inputs.')\n        input_shapes = input_shape\n        output_shape = list(input_shapes[0])\n        for shape in input_shapes[1:]:\n            if output_shape[self.axis] is None or shape[self.axis] is None:\n                output_shape[self.axis] = None\n                break\n            output_shape[self.axis] += shape[self.axis]\n        return tuple(output_shape)",
        "begin_line": 349,
        "end_line": 360,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0017985611510791368,
            "pseudo_dstar_susp": 0.0012738853503184713,
            "pseudo_tarantula_susp": 0.002421307506053269,
            "pseudo_op2_susp": 0.0012738853503184713,
            "pseudo_barinel_susp": 0.002421307506053269
        }
    },
    {
        "name": "keras.layers.merge.Concatenate.compute_mask#362",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Concatenate",
        "signature": "keras.layers.merge.Concatenate.compute_mask(self, inputs, mask=None)",
        "snippet": "    def compute_mask(self, inputs, mask=None):\n        if mask is None:\n            return None\n        if not isinstance(mask, list):\n            raise ValueError('`mask` should be a list.')\n        if not isinstance(inputs, list):\n            raise ValueError('`inputs` should be a list.')\n        if len(mask) != len(inputs):\n            raise ValueError('The lists `inputs` and `mask` '\n                             'should have the same length.')\n        if all([m is None for m in mask]):\n            return None\n        # Make a list of masks while making sure\n        # the dimensionality of each mask\n        # is the same as the corresponding input.\n        masks = []\n        for input_i, mask_i in zip(inputs, mask):\n            if mask_i is None:\n                # Input is unmasked. Append all 1s to masks,\n                masks.append(K.ones_like(input_i, dtype='bool'))\n            elif K.ndim(mask_i) < K.ndim(input_i):\n                # Mask is smaller than the input, expand it\n                masks.append(K.expand_dims(mask_i))\n            else:\n                masks.append(mask_i)\n        concatenated = K.concatenate(masks, axis=self.axis)\n        return K.all(concatenated, axis=-1, keepdims=False)",
        "begin_line": 362,
        "end_line": 388,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002898550724637681,
            "pseudo_dstar_susp": 0.002770083102493075,
            "pseudo_tarantula_susp": 0.002421307506053269,
            "pseudo_op2_susp": 0.002770083102493075,
            "pseudo_barinel_susp": 0.002421307506053269
        }
    },
    {
        "name": "keras.layers.merge.Concatenate.get_config#390",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Concatenate",
        "signature": "keras.layers.merge.Concatenate.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {\n            'axis': self.axis,\n        }\n        base_config = super(Concatenate, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 390,
        "end_line": 395,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.005813953488372093,
            "pseudo_dstar_susp": 0.0018181818181818182,
            "pseudo_tarantula_susp": 0.006134969325153374,
            "pseudo_op2_susp": 0.0018181818181818182,
            "pseudo_barinel_susp": 0.006134969325153374
        }
    },
    {
        "name": "keras.layers.merge.Dot.__init__#416",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Dot",
        "signature": "keras.layers.merge.Dot.__init__(self, axes, normalize=False, **kwargs)",
        "snippet": "    def __init__(self, axes, normalize=False, **kwargs):\n        super(Dot, self).__init__(**kwargs)\n        if not isinstance(axes, int):\n            if not isinstance(axes, (list, tuple)):\n                raise TypeError('Invalid type for `axes` - '\n                                'should be a list or an int.')\n            if len(axes) != 2:\n                raise ValueError('Invalid format for `axes` - '\n                                 'should contain two elements.')\n            if not isinstance(axes[0], int) or not isinstance(axes[1], int):\n                raise ValueError('Invalid format for `axes` - '\n                                 'list elements should be \"int\".')\n        self.axes = axes\n        self.normalize = normalize\n        self.supports_masking = True",
        "begin_line": 416,
        "end_line": 430,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.merge.Dot.build#432",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Dot",
        "signature": "keras.layers.merge.Dot.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        # Used purely for shape validation.\n        if not isinstance(input_shape, list) or len(input_shape) != 2:\n            raise ValueError('A `Dot` layer should be called '\n                             'on a list of 2 inputs.')\n        shape1 = input_shape[0]\n        shape2 = input_shape[1]\n        if shape1 is None or shape2 is None:\n            return\n        if isinstance(self.axes, int):\n            if self.axes < 0:\n                axes = [self.axes % len(shape1), self.axes % len(shape2)]\n            else:\n                axes = [self.axes] * 2\n        else:\n            axes = self.axes\n        if shape1[axes[0]] != shape2[axes[1]]:\n            raise ValueError(\n                'Dimension incompatibility '\n                '%s != %s. ' % (shape1[axes[0]], shape2[axes[1]]) +\n                'Layer shapes: %s, %s' % (shape1, shape2))",
        "begin_line": 432,
        "end_line": 452,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.merge.Dot.call#454",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Dot",
        "signature": "keras.layers.merge.Dot.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        x1 = inputs[0]\n        x2 = inputs[1]\n        if isinstance(self.axes, int):\n            if self.axes < 0:\n                axes = [self.axes % K.ndim(x1), self.axes % K.ndim(x2)]\n            else:\n                axes = [self.axes] * 2\n        else:\n            axes = []\n            for i in range(len(self.axes)):\n                if self.axes[i] < 0:\n                    axes.append(self.axes[i] % K.ndim(inputs[i]))\n                else:\n                    axes.append(self.axes[i])\n        if self.normalize:\n            x1 = K.l2_normalize(x1, axis=axes[0])\n            x2 = K.l2_normalize(x2, axis=axes[1])\n        output = K.batch_dot(x1, x2, axes)\n        return output",
        "begin_line": 454,
        "end_line": 473,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.merge.Dot.compute_output_shape#475",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Dot",
        "signature": "keras.layers.merge.Dot.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if not isinstance(input_shape, list) or len(input_shape) != 2:\n            raise ValueError('A `Dot` layer should be called '\n                             'on a list of 2 inputs.')\n        shape1 = list(input_shape[0])\n        shape2 = list(input_shape[1])\n        if isinstance(self.axes, int):\n            if self.axes < 0:\n                axes = [self.axes % len(shape1), self.axes % len(shape2)]\n            else:\n                axes = [self.axes] * 2\n        else:\n            axes = self.axes\n        shape1.pop(axes[0])\n        shape2.pop(axes[1])\n        shape2.pop(0)\n        output_shape = shape1 + shape2\n        if len(output_shape) == 1:\n            output_shape += [1]\n        return tuple(output_shape)",
        "begin_line": 475,
        "end_line": 494,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.merge.Dot.compute_mask#496",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge.Dot",
        "signature": "keras.layers.merge.Dot.compute_mask(self, inputs, mask=None)",
        "snippet": "    def compute_mask(self, inputs, mask=None):\n        return None",
        "begin_line": 496,
        "end_line": 497,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.merge.add#508",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge",
        "signature": "keras.layers.merge.add(inputs, **kwargs)",
        "snippet": "def add(inputs, **kwargs):\n    \"\"\"Functional interface to the `Add` layer.\n\n    # Arguments\n        inputs: A list of input tensors (at least 2).\n        **kwargs: Standard layer keyword arguments.\n\n    # Returns\n        A tensor, the sum of the inputs.\n\n    # Examples\n\n    ```python\n        import keras\n\n        input1 = keras.layers.Input(shape=(16,))\n        x1 = keras.layers.Dense(8, activation='relu')(input1)\n        input2 = keras.layers.Input(shape=(32,))\n        x2 = keras.layers.Dense(8, activation='relu')(input2)\n        added = keras.layers.add([x1, x2])\n\n        out = keras.layers.Dense(4)(added)\n        model = keras.models.Model(inputs=[input1, input2], outputs=out)\n    ```\n    \"\"\"\n    return Add(**kwargs)(inputs)",
        "begin_line": 508,
        "end_line": 533,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010984182776801405,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.merge.subtract#536",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge",
        "signature": "keras.layers.merge.subtract(inputs, **kwargs)",
        "snippet": "def subtract(inputs, **kwargs):\n    \"\"\"Functional interface to the `Subtract` layer.\n\n    # Arguments\n        inputs: A list of input tensors (exactly 2).\n        **kwargs: Standard layer keyword arguments.\n\n    # Returns\n        A tensor, the difference of the inputs.\n\n    # Examples\n\n    ```python\n        import keras\n\n        input1 = keras.layers.Input(shape=(16,))\n        x1 = keras.layers.Dense(8, activation='relu')(input1)\n        input2 = keras.layers.Input(shape=(32,))\n        x2 = keras.layers.Dense(8, activation='relu')(input2)\n        subtracted = keras.layers.subtract([x1, x2])\n\n        out = keras.layers.Dense(4)(subtracted)\n        model = keras.models.Model(inputs=[input1, input2], outputs=out)\n    ```\n    \"\"\"\n    return Subtract(**kwargs)(inputs)",
        "begin_line": 536,
        "end_line": 561,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.merge.multiply#564",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge",
        "signature": "keras.layers.merge.multiply(inputs, **kwargs)",
        "snippet": "def multiply(inputs, **kwargs):\n    \"\"\"Functional interface to the `Multiply` layer.\n\n    # Arguments\n        inputs: A list of input tensors (at least 2).\n        **kwargs: Standard layer keyword arguments.\n\n    # Returns\n        A tensor, the element-wise product of the inputs.\n    \"\"\"\n    return Multiply(**kwargs)(inputs)",
        "begin_line": 564,
        "end_line": 574,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.merge.average#577",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge",
        "signature": "keras.layers.merge.average(inputs, **kwargs)",
        "snippet": "def average(inputs, **kwargs):\n    \"\"\"Functional interface to the `Average` layer.\n\n    # Arguments\n        inputs: A list of input tensors (at least 2).\n        **kwargs: Standard layer keyword arguments.\n\n    # Returns\n        A tensor, the average of the inputs.\n    \"\"\"\n    return Average(**kwargs)(inputs)",
        "begin_line": 577,
        "end_line": 587,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.merge.maximum#590",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge",
        "signature": "keras.layers.merge.maximum(inputs, **kwargs)",
        "snippet": "def maximum(inputs, **kwargs):\n    \"\"\"Functional interface to the `Maximum` layer.\n\n    # Arguments\n        inputs: A list of input tensors (at least 2).\n        **kwargs: Standard layer keyword arguments.\n\n    # Returns\n        A tensor, the element-wise maximum of the inputs.\n    \"\"\"\n    return Maximum(**kwargs)(inputs)",
        "begin_line": 590,
        "end_line": 600,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.merge.minimum#603",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge",
        "signature": "keras.layers.merge.minimum(inputs, **kwargs)",
        "snippet": "def minimum(inputs, **kwargs):\n    \"\"\"Functional interface to the `Minimum` layer.\n\n    # Arguments\n        inputs: A list of input tensors (at least 2).\n        **kwargs: Standard layer keyword arguments.\n\n    # Returns\n        A tensor, the element-wise minimum of the inputs.\n    \"\"\"\n    return Minimum(**kwargs)(inputs)",
        "begin_line": 603,
        "end_line": 613,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.merge.concatenate#616",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge",
        "signature": "keras.layers.merge.concatenate(inputs, axis=-1, **kwargs)",
        "snippet": "def concatenate(inputs, axis=-1, **kwargs):\n    \"\"\"Functional interface to the `Concatenate` layer.\n\n    # Arguments\n        inputs: A list of input tensors (at least 2).\n        axis: Concatenation axis.\n        **kwargs: Standard layer keyword arguments.\n\n    # Returns\n        A tensor, the concatenation of the inputs alongside axis `axis`.\n    \"\"\"\n    return Concatenate(axis=axis, **kwargs)(inputs)",
        "begin_line": 616,
        "end_line": 627,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002304147465437788,
            "pseudo_dstar_susp": 0.0014577259475218659,
            "pseudo_tarantula_susp": 0.003289473684210526,
            "pseudo_op2_susp": 0.0014577259475218659,
            "pseudo_barinel_susp": 0.003289473684210526
        }
    },
    {
        "name": "keras.layers.merge.dot#630",
        "src_path": "keras/layers/merge.py",
        "class_name": "keras.layers.merge",
        "signature": "keras.layers.merge.dot(inputs, axes, normalize=False, **kwargs)",
        "snippet": "def dot(inputs, axes, normalize=False, **kwargs):\n    \"\"\"Functional interface to the `Dot` layer.\n\n    # Arguments\n        inputs: A list of input tensors (at least 2).\n        axes: Integer or tuple of integers,\n            axis or axes along which to take the dot product.\n        normalize: Whether to L2-normalize samples along the\n            dot product axis before taking the dot product.\n            If set to True, then the output of the dot product\n            is the cosine proximity between the two samples.\n        **kwargs: Standard layer keyword arguments.\n\n    # Returns\n        A tensor, the dot product of the samples from the inputs.\n    \"\"\"\n    return Dot(axes=axes, normalize=normalize, **kwargs)(inputs)",
        "begin_line": 630,
        "end_line": 646,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.__init__.deserialize#37",
        "src_path": "keras/layers/__init__.py",
        "class_name": "keras.layers.__init__",
        "signature": "keras.layers.__init__.deserialize(config, custom_objects=None)",
        "snippet": "def deserialize(config, custom_objects=None):\n    \"\"\"Instantiate a layer from a config dictionary.\n\n    # Arguments\n        config: dict of the form {'class_name': str, 'config': dict}\n        custom_objects: dict mapping class names (or function names)\n            of custom (non-Keras) objects to class/functions\n\n    # Returns\n        Layer instance (may be Model, Sequential, Layer...)\n    \"\"\"\n    from .. import models\n    globs = globals()  # All layers.\n    globs['Model'] = models.Model\n    globs['Sequential'] = models.Sequential\n    return deserialize_keras_object(config,\n                                    module_objects=globs,\n                                    custom_objects=custom_objects,\n                                    printable_module_name='layer')",
        "begin_line": 37,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007836990595611285,
            "pseudo_dstar_susp": 0.0007733952049497294,
            "pseudo_tarantula_susp": 0.0007886435331230284,
            "pseudo_op2_susp": 0.0007733952049497294,
            "pseudo_barinel_susp": 0.0007886435331230284
        }
    },
    {
        "name": "keras.initializers.Initializer.get_config#16",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Initializer",
        "signature": "keras.initializers.Initializer.get_config(self)",
        "snippet": "    def get_config(self):\n        return {}",
        "begin_line": 16,
        "end_line": 17,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008865248226950354,
            "pseudo_dstar_susp": 0.0008733624454148472,
            "pseudo_tarantula_susp": 0.0009823182711198428,
            "pseudo_op2_susp": 0.0008733624454148472,
            "pseudo_barinel_susp": 0.0009823182711198428
        }
    },
    {
        "name": "keras.initializers.Initializer.from_config#20",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Initializer",
        "signature": "keras.initializers.Initializer.from_config(cls, config)",
        "snippet": "    def from_config(cls, config):\n        if 'dtype' in config:\n            # Initializers saved from `tf.keras`\n            # may contain an unused `dtype` argument.\n            config.pop('dtype')\n        return cls(**config)",
        "begin_line": 20,
        "end_line": 25,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0014771048744460858,
            "pseudo_dstar_susp": 0.006802721088435374,
            "pseudo_tarantula_susp": 0.0010319917440660474,
            "pseudo_op2_susp": 0.006802721088435374,
            "pseudo_barinel_susp": 0.0010319917440660474
        }
    },
    {
        "name": "keras.initializers.Zeros.__call__#32",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Zeros",
        "signature": "keras.initializers.Zeros.__call__(self, shape, dtype=None)",
        "snippet": "    def __call__(self, shape, dtype=None):\n        return K.constant(0, shape=shape, dtype=dtype)",
        "begin_line": 32,
        "end_line": 33,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0017421602787456446,
            "pseudo_dstar_susp": 0.012658227848101266,
            "pseudo_tarantula_susp": 0.0011160714285714285,
            "pseudo_op2_susp": 0.012658227848101266,
            "pseudo_barinel_susp": 0.0011160714285714285
        }
    },
    {
        "name": "keras.initializers.Ones.__call__#40",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Ones",
        "signature": "keras.initializers.Ones.__call__(self, shape, dtype=None)",
        "snippet": "    def __call__(self, shape, dtype=None):\n        return K.constant(1, shape=shape, dtype=dtype)",
        "begin_line": 40,
        "end_line": 41,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009090909090909091,
            "pseudo_dstar_susp": 0.0008920606601248885,
            "pseudo_tarantula_susp": 0.0011210762331838565,
            "pseudo_op2_susp": 0.0008920606601248885,
            "pseudo_barinel_susp": 0.0011210762331838565
        }
    },
    {
        "name": "keras.initializers.Constant.__init__#51",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Constant",
        "signature": "keras.initializers.Constant.__init__(self, value=0)",
        "snippet": "    def __init__(self, value=0):\n        self.value = value",
        "begin_line": 51,
        "end_line": 52,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.initializers.Constant.__call__#54",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Constant",
        "signature": "keras.initializers.Constant.__call__(self, shape, dtype=None)",
        "snippet": "    def __call__(self, shape, dtype=None):\n        return K.constant(self.value, shape=shape, dtype=dtype)",
        "begin_line": 54,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.initializers.RandomNormal.__init__#72",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.RandomNormal",
        "signature": "keras.initializers.RandomNormal.__init__(self, mean=0.0, stddev=0.05, seed=None)",
        "snippet": "    def __init__(self, mean=0., stddev=0.05, seed=None):\n        self.mean = mean\n        self.stddev = stddev\n        self.seed = seed",
        "begin_line": 72,
        "end_line": 75,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010733068584308254,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.initializers.RandomNormal.__call__#77",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.RandomNormal",
        "signature": "keras.initializers.RandomNormal.__call__(self, shape, dtype=None)",
        "snippet": "    def __call__(self, shape, dtype=None):\n        return K.random_normal(shape, self.mean, self.stddev,\n                               dtype=dtype, seed=self.seed)",
        "begin_line": 77,
        "end_line": 79,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.initializers.RandomNormal.get_config#81",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.RandomNormal",
        "signature": "keras.initializers.RandomNormal.get_config(self)",
        "snippet": "    def get_config(self):\n        return {\n            'mean': self.mean,\n            'stddev': self.stddev,\n            'seed': self.seed\n        }",
        "begin_line": 81,
        "end_line": 86,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010882576994232234,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.initializers.RandomUniform.__init__#100",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.RandomUniform",
        "signature": "keras.initializers.RandomUniform.__init__(self, minval=-0.05, maxval=0.05, seed=None)",
        "snippet": "    def __init__(self, minval=-0.05, maxval=0.05, seed=None):\n        self.minval = minval\n        self.maxval = maxval\n        self.seed = seed",
        "begin_line": 100,
        "end_line": 103,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010299721907508497,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.initializers.RandomUniform.__call__#105",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.RandomUniform",
        "signature": "keras.initializers.RandomUniform.__call__(self, shape, dtype=None)",
        "snippet": "    def __call__(self, shape, dtype=None):\n        return K.random_uniform(shape, self.minval, self.maxval,\n                                dtype=dtype, seed=self.seed)",
        "begin_line": 105,
        "end_line": 107,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010520778537611783,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.initializers.RandomUniform.get_config#109",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.RandomUniform",
        "signature": "keras.initializers.RandomUniform.get_config(self)",
        "snippet": "    def get_config(self):\n        return {\n            'minval': self.minval,\n            'maxval': self.maxval,\n            'seed': self.seed,\n        }",
        "begin_line": 109,
        "end_line": 114,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00012818869375721061,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.initializers.TruncatedNormal.__init__#133",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.TruncatedNormal",
        "signature": "keras.initializers.TruncatedNormal.__init__(self, mean=0.0, stddev=0.05, seed=None)",
        "snippet": "    def __init__(self, mean=0., stddev=0.05, seed=None):\n        self.mean = mean\n        self.stddev = stddev\n        self.seed = seed",
        "begin_line": 133,
        "end_line": 136,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.initializers.TruncatedNormal.__call__#138",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.TruncatedNormal",
        "signature": "keras.initializers.TruncatedNormal.__call__(self, shape, dtype=None)",
        "snippet": "    def __call__(self, shape, dtype=None):\n        return K.truncated_normal(shape, self.mean, self.stddev,\n                                  dtype=dtype, seed=self.seed)",
        "begin_line": 138,
        "end_line": 140,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.initializers.VarianceScaling.__init__#175",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.VarianceScaling",
        "signature": "keras.initializers.VarianceScaling.__init__(self, scale=1.0, mode='fan_in', distribution='normal', seed=None)",
        "snippet": "    def __init__(self, scale=1.0,\n                 mode='fan_in',\n                 distribution='normal',\n                 seed=None):\n        if scale <= 0.:\n            raise ValueError('`scale` must be a positive float. Got:', scale)\n        mode = mode.lower()\n        if mode not in {'fan_in', 'fan_out', 'fan_avg'}:\n            raise ValueError('Invalid `mode` argument: '\n                             'expected on of {\"fan_in\", \"fan_out\", \"fan_avg\"} '\n                             'but got', mode)\n        distribution = distribution.lower()\n        if distribution not in {'normal', 'uniform'}:\n            raise ValueError('Invalid `distribution` argument: '\n                             'expected one of {\"normal\", \"uniform\"} '\n                             'but got', distribution)\n        self.scale = scale\n        self.mode = mode\n        self.distribution = distribution\n        self.seed = seed",
        "begin_line": 175,
        "end_line": 194,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0015128593040847202,
            "pseudo_dstar_susp": 0.007633587786259542,
            "pseudo_tarantula_susp": 0.001049317943336831,
            "pseudo_op2_susp": 0.007633587786259542,
            "pseudo_barinel_susp": 0.001049317943336831
        }
    },
    {
        "name": "keras.initializers.VarianceScaling.__call__#196",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.VarianceScaling",
        "signature": "keras.initializers.VarianceScaling.__call__(self, shape, dtype=None)",
        "snippet": "    def __call__(self, shape, dtype=None):\n        fan_in, fan_out = _compute_fans(shape)\n        scale = self.scale\n        if self.mode == 'fan_in':\n            scale /= max(1., fan_in)\n        elif self.mode == 'fan_out':\n            scale /= max(1., fan_out)\n        else:\n            scale /= max(1., float(fan_in + fan_out) / 2)\n        if self.distribution == 'normal':\n            stddev = np.sqrt(scale)\n            return K.truncated_normal(shape, 0., stddev,\n                                      dtype=dtype, seed=self.seed)\n        else:\n            limit = np.sqrt(3. * scale)\n            return K.random_uniform(shape, -limit, limit,\n                                    dtype=dtype, seed=self.seed)",
        "begin_line": 196,
        "end_line": 212,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0018656716417910447,
            "pseudo_dstar_susp": 0.0136986301369863,
            "pseudo_tarantula_susp": 0.0011312217194570137,
            "pseudo_op2_susp": 0.0136986301369863,
            "pseudo_barinel_susp": 0.0011312217194570137
        }
    },
    {
        "name": "keras.initializers.VarianceScaling.get_config#214",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.VarianceScaling",
        "signature": "keras.initializers.VarianceScaling.get_config(self)",
        "snippet": "    def get_config(self):\n        return {\n            'scale': self.scale,\n            'mode': self.mode,\n            'distribution': self.distribution,\n            'seed': self.seed\n        }",
        "begin_line": 214,
        "end_line": 220,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008920606601248885,
            "pseudo_dstar_susp": 0.0008771929824561404,
            "pseudo_tarantula_susp": 0.001001001001001001,
            "pseudo_op2_susp": 0.0008771929824561404,
            "pseudo_barinel_susp": 0.001001001001001001
        }
    },
    {
        "name": "keras.initializers.Orthogonal.__init__#234",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Orthogonal",
        "signature": "keras.initializers.Orthogonal.__init__(self, gain=1.0, seed=None)",
        "snippet": "    def __init__(self, gain=1., seed=None):\n        self.gain = gain\n        self.seed = seed",
        "begin_line": 234,
        "end_line": 236,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0024752475247524753,
            "pseudo_dstar_susp": 0.003115264797507788,
            "pseudo_tarantula_susp": 0.001303780964797914,
            "pseudo_op2_susp": 0.003115264797507788,
            "pseudo_barinel_susp": 0.001303780964797914
        }
    },
    {
        "name": "keras.initializers.Orthogonal.__call__#238",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Orthogonal",
        "signature": "keras.initializers.Orthogonal.__call__(self, shape, dtype=None)",
        "snippet": "    def __call__(self, shape, dtype=None):\n        num_rows = 1\n        for dim in shape[:-1]:\n            num_rows *= dim\n        num_cols = shape[-1]\n        flat_shape = (num_rows, num_cols)\n        if self.seed is not None:\n            np.random.seed(self.seed)\n        a = np.random.normal(0.0, 1.0, flat_shape)\n        u, _, v = np.linalg.svd(a, full_matrices=False)\n        # Pick the one with the correct shape.\n        q = u if u.shape == flat_shape else v\n        q = q.reshape(shape)\n        return self.gain * q[:shape[0], :shape[1]]",
        "begin_line": 238,
        "end_line": 251,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0026595744680851063,
            "pseudo_dstar_susp": 0.0033444816053511705,
            "pseudo_tarantula_susp": 0.0015015015015015015,
            "pseudo_op2_susp": 0.0033444816053511705,
            "pseudo_barinel_susp": 0.0015015015015015015
        }
    },
    {
        "name": "keras.initializers.Orthogonal.get_config#253",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Orthogonal",
        "signature": "keras.initializers.Orthogonal.get_config(self)",
        "snippet": "    def get_config(self):\n        return {\n            'gain': self.gain,\n            'seed': self.seed\n        }",
        "begin_line": 253,
        "end_line": 257,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001026694045174538,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.initializers.Identity.__init__#269",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Identity",
        "signature": "keras.initializers.Identity.__init__(self, gain=1.0)",
        "snippet": "    def __init__(self, gain=1.):\n        self.gain = gain",
        "begin_line": 269,
        "end_line": 270,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.initializers.Identity.__call__#272",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Identity",
        "signature": "keras.initializers.Identity.__call__(self, shape, dtype=None)",
        "snippet": "    def __call__(self, shape, dtype=None):\n        if len(shape) != 2 or shape[0] != shape[1]:\n            raise ValueError('Identity matrix initializer can only be used '\n                             'for 2D square matrices.')\n        else:\n            return self.gain * np.identity(shape[0])",
        "begin_line": 272,
        "end_line": 277,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.initializers.lecun_uniform#285",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers",
        "signature": "keras.initializers.lecun_uniform(seed=None)",
        "snippet": "def lecun_uniform(seed=None):\n    \"\"\"LeCun uniform initializer.\n\n    It draws samples from a uniform distribution within [-limit, limit]\n    where `limit` is `sqrt(3 / fan_in)`\n    where `fan_in` is the number of input units in the weight tensor.\n\n    # Arguments\n        seed: A Python integer. Used to seed the random generator.\n\n    # Returns\n        An initializer.\n\n    # References\n        LeCun 98, Efficient Backprop,\n        http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf\n    \"\"\"\n    return VarianceScaling(scale=1.,\n                           mode='fan_in',\n                           distribution='uniform',\n                           seed=seed)",
        "begin_line": 285,
        "end_line": 305,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.initializers.glorot_normal#308",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers",
        "signature": "keras.initializers.glorot_normal(seed=None)",
        "snippet": "def glorot_normal(seed=None):\n    \"\"\"Glorot normal initializer, also called Xavier normal initializer.\n\n    It draws samples from a truncated normal distribution centered on 0\n    with `stddev = sqrt(2 / (fan_in + fan_out))`\n    where `fan_in` is the number of input units in the weight tensor\n    and `fan_out` is the number of output units in the weight tensor.\n\n    # Arguments\n        seed: A Python integer. Used to seed the random generator.\n\n    # Returns\n        An initializer.\n\n    # References\n        Glorot & Bengio, AISTATS 2010\n        http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf\n    \"\"\"\n    return VarianceScaling(scale=1.,\n                           mode='fan_avg',\n                           distribution='normal',\n                           seed=seed)",
        "begin_line": 308,
        "end_line": 329,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.initializers.glorot_uniform#332",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers",
        "signature": "keras.initializers.glorot_uniform(seed=None)",
        "snippet": "def glorot_uniform(seed=None):\n    \"\"\"Glorot uniform initializer, also called Xavier uniform initializer.\n\n    It draws samples from a uniform distribution within [-limit, limit]\n    where `limit` is `sqrt(6 / (fan_in + fan_out))`\n    where `fan_in` is the number of input units in the weight tensor\n    and `fan_out` is the number of output units in the weight tensor.\n\n    # Arguments\n        seed: A Python integer. Used to seed the random generator.\n\n    # Returns\n        An initializer.\n\n    # References\n        Glorot & Bengio, AISTATS 2010\n        http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf\n    \"\"\"\n    return VarianceScaling(scale=1.,\n                           mode='fan_avg',\n                           distribution='uniform',\n                           seed=seed)",
        "begin_line": 332,
        "end_line": 353,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0017035775127768314,
            "pseudo_dstar_susp": 0.010869565217391304,
            "pseudo_tarantula_susp": 0.0011001100110011,
            "pseudo_op2_susp": 0.010869565217391304,
            "pseudo_barinel_susp": 0.0011001100110011
        }
    },
    {
        "name": "keras.initializers.he_normal#356",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers",
        "signature": "keras.initializers.he_normal(seed=None)",
        "snippet": "def he_normal(seed=None):\n    \"\"\"He normal initializer.\n\n    It draws samples from a truncated normal distribution centered on 0\n    with `stddev = sqrt(2 / fan_in)`\n    where `fan_in` is the number of input units in the weight tensor.\n\n    # Arguments\n        seed: A Python integer. Used to seed the random generator.\n\n    # Returns\n        An initializer.\n\n    # References\n        He et al., http://arxiv.org/abs/1502.01852\n    \"\"\"\n    return VarianceScaling(scale=2.,\n                           mode='fan_in',\n                           distribution='normal',\n                           seed=seed)",
        "begin_line": 356,
        "end_line": 375,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.initializers.lecun_normal#378",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers",
        "signature": "keras.initializers.lecun_normal(seed=None)",
        "snippet": "def lecun_normal(seed=None):\n    \"\"\"LeCun normal initializer.\n\n    It draws samples from a truncated normal distribution centered on 0\n    with `stddev = sqrt(1 / fan_in)`\n    where `fan_in` is the number of input units in the weight tensor.\n\n    # Arguments\n        seed: A Python integer. Used to seed the random generator.\n\n    # Returns\n        An initializer.\n\n    # References\n        - [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)\n        - [Efficient Backprop](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf)\n    \"\"\"\n    return VarianceScaling(scale=1.,\n                           mode='fan_in',\n                           distribution='normal',\n                           seed=seed)",
        "begin_line": 378,
        "end_line": 398,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.initializers.he_uniform#401",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers",
        "signature": "keras.initializers.he_uniform(seed=None)",
        "snippet": "def he_uniform(seed=None):\n    \"\"\"He uniform variance scaling initializer.\n\n    It draws samples from a uniform distribution within [-limit, limit]\n    where `limit` is `sqrt(6 / fan_in)`\n    where `fan_in` is the number of input units in the weight tensor.\n\n    # Arguments\n        seed: A Python integer. Used to seed the random generator.\n\n    # Returns\n        An initializer.\n\n    # References\n        He et al., http://arxiv.org/abs/1502.01852\n    \"\"\"\n    return VarianceScaling(scale=2.,\n                           mode='fan_in',\n                           distribution='uniform',\n                           seed=seed)",
        "begin_line": 401,
        "end_line": 420,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.initializers._compute_fans#437",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers",
        "signature": "keras.initializers._compute_fans(shape, data_format='channels_last')",
        "snippet": "def _compute_fans(shape, data_format='channels_last'):\n    \"\"\"Computes the number of input and output units for a weight shape.\n\n    # Arguments\n        shape: Integer shape tuple.\n        data_format: Image data format to use for convolution kernels.\n            Note that all kernels in Keras are standardized on the\n            `channels_last` ordering (even when inputs are set\n            to `channels_first`).\n\n    # Returns\n        A tuple of scalars, `(fan_in, fan_out)`.\n\n    # Raises\n        ValueError: in case of invalid `data_format` argument.\n    \"\"\"\n    if len(shape) == 2:\n        fan_in = shape[0]\n        fan_out = shape[1]\n    elif len(shape) in {3, 4, 5}:\n        # Assuming convolution kernels (1D, 2D or 3D).\n        # TH kernel shape: (depth, input_depth, ...)\n        # TF kernel shape: (..., input_depth, depth)\n        if data_format == 'channels_first':\n            receptive_field_size = np.prod(shape[2:])\n            fan_in = shape[1] * receptive_field_size\n            fan_out = shape[0] * receptive_field_size\n        elif data_format == 'channels_last':\n            receptive_field_size = np.prod(shape[:-2])\n            fan_in = shape[-2] * receptive_field_size\n            fan_out = shape[-1] * receptive_field_size\n        else:\n            raise ValueError('Invalid data_format: ' + data_format)\n    else:\n        # No specific assumptions.\n        fan_in = np.sqrt(np.prod(shape))\n        fan_out = np.sqrt(np.prod(shape))\n    return fan_in, fan_out",
        "begin_line": 437,
        "end_line": 474,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0019193857965451055,
            "pseudo_dstar_susp": 0.014925373134328358,
            "pseudo_tarantula_susp": 0.001183431952662722,
            "pseudo_op2_susp": 0.014925373134328358,
            "pseudo_barinel_susp": 0.001183431952662722
        }
    },
    {
        "name": "keras.initializers.serialize#477",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers",
        "signature": "keras.initializers.serialize(initializer)",
        "snippet": "def serialize(initializer):\n    return serialize_keras_object(initializer)",
        "begin_line": 477,
        "end_line": 478,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007987220447284345,
            "pseudo_dstar_susp": 0.0007880220646178094,
            "pseudo_tarantula_susp": 0.0008453085376162299,
            "pseudo_op2_susp": 0.0007880220646178094,
            "pseudo_barinel_susp": 0.0008453085376162299
        }
    },
    {
        "name": "keras.initializers.deserialize#481",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers",
        "signature": "keras.initializers.deserialize(config, custom_objects=None)",
        "snippet": "def deserialize(config, custom_objects=None):\n    return deserialize_keras_object(config,\n                                    module_objects=globals(),\n                                    custom_objects=custom_objects,\n                                    printable_module_name='initializer')",
        "begin_line": 481,
        "end_line": 485,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0014771048744460858,
            "pseudo_dstar_susp": 0.006802721088435374,
            "pseudo_tarantula_susp": 0.0010319917440660474,
            "pseudo_op2_susp": 0.006802721088435374,
            "pseudo_barinel_susp": 0.0010319917440660474
        }
    },
    {
        "name": "keras.initializers.get#488",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers",
        "signature": "keras.initializers.get(identifier)",
        "snippet": "def get(identifier):\n    if isinstance(identifier, dict):\n        return deserialize(identifier)\n    elif isinstance(identifier, six.string_types):\n        config = {'class_name': str(identifier), 'config': {}}\n        return deserialize(config)\n    elif callable(identifier):\n        return identifier\n    else:\n        raise ValueError('Could not interpret initializer identifier:',\n                         identifier)",
        "begin_line": 488,
        "end_line": 498,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0017035775127768314,
            "pseudo_dstar_susp": 0.010869565217391304,
            "pseudo_tarantula_susp": 0.0011001100110011,
            "pseudo_op2_susp": 0.010869565217391304,
            "pseudo_barinel_susp": 0.0011001100110011
        }
    },
    {
        "name": "keras.engine.training._standardize_input_data#30",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training",
        "signature": "keras.engine.training._standardize_input_data(data, names, shapes=None, check_batch_axis=True, exception_prefix='')",
        "snippet": "def _standardize_input_data(data, names, shapes=None,\n                            check_batch_axis=True,\n                            exception_prefix=''):\n    \"\"\"Normalizes inputs and targets provided by users.\n\n    Users may pass data as a list of arrays, dictionary of arrays,\n    or as a single array. We normalize this to an ordered list of\n    arrays (same order as `names`), while checking that the provided\n    arrays have shapes that match the network's expectations.\n\n    # Arguments\n        data: User-provided input data (polymorphic).\n        names: List of expected array names.\n        shapes: Optional list of expected array shapes.\n        check_batch_axis: Boolean; whether to check that\n            the batch axis of the arrays matches the expected\n            value found in `shapes`.\n        exception_prefix: String prefix used for exception formatting.\n\n    # Returns\n        List of standardized input arrays (one array per model input).\n\n    # Raises\n        ValueError: in case of improperly formatted user-provided data.\n    \"\"\"\n    if not names:\n        if data is not None and hasattr(data, '__len__') and len(data):\n            raise ValueError('Error when checking model ' +\n                             exception_prefix + ': '\n                             'expected no data, but got:', data)\n        return []\n    if data is None:\n        return [None for _ in range(len(names))]\n    if isinstance(data, dict):\n        for key, value in data.items():\n            if value.__class__.__name__ == 'DataFrame':\n                data[key] = value.values\n        arrays = []\n        for name in names:\n            if name not in data:\n                raise ValueError('No data provided for \"' +\n                                 name + '\". Need data for each key in: ' +\n                                 str(names))\n            arrays.append(data[name])\n    elif isinstance(data, list):\n        for key, value in enumerate(data):\n            if value.__class__.__name__ == 'DataFrame':\n                data[key] = value.values\n        if len(data) != len(names):\n            if data and hasattr(data[0], 'shape'):\n                raise ValueError('Error when checking model ' +\n                                 exception_prefix +\n                                 ': the list of Numpy arrays '\n                                 'that you are passing to your model '\n                                 'is not the size the model expected. '\n                                 'Expected to see ' + str(len(names)) +\n                                 ' array(s), but instead got '\n                                 'the following list of ' + str(len(data)) +\n                                 ' arrays: ' + str(data)[:200] +\n                                 '...')\n            else:\n                if len(names) == 1:\n                    data = [np.asarray(data)]\n                else:\n                    raise ValueError(\n                        'Error when checking model ' +\n                        exception_prefix +\n                        ': you are passing a list as '\n                        'input to your model, '\n                        'but the model expects '\n                        'a list of ' + str(len(names)) +\n                        ' Numpy arrays instead. '\n                        'The list you passed was: ' +\n                        str(data)[:200])\n        arrays = data\n    elif data.__class__.__name__ == 'DataFrame':\n        # test if data is a DataFrame, without pandas installed\n        data = data.values\n    else:\n        if not hasattr(data, 'shape'):\n            raise TypeError('Error when checking model ' +\n                            exception_prefix +\n                            ': data should be a Numpy array, '\n                            'or list/dict of Numpy arrays. '\n                            'Found: ' + str(data)[:200] + '...')\n        if len(names) > 1:\n            # Case: model expects multiple inputs but only received\n            # a single Numpy array.\n            raise ValueError('The model expects ' + str(len(names)) + ' ' +\n                             exception_prefix +\n                             ' arrays, but only received one array. '\n                             'Found: array with shape ' + str(data.shape))\n        arrays = [data]\n\n    # Make arrays at least 2D.\n    for i in range(len(names)):\n        array = arrays[i]\n        if len(array.shape) == 1:\n            array = np.expand_dims(array, 1)\n            arrays[i] = array\n\n    # Check shapes compatibility.\n    if shapes:\n        for i in range(len(names)):\n            if shapes[i] is None:\n                continue\n            array = arrays[i]\n            if len(array.shape) != len(shapes[i]):\n                raise ValueError('Error when checking ' + exception_prefix +\n                                 ': expected ' + names[i] +\n                                 ' to have ' + str(len(shapes[i])) +\n                                 ' dimensions, but got array with shape ' +\n                                 str(array.shape))\n            for j, (dim, ref_dim) in enumerate(zip(array.shape, shapes[i])):\n                if not j and not check_batch_axis:\n                    # skip the first axis\n                    continue\n                if ref_dim:\n                    if ref_dim != dim:\n                        raise ValueError(\n                            'Error when checking ' + exception_prefix +\n                            ': expected ' + names[i] +\n                            ' to have shape ' + str(shapes[i]) +\n                            ' but got array with shape ' +\n                            str(array.shape))\n    return arrays",
        "begin_line": 30,
        "end_line": 155,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training._standardize_sample_or_class_weights#158",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training",
        "signature": "keras.engine.training._standardize_sample_or_class_weights(x_weight, output_names, weight_type)",
        "snippet": "def _standardize_sample_or_class_weights(x_weight, output_names, weight_type):\n    \"\"\"Maps `sample_weight` or `class_weight` to model outputs.\n\n    # Arguments\n        x_weight: User-provided `sample_weight` or `class_weight` argument.\n        output_names: List of output names (strings) in the model.\n        weight_type: A string used purely for exception printing.\n\n    # Returns\n        A list of `sample_weight` or `class_weight` where there are exactly\n            one element per model output.\n\n    # Raises\n        ValueError: In case of invalid user-provided argument.\n    \"\"\"\n    if x_weight is None or len(x_weight) == 0:\n        return [None for _ in output_names]\n    if len(output_names) == 1:\n        if isinstance(x_weight, list) and len(x_weight) == 1:\n            return x_weight\n        if isinstance(x_weight, dict) and output_names[0] in x_weight:\n            return [x_weight[output_names[0]]]\n        else:\n            return [x_weight]\n    if isinstance(x_weight, list):\n        if len(x_weight) != len(output_names):\n            raise ValueError('Provided `' + weight_type + '` was a list of ' +\n                             str(len(x_weight)) +\n                             ' elements, but the model has ' +\n                             str(len(output_names)) + ' outputs. '\n                             'You should provide one `' + weight_type + '`'\n                             'array per model output.')\n        return x_weight\n    if isinstance(x_weight, dict):\n        x_weights = []\n        for name in output_names:\n            x_weights.append(x_weight.get(name))\n        return x_weights\n    else:\n        raise TypeError('The model has multiple outputs, so `' +\n                        weight_type + '` '\n                        'should be either a list of a dict. '\n                        'Provided `' + weight_type +\n                        '` type not understood: ' +\n                        str(x_weight))",
        "begin_line": 158,
        "end_line": 202,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training._standardize_class_weights#205",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training",
        "signature": "keras.engine.training._standardize_class_weights(class_weight, output_names)",
        "snippet": "def _standardize_class_weights(class_weight, output_names):\n    return _standardize_sample_or_class_weights(class_weight,\n                                                output_names,\n                                                'class_weight')",
        "begin_line": 205,
        "end_line": 208,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 8.87154009936125e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training._standardize_sample_weights#211",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training",
        "signature": "keras.engine.training._standardize_sample_weights(sample_weight, output_names)",
        "snippet": "def _standardize_sample_weights(sample_weight, output_names):\n    return _standardize_sample_or_class_weights(sample_weight,\n                                                output_names,\n                                                'sample_weight')",
        "begin_line": 211,
        "end_line": 214,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 8.87154009936125e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training._check_array_lengths#217",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training",
        "signature": "keras.engine.training._check_array_lengths(inputs, targets, weights=None)",
        "snippet": "def _check_array_lengths(inputs, targets, weights=None):\n    \"\"\"Does user input validation for numpy arrays.\n\n    # Arguments\n        inputs: list of Numpy arrays of inputs.\n        targets: list of Numpy arrays of targets.\n        weights: list of Numpy arrays of sample weights.\n\n    # Raises\n        ValueError: in case of incorrectly formatted data.\n    \"\"\"\n    def set_of_lengths(x):\n        # return a set with the variation between\n        # different shapes, with None => 0\n        if x is None:\n            return {0}\n        else:\n            return set([0 if y is None else y.shape[0] for y in x])\n\n    set_x = set_of_lengths(inputs)\n    set_y = set_of_lengths(targets)\n    set_w = set_of_lengths(weights)\n    if len(set_x) > 1:\n        raise ValueError('All input arrays (x) should have '\n                         'the same number of samples. Got array shapes: ' +\n                         str([x.shape for x in inputs]))\n    if len(set_y) > 1:\n        raise ValueError('All target arrays (y) should have '\n                         'the same number of samples. Got array shapes: ' +\n                         str([y.shape for y in targets]))\n    if set_x and set_y and list(set_x)[0] != list(set_y)[0]:\n        raise ValueError('Input arrays should have '\n                         'the same number of samples as target arrays. '\n                         'Found ' + str(list(set_x)[0]) + ' input samples '\n                         'and ' + str(list(set_y)[0]) + ' target samples.')\n    if len(set_w) > 1:\n        raise ValueError('All sample_weight arrays should have '\n                         'the same number of samples. Got array shapes: ' +\n                         str([w.shape for w in weights]))\n    if set_y and set_w and list(set_y)[0] != list(set_w)[0]:\n        raise ValueError('Sample_weight arrays should have '\n                         'the same number of samples as target arrays. Got ' +\n                         str(list(set_y)[0]) + ' input samples and ' +\n                         str(list(set_w)[0]) + ' target samples.')",
        "begin_line": 217,
        "end_line": 260,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training.set_of_lengths#228",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training",
        "signature": "keras.engine.training.set_of_lengths(x)",
        "snippet": "    def set_of_lengths(x):\n        # return a set with the variation between\n        # different shapes, with None => 0\n        if x is None:\n            return {0}\n        else:\n            return set([0 if y is None else y.shape[0] for y in x])",
        "begin_line": 228,
        "end_line": 234,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training._check_loss_and_target_compatibility#263",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training",
        "signature": "keras.engine.training._check_loss_and_target_compatibility(targets, loss_fns, output_shapes)",
        "snippet": "def _check_loss_and_target_compatibility(targets, loss_fns, output_shapes):\n    \"\"\"Does validation on the compatibility of targets and loss functions.\n\n    This helps prevent users from using loss functions incorrectly.\n\n    # Arguments\n        targets: list of Numpy arrays of targets.\n        loss_fns: list of loss functions.\n        output_shapes: list of shapes of model outputs.\n\n    # Raises\n        ValueError: if a loss function or target array\n            is incompatible with an output.\n    \"\"\"\n    key_losses = {'mean_squared_error',\n                  'binary_crossentropy',\n                  'categorical_crossentropy'}\n    for y, loss, shape in zip(targets, loss_fns, output_shapes):\n        if loss is None:\n            continue\n        if loss.__name__ == 'categorical_crossentropy':\n            if y.shape[-1] == 1:\n                raise ValueError(\n                    'You are passing a target array of shape ' + str(y.shape) +\n                    ' while using as loss `categorical_crossentropy`. '\n                    '`categorical_crossentropy` expects '\n                    'targets to be binary matrices (1s and 0s) '\n                    'of shape (samples, classes). '\n                    'If your targets are integer classes, '\n                    'you can convert them to the expected format via:\\n'\n                    '```\\n'\n                    'from keras.utils.np_utils import to_categorical\\n'\n                    'y_binary = to_categorical(y_int)\\n'\n                    '```\\n'\n                    '\\n'\n                    'Alternatively, you can use the loss function '\n                    '`sparse_categorical_crossentropy` instead, '\n                    'which does expect integer targets.')\n        if loss.__name__ in key_losses:\n            for target_dim, out_dim in zip(y.shape[1:], shape[1:]):\n                if out_dim is not None and target_dim != out_dim:\n                    raise ValueError(\n                        'A target array with shape ' + str(y.shape) +\n                        ' was passed for an output of shape ' + str(shape) +\n                        ' while using as loss `' + loss.__name__ + '`. '\n                        'This loss expects '\n                        'targets to have the same shape '\n                        'as the output.')",
        "begin_line": 263,
        "end_line": 310,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training._collect_metrics#313",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training",
        "signature": "keras.engine.training._collect_metrics(metrics, output_names)",
        "snippet": "def _collect_metrics(metrics, output_names):\n    \"\"\"Maps metric functions to model outputs.\n\n    # Arguments\n        metrics: a list or dict of metric functions.\n        output_names: a list of the names (strings) of model outputs.\n\n    # Returns\n        A list (one entry per model output) of lists of metric functions.\n        For instance, if the model has 2 outputs, and for the first output\n        we want to compute \"binary_accuracy\" and \"binary_crossentropy\",\n        and just \"binary_accuracy\" for the second output,\n        the list would look like:\n            `[[binary_accuracy, binary_crossentropy], [binary_accuracy]]`\n\n    # Raises\n        TypeError: if an incorrect type is passed for the `metrics` argument.\n    \"\"\"\n    if not metrics:\n        return [[] for _ in output_names]\n    if isinstance(metrics, list):\n        # we then apply all metrics to all outputs.\n        return [copy.copy(metrics) for _ in output_names]\n    elif isinstance(metrics, dict):\n        nested_metrics = []\n        for name in output_names:\n            output_metrics = metrics.get(name, [])\n            if not isinstance(output_metrics, list):\n                output_metrics = [output_metrics]\n            nested_metrics.append(output_metrics)\n        return nested_metrics\n    else:\n        raise TypeError('Type of `metrics` argument not understood. '\n                        'Expected a list or dictionary, found: ' +\n                        str(metrics))",
        "begin_line": 313,
        "end_line": 347,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training._batch_shuffle#350",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training",
        "signature": "keras.engine.training._batch_shuffle(index_array, batch_size)",
        "snippet": "def _batch_shuffle(index_array, batch_size):\n    \"\"\"Shuffles an array in a batch-wise fashion.\n\n    Useful for shuffling HDF5 arrays\n    (where one cannot access arbitrary indices).\n\n    # Arguments\n        index_array: array of indices to be shuffled.\n        batch_size: integer.\n\n    # Returns\n        The `index_array` array, shuffled in a batch-wise fashion.\n    \"\"\"\n    batch_count = int(len(index_array) / batch_size)\n    # to reshape we need to be cleanly divisible by batch size\n    # we stash extra items and reappend them after shuffling\n    last_batch = index_array[batch_count * batch_size:]\n    index_array = index_array[:batch_count * batch_size]\n    index_array = index_array.reshape((batch_count, batch_size))\n    np.random.shuffle(index_array)\n    index_array = index_array.flatten()\n    return np.append(index_array, last_batch)",
        "begin_line": 350,
        "end_line": 371,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training._make_batches#374",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training",
        "signature": "keras.engine.training._make_batches(size, batch_size)",
        "snippet": "def _make_batches(size, batch_size):\n    \"\"\"Returns a list of batch indices (tuples of indices).\n\n    # Arguments\n        size: Integer, total size of the data to slice into batches.\n        batch_size: Integer, batch size.\n\n    # Returns\n        A list of tuples of array indices.\n    \"\"\"\n    num_batches = int(np.ceil(size / float(batch_size)))\n    return [(i * batch_size, min(size, (i + 1) * batch_size))\n            for i in range(num_batches)]",
        "begin_line": 374,
        "end_line": 386,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 8.87154009936125e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training._slice_arrays#389",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training",
        "signature": "keras.engine.training._slice_arrays(arrays, start=None, stop=None)",
        "snippet": "def _slice_arrays(arrays, start=None, stop=None):\n    \"\"\"Slice an array or list of arrays.\n\n    This takes an array-like, or a list of\n    array-likes, and outputs:\n        - arrays[start:stop] if `arrays` is an array-like\n        - [x[start:stop] for x in arrays] if `arrays` is a list\n\n    Can also work on list/array of indices: `_slice_arrays(x, indices)`\n\n    # Arguments\n        arrays: Single array or list of arrays.\n        start: can be an integer index (start index)\n            or a list/array of indices\n        stop: integer (stop index); should be None if\n            `start` was a list.\n\n    # Returns\n        A slice of the array(s).\n    \"\"\"\n    if arrays is None:\n        return [None]\n    elif isinstance(arrays, list):\n        if hasattr(start, '__len__'):\n            # hdf5 datasets only support list objects as indices\n            if hasattr(start, 'shape'):\n                start = start.tolist()\n            return [None if x is None else x[start] for x in arrays]\n        else:\n            return [None if x is None else x[start:stop] for x in arrays]\n    else:\n        if hasattr(start, '__len__'):\n            if hasattr(start, 'shape'):\n                start = start.tolist()\n            return arrays[start]\n        elif hasattr(start, '__getitem__'):\n            return arrays[start:stop]\n        else:\n            return [None]",
        "begin_line": 389,
        "end_line": 427,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training._weighted_masked_objective#430",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training",
        "signature": "keras.engine.training._weighted_masked_objective(fn)",
        "snippet": "def _weighted_masked_objective(fn):\n    \"\"\"Adds support for masking and sample-weighting to an objective function.\n\n    It transforms an objective function `fn(y_true, y_pred)`\n    into a sample-weighted, cost-masked objective function\n    `fn(y_true, y_pred, weights, mask)`.\n\n    # Arguments\n        fn: The objective function to wrap,\n            with signature `fn(y_true, y_pred)`.\n\n    # Returns\n        A function with signature `fn(y_true, y_pred, weights, mask)`.\n    \"\"\"\n    if fn is None:\n        return None\n\n    def weighted(y_true, y_pred, weights, mask=None):\n        \"\"\"Wrapper function.\n\n        # Arguments\n            y_true: `y_true` argument of `fn`.\n            y_pred: `y_pred` argument of `fn`.\n            weights: Weights tensor.\n            mask: Mask tensor.\n\n        # Returns\n            Scalar tensor.\n        \"\"\"\n        # score_array has ndim >= 2\n        score_array = fn(y_true, y_pred)\n        if mask is not None:\n            # Cast the mask to floatX to avoid float64 upcasting in theano\n            mask = K.cast(mask, K.floatx())\n            # mask should have the same shape as score_array\n            score_array *= mask\n            #  the loss per batch should be proportional\n            #  to the number of unmasked samples.\n            score_array /= K.mean(mask)\n\n        # apply sample weighting\n        if weights is not None:\n            # reduce score_array to same ndim as weight array\n            ndim = K.ndim(score_array)\n            weight_ndim = K.ndim(weights)\n            score_array = K.mean(score_array, axis=list(range(weight_ndim, ndim)))\n            score_array *= weights\n            score_array /= K.mean(K.cast(K.not_equal(weights, 0), K.floatx()))\n        return K.mean(score_array)\n    return weighted",
        "begin_line": 430,
        "end_line": 479,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training.weighted#447",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training",
        "signature": "keras.engine.training.weighted(y_true, y_pred, weights, mask=None)",
        "snippet": "    def weighted(y_true, y_pred, weights, mask=None):\n        \"\"\"Wrapper function.\n\n        # Arguments\n            y_true: `y_true` argument of `fn`.\n            y_pred: `y_pred` argument of `fn`.\n            weights: Weights tensor.\n            mask: Mask tensor.\n\n        # Returns\n            Scalar tensor.\n        \"\"\"\n        # score_array has ndim >= 2\n        score_array = fn(y_true, y_pred)\n        if mask is not None:\n            # Cast the mask to floatX to avoid float64 upcasting in theano\n            mask = K.cast(mask, K.floatx())\n            # mask should have the same shape as score_array\n            score_array *= mask\n            #  the loss per batch should be proportional\n            #  to the number of unmasked samples.\n            score_array /= K.mean(mask)\n\n        # apply sample weighting\n        if weights is not None:\n            # reduce score_array to same ndim as weight array\n            ndim = K.ndim(score_array)\n            weight_ndim = K.ndim(weights)\n            score_array = K.mean(score_array, axis=list(range(weight_ndim, ndim)))\n            score_array *= weights\n            score_array /= K.mean(K.cast(K.not_equal(weights, 0), K.floatx()))\n        return K.mean(score_array)",
        "begin_line": 447,
        "end_line": 478,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011301989150090416,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training._standardize_weights#482",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training",
        "signature": "keras.engine.training._standardize_weights(y, sample_weight=None, class_weight=None, sample_weight_mode=None)",
        "snippet": "def _standardize_weights(y, sample_weight=None, class_weight=None,\n                         sample_weight_mode=None):\n    \"\"\"Performs sample weight validation and standardization.\n\n    Everything gets normalized to a single sample-wise (or timestep-wise)\n    weight array.\n\n    # Arguments\n        y: Numpy array of model targets to be weighted.\n        sample_weight: User-provided `sample_weight` argument.\n        class_weight: User-provided `class_weight` argument.\n        sample_weight_mode: One of `None` or `\"temporal\"`.\n            `\"temporal\"` indicated that we expect 2D weight data\n            that will be applied to the last 2 dimensions of\n            the targets (i.e. we are weighting timesteps, not samples).\n\n    # Returns\n        A numpy array of target weights, one entry per sample to weight.\n\n    # Raises\n        ValueError: In case of invalid user-provided arguments.\n    \"\"\"\n    if sample_weight_mode is not None:\n        if sample_weight_mode != 'temporal':\n            raise ValueError('\"sample_weight_mode '\n                             'should be None or \"temporal\". '\n                             'Found: ' + str(sample_weight_mode))\n        if len(y.shape) < 3:\n            raise ValueError('Found a sample_weight array for '\n                             'an input with shape ' +\n                             str(y.shape) + '. '\n                             'Timestep-wise sample weighting (use of '\n                             'sample_weight_mode=\"temporal\") is restricted to '\n                             'outputs that are at least 3D, i.e. that have '\n                             'a time dimension.')\n        if sample_weight is not None and len(sample_weight.shape) != 2:\n            raise ValueError('Found a sample_weight array with shape ' +\n                             str(sample_weight.shape) + '. '\n                             'In order to use timestep-wise sample weighting, '\n                             'you should pass a 2D sample_weight array.')\n    else:\n        if sample_weight is not None and len(sample_weight.shape) != 1:\n            raise ValueError('Found a sample_weight array with shape ' +\n                             str(sample_weight.shape) + '. '\n                             'In order to use timestep-wise sample weights, '\n                             'you should specify '\n                             'sample_weight_mode=\"temporal\" '\n                             'in compile(). If you just mean to use '\n                             'sample-wise weights, make sure your '\n                             'sample_weight array is 1D.')\n\n    if sample_weight is not None:\n        if len(sample_weight.shape) > len(y.shape):\n            raise ValueError('Found a sample_weight with shape' +\n                             str(sample_weight.shape) + '.'\n                             'Expected sample_weight with rank '\n                             'less than or equal to ' + str(len(y.shape)))\n\n        if y.shape[:sample_weight.ndim] != sample_weight.shape:\n            raise ValueError('Found a sample_weight array with shape ' +\n                             str(sample_weight.shape) + ' for an input with shape ' +\n                             str(y.shape) + '. '\n                             'sample_weight cannot be broadcast.')\n        return sample_weight\n    elif isinstance(class_weight, dict):\n        if len(y.shape) > 2:\n            raise ValueError('`class_weight` not supported for '\n                             '3+ dimensional targets.')\n        if y.shape[1] > 1:\n            y_classes = y.argmax(axis=1)\n        elif y.shape[1] == 1:\n            y_classes = np.reshape(y, y.shape[0])\n        else:\n            y_classes = y\n\n        weights = np.asarray([class_weight[cls] for cls in y_classes\n                              if cls in class_weight])\n\n        if len(weights) != len(y_classes):\n            # subtract the sets to pick all missing classes\n            existing_classes = set(y_classes)\n            existing_class_weight = set(class_weight.keys())\n            raise ValueError('`class_weight` must contain all classes in the data.'\n                             ' The classes %s exist in the data but not in '\n                             '`class_weight`.'\n                             % (existing_classes - existing_class_weight))\n        return weights\n    else:\n        if sample_weight_mode is None:\n            return np.ones((y.shape[0],), dtype=K.floatx())\n        else:\n            return np.ones((y.shape[0], y.shape[1]), dtype=K.floatx())",
        "begin_line": 482,
        "end_line": 573,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training.Model.compile#580",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model.compile(self, optimizer, loss, metrics=None, loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None, **kwargs)",
        "snippet": "    def compile(self, optimizer, loss, metrics=None, loss_weights=None,\n                sample_weight_mode=None, weighted_metrics=None,\n                target_tensors=None, **kwargs):\n        \"\"\"Configures the model for training.\n\n        # Arguments\n            optimizer: String (name of optimizer) or optimizer object.\n                See [optimizers](/optimizers).\n            loss: String (name of objective function) or objective function.\n                See [losses](/losses).\n                If the model has multiple outputs, you can use a different loss\n                on each output by passing a dictionary or a list of losses.\n                The loss value that will be minimized by the model\n                will then be the sum of all individual losses.\n            metrics: List of metrics to be evaluated by the model\n                during training and testing.\n                Typically you will use `metrics=['accuracy']`.\n                To specify different metrics for different outputs of a\n                multi-output model, you could also pass a dictionary,\n                such as `metrics={'output_a': 'accuracy'}`.\n            loss_weights: Optional list or dictionary specifying scalar\n                coefficients (Python floats) to weight the loss contributions\n                of different model outputs.\n                The loss value that will be minimized by the model\n                will then be the *weighted sum* of all individual losses,\n                weighted by the `loss_weights` coefficients.\n                If a list, it is expected to have a 1:1 mapping\n                to the model's outputs. If a tensor, it is expected to map\n                output names (strings) to scalar coefficients.\n            sample_weight_mode: If you need to do timestep-wise\n                sample weighting (2D weights), set this to `\"temporal\"`.\n                `None` defaults to sample-wise weights (1D).\n                If the model has multiple outputs, you can use a different\n                `sample_weight_mode` on each output by passing a\n                dictionary or a list of modes.\n            weighted_metrics: List of metrics to be evaluated and weighted\n                by sample_weight or class_weight during training and testing.\n            target_tensors: By default, Keras will create placeholders for the\n                model's target, which will be fed with the target data during\n                training. If instead you would like to use your own\n                target tensors (in turn, Keras will not expect external\n                Numpy data for these targets at training time), you\n                can specify them via the `target_tensors` argument. It can be\n                a single tensor (for a single-output model), a list of tensors,\n                or a dict mapping output names to target tensors.\n            **kwargs: When using the Theano/CNTK backends, these arguments\n                are passed into K.function. When using the TensorFlow backend,\n                these arguments are passed into `tf.Session.run`.\n\n        # Raises\n            ValueError: In case of invalid arguments for\n                `optimizer`, `loss`, `metrics` or `sample_weight_mode`.\n        \"\"\"\n        loss = loss or {}\n        self.optimizer = optimizers.get(optimizer)\n        self.loss = loss\n        self.loss_weights = loss_weights\n        self.sample_weight_mode = sample_weight_mode\n\n        # Prepare loss functions.\n        if isinstance(loss, dict):\n            for name in loss:\n                if name not in self.output_names:\n                    raise ValueError('Unknown entry in loss '\n                                     'dictionary: \"' + name + '\". '\n                                     'Only expected the following keys: ' +\n                                     str(self.output_names))\n            loss_functions = []\n            for name in self.output_names:\n                if name not in loss:\n                    warnings.warn('Output \"' + name +\n                                  '\" missing from loss dictionary. '\n                                  'We assume this was done on purpose, '\n                                  'and we will not be expecting '\n                                  'any data to be passed to \"' + name +\n                                  '\" during training.', stacklevel=2)\n                loss_functions.append(losses.get(loss.get(name)))\n        elif isinstance(loss, list):\n            if len(loss) != len(self.outputs):\n                raise ValueError('When passing a list as loss, '\n                                 'it should have one entry per model outputs. '\n                                 'The model has ' + str(len(self.outputs)) +\n                                 ' outputs, but you passed loss=' +\n                                 str(loss))\n            loss_functions = [losses.get(l) for l in loss]\n        else:\n            loss_function = losses.get(loss)\n            loss_functions = [loss_function for _ in range(len(self.outputs))]\n        self.loss_functions = loss_functions\n        weighted_losses = [_weighted_masked_objective(fn) for fn in loss_functions]\n        skip_target_indices = []\n        skip_target_weighing_indices = []\n        self._feed_outputs = []\n        self._feed_output_names = []\n        self._feed_output_shapes = []\n        self._feed_loss_fns = []\n        for i in range(len(weighted_losses)):\n            if weighted_losses[i] is None:\n                skip_target_indices.append(i)\n                skip_target_weighing_indices.append(i)\n\n        # Prepare output masks.\n        masks = self.compute_mask(self.inputs, mask=None)\n        if masks is None:\n            masks = [None for _ in self.outputs]\n        if not isinstance(masks, list):\n            masks = [masks]\n\n        # Prepare loss weights.\n        if loss_weights is None:\n            loss_weights_list = [1. for _ in range(len(self.outputs))]\n        elif isinstance(loss_weights, dict):\n            for name in loss_weights:\n                if name not in self.output_names:\n                    raise ValueError('Unknown entry in loss_weights '\n                                     'dictionary: \"' + name + '\". '\n                                     'Only expected the following keys: ' +\n                                     str(self.output_names))\n            loss_weights_list = []\n            for name in self.output_names:\n                loss_weights_list.append(loss_weights.get(name, 1.))\n        elif isinstance(loss_weights, list):\n            if len(loss_weights) != len(self.outputs):\n                raise ValueError('When passing a list as loss_weights, '\n                                 'it should have one entry per model outputs. '\n                                 'The model has ' + str(len(self.outputs)) +\n                                 ' outputs, but you passed loss_weights=' +\n                                 str(loss_weights))\n            loss_weights_list = loss_weights\n        else:\n            raise TypeError('Could not interpret loss_weights argument: ' +\n                            str(loss_weights) +\n                            ' - expected a list of dicts.')\n\n        # Prepare targets of model.\n        self.targets = []\n        self._feed_targets = []\n        if target_tensors is not None:\n            if isinstance(target_tensors, list):\n                if len(target_tensors) != len(self.outputs):\n                    raise ValueError(\n                        'When passing a list as `target_tensors`, '\n                        'it should have one entry per model outputs. '\n                        'The model has ' + str(len(self.outputs)) +\n                        ' outputs, but you passed target_tensors=' +\n                        str(target_tensors))\n            elif isinstance(target_tensors, dict):\n                for name in target_tensors:\n                    if name not in self.output_names:\n                        raise ValueError('Unknown entry in `target_tensors` '\n                                         'dictionary: \"' + name + '\". '\n                                         'Only expected the following keys: ' +\n                                         str(self.output_names))\n                _target_tensors = []\n                for name in self.output_names:\n                    _target_tensors.append(target_tensors.get(name, None))\n                target_tensors = _target_tensors\n            else:\n                raise TypeError('Expected `target_tensors` to be '\n                                'a list or dict, but got:', target_tensors)\n        for i in range(len(self.outputs)):\n            if i in skip_target_indices:\n                self.targets.append(None)\n            else:\n                shape = self.internal_output_shapes[i]\n                name = self.output_names[i]\n                if target_tensors is not None:\n                    target = target_tensors[i]\n                else:\n                    target = None\n                if target is None or K.is_placeholder(target):\n                    if target is None:\n                        target = K.placeholder(ndim=len(shape),\n                                               name=name + '_target',\n                                               sparse=K.is_sparse(self.outputs[i]),\n                                               dtype=K.dtype(self.outputs[i]))\n                    self._feed_targets.append(target)\n                    self._feed_outputs.append(self.outputs[i])\n                    self._feed_output_names.append(name)\n                    self._feed_output_shapes.append(shape)\n                    self._feed_loss_fns.append(self.loss_functions[i])\n                else:\n                    skip_target_weighing_indices.append(i)\n                self.targets.append(target)\n\n        # Prepare sample weights.\n        sample_weights = []\n        sample_weight_modes = []\n        if isinstance(sample_weight_mode, dict):\n            for name in sample_weight_mode:\n                if name not in self.output_names:\n                    raise ValueError('Unknown entry in '\n                                     'sample_weight_mode dictionary: \"' +\n                                     name + '\". '\n                                     'Only expected the following keys: ' +\n                                     str(self.output_names))\n            for i, name in enumerate(self.output_names):\n                if i in skip_target_weighing_indices:\n                    weight = None\n                    sample_weight_modes.append(None)\n                else:\n                    if name not in sample_weight_mode:\n                        raise ValueError('Output \"' + name +\n                                         '\" missing from sample_weight_modes '\n                                         'dictionary')\n                    if sample_weight_mode.get(name) == 'temporal':\n                        weight = K.placeholder(ndim=2,\n                                               name=name + '_sample_weights')\n                        sample_weight_modes.append('temporal')\n                    else:\n                        weight = K.placeholder(ndim=1,\n                                               name=name + '_sample_weights')\n                        sample_weight_modes.append(None)\n                sample_weights.append(weight)\n        elif isinstance(sample_weight_mode, list):\n            if len(sample_weight_mode) != len(self.outputs):\n                raise ValueError('When passing a list as sample_weight_mode, '\n                                 'it should have one entry per model outputs. '\n                                 'The model has ' + str(len(self.outputs)) +\n                                 ' outputs, but you passed '\n                                 'sample_weight_mode=' +\n                                 str(sample_weight_mode))\n            for i in range(len(self.output_names)):\n                if i in skip_target_weighing_indices:\n                    weight = None\n                    sample_weight_modes.append(None)\n                else:\n                    mode = sample_weight_mode[i]\n                    name = self.output_names[i]\n                    if mode == 'temporal':\n                        weight = K.placeholder(ndim=2,\n                                               name=name + '_sample_weights')\n                        sample_weight_modes.append('temporal')\n                    else:\n                        weight = K.placeholder(ndim=1,\n                                               name=name + '_sample_weights')\n                        sample_weight_modes.append(None)\n                sample_weights.append(weight)\n        else:\n            for i, name in enumerate(self.output_names):\n                if i in skip_target_weighing_indices:\n                    sample_weight_modes.append(None)\n                    sample_weights.append(None)\n                else:\n                    if sample_weight_mode == 'temporal':\n                        sample_weights.append(\n                            K.placeholder(ndim=2,\n                                          name=name + '_sample_weights'))\n                        sample_weight_modes.append('temporal')\n                    else:\n                        sample_weights.append(\n                            K.placeholder(ndim=1,\n                                          name=name + '_sample_weights'))\n                        sample_weight_modes.append(None)\n        self.sample_weight_modes = sample_weight_modes\n        self._feed_sample_weight_modes = []\n        for i in range(len(self.outputs)):\n            if i not in skip_target_weighing_indices:\n                self._feed_sample_weight_modes.append(self.sample_weight_modes[i])\n\n        # Prepare metrics.\n        self.metrics = metrics\n        self.weighted_metrics = weighted_metrics\n        self.metrics_names = ['loss']\n        self.metrics_tensors = []\n\n        # Compute total loss.\n        total_loss = None\n        with K.name_scope('loss'):\n            for i in range(len(self.outputs)):\n                if i in skip_target_indices:\n                    continue\n                y_true = self.targets[i]\n                y_pred = self.outputs[i]\n                weighted_loss = weighted_losses[i]\n                sample_weight = sample_weights[i]\n                mask = masks[i]\n                loss_weight = loss_weights_list[i]\n                with K.name_scope(self.output_names[i] + '_loss'):\n                    output_loss = weighted_loss(y_true, y_pred,\n                                                sample_weight, mask)\n                if len(self.outputs) > 1:\n                    self.metrics_tensors.append(output_loss)\n                    self.metrics_names.append(self.output_names[i] + '_loss')\n                if total_loss is None:\n                    total_loss = loss_weight * output_loss\n                else:\n                    total_loss += loss_weight * output_loss\n            if total_loss is None:\n                if not self.losses:\n                    raise ValueError('The model cannot be compiled '\n                                     'because it has no loss to optimize.')\n                else:\n                    total_loss = 0.\n\n            # Add regularization penalties\n            # and other layer-specific losses.\n            for loss_tensor in self.losses:\n                total_loss += loss_tensor\n\n        # List of same size as output_names.\n        # contains tuples (metrics for output, names of metrics).\n        nested_metrics = _collect_metrics(metrics, self.output_names)\n        nested_weighted_metrics = _collect_metrics(weighted_metrics, self.output_names)\n\n        def append_metric(layer_index, metric_name, metric_tensor):\n            \"\"\"Helper function used in loop below.\"\"\"\n            if len(self.output_names) > 1:\n                metric_name = self.output_names[layer_index] + '_' + metric_name\n            self.metrics_names.append(metric_name)\n            self.metrics_tensors.append(metric_tensor)\n\n        with K.name_scope('metrics'):\n            for i in range(len(self.outputs)):\n                if i in skip_target_indices:\n                    continue\n\n                y_true = self.targets[i]\n                y_pred = self.outputs[i]\n                weights = sample_weights[i]\n                output_metrics = nested_metrics[i]\n                output_weighted_metrics = nested_weighted_metrics[i]\n\n                def handle_metrics(metrics, weights=None):\n                    metric_name_prefix = 'weighted_' if weights is not None else ''\n\n                    for metric in metrics:\n                        if metric == 'accuracy' or metric == 'acc':\n                            # custom handling of accuracy\n                            # (because of class mode duality)\n                            output_shape = self.internal_output_shapes[i]\n                            if (output_shape[-1] == 1 or\n                               self.loss_functions[i] == losses.binary_crossentropy):\n                                # case: binary accuracy\n                                acc_fn = metrics_module.binary_accuracy\n                            elif self.loss_functions[i] == losses.sparse_categorical_crossentropy:\n                                # case: categorical accuracy with sparse targets\n                                acc_fn = metrics_module.sparse_categorical_accuracy\n                            else:\n                                acc_fn = metrics_module.categorical_accuracy\n\n                            weighted_metric_fn = _weighted_masked_objective(acc_fn)\n                            metric_name = metric_name_prefix + 'acc'\n                        else:\n                            metric_fn = metrics_module.get(metric)\n                            weighted_metric_fn = _weighted_masked_objective(metric_fn)\n                            metric_name = metric_name_prefix + metric_fn.__name__\n\n                        with K.name_scope(metric_name):\n                            metric_result = weighted_metric_fn(y_true, y_pred,\n                                                               weights=weights,\n                                                               mask=masks[i])\n                        append_metric(i, metric_name, metric_result)\n\n                handle_metrics(output_metrics)\n                handle_metrics(output_weighted_metrics, weights=weights)\n\n        # Prepare gradient updates and state updates.\n        self.total_loss = total_loss\n        self.sample_weights = sample_weights\n        self._feed_sample_weights = []\n        for i in range(len(self.sample_weights)):\n            if i not in skip_target_weighing_indices:\n                self._feed_sample_weights.append(sample_weights[i])\n\n        # Functions for train, test and predict will\n        # be compiled lazily when required.\n        # This saves time when the user is not using all functions.\n        self._function_kwargs = kwargs\n\n        self.train_function = None\n        self.test_function = None\n        self.predict_function = None\n\n        # Collected trainable weights, sorted in topological order.\n        trainable_weights = self.trainable_weights\n        self._collected_trainable_weights = trainable_weights",
        "begin_line": 580,
        "end_line": 956,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training.Model.append_metric#885",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model.append_metric(layer_index, metric_name, metric_tensor)",
        "snippet": "        def append_metric(layer_index, metric_name, metric_tensor):\n            \"\"\"Helper function used in loop below.\"\"\"\n            if len(self.output_names) > 1:\n                metric_name = self.output_names[layer_index] + '_' + metric_name\n            self.metrics_names.append(metric_name)\n            self.metrics_tensors.append(metric_tensor)",
        "begin_line": 885,
        "end_line": 890,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training.Model.handle_metrics#903",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model.handle_metrics(metrics, weights=None)",
        "snippet": "                def handle_metrics(metrics, weights=None):\n                    metric_name_prefix = 'weighted_' if weights is not None else ''\n\n                    for metric in metrics:\n                        if metric == 'accuracy' or metric == 'acc':\n                            # custom handling of accuracy\n                            # (because of class mode duality)\n                            output_shape = self.internal_output_shapes[i]\n                            if (output_shape[-1] == 1 or\n                               self.loss_functions[i] == losses.binary_crossentropy):\n                                # case: binary accuracy\n                                acc_fn = metrics_module.binary_accuracy\n                            elif self.loss_functions[i] == losses.sparse_categorical_crossentropy:\n                                # case: categorical accuracy with sparse targets\n                                acc_fn = metrics_module.sparse_categorical_accuracy\n                            else:\n                                acc_fn = metrics_module.categorical_accuracy\n\n                            weighted_metric_fn = _weighted_masked_objective(acc_fn)\n                            metric_name = metric_name_prefix + 'acc'\n                        else:\n                            metric_fn = metrics_module.get(metric)\n                            weighted_metric_fn = _weighted_masked_objective(metric_fn)\n                            metric_name = metric_name_prefix + metric_fn.__name__\n\n                        with K.name_scope(metric_name):\n                            metric_result = weighted_metric_fn(y_true, y_pred,\n                                                               weights=weights,\n                                                               mask=masks[i])\n                        append_metric(i, metric_name, metric_result)",
        "begin_line": 903,
        "end_line": 932,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training.Model._check_trainable_weights_consistency#958",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model._check_trainable_weights_consistency(self)",
        "snippet": "    def _check_trainable_weights_consistency(self):\n        \"\"\"Check trainable weights count consistency.\n\n        This will raise a warning if `trainable_weights` and\n        `_collected_trainable_weights` are consistent (i.e. have the same\n        number of parameters).\n        Inconsistency will typically arise when one modifies `model.trainable`\n        without calling `model.compile` again.\n        \"\"\"\n        if not hasattr(self, '_collected_trainable_weights'):\n            return\n\n        if (count_params(self.trainable_weights) !=\n                count_params(self._collected_trainable_weights)):\n            warnings.warn(UserWarning(\n                'Discrepancy between trainable weights and collected trainable'\n                ' weights, did you set `model.trainable` without calling'\n                ' `model.compile` after ?'))",
        "begin_line": 958,
        "end_line": 975,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0017985611510791368,
            "pseudo_dstar_susp": 0.0012738853503184713,
            "pseudo_tarantula_susp": 0.002421307506053269,
            "pseudo_op2_susp": 0.0012738853503184713,
            "pseudo_barinel_susp": 0.002421307506053269
        }
    },
    {
        "name": "keras.engine.training.Model._make_train_function#977",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model._make_train_function(self)",
        "snippet": "    def _make_train_function(self):\n        if not hasattr(self, 'train_function'):\n            raise RuntimeError('You must compile your model before using it.')\n        self._check_trainable_weights_consistency()\n        if self.train_function is None:\n            inputs = self._feed_inputs + self._feed_targets + self._feed_sample_weights\n            if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n                inputs += [K.learning_phase()]\n\n            with K.name_scope('training'):\n                with K.name_scope(self.optimizer.__class__.__name__):\n                    training_updates = self.optimizer.get_updates(\n                        params=self._collected_trainable_weights,\n                        loss=self.total_loss)\n                updates = self.updates + training_updates\n                # Gets loss and metrics. Updates weights at each call.\n                self.train_function = K.function(inputs,\n                                                 [self.total_loss] + self.metrics_tensors,\n                                                 updates=updates,\n                                                 name='train_function',\n                                                 **self._function_kwargs)",
        "begin_line": 977,
        "end_line": 997,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010002000400080016,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training.Model._make_test_function#999",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model._make_test_function(self)",
        "snippet": "    def _make_test_function(self):\n        if not hasattr(self, 'test_function'):\n            raise RuntimeError('You must compile your model before using it.')\n        if self.test_function is None:\n            inputs = self._feed_inputs + self._feed_targets + self._feed_sample_weights\n            if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n                inputs += [K.learning_phase()]\n            # Return loss and metrics, no gradient updates.\n            # Does update the network states.\n            self.test_function = K.function(inputs,\n                                            [self.total_loss] + self.metrics_tensors,\n                                            updates=self.state_updates,\n                                            name='test_function',\n                                            **self._function_kwargs)",
        "begin_line": 999,
        "end_line": 1012,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training.Model._make_predict_function#1014",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model._make_predict_function(self)",
        "snippet": "    def _make_predict_function(self):\n        if not hasattr(self, 'predict_function'):\n            self.predict_function = None\n        if self.predict_function is None:\n            if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n                inputs = self._feed_inputs + [K.learning_phase()]\n            else:\n                inputs = self._feed_inputs\n            # Gets network outputs. Does not update weights.\n            # Does update the network states.\n            kwargs = getattr(self, '_function_kwargs', {})\n            self.predict_function = K.function(inputs,\n                                               self.outputs,\n                                               updates=self.state_updates,\n                                               name='predict_function',\n                                               **kwargs)",
        "begin_line": 1014,
        "end_line": 1029,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010520778537611783,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training.Model._check_num_samples#1031",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model._check_num_samples(self, ins, batch_size=None, steps=None, steps_name='steps')",
        "snippet": "    def _check_num_samples(self, ins, batch_size=None, steps=None, steps_name='steps'):\n        \"\"\"Determine the number of samples provided for training and evaluation.\n\n        The number of samples is not defined when running with `steps`,\n        in which case the number of samples is set to `None`.\n\n        # Arguments\n            ins: List of tensors to be fed to the Keras function.\n            batch_size: Integer batch size or `None` if not defined.\n            steps: Total number of steps (batches of samples)\n                before declaring `_predict_loop` finished.\n                Ignored with the default value of `None`.\n            steps_name: The public API's parameter name for `steps`.\n\n        # Raises\n            ValueError: when `steps` is `None` and the attribute `ins.shape`\n            does not exist. Also raises ValueError when `steps` is not `None`\n            and `batch_size` is not `None` because they are mutually\n            exclusive.\n\n        # Returns\n            When steps is `None`, returns the number of samples to be\n            processed based on the size of the first dimension of the\n            first input numpy array. When steps is not `None` and\n            `batch_size` is `None`, returns `None`.\n        \"\"\"\n        if steps is not None:\n            num_samples = None\n            if batch_size is not None:\n                raise ValueError('If ' + steps_name +\n                                 ' is set, the `batch_size` must be None.')\n        elif ins and hasattr(ins[0], 'shape'):\n            num_samples = ins[0].shape[0]\n        else:\n            raise ValueError('Either the input data should have '\n                             'a defined shape, or ' + steps_name +\n                             ' should be specified.')\n        return num_samples",
        "begin_line": 1031,
        "end_line": 1068,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training.Model._fit_loop#1070",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model._fit_loop(self, f, ins, out_labels=None, batch_size=None, epochs=100, verbose=1, callbacks=None, val_f=None, val_ins=None, shuffle=True, callback_metrics=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None)",
        "snippet": "    def _fit_loop(self, f, ins, out_labels=None, batch_size=None,\n                  epochs=100, verbose=1, callbacks=None,\n                  val_f=None, val_ins=None, shuffle=True,\n                  callback_metrics=None, initial_epoch=0,\n                  steps_per_epoch=None, validation_steps=None):\n        \"\"\"Abstract fit function for `f(ins)`.\n\n        Assume that f returns a list, labeled by out_labels.\n\n        # Arguments\n            f: Keras function returning a list of tensors\n            ins: List of tensors to be fed to `f`\n            out_labels: List of strings, display names of\n                the outputs of `f`\n            batch_size: Integer batch size or None if unknown.\n            epochs: Number of times to iterate over the data\n            verbose: Verbosity mode, 0, 1 or 2\n            callbacks: List of callbacks to be called during training\n            val_f: Keras function to call for validation\n            val_ins: List of tensors to be fed to `val_f`\n            shuffle: Whether to shuffle the data at the beginning of each epoch\n            callback_metrics: List of strings, the display names of the metrics\n                passed to the callbacks. They should be the\n                concatenation of list the display names of the outputs of\n                 `f` and the list of display names of the outputs of `f_val`.\n            initial_epoch: Epoch at which to start training\n                (useful for resuming a previous training run)\n            steps_per_epoch: Total number of steps (batches of samples)\n                before declaring one epoch finished and starting the\n                next epoch. Ignored with the default value of `None`.\n            validation_steps: Number of steps to run validation for\n                (only if doing validation from data tensors).\n                Ignored with the default value of `None`.\n\n        # Returns\n            `History` object.\n        \"\"\"\n        do_validation = False\n        if val_f and val_ins:\n            do_validation = True\n            if verbose and ins and hasattr(ins[0], 'shape') and hasattr(val_ins[0], 'shape'):\n                print('Train on %d samples, validate on %d samples' %\n                      (ins[0].shape[0], val_ins[0].shape[0]))\n        if validation_steps:\n            do_validation = True\n            if steps_per_epoch is None:\n                raise ValueError('Can only use `validation_steps` '\n                                 'when doing step-wise '\n                                 'training, i.e. `steps_per_epoch` '\n                                 'must be set.')\n\n        num_train_samples = self._check_num_samples(ins, batch_size,\n                                                    steps_per_epoch,\n                                                    'steps_per_epoch')\n        if num_train_samples is not None:\n            index_array = np.arange(num_train_samples)\n\n        self.history = cbks.History()\n        callbacks = [cbks.BaseLogger()] + (callbacks or []) + [self.history]\n        if verbose:\n            if steps_per_epoch is not None:\n                count_mode = 'steps'\n            else:\n                count_mode = 'samples'\n            callbacks += [cbks.ProgbarLogger(count_mode)]\n        callbacks = cbks.CallbackList(callbacks)\n        out_labels = out_labels or []\n\n        # it's possible to callback a different model than self\n        # (used by Sequential models)\n        if hasattr(self, 'callback_model') and self.callback_model:\n            callback_model = self.callback_model\n        else:\n            callback_model = self\n\n        callbacks.set_model(callback_model)\n        callbacks.set_params({\n            'batch_size': batch_size,\n            'epochs': epochs,\n            'steps': steps_per_epoch,\n            'samples': num_train_samples,\n            'verbose': verbose,\n            'do_validation': do_validation,\n            'metrics': callback_metrics or [],\n        })\n        callbacks.on_train_begin()\n        callback_model.stop_training = False\n        for cbk in callbacks:\n            cbk.validation_data = val_ins\n\n        for epoch in range(initial_epoch, epochs):\n            callbacks.on_epoch_begin(epoch)\n            epoch_logs = {}\n            if steps_per_epoch is not None:\n                for step_index in range(steps_per_epoch):\n                    batch_logs = {}\n                    batch_logs['batch'] = step_index\n                    batch_logs['size'] = 1\n                    callbacks.on_batch_begin(step_index, batch_logs)\n                    outs = f(ins)\n\n                    if not isinstance(outs, list):\n                        outs = [outs]\n                    for l, o in zip(out_labels, outs):\n                        batch_logs[l] = o\n\n                    callbacks.on_batch_end(step_index, batch_logs)\n                    if callback_model.stop_training:\n                        break\n\n                if do_validation:\n                    val_outs = self._test_loop(val_f, val_ins,\n                                               batch_size=batch_size,\n                                               steps=validation_steps,\n                                               verbose=0)\n                    if not isinstance(val_outs, list):\n                        val_outs = [val_outs]\n                    # Same labels assumed.\n                    for l, o in zip(out_labels, val_outs):\n                        epoch_logs['val_' + l] = o\n            else:\n                if shuffle == 'batch':\n                    index_array = _batch_shuffle(index_array, batch_size)\n                elif shuffle:\n                    np.random.shuffle(index_array)\n\n                batches = _make_batches(num_train_samples, batch_size)\n                for batch_index, (batch_start, batch_end) in enumerate(batches):\n                    batch_ids = index_array[batch_start:batch_end]\n                    try:\n                        if isinstance(ins[-1], float):\n                            # Do not slice the training phase flag.\n                            ins_batch = _slice_arrays(ins[:-1], batch_ids) + [ins[-1]]\n                        else:\n                            ins_batch = _slice_arrays(ins, batch_ids)\n                    except TypeError:\n                        raise TypeError('TypeError while preparing batch. '\n                                        'If using HDF5 input data, '\n                                        'pass shuffle=\"batch\".')\n                    batch_logs = {}\n                    batch_logs['batch'] = batch_index\n                    batch_logs['size'] = len(batch_ids)\n                    callbacks.on_batch_begin(batch_index, batch_logs)\n                    outs = f(ins_batch)\n                    if not isinstance(outs, list):\n                        outs = [outs]\n                    for l, o in zip(out_labels, outs):\n                        batch_logs[l] = o\n\n                    callbacks.on_batch_end(batch_index, batch_logs)\n                    if callback_model.stop_training:\n                        break\n\n                    if batch_index == len(batches) - 1:  # Last batch.\n                        if do_validation:\n                            val_outs = self._test_loop(val_f, val_ins,\n                                                       batch_size=batch_size,\n                                                       verbose=0)\n                            if not isinstance(val_outs, list):\n                                val_outs = [val_outs]\n                            # Same labels assumed.\n                            for l, o in zip(out_labels, val_outs):\n                                epoch_logs['val_' + l] = o\n            callbacks.on_epoch_end(epoch, epoch_logs)\n            if callback_model.stop_training:\n                break\n        callbacks.on_train_end()\n        return self.history",
        "begin_line": 1070,
        "end_line": 1237,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training.Model._predict_loop#1239",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model._predict_loop(self, f, ins, batch_size=32, verbose=0, steps=None)",
        "snippet": "    def _predict_loop(self, f, ins, batch_size=32, verbose=0, steps=None):\n        \"\"\"Abstract method to loop over some data in batches.\n\n        # Arguments\n            f: Keras function returning a list of tensors.\n            ins: list of tensors to be fed to `f`.\n            batch_size: integer batch size.\n            verbose: verbosity mode.\n            steps: Total number of steps (batches of samples)\n                before declaring `_predict_loop` finished.\n                Ignored with the default value of `None`.\n\n        # Returns\n            Array of predictions (if the model has a single output)\n            or list of arrays of predictions\n            (if the model has multiple outputs).\n        \"\"\"\n        num_samples = self._check_num_samples(ins, batch_size,\n                                              steps,\n                                              'steps')\n        if verbose == 1:\n            if steps is not None:\n                progbar = Progbar(target=steps)\n            else:\n                progbar = Progbar(target=num_samples)\n        if steps is not None:\n            # Step-based predictions.\n            # Since we do not know how many samples\n            # we will see, we cannot pre-allocate\n            # the returned Numpy arrays.\n            # Instead, we store one array per batch seen\n            # and concatenate them upon returning.\n            unconcatenated_outs = []\n            for step in range(steps):\n                batch_outs = f(ins)\n                if not isinstance(batch_outs, list):\n                    batch_outs = [batch_outs]\n                if step == 0:\n                    for batch_out in batch_outs:\n                        unconcatenated_outs.append([])\n                for i, batch_out in enumerate(batch_outs):\n                    unconcatenated_outs[i].append(batch_out)\n                if verbose == 1:\n                    progbar.update(step + 1)\n            if len(unconcatenated_outs) == 1:\n                return np.concatenate(unconcatenated_outs[0], axis=0)\n            return [np.concatenate(unconcatenated_outs[i], axis=0)\n                    for i in range(len(unconcatenated_outs))]\n        else:\n            # Sample-based predictions.\n            outs = []\n            batches = _make_batches(num_samples, batch_size)\n            index_array = np.arange(num_samples)\n            for batch_index, (batch_start, batch_end) in enumerate(batches):\n                batch_ids = index_array[batch_start:batch_end]\n                if ins and isinstance(ins[-1], float):\n                    # Do not slice the training phase flag.\n                    ins_batch = _slice_arrays(ins[:-1], batch_ids) + [ins[-1]]\n                else:\n                    ins_batch = _slice_arrays(ins, batch_ids)\n                batch_outs = f(ins_batch)\n                if not isinstance(batch_outs, list):\n                    batch_outs = [batch_outs]\n                if batch_index == 0:\n                    # Pre-allocate the results arrays.\n                    for batch_out in batch_outs:\n                        shape = (num_samples,) + batch_out.shape[1:]\n                        outs.append(np.zeros(shape, dtype=batch_out.dtype))\n                for i, batch_out in enumerate(batch_outs):\n                    outs[i][batch_start:batch_end] = batch_out\n                if verbose == 1:\n                    progbar.update(batch_end)\n            if len(outs) == 1:\n                return outs[0]\n            return outs",
        "begin_line": 1239,
        "end_line": 1313,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training.Model._test_loop#1315",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model._test_loop(self, f, ins, batch_size=None, verbose=0, steps=None)",
        "snippet": "    def _test_loop(self, f, ins, batch_size=None, verbose=0, steps=None):\n        \"\"\"Abstract method to loop over some data in batches.\n\n        # Arguments\n            f: Keras function returning a list of tensors.\n            ins: list of tensors to be fed to `f`.\n            batch_size: integer batch size or `None`.\n            verbose: verbosity mode.\n            steps: Total number of steps (batches of samples)\n                before declaring predictions finished.\n                Ignored with the default value of `None`.\n\n        # Returns\n            Scalar loss (if the model has a single output and no metrics)\n            or list of scalars (if the model has multiple outputs\n            and/or metrics). The attribute `model.metrics_names` will give you\n            the display labels for the scalar outputs.\n        \"\"\"\n        num_samples = self._check_num_samples(ins, batch_size,\n                                              steps,\n                                              'steps')\n        outs = []\n        if verbose == 1:\n            if steps is not None:\n                progbar = Progbar(target=steps)\n            else:\n                progbar = Progbar(target=num_samples)\n        if steps is not None:\n            for step in range(steps):\n                batch_outs = f(ins)\n                if isinstance(batch_outs, list):\n                    if step == 0:\n                        for _ in enumerate(batch_outs):\n                            outs.append(0.)\n                    for i, batch_out in enumerate(batch_outs):\n                        outs[i] += batch_out\n                else:\n                    if step == 0:\n                        outs.append(0.)\n                    outs[0] += batch_outs\n                if verbose == 1:\n                    progbar.update(step + 1)\n            for i in range(len(outs)):\n                outs[i] /= steps\n        else:\n            batches = _make_batches(num_samples, batch_size)\n            index_array = np.arange(num_samples)\n            for batch_index, (batch_start, batch_end) in enumerate(batches):\n                batch_ids = index_array[batch_start:batch_end]\n                if isinstance(ins[-1], float):\n                    # Do not slice the training phase flag.\n                    ins_batch = _slice_arrays(ins[:-1], batch_ids) + [ins[-1]]\n                else:\n                    ins_batch = _slice_arrays(ins, batch_ids)\n\n                batch_outs = f(ins_batch)\n                if isinstance(batch_outs, list):\n                    if batch_index == 0:\n                        for batch_out in enumerate(batch_outs):\n                            outs.append(0.)\n                    for i, batch_out in enumerate(batch_outs):\n                        outs[i] += batch_out * len(batch_ids)\n                else:\n                    if batch_index == 0:\n                        outs.append(0.)\n                    outs[0] += batch_outs * len(batch_ids)\n\n                if verbose == 1:\n                    progbar.update(batch_end)\n            for i in range(len(outs)):\n                outs[i] /= num_samples\n        if len(outs) == 1:\n            return outs[0]\n        return outs",
        "begin_line": 1315,
        "end_line": 1388,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training.Model._standardize_user_data#1390",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model._standardize_user_data(self, x, y, sample_weight=None, class_weight=None, check_batch_axis=True, batch_size=None)",
        "snippet": "    def _standardize_user_data(self, x, y,\n                               sample_weight=None, class_weight=None,\n                               check_batch_axis=True, batch_size=None):\n        if not hasattr(self, 'optimizer'):\n            raise RuntimeError('You must compile a model before '\n                               'training/testing. '\n                               'Use `model.compile(optimizer, loss)`.')\n\n        output_shapes = []\n        for output_shape, loss_fn in zip(self._feed_output_shapes, self._feed_loss_fns):\n            if loss_fn.__name__ == 'sparse_categorical_crossentropy':\n                output_shapes.append(output_shape[:-1] + (1,))\n            elif getattr(losses, loss_fn.__name__, None) is None:\n                output_shapes.append(None)\n            else:\n                output_shapes.append(output_shape)\n        x = _standardize_input_data(x, self._feed_input_names,\n                                    self._feed_input_shapes,\n                                    check_batch_axis=False,\n                                    exception_prefix='input')\n        y = _standardize_input_data(y, self._feed_output_names,\n                                    output_shapes,\n                                    check_batch_axis=False,\n                                    exception_prefix='target')\n        sample_weights = _standardize_sample_weights(sample_weight,\n                                                     self._feed_output_names)\n        class_weights = _standardize_class_weights(class_weight,\n                                                   self._feed_output_names)\n        sample_weights = [_standardize_weights(ref, sw, cw, mode)\n                          for (ref, sw, cw, mode)\n                          in zip(y, sample_weights, class_weights, self._feed_sample_weight_modes)]\n        _check_array_lengths(x, y, sample_weights)\n        _check_loss_and_target_compatibility(y,\n                                             self._feed_loss_fns,\n                                             self._feed_output_shapes)\n        if self.stateful and batch_size:\n            if x[0].shape[0] % batch_size != 0:\n                raise ValueError('In a stateful network, '\n                                 'you should only pass inputs with '\n                                 'a number of samples that can be '\n                                 'divided by the batch size. Found: ' +\n                                 str(x[0].shape[0]) + ' samples')\n        return x, y, sample_weights",
        "begin_line": 1390,
        "end_line": 1432,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training.Model._get_deduped_metrics_names#1434",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model._get_deduped_metrics_names(self)",
        "snippet": "    def _get_deduped_metrics_names(self):\n        out_labels = self.metrics_names\n\n        # Rename duplicated metrics name\n        # (can happen with an output layer shared among multiple dataflows).\n        deduped_out_labels = []\n        for i, label in enumerate(out_labels):\n            new_label = label\n            if out_labels.count(label) > 1:\n                dup_idx = out_labels[:i].count(label)\n                new_label += '_' + str(dup_idx + 1)\n            deduped_out_labels.append(new_label)\n        return deduped_out_labels",
        "begin_line": 1434,
        "end_line": 1446,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.153318077803204e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training.Model.fit#1448",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model.fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, **kwargs)",
        "snippet": "    def fit(self, x=None,\n            y=None,\n            batch_size=None,\n            epochs=1,\n            verbose=1,\n            callbacks=None,\n            validation_split=0.,\n            validation_data=None,\n            shuffle=True,\n            class_weight=None,\n            sample_weight=None,\n            initial_epoch=0,\n            steps_per_epoch=None,\n            validation_steps=None,\n            **kwargs):\n        \"\"\"Trains the model for a fixed number of epochs (iterations on a dataset).\n\n        # Arguments\n            x: Numpy array of training data,\n                or list of Numpy arrays if the model has multiple inputs.\n                If all inputs in the model are named,\n                you can also pass a dictionary\n                mapping input names to Numpy arrays.\n                Can be `None` (default) if feeding from framework-native tensors.\n            y: Numpy array of target data,\n                or list of Numpy arrays if the model has multiple outputs.\n                If all outputs in the model are named,\n                you can also pass a dictionary\n                mapping output names to Numpy arrays.\n                Can be `None` (default) if feeding from framework-native tensors.\n            batch_size: Integer or `None`.\n                Number of samples per gradient update.\n                If unspecified, it will default to 32.\n            epochs: Integer, the number of times to iterate\n                over the training data arrays.\n            verbose: 0, 1, or 2. Verbosity mode.\n                0 = silent, 1 = verbose, 2 = one log line per epoch.\n            callbacks: List of callbacks to be called during training.\n                See [callbacks](/callbacks).\n            validation_split: Float between 0 and 1:\n                fraction of the training data to be used as validation data.\n                The model will set apart this fraction of the training data,\n                will not train on it, and will evaluate\n                the loss and any model metrics\n                on this data at the end of each epoch.\n            validation_data: Data on which to evaluate\n                the loss and any model metrics\n                at the end of each epoch. The model will not\n                be trained on this data.\n                This could be a tuple (x_val, y_val)\n                or a tuple (x_val, y_val, val_sample_weights).\n            shuffle: Boolean, whether to shuffle the training data\n                before each epoch. Has no effect when `steps_per_epoch`\n                is not `None`.\n            class_weight: Optional dictionary mapping\n                class indices (integers) to\n                a weight (float) to apply to the model's loss for the samples\n                from this class during training.\n                This can be useful to tell the model to \"pay more attention\" to\n                samples from an under-represented class.\n            sample_weight: Optional array of the same length as x, containing\n                weights to apply to the model's loss for each sample.\n                In the case of temporal data, you can pass a 2D array\n                with shape (samples, sequence_length),\n                to apply a different weight to every timestep of every sample.\n                In this case you should make sure to specify\n                sample_weight_mode=\"temporal\" in compile().\n            initial_epoch: Epoch at which to start training\n                (useful for resuming a previous training run)\n            steps_per_epoch: Total number of steps (batches of samples)\n                before declaring one epoch finished and starting the\n                next epoch. When training with Input Tensors such as\n                TensorFlow data tensors, the default `None` is equal to\n                the number of unique samples in your dataset divided by\n                the batch size, or 1 if that cannot be determined.\n            validation_steps: Only relevant if `steps_per_epoch`\n                is specified. Total number of steps (batches of samples)\n                to validate before stopping.\n\n        # Returns\n            A `History` instance. Its `history` attribute contains\n            all information collected during training.\n\n        # Raises\n            ValueError: In case of mismatch between the provided input data\n                and what the model expects.\n        \"\"\"\n        # Backwards compatibility\n        if batch_size is None and steps_per_epoch is None:\n            batch_size = 32\n        # Legacy support\n        if 'nb_epoch' in kwargs:\n            warnings.warn('The `nb_epoch` argument in `fit` '\n                          'has been renamed `epochs`.', stacklevel=2)\n            epochs = kwargs.pop('nb_epoch')\n        if kwargs:\n            raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\n        if x is None and y is None and steps_per_epoch is None:\n            raise ValueError('If fitting from data tensors, '\n                             'you should specify the `steps_per_epoch` '\n                             'argument.')\n        # Validate user data.\n        x, y, sample_weights = self._standardize_user_data(\n            x, y,\n            sample_weight=sample_weight,\n            class_weight=class_weight,\n            check_batch_axis=False,\n            batch_size=batch_size)\n        # Prepare validation data.\n        do_validation = False\n        if validation_data:\n            do_validation = True\n            if len(validation_data) == 2:\n                val_x, val_y = validation_data\n                val_sample_weight = None\n            elif len(validation_data) == 3:\n                val_x, val_y, val_sample_weight = validation_data\n            else:\n                raise ValueError('When passing validation_data, '\n                                 'it must contain 2 (x_val, y_val) '\n                                 'or 3 (x_val, y_val, val_sample_weights) '\n                                 'items, however it contains %d items' %\n                                 len(validation_data))\n\n            val_x, val_y, val_sample_weights = self._standardize_user_data(\n                val_x, val_y,\n                sample_weight=val_sample_weight,\n                check_batch_axis=False,\n                batch_size=batch_size)\n            if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n                val_ins = val_x + val_y + val_sample_weights + [0.]\n            else:\n                val_ins = val_x + val_y + val_sample_weights\n\n        elif validation_split and 0. < validation_split < 1.:\n            do_validation = True\n            if hasattr(x[0], 'shape'):\n                split_at = int(x[0].shape[0] * (1. - validation_split))\n            else:\n                split_at = int(len(x[0]) * (1. - validation_split))\n            x, val_x = (_slice_arrays(x, 0, split_at), _slice_arrays(x, split_at))\n            y, val_y = (_slice_arrays(y, 0, split_at), _slice_arrays(y, split_at))\n            sample_weights, val_sample_weights = (\n                _slice_arrays(sample_weights, 0, split_at),\n                _slice_arrays(sample_weights, split_at))\n            if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n                val_ins = val_x + val_y + val_sample_weights + [0.]\n            else:\n                val_ins = val_x + val_y + val_sample_weights\n\n        elif validation_steps:\n            do_validation = True\n            if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n                val_ins = [0.]\n\n        # Prepare input arrays and training function.\n        if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n            ins = x + y + sample_weights + [1.]\n        else:\n            ins = x + y + sample_weights\n        self._make_train_function()\n        f = self.train_function\n\n        # Prepare display labels.\n        out_labels = self._get_deduped_metrics_names()\n\n        if do_validation:\n            self._make_test_function()\n            val_f = self.test_function\n            callback_metrics = copy.copy(out_labels) + ['val_' + n for n in out_labels]\n        else:\n            callback_metrics = copy.copy(out_labels)\n            val_f = None\n            val_ins = []\n\n        # Delegate logic to `_fit_loop`.\n        return self._fit_loop(f, ins, out_labels=out_labels,\n                              batch_size=batch_size, epochs=epochs,\n                              verbose=verbose, callbacks=callbacks,\n                              val_f=val_f, val_ins=val_ins, shuffle=shuffle,\n                              callback_metrics=callback_metrics,\n                              initial_epoch=initial_epoch,\n                              steps_per_epoch=steps_per_epoch,\n                              validation_steps=validation_steps)",
        "begin_line": 1448,
        "end_line": 1631,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training.Model.evaluate#1633",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model.evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None)",
        "snippet": "    def evaluate(self, x=None, y=None,\n                 batch_size=None,\n                 verbose=1,\n                 sample_weight=None,\n                 steps=None):\n        \"\"\"Returns the loss value & metrics values for the model in test mode.\n\n        Computation is done in batches.\n\n        # Arguments\n            x: Numpy array of test data,\n                or list of Numpy arrays if the model has multiple inputs.\n                If all inputs in the model are named,\n                you can also pass a dictionary\n                mapping input names to Numpy arrays.\n                Can be `None` (default) if feeding from framework-native tensors.\n            y: Numpy array of target data,\n                or list of Numpy arrays if the model has multiple outputs.\n                If all outputs in the model are named,\n                you can also pass a dictionary\n                mapping output names to Numpy arrays.\n                Can be `None` (default) if feeding from framework-native tensors.\n            batch_size: Integer. If unspecified, it will default to 32.\n            verbose: Verbosity mode, 0 or 1.\n            sample_weight: Array of weights to weight the contribution\n                of different samples to the loss and metrics.\n            steps: Total number of steps (batches of samples)\n                before declaring the evaluation round finished.\n                Ignored with the default value of `None`.\n\n        # Returns\n            Scalar test loss (if the model has a single output and no metrics)\n            or list of scalars (if the model has multiple outputs\n            and/or metrics). The attribute `model.metrics_names` will give you\n            the display labels for the scalar outputs.\n        \"\"\"\n        # Backwards compatibility.\n        if batch_size is None and steps is None:\n            batch_size = 32\n        if x is None and y is None and steps is None:\n            raise ValueError('If evaluating from data tensors, '\n                             'you should specify the `steps` '\n                             'argument.')\n        # Validate user data.\n        x, y, sample_weights = self._standardize_user_data(\n            x, y,\n            sample_weight=sample_weight,\n            check_batch_axis=False,\n            batch_size=batch_size)\n        # Prepare inputs, delegate logic to `_test_loop`.\n        if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n            ins = x + y + sample_weights + [0.]\n        else:\n            ins = x + y + sample_weights\n        self._make_test_function()\n        f = self.test_function\n        return self._test_loop(f, ins,\n                               batch_size=batch_size,\n                               verbose=verbose,\n                               steps=steps)",
        "begin_line": 1633,
        "end_line": 1692,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training.Model.predict#1694",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model.predict(self, x, batch_size=None, verbose=0, steps=None)",
        "snippet": "    def predict(self, x,\n                batch_size=None,\n                verbose=0,\n                steps=None):\n        \"\"\"Generates output predictions for the input samples.\n\n        Computation is done in batches.\n\n        # Arguments\n            x: The input data, as a Numpy array\n                (or list of Numpy arrays if the model has multiple outputs).\n            batch_size: Integer. If unspecified, it will default to 32.\n            verbose: Verbosity mode, 0 or 1.\n            steps: Total number of steps (batches of samples)\n                before declaring the prediction round finished.\n                Ignored with the default value of `None`.\n\n        # Returns\n            Numpy array(s) of predictions.\n\n        # Raises\n            ValueError: In case of mismatch between the provided\n                input data and the model's expectations,\n                or in case a stateful model receives a number of samples\n                that is not a multiple of the batch size.\n        \"\"\"\n        # Backwards compatibility.\n        if batch_size is None and steps is None:\n            batch_size = 32\n        if x is None and steps is None:\n            raise ValueError('If predicting from data tensors, '\n                             'you should specify the `steps` '\n                             'argument.')\n        # Validate user data.\n        x = _standardize_input_data(x, self._feed_input_names,\n                                    self._feed_input_shapes,\n                                    check_batch_axis=False)\n        if self.stateful:\n            if x[0].shape[0] > batch_size and x[0].shape[0] % batch_size != 0:\n                raise ValueError('In a stateful network, '\n                                 'you should only pass inputs with '\n                                 'a number of samples that can be '\n                                 'divided by the batch size. Found: ' +\n                                 str(x[0].shape[0]) + ' samples. '\n                                 'Batch size: ' + str(batch_size) + '.')\n\n        # Prepare inputs, delegate logic to `_predict_loop`.\n        if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n            ins = x + [0.]\n        else:\n            ins = x\n        self._make_predict_function()\n        f = self.predict_function\n        return self._predict_loop(f, ins, batch_size=batch_size,\n                                  verbose=verbose, steps=steps)",
        "begin_line": 1694,
        "end_line": 1748,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training.Model.train_on_batch#1750",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model.train_on_batch(self, x, y, sample_weight=None, class_weight=None)",
        "snippet": "    def train_on_batch(self, x, y,\n                       sample_weight=None,\n                       class_weight=None):\n        \"\"\"Runs a single gradient update on a single batch of data.\n\n        # Arguments\n            x: Numpy array of training data,\n                or list of Numpy arrays if the model has multiple inputs.\n                If all inputs in the model are named,\n                you can also pass a dictionary\n                mapping input names to Numpy arrays.\n            y: Numpy array of target data,\n                or list of Numpy arrays if the model has multiple outputs.\n                If all outputs in the model are named,\n                you can also pass a dictionary\n                mapping output names to Numpy arrays.\n            sample_weight: Optional array of the same length as x, containing\n                weights to apply to the model's loss for each sample.\n                In the case of temporal data, you can pass a 2D array\n                with shape (samples, sequence_length),\n                to apply a different weight to every timestep of every sample.\n                In this case you should make sure to specify\n                sample_weight_mode=\"temporal\" in compile().\n            class_weight: Optional dictionary mapping\n                class indices (integers) to\n                a weight (float) to apply to the model's loss for the samples\n                from this class during training.\n                This can be useful to tell the model to \"pay more attention\" to\n                samples from an under-represented class.\n\n        # Returns\n            Scalar training loss\n            (if the model has a single output and no metrics)\n            or list of scalars (if the model has multiple outputs\n            and/or metrics). The attribute `model.metrics_names` will give you\n            the display labels for the scalar outputs.\n        \"\"\"\n        x, y, sample_weights = self._standardize_user_data(\n            x, y,\n            sample_weight=sample_weight,\n            class_weight=class_weight,\n            check_batch_axis=True)\n        if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n            ins = x + y + sample_weights + [1.]\n        else:\n            ins = x + y + sample_weights\n        self._make_train_function()\n        outputs = self.train_function(ins)\n        if len(outputs) == 1:\n            return outputs[0]\n        return outputs",
        "begin_line": 1750,
        "end_line": 1800,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010191602119853241,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training.Model.test_on_batch#1802",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model.test_on_batch(self, x, y, sample_weight=None)",
        "snippet": "    def test_on_batch(self, x, y, sample_weight=None):\n        \"\"\"Test the model on a single batch of samples.\n\n        # Arguments\n            x: Numpy array of test data,\n                or list of Numpy arrays if the model has multiple inputs.\n                If all inputs in the model are named,\n                you can also pass a dictionary\n                mapping input names to Numpy arrays.\n            y: Numpy array of target data,\n                or list of Numpy arrays if the model has multiple outputs.\n                If all outputs in the model are named,\n                you can also pass a dictionary\n                mapping output names to Numpy arrays.\n            sample_weight: Optional array of the same length as x, containing\n                weights to apply to the model's loss for each sample.\n                In the case of temporal data, you can pass a 2D array\n                with shape (samples, sequence_length),\n                to apply a different weight to every timestep of every sample.\n                In this case you should make sure to specify\n                sample_weight_mode=\"temporal\" in compile().\n\n        # Returns\n            Scalar test loss (if the model has a single output and no metrics)\n            or list of scalars (if the model has multiple outputs\n            and/or metrics). The attribute `model.metrics_names` will give you\n            the display labels for the scalar outputs.\n        \"\"\"\n        x, y, sample_weights = self._standardize_user_data(\n            x, y,\n            sample_weight=sample_weight,\n            check_batch_axis=True)\n        if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n            ins = x + y + sample_weights + [0.]\n        else:\n            ins = x + y + sample_weights\n        self._make_test_function()\n        outputs = self.test_function(ins)\n        if len(outputs) == 1:\n            return outputs[0]\n        return outputs",
        "begin_line": 1802,
        "end_line": 1842,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00012818869375721061,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training.Model.predict_on_batch#1844",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model.predict_on_batch(self, x)",
        "snippet": "    def predict_on_batch(self, x):\n        \"\"\"Returns predictions for a single batch of samples.\n\n        # Arguments\n            x: Input samples, as a Numpy array.\n\n        # Returns\n            Numpy array(s) of predictions.\n        \"\"\"\n        x = _standardize_input_data(x, self._feed_input_names,\n                                    self._feed_input_shapes)\n        if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n            ins = x + [0.]\n        else:\n            ins = x\n        self._make_predict_function()\n        outputs = self.predict_function(ins)\n        if len(outputs) == 1:\n            return outputs[0]\n        return outputs",
        "begin_line": 1844,
        "end_line": 1863,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training.Model.fit_generator#1866",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model.fit_generator(self, generator, steps_per_epoch, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)",
        "snippet": "    def fit_generator(self, generator,\n                      steps_per_epoch,\n                      epochs=1,\n                      verbose=1,\n                      callbacks=None,\n                      validation_data=None,\n                      validation_steps=None,\n                      class_weight=None,\n                      max_queue_size=10,\n                      workers=1,\n                      use_multiprocessing=False,\n                      shuffle=True,\n                      initial_epoch=0):\n        \"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\n\n        The generator is run in parallel to the model, for efficiency.\n        For instance, this allows you to do real-time data augmentation\n        on images on CPU in parallel to training your model on GPU.\n\n        The use of `keras.utils.Sequence` guarantees the ordering\n        and guarantees the single use of every input per epoch when\n        using `use_multiprocessing=True`.\n\n        # Arguments\n            generator: A generator or an instance of Sequence (keras.utils.Sequence)\n                    object in order to avoid duplicate data\n                    when using multiprocessing.\n                The output of the generator must be either\n                - a tuple (inputs, targets)\n                - a tuple (inputs, targets, sample_weights).\n                All arrays should contain the same number of samples.\n                The generator is expected to loop over its data\n                indefinitely. An epoch finishes when `steps_per_epoch`\n                batches have been seen by the model.\n            steps_per_epoch: Total number of steps (batches of samples)\n                to yield from `generator` before declaring one epoch\n                finished and starting the next epoch. It should typically\n                be equal to the number of unique samples of your dataset\n                divided by the batch size. Not used if using `Sequence`.\n            epochs: Integer, total number of iterations on the data.\n            verbose: Verbosity mode, 0, 1, or 2.\n            callbacks: List of callbacks to be called during training.\n            validation_data: This can be either\n                - a generator for the validation data\n                - a tuple (inputs, targets)\n                - a tuple (inputs, targets, sample_weights).\n            validation_steps: Only relevant if `validation_data`\n                is a generator. Total number of steps (batches of samples)\n                to yield from `generator` before stopping.\n            class_weight: Dictionary mapping class indices to a weight\n                for the class.\n            max_queue_size: Maximum size for the generator queue\n            workers: Maximum number of processes to spin up\n                when using process based threading\n            use_multiprocessing: If True, use process based threading.\n                Note that because\n                this implementation relies on multiprocessing,\n                you should not pass\n                non picklable arguments to the generator\n                as they can't be passed\n                easily to children processes.\n            shuffle: Whether to shuffle the order of the batches at\n                the beginning of each epoch. Only used with instances\n                of `Sequence` (keras.utils.Sequence).\n            initial_epoch: Epoch at which to start training\n                (useful for resuming a previous training run)\n\n        # Returns\n            A `History` object.\n\n        # Example\n\n        ```python\n            def generate_arrays_from_file(path):\n                while 1:\n                    f = open(path)\n                    for line in f:\n                        # create numpy arrays of input data\n                        # and labels, from each line in the file\n                        x1, x2, y = process_line(line)\n                        yield ({'input_1': x1, 'input_2': x2}, {'output': y})\n                    f.close()\n\n            model.fit_generator(generate_arrays_from_file('/my_file.txt'),\n                                steps_per_epoch=10000, epochs=10)\n        ```\n\n        # Raises\n            ValueError: In case the generator yields\n                data in an invalid format.\n        \"\"\"\n        wait_time = 0.01  # in seconds\n        epoch = initial_epoch\n\n        do_validation = bool(validation_data)\n        self._make_train_function()\n        if do_validation:\n            self._make_test_function()\n\n        # python 2 has 'next', 3 has '__next__'\n        # avoid any explicit version checks\n        val_gen = (hasattr(validation_data, 'next') or\n                   hasattr(validation_data, '__next__') or\n                   isinstance(validation_data, Sequence))\n        if val_gen and not validation_steps:\n            raise ValueError('When using a generator for validation data, '\n                             'you must specify a value for '\n                             '`validation_steps`.')\n\n        # Prepare display labels.\n        out_labels = self._get_deduped_metrics_names()\n        callback_metrics = out_labels + ['val_' + n for n in out_labels]\n\n        # prepare callbacks\n        self.history = cbks.History()\n        callbacks = [cbks.BaseLogger()] + (callbacks or []) + [self.history]\n        if verbose:\n            callbacks += [cbks.ProgbarLogger(count_mode='steps')]\n        callbacks = cbks.CallbackList(callbacks)\n\n        # it's possible to callback a different model than self:\n        if hasattr(self, 'callback_model') and self.callback_model:\n            callback_model = self.callback_model\n        else:\n            callback_model = self\n        callbacks.set_model(callback_model)\n        callbacks.set_params({\n            'epochs': epochs,\n            'steps': steps_per_epoch,\n            'verbose': verbose,\n            'do_validation': do_validation,\n            'metrics': callback_metrics,\n        })\n        callbacks.on_train_begin()\n\n        if do_validation and not val_gen:\n            if len(validation_data) == 2:\n                val_x, val_y = validation_data\n                val_sample_weight = None\n            elif len(validation_data) == 3:\n                val_x, val_y, val_sample_weight = validation_data\n            else:\n                raise ValueError('`validation_data` should be a tuple '\n                                 '`(val_x, val_y, val_sample_weight)` '\n                                 'or `(val_x, val_y)`. Found: ' +\n                                 str(validation_data))\n            val_x, val_y, val_sample_weights = self._standardize_user_data(\n                val_x, val_y, val_sample_weight)\n            val_data = val_x + val_y + val_sample_weights\n            if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n                val_data += [0.]\n            for cbk in callbacks:\n                cbk.validation_data = val_data\n        is_sequence = isinstance(generator, Sequence)\n        if not is_sequence and use_multiprocessing and workers > 1:\n            warnings.warn(\n                UserWarning('Using a generator with `use_multiprocessing=True`'\n                            ' and multiple workers may duplicate your data.'\n                            ' Please consider using the`keras.utils.Sequence'\n                            ' class.'))\n        if is_sequence:\n            steps_per_epoch = len(generator)\n        enqueuer = None\n\n        try:\n            if is_sequence:\n                enqueuer = OrderedEnqueuer(generator,\n                                           use_multiprocessing=use_multiprocessing,\n                                           shuffle=shuffle)\n            else:\n                enqueuer = GeneratorEnqueuer(generator,\n                                             use_multiprocessing=use_multiprocessing,\n                                             wait_time=wait_time)\n            enqueuer.start(workers=workers, max_queue_size=max_queue_size)\n            output_generator = enqueuer.get()\n\n            callback_model.stop_training = False\n            while epoch < epochs:\n                callbacks.on_epoch_begin(epoch)\n                steps_done = 0\n                batch_index = 0\n                while steps_done < steps_per_epoch:\n                    generator_output = next(output_generator)\n\n                    if not hasattr(generator_output, '__len__'):\n                        raise ValueError('Output of generator should be '\n                                         'a tuple `(x, y, sample_weight)` '\n                                         'or `(x, y)`. Found: ' +\n                                         str(generator_output))\n                    if len(generator_output) == 2:\n                        x, y = generator_output\n                        sample_weight = None\n                    elif len(generator_output) == 3:\n                        x, y, sample_weight = generator_output\n                    else:\n                        raise ValueError('Output of generator should be '\n                                         'a tuple `(x, y, sample_weight)` '\n                                         'or `(x, y)`. Found: ' +\n                                         str(generator_output))\n                    # build batch logs\n                    batch_logs = {}\n                    if isinstance(x, list):\n                        batch_size = x[0].shape[0]\n                    elif isinstance(x, dict):\n                        batch_size = list(x.values())[0].shape[0]\n                    else:\n                        batch_size = x.shape[0]\n                    batch_logs['batch'] = batch_index\n                    batch_logs['size'] = batch_size\n                    callbacks.on_batch_begin(batch_index, batch_logs)\n\n                    outs = self.train_on_batch(x, y,\n                                               sample_weight=sample_weight,\n                                               class_weight=class_weight)\n\n                    if not isinstance(outs, list):\n                        outs = [outs]\n                    for l, o in zip(out_labels, outs):\n                        batch_logs[l] = o\n\n                    callbacks.on_batch_end(batch_index, batch_logs)\n\n                    # Construct epoch logs.\n                    epoch_logs = {}\n                    batch_index += 1\n                    steps_done += 1\n\n                    # Epoch finished.\n                    if steps_done >= steps_per_epoch and do_validation:\n                        if val_gen:\n                            val_outs = self.evaluate_generator(\n                                validation_data,\n                                validation_steps,\n                                max_queue_size=max_queue_size,\n                                workers=workers,\n                                use_multiprocessing=use_multiprocessing)\n                        else:\n                            # No need for try/except because\n                            # data has already been validated.\n                            val_outs = self.evaluate(\n                                val_x, val_y,\n                                batch_size=batch_size,\n                                sample_weight=val_sample_weights,\n                                verbose=0)\n                        if not isinstance(val_outs, list):\n                            val_outs = [val_outs]\n                        # Same labels assumed.\n                        for l, o in zip(out_labels, val_outs):\n                            epoch_logs['val_' + l] = o\n\n                    if callback_model.stop_training:\n                        break\n\n                callbacks.on_epoch_end(epoch, epoch_logs)\n                epoch += 1\n                if callback_model.stop_training:\n                    break\n\n        finally:\n            if enqueuer is not None:\n                enqueuer.stop()\n\n        callbacks.on_train_end()\n        return self.history",
        "begin_line": 1866,
        "end_line": 2129,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training.Model.evaluate_generator#2132",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model.evaluate_generator(self, generator, steps, max_queue_size=10, workers=1, use_multiprocessing=False)",
        "snippet": "    def evaluate_generator(self, generator, steps,\n                           max_queue_size=10,\n                           workers=1,\n                           use_multiprocessing=False):\n        \"\"\"Evaluates the model on a data generator.\n\n        The generator should return the same kind of data\n        as accepted by `test_on_batch`.\n\n        # Arguments\n            generator: Generator yielding tuples (inputs, targets)\n                or (inputs, targets, sample_weights)\n                or an instance of Sequence (keras.utils.Sequence)\n                    object in order to avoid duplicate data\n                    when using multiprocessing.\n            steps: Total number of steps (batches of samples)\n                to yield from `generator` before stopping.\n                Not used if using Sequence.\n            max_queue_size: maximum size for the generator queue\n            workers: maximum number of processes to spin up\n                when using process based threading\n            use_multiprocessing: if True, use process based threading.\n                Note that because\n                this implementation relies on multiprocessing,\n                you should not pass\n                non picklable arguments to the generator\n                as they can't be passed\n                easily to children processes.\n\n        # Returns\n            Scalar test loss (if the model has a single output and no metrics)\n            or list of scalars (if the model has multiple outputs\n            and/or metrics). The attribute `model.metrics_names` will give you\n            the display labels for the scalar outputs.\n\n        # Raises\n            ValueError: In case the generator yields\n                data in an invalid format.\n        \"\"\"\n        self._make_test_function()\n\n        steps_done = 0\n        wait_time = 0.01\n        all_outs = []\n        batch_sizes = []\n        is_sequence = isinstance(generator, Sequence)\n        if not is_sequence and use_multiprocessing and workers > 1:\n            warnings.warn(\n                UserWarning('Using a generator with `use_multiprocessing=True`'\n                            ' and multiple workers may duplicate your data.'\n                            ' Please consider using the`keras.utils.Sequence'\n                            ' class.'))\n        if is_sequence:\n            steps = len(generator)\n        enqueuer = None\n\n        try:\n            if is_sequence:\n                enqueuer = OrderedEnqueuer(generator,\n                                           use_multiprocessing=use_multiprocessing)\n            else:\n                enqueuer = GeneratorEnqueuer(generator,\n                                             use_multiprocessing=use_multiprocessing,\n                                             wait_time=wait_time)\n            enqueuer.start(workers=workers, max_queue_size=max_queue_size)\n            output_generator = enqueuer.get()\n\n            while steps_done < steps:\n                generator_output = next(output_generator)\n                if not hasattr(generator_output, '__len__'):\n                    raise ValueError('Output of generator should be a tuple '\n                                     '(x, y, sample_weight) '\n                                     'or (x, y). Found: ' +\n                                     str(generator_output))\n                if len(generator_output) == 2:\n                    x, y = generator_output\n                    sample_weight = None\n                elif len(generator_output) == 3:\n                    x, y, sample_weight = generator_output\n                else:\n                    raise ValueError('Output of generator should be a tuple '\n                                     '(x, y, sample_weight) '\n                                     'or (x, y). Found: ' +\n                                     str(generator_output))\n                outs = self.test_on_batch(x, y, sample_weight=sample_weight)\n\n                if isinstance(x, list):\n                    batch_size = len(x[0])\n                elif isinstance(x, dict):\n                    batch_size = len(list(x.values())[0])\n                else:\n                    batch_size = len(x)\n                if batch_size == 0:\n                    raise ValueError('Received an empty batch. '\n                                     'Batches should at least contain one item.')\n                all_outs.append(outs)\n\n                steps_done += 1\n                batch_sizes.append(batch_size)\n\n        finally:\n            if enqueuer is not None:\n                enqueuer.stop()\n\n        if not isinstance(outs, list):\n            return np.average(np.asarray(all_outs),\n                              weights=batch_sizes)\n        else:\n            averages = []\n            for i in range(len(outs)):\n                averages.append(np.average([out[i] for out in all_outs],\n                                           weights=batch_sizes))\n            return averages",
        "begin_line": 2132,
        "end_line": 2244,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.training.Model.predict_generator#2247",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model.predict_generator(self, generator, steps, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)",
        "snippet": "    def predict_generator(self, generator, steps,\n                          max_queue_size=10,\n                          workers=1,\n                          use_multiprocessing=False,\n                          verbose=0):\n        \"\"\"Generates predictions for the input samples from a data generator.\n\n        The generator should return the same kind of data as accepted by\n        `predict_on_batch`.\n\n        # Arguments\n            generator: Generator yielding batches of input samples\n                    or an instance of Sequence (keras.utils.Sequence)\n                    object in order to avoid duplicate data\n                    when using multiprocessing.\n            steps: Total number of steps (batches of samples)\n                to yield from `generator` before stopping.\n                Not used if using Sequence.\n            max_queue_size: Maximum size for the generator queue.\n            workers: Maximum number of processes to spin up\n                when using process based threading\n            use_multiprocessing: If `True`, use process based threading.\n                Note that because\n                this implementation relies on multiprocessing,\n                you should not pass\n                non picklable arguments to the generator\n                as they can't be passed\n                easily to children processes.\n            verbose: verbosity mode, 0 or 1.\n\n        # Returns\n            Numpy array(s) of predictions.\n\n        # Raises\n            ValueError: In case the generator yields\n                data in an invalid format.\n        \"\"\"\n        self._make_predict_function()\n\n        steps_done = 0\n        wait_time = 0.01\n        all_outs = []\n        is_sequence = isinstance(generator, Sequence)\n        if not is_sequence and use_multiprocessing and workers > 1:\n            warnings.warn(\n                UserWarning('Using a generator with `use_multiprocessing=True`'\n                            ' and multiple workers may duplicate your data.'\n                            ' Please consider using the`keras.utils.Sequence'\n                            ' class.'))\n        if is_sequence:\n            steps = len(generator)\n        enqueuer = None\n\n        try:\n            if is_sequence:\n                enqueuer = OrderedEnqueuer(generator,\n                                           use_multiprocessing=use_multiprocessing)\n            else:\n                enqueuer = GeneratorEnqueuer(generator,\n                                             use_multiprocessing=use_multiprocessing,\n                                             wait_time=wait_time)\n            enqueuer.start(workers=workers, max_queue_size=max_queue_size)\n            output_generator = enqueuer.get()\n\n            if verbose == 1:\n                progbar = Progbar(target=steps)\n\n            while steps_done < steps:\n                generator_output = next(output_generator)\n                if isinstance(generator_output, tuple):\n                    # Compatibility with the generators\n                    # used for training.\n                    if len(generator_output) == 2:\n                        x, _ = generator_output\n                    elif len(generator_output) == 3:\n                        x, _, _ = generator_output\n                    else:\n                        raise ValueError('Output of generator should be '\n                                         'a tuple `(x, y, sample_weight)` '\n                                         'or `(x, y)`. Found: ' +\n                                         str(generator_output))\n                else:\n                    # Assumes a generator that only\n                    # yields inputs (not targets and sample weights).\n                    x = generator_output\n\n                outs = self.predict_on_batch(x)\n                if not isinstance(outs, list):\n                    outs = [outs]\n\n                if not all_outs:\n                    for out in outs:\n                        all_outs.append([])\n\n                for i, out in enumerate(outs):\n                    all_outs[i].append(out)\n                steps_done += 1\n                if verbose == 1:\n                    progbar.update(steps_done)\n\n        finally:\n            if enqueuer is not None:\n                enqueuer.stop()\n\n        if len(all_outs) == 1:\n            if steps_done == 1:\n                return all_outs[0][0]\n            else:\n                return np.concatenate(all_outs[0])\n        if steps_done == 1:\n            return [out for out in all_outs]\n        else:\n            return [np.concatenate(out) for out in all_outs]",
        "begin_line": 2247,
        "end_line": 2359,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.np_utils.to_categorical#7",
        "src_path": "keras/utils/np_utils.py",
        "class_name": "keras.utils.np_utils",
        "signature": "keras.utils.np_utils.to_categorical(y, num_classes=None)",
        "snippet": "def to_categorical(y, num_classes=None):\n    \"\"\"Converts a class vector (integers) to binary class matrix.\n\n    E.g. for use with categorical_crossentropy.\n\n    # Arguments\n        y: class vector to be converted into a matrix\n            (integers from 0 to num_classes).\n        num_classes: total number of classes.\n\n    # Returns\n        A binary matrix representation of the input.\n    \"\"\"\n    y = np.array(y, dtype='int').ravel()\n    if not num_classes:\n        num_classes = np.max(y) + 1\n    n = y.shape[0]\n    categorical = np.zeros((n, num_classes))\n    categorical[np.arange(n), y] = 1\n    return categorical",
        "begin_line": 7,
        "end_line": 26,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.889240506329114e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional._Conv.__init__#83",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional._Conv",
        "signature": "keras.layers.convolutional._Conv.__init__(self, rank, filters, kernel_size, strides=1, padding='valid', data_format=None, dilation_rate=1, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)",
        "snippet": "    def __init__(self, rank,\n                 filters,\n                 kernel_size,\n                 strides=1,\n                 padding='valid',\n                 data_format=None,\n                 dilation_rate=1,\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(_Conv, self).__init__(**kwargs)\n        self.rank = rank\n        self.filters = filters\n        self.kernel_size = conv_utils.normalize_tuple(kernel_size, rank, 'kernel_size')\n        self.strides = conv_utils.normalize_tuple(strides, rank, 'strides')\n        self.padding = conv_utils.normalize_padding(padding)\n        self.data_format = conv_utils.normalize_data_format(data_format)\n        self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, rank, 'dilation_rate')\n        self.activation = activations.get(activation)\n        self.use_bias = use_bias\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n        self.input_spec = InputSpec(ndim=self.rank + 2)",
        "begin_line": 83,
        "end_line": 117,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.675858732462506e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional._Conv.build#119",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional._Conv",
        "signature": "keras.layers.convolutional._Conv.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        if self.data_format == 'channels_first':\n            channel_axis = 1\n        else:\n            channel_axis = -1\n        if input_shape[channel_axis] is None:\n            raise ValueError('The channel dimension of the inputs '\n                             'should be defined. Found `None`.')\n        input_dim = input_shape[channel_axis]\n        kernel_shape = self.kernel_size + (input_dim, self.filters)\n\n        self.kernel = self.add_weight(shape=kernel_shape,\n                                      initializer=self.kernel_initializer,\n                                      name='kernel',\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(self.filters,),\n                                        initializer=self.bias_initializer,\n                                        name='bias',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        # Set input spec.\n        self.input_spec = InputSpec(ndim=self.rank + 2,\n                                    axes={channel_axis: input_dim})\n        self.built = True",
        "begin_line": 119,
        "end_line": 146,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional._Conv.call#148",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional._Conv",
        "signature": "keras.layers.convolutional._Conv.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        if self.rank == 1:\n            outputs = K.conv1d(\n                inputs,\n                self.kernel,\n                strides=self.strides[0],\n                padding=self.padding,\n                data_format=self.data_format,\n                dilation_rate=self.dilation_rate[0])\n        if self.rank == 2:\n            outputs = K.conv2d(\n                inputs,\n                self.kernel,\n                strides=self.strides,\n                padding=self.padding,\n                data_format=self.data_format,\n                dilation_rate=self.dilation_rate)\n        if self.rank == 3:\n            outputs = K.conv3d(\n                inputs,\n                self.kernel,\n                strides=self.strides,\n                padding=self.padding,\n                data_format=self.data_format,\n                dilation_rate=self.dilation_rate)\n\n        if self.use_bias:\n            outputs = K.bias_add(\n                outputs,\n                self.bias,\n                data_format=self.data_format)\n\n        if self.activation is not None:\n            return self.activation(outputs)\n        return outputs",
        "begin_line": 148,
        "end_line": 182,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional._Conv.compute_output_shape#184",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional._Conv",
        "signature": "keras.layers.convolutional._Conv.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self.data_format == 'channels_last':\n            space = input_shape[1:-1]\n            new_space = []\n            for i in range(len(space)):\n                new_dim = conv_utils.conv_output_length(\n                    space[i],\n                    self.kernel_size[i],\n                    padding=self.padding,\n                    stride=self.strides[i],\n                    dilation=self.dilation_rate[i])\n                new_space.append(new_dim)\n            return (input_shape[0],) + tuple(new_space) + (self.filters,)\n        if self.data_format == 'channels_first':\n            space = input_shape[2:]\n            new_space = []\n            for i in range(len(space)):\n                new_dim = conv_utils.conv_output_length(\n                    space[i],\n                    self.kernel_size[i],\n                    padding=self.padding,\n                    stride=self.strides[i],\n                    dilation=self.dilation_rate[i])\n                new_space.append(new_dim)\n            return (input_shape[0], self.filters) + tuple(new_space)",
        "begin_line": 184,
        "end_line": 208,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional._Conv.get_config#210",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional._Conv",
        "signature": "keras.layers.convolutional._Conv.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {\n            'rank': self.rank,\n            'filters': self.filters,\n            'kernel_size': self.kernel_size,\n            'strides': self.strides,\n            'padding': self.padding,\n            'data_format': self.data_format,\n            'dilation_rate': self.dilation_rate,\n            'activation': activations.serialize(self.activation),\n            'use_bias': self.use_bias,\n            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n            'bias_initializer': initializers.serialize(self.bias_initializer),\n            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n            'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n            'bias_constraint': constraints.serialize(self.bias_constraint)\n        }\n        base_config = super(_Conv, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 210,
        "end_line": 230,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010630381630700542,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.Conv1D.__init__#301",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv1D",
        "signature": "keras.layers.convolutional.Conv1D.__init__(self, filters, kernel_size, strides=1, padding='valid', dilation_rate=1, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)",
        "snippet": "    def __init__(self, filters,\n                 kernel_size,\n                 strides=1,\n                 padding='valid',\n                 dilation_rate=1,\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(Conv1D, self).__init__(\n            rank=1,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=padding,\n            data_format='channels_last',\n            dilation_rate=dilation_rate,\n            activation=activation,\n            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            kernel_constraint=kernel_constraint,\n            bias_constraint=bias_constraint,\n            **kwargs)\n        self.input_spec = InputSpec(ndim=3)",
        "begin_line": 301,
        "end_line": 334,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.Conv1D.get_config#336",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv1D",
        "signature": "keras.layers.convolutional.Conv1D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = super(Conv1D, self).get_config()\n        config.pop('rank')\n        config.pop('data_format')\n        return config",
        "begin_line": 336,
        "end_line": 340,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.Conv2D.__init__#425",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv2D",
        "signature": "keras.layers.convolutional.Conv2D.__init__(self, filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)",
        "snippet": "    def __init__(self, filters,\n                 kernel_size,\n                 strides=(1, 1),\n                 padding='valid',\n                 data_format=None,\n                 dilation_rate=(1, 1),\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(Conv2D, self).__init__(\n            rank=2,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=padding,\n            data_format=data_format,\n            dilation_rate=dilation_rate,\n            activation=activation,\n            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            kernel_constraint=kernel_constraint,\n            bias_constraint=bias_constraint,\n            **kwargs)\n        self.input_spec = InputSpec(ndim=4)",
        "begin_line": 425,
        "end_line": 459,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.770395701025892e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.Conv2D.get_config#461",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv2D",
        "signature": "keras.layers.convolutional.Conv2D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = super(Conv2D, self).get_config()\n        config.pop('rank')\n        return config",
        "begin_line": 461,
        "end_line": 464,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011147029316687103,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.Conv3D.__init__#550",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv3D",
        "signature": "keras.layers.convolutional.Conv3D.__init__(self, filters, kernel_size, strides=(1, 1, 1), padding='valid', data_format=None, dilation_rate=(1, 1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)",
        "snippet": "    def __init__(self, filters,\n                 kernel_size,\n                 strides=(1, 1, 1),\n                 padding='valid',\n                 data_format=None,\n                 dilation_rate=(1, 1, 1),\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(Conv3D, self).__init__(\n            rank=3,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=padding,\n            data_format=data_format,\n            dilation_rate=dilation_rate,\n            activation=activation,\n            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            kernel_constraint=kernel_constraint,\n            bias_constraint=bias_constraint,\n            **kwargs)\n        self.input_spec = InputSpec(ndim=5)",
        "begin_line": 550,
        "end_line": 584,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.Conv3D.get_config#586",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv3D",
        "signature": "keras.layers.convolutional.Conv3D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = super(Conv3D, self).get_config()\n        config.pop('rank')\n        return config",
        "begin_line": 586,
        "end_line": 589,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.Conv2DTranspose.__init__#679",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv2DTranspose",
        "signature": "keras.layers.convolutional.Conv2DTranspose.__init__(self, filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)",
        "snippet": "    def __init__(self, filters,\n                 kernel_size,\n                 strides=(1, 1),\n                 padding='valid',\n                 data_format=None,\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(Conv2DTranspose, self).__init__(\n            filters,\n            kernel_size,\n            strides=strides,\n            padding=padding,\n            data_format=data_format,\n            activation=activation,\n            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            kernel_constraint=kernel_constraint,\n            bias_constraint=bias_constraint,\n            **kwargs)\n        self.input_spec = InputSpec(ndim=4)",
        "begin_line": 679,
        "end_line": 710,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.Conv2DTranspose.build#712",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv2DTranspose",
        "signature": "keras.layers.convolutional.Conv2DTranspose.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        if len(input_shape) != 4:\n            raise ValueError('Inputs should have rank ' +\n                             str(4) +\n                             '; Received input shape:', str(input_shape))\n        if self.data_format == 'channels_first':\n            channel_axis = 1\n        else:\n            channel_axis = -1\n        if input_shape[channel_axis] is None:\n            raise ValueError('The channel dimension of the inputs '\n                             'should be defined. Found `None`.')\n        input_dim = input_shape[channel_axis]\n        kernel_shape = self.kernel_size + (self.filters, input_dim)\n\n        self.kernel = self.add_weight(shape=kernel_shape,\n                                      initializer=self.kernel_initializer,\n                                      name='kernel',\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(self.filters,),\n                                        initializer=self.bias_initializer,\n                                        name='bias',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        # Set input spec.\n        self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})\n        self.built = True",
        "begin_line": 712,
        "end_line": 742,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.Conv2DTranspose.call#744",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv2DTranspose",
        "signature": "keras.layers.convolutional.Conv2DTranspose.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        input_shape = K.shape(inputs)\n        batch_size = input_shape[0]\n        if self.data_format == 'channels_first':\n            h_axis, w_axis = 2, 3\n        else:\n            h_axis, w_axis = 1, 2\n\n        height, width = input_shape[h_axis], input_shape[w_axis]\n        kernel_h, kernel_w = self.kernel_size\n        stride_h, stride_w = self.strides\n\n        # Infer the dynamic output shape:\n        out_height = conv_utils.deconv_length(height,\n                                              stride_h, kernel_h,\n                                              self.padding)\n        out_width = conv_utils.deconv_length(width,\n                                             stride_w, kernel_w,\n                                             self.padding)\n        if self.data_format == 'channels_first':\n            output_shape = (batch_size, self.filters, out_height, out_width)\n        else:\n            output_shape = (batch_size, out_height, out_width, self.filters)\n\n        outputs = K.conv2d_transpose(\n            inputs,\n            self.kernel,\n            output_shape,\n            self.strides,\n            padding=self.padding,\n            data_format=self.data_format)\n\n        if self.bias:\n            outputs = K.bias_add(\n                outputs,\n                self.bias,\n                data_format=self.data_format)\n\n        if self.activation is not None:\n            return self.activation(outputs)\n        return outputs",
        "begin_line": 744,
        "end_line": 784,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.Conv2DTranspose.compute_output_shape#786",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv2DTranspose",
        "signature": "keras.layers.convolutional.Conv2DTranspose.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        output_shape = list(input_shape)\n        if self.data_format == 'channels_first':\n            c_axis, h_axis, w_axis = 1, 2, 3\n        else:\n            c_axis, h_axis, w_axis = 3, 1, 2\n\n        kernel_h, kernel_w = self.kernel_size\n        stride_h, stride_w = self.strides\n\n        output_shape[c_axis] = self.filters\n        output_shape[h_axis] = conv_utils.deconv_length(\n            output_shape[h_axis], stride_h, kernel_h, self.padding)\n        output_shape[w_axis] = conv_utils.deconv_length(\n            output_shape[w_axis], stride_w, kernel_w, self.padding)\n        return tuple(output_shape)",
        "begin_line": 786,
        "end_line": 801,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.Conv2DTranspose.get_config#803",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv2DTranspose",
        "signature": "keras.layers.convolutional.Conv2DTranspose.get_config(self)",
        "snippet": "    def get_config(self):\n        config = super(Conv2DTranspose, self).get_config()\n        config.pop('dilation_rate')\n        return config",
        "begin_line": 803,
        "end_line": 806,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.Conv3DTranspose.__init__#895",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv3DTranspose",
        "signature": "keras.layers.convolutional.Conv3DTranspose.__init__(self, filters, kernel_size, strides=(1, 1, 1), padding='valid', data_format=None, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)",
        "snippet": "    def __init__(self, filters,\n                 kernel_size,\n                 strides=(1, 1, 1),\n                 padding='valid',\n                 data_format=None,\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(Conv3DTranspose, self).__init__(\n            filters,\n            kernel_size,\n            strides=strides,\n            padding=padding,\n            data_format=data_format,\n            activation=activation,\n            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            kernel_constraint=kernel_constraint,\n            bias_constraint=bias_constraint,\n            **kwargs)\n        self.input_spec = InputSpec(ndim=5)",
        "begin_line": 895,
        "end_line": 926,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.Conv3DTranspose.build#928",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv3DTranspose",
        "signature": "keras.layers.convolutional.Conv3DTranspose.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        if len(input_shape) != 5:\n            raise ValueError('Inputs should have rank ' +\n                             str(5) +\n                             '; Received input shape:', str(input_shape))\n        if self.data_format == 'channels_first':\n            channel_axis = 1\n        else:\n            channel_axis = -1\n        if input_shape[channel_axis] is None:\n            raise ValueError('The channel dimension of the inputs '\n                             'should be defined. Found `None`.')\n        input_dim = input_shape[channel_axis]\n        kernel_shape = self.kernel_size + (self.filters, input_dim)\n\n        self.kernel = self.add_weight(shape=kernel_shape,\n                                      initializer=self.kernel_initializer,\n                                      name='kernel',\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(self.filters,),\n                                        initializer=self.bias_initializer,\n                                        name='bias',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        # Set input spec.\n        self.input_spec = InputSpec(ndim=5, axes={channel_axis: input_dim})\n        self.built = True",
        "begin_line": 928,
        "end_line": 958,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.Conv3DTranspose.call#960",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv3DTranspose",
        "signature": "keras.layers.convolutional.Conv3DTranspose.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        input_shape = K.shape(inputs)\n        batch_size = input_shape[0]\n        if self.data_format == 'channels_first':\n            d_axis, h_axis, w_axis = 2, 3, 4\n        else:\n            d_axis, h_axis, w_axis = 1, 2, 3\n\n        depth = input_shape[d_axis]\n        height = input_shape[h_axis]\n        width = input_shape[w_axis]\n\n        kernel_d, kernel_h, kernel_w = self.kernel_size\n        stride_d, stride_h, stride_w = self.strides\n\n        # Infer the dynamic output shape:\n        out_depth = conv_utils.deconv_length(depth,\n                                             stride_d, kernel_d,\n                                             self.padding)\n        out_height = conv_utils.deconv_length(height,\n                                              stride_h, kernel_h,\n                                              self.padding)\n        out_width = conv_utils.deconv_length(width,\n                                             stride_w, kernel_w,\n                                             self.padding)\n\n        if self.data_format == 'channels_first':\n            output_shape = (batch_size, self.filters, out_depth, out_height, out_width)\n        else:\n            output_shape = (batch_size, out_depth, out_height, out_width, self.filters)\n\n        outputs = K.conv3d_transpose(inputs,\n                                     self.kernel,\n                                     output_shape,\n                                     self.strides,\n                                     padding=self.padding,\n                                     data_format=self.data_format)\n\n        if self.bias:\n            outputs = K.bias_add(\n                outputs,\n                self.bias,\n                data_format=self.data_format)\n\n        if self.activation is not None:\n            return self.activation(outputs)\n        return outputs",
        "begin_line": 960,
        "end_line": 1006,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.Conv3DTranspose.compute_output_shape#1008",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv3DTranspose",
        "signature": "keras.layers.convolutional.Conv3DTranspose.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        output_shape = list(input_shape)\n        if self.data_format == 'channels_first':\n            c_axis, d_axis, h_axis, w_axis = 1, 2, 3, 4\n        else:\n            c_axis, d_axis, h_axis, w_axis = 4, 1, 2, 3\n\n        kernel_d, kernel_h, kernel_w = self.kernel_size\n        stride_d, stride_h, stride_w = self.strides\n\n        output_shape[c_axis] = self.filters\n        output_shape[d_axis] = conv_utils.deconv_length(output_shape[d_axis],\n                                                        stride_d,\n                                                        kernel_d,\n                                                        self.padding)\n        output_shape[h_axis] = conv_utils.deconv_length(output_shape[h_axis],\n                                                        stride_h,\n                                                        kernel_h,\n                                                        self.padding)\n        output_shape[w_axis] = conv_utils.deconv_length(output_shape[w_axis],\n                                                        stride_w,\n                                                        kernel_w,\n                                                        self.padding)\n\n        return tuple(output_shape)",
        "begin_line": 1008,
        "end_line": 1032,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.Conv3DTranspose.get_config#1034",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv3DTranspose",
        "signature": "keras.layers.convolutional.Conv3DTranspose.get_config(self)",
        "snippet": "    def get_config(self):\n        config = super(Conv3DTranspose, self).get_config()\n        config.pop('dilation_rate')\n        return config",
        "begin_line": 1034,
        "end_line": 1037,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.SeparableConv2D.__init__#1128",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.SeparableConv2D",
        "signature": "keras.layers.convolutional.SeparableConv2D.__init__(self, filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, depth_multiplier=1, activation=None, use_bias=True, depthwise_initializer='glorot_uniform', pointwise_initializer='glorot_uniform', bias_initializer='zeros', depthwise_regularizer=None, pointwise_regularizer=None, bias_regularizer=None, activity_regularizer=None, depthwise_constraint=None, pointwise_constraint=None, bias_constraint=None, **kwargs)",
        "snippet": "    def __init__(self, filters,\n                 kernel_size,\n                 strides=(1, 1),\n                 padding='valid',\n                 data_format=None,\n                 depth_multiplier=1,\n                 activation=None,\n                 use_bias=True,\n                 depthwise_initializer='glorot_uniform',\n                 pointwise_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n                 depthwise_regularizer=None,\n                 pointwise_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 depthwise_constraint=None,\n                 pointwise_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(SeparableConv2D, self).__init__(\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=padding,\n            data_format=data_format,\n            activation=activation,\n            use_bias=use_bias,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            bias_constraint=bias_constraint,\n            **kwargs)\n        self.depth_multiplier = depth_multiplier\n        self.depthwise_initializer = initializers.get(depthwise_initializer)\n        self.pointwise_initializer = initializers.get(pointwise_initializer)\n        self.depthwise_regularizer = regularizers.get(depthwise_regularizer)\n        self.pointwise_regularizer = regularizers.get(pointwise_regularizer)\n        self.depthwise_constraint = constraints.get(depthwise_constraint)\n        self.pointwise_constraint = constraints.get(pointwise_constraint)",
        "begin_line": 1128,
        "end_line": 1165,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.SeparableConv2D.build#1167",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.SeparableConv2D",
        "signature": "keras.layers.convolutional.SeparableConv2D.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        if len(input_shape) < 4:\n            raise ValueError('Inputs to `SeparableConv2D` should have rank 4. '\n                             'Received input shape:', str(input_shape))\n        if self.data_format == 'channels_first':\n            channel_axis = 1\n        else:\n            channel_axis = 3\n        if input_shape[channel_axis] is None:\n            raise ValueError('The channel dimension of the inputs to '\n                             '`SeparableConv2D` '\n                             'should be defined. Found `None`.')\n        input_dim = int(input_shape[channel_axis])\n        depthwise_kernel_shape = (self.kernel_size[0],\n                                  self.kernel_size[1],\n                                  input_dim,\n                                  self.depth_multiplier)\n        pointwise_kernel_shape = (1, 1,\n                                  self.depth_multiplier * input_dim,\n                                  self.filters)\n\n        self.depthwise_kernel = self.add_weight(\n            shape=depthwise_kernel_shape,\n            initializer=self.depthwise_initializer,\n            name='depthwise_kernel',\n            regularizer=self.depthwise_regularizer,\n            constraint=self.depthwise_constraint)\n        self.pointwise_kernel = self.add_weight(\n            shape=pointwise_kernel_shape,\n            initializer=self.pointwise_initializer,\n            name='pointwise_kernel',\n            regularizer=self.pointwise_regularizer,\n            constraint=self.pointwise_constraint)\n\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(self.filters,),\n                                        initializer=self.bias_initializer,\n                                        name='bias',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        # Set input spec.\n        self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})\n        self.built = True",
        "begin_line": 1167,
        "end_line": 1211,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.SeparableConv2D.call#1213",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.SeparableConv2D",
        "signature": "keras.layers.convolutional.SeparableConv2D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        outputs = K.separable_conv2d(\n            inputs,\n            self.depthwise_kernel,\n            self.pointwise_kernel,\n            data_format=self.data_format,\n            strides=self.strides,\n            padding=self.padding,\n            dilation_rate=self.dilation_rate)\n\n        if self.bias:\n            outputs = K.bias_add(\n                outputs,\n                self.bias,\n                data_format=self.data_format)\n\n        if self.activation is not None:\n            return self.activation(outputs)\n        return outputs",
        "begin_line": 1213,
        "end_line": 1231,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.SeparableConv2D.get_config#1233",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.SeparableConv2D",
        "signature": "keras.layers.convolutional.SeparableConv2D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = super(SeparableConv2D, self).get_config()\n        config.pop('kernel_initializer')\n        config.pop('kernel_regularizer')\n        config.pop('kernel_constraint')\n        config['depth_multiplier'] = self.depth_multiplier\n        config['depthwise_initializer'] = initializers.serialize(self.depthwise_initializer)\n        config['pointwise_initializer'] = initializers.serialize(self.pointwise_initializer)\n        config['depthwise_regularizer'] = regularizers.serialize(self.depthwise_regularizer)\n        config['pointwise_regularizer'] = regularizers.serialize(self.pointwise_regularizer)\n        config['depthwise_constraint'] = constraints.serialize(self.depthwise_constraint)\n        config['pointwise_constraint'] = constraints.serialize(self.pointwise_constraint)\n        return config",
        "begin_line": 1233,
        "end_line": 1245,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.UpSampling1D.__init__#1264",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.UpSampling1D",
        "signature": "keras.layers.convolutional.UpSampling1D.__init__(self, size=2, **kwargs)",
        "snippet": "    def __init__(self, size=2, **kwargs):\n        super(UpSampling1D, self).__init__(**kwargs)\n        self.size = int(size)\n        self.input_spec = InputSpec(ndim=3)",
        "begin_line": 1264,
        "end_line": 1267,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.UpSampling1D.compute_output_shape#1269",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.UpSampling1D",
        "signature": "keras.layers.convolutional.UpSampling1D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        size = self.size * input_shape[1] if input_shape[1] is not None else None\n        return (input_shape[0], size, input_shape[2])",
        "begin_line": 1269,
        "end_line": 1271,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.UpSampling1D.call#1273",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.UpSampling1D",
        "signature": "keras.layers.convolutional.UpSampling1D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        output = K.repeat_elements(inputs, self.size, axis=1)\n        return output",
        "begin_line": 1273,
        "end_line": 1275,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.UpSampling1D.get_config#1277",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.UpSampling1D",
        "signature": "keras.layers.convolutional.UpSampling1D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'size': self.size}\n        base_config = super(UpSampling1D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 1277,
        "end_line": 1280,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.UpSampling2D.__init__#1319",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.UpSampling2D",
        "signature": "keras.layers.convolutional.UpSampling2D.__init__(self, size=(2, 2), data_format=None, **kwargs)",
        "snippet": "    def __init__(self, size=(2, 2), data_format=None, **kwargs):\n        super(UpSampling2D, self).__init__(**kwargs)\n        self.data_format = conv_utils.normalize_data_format(data_format)\n        self.size = conv_utils.normalize_tuple(size, 2, 'size')\n        self.input_spec = InputSpec(ndim=4)",
        "begin_line": 1319,
        "end_line": 1323,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.UpSampling2D.compute_output_shape#1325",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.UpSampling2D",
        "signature": "keras.layers.convolutional.UpSampling2D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self.data_format == 'channels_first':\n            height = self.size[0] * input_shape[2] if input_shape[2] is not None else None\n            width = self.size[1] * input_shape[3] if input_shape[3] is not None else None\n            return (input_shape[0],\n                    input_shape[1],\n                    height,\n                    width)\n        elif self.data_format == 'channels_last':\n            height = self.size[0] * input_shape[1] if input_shape[1] is not None else None\n            width = self.size[1] * input_shape[2] if input_shape[2] is not None else None\n            return (input_shape[0],\n                    height,\n                    width,\n                    input_shape[3])",
        "begin_line": 1325,
        "end_line": 1339,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.UpSampling2D.call#1341",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.UpSampling2D",
        "signature": "keras.layers.convolutional.UpSampling2D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        return K.resize_images(inputs, self.size[0], self.size[1],\n                               self.data_format)",
        "begin_line": 1341,
        "end_line": 1343,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.UpSampling2D.get_config#1345",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.UpSampling2D",
        "signature": "keras.layers.convolutional.UpSampling2D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'size': self.size,\n                  'data_format': self.data_format}\n        base_config = super(UpSampling2D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 1345,
        "end_line": 1349,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.UpSampling3D.__init__#1388",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.UpSampling3D",
        "signature": "keras.layers.convolutional.UpSampling3D.__init__(self, size=(2, 2, 2), data_format=None, **kwargs)",
        "snippet": "    def __init__(self, size=(2, 2, 2), data_format=None, **kwargs):\n        self.data_format = conv_utils.normalize_data_format(data_format)\n        self.size = conv_utils.normalize_tuple(size, 3, 'size')\n        self.input_spec = InputSpec(ndim=5)\n        super(UpSampling3D, self).__init__(**kwargs)",
        "begin_line": 1388,
        "end_line": 1392,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.UpSampling3D.compute_output_shape#1394",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.UpSampling3D",
        "signature": "keras.layers.convolutional.UpSampling3D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self.data_format == 'channels_first':\n            dim1 = self.size[0] * input_shape[2] if input_shape[2] is not None else None\n            dim2 = self.size[1] * input_shape[3] if input_shape[3] is not None else None\n            dim3 = self.size[2] * input_shape[4] if input_shape[4] is not None else None\n            return (input_shape[0],\n                    input_shape[1],\n                    dim1,\n                    dim2,\n                    dim3)\n        elif self.data_format == 'channels_last':\n            dim1 = self.size[0] * input_shape[1] if input_shape[1] is not None else None\n            dim2 = self.size[1] * input_shape[2] if input_shape[2] is not None else None\n            dim3 = self.size[2] * input_shape[3] if input_shape[3] is not None else None\n            return (input_shape[0],\n                    dim1,\n                    dim2,\n                    dim3,\n                    input_shape[4])",
        "begin_line": 1394,
        "end_line": 1412,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.UpSampling3D.call#1414",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.UpSampling3D",
        "signature": "keras.layers.convolutional.UpSampling3D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        return K.resize_volumes(inputs,\n                                self.size[0], self.size[1], self.size[2],\n                                self.data_format)",
        "begin_line": 1414,
        "end_line": 1417,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.UpSampling3D.get_config#1419",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.UpSampling3D",
        "signature": "keras.layers.convolutional.UpSampling3D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'size': self.size,\n                  'data_format': self.data_format}\n        base_config = super(UpSampling3D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 1419,
        "end_line": 1423,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.ZeroPadding1D.__init__#1445",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.ZeroPadding1D",
        "signature": "keras.layers.convolutional.ZeroPadding1D.__init__(self, padding=1, **kwargs)",
        "snippet": "    def __init__(self, padding=1, **kwargs):\n        super(ZeroPadding1D, self).__init__(**kwargs)\n        self.padding = conv_utils.normalize_tuple(padding, 2, 'padding')\n        self.input_spec = InputSpec(ndim=3)",
        "begin_line": 1445,
        "end_line": 1448,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.ZeroPadding1D.compute_output_shape#1450",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.ZeroPadding1D",
        "signature": "keras.layers.convolutional.ZeroPadding1D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if input_shape[1] is not None:\n            length = input_shape[1] + self.padding[0] + self.padding[1]\n        else:\n            length = None\n        return (input_shape[0],\n                length,\n                input_shape[2])",
        "begin_line": 1450,
        "end_line": 1457,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.ZeroPadding1D.call#1459",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.ZeroPadding1D",
        "signature": "keras.layers.convolutional.ZeroPadding1D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        return K.temporal_padding(inputs, padding=self.padding)",
        "begin_line": 1459,
        "end_line": 1460,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.ZeroPadding1D.get_config#1462",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.ZeroPadding1D",
        "signature": "keras.layers.convolutional.ZeroPadding1D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'padding': self.padding}\n        base_config = super(ZeroPadding1D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 1462,
        "end_line": 1465,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.ZeroPadding2D.__init__#1512",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.ZeroPadding2D",
        "signature": "keras.layers.convolutional.ZeroPadding2D.__init__(self, padding=(1, 1), data_format=None, **kwargs)",
        "snippet": "    def __init__(self,\n                 padding=(1, 1),\n                 data_format=None,\n                 **kwargs):\n        super(ZeroPadding2D, self).__init__(**kwargs)\n        self.data_format = conv_utils.normalize_data_format(data_format)\n        if isinstance(padding, int):\n            self.padding = ((padding, padding), (padding, padding))\n        elif hasattr(padding, '__len__'):\n            if len(padding) != 2:\n                raise ValueError('`padding` should have two elements. '\n                                 'Found: ' + str(padding))\n            height_padding = conv_utils.normalize_tuple(padding[0], 2,\n                                                        '1st entry of padding')\n            width_padding = conv_utils.normalize_tuple(padding[1], 2,\n                                                       '2nd entry of padding')\n            self.padding = (height_padding, width_padding)\n        else:\n            raise ValueError('`padding` should be either an int, '\n                             'a tuple of 2 ints '\n                             '(symmetric_height_pad, symmetric_width_pad), '\n                             'or a tuple of 2 tuples of 2 ints '\n                             '((top_pad, bottom_pad), (left_pad, right_pad)). '\n                             'Found: ' + str(padding))\n        self.input_spec = InputSpec(ndim=4)",
        "begin_line": 1512,
        "end_line": 1536,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.ZeroPadding2D.compute_output_shape#1538",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.ZeroPadding2D",
        "signature": "keras.layers.convolutional.ZeroPadding2D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self.data_format == 'channels_first':\n            if input_shape[2] is not None:\n                rows = input_shape[2] + self.padding[0][0] + self.padding[0][1]\n            else:\n                rows = None\n            if input_shape[3] is not None:\n                cols = input_shape[3] + self.padding[1][0] + self.padding[1][1]\n            else:\n                cols = None\n            return (input_shape[0],\n                    input_shape[1],\n                    rows,\n                    cols)\n        elif self.data_format == 'channels_last':\n            if input_shape[1] is not None:\n                rows = input_shape[1] + self.padding[0][0] + self.padding[0][1]\n            else:\n                rows = None\n            if input_shape[2] is not None:\n                cols = input_shape[2] + self.padding[1][0] + self.padding[1][1]\n            else:\n                cols = None\n            return (input_shape[0],\n                    rows,\n                    cols,\n                    input_shape[3])",
        "begin_line": 1538,
        "end_line": 1564,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.ZeroPadding2D.call#1566",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.ZeroPadding2D",
        "signature": "keras.layers.convolutional.ZeroPadding2D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        return K.spatial_2d_padding(inputs,\n                                    padding=self.padding,\n                                    data_format=self.data_format)",
        "begin_line": 1566,
        "end_line": 1569,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.ZeroPadding2D.get_config#1571",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.ZeroPadding2D",
        "signature": "keras.layers.convolutional.ZeroPadding2D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'padding': self.padding,\n                  'data_format': self.data_format}\n        base_config = super(ZeroPadding2D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 1571,
        "end_line": 1575,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.ZeroPadding3D.__init__#1619",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.ZeroPadding3D",
        "signature": "keras.layers.convolutional.ZeroPadding3D.__init__(self, padding=(1, 1, 1), data_format=None, **kwargs)",
        "snippet": "    def __init__(self, padding=(1, 1, 1), data_format=None, **kwargs):\n        super(ZeroPadding3D, self).__init__(**kwargs)\n        self.data_format = conv_utils.normalize_data_format(data_format)\n        if isinstance(padding, int):\n            self.padding = ((padding, padding), (padding, padding), (padding, padding))\n        elif hasattr(padding, '__len__'):\n            if len(padding) != 3:\n                raise ValueError('`padding` should have 3 elements. '\n                                 'Found: ' + str(padding))\n            dim1_padding = conv_utils.normalize_tuple(padding[0], 2,\n                                                      '1st entry of padding')\n            dim2_padding = conv_utils.normalize_tuple(padding[1], 2,\n                                                      '2nd entry of padding')\n            dim3_padding = conv_utils.normalize_tuple(padding[2], 2,\n                                                      '3rd entry of padding')\n            self.padding = (dim1_padding, dim2_padding, dim3_padding)\n        else:\n            raise ValueError('`padding` should be either an int, '\n                             'a tuple of 3 ints '\n                             '(symmetric_dim1_pad, symmetric_dim2_pad, symmetric_dim3_pad), '\n                             'or a tuple of 3 tuples of 2 ints '\n                             '((left_dim1_pad, right_dim1_pad),'\n                             ' (left_dim2_pad, right_dim2_pad),'\n                             ' (left_dim3_pad, right_dim2_pad)). '\n                             'Found: ' + str(padding))\n        self.input_spec = InputSpec(ndim=5)",
        "begin_line": 1619,
        "end_line": 1644,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.ZeroPadding3D.compute_output_shape#1646",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.ZeroPadding3D",
        "signature": "keras.layers.convolutional.ZeroPadding3D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self.data_format == 'channels_first':\n            if input_shape[2] is not None:\n                dim1 = input_shape[2] + self.padding[0][0] + self.padding[0][1]\n            else:\n                dim1 = None\n            if input_shape[3] is not None:\n                dim2 = input_shape[3] + self.padding[1][0] + self.padding[1][1]\n            else:\n                dim2 = None\n            if input_shape[4] is not None:\n                dim3 = input_shape[4] + self.padding[2][0] + self.padding[2][1]\n            else:\n                dim3 = None\n            return (input_shape[0],\n                    input_shape[1],\n                    dim1,\n                    dim2,\n                    dim3)\n        elif self.data_format == 'channels_last':\n            if input_shape[1] is not None:\n                dim1 = input_shape[1] + self.padding[0][0] + self.padding[0][1]\n            else:\n                dim1 = None\n            if input_shape[2] is not None:\n                dim2 = input_shape[2] + self.padding[1][0] + self.padding[1][1]\n            else:\n                dim2 = None\n            if input_shape[3] is not None:\n                dim3 = input_shape[3] + self.padding[2][0] + self.padding[2][1]\n            else:\n                dim3 = None\n            return (input_shape[0],\n                    dim1,\n                    dim2,\n                    dim3,\n                    input_shape[4])",
        "begin_line": 1646,
        "end_line": 1682,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.ZeroPadding3D.call#1684",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.ZeroPadding3D",
        "signature": "keras.layers.convolutional.ZeroPadding3D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        return K.spatial_3d_padding(inputs,\n                                    padding=self.padding,\n                                    data_format=self.data_format)",
        "begin_line": 1684,
        "end_line": 1687,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.ZeroPadding3D.get_config#1689",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.ZeroPadding3D",
        "signature": "keras.layers.convolutional.ZeroPadding3D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'padding': self.padding,\n                  'data_format': self.data_format}\n        base_config = super(ZeroPadding3D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 1689,
        "end_line": 1693,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.Cropping1D.__init__#1715",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Cropping1D",
        "signature": "keras.layers.convolutional.Cropping1D.__init__(self, cropping=(1, 1), **kwargs)",
        "snippet": "    def __init__(self, cropping=(1, 1), **kwargs):\n        super(Cropping1D, self).__init__(**kwargs)\n        self.cropping = conv_utils.normalize_tuple(cropping, 2, 'cropping')\n        self.input_spec = InputSpec(ndim=3)",
        "begin_line": 1715,
        "end_line": 1718,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.Cropping1D.compute_output_shape#1720",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Cropping1D",
        "signature": "keras.layers.convolutional.Cropping1D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if input_shape[1] is not None:\n            length = input_shape[1] - self.cropping[0] - self.cropping[1]\n        else:\n            length = None\n        return (input_shape[0],\n                length,\n                input_shape[2])",
        "begin_line": 1720,
        "end_line": 1727,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.Cropping1D.call#1729",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Cropping1D",
        "signature": "keras.layers.convolutional.Cropping1D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        if self.cropping[1] == 0:\n            return inputs[:, self.cropping[0]:, :]\n        else:\n            return inputs[:, self.cropping[0]: -self.cropping[1], :]",
        "begin_line": 1729,
        "end_line": 1733,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.Cropping1D.get_config#1735",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Cropping1D",
        "signature": "keras.layers.convolutional.Cropping1D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'cropping': self.cropping}\n        base_config = super(Cropping1D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 1735,
        "end_line": 1738,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.Cropping2D.__init__#1797",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Cropping2D",
        "signature": "keras.layers.convolutional.Cropping2D.__init__(self, cropping=((0, 0), (0, 0)), data_format=None, **kwargs)",
        "snippet": "    def __init__(self, cropping=((0, 0), (0, 0)),\n                 data_format=None, **kwargs):\n        super(Cropping2D, self).__init__(**kwargs)\n        self.data_format = conv_utils.normalize_data_format(data_format)\n        if isinstance(cropping, int):\n            self.cropping = ((cropping, cropping), (cropping, cropping))\n        elif hasattr(cropping, '__len__'):\n            if len(cropping) != 2:\n                raise ValueError('`cropping` should have two elements. '\n                                 'Found: ' + str(cropping))\n            height_cropping = conv_utils.normalize_tuple(\n                cropping[0], 2,\n                '1st entry of cropping')\n            width_cropping = conv_utils.normalize_tuple(\n                cropping[1], 2,\n                '2nd entry of cropping')\n            self.cropping = (height_cropping, width_cropping)\n        else:\n            raise ValueError('`cropping` should be either an int, '\n                             'a tuple of 2 ints '\n                             '(symmetric_height_crop, symmetric_width_crop), '\n                             'or a tuple of 2 tuples of 2 ints '\n                             '((top_crop, bottom_crop), (left_crop, right_crop)). '\n                             'Found: ' + str(cropping))\n        self.input_spec = InputSpec(ndim=4)",
        "begin_line": 1797,
        "end_line": 1821,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.Cropping2D.compute_output_shape#1823",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Cropping2D",
        "signature": "keras.layers.convolutional.Cropping2D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self.data_format == 'channels_first':\n            return (input_shape[0],\n                    input_shape[1],\n                    input_shape[2] - self.cropping[0][0] - self.cropping[0][1] if input_shape[2] else None,\n                    input_shape[3] - self.cropping[1][0] - self.cropping[1][1] if input_shape[3] else None)\n        elif self.data_format == 'channels_last':\n            return (input_shape[0],\n                    input_shape[1] - self.cropping[0][0] - self.cropping[0][1] if input_shape[1] else None,\n                    input_shape[2] - self.cropping[1][0] - self.cropping[1][1] if input_shape[2] else None,\n                    input_shape[3])",
        "begin_line": 1823,
        "end_line": 1833,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.Cropping2D.call#1835",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Cropping2D",
        "signature": "keras.layers.convolutional.Cropping2D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        if self.data_format == 'channels_first':\n            if self.cropping[0][1] == self.cropping[1][1] == 0:\n                return inputs[:,\n                              :,\n                              self.cropping[0][0]:,\n                              self.cropping[1][0]:]\n            elif self.cropping[0][1] == 0:\n                return inputs[:,\n                              :,\n                              self.cropping[0][0]:,\n                              self.cropping[1][0]: -self.cropping[1][1]]\n            elif self.cropping[1][1] == 0:\n                return inputs[:,\n                              :,\n                              self.cropping[0][0]: -self.cropping[0][1],\n                              self.cropping[1][0]:]\n            return inputs[:,\n                          :,\n                          self.cropping[0][0]: -self.cropping[0][1],\n                          self.cropping[1][0]: -self.cropping[1][1]]\n        elif self.data_format == 'channels_last':\n            if self.cropping[0][1] == self.cropping[1][1] == 0:\n                return inputs[:,\n                              self.cropping[0][0]:,\n                              self.cropping[1][0]:,\n                              :]\n            elif self.cropping[0][1] == 0:\n                return inputs[:,\n                              self.cropping[0][0]:,\n                              self.cropping[1][0]: -self.cropping[1][1],\n                              :]\n            elif self.cropping[1][1] == 0:\n                return inputs[:,\n                              self.cropping[0][0]: -self.cropping[0][1],\n                              self.cropping[1][0]:,\n                              :]\n            return inputs[:,\n                          self.cropping[0][0]: -self.cropping[0][1],\n                          self.cropping[1][0]: -self.cropping[1][1],\n                          :]",
        "begin_line": 1835,
        "end_line": 1875,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.Cropping2D.get_config#1877",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Cropping2D",
        "signature": "keras.layers.convolutional.Cropping2D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'cropping': self.cropping,\n                  'data_format': self.data_format}\n        base_config = super(Cropping2D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 1877,
        "end_line": 1881,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.Cropping3D.__init__#1925",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Cropping3D",
        "signature": "keras.layers.convolutional.Cropping3D.__init__(self, cropping=((1, 1), (1, 1), (1, 1)), data_format=None, **kwargs)",
        "snippet": "    def __init__(self, cropping=((1, 1), (1, 1), (1, 1)),\n                 data_format=None, **kwargs):\n        super(Cropping3D, self).__init__(**kwargs)\n        self.data_format = conv_utils.normalize_data_format(data_format)\n        if isinstance(cropping, int):\n            self.cropping = ((cropping, cropping),\n                             (cropping, cropping),\n                             (cropping, cropping))\n        elif hasattr(cropping, '__len__'):\n            if len(cropping) != 3:\n                raise ValueError('`cropping` should have 3 elements. '\n                                 'Found: ' + str(cropping))\n            dim1_cropping = conv_utils.normalize_tuple(cropping[0], 2,\n                                                       '1st entry of cropping')\n            dim2_cropping = conv_utils.normalize_tuple(cropping[1], 2,\n                                                       '2nd entry of cropping')\n            dim3_cropping = conv_utils.normalize_tuple(cropping[2], 2,\n                                                       '3rd entry of cropping')\n            self.cropping = (dim1_cropping, dim2_cropping, dim3_cropping)\n        else:\n            raise ValueError('`cropping` should be either an int, '\n                             'a tuple of 3 ints '\n                             '(symmetric_dim1_crop, symmetric_dim2_crop, symmetric_dim3_crop), '\n                             'or a tuple of 3 tuples of 2 ints '\n                             '((left_dim1_crop, right_dim1_crop),'\n                             ' (left_dim2_crop, right_dim2_crop),'\n                             ' (left_dim3_crop, right_dim2_crop)). '\n                             'Found: ' + str(cropping))\n        self.input_spec = InputSpec(ndim=5)",
        "begin_line": 1925,
        "end_line": 1953,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.Cropping3D.compute_output_shape#1955",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Cropping3D",
        "signature": "keras.layers.convolutional.Cropping3D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self.data_format == 'channels_first':\n            if input_shape[2] is not None:\n                dim1 = input_shape[2] - self.cropping[0][0] - self.cropping[0][1]\n            else:\n                dim1 = None\n            if input_shape[3] is not None:\n                dim2 = input_shape[3] - self.cropping[1][0] - self.cropping[1][1]\n            else:\n                dim2 = None\n            if input_shape[4] is not None:\n                dim3 = input_shape[4] - self.cropping[2][0] - self.cropping[2][1]\n            else:\n                dim3 = None\n            return (input_shape[0],\n                    input_shape[1],\n                    dim1,\n                    dim2,\n                    dim3)\n        elif self.data_format == 'channels_last':\n            if input_shape[1] is not None:\n                dim1 = input_shape[1] - self.cropping[0][0] - self.cropping[0][1]\n            else:\n                dim1 = None\n            if input_shape[2] is not None:\n                dim2 = input_shape[2] - self.cropping[1][0] - self.cropping[1][1]\n            else:\n                dim2 = None\n            if input_shape[3] is not None:\n                dim3 = input_shape[3] - self.cropping[2][0] - self.cropping[2][1]\n            else:\n                dim3 = None\n            return (input_shape[0],\n                    dim1,\n                    dim2,\n                    dim3,\n                    input_shape[4])",
        "begin_line": 1955,
        "end_line": 1991,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.Cropping3D.call#1993",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Cropping3D",
        "signature": "keras.layers.convolutional.Cropping3D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        if self.data_format == 'channels_first':\n            if self.cropping[0][1] == self.cropping[1][1] == self.cropping[2][1] == 0:\n                return inputs[:,\n                              :,\n                              self.cropping[0][0]:,\n                              self.cropping[1][0]:,\n                              self.cropping[2][0]:]\n            elif self.cropping[0][1] == self.cropping[1][1] == 0:\n                return inputs[:,\n                              :,\n                              self.cropping[0][0]:,\n                              self.cropping[1][0]:,\n                              self.cropping[2][0]: -self.cropping[2][1]]\n            elif self.cropping[1][1] == self.cropping[2][1] == 0:\n                return inputs[:,\n                              :,\n                              self.cropping[0][0]: -self.cropping[0][1],\n                              self.cropping[1][0]:,\n                              self.cropping[2][0]:]\n            elif self.cropping[0][1] == self.cropping[2][1] == 0:\n                return inputs[:,\n                              :,\n                              self.cropping[0][0]:,\n                              self.cropping[1][0]: -self.cropping[1][1],\n                              self.cropping[2][0]:]\n            elif self.cropping[0][1] == 0:\n                return inputs[:,\n                              :,\n                              self.cropping[0][0]:,\n                              self.cropping[1][0]: -self.cropping[1][1],\n                              self.cropping[2][0]: -self.cropping[2][1]]\n            elif self.cropping[1][1] == 0:\n                return inputs[:,\n                              :,\n                              self.cropping[0][0]: -self.cropping[0][1],\n                              self.cropping[1][0]:,\n                              self.cropping[2][0]: -self.cropping[2][1]]\n            elif self.cropping[2][1] == 0:\n                return inputs[:,\n                              :,\n                              self.cropping[0][0]: -self.cropping[0][1],\n                              self.cropping[1][0]: -self.cropping[1][1],\n                              self.cropping[2][0]:]\n            return inputs[:,\n                          :,\n                          self.cropping[0][0]: -self.cropping[0][1],\n                          self.cropping[1][0]: -self.cropping[1][1],\n                          self.cropping[2][0]: -self.cropping[2][1]]\n\n        elif self.data_format == 'channels_last':\n            if self.cropping[0][1] == self.cropping[1][1] == self.cropping[2][1] == 0:\n                return inputs[:,\n                              self.cropping[0][0]:,\n                              self.cropping[1][0]:,\n                              self.cropping[2][0]:,\n                              :]\n            elif self.cropping[0][1] == self.cropping[1][1] == 0:\n                return inputs[:,\n                              self.cropping[0][0]:,\n                              self.cropping[1][0]:,\n                              self.cropping[2][0]: -self.cropping[2][1],\n                              :]\n            elif self.cropping[1][1] == self.cropping[2][1] == 0:\n                return inputs[:,\n                              self.cropping[0][0]: -self.cropping[0][1],\n                              self.cropping[1][0]:,\n                              self.cropping[2][0]:,\n                              :]\n            elif self.cropping[0][1] == self.cropping[2][1] == 0:\n                return inputs[:,\n                              self.cropping[0][0]:,\n                              self.cropping[1][0]:-self.cropping[1][1],\n                              self.cropping[2][0]:,\n                              :]\n            elif self.cropping[0][1] == 0:\n                return inputs[:,\n                              self.cropping[0][0]:,\n                              self.cropping[1][0]: -self.cropping[1][1],\n                              self.cropping[2][0]: -self.cropping[2][1],\n                              :]\n            elif self.cropping[1][1] == 0:\n                return inputs[:,\n                              self.cropping[0][0]: -self.cropping[0][1],\n                              self.cropping[1][0]:,\n                              self.cropping[2][0]: -self.cropping[2][1],\n                              :]\n            elif self.cropping[2][1] == 0:\n                return inputs[:,\n                              self.cropping[0][0]: -self.cropping[0][1],\n                              self.cropping[1][0]: -self.cropping[1][1],\n                              self.cropping[2][0]:,\n                              :]\n            return inputs[:,\n                          self.cropping[0][0]: -self.cropping[0][1],\n                          self.cropping[1][0]: -self.cropping[1][1],\n                          self.cropping[2][0]: -self.cropping[2][1],\n                          :]",
        "begin_line": 1993,
        "end_line": 2090,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.convolutional.Cropping3D.get_config#2092",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Cropping3D",
        "signature": "keras.layers.convolutional.Cropping3D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'cropping': self.cropping,\n                  'data_format': self.data_format}\n        base_config = super(Cropping3D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 2092,
        "end_line": 2096,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image.random_rotation#44",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image",
        "signature": "keras.preprocessing.image.random_rotation(x, rg, row_axis=1, col_axis=2, channel_axis=0, fill_mode='nearest', cval=0.0)",
        "snippet": "def random_rotation(x, rg, row_axis=1, col_axis=2, channel_axis=0,\n                    fill_mode='nearest', cval=0.):\n    \"\"\"Performs a random rotation of a Numpy image tensor.\n\n    # Arguments\n        x: Input tensor. Must be 3D.\n        rg: Rotation range, in degrees.\n        row_axis: Index of axis for rows in the input tensor.\n        col_axis: Index of axis for columns in the input tensor.\n        channel_axis: Index of axis for channels in the input tensor.\n        fill_mode: Points outside the boundaries of the input\n            are filled according to the given mode\n            (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).\n        cval: Value used for points outside the boundaries\n            of the input if `mode='constant'`.\n\n    # Returns\n        Rotated Numpy image tensor.\n    \"\"\"\n    theta = np.pi / 180 * np.random.uniform(-rg, rg)\n    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n                                [np.sin(theta), np.cos(theta), 0],\n                                [0, 0, 1]])\n\n    h, w = x.shape[row_axis], x.shape[col_axis]\n    transform_matrix = transform_matrix_offset_center(rotation_matrix, h, w)\n    x = apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)\n    return x",
        "begin_line": 44,
        "end_line": 71,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image.random_shift#74",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image",
        "signature": "keras.preprocessing.image.random_shift(x, wrg, hrg, row_axis=1, col_axis=2, channel_axis=0, fill_mode='nearest', cval=0.0)",
        "snippet": "def random_shift(x, wrg, hrg, row_axis=1, col_axis=2, channel_axis=0,\n                 fill_mode='nearest', cval=0.):\n    \"\"\"Performs a random spatial shift of a Numpy image tensor.\n\n    # Arguments\n        x: Input tensor. Must be 3D.\n        wrg: Width shift range, as a float fraction of the width.\n        hrg: Height shift range, as a float fraction of the height.\n        row_axis: Index of axis for rows in the input tensor.\n        col_axis: Index of axis for columns in the input tensor.\n        channel_axis: Index of axis for channels in the input tensor.\n        fill_mode: Points outside the boundaries of the input\n            are filled according to the given mode\n            (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).\n        cval: Value used for points outside the boundaries\n            of the input if `mode='constant'`.\n\n    # Returns\n        Shifted Numpy image tensor.\n    \"\"\"\n    h, w = x.shape[row_axis], x.shape[col_axis]\n    tx = np.random.uniform(-hrg, hrg) * h\n    ty = np.random.uniform(-wrg, wrg) * w\n    translation_matrix = np.array([[1, 0, tx],\n                                   [0, 1, ty],\n                                   [0, 0, 1]])\n\n    transform_matrix = translation_matrix  # no need to do offset\n    x = apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)\n    return x",
        "begin_line": 74,
        "end_line": 103,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image.random_shear#106",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image",
        "signature": "keras.preprocessing.image.random_shear(x, intensity, row_axis=1, col_axis=2, channel_axis=0, fill_mode='nearest', cval=0.0)",
        "snippet": "def random_shear(x, intensity, row_axis=1, col_axis=2, channel_axis=0,\n                 fill_mode='nearest', cval=0.):\n    \"\"\"Performs a random spatial shear of a Numpy image tensor.\n\n    # Arguments\n        x: Input tensor. Must be 3D.\n        intensity: Transformation intensity.\n        row_axis: Index of axis for rows in the input tensor.\n        col_axis: Index of axis for columns in the input tensor.\n        channel_axis: Index of axis for channels in the input tensor.\n        fill_mode: Points outside the boundaries of the input\n            are filled according to the given mode\n            (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).\n        cval: Value used for points outside the boundaries\n            of the input if `mode='constant'`.\n\n    # Returns\n        Sheared Numpy image tensor.\n    \"\"\"\n    shear = np.random.uniform(-intensity, intensity)\n    shear_matrix = np.array([[1, -np.sin(shear), 0],\n                             [0, np.cos(shear), 0],\n                             [0, 0, 1]])\n\n    h, w = x.shape[row_axis], x.shape[col_axis]\n    transform_matrix = transform_matrix_offset_center(shear_matrix, h, w)\n    x = apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)\n    return x",
        "begin_line": 106,
        "end_line": 133,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image.random_zoom#136",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image",
        "signature": "keras.preprocessing.image.random_zoom(x, zoom_range, row_axis=1, col_axis=2, channel_axis=0, fill_mode='nearest', cval=0.0)",
        "snippet": "def random_zoom(x, zoom_range, row_axis=1, col_axis=2, channel_axis=0,\n                fill_mode='nearest', cval=0.):\n    \"\"\"Performs a random spatial zoom of a Numpy image tensor.\n\n    # Arguments\n        x: Input tensor. Must be 3D.\n        zoom_range: Tuple of floats; zoom range for width and height.\n        row_axis: Index of axis for rows in the input tensor.\n        col_axis: Index of axis for columns in the input tensor.\n        channel_axis: Index of axis for channels in the input tensor.\n        fill_mode: Points outside the boundaries of the input\n            are filled according to the given mode\n            (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).\n        cval: Value used for points outside the boundaries\n            of the input if `mode='constant'`.\n\n    # Returns\n        Zoomed Numpy image tensor.\n\n    # Raises\n        ValueError: if `zoom_range` isn't a tuple.\n    \"\"\"\n    if len(zoom_range) != 2:\n        raise ValueError('`zoom_range` should be a tuple or list of two floats. '\n                         'Received arg: ', zoom_range)\n\n    if zoom_range[0] == 1 and zoom_range[1] == 1:\n        zx, zy = 1, 1\n    else:\n        zx, zy = np.random.uniform(zoom_range[0], zoom_range[1], 2)\n    zoom_matrix = np.array([[zx, 0, 0],\n                            [0, zy, 0],\n                            [0, 0, 1]])\n\n    h, w = x.shape[row_axis], x.shape[col_axis]\n    transform_matrix = transform_matrix_offset_center(zoom_matrix, h, w)\n    x = apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)\n    return x",
        "begin_line": 136,
        "end_line": 173,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image.random_channel_shift#176",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image",
        "signature": "keras.preprocessing.image.random_channel_shift(x, intensity, channel_axis=0)",
        "snippet": "def random_channel_shift(x, intensity, channel_axis=0):\n    x = np.rollaxis(x, channel_axis, 0)\n    min_x, max_x = np.min(x), np.max(x)\n    channel_images = [np.clip(x_channel + np.random.uniform(-intensity, intensity), min_x, max_x)\n                      for x_channel in x]\n    x = np.stack(channel_images, axis=0)\n    x = np.rollaxis(x, 0, channel_axis + 1)\n    return x",
        "begin_line": 176,
        "end_line": 183,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image.transform_matrix_offset_center#186",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image",
        "signature": "keras.preprocessing.image.transform_matrix_offset_center(matrix, x, y)",
        "snippet": "def transform_matrix_offset_center(matrix, x, y):\n    o_x = float(x) / 2 + 0.5\n    o_y = float(y) / 2 + 0.5\n    offset_matrix = np.array([[1, 0, o_x], [0, 1, o_y], [0, 0, 1]])\n    reset_matrix = np.array([[1, 0, -o_x], [0, 1, -o_y], [0, 0, 1]])\n    transform_matrix = np.dot(np.dot(offset_matrix, matrix), reset_matrix)\n    return transform_matrix",
        "begin_line": 186,
        "end_line": 192,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image.apply_transform#195",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image",
        "signature": "keras.preprocessing.image.apply_transform(x, transform_matrix, channel_axis=0, fill_mode='nearest', cval=0.0)",
        "snippet": "def apply_transform(x,\n                    transform_matrix,\n                    channel_axis=0,\n                    fill_mode='nearest',\n                    cval=0.):\n    \"\"\"Apply the image transformation specified by a matrix.\n\n    # Arguments\n        x: 2D numpy array, single image.\n        transform_matrix: Numpy array specifying the geometric transformation.\n        channel_axis: Index of axis for channels in the input tensor.\n        fill_mode: Points outside the boundaries of the input\n            are filled according to the given mode\n            (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).\n        cval: Value used for points outside the boundaries\n            of the input if `mode='constant'`.\n\n    # Returns\n        The transformed version of the input.\n    \"\"\"\n    x = np.rollaxis(x, channel_axis, 0)\n    final_affine_matrix = transform_matrix[:2, :2]\n    final_offset = transform_matrix[:2, 2]\n    channel_images = [ndi.interpolation.affine_transform(\n        x_channel,\n        final_affine_matrix,\n        final_offset,\n        order=0,\n        mode=fill_mode,\n        cval=cval) for x_channel in x]\n    x = np.stack(channel_images, axis=0)\n    x = np.rollaxis(x, 0, channel_axis + 1)\n    return x",
        "begin_line": 195,
        "end_line": 227,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image.flip_axis#230",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image",
        "signature": "keras.preprocessing.image.flip_axis(x, axis)",
        "snippet": "def flip_axis(x, axis):\n    x = np.asarray(x).swapaxes(axis, 0)\n    x = x[::-1, ...]\n    x = x.swapaxes(0, axis)\n    return x",
        "begin_line": 230,
        "end_line": 234,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image.array_to_img#237",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image",
        "signature": "keras.preprocessing.image.array_to_img(x, data_format=None, scale=True)",
        "snippet": "def array_to_img(x, data_format=None, scale=True):\n    \"\"\"Converts a 3D Numpy array to a PIL Image instance.\n\n    # Arguments\n        x: Input Numpy array.\n        data_format: Image data format.\n        scale: Whether to rescale image values\n            to be within [0, 255].\n\n    # Returns\n        A PIL Image instance.\n\n    # Raises\n        ImportError: if PIL is not available.\n        ValueError: if invalid `x` or `data_format` is passed.\n    \"\"\"\n    if pil_image is None:\n        raise ImportError('Could not import PIL.Image. '\n                          'The use of `array_to_img` requires PIL.')\n    x = np.asarray(x, dtype=K.floatx())\n    if x.ndim != 3:\n        raise ValueError('Expected image array to have rank 3 (single image). '\n                         'Got array with shape:', x.shape)\n\n    if data_format is None:\n        data_format = K.image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Invalid data_format:', data_format)\n\n    # Original Numpy array x has format (height, width, channel)\n    # or (channel, height, width)\n    # but target PIL image has format (width, height, channel)\n    if data_format == 'channels_first':\n        x = x.transpose(1, 2, 0)\n    if scale:\n        x = x + max(-np.min(x), 0)\n        x_max = np.max(x)\n        if x_max != 0:\n            x /= x_max\n        x *= 255\n    if x.shape[2] == 3:\n        # RGB\n        return pil_image.fromarray(x.astype('uint8'), 'RGB')\n    elif x.shape[2] == 1:\n        # grayscale\n        return pil_image.fromarray(x[:, :, 0].astype('uint8'), 'L')\n    else:\n        raise ValueError('Unsupported channel number: ', x.shape[2])",
        "begin_line": 237,
        "end_line": 284,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image.img_to_array#287",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image",
        "signature": "keras.preprocessing.image.img_to_array(img, data_format=None)",
        "snippet": "def img_to_array(img, data_format=None):\n    \"\"\"Converts a PIL Image instance to a Numpy array.\n\n    # Arguments\n        img: PIL Image instance.\n        data_format: Image data format.\n\n    # Returns\n        A 3D Numpy array.\n\n    # Raises\n        ValueError: if invalid `img` or `data_format` is passed.\n    \"\"\"\n    if data_format is None:\n        data_format = K.image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format: ', data_format)\n    # Numpy array x has format (height, width, channel)\n    # or (channel, height, width)\n    # but original PIL image has format (width, height, channel)\n    x = np.asarray(img, dtype=K.floatx())\n    if len(x.shape) == 3:\n        if data_format == 'channels_first':\n            x = x.transpose(2, 0, 1)\n    elif len(x.shape) == 2:\n        if data_format == 'channels_first':\n            x = x.reshape((1, x.shape[0], x.shape[1]))\n        else:\n            x = x.reshape((x.shape[0], x.shape[1], 1))\n    else:\n        raise ValueError('Unsupported image shape: ', x.shape)\n    return x",
        "begin_line": 287,
        "end_line": 318,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image.load_img#321",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image",
        "signature": "keras.preprocessing.image.load_img(path, grayscale=False, target_size=None, interpolation='bilinear')",
        "snippet": "def load_img(path, grayscale=False, target_size=None,\n             interpolation='bilinear'):\n    \"\"\"Loads an image into PIL format.\n\n    # Arguments\n        path: Path to image file\n        grayscale: Boolean, whether to load the image as grayscale.\n        target_size: Either `None` (default to original size)\n            or tuple of ints `(img_height, img_width)`.\n        interpolation: Interpolation method used to resample the image if the\n            target size is different from that of the loaded image.\n            Supported methods are \"nearest\", \"bilinear\", and \"bicubic\".\n            If PIL version 1.1.3 or newer is installed, \"lanczos\" is also\n            supported. If PIL version 3.4.0 or newer is installed, \"box\" and\n            \"hamming\" are also supported. By default, \"bilinear\" is used.\n\n    # Returns\n        A PIL Image instance.\n\n    # Raises\n        ImportError: if PIL is not available.\n        ValueError: if interpolation method is not supported.\n    \"\"\"\n    if pil_image is None:\n        raise ImportError('Could not import PIL.Image. '\n                          'The use of `array_to_img` requires PIL.')\n    img = pil_image.open(path)\n    if grayscale:\n        if img.mode != 'L':\n            img = img.convert('L')\n    else:\n        if img.mode != 'RGB':\n            img = img.convert('RGB')\n    if target_size is not None:\n        width_height_tuple = (target_size[1], target_size[0])\n        if img.size != width_height_tuple:\n            if interpolation not in _PIL_INTERPOLATION_METHODS:\n                raise ValueError(\n                    'Invalid interpolation method {} specified. Supported '\n                    'methods are {}'.format(\n                        interpolation,\n                        \", \".join(_PIL_INTERPOLATION_METHODS.keys())))\n            resample = _PIL_INTERPOLATION_METHODS[interpolation]\n            img = img.resize(width_height_tuple, resample)\n    return img",
        "begin_line": 321,
        "end_line": 365,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image.ImageDataGenerator.__init__#415",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image.ImageDataGenerator",
        "signature": "keras.preprocessing.image.ImageDataGenerator.__init__(self, featurewise_center=False, samplewise_center=False, featurewise_std_normalization=False, samplewise_std_normalization=False, zca_whitening=False, zca_epsilon=1e-06, rotation_range=0.0, width_shift_range=0.0, height_shift_range=0.0, shear_range=0.0, zoom_range=0.0, channel_shift_range=0.0, fill_mode='nearest', cval=0.0, horizontal_flip=False, vertical_flip=False, rescale=None, preprocessing_function=None, data_format=None)",
        "snippet": "    def __init__(self,\n                 featurewise_center=False,\n                 samplewise_center=False,\n                 featurewise_std_normalization=False,\n                 samplewise_std_normalization=False,\n                 zca_whitening=False,\n                 zca_epsilon=1e-6,\n                 rotation_range=0.,\n                 width_shift_range=0.,\n                 height_shift_range=0.,\n                 shear_range=0.,\n                 zoom_range=0.,\n                 channel_shift_range=0.,\n                 fill_mode='nearest',\n                 cval=0.,\n                 horizontal_flip=False,\n                 vertical_flip=False,\n                 rescale=None,\n                 preprocessing_function=None,\n                 data_format=None):\n        if data_format is None:\n            data_format = K.image_data_format()\n        self.featurewise_center = featurewise_center\n        self.samplewise_center = samplewise_center\n        self.featurewise_std_normalization = featurewise_std_normalization\n        self.samplewise_std_normalization = samplewise_std_normalization\n        self.zca_whitening = zca_whitening\n        self.zca_epsilon = zca_epsilon\n        self.rotation_range = rotation_range\n        self.width_shift_range = width_shift_range\n        self.height_shift_range = height_shift_range\n        self.shear_range = shear_range\n        self.zoom_range = zoom_range\n        self.channel_shift_range = channel_shift_range\n        self.fill_mode = fill_mode\n        self.cval = cval\n        self.horizontal_flip = horizontal_flip\n        self.vertical_flip = vertical_flip\n        self.rescale = rescale\n        self.preprocessing_function = preprocessing_function\n\n        if data_format not in {'channels_last', 'channels_first'}:\n            raise ValueError('`data_format` should be `\"channels_last\"` (channel after row and '\n                             'column) or `\"channels_first\"` (channel before row and column). '\n                             'Received arg: ', data_format)\n        self.data_format = data_format\n        if data_format == 'channels_first':\n            self.channel_axis = 1\n            self.row_axis = 2\n            self.col_axis = 3\n        if data_format == 'channels_last':\n            self.channel_axis = 3\n            self.row_axis = 1\n            self.col_axis = 2\n\n        self.mean = None\n        self.std = None\n        self.principal_components = None\n\n        if np.isscalar(zoom_range):\n            self.zoom_range = [1 - zoom_range, 1 + zoom_range]\n        elif len(zoom_range) == 2:\n            self.zoom_range = [zoom_range[0], zoom_range[1]]\n        else:\n            raise ValueError('`zoom_range` should be a float or '\n                             'a tuple or list of two floats. '\n                             'Received arg: ', zoom_range)",
        "begin_line": 415,
        "end_line": 481,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image.ImageDataGenerator.flow#483",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image.ImageDataGenerator",
        "signature": "keras.preprocessing.image.ImageDataGenerator.flow(self, x, y=None, batch_size=32, shuffle=True, seed=None, save_to_dir=None, save_prefix='', save_format='png')",
        "snippet": "    def flow(self, x, y=None, batch_size=32, shuffle=True, seed=None,\n             save_to_dir=None, save_prefix='', save_format='png'):\n        return NumpyArrayIterator(\n            x, y, self,\n            batch_size=batch_size,\n            shuffle=shuffle,\n            seed=seed,\n            data_format=self.data_format,\n            save_to_dir=save_to_dir,\n            save_prefix=save_prefix,\n            save_format=save_format)",
        "begin_line": 483,
        "end_line": 493,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image.ImageDataGenerator.flow_from_directory#495",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image.ImageDataGenerator",
        "signature": "keras.preprocessing.image.ImageDataGenerator.flow_from_directory(self, directory, target_size=(256, 256), color_mode='rgb', classes=None, class_mode='categorical', batch_size=32, shuffle=True, seed=None, save_to_dir=None, save_prefix='', save_format='png', follow_links=False)",
        "snippet": "    def flow_from_directory(self, directory,\n                            target_size=(256, 256), color_mode='rgb',\n                            classes=None, class_mode='categorical',\n                            batch_size=32, shuffle=True, seed=None,\n                            save_to_dir=None,\n                            save_prefix='',\n                            save_format='png',\n                            follow_links=False):\n        return DirectoryIterator(\n            directory, self,\n            target_size=target_size, color_mode=color_mode,\n            classes=classes, class_mode=class_mode,\n            data_format=self.data_format,\n            batch_size=batch_size, shuffle=shuffle, seed=seed,\n            save_to_dir=save_to_dir,\n            save_prefix=save_prefix,\n            save_format=save_format,\n            follow_links=follow_links)",
        "begin_line": 495,
        "end_line": 512,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image.ImageDataGenerator.standardize#514",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image.ImageDataGenerator",
        "signature": "keras.preprocessing.image.ImageDataGenerator.standardize(self, x)",
        "snippet": "    def standardize(self, x):\n        \"\"\"Apply the normalization configuration to a batch of inputs.\n\n        # Arguments\n            x: batch of inputs to be normalized.\n\n        # Returns\n            The inputs, normalized.\n        \"\"\"\n        if self.preprocessing_function:\n            x = self.preprocessing_function(x)\n        if self.rescale:\n            x *= self.rescale\n        if self.samplewise_center:\n            x -= np.mean(x, keepdims=True)\n        if self.samplewise_std_normalization:\n            x /= np.std(x, keepdims=True) + 1e-7\n\n        if self.featurewise_center:\n            if self.mean is not None:\n                x -= self.mean\n            else:\n                warnings.warn('This ImageDataGenerator specifies '\n                              '`featurewise_center`, but it hasn\\'t'\n                              'been fit on any training data. Fit it '\n                              'first by calling `.fit(numpy_data)`.')\n        if self.featurewise_std_normalization:\n            if self.std is not None:\n                x /= (self.std + 1e-7)\n            else:\n                warnings.warn('This ImageDataGenerator specifies '\n                              '`featurewise_std_normalization`, but it hasn\\'t'\n                              'been fit on any training data. Fit it '\n                              'first by calling `.fit(numpy_data)`.')\n        if self.zca_whitening:\n            if self.principal_components is not None:\n                flatx = np.reshape(x, (-1, np.prod(x.shape[-3:])))\n                whitex = np.dot(flatx, self.principal_components)\n                x = np.reshape(whitex, x.shape)\n            else:\n                warnings.warn('This ImageDataGenerator specifies '\n                              '`zca_whitening`, but it hasn\\'t'\n                              'been fit on any training data. Fit it '\n                              'first by calling `.fit(numpy_data)`.')\n        return x",
        "begin_line": 514,
        "end_line": 558,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image.ImageDataGenerator.random_transform#560",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image.ImageDataGenerator",
        "signature": "keras.preprocessing.image.ImageDataGenerator.random_transform(self, x, seed=None)",
        "snippet": "    def random_transform(self, x, seed=None):\n        \"\"\"Randomly augment a single image tensor.\n\n        # Arguments\n            x: 3D tensor, single image.\n            seed: random seed.\n\n        # Returns\n            A randomly transformed version of the input (same shape).\n        \"\"\"\n        # x is a single image, so it doesn't have image number at index 0\n        img_row_axis = self.row_axis - 1\n        img_col_axis = self.col_axis - 1\n        img_channel_axis = self.channel_axis - 1\n\n        if seed is not None:\n            np.random.seed(seed)\n\n        # use composition of homographies\n        # to generate final transform that needs to be applied\n        if self.rotation_range:\n            theta = np.pi / 180 * np.random.uniform(-self.rotation_range, self.rotation_range)\n        else:\n            theta = 0\n\n        if self.height_shift_range:\n            tx = np.random.uniform(-self.height_shift_range, self.height_shift_range) * x.shape[img_row_axis]\n        else:\n            tx = 0\n\n        if self.width_shift_range:\n            ty = np.random.uniform(-self.width_shift_range, self.width_shift_range) * x.shape[img_col_axis]\n        else:\n            ty = 0\n\n        if self.shear_range:\n            shear = np.random.uniform(-self.shear_range, self.shear_range)\n        else:\n            shear = 0\n\n        if self.zoom_range[0] == 1 and self.zoom_range[1] == 1:\n            zx, zy = 1, 1\n        else:\n            zx, zy = np.random.uniform(self.zoom_range[0], self.zoom_range[1], 2)\n\n        transform_matrix = None\n        if theta != 0:\n            rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n                                        [np.sin(theta), np.cos(theta), 0],\n                                        [0, 0, 1]])\n            transform_matrix = rotation_matrix\n\n        if tx != 0 or ty != 0:\n            shift_matrix = np.array([[1, 0, tx],\n                                     [0, 1, ty],\n                                     [0, 0, 1]])\n            transform_matrix = shift_matrix if transform_matrix is None else np.dot(transform_matrix, shift_matrix)\n\n        if shear != 0:\n            shear_matrix = np.array([[1, -np.sin(shear), 0],\n                                    [0, np.cos(shear), 0],\n                                    [0, 0, 1]])\n            transform_matrix = shear_matrix if transform_matrix is None else np.dot(transform_matrix, shear_matrix)\n\n        if zx != 1 or zy != 1:\n            zoom_matrix = np.array([[zx, 0, 0],\n                                    [0, zy, 0],\n                                    [0, 0, 1]])\n            transform_matrix = zoom_matrix if transform_matrix is None else np.dot(transform_matrix, zoom_matrix)\n\n        if transform_matrix is not None:\n            h, w = x.shape[img_row_axis], x.shape[img_col_axis]\n            transform_matrix = transform_matrix_offset_center(transform_matrix, h, w)\n            x = apply_transform(x, transform_matrix, img_channel_axis,\n                                fill_mode=self.fill_mode, cval=self.cval)\n\n        if self.channel_shift_range != 0:\n            x = random_channel_shift(x,\n                                     self.channel_shift_range,\n                                     img_channel_axis)\n        if self.horizontal_flip:\n            if np.random.random() < 0.5:\n                x = flip_axis(x, img_col_axis)\n\n        if self.vertical_flip:\n            if np.random.random() < 0.5:\n                x = flip_axis(x, img_row_axis)\n\n        return x",
        "begin_line": 560,
        "end_line": 648,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image.ImageDataGenerator.fit#650",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image.ImageDataGenerator",
        "signature": "keras.preprocessing.image.ImageDataGenerator.fit(self, x, augment=False, rounds=1, seed=None)",
        "snippet": "    def fit(self, x,\n            augment=False,\n            rounds=1,\n            seed=None):\n        \"\"\"Fits internal statistics to some sample data.\n\n        Required for featurewise_center, featurewise_std_normalization\n        and zca_whitening.\n\n        # Arguments\n            x: Numpy array, the data to fit on. Should have rank 4.\n                In case of grayscale data,\n                the channels axis should have value 1, and in case\n                of RGB data, it should have value 3.\n            augment: Whether to fit on randomly augmented samples\n            rounds: If `augment`,\n                how many augmentation passes to do over the data\n            seed: random seed.\n\n        # Raises\n            ValueError: in case of invalid input `x`.\n        \"\"\"\n        x = np.asarray(x, dtype=K.floatx())\n        if x.ndim != 4:\n            raise ValueError('Input to `.fit()` should have rank 4. '\n                             'Got array with shape: ' + str(x.shape))\n        if x.shape[self.channel_axis] not in {1, 3, 4}:\n            warnings.warn(\n                'Expected input to be images (as Numpy array) '\n                'following the data format convention \"' + self.data_format + '\" '\n                '(channels on axis ' + str(self.channel_axis) + '), i.e. expected '\n                'either 1, 3 or 4 channels on axis ' + str(self.channel_axis) + '. '\n                'However, it was passed an array with shape ' + str(x.shape) +\n                ' (' + str(x.shape[self.channel_axis]) + ' channels).')\n\n        if seed is not None:\n            np.random.seed(seed)\n\n        x = np.copy(x)\n        if augment:\n            ax = np.zeros(tuple([rounds * x.shape[0]] + list(x.shape)[1:]), dtype=K.floatx())\n            for r in range(rounds):\n                for i in range(x.shape[0]):\n                    ax[i + r * x.shape[0]] = self.random_transform(x[i])\n            x = ax\n\n        if self.featurewise_center:\n            self.mean = np.mean(x, axis=(0, self.row_axis, self.col_axis))\n            broadcast_shape = [1, 1, 1]\n            broadcast_shape[self.channel_axis - 1] = x.shape[self.channel_axis]\n            self.mean = np.reshape(self.mean, broadcast_shape)\n            x -= self.mean\n\n        if self.featurewise_std_normalization:\n            self.std = np.std(x, axis=(0, self.row_axis, self.col_axis))\n            broadcast_shape = [1, 1, 1]\n            broadcast_shape[self.channel_axis - 1] = x.shape[self.channel_axis]\n            self.std = np.reshape(self.std, broadcast_shape)\n            x /= (self.std + K.epsilon())\n\n        if self.zca_whitening:\n            flat_x = np.reshape(x, (x.shape[0], x.shape[1] * x.shape[2] * x.shape[3]))\n            sigma = np.dot(flat_x.T, flat_x) / flat_x.shape[0]\n            u, s, _ = linalg.svd(sigma)\n            self.principal_components = np.dot(np.dot(u, np.diag(1. / np.sqrt(s + self.zca_epsilon))), u.T)",
        "begin_line": 650,
        "end_line": 714,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image.Iterator.__init__#730",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image.Iterator",
        "signature": "keras.preprocessing.image.Iterator.__init__(self, n, batch_size, shuffle, seed)",
        "snippet": "    def __init__(self, n, batch_size, shuffle, seed):\n        self.n = n\n        self.batch_size = batch_size\n        self.seed = seed\n        self.shuffle = shuffle\n        self.batch_index = 0\n        self.total_batches_seen = 0\n        self.lock = threading.Lock()\n        self.index_array = None\n        self.index_generator = self._flow_index()",
        "begin_line": 730,
        "end_line": 739,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image.Iterator._set_index_array#741",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image.Iterator",
        "signature": "keras.preprocessing.image.Iterator._set_index_array(self)",
        "snippet": "    def _set_index_array(self):\n        self.index_array = np.arange(self.n)\n        if self.shuffle:\n            self.index_array = np.random.permutation(self.n)",
        "begin_line": 741,
        "end_line": 744,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image.Iterator.__getitem__#746",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image.Iterator",
        "signature": "keras.preprocessing.image.Iterator.__getitem__(self, idx)",
        "snippet": "    def __getitem__(self, idx):\n        if idx >= len(self):\n            raise ValueError('Asked to retrieve element {idx}, '\n                             'but the Sequence '\n                             'has length {length}'.format(idx=idx,\n                                                          length=len(self)))\n        if self.seed is not None:\n            np.random.seed(self.seed + self.total_batches_seen)\n        self.total_batches_seen += 1\n        if self.index_array is None:\n            self._set_index_array()\n        index_array = self.index_array[self.batch_size * idx:\n                                       self.batch_size * (idx + 1)]\n        return self._get_batches_of_transformed_samples(index_array)",
        "begin_line": 746,
        "end_line": 759,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image.Iterator.__len__#761",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image.Iterator",
        "signature": "keras.preprocessing.image.Iterator.__len__(self)",
        "snippet": "    def __len__(self):\n        return int(np.ceil(self.n / float(self.batch_size)))",
        "begin_line": 761,
        "end_line": 762,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image.Iterator.on_epoch_end#764",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image.Iterator",
        "signature": "keras.preprocessing.image.Iterator.on_epoch_end(self)",
        "snippet": "    def on_epoch_end(self):\n        self._set_index_array()",
        "begin_line": 764,
        "end_line": 765,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image.Iterator.reset#767",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image.Iterator",
        "signature": "keras.preprocessing.image.Iterator.reset(self)",
        "snippet": "    def reset(self):\n        self.batch_index = 0",
        "begin_line": 767,
        "end_line": 768,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image.Iterator._flow_index#770",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image.Iterator",
        "signature": "keras.preprocessing.image.Iterator._flow_index(self)",
        "snippet": "    def _flow_index(self):\n        # Ensure self.batch_index is 0.\n        self.reset()\n        while 1:\n            if self.seed is not None:\n                np.random.seed(self.seed + self.total_batches_seen)\n            if self.batch_index == 0:\n                self._set_index_array()\n\n            current_index = (self.batch_index * self.batch_size) % self.n\n            if self.n > current_index + self.batch_size:\n                self.batch_index += 1\n            else:\n                self.batch_index = 0\n            self.total_batches_seen += 1\n            yield self.index_array[current_index:\n                                   current_index + self.batch_size]",
        "begin_line": 770,
        "end_line": 786,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image.Iterator.__iter__#788",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image.Iterator",
        "signature": "keras.preprocessing.image.Iterator.__iter__(self)",
        "snippet": "    def __iter__(self):\n        # Needed if we want to do something like:\n        # for x, y in data_gen.flow(...):\n        return self",
        "begin_line": 788,
        "end_line": 791,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image.Iterator.__next__#793",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image.Iterator",
        "signature": "keras.preprocessing.image.Iterator.__next__(self, *args, **kwargs)",
        "snippet": "    def __next__(self, *args, **kwargs):\n        return self.next(*args, **kwargs)",
        "begin_line": 793,
        "end_line": 794,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image.NumpyArrayIterator.__init__#830",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image.NumpyArrayIterator",
        "signature": "keras.preprocessing.image.NumpyArrayIterator.__init__(self, x, y, image_data_generator, batch_size=32, shuffle=False, seed=None, data_format=None, save_to_dir=None, save_prefix='', save_format='png')",
        "snippet": "    def __init__(self, x, y, image_data_generator,\n                 batch_size=32, shuffle=False, seed=None,\n                 data_format=None,\n                 save_to_dir=None, save_prefix='', save_format='png'):\n        if y is not None and len(x) != len(y):\n            raise ValueError('X (images tensor) and y (labels) '\n                             'should have the same length. '\n                             'Found: X.shape = %s, y.shape = %s' %\n                             (np.asarray(x).shape, np.asarray(y).shape))\n\n        if data_format is None:\n            data_format = K.image_data_format()\n        self.x = np.asarray(x, dtype=K.floatx())\n\n        if self.x.ndim != 4:\n            raise ValueError('Input data in `NumpyArrayIterator` '\n                             'should have rank 4. You passed an array '\n                             'with shape', self.x.shape)\n        channels_axis = 3 if data_format == 'channels_last' else 1\n        if self.x.shape[channels_axis] not in {1, 3, 4}:\n            warnings.warn('NumpyArrayIterator is set to use the '\n                          'data format convention \"' + data_format + '\" '\n                          '(channels on axis ' + str(channels_axis) + '), i.e. expected '\n                          'either 1, 3 or 4 channels on axis ' + str(channels_axis) + '. '\n                          'However, it was passed an array with shape ' + str(self.x.shape) +\n                          ' (' + str(self.x.shape[channels_axis]) + ' channels).')\n        if y is not None:\n            self.y = np.asarray(y)\n        else:\n            self.y = None\n        self.image_data_generator = image_data_generator\n        self.data_format = data_format\n        self.save_to_dir = save_to_dir\n        self.save_prefix = save_prefix\n        self.save_format = save_format\n        super(NumpyArrayIterator, self).__init__(x.shape[0], batch_size, shuffle, seed)",
        "begin_line": 830,
        "end_line": 865,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image.NumpyArrayIterator._get_batches_of_transformed_samples#867",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image.NumpyArrayIterator",
        "signature": "keras.preprocessing.image.NumpyArrayIterator._get_batches_of_transformed_samples(self, index_array)",
        "snippet": "    def _get_batches_of_transformed_samples(self, index_array):\n        batch_x = np.zeros(tuple([len(index_array)] + list(self.x.shape)[1:]),\n                           dtype=K.floatx())\n        for i, j in enumerate(index_array):\n            x = self.x[j]\n            x = self.image_data_generator.random_transform(x.astype(K.floatx()))\n            x = self.image_data_generator.standardize(x)\n            batch_x[i] = x\n        if self.save_to_dir:\n            for i, j in enumerate(index_array):\n                img = array_to_img(batch_x[i], self.data_format, scale=True)\n                fname = '{prefix}_{index}_{hash}.{format}'.format(prefix=self.save_prefix,\n                                                                  index=j,\n                                                                  hash=np.random.randint(1e4),\n                                                                  format=self.save_format)\n                img.save(os.path.join(self.save_to_dir, fname))\n        if self.y is None:\n            return batch_x\n        batch_y = self.y[index_array]\n        return batch_x, batch_y",
        "begin_line": 867,
        "end_line": 886,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image.NumpyArrayIterator.next#888",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image.NumpyArrayIterator",
        "signature": "keras.preprocessing.image.NumpyArrayIterator.next(self)",
        "snippet": "    def next(self):\n        \"\"\"For python 2.x.\n\n        # Returns\n            The next batch.\n        \"\"\"\n        # Keeps under lock only the mechanism which advances\n        # the indexing of each batch.\n        with self.lock:\n            index_array = next(self.index_generator)\n        # The transformation of images is not under thread lock\n        # so it can be done in parallel\n        return self._get_batches_of_transformed_samples(index_array)",
        "begin_line": 888,
        "end_line": 900,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image._count_valid_files_in_directory#903",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image",
        "signature": "keras.preprocessing.image._count_valid_files_in_directory(directory, white_list_formats, follow_links)",
        "snippet": "def _count_valid_files_in_directory(directory, white_list_formats, follow_links):\n    \"\"\"Count files with extension in `white_list_formats` contained in a directory.\n\n    # Arguments\n        directory: absolute path to the directory containing files to be counted\n        white_list_formats: set of strings containing allowed extensions for\n            the files to be counted.\n\n    # Returns\n        the count of files with extension in `white_list_formats` contained in\n        the directory.\n    \"\"\"\n    def _recursive_list(subpath):\n        return sorted(os.walk(subpath, followlinks=follow_links), key=lambda tpl: tpl[0])\n\n    samples = 0\n    for root, _, files in _recursive_list(directory):\n        for fname in files:\n            is_valid = False\n            for extension in white_list_formats:\n                if fname.lower().endswith('.' + extension):\n                    is_valid = True\n                    break\n            if is_valid:\n                samples += 1\n    return samples",
        "begin_line": 903,
        "end_line": 928,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image._recursive_list#915",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image",
        "signature": "keras.preprocessing.image._recursive_list(subpath)",
        "snippet": "    def _recursive_list(subpath):\n        return sorted(os.walk(subpath, followlinks=follow_links), key=lambda tpl: tpl[0])",
        "begin_line": 915,
        "end_line": 916,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image._list_valid_filenames_in_directory#931",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image",
        "signature": "keras.preprocessing.image._list_valid_filenames_in_directory(directory, white_list_formats, class_indices, follow_links)",
        "snippet": "def _list_valid_filenames_in_directory(directory, white_list_formats,\n                                       class_indices, follow_links):\n    \"\"\"List paths of files in `subdir` relative from `directory` whose extensions are in `white_list_formats`.\n\n    # Arguments\n        directory: absolute path to a directory containing the files to list.\n            The directory name is used as class label and must be a key of `class_indices`.\n        white_list_formats: set of strings containing allowed extensions for\n            the files to be counted.\n        class_indices: dictionary mapping a class name to its index.\n\n    # Returns\n        classes: a list of class indices\n        filenames: the path of valid files in `directory`, relative from\n            `directory`'s parent (e.g., if `directory` is \"dataset/class1\",\n            the filenames will be [\"class1/file1.jpg\", \"class1/file2.jpg\", ...]).\n    \"\"\"\n    def _recursive_list(subpath):\n        return sorted(os.walk(subpath, followlinks=follow_links), key=lambda tpl: tpl[0])\n\n    classes = []\n    filenames = []\n    subdir = os.path.basename(directory)\n    basedir = os.path.dirname(directory)\n    for root, _, files in _recursive_list(directory):\n        for fname in sorted(files):\n            is_valid = False\n            for extension in white_list_formats:\n                if fname.lower().endswith('.' + extension):\n                    is_valid = True\n                    break\n            if is_valid:\n                classes.append(class_indices[subdir])\n                # add filename relative to directory\n                absolute_path = os.path.join(root, fname)\n                filenames.append(os.path.relpath(absolute_path, basedir))\n    return classes, filenames",
        "begin_line": 931,
        "end_line": 967,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image._recursive_list#948",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image",
        "signature": "keras.preprocessing.image._recursive_list(subpath)",
        "snippet": "    def _recursive_list(subpath):\n        return sorted(os.walk(subpath, followlinks=follow_links), key=lambda tpl: tpl[0])",
        "begin_line": 948,
        "end_line": 949,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image.DirectoryIterator.__init__#1007",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image.DirectoryIterator",
        "signature": "keras.preprocessing.image.DirectoryIterator.__init__(self, directory, image_data_generator, target_size=(256, 256), color_mode='rgb', classes=None, class_mode='categorical', batch_size=32, shuffle=True, seed=None, data_format=None, save_to_dir=None, save_prefix='', save_format='png', follow_links=False)",
        "snippet": "    def __init__(self, directory, image_data_generator,\n                 target_size=(256, 256), color_mode='rgb',\n                 classes=None, class_mode='categorical',\n                 batch_size=32, shuffle=True, seed=None,\n                 data_format=None,\n                 save_to_dir=None, save_prefix='', save_format='png',\n                 follow_links=False):\n        if data_format is None:\n            data_format = K.image_data_format()\n        self.directory = directory\n        self.image_data_generator = image_data_generator\n        self.target_size = tuple(target_size)\n        if color_mode not in {'rgb', 'grayscale'}:\n            raise ValueError('Invalid color mode:', color_mode,\n                             '; expected \"rgb\" or \"grayscale\".')\n        self.color_mode = color_mode\n        self.data_format = data_format\n        if self.color_mode == 'rgb':\n            if self.data_format == 'channels_last':\n                self.image_shape = self.target_size + (3,)\n            else:\n                self.image_shape = (3,) + self.target_size\n        else:\n            if self.data_format == 'channels_last':\n                self.image_shape = self.target_size + (1,)\n            else:\n                self.image_shape = (1,) + self.target_size\n        self.classes = classes\n        if class_mode not in {'categorical', 'binary', 'sparse',\n                              'input', None}:\n            raise ValueError('Invalid class_mode:', class_mode,\n                             '; expected one of \"categorical\", '\n                             '\"binary\", \"sparse\", \"input\"'\n                             ' or None.')\n        self.class_mode = class_mode\n        self.save_to_dir = save_to_dir\n        self.save_prefix = save_prefix\n        self.save_format = save_format\n\n        white_list_formats = {'png', 'jpg', 'jpeg', 'bmp', 'ppm'}\n\n        # first, count the number of samples and classes\n        self.samples = 0\n\n        if not classes:\n            classes = []\n            for subdir in sorted(os.listdir(directory)):\n                if os.path.isdir(os.path.join(directory, subdir)):\n                    classes.append(subdir)\n        self.num_classes = len(classes)\n        self.class_indices = dict(zip(classes, range(len(classes))))\n\n        pool = multiprocessing.pool.ThreadPool()\n        function_partial = partial(_count_valid_files_in_directory,\n                                   white_list_formats=white_list_formats,\n                                   follow_links=follow_links)\n        self.samples = sum(pool.map(function_partial,\n                                    (os.path.join(directory, subdir)\n                                     for subdir in classes)))\n\n        print('Found %d images belonging to %d classes.' % (self.samples, self.num_classes))\n\n        # second, build an index of the images in the different class subfolders\n        results = []\n\n        self.filenames = []\n        self.classes = np.zeros((self.samples,), dtype='int32')\n        i = 0\n        for dirpath in (os.path.join(directory, subdir) for subdir in classes):\n            results.append(pool.apply_async(_list_valid_filenames_in_directory,\n                                            (dirpath, white_list_formats,\n                                             self.class_indices, follow_links)))\n        for res in results:\n            classes, filenames = res.get()\n            self.classes[i:i + len(classes)] = classes\n            self.filenames += filenames\n            i += len(classes)\n        pool.close()\n        pool.join()\n        super(DirectoryIterator, self).__init__(self.samples, batch_size, shuffle, seed)",
        "begin_line": 1007,
        "end_line": 1086,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image.DirectoryIterator._get_batches_of_transformed_samples#1088",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image.DirectoryIterator",
        "signature": "keras.preprocessing.image.DirectoryIterator._get_batches_of_transformed_samples(self, index_array)",
        "snippet": "    def _get_batches_of_transformed_samples(self, index_array):\n        batch_x = np.zeros((len(index_array),) + self.image_shape, dtype=K.floatx())\n        grayscale = self.color_mode == 'grayscale'\n        # build batch of image data\n        for i, j in enumerate(index_array):\n            fname = self.filenames[j]\n            img = load_img(os.path.join(self.directory, fname),\n                           grayscale=grayscale,\n                           target_size=self.target_size)\n            x = img_to_array(img, data_format=self.data_format)\n            x = self.image_data_generator.random_transform(x)\n            x = self.image_data_generator.standardize(x)\n            batch_x[i] = x\n        # optionally save augmented images to disk for debugging purposes\n        if self.save_to_dir:\n            for i, j in enumerate(index_array):\n                img = array_to_img(batch_x[i], self.data_format, scale=True)\n                fname = '{prefix}_{index}_{hash}.{format}'.format(prefix=self.save_prefix,\n                                                                  index=j,\n                                                                  hash=np.random.randint(1e7),\n                                                                  format=self.save_format)\n                img.save(os.path.join(self.save_to_dir, fname))\n        # build batch of labels\n        if self.class_mode == 'input':\n            batch_y = batch_x.copy()\n        elif self.class_mode == 'sparse':\n            batch_y = self.classes[index_array]\n        elif self.class_mode == 'binary':\n            batch_y = self.classes[index_array].astype(K.floatx())\n        elif self.class_mode == 'categorical':\n            batch_y = np.zeros((len(batch_x), self.num_classes), dtype=K.floatx())\n            for i, label in enumerate(self.classes[index_array]):\n                batch_y[i, label] = 1.\n        else:\n            return batch_x\n        return batch_x, batch_y",
        "begin_line": 1088,
        "end_line": 1123,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.preprocessing.image.DirectoryIterator.next#1125",
        "src_path": "keras/preprocessing/image.py",
        "class_name": "keras.preprocessing.image.DirectoryIterator",
        "signature": "keras.preprocessing.image.DirectoryIterator.next(self)",
        "snippet": "    def next(self):\n        \"\"\"For python 2.x.\n\n        # Returns\n            The next batch.\n        \"\"\"\n        with self.lock:\n            index_array = next(self.index_generator)\n        # The transformation of images is not under thread lock\n        # so it can be done in parallel\n        return self._get_batches_of_transformed_samples(index_array)",
        "begin_line": 1125,
        "end_line": 1135,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.applications.xception.Xception#48",
        "src_path": "keras/applications/xception.py",
        "class_name": "keras.applications.xception",
        "signature": "keras.applications.xception.Xception(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)",
        "snippet": "def Xception(include_top=True, weights='imagenet',\n             input_tensor=None, input_shape=None,\n             pooling=None,\n             classes=1000):\n    \"\"\"Instantiates the Xception architecture.\n\n    Optionally loads weights pre-trained\n    on ImageNet. This model is available for TensorFlow only,\n    and can only be used with inputs following the TensorFlow\n    data format `(width, height, channels)`.\n    You should set `image_data_format='channels_last'` in your Keras config\n    located at ~/.keras/keras.json.\n\n    Note that the default input image size for this model is 299x299.\n\n    # Arguments\n        include_top: whether to include the fully-connected\n            layer at the top of the network.\n        weights: one of `None` (random initialization)\n            or 'imagenet' (pre-training on ImageNet).\n        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n            to use as image input for the model.\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(299, 299, 3)`.\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 71.\n            E.g. `(150, 150, 3)` would be one valid value.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model will be\n                the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a 2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n\n    # Returns\n        A Keras model instance.\n\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n        RuntimeError: If attempting to run this model with a\n            backend that does not support separable convolutions.\n    \"\"\"\n    if weights not in {'imagenet', None}:\n        raise ValueError('The `weights` argument should be either '\n                         '`None` (random initialization) or `imagenet` '\n                         '(pre-training on ImageNet).')\n\n    if weights == 'imagenet' and include_top and classes != 1000:\n        raise ValueError('If using `weights` as imagenet with `include_top`'\n                         ' as true, `classes` should be 1000')\n\n    if K.backend() != 'tensorflow':\n        raise RuntimeError('The Xception model is only available with '\n                           'the TensorFlow backend.')\n    if K.image_data_format() != 'channels_last':\n        warnings.warn('The Xception model is only available for the '\n                      'input data format \"channels_last\" '\n                      '(width, height, channels). '\n                      'However your settings specify the default '\n                      'data format \"channels_first\" (channels, width, height). '\n                      'You should set `image_data_format=\"channels_last\"` in your Keras '\n                      'config located at ~/.keras/keras.json. '\n                      'The model being returned right now will expect inputs '\n                      'to follow the \"channels_last\" data format.')\n        K.set_image_data_format('channels_last')\n        old_data_format = 'channels_first'\n    else:\n        old_data_format = None\n\n    # Determine proper input shape\n    input_shape = _obtain_input_shape(input_shape,\n                                      default_size=299,\n                                      min_size=71,\n                                      data_format=K.image_data_format(),\n                                      require_flatten=False,\n                                      weights=weights)\n\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n\n    x = Conv2D(32, (3, 3), strides=(2, 2), use_bias=False, name='block1_conv1')(img_input)\n    x = BatchNormalization(name='block1_conv1_bn')(x)\n    x = Activation('relu', name='block1_conv1_act')(x)\n    x = Conv2D(64, (3, 3), use_bias=False, name='block1_conv2')(x)\n    x = BatchNormalization(name='block1_conv2_bn')(x)\n    x = Activation('relu', name='block1_conv2_act')(x)\n\n    residual = Conv2D(128, (1, 1), strides=(2, 2),\n                      padding='same', use_bias=False)(x)\n    residual = BatchNormalization()(residual)\n\n    x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False, name='block2_sepconv1')(x)\n    x = BatchNormalization(name='block2_sepconv1_bn')(x)\n    x = Activation('relu', name='block2_sepconv2_act')(x)\n    x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False, name='block2_sepconv2')(x)\n    x = BatchNormalization(name='block2_sepconv2_bn')(x)\n\n    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block2_pool')(x)\n    x = layers.add([x, residual])\n\n    residual = Conv2D(256, (1, 1), strides=(2, 2),\n                      padding='same', use_bias=False)(x)\n    residual = BatchNormalization()(residual)\n\n    x = Activation('relu', name='block3_sepconv1_act')(x)\n    x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False, name='block3_sepconv1')(x)\n    x = BatchNormalization(name='block3_sepconv1_bn')(x)\n    x = Activation('relu', name='block3_sepconv2_act')(x)\n    x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False, name='block3_sepconv2')(x)\n    x = BatchNormalization(name='block3_sepconv2_bn')(x)\n\n    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block3_pool')(x)\n    x = layers.add([x, residual])\n\n    residual = Conv2D(728, (1, 1), strides=(2, 2),\n                      padding='same', use_bias=False)(x)\n    residual = BatchNormalization()(residual)\n\n    x = Activation('relu', name='block4_sepconv1_act')(x)\n    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name='block4_sepconv1')(x)\n    x = BatchNormalization(name='block4_sepconv1_bn')(x)\n    x = Activation('relu', name='block4_sepconv2_act')(x)\n    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name='block4_sepconv2')(x)\n    x = BatchNormalization(name='block4_sepconv2_bn')(x)\n\n    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block4_pool')(x)\n    x = layers.add([x, residual])\n\n    for i in range(8):\n        residual = x\n        prefix = 'block' + str(i + 5)\n\n        x = Activation('relu', name=prefix + '_sepconv1_act')(x)\n        x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name=prefix + '_sepconv1')(x)\n        x = BatchNormalization(name=prefix + '_sepconv1_bn')(x)\n        x = Activation('relu', name=prefix + '_sepconv2_act')(x)\n        x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name=prefix + '_sepconv2')(x)\n        x = BatchNormalization(name=prefix + '_sepconv2_bn')(x)\n        x = Activation('relu', name=prefix + '_sepconv3_act')(x)\n        x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name=prefix + '_sepconv3')(x)\n        x = BatchNormalization(name=prefix + '_sepconv3_bn')(x)\n\n        x = layers.add([x, residual])\n\n    residual = Conv2D(1024, (1, 1), strides=(2, 2),\n                      padding='same', use_bias=False)(x)\n    residual = BatchNormalization()(residual)\n\n    x = Activation('relu', name='block13_sepconv1_act')(x)\n    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name='block13_sepconv1')(x)\n    x = BatchNormalization(name='block13_sepconv1_bn')(x)\n    x = Activation('relu', name='block13_sepconv2_act')(x)\n    x = SeparableConv2D(1024, (3, 3), padding='same', use_bias=False, name='block13_sepconv2')(x)\n    x = BatchNormalization(name='block13_sepconv2_bn')(x)\n\n    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block13_pool')(x)\n    x = layers.add([x, residual])\n\n    x = SeparableConv2D(1536, (3, 3), padding='same', use_bias=False, name='block14_sepconv1')(x)\n    x = BatchNormalization(name='block14_sepconv1_bn')(x)\n    x = Activation('relu', name='block14_sepconv1_act')(x)\n\n    x = SeparableConv2D(2048, (3, 3), padding='same', use_bias=False, name='block14_sepconv2')(x)\n    x = BatchNormalization(name='block14_sepconv2_bn')(x)\n    x = Activation('relu', name='block14_sepconv2_act')(x)\n\n    if include_top:\n        x = GlobalAveragePooling2D(name='avg_pool')(x)\n        x = Dense(classes, activation='softmax', name='predictions')(x)\n    else:\n        if pooling == 'avg':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling == 'max':\n            x = GlobalMaxPooling2D()(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n    # Create model.\n    model = Model(inputs, x, name='xception')\n\n    # load weights\n    if weights == 'imagenet':\n        if include_top:\n            weights_path = get_file('xception_weights_tf_dim_ordering_tf_kernels.h5',\n                                    TF_WEIGHTS_PATH,\n                                    cache_subdir='models',\n                                    file_hash='0a58e3b7378bc2990ea3b43d5981f1f6')\n        else:\n            weights_path = get_file('xception_weights_tf_dim_ordering_tf_kernels_notop.h5',\n                                    TF_WEIGHTS_PATH_NO_TOP,\n                                    cache_subdir='models',\n                                    file_hash='b0042744bf5b25fce3cb969f33bebb97')\n        model.load_weights(weights_path)\n\n    if old_data_format:\n        K.set_image_data_format(old_data_format)\n    return model",
        "begin_line": 48,
        "end_line": 263,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.clip_norm#15",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers",
        "signature": "keras.optimizers.clip_norm(g, c, n)",
        "snippet": "def clip_norm(g, c, n):\n    if c <= 0:  # if clipnorm == 0 no need to add ops to the graph\n        return g\n\n    # tf require using a special op to multiply IndexedSliced by scalar\n    if K.backend() == 'tensorflow':\n        condition = n >= c\n        then_expression = tf.scalar_mul(c / n, g)\n        else_expression = g\n\n        # saving the shape to avoid converting sparse tensor to dense\n        if isinstance(then_expression, tf.Tensor):\n            g_shape = copy.copy(then_expression.get_shape())\n        elif isinstance(then_expression, tf.IndexedSlices):\n            g_shape = copy.copy(then_expression.dense_shape)\n        if condition.dtype != tf.bool:\n            condition = tf.cast(condition, 'bool')\n        g = tf.cond(condition,\n                    lambda: then_expression,\n                    lambda: else_expression)\n        if isinstance(then_expression, tf.Tensor):\n            g.set_shape(g_shape)\n        elif isinstance(then_expression, tf.IndexedSlices):\n            g._dense_shape = g_shape\n    else:\n        g = K.switch(K.greater_equal(n, c), g * c / n, g)\n    return g",
        "begin_line": 15,
        "end_line": 41,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.Optimizer.__init__#58",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Optimizer",
        "signature": "keras.optimizers.Optimizer.__init__(self, **kwargs)",
        "snippet": "    def __init__(self, **kwargs):\n        allowed_kwargs = {'clipnorm', 'clipvalue'}\n        for k in kwargs:\n            if k not in allowed_kwargs:\n                raise TypeError('Unexpected keyword argument '\n                                'passed to optimizer: ' + str(k))\n        self.__dict__.update(kwargs)\n        self.updates = []\n        self.weights = []",
        "begin_line": 58,
        "end_line": 66,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.Optimizer.get_gradients#72",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Optimizer",
        "signature": "keras.optimizers.Optimizer.get_gradients(self, loss, params)",
        "snippet": "    def get_gradients(self, loss, params):\n        grads = K.gradients(loss, params)\n        if hasattr(self, 'clipnorm') and self.clipnorm > 0:\n            norm = K.sqrt(sum([K.sum(K.square(g)) for g in grads]))\n            grads = [clip_norm(g, self.clipnorm, norm) for g in grads]\n        if hasattr(self, 'clipvalue') and self.clipvalue > 0:\n            grads = [K.clip(g, -self.clipvalue, self.clipvalue) for g in grads]\n        return grads",
        "begin_line": 72,
        "end_line": 79,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.Optimizer.set_weights#81",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Optimizer",
        "signature": "keras.optimizers.Optimizer.set_weights(self, weights)",
        "snippet": "    def set_weights(self, weights):\n        \"\"\"Sets the weights of the optimizer, from Numpy arrays.\n\n        Should only be called after computing the gradients\n        (otherwise the optimizer has no weights).\n\n        # Arguments\n            weights: a list of Numpy arrays. The number\n                of arrays and their shape must match\n                number of the dimensions of the weights\n                of the optimizer (i.e. it should match the\n                output of `get_weights`).\n\n        # Raises\n            ValueError: in case of incompatible weight shapes.\n        \"\"\"\n        params = self.weights\n        weight_value_tuples = []\n        param_values = K.batch_get_value(params)\n        for pv, p, w in zip(param_values, params, weights):\n            if pv.shape != w.shape:\n                raise ValueError('Optimizer weight shape ' +\n                                 str(pv.shape) +\n                                 ' not compatible with '\n                                 'provided weight shape ' + str(w.shape))\n            weight_value_tuples.append((p, w))\n        K.batch_set_value(weight_value_tuples)",
        "begin_line": 81,
        "end_line": 107,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.Optimizer.get_config#117",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Optimizer",
        "signature": "keras.optimizers.Optimizer.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {}\n        if hasattr(self, 'clipnorm'):\n            config['clipnorm'] = self.clipnorm\n        if hasattr(self, 'clipvalue'):\n            config['clipvalue'] = self.clipvalue\n        return config",
        "begin_line": 117,
        "end_line": 123,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.Optimizer.from_config#126",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Optimizer",
        "signature": "keras.optimizers.Optimizer.from_config(cls, config)",
        "snippet": "    def from_config(cls, config):\n        return cls(**config)",
        "begin_line": 126,
        "end_line": 127,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 8.835483300936562e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.SGD.__init__#143",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.SGD",
        "signature": "keras.optimizers.SGD.__init__(self, lr=0.01, momentum=0.0, decay=0.0, nesterov=False, **kwargs)",
        "snippet": "    def __init__(self, lr=0.01, momentum=0., decay=0.,\n                 nesterov=False, **kwargs):\n        super(SGD, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.iterations = K.variable(0, dtype='int64', name='iterations')\n            self.lr = K.variable(lr, name='lr')\n            self.momentum = K.variable(momentum, name='momentum')\n            self.decay = K.variable(decay, name='decay')\n        self.initial_decay = decay\n        self.nesterov = nesterov",
        "begin_line": 143,
        "end_line": 152,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.539254030334828e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.SGD.get_updates#155",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.SGD",
        "signature": "keras.optimizers.SGD.get_updates(self, loss, params)",
        "snippet": "    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        self.updates = [K.update_add(self.iterations, 1)]\n\n        lr = self.lr\n        if self.initial_decay > 0:\n            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n                                                  K.dtype(self.decay))))\n        # momentum\n        shapes = [K.int_shape(p) for p in params]\n        moments = [K.zeros(shape) for shape in shapes]\n        self.weights = [self.iterations] + moments\n        for p, g, m in zip(params, grads, moments):\n            v = self.momentum * m - lr * g  # velocity\n            self.updates.append(K.update(m, v))\n\n            if self.nesterov:\n                new_p = p + self.momentum * v - lr * g\n            else:\n                new_p = p + v\n\n            # Apply constraints.\n            if getattr(p, 'constraint', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n        return self.updates",
        "begin_line": 155,
        "end_line": 181,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.SGD.get_config#183",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.SGD",
        "signature": "keras.optimizers.SGD.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'lr': float(K.get_value(self.lr)),\n                  'momentum': float(K.get_value(self.momentum)),\n                  'decay': float(K.get_value(self.decay)),\n                  'nesterov': self.nesterov}\n        base_config = super(SGD, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 183,
        "end_line": 189,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.RMSprop.__init__#212",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.RMSprop",
        "signature": "keras.optimizers.RMSprop.__init__(self, lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0, **kwargs)",
        "snippet": "    def __init__(self, lr=0.001, rho=0.9, epsilon=1e-8, decay=0.,\n                 **kwargs):\n        super(RMSprop, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.lr = K.variable(lr, name='lr')\n            self.rho = K.variable(rho, name='rho')\n            self.decay = K.variable(decay, name='decay')\n            self.iterations = K.variable(0, dtype='int64', name='iterations')\n        self.epsilon = epsilon\n        self.initial_decay = decay",
        "begin_line": 212,
        "end_line": 221,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.102494083378845e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.RMSprop.get_updates#224",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.RMSprop",
        "signature": "keras.optimizers.RMSprop.get_updates(self, loss, params)",
        "snippet": "    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        accumulators = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n        self.weights = accumulators\n        self.updates = [K.update_add(self.iterations, 1)]\n\n        lr = self.lr\n        if self.initial_decay > 0:\n            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n                                                  K.dtype(self.decay))))\n\n        for p, g, a in zip(params, grads, accumulators):\n            # update accumulator\n            new_a = self.rho * a + (1. - self.rho) * K.square(g)\n            self.updates.append(K.update(a, new_a))\n            new_p = p - lr * g / (K.sqrt(new_a) + self.epsilon)\n\n            # Apply constraints.\n            if getattr(p, 'constraint', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n        return self.updates",
        "begin_line": 224,
        "end_line": 246,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.RMSprop.get_config#248",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.RMSprop",
        "signature": "keras.optimizers.RMSprop.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'lr': float(K.get_value(self.lr)),\n                  'rho': float(K.get_value(self.rho)),\n                  'decay': float(K.get_value(self.decay)),\n                  'epsilon': self.epsilon}\n        base_config = super(RMSprop, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 248,
        "end_line": 254,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.Adagrad.__init__#272",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Adagrad",
        "signature": "keras.optimizers.Adagrad.__init__(self, lr=0.01, epsilon=1e-08, decay=0.0, **kwargs)",
        "snippet": "    def __init__(self, lr=0.01, epsilon=1e-8, decay=0., **kwargs):\n        super(Adagrad, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.lr = K.variable(lr, name='lr')\n            self.decay = K.variable(decay, name='decay')\n            self.iterations = K.variable(0, dtype='int64', name='iterations')\n        self.epsilon = epsilon\n        self.initial_decay = decay",
        "begin_line": 272,
        "end_line": 279,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.Adagrad.get_updates#282",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Adagrad",
        "signature": "keras.optimizers.Adagrad.get_updates(self, loss, params)",
        "snippet": "    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        shapes = [K.int_shape(p) for p in params]\n        accumulators = [K.zeros(shape) for shape in shapes]\n        self.weights = accumulators\n        self.updates = [K.update_add(self.iterations, 1)]\n\n        lr = self.lr\n        if self.initial_decay > 0:\n            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n                                                  K.dtype(self.decay))))\n\n        for p, g, a in zip(params, grads, accumulators):\n            new_a = a + K.square(g)  # update accumulator\n            self.updates.append(K.update(a, new_a))\n            new_p = p - lr * g / (K.sqrt(new_a) + self.epsilon)\n\n            # Apply constraints.\n            if getattr(p, 'constraint', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n        return self.updates",
        "begin_line": 282,
        "end_line": 304,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.Adagrad.get_config#306",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Adagrad",
        "signature": "keras.optimizers.Adagrad.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'lr': float(K.get_value(self.lr)),\n                  'decay': float(K.get_value(self.decay)),\n                  'epsilon': self.epsilon}\n        base_config = super(Adagrad, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 306,
        "end_line": 311,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.Adadelta.__init__#331",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Adadelta",
        "signature": "keras.optimizers.Adadelta.__init__(self, lr=1.0, rho=0.95, epsilon=1e-08, decay=0.0, **kwargs)",
        "snippet": "    def __init__(self, lr=1.0, rho=0.95, epsilon=1e-8, decay=0.,\n                 **kwargs):\n        super(Adadelta, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.lr = K.variable(lr, name='lr')\n            self.decay = K.variable(decay, name='decay')\n            self.iterations = K.variable(0, dtype='int64', name='iterations')\n        self.rho = rho\n        self.epsilon = epsilon\n        self.initial_decay = decay",
        "begin_line": 331,
        "end_line": 340,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011301989150090416,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.Adadelta.get_updates#343",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Adadelta",
        "signature": "keras.optimizers.Adadelta.get_updates(self, loss, params)",
        "snippet": "    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        shapes = [K.int_shape(p) for p in params]\n        accumulators = [K.zeros(shape) for shape in shapes]\n        delta_accumulators = [K.zeros(shape) for shape in shapes]\n        self.weights = accumulators + delta_accumulators\n        self.updates = [K.update_add(self.iterations, 1)]\n\n        lr = self.lr\n        if self.initial_decay > 0:\n            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n                                                  K.dtype(self.decay))))\n\n        for p, g, a, d_a in zip(params, grads, accumulators, delta_accumulators):\n            # update accumulator\n            new_a = self.rho * a + (1. - self.rho) * K.square(g)\n            self.updates.append(K.update(a, new_a))\n\n            # use the new accumulator and the *old* delta_accumulator\n            update = g * K.sqrt(d_a + self.epsilon) / K.sqrt(new_a + self.epsilon)\n            new_p = p - lr * update\n\n            # Apply constraints.\n            if getattr(p, 'constraint', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n\n            # update delta_accumulator\n            new_d_a = self.rho * d_a + (1 - self.rho) * K.square(update)\n            self.updates.append(K.update(d_a, new_d_a))\n        return self.updates",
        "begin_line": 343,
        "end_line": 374,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.Adadelta.get_config#376",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Adadelta",
        "signature": "keras.optimizers.Adadelta.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'lr': float(K.get_value(self.lr)),\n                  'rho': self.rho,\n                  'decay': float(K.get_value(self.decay)),\n                  'epsilon': self.epsilon}\n        base_config = super(Adadelta, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 376,
        "end_line": 382,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.Adam.__init__#401",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Adam",
        "signature": "keras.optimizers.Adam.__init__(self, lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0, **kwargs)",
        "snippet": "    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999,\n                 epsilon=1e-8, decay=0., **kwargs):\n        super(Adam, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.iterations = K.variable(0, dtype='int64', name='iterations')\n            self.lr = K.variable(lr, name='lr')\n            self.beta_1 = K.variable(beta_1, name='beta_1')\n            self.beta_2 = K.variable(beta_2, name='beta_2')\n            self.decay = K.variable(decay, name='decay')\n        self.epsilon = epsilon\n        self.initial_decay = decay",
        "begin_line": 401,
        "end_line": 411,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010421008753647353,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.Adam.get_updates#414",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Adam",
        "signature": "keras.optimizers.Adam.get_updates(self, loss, params)",
        "snippet": "    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        self.updates = [K.update_add(self.iterations, 1)]\n\n        lr = self.lr\n        if self.initial_decay > 0:\n            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n                                                  K.dtype(self.decay))))\n\n        t = K.cast(self.iterations, K.floatx()) + 1\n        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) /\n                     (1. - K.pow(self.beta_1, t)))\n\n        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n        self.weights = [self.iterations] + ms + vs\n\n        for p, g, m, v in zip(params, grads, ms, vs):\n            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n            p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon)\n\n            self.updates.append(K.update(m, m_t))\n            self.updates.append(K.update(v, v_t))\n            new_p = p_t\n\n            # Apply constraints.\n            if getattr(p, 'constraint', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n        return self.updates",
        "begin_line": 414,
        "end_line": 445,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.Adam.get_config#447",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Adam",
        "signature": "keras.optimizers.Adam.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'lr': float(K.get_value(self.lr)),\n                  'beta_1': float(K.get_value(self.beta_1)),\n                  'beta_2': float(K.get_value(self.beta_2)),\n                  'decay': float(K.get_value(self.decay)),\n                  'epsilon': self.epsilon}\n        base_config = super(Adam, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 447,
        "end_line": 454,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.Adamax.__init__#473",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Adamax",
        "signature": "keras.optimizers.Adamax.__init__(self, lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0, **kwargs)",
        "snippet": "    def __init__(self, lr=0.002, beta_1=0.9, beta_2=0.999,\n                 epsilon=1e-8, decay=0., **kwargs):\n        super(Adamax, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.iterations = K.variable(0, dtype='int64', name='iterations')\n            self.lr = K.variable(lr, name='lr')\n            self.beta_1 = K.variable(beta_1, name='beta_1')\n            self.beta_2 = K.variable(beta_2, name='beta_2')\n            self.decay = K.variable(decay, name='decay')\n        self.epsilon = epsilon\n        self.initial_decay = decay",
        "begin_line": 473,
        "end_line": 483,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.Adamax.get_updates#486",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Adamax",
        "signature": "keras.optimizers.Adamax.get_updates(self, loss, params)",
        "snippet": "    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        self.updates = [K.update_add(self.iterations, 1)]\n\n        lr = self.lr\n        if self.initial_decay > 0:\n            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n                                                  K.dtype(self.decay))))\n\n        t = K.cast(self.iterations, K.floatx()) + 1\n        lr_t = lr / (1. - K.pow(self.beta_1, t))\n\n        shapes = [K.int_shape(p) for p in params]\n        # zero init of 1st moment\n        ms = [K.zeros(shape) for shape in shapes]\n        # zero init of exponentially weighted infinity norm\n        us = [K.zeros(shape) for shape in shapes]\n        self.weights = [self.iterations] + ms + us\n\n        for p, g, m, u in zip(params, grads, ms, us):\n\n            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n            u_t = K.maximum(self.beta_2 * u, K.abs(g))\n            p_t = p - lr_t * m_t / (u_t + self.epsilon)\n\n            self.updates.append(K.update(m, m_t))\n            self.updates.append(K.update(u, u_t))\n            new_p = p_t\n\n            # Apply constraints.\n            if getattr(p, 'constraint', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n        return self.updates",
        "begin_line": 486,
        "end_line": 520,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.Adamax.get_config#522",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Adamax",
        "signature": "keras.optimizers.Adamax.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'lr': float(K.get_value(self.lr)),\n                  'beta_1': float(K.get_value(self.beta_1)),\n                  'beta_2': float(K.get_value(self.beta_2)),\n                  'decay': float(K.get_value(self.decay)),\n                  'epsilon': self.epsilon}\n        base_config = super(Adamax, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 522,
        "end_line": 529,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.Nadam.__init__#552",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Nadam",
        "signature": "keras.optimizers.Nadam.__init__(self, lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004, **kwargs)",
        "snippet": "    def __init__(self, lr=0.002, beta_1=0.9, beta_2=0.999,\n                 epsilon=1e-8, schedule_decay=0.004, **kwargs):\n        super(Nadam, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.iterations = K.variable(0, dtype='int64', name='iterations')\n            self.m_schedule = K.variable(1., name='m_schedule')\n            self.lr = K.variable(lr, name='lr')\n            self.beta_1 = K.variable(beta_1, name='beta_1')\n            self.beta_2 = K.variable(beta_2, name='beta_2')\n        self.epsilon = epsilon\n        self.schedule_decay = schedule_decay",
        "begin_line": 552,
        "end_line": 562,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.Nadam.get_updates#565",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Nadam",
        "signature": "keras.optimizers.Nadam.get_updates(self, loss, params)",
        "snippet": "    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        self.updates = [K.update_add(self.iterations, 1)]\n\n        t = K.cast(self.iterations, K.floatx()) + 1\n\n        # Due to the recommendations in [2], i.e. warming momentum schedule\n        momentum_cache_t = self.beta_1 * (1. - 0.5 * (K.pow(K.cast_to_floatx(0.96), t * self.schedule_decay)))\n        momentum_cache_t_1 = self.beta_1 * (1. - 0.5 * (K.pow(K.cast_to_floatx(0.96), (t + 1) * self.schedule_decay)))\n        m_schedule_new = self.m_schedule * momentum_cache_t\n        m_schedule_next = self.m_schedule * momentum_cache_t * momentum_cache_t_1\n        self.updates.append((self.m_schedule, m_schedule_new))\n\n        shapes = [K.int_shape(p) for p in params]\n        ms = [K.zeros(shape) for shape in shapes]\n        vs = [K.zeros(shape) for shape in shapes]\n\n        self.weights = [self.iterations] + ms + vs\n\n        for p, g, m, v in zip(params, grads, ms, vs):\n            # the following equations given in [1]\n            g_prime = g / (1. - m_schedule_new)\n            m_t = self.beta_1 * m + (1. - self.beta_1) * g\n            m_t_prime = m_t / (1. - m_schedule_next)\n            v_t = self.beta_2 * v + (1. - self.beta_2) * K.square(g)\n            v_t_prime = v_t / (1. - K.pow(self.beta_2, t))\n            m_t_bar = (1. - momentum_cache_t) * g_prime + momentum_cache_t_1 * m_t_prime\n\n            self.updates.append(K.update(m, m_t))\n            self.updates.append(K.update(v, v_t))\n\n            p_t = p - self.lr * m_t_bar / (K.sqrt(v_t_prime) + self.epsilon)\n            new_p = p_t\n\n            # Apply constraints.\n            if getattr(p, 'constraint', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n        return self.updates",
        "begin_line": 565,
        "end_line": 604,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.Nadam.get_config#606",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Nadam",
        "signature": "keras.optimizers.Nadam.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'lr': float(K.get_value(self.lr)),\n                  'beta_1': float(K.get_value(self.beta_1)),\n                  'beta_2': float(K.get_value(self.beta_2)),\n                  'epsilon': self.epsilon,\n                  'schedule_decay': self.schedule_decay}\n        base_config = super(Nadam, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 606,
        "end_line": 613,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.TFOptimizer.__init__#620",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.TFOptimizer",
        "signature": "keras.optimizers.TFOptimizer.__init__(self, optimizer)",
        "snippet": "    def __init__(self, optimizer):\n        self.optimizer = optimizer\n        with K.name_scope(self.__class__.__name__):\n            self.iterations = K.variable(0, dtype='int64', name='iterations')",
        "begin_line": 620,
        "end_line": 623,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.TFOptimizer.get_updates#626",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.TFOptimizer",
        "signature": "keras.optimizers.TFOptimizer.get_updates(self, loss, params)",
        "snippet": "    def get_updates(self, loss, params):\n        grads = self.optimizer.compute_gradients(loss, params)\n        self.updates = [K.update_add(self.iterations, 1)]\n        opt_update = self.optimizer.apply_gradients(\n            grads, global_step=self.iterations)\n        self.updates.append(opt_update)\n        return self.updates",
        "begin_line": 626,
        "end_line": 632,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.TFOptimizer.weights#635",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.TFOptimizer",
        "signature": "keras.optimizers.TFOptimizer.weights(self)",
        "snippet": "    def weights(self):\n        raise NotImplementedError",
        "begin_line": 635,
        "end_line": 636,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.TFOptimizer.get_config#638",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.TFOptimizer",
        "signature": "keras.optimizers.TFOptimizer.get_config(self)",
        "snippet": "    def get_config(self):\n        raise NotImplementedError",
        "begin_line": 638,
        "end_line": 639,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.TFOptimizer.from_config#641",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.TFOptimizer",
        "signature": "keras.optimizers.TFOptimizer.from_config(self, config)",
        "snippet": "    def from_config(self, config):\n        raise NotImplementedError",
        "begin_line": 641,
        "end_line": 642,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.serialize#656",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers",
        "signature": "keras.optimizers.serialize(optimizer)",
        "snippet": "def serialize(optimizer):\n    return serialize_keras_object(optimizer)",
        "begin_line": 656,
        "end_line": 657,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011301989150090416,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.deserialize#660",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers",
        "signature": "keras.optimizers.deserialize(config, custom_objects=None)",
        "snippet": "def deserialize(config, custom_objects=None):\n    \"\"\"Inverse of the `serialize` function.\n\n    # Arguments\n        config: Optimizer configuration dictionary.\n        custom_objects: Optional dictionary mapping\n            names (strings) to custom objects\n            (classes and functions)\n            to be considered during deserialization.\n\n    # Returns\n        A Keras Optimizer instance.\n    \"\"\"\n    all_classes = {\n        'sgd': SGD,\n        'rmsprop': RMSprop,\n        'adagrad': Adagrad,\n        'adadelta': Adadelta,\n        'adam': Adam,\n        'adamax': Adamax,\n        'nadam': Nadam,\n        'tfoptimizer': TFOptimizer,\n    }\n    # Make deserialization case-insensitive for built-in optimizers.\n    if config['class_name'].lower() in all_classes:\n        config['class_name'] = config['class_name'].lower()\n    return deserialize_keras_object(config,\n                                    module_objects=all_classes,\n                                    custom_objects=custom_objects,\n                                    printable_module_name='optimizer')",
        "begin_line": 660,
        "end_line": 689,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 8.835483300936562e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.optimizers.get#692",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers",
        "signature": "keras.optimizers.get(identifier)",
        "snippet": "def get(identifier):\n    \"\"\"Retrieves a Keras Optimizer instance.\n\n    # Arguments\n        identifier: Optimizer identifier, one of\n            - String: name of an optimizer\n            - Dictionary: configuration dictionary.\n            - Keras Optimizer instance (it will be returned unchanged).\n            - TensorFlow Optimizer instance\n                (it will be wrapped as a Keras Optimizer).\n\n    # Returns\n        A Keras Optimizer instance.\n\n    # Raises\n        ValueError: If `identifier` cannot be interpreted.\n    \"\"\"\n    if K.backend() == 'tensorflow':\n        # Wrap TF optimizer instances\n        if isinstance(identifier, tf.train.Optimizer):\n            return TFOptimizer(identifier)\n    if isinstance(identifier, dict):\n        return deserialize(identifier)\n    elif isinstance(identifier, six.string_types):\n        config = {'class_name': str(identifier), 'config': {}}\n        return deserialize(config)\n    if isinstance(identifier, Optimizer):\n        return identifier\n    else:\n        raise ValueError('Could not interpret optimizer identifier:',\n                         identifier)",
        "begin_line": 692,
        "end_line": 722,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010219724067450178,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.wrappers.scikit_learn.BaseWrapper.__init__#54",
        "src_path": "keras/wrappers/scikit_learn.py",
        "class_name": "keras.wrappers.scikit_learn.BaseWrapper",
        "signature": "keras.wrappers.scikit_learn.BaseWrapper.__init__(self, build_fn=None, **sk_params)",
        "snippet": "    def __init__(self, build_fn=None, **sk_params):\n        self.build_fn = build_fn\n        self.sk_params = sk_params\n        self.check_params(sk_params)",
        "begin_line": 54,
        "end_line": 57,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.wrappers.scikit_learn.BaseWrapper.check_params#59",
        "src_path": "keras/wrappers/scikit_learn.py",
        "class_name": "keras.wrappers.scikit_learn.BaseWrapper",
        "signature": "keras.wrappers.scikit_learn.BaseWrapper.check_params(self, params)",
        "snippet": "    def check_params(self, params):\n        \"\"\"Checks for user typos in \"params\".\n\n        # Arguments\n            params: dictionary; the parameters to be checked\n\n        # Raises\n            ValueError: if any member of `params` is not a valid argument.\n        \"\"\"\n        legal_params_fns = [Sequential.fit, Sequential.predict,\n                            Sequential.predict_classes, Sequential.evaluate]\n        if self.build_fn is None:\n            legal_params_fns.append(self.__call__)\n        elif (not isinstance(self.build_fn, types.FunctionType) and\n              not isinstance(self.build_fn, types.MethodType)):\n            legal_params_fns.append(self.build_fn.__call__)\n        else:\n            legal_params_fns.append(self.build_fn)\n\n        for params_name in params:\n            for fn in legal_params_fns:\n                if has_arg(fn, params_name):\n                    break\n            else:\n                if params_name != 'nb_epoch':\n                    raise ValueError(\n                        '{} is not a legal parameter'.format(params_name))",
        "begin_line": 59,
        "end_line": 85,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.wrappers.scikit_learn.BaseWrapper.fit#113",
        "src_path": "keras/wrappers/scikit_learn.py",
        "class_name": "keras.wrappers.scikit_learn.BaseWrapper",
        "signature": "keras.wrappers.scikit_learn.BaseWrapper.fit(self, x, y, **kwargs)",
        "snippet": "    def fit(self, x, y, **kwargs):\n        \"\"\"Constructs a new model with `build_fn` & fit the model to `(x, y)`.\n\n        # Arguments\n            x : array-like, shape `(n_samples, n_features)`\n                Training samples where n_samples in the number of samples\n                and n_features is the number of features.\n            y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n                True labels for X.\n            **kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.fit`\n\n        # Returns\n            history : object\n                details about the training history at each epoch.\n        \"\"\"\n        if self.build_fn is None:\n            self.model = self.__call__(**self.filter_sk_params(self.__call__))\n        elif (not isinstance(self.build_fn, types.FunctionType) and\n              not isinstance(self.build_fn, types.MethodType)):\n            self.model = self.build_fn(\n                **self.filter_sk_params(self.build_fn.__call__))\n        else:\n            self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n\n        loss_name = self.model.loss\n        if hasattr(loss_name, '__name__'):\n            loss_name = loss_name.__name__\n        if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n            y = to_categorical(y)\n\n        fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n        fit_args.update(kwargs)\n\n        history = self.model.fit(x, y, **fit_args)\n\n        return history",
        "begin_line": 113,
        "end_line": 149,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.wrappers.scikit_learn.BaseWrapper.filter_sk_params#151",
        "src_path": "keras/wrappers/scikit_learn.py",
        "class_name": "keras.wrappers.scikit_learn.BaseWrapper",
        "signature": "keras.wrappers.scikit_learn.BaseWrapper.filter_sk_params(self, fn, override=None)",
        "snippet": "    def filter_sk_params(self, fn, override=None):\n        \"\"\"Filters `sk_params` and return those in `fn`'s arguments.\n\n        # Arguments\n            fn : arbitrary function\n            override: dictionary, values to override sk_params\n\n        # Returns\n            res : dictionary dictionary containing variables\n                in both sk_params and fn's arguments.\n        \"\"\"\n        override = override or {}\n        res = {}\n        for name, value in self.sk_params.items():\n            if has_arg(fn, name):\n                res.update({name: value})\n        res.update(override)\n        return res",
        "begin_line": 151,
        "end_line": 168,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.wrappers.scikit_learn.KerasClassifier.fit#175",
        "src_path": "keras/wrappers/scikit_learn.py",
        "class_name": "keras.wrappers.scikit_learn.KerasClassifier",
        "signature": "keras.wrappers.scikit_learn.KerasClassifier.fit(self, x, y, **kwargs)",
        "snippet": "    def fit(self, x, y, **kwargs):\n        \"\"\"Constructs a new model with `build_fn` & fit the model to `(x, y)`.\n\n        # Arguments\n            x : array-like, shape `(n_samples, n_features)`\n                Training samples where n_samples in the number of samples\n                and n_features is the number of features.\n            y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n                True labels for X.\n            **kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.fit`\n\n        # Returns\n            history : object\n                details about the training history at each epoch.\n\n        # Raises\n            ValueError: In case of invalid shape for `y` argument.\n        \"\"\"\n        y = np.array(y)\n        if len(y.shape) == 2 and y.shape[1] > 1:\n            self.classes_ = np.arange(y.shape[1])\n        elif (len(y.shape) == 2 and y.shape[1] == 1) or len(y.shape) == 1:\n            self.classes_ = np.unique(y)\n            y = np.searchsorted(self.classes_, y)\n        else:\n            raise ValueError('Invalid shape for y: ' + str(y.shape))\n        self.n_classes_ = len(self.classes_)\n        return super(KerasClassifier, self).fit(x, y, **kwargs)",
        "begin_line": 175,
        "end_line": 203,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.wrappers.scikit_learn.KerasClassifier.predict#205",
        "src_path": "keras/wrappers/scikit_learn.py",
        "class_name": "keras.wrappers.scikit_learn.KerasClassifier",
        "signature": "keras.wrappers.scikit_learn.KerasClassifier.predict(self, x, **kwargs)",
        "snippet": "    def predict(self, x, **kwargs):\n        \"\"\"Returns the class predictions for the given test data.\n\n        # Arguments\n            x: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            **kwargs: dictionary arguments\n                Legal arguments are the arguments\n                of `Sequential.predict_classes`.\n\n        # Returns\n            preds: array-like, shape `(n_samples,)`\n                Class predictions.\n        \"\"\"\n        kwargs = self.filter_sk_params(Sequential.predict_classes, kwargs)\n        classes = self.model.predict_classes(x, **kwargs)\n        return self.classes_[classes]",
        "begin_line": 205,
        "end_line": 222,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.wrappers.scikit_learn.KerasClassifier.predict_proba#224",
        "src_path": "keras/wrappers/scikit_learn.py",
        "class_name": "keras.wrappers.scikit_learn.KerasClassifier",
        "signature": "keras.wrappers.scikit_learn.KerasClassifier.predict_proba(self, x, **kwargs)",
        "snippet": "    def predict_proba(self, x, **kwargs):\n        \"\"\"Returns class probability estimates for the given test data.\n\n        # Arguments\n            x: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            **kwargs: dictionary arguments\n                Legal arguments are the arguments\n                of `Sequential.predict_classes`.\n\n        # Returns\n            proba: array-like, shape `(n_samples, n_outputs)`\n                Class probability estimates.\n                In the case of binary classification,\n                tp match the scikit-learn API,\n                will return an array of shape '(n_samples, 2)'\n                (instead of `(n_sample, 1)` as in Keras).\n        \"\"\"\n        kwargs = self.filter_sk_params(Sequential.predict_proba, kwargs)\n        probs = self.model.predict_proba(x, **kwargs)\n\n        # check if binary classification\n        if probs.shape[1] == 1:\n            # first column is probability of class 0 and second is of class 1\n            probs = np.hstack([1 - probs, probs])\n        return probs",
        "begin_line": 224,
        "end_line": 250,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.wrappers.scikit_learn.KerasClassifier.score#252",
        "src_path": "keras/wrappers/scikit_learn.py",
        "class_name": "keras.wrappers.scikit_learn.KerasClassifier",
        "signature": "keras.wrappers.scikit_learn.KerasClassifier.score(self, x, y, **kwargs)",
        "snippet": "    def score(self, x, y, **kwargs):\n        \"\"\"Returns the mean accuracy on the given test data and labels.\n\n        # Arguments\n            x: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            y: array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n                True labels for x.\n            **kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.evaluate`.\n\n        # Returns\n            score: float\n                Mean accuracy of predictions on X wrt. y.\n\n        # Raises\n            ValueError: If the underlying model isn't configured to\n                compute accuracy. You should pass `metrics=[\"accuracy\"]` to\n                the `.compile()` method of the model.\n        \"\"\"\n        y = np.searchsorted(self.classes_, y)\n        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n\n        loss_name = self.model.loss\n        if hasattr(loss_name, '__name__'):\n            loss_name = loss_name.__name__\n        if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n            y = to_categorical(y)\n\n        outputs = self.model.evaluate(x, y, **kwargs)\n        if not isinstance(outputs, list):\n            outputs = [outputs]\n        for name, output in zip(self.model.metrics_names, outputs):\n            if name == 'acc':\n                return output\n        raise ValueError('The model is not configured to compute accuracy. '\n                         'You should pass `metrics=[\"accuracy\"]` to '\n                         'the `model.compile()` method.')",
        "begin_line": 252,
        "end_line": 290,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.wrappers.scikit_learn.KerasRegressor.predict#297",
        "src_path": "keras/wrappers/scikit_learn.py",
        "class_name": "keras.wrappers.scikit_learn.KerasRegressor",
        "signature": "keras.wrappers.scikit_learn.KerasRegressor.predict(self, x, **kwargs)",
        "snippet": "    def predict(self, x, **kwargs):\n        \"\"\"Returns predictions for the given test data.\n\n        # Arguments\n            x: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            **kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.predict`.\n\n        # Returns\n            preds: array-like, shape `(n_samples,)`\n                Predictions.\n        \"\"\"\n        kwargs = self.filter_sk_params(Sequential.predict, kwargs)\n        return np.squeeze(self.model.predict(x, **kwargs))",
        "begin_line": 297,
        "end_line": 312,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.wrappers.scikit_learn.KerasRegressor.score#314",
        "src_path": "keras/wrappers/scikit_learn.py",
        "class_name": "keras.wrappers.scikit_learn.KerasRegressor",
        "signature": "keras.wrappers.scikit_learn.KerasRegressor.score(self, x, y, **kwargs)",
        "snippet": "    def score(self, x, y, **kwargs):\n        \"\"\"Returns the mean loss on the given test data and labels.\n\n        # Arguments\n            x: array-like, shape `(n_samples, n_features)`\n                Test samples where n_samples in the number of samples\n                and n_features is the number of features.\n            y: array-like, shape `(n_samples,)`\n                True labels for X.\n            **kwargs: dictionary arguments\n                Legal arguments are the arguments of `Sequential.evaluate`.\n\n        # Returns\n            score: float\n                Mean accuracy of predictions on X wrt. y.\n        \"\"\"\n        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n        loss = self.model.evaluate(x, y, **kwargs)\n        if isinstance(loss, list):\n            return -loss[0]\n        return -loss",
        "begin_line": 314,
        "end_line": 334,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.generic_utils.CustomObjectScope.__init__#36",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils.CustomObjectScope",
        "signature": "keras.utils.generic_utils.CustomObjectScope.__init__(self, *args)",
        "snippet": "    def __init__(self, *args):\n        self.custom_objects = args\n        self.backup = None",
        "begin_line": 36,
        "end_line": 38,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001366120218579235,
            "pseudo_dstar_susp": 0.00510204081632653,
            "pseudo_tarantula_susp": 0.0009633911368015414,
            "pseudo_op2_susp": 0.00510204081632653,
            "pseudo_barinel_susp": 0.0009633911368015414
        }
    },
    {
        "name": "keras.utils.generic_utils.CustomObjectScope.__enter__#40",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils.CustomObjectScope",
        "signature": "keras.utils.generic_utils.CustomObjectScope.__enter__(self)",
        "snippet": "    def __enter__(self):\n        self.backup = _GLOBAL_CUSTOM_OBJECTS.copy()\n        for objects in self.custom_objects:\n            _GLOBAL_CUSTOM_OBJECTS.update(objects)\n        return self",
        "begin_line": 40,
        "end_line": 44,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001366120218579235,
            "pseudo_dstar_susp": 0.00510204081632653,
            "pseudo_tarantula_susp": 0.0009633911368015414,
            "pseudo_op2_susp": 0.00510204081632653,
            "pseudo_barinel_susp": 0.0009633911368015414
        }
    },
    {
        "name": "keras.utils.generic_utils.CustomObjectScope.__exit__#46",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils.CustomObjectScope",
        "signature": "keras.utils.generic_utils.CustomObjectScope.__exit__(self, *args, **kwargs)",
        "snippet": "    def __exit__(self, *args, **kwargs):\n        _GLOBAL_CUSTOM_OBJECTS.clear()\n        _GLOBAL_CUSTOM_OBJECTS.update(self.backup)",
        "begin_line": 46,
        "end_line": 48,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001366120218579235,
            "pseudo_dstar_susp": 0.00510204081632653,
            "pseudo_tarantula_susp": 0.0009633911368015414,
            "pseudo_op2_susp": 0.00510204081632653,
            "pseudo_barinel_susp": 0.0009633911368015414
        }
    },
    {
        "name": "keras.utils.generic_utils.custom_object_scope#51",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils",
        "signature": "keras.utils.generic_utils.custom_object_scope(*args)",
        "snippet": "def custom_object_scope(*args):\n    \"\"\"Provides a scope that changes to `_GLOBAL_CUSTOM_OBJECTS` cannot escape.\n\n    Convenience wrapper for `CustomObjectScope`.\n    Code within a `with` statement will be able to access custom objects\n    by name. Changes to global custom objects persist\n    within the enclosing `with` statement. At end of the `with` statement,\n    global custom objects are reverted to state\n    at beginning of the `with` statement.\n\n    # Example\n\n    Consider a custom object `MyObject`\n\n    ```python\n        with custom_object_scope({'MyObject':MyObject}):\n            layer = Dense(..., kernel_regularizer='MyObject')\n            # save, load, etc. will recognize custom object by name\n    ```\n\n    # Arguments\n        *args: Variable length list of dictionaries of name,\n            class pairs to add to custom objects.\n\n    # Returns\n        Object of type `CustomObjectScope`.\n    \"\"\"\n    return CustomObjectScope(*args)",
        "begin_line": 51,
        "end_line": 78,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.generic_utils.serialize_keras_object#101",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils",
        "signature": "keras.utils.generic_utils.serialize_keras_object(instance)",
        "snippet": "def serialize_keras_object(instance):\n    if instance is None:\n        return None\n    if hasattr(instance, 'get_config'):\n        return {\n            'class_name': instance.__class__.__name__,\n            'config': instance.get_config()\n        }\n    if hasattr(instance, '__name__'):\n        return instance.__name__\n    else:\n        raise ValueError('Cannot serialize', instance)",
        "begin_line": 101,
        "end_line": 112,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007987220447284345,
            "pseudo_dstar_susp": 0.0007880220646178094,
            "pseudo_tarantula_susp": 0.0008453085376162299,
            "pseudo_op2_susp": 0.0007880220646178094,
            "pseudo_barinel_susp": 0.0008453085376162299
        }
    },
    {
        "name": "keras.utils.generic_utils.deserialize_keras_object#115",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils",
        "signature": "keras.utils.generic_utils.deserialize_keras_object(identifier, module_objects=None, custom_objects=None, printable_module_name='object')",
        "snippet": "def deserialize_keras_object(identifier, module_objects=None,\n                             custom_objects=None,\n                             printable_module_name='object'):\n    if isinstance(identifier, dict):\n        # In this case we are dealing with a Keras config dictionary.\n        config = identifier\n        if 'class_name' not in config or 'config' not in config:\n            raise ValueError('Improper config format: ' + str(config))\n        class_name = config['class_name']\n        if custom_objects and class_name in custom_objects:\n            cls = custom_objects[class_name]\n        elif class_name in _GLOBAL_CUSTOM_OBJECTS:\n            cls = _GLOBAL_CUSTOM_OBJECTS[class_name]\n        else:\n            module_objects = module_objects or {}\n            cls = module_objects.get(class_name)\n            if cls is None:\n                raise ValueError('Unknown ' + printable_module_name +\n                                 ': ' + class_name)\n        if hasattr(cls, 'from_config'):\n            custom_objects = custom_objects or {}\n            if has_arg(cls.from_config, 'custom_objects'):\n                return cls.from_config(config['config'],\n                                       custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n                                                           list(custom_objects.items())))\n            with CustomObjectScope(custom_objects):\n                return cls.from_config(config['config'])\n        else:\n            # Then `cls` may be a function returning a class.\n            # in this case by convention `config` holds\n            # the kwargs of the function.\n            custom_objects = custom_objects or {}\n            with CustomObjectScope(custom_objects):\n                return cls(**config['config'])\n    elif isinstance(identifier, six.string_types):\n        function_name = identifier\n        if custom_objects and function_name in custom_objects:\n            fn = custom_objects.get(function_name)\n        elif function_name in _GLOBAL_CUSTOM_OBJECTS:\n            fn = _GLOBAL_CUSTOM_OBJECTS[function_name]\n        else:\n            fn = module_objects.get(function_name)\n            if fn is None:\n                raise ValueError('Unknown ' + printable_module_name +\n                                 ':' + function_name)\n        return fn\n    else:\n        raise ValueError('Could not interpret serialized ' +\n                         printable_module_name + ': ' + identifier)",
        "begin_line": 115,
        "end_line": 163,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001652892561983471,
            "pseudo_dstar_susp": 0.00909090909090909,
            "pseudo_tarantula_susp": 0.0015015015015015015,
            "pseudo_op2_susp": 0.00909090909090909,
            "pseudo_barinel_susp": 0.0015015015015015015
        }
    },
    {
        "name": "keras.utils.generic_utils.func_dump#166",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils",
        "signature": "keras.utils.generic_utils.func_dump(func)",
        "snippet": "def func_dump(func):\n    \"\"\"Serializes a user defined function.\n\n    # Arguments\n        func: the function to serialize.\n\n    # Returns\n        A tuple `(code, defaults, closure)`.\n    \"\"\"\n    code = marshal.dumps(func.__code__).decode('raw_unicode_escape')\n    defaults = func.__defaults__\n    if func.__closure__:\n        closure = tuple(c.cell_contents for c in func.__closure__)\n    else:\n        closure = None\n    return code, defaults, closure",
        "begin_line": 166,
        "end_line": 181,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00012818869375721061,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.generic_utils.func_load#184",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils",
        "signature": "keras.utils.generic_utils.func_load(code, defaults=None, closure=None, globs=None)",
        "snippet": "def func_load(code, defaults=None, closure=None, globs=None):\n    \"\"\"Deserializes a user defined function.\n\n    # Arguments\n        code: bytecode of the function.\n        defaults: defaults of the function.\n        closure: closure of the function.\n        globs: dictionary of global objects.\n\n    # Returns\n        A function object.\n    \"\"\"\n    if isinstance(code, (tuple, list)):  # unpack previous dump\n        code, defaults, closure = code\n        if isinstance(defaults, list):\n            defaults = tuple(defaults)\n    code = marshal.loads(code.encode('raw_unicode_escape'))\n    if globs is None:\n        globs = globals()\n    return python_types.FunctionType(code, globs,\n                                     name=code.co_name,\n                                     argdefs=defaults,\n                                     closure=closure)",
        "begin_line": 184,
        "end_line": 206,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00012818869375721061,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.generic_utils.has_arg#209",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils",
        "signature": "keras.utils.generic_utils.has_arg(fn, name, accept_all=False)",
        "snippet": "def has_arg(fn, name, accept_all=False):\n    \"\"\"Checks if a callable accepts a given keyword argument.\n\n    For Python 2, checks if there is an argument with the given name.\n\n    For Python 3, checks if there is an argument with the given name, and\n    also whether this argument can be called with a keyword (i.e. if it is\n    not a positional-only argument).\n\n    # Arguments\n        fn: Callable to inspect.\n        name: Check if `fn` can be called with `name` as a keyword argument.\n        accept_all: What to return if there is no parameter called `name`\n                    but the function accepts a `**kwargs` argument.\n\n    # Returns\n        bool, whether `fn` accepts a `name` keyword argument.\n    \"\"\"\n    if sys.version_info < (3,):\n        arg_spec = inspect.getargspec(fn)\n        if accept_all and arg_spec.keywords is not None:\n            return True\n        return (name in arg_spec.args)\n    elif sys.version_info < (3, 3):\n        arg_spec = inspect.getfullargspec(fn)\n        if accept_all and arg_spec.varkw is not None:\n            return True\n        return (name in arg_spec.args or\n                name in arg_spec.kwonlyargs)\n    else:\n        signature = inspect.signature(fn)\n        parameter = signature.parameters.get(name)\n        if parameter is None:\n            if accept_all:\n                for param in signature.parameters.values():\n                    if param.kind == inspect.Parameter.VAR_KEYWORD:\n                        return True\n            return False\n        return (parameter.kind in (inspect.Parameter.POSITIONAL_OR_KEYWORD,\n                                   inspect.Parameter.KEYWORD_ONLY))",
        "begin_line": 209,
        "end_line": 248,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0013297872340425532,
            "pseudo_dstar_susp": 0.004629629629629629,
            "pseudo_tarantula_susp": 0.0008453085376162299,
            "pseudo_op2_susp": 0.004629629629629629,
            "pseudo_barinel_susp": 0.0008453085376162299
        }
    },
    {
        "name": "keras.utils.generic_utils.Progbar.__init__#259",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils.Progbar",
        "signature": "keras.utils.generic_utils.Progbar.__init__(self, target, width=30, verbose=1, interval=0.05)",
        "snippet": "    def __init__(self, target, width=30, verbose=1, interval=0.05):\n        self.width = width\n        self.target = target\n        self.sum_values = {}\n        self.unique_values = []\n        self.start = time.time()\n        self.last_update = 0\n        self.interval = interval\n        self.total_width = 0\n        self.seen_so_far = 0\n        self.verbose = verbose\n        self._dynamic_display = (sys.stdout.isatty() or\n                                 'ipykernel' in sys.modules)",
        "begin_line": 259,
        "end_line": 271,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.513842641042717e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.utils.generic_utils.Progbar.update#273",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils.Progbar",
        "signature": "keras.utils.generic_utils.Progbar.update(self, current, values=None, force=False)",
        "snippet": "    def update(self, current, values=None, force=False):\n        \"\"\"Updates the progress bar.\n\n        # Arguments\n            current: Index of current step.\n            values: List of tuples (name, value_for_last_step).\n                The progress bar will display averages for these values.\n            force: Whether to force visual progress update.\n        \"\"\"\n        values = values or []\n        for k, v in values:\n            if k not in self.sum_values:\n                self.sum_values[k] = [v * (current - self.seen_so_far),\n                                      current - self.seen_so_far]\n                self.unique_values.append(k)\n            else:\n                self.sum_values[k][0] += v * (current - self.seen_so_far)\n                self.sum_values[k][1] += (current - self.seen_so_far)\n        self.seen_so_far = current\n\n        now = time.time()\n        info = ' - %.0fs' % (now - self.start)\n        if self.verbose == 1:\n            if (not force and (now - self.last_update) < self.interval and\n                    current < self.target):\n                return\n\n            prev_total_width = self.total_width\n            if self._dynamic_display:\n                sys.stdout.write('\\b' * prev_total_width)\n                sys.stdout.write('\\r')\n            else:\n                sys.stdout.write('\\n')\n\n            if self.target is not None:\n                numdigits = int(np.floor(np.log10(self.target))) + 1\n                barstr = '%%%dd/%d [' % (numdigits, self.target)\n                bar = barstr % current\n                prog = float(current) / self.target\n                prog_width = int(self.width * prog)\n                if prog_width > 0:\n                    bar += ('=' * (prog_width - 1))\n                    if current < self.target:\n                        bar += '>'\n                    else:\n                        bar += '='\n                bar += ('.' * (self.width - prog_width))\n                bar += ']'\n            else:\n                bar = '%7d/Unknown' % current\n\n            self.total_width = len(bar)\n            sys.stdout.write(bar)\n\n            if current:\n                time_per_unit = (now - self.start) / current\n            else:\n                time_per_unit = 0\n            if self.target is not None and current < self.target:\n                eta = time_per_unit * (self.target - current)\n                if eta > 3600:\n                    eta_format = '%d:%02d:%02d' % (eta // 3600, (eta % 3600) // 60, eta % 60)\n                elif eta > 60:\n                    eta_format = '%d:%02d' % (eta // 60, eta % 60)\n                else:\n                    eta_format = '%ds' % eta\n\n                info = ' - ETA: %s' % eta_format\n            else:\n                if time_per_unit >= 1:\n                    info += ' %.0fs/step' % time_per_unit\n                elif time_per_unit >= 1e-3:\n                    info += ' %.0fms/step' % (time_per_unit * 1e3)\n                else:\n                    info += ' %.0fus/step' % (time_per_unit * 1e6)\n\n            for k in self.unique_values:\n                info += ' - %s:' % k\n                if isinstance(self.sum_values[k], list):\n                    avg = np.mean(\n                        self.sum_values[k][0] / max(1, self.sum_values[k][1]))\n                    if abs(avg) > 1e-3:\n                        info += ' %.4f' % avg\n                    else:\n                        info += ' %.4e' % avg\n                else:\n                    info += ' %s' % self.sum_values[k]\n\n            self.total_width += len(info)\n            if prev_total_width > self.total_width:\n                info += (' ' * (prev_total_width - self.total_width))\n\n            if self.target is not None and current >= self.target:\n                info += '\\n'\n\n            sys.stdout.write(info)\n            sys.stdout.flush()\n\n        elif self.verbose == 2:\n            if self.target is None or current >= self.target:\n                for k in self.unique_values:\n                    info += ' - %s:' % k\n                    avg = np.mean(\n                        self.sum_values[k][0] / max(1, self.sum_values[k][1]))\n                    if avg > 1e-3:\n                        info += ' %.4f' % avg\n                    else:\n                        info += ' %.4e' % avg\n                info += '\\n'\n\n                sys.stdout.write(info)\n                sys.stdout.flush()\n\n        self.last_update = now",
        "begin_line": 273,
        "end_line": 386,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.constraints.Constraint.get_config#13",
        "src_path": "keras/constraints.py",
        "class_name": "keras.constraints.Constraint",
        "signature": "keras.constraints.Constraint.get_config(self)",
        "snippet": "    def get_config(self):\n        return {}",
        "begin_line": 13,
        "end_line": 14,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.constraints.MaxNorm.__init__#41",
        "src_path": "keras/constraints.py",
        "class_name": "keras.constraints.MaxNorm",
        "signature": "keras.constraints.MaxNorm.__init__(self, max_value=2, axis=0)",
        "snippet": "    def __init__(self, max_value=2, axis=0):\n        self.max_value = max_value\n        self.axis = axis",
        "begin_line": 41,
        "end_line": 43,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010299721907508497,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.constraints.MaxNorm.__call__#45",
        "src_path": "keras/constraints.py",
        "class_name": "keras.constraints.MaxNorm",
        "signature": "keras.constraints.MaxNorm.__call__(self, w)",
        "snippet": "    def __call__(self, w):\n        norms = K.sqrt(K.sum(K.square(w), axis=self.axis, keepdims=True))\n        desired = K.clip(norms, 0, self.max_value)\n        w *= (desired / (K.epsilon() + norms))\n        return w",
        "begin_line": 45,
        "end_line": 49,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011147029316687103,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.constraints.MaxNorm.get_config#51",
        "src_path": "keras/constraints.py",
        "class_name": "keras.constraints.MaxNorm",
        "signature": "keras.constraints.MaxNorm.get_config(self)",
        "snippet": "    def get_config(self):\n        return {'max_value': self.max_value,\n                'axis': self.axis}",
        "begin_line": 51,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010520778537611783,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.constraints.NonNeg.__call__#60",
        "src_path": "keras/constraints.py",
        "class_name": "keras.constraints.NonNeg",
        "signature": "keras.constraints.NonNeg.__call__(self, w)",
        "snippet": "    def __call__(self, w):\n        w *= K.cast(K.greater_equal(w, 0.), K.floatx())\n        return w",
        "begin_line": 60,
        "end_line": 62,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.constraints.UnitNorm.__init__#82",
        "src_path": "keras/constraints.py",
        "class_name": "keras.constraints.UnitNorm",
        "signature": "keras.constraints.UnitNorm.__init__(self, axis=0)",
        "snippet": "    def __init__(self, axis=0):\n        self.axis = axis",
        "begin_line": 82,
        "end_line": 83,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011059500110595002,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.constraints.UnitNorm.__call__#85",
        "src_path": "keras/constraints.py",
        "class_name": "keras.constraints.UnitNorm",
        "signature": "keras.constraints.UnitNorm.__call__(self, w)",
        "snippet": "    def __call__(self, w):\n        return w / (K.epsilon() + K.sqrt(K.sum(K.square(w),\n                                               axis=self.axis,\n                                               keepdims=True)))",
        "begin_line": 85,
        "end_line": 88,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.constraints.UnitNorm.get_config#90",
        "src_path": "keras/constraints.py",
        "class_name": "keras.constraints.UnitNorm",
        "signature": "keras.constraints.UnitNorm.get_config(self)",
        "snippet": "    def get_config(self):\n        return {'axis': self.axis}",
        "begin_line": 90,
        "end_line": 91,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011147029316687103,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.constraints.MinMaxNorm.__init__#123",
        "src_path": "keras/constraints.py",
        "class_name": "keras.constraints.MinMaxNorm",
        "signature": "keras.constraints.MinMaxNorm.__init__(self, min_value=0.0, max_value=1.0, rate=1.0, axis=0)",
        "snippet": "    def __init__(self, min_value=0.0, max_value=1.0, rate=1.0, axis=0):\n        self.min_value = min_value\n        self.max_value = max_value\n        self.rate = rate\n        self.axis = axis",
        "begin_line": 123,
        "end_line": 127,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.constraints.MinMaxNorm.__call__#129",
        "src_path": "keras/constraints.py",
        "class_name": "keras.constraints.MinMaxNorm",
        "signature": "keras.constraints.MinMaxNorm.__call__(self, w)",
        "snippet": "    def __call__(self, w):\n        norms = K.sqrt(K.sum(K.square(w), axis=self.axis, keepdims=True))\n        desired = (self.rate * K.clip(norms, self.min_value, self.max_value) +\n                   (1 - self.rate) * norms)\n        w *= (desired / (K.epsilon() + norms))\n        return w",
        "begin_line": 129,
        "end_line": 134,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.constraints.MinMaxNorm.get_config#136",
        "src_path": "keras/constraints.py",
        "class_name": "keras.constraints.MinMaxNorm",
        "signature": "keras.constraints.MinMaxNorm.get_config(self)",
        "snippet": "    def get_config(self):\n        return {'min_value': self.min_value,\n                'max_value': self.max_value,\n                'rate': self.rate,\n                'axis': self.axis}",
        "begin_line": 136,
        "end_line": 140,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.constraints.serialize#157",
        "src_path": "keras/constraints.py",
        "class_name": "keras.constraints",
        "signature": "keras.constraints.serialize(constraint)",
        "snippet": "def serialize(constraint):\n    return serialize_keras_object(constraint)",
        "begin_line": 157,
        "end_line": 158,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007968127490039841,
            "pseudo_dstar_susp": 0.0007861635220125787,
            "pseudo_tarantula_susp": 0.0008410428931875525,
            "pseudo_op2_susp": 0.0007861635220125787,
            "pseudo_barinel_susp": 0.0008410428931875525
        }
    },
    {
        "name": "keras.constraints.deserialize#161",
        "src_path": "keras/constraints.py",
        "class_name": "keras.constraints",
        "signature": "keras.constraints.deserialize(config, custom_objects=None)",
        "snippet": "def deserialize(config, custom_objects=None):\n    return deserialize_keras_object(config,\n                                    module_objects=globals(),\n                                    custom_objects=custom_objects,\n                                    printable_module_name='constraint')",
        "begin_line": 161,
        "end_line": 165,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010299721907508497,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.constraints.get#168",
        "src_path": "keras/constraints.py",
        "class_name": "keras.constraints",
        "signature": "keras.constraints.get(identifier)",
        "snippet": "def get(identifier):\n    if identifier is None:\n        return None\n    if isinstance(identifier, dict):\n        return deserialize(identifier)\n    elif isinstance(identifier, six.string_types):\n        config = {'class_name': str(identifier), 'config': {}}\n        return deserialize(config)\n    elif callable(identifier):\n        return identifier\n    else:\n        raise ValueError('Could not interpret constraint identifier:',\n                         identifier)",
        "begin_line": 168,
        "end_line": 180,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0014992503748125937,
            "pseudo_dstar_susp": 0.0072992700729927005,
            "pseudo_tarantula_susp": 0.0010427528675703858,
            "pseudo_op2_susp": 0.0072992700729927005,
            "pseudo_barinel_susp": 0.0010427528675703858
        }
    },
    {
        "name": "keras.activations.softmax#9",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.softmax(x, axis=-1)",
        "snippet": "def softmax(x, axis=-1):\n    \"\"\"Softmax activation function.\n\n    # Arguments\n        x : Tensor.\n        axis: Integer, axis along which the softmax normalization is applied.\n\n    # Returns\n        Tensor, output of softmax transformation.\n\n    # Raises\n        ValueError: In case `dim(x) == 1`.\n    \"\"\"\n    ndim = K.ndim(x)\n    if ndim == 2:\n        return K.softmax(x)\n    elif ndim > 2:\n        e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n        s = K.sum(e, axis=axis, keepdims=True)\n        return e / s\n    else:\n        raise ValueError('Cannot apply softmax to a tensor that is 1D')",
        "begin_line": 9,
        "end_line": 30,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.activations.elu#33",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.elu(x, alpha=1.0)",
        "snippet": "def elu(x, alpha=1.0):\n    return K.elu(x, alpha)",
        "begin_line": 33,
        "end_line": 34,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.activations.selu#37",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.selu(x)",
        "snippet": "def selu(x):\n    \"\"\"Scaled Exponential Linear Unit. (Klambauer et al., 2017)\n\n    # Arguments\n        x: A tensor or variable to compute the activation function for.\n\n    # References\n        - [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)\n    \"\"\"\n    alpha = 1.6732632423543772848170429916717\n    scale = 1.0507009873554804934193349852946\n    return scale * K.elu(x, alpha)",
        "begin_line": 37,
        "end_line": 48,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.activations.softplus#51",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.softplus(x)",
        "snippet": "def softplus(x):\n    return K.softplus(x)",
        "begin_line": 51,
        "end_line": 52,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.activations.softsign#55",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.softsign(x)",
        "snippet": "def softsign(x):\n    return K.softsign(x)",
        "begin_line": 55,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.activations.relu#59",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.relu(x, alpha=0.0, max_value=None)",
        "snippet": "def relu(x, alpha=0., max_value=None):\n    return K.relu(x, alpha=alpha, max_value=max_value)",
        "begin_line": 59,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.311853990129435e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.activations.tanh#63",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.tanh(x)",
        "snippet": "def tanh(x):\n    return K.tanh(x)",
        "begin_line": 63,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.436633009342267e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.activations.sigmoid#67",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.sigmoid(x)",
        "snippet": "def sigmoid(x):\n    return K.sigmoid(x)",
        "begin_line": 67,
        "end_line": 68,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.activations.hard_sigmoid#71",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.hard_sigmoid(x)",
        "snippet": "def hard_sigmoid(x):\n    return K.hard_sigmoid(x)",
        "begin_line": 71,
        "end_line": 72,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.795278675678323e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.activations.linear#75",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.linear(x)",
        "snippet": "def linear(x):\n    return x",
        "begin_line": 75,
        "end_line": 76,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007473841554559044,
            "pseudo_dstar_susp": 0.0007407407407407407,
            "pseudo_tarantula_susp": 0.0007513148009015778,
            "pseudo_op2_susp": 0.0007407407407407407,
            "pseudo_barinel_susp": 0.0007513148009015778
        }
    },
    {
        "name": "keras.activations.serialize#79",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.serialize(activation)",
        "snippet": "def serialize(activation):\n    return activation.__name__",
        "begin_line": 79,
        "end_line": 80,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008888888888888889,
            "pseudo_dstar_susp": 0.0008748906386701663,
            "pseudo_tarantula_susp": 0.0009891196834817012,
            "pseudo_op2_susp": 0.0008748906386701663,
            "pseudo_barinel_susp": 0.0009891196834817012
        }
    },
    {
        "name": "keras.activations.deserialize#83",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.deserialize(name, custom_objects=None)",
        "snippet": "def deserialize(name, custom_objects=None):\n    return deserialize_keras_object(name,\n                                    module_objects=globals(),\n                                    custom_objects=custom_objects,\n                                    printable_module_name='activation function')",
        "begin_line": 83,
        "end_line": 87,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001937984496124031,
            "pseudo_dstar_susp": 0.015873015873015872,
            "pseudo_tarantula_susp": 0.0011890606420927466,
            "pseudo_op2_susp": 0.015873015873015872,
            "pseudo_barinel_susp": 0.0011890606420927466
        }
    },
    {
        "name": "keras.activations.get#90",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.get(identifier)",
        "snippet": "def get(identifier):\n    if identifier is None:\n        return linear\n    if isinstance(identifier, six.string_types):\n        identifier = str(identifier)\n        return deserialize(identifier)\n    elif callable(identifier):\n        if isinstance(identifier, Layer):\n            warnings.warn((\n                'Do not pass a layer instance (such as {identifier}) as the '\n                'activation argument of another layer. Instead, advanced '\n                'activation layers should be used just like any other '\n                'layer in a model.'\n            ).format(identifier=identifier.__class__.__name__))\n        return identifier\n    else:\n        raise ValueError('Could not interpret '\n                         'activation function identifier:', identifier)",
        "begin_line": 90,
        "end_line": 107,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001937984496124031,
            "pseudo_dstar_susp": 0.015873015873015872,
            "pseudo_tarantula_susp": 0.0011890606420927466,
            "pseudo_op2_susp": 0.015873015873015872,
            "pseudo_barinel_susp": 0.0011890606420927466
        }
    },
    {
        "name": "keras.engine.topology.InputSpec.__init__#50",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.InputSpec",
        "signature": "keras.engine.topology.InputSpec.__init__(self, dtype=None, shape=None, ndim=None, max_ndim=None, min_ndim=None, axes=None)",
        "snippet": "    def __init__(self, dtype=None,\n                 shape=None,\n                 ndim=None,\n                 max_ndim=None,\n                 min_ndim=None,\n                 axes=None):\n        self.dtype = dtype\n        self.shape = shape\n        if shape is not None:\n            self.ndim = len(shape)\n        else:\n            self.ndim = ndim\n        self.max_ndim = max_ndim\n        self.min_ndim = min_ndim\n        self.axes = axes or {}",
        "begin_line": 50,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0023923444976076554,
            "pseudo_dstar_susp": 0.00510204081632653,
            "pseudo_tarantula_susp": 0.0012836970474967907,
            "pseudo_op2_susp": 0.00510204081632653,
            "pseudo_barinel_susp": 0.0012836970474967907
        }
    },
    {
        "name": "keras.engine.topology.Node.__init__#112",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Node",
        "signature": "keras.engine.topology.Node.__init__(self, outbound_layer, inbound_layers, node_indices, tensor_indices, input_tensors, output_tensors, input_masks, output_masks, input_shapes, output_shapes, arguments=None)",
        "snippet": "    def __init__(self, outbound_layer,\n                 inbound_layers, node_indices, tensor_indices,\n                 input_tensors, output_tensors,\n                 input_masks, output_masks,\n                 input_shapes, output_shapes,\n                 arguments=None):\n        # Layer instance (NOT a list).\n        # this is the layer that takes a list of input tensors\n        # and turns them into a list of output tensors.\n        # the current node will be added to\n        # the inbound_nodes of outbound_layer.\n        self.outbound_layer = outbound_layer\n\n        # The following 3 properties describe where\n        # the input tensors come from: which layers,\n        # and for each layer, which node and which\n        # tensor output of each node.\n\n        # List of layer instances.\n        self.inbound_layers = inbound_layers\n        # List of integers, 1:1 mapping with inbound_layers.\n        self.node_indices = node_indices\n        # List of integers, 1:1 mapping with inbound_layers.\n        self.tensor_indices = tensor_indices\n\n        # Following 2 properties:\n        # tensor inputs and outputs of outbound_layer.\n\n        # List of tensors. 1:1 mapping with inbound_layers.\n        self.input_tensors = input_tensors\n        # List of tensors, created by outbound_layer.call().\n        self.output_tensors = output_tensors\n\n        # Following 2 properties: input and output masks.\n        # List of tensors, 1:1 mapping with input_tensor.\n        self.input_masks = input_masks\n        # List of tensors, created by outbound_layer.compute_mask().\n        self.output_masks = output_masks\n\n        # Following 2 properties: input and output shapes.\n\n        # List of shape tuples, shapes of input_tensors.\n        self.input_shapes = input_shapes\n        # List of shape tuples, shapes of output_tensors.\n        self.output_shapes = output_shapes\n\n        # Optional keyword arguments to layer's `call`.\n        self.arguments = arguments\n\n        # Add nodes to all layers involved.\n        for layer in inbound_layers:\n            if layer is not None:\n                layer.outbound_nodes.append(self)\n        outbound_layer.inbound_nodes.append(self)",
        "begin_line": 112,
        "end_line": 165,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006067961165048543,
            "pseudo_dstar_susp": 0.0006067961165048543,
            "pseudo_tarantula_susp": 0.0006075334143377885,
            "pseudo_op2_susp": 0.0006067961165048543,
            "pseudo_barinel_susp": 0.0006075334143377885
        }
    },
    {
        "name": "keras.engine.topology.Node.get_config#167",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Node",
        "signature": "keras.engine.topology.Node.get_config(self)",
        "snippet": "    def get_config(self):\n        inbound_names = []\n        for layer in self.inbound_layers:\n            if layer:\n                inbound_names.append(layer.name)\n            else:\n                inbound_names.append(None)\n        return {'outbound_layer': self.outbound_layer.name if self.outbound_layer else None,\n                'inbound_layers': inbound_names,\n                'node_indices': self.node_indices,\n                'tensor_indices': self.tensor_indices}",
        "begin_line": 167,
        "end_line": 177,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.topology.Layer.__init__#247",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.__init__(self, **kwargs)",
        "snippet": "    def __init__(self, **kwargs):\n        self.input_spec = None\n        self.supports_masking = False\n\n        # These properties will be set upon call of self.build()\n        self._trainable_weights = []\n        self._non_trainable_weights = []\n        self._losses = []\n        self._updates = []\n        self._per_input_losses = {}\n        self._per_input_updates = {}\n        self._built = False\n\n        # These lists will be filled via successive calls\n        # to self._add_inbound_node().\n        self.inbound_nodes = []\n        self.outbound_nodes = []\n\n        # These properties should be set by the user via keyword arguments.\n        # note that 'dtype', 'input_shape' and 'batch_input_shape'\n        # are only applicable to input layers: do not pass these keywords\n        # to non-input layers.\n        allowed_kwargs = {'input_shape',\n                          'batch_input_shape',\n                          'batch_size',\n                          'dtype',\n                          'name',\n                          'trainable',\n                          'weights',\n                          'input_dtype',  # legacy\n                          }\n        for kwarg in kwargs:\n            if kwarg not in allowed_kwargs:\n                raise TypeError('Keyword argument not understood:', kwarg)\n        name = kwargs.get('name')\n        if not name:\n            prefix = self.__class__.__name__\n            name = _to_snake_case(prefix) + '_' + str(K.get_uid(prefix))\n        self.name = name\n\n        self.trainable = kwargs.get('trainable', True)\n        if 'input_shape' in kwargs or 'batch_input_shape' in kwargs:\n            # In this case we will later create an input layer\n            # to insert before the current layer\n            if 'batch_input_shape' in kwargs:\n                batch_input_shape = tuple(kwargs['batch_input_shape'])\n            elif 'input_shape' in kwargs:\n                if 'batch_size' in kwargs:\n                    batch_size = kwargs['batch_size']\n                else:\n                    batch_size = None\n                batch_input_shape = (batch_size,) + tuple(kwargs['input_shape'])\n            self.batch_input_shape = batch_input_shape\n\n            # Set dtype.\n            dtype = kwargs.get('dtype')\n            if dtype is None:\n                dtype = kwargs.get('input_dtype')\n            if dtype is None:\n                dtype = K.floatx()\n            self.dtype = dtype\n\n        if 'weights' in kwargs:\n            self._initial_weights = kwargs['weights']\n        else:\n            self._initial_weights = None",
        "begin_line": 247,
        "end_line": 312,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0014245014245014246,
            "pseudo_dstar_susp": 0.005952380952380952,
            "pseudo_tarantula_susp": 0.0009940357852882703,
            "pseudo_op2_susp": 0.005952380952380952,
            "pseudo_barinel_susp": 0.0009940357852882703
        }
    },
    {
        "name": "keras.engine.topology.Layer._node_key#315",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer._node_key(layer, node_index)",
        "snippet": "    def _node_key(layer, node_index):\n        \"\"\"Converts a layer and its index to a unique (immutable type) name.\n        This function is used internally with `self.container_nodes`.\n\n        # Arguments\n            layer: The layer.\n            node_index: The layer's position (e.g. via enumerate) in a list of\n                nodes.\n\n        # Returns\n            The unique name.\n        \"\"\"\n        return layer.name + '_ib-' + str(node_index)",
        "begin_line": 315,
        "end_line": 327,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.000643915003219575,
            "pseudo_dstar_susp": 0.000643915003219575,
            "pseudo_tarantula_susp": 0.000646830530401035,
            "pseudo_op2_susp": 0.000643915003219575,
            "pseudo_barinel_susp": 0.000646830530401035
        }
    },
    {
        "name": "keras.engine.topology.Layer.losses#330",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.losses(self)",
        "snippet": "    def losses(self):\n        return self._losses",
        "begin_line": 330,
        "end_line": 331,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 8.705493166187865e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.topology.Layer.updates#334",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.updates(self)",
        "snippet": "    def updates(self):\n        return self._updates",
        "begin_line": 334,
        "end_line": 335,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 8.87154009936125e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.topology.Layer.built#338",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.built(self)",
        "snippet": "    def built(self):\n        return self._built",
        "begin_line": 338,
        "end_line": 339,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005885815185403178,
            "pseudo_dstar_susp": 0.0005885815185403178,
            "pseudo_tarantula_susp": 0.0005889281507656066,
            "pseudo_op2_susp": 0.0005885815185403178,
            "pseudo_barinel_susp": 0.0005889281507656066
        }
    },
    {
        "name": "keras.engine.topology.Layer.built#342",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.built(self, value)",
        "snippet": "    def built(self, value):\n        self._built = value",
        "begin_line": 342,
        "end_line": 343,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0014104372355430183,
            "pseudo_dstar_susp": 0.005780346820809248,
            "pseudo_tarantula_susp": 0.0009871668311944718,
            "pseudo_op2_susp": 0.005780346820809248,
            "pseudo_barinel_susp": 0.0009871668311944718
        }
    },
    {
        "name": "keras.engine.topology.Layer.trainable_weights#346",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.trainable_weights(self)",
        "snippet": "    def trainable_weights(self):\n        trainable = getattr(self, 'trainable', True)\n        if trainable:\n            return self._trainable_weights\n        else:\n            return []",
        "begin_line": 346,
        "end_line": 351,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.014285714285714285,
            "pseudo_tarantula_susp": 0.0011441647597254005,
            "pseudo_op2_susp": 0.014285714285714285,
            "pseudo_barinel_susp": 0.0011441647597254005
        }
    },
    {
        "name": "keras.engine.topology.Layer.non_trainable_weights#358",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.non_trainable_weights(self)",
        "snippet": "    def non_trainable_weights(self):\n        trainable = getattr(self, 'trainable', True)\n        if not trainable:\n            return self._trainable_weights + self._non_trainable_weights\n        else:\n            return self._non_trainable_weights",
        "begin_line": 358,
        "end_line": 363,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0027624309392265192,
            "pseudo_dstar_susp": 0.017543859649122806,
            "pseudo_tarantula_susp": 0.0012547051442910915,
            "pseudo_op2_susp": 0.017543859649122806,
            "pseudo_barinel_susp": 0.0012547051442910915
        }
    },
    {
        "name": "keras.engine.topology.Layer.add_weight#370",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.add_weight(self, name, shape, dtype=None, initializer=None, regularizer=None, trainable=True, constraint=None)",
        "snippet": "    def add_weight(self,\n                   name,\n                   shape,\n                   dtype=None,\n                   initializer=None,\n                   regularizer=None,\n                   trainable=True,\n                   constraint=None):\n        \"\"\"Adds a weight variable to the layer.\n\n        # Arguments\n            name: String, the name for the weight variable.\n            shape: The shape tuple of the weight.\n            dtype: The dtype of the weight.\n            initializer: An Initializer instance (callable).\n            regularizer: An optional Regularizer instance.\n            trainable: A boolean, whether the weight should\n                be trained via backprop or not (assuming\n                that the layer itself is also trainable).\n            constraint: An optional Constraint instance.\n\n        # Returns\n            The created weight variable.\n        \"\"\"\n        initializer = initializers.get(initializer)\n        if dtype is None:\n            dtype = K.floatx()\n        weight = K.variable(initializer(shape),\n                            dtype=dtype,\n                            name=name,\n                            constraint=constraint)\n        if regularizer is not None:\n            self.add_loss(regularizer(weight))\n        if trainable:\n            self._trainable_weights.append(weight)\n        else:\n            self._non_trainable_weights.append(weight)\n        return weight",
        "begin_line": 370,
        "end_line": 407,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0017035775127768314,
            "pseudo_dstar_susp": 0.010869565217391304,
            "pseudo_tarantula_susp": 0.0011001100110011,
            "pseudo_op2_susp": 0.010869565217391304,
            "pseudo_barinel_susp": 0.0011001100110011
        }
    },
    {
        "name": "keras.engine.topology.Layer.assert_input_compatibility#409",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.assert_input_compatibility(self, inputs)",
        "snippet": "    def assert_input_compatibility(self, inputs):\n        \"\"\"Checks compatibility between the layer and provided inputs.\n\n        This checks that the tensor(s) `input`\n        verify the input assumptions of the layer\n        (if any). If not, exceptions are raised.\n\n        # Arguments\n            inputs: input tensor or list of input tensors.\n\n        # Raises\n            ValueError: in case of mismatch between\n                the provided inputs and the expectations of the layer.\n        \"\"\"\n        inputs = _to_list(inputs)\n        for x in inputs:\n            try:\n                K.is_keras_tensor(x)\n            except ValueError:\n                raise ValueError('Layer ' + self.name + ' was called with '\n                                 'an input that isn\\'t a symbolic tensor. '\n                                 'Received type: ' +\n                                 str(type(x)) + '. Full input: ' +\n                                 str(inputs) + '. All inputs to the layer '\n                                 'should be tensors.')\n\n        if not self.input_spec:\n            return\n        if not isinstance(self.input_spec, (list, tuple)):\n            input_spec = _to_list(self.input_spec)\n        else:\n            input_spec = self.input_spec\n        if len(inputs) != len(input_spec):\n            raise ValueError('Layer ' + self.name + ' expects ' +\n                             str(len(input_spec)) + ' inputs, '\n                             'but it received ' + str(len(inputs)) +\n                             ' input tensors. Input received: ' +\n                             str(inputs))\n        for input_index, (x, spec) in enumerate(zip(inputs, input_spec)):\n            if spec is None:\n                continue\n\n            # Check ndim.\n            if spec.ndim is not None:\n                if K.ndim(x) != spec.ndim:\n                    raise ValueError('Input ' + str(input_index) +\n                                     ' is incompatible with layer ' +\n                                     self.name + ': expected ndim=' +\n                                     str(spec.ndim) + ', found ndim=' +\n                                     str(K.ndim(x)))\n            if spec.max_ndim is not None:\n                ndim = K.ndim(x)\n                if ndim is not None and ndim > spec.max_ndim:\n                    raise ValueError('Input ' + str(input_index) +\n                                     ' is incompatible with layer ' +\n                                     self.name + ': expected max_ndim=' +\n                                     str(spec.max_ndim) + ', found ndim=' +\n                                     str(K.ndim(x)))\n            if spec.min_ndim is not None:\n                ndim = K.ndim(x)\n                if ndim is not None and ndim < spec.min_ndim:\n                    raise ValueError('Input ' + str(input_index) +\n                                     ' is incompatible with layer ' +\n                                     self.name + ': expected min_ndim=' +\n                                     str(spec.min_ndim) + ', found ndim=' +\n                                     str(K.ndim(x)))\n            # Check dtype.\n            if spec.dtype is not None:\n                if K.dtype(x) != spec.dtype:\n                    raise ValueError('Input ' + str(input_index) +\n                                     ' is incompatible with layer ' +\n                                     self.name + ': expected dtype=' +\n                                     str(spec.dtype) + ', found dtype=' +\n                                     str(K.dtype(x)))\n            # Check specific shape axes.\n            if spec.axes:\n                try:\n                    x_shape = K.int_shape(x)\n                except TypeError:\n                    x_shape = None\n                if x_shape is not None:\n                    for axis, value in spec.axes.items():\n                        if value is not None and x_shape[int(axis)] not in {value, None}:\n                            raise ValueError('Input ' + str(input_index) +\n                                             ' is incompatible with layer ' +\n                                             self.name + ': expected axis ' +\n                                             str(axis) + ' of input shape to have '\n                                             'value ' + str(value) +\n                                             ' but got shape ' + str(x_shape))\n            # Check shape.\n            if spec.shape is not None:\n                try:\n                    x_shape = K.int_shape(x)\n                except TypeError:\n                    x_shape = None\n                if x_shape is not None:\n                    for spec_dim, dim in zip(spec.shape, x_shape):\n                        if spec_dim is not None and dim is not None:\n                            if spec_dim != dim:\n                                raise ValueError(\n                                    'Input ' + str(input_index) +\n                                    ' is incompatible with layer ' +\n                                    self.name + ': expected shape=' +\n                                    str(spec.shape) + ', found shape=' +\n                                    str(x_shape))",
        "begin_line": 409,
        "end_line": 513,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.005813953488372093,
            "pseudo_dstar_susp": 0.0018181818181818182,
            "pseudo_tarantula_susp": 0.006134969325153374,
            "pseudo_op2_susp": 0.0018181818181818182,
            "pseudo_barinel_susp": 0.006134969325153374
        }
    },
    {
        "name": "keras.engine.topology.Layer.call#515",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.call(self, inputs, **kwargs)",
        "snippet": "    def call(self, inputs, **kwargs):\n        \"\"\"This is where the layer's logic lives.\n\n        # Arguments\n            inputs: Input tensor, or list/tuple of input tensors.\n            **kwargs: Additional keyword arguments.\n\n        # Returns\n            A tensor or list/tuple of tensors.\n        \"\"\"\n        return inputs",
        "begin_line": 515,
        "end_line": 525,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0018975332068311196,
            "pseudo_dstar_susp": 0.0013054830287206266,
            "pseudo_tarantula_susp": 0.002551020408163265,
            "pseudo_op2_susp": 0.0013054830287206266,
            "pseudo_barinel_susp": 0.002551020408163265
        }
    },
    {
        "name": "keras.engine.topology.Layer.__call__#527",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.__call__(self, inputs, **kwargs)",
        "snippet": "    def __call__(self, inputs, **kwargs):\n        \"\"\"Wrapper around self.call(), for handling internal references.\n\n        If a Keras tensor is passed:\n            - We call self._add_inbound_node().\n            - If necessary, we `build` the layer to match\n                the _keras_shape of the input(s).\n            - We update the _keras_shape of every input tensor with\n                its new shape (obtained via self.compute_output_shape).\n                This is done as part of _add_inbound_node().\n            - We update the _keras_history of the output tensor(s)\n                with the current layer.\n                This is done as part of _add_inbound_node().\n\n        # Arguments\n            inputs: Can be a tensor or list/tuple of tensors.\n            **kwargs: Additional keyword arguments to be passed to `call()`.\n\n        # Returns\n            Output of the layer's `call` method.\n\n        # Raises\n            ValueError: in case the layer is missing shape information\n                for its `build` call.\n        \"\"\"\n        if isinstance(inputs, list):\n            inputs = inputs[:]\n        with K.name_scope(self.name):\n            # Handle laying building (weight creating, input spec locking).\n            if not self.built:\n                # Raise exceptions in case the input is not compatible\n                # with the input_spec specified in the layer constructor.\n                self.assert_input_compatibility(inputs)\n\n                # Collect input shapes to build layer.\n                input_shapes = []\n                for x_elem in _to_list(inputs):\n                    if hasattr(x_elem, '_keras_shape'):\n                        input_shapes.append(x_elem._keras_shape)\n                    elif hasattr(K, 'int_shape'):\n                        input_shapes.append(K.int_shape(x_elem))\n                    else:\n                        raise ValueError('You tried to call layer \"' + self.name +\n                                         '\". This layer has no information'\n                                         ' about its expected input shape, '\n                                         'and thus cannot be built. '\n                                         'You can build it manually via: '\n                                         '`layer.build(batch_input_shape)`')\n                if len(input_shapes) == 1:\n                    self.build(input_shapes[0])\n                else:\n                    self.build(input_shapes)\n                self.built = True\n\n                # Load weights that were specified at layer instantiation.\n                if self._initial_weights is not None:\n                    self.set_weights(self._initial_weights)\n\n            # Raise exceptions in case the input is not compatible\n            # with the input_spec set at build time.\n            self.assert_input_compatibility(inputs)\n\n            # Handle mask propagation.\n            previous_mask = _collect_previous_mask(inputs)\n            user_kwargs = copy.copy(kwargs)\n            if not _is_all_none(previous_mask):\n                # The previous layer generated a mask.\n                if has_arg(self.call, 'mask'):\n                    if 'mask' not in kwargs:\n                        # If mask is explicitly passed to __call__,\n                        # we should override the default mask.\n                        kwargs['mask'] = previous_mask\n            # Handle automatic shape inference (only useful for Theano).\n            input_shape = _collect_input_shape(inputs)\n\n            # Actually call the layer, collecting output(s), mask(s), and shape(s).\n            output = self.call(inputs, **kwargs)\n            output_mask = self.compute_mask(inputs, previous_mask)\n\n            # If the layer returns tensors from its inputs, unmodified,\n            # we copy them to avoid loss of tensor metadata.\n            output_ls = _to_list(output)\n            inputs_ls = _to_list(inputs)\n            output_ls_copy = []\n            for x in output_ls:\n                if x in inputs_ls:\n                    x = K.identity(x)\n                output_ls_copy.append(x)\n            if len(output_ls_copy) == 1:\n                output = output_ls_copy[0]\n            else:\n                output = output_ls_copy\n\n            # Inferring the output shape is only relevant for Theano.\n            if all([s is not None for s in _to_list(input_shape)]):\n                output_shape = self.compute_output_shape(input_shape)\n            else:\n                if isinstance(input_shape, list):\n                    output_shape = [None for _ in input_shape]\n                else:\n                    output_shape = None\n\n            if not isinstance(output_mask, (list, tuple)) and len(output_ls) > 1:\n                # Augment the mask to match the length of the output.\n                output_mask = [output_mask] * len(output_ls)\n\n            # Add an inbound node to the layer, so that it keeps track\n            # of the call and of all new variables created during the call.\n            # This also updates the layer history of the output tensor(s).\n            # If the input tensor(s) had not previous Keras history,\n            # this does nothing.\n            self._add_inbound_node(input_tensors=inputs, output_tensors=output,\n                                   input_masks=previous_mask, output_masks=output_mask,\n                                   input_shapes=input_shape, output_shapes=output_shape,\n                                   arguments=user_kwargs)\n\n            # Apply activity regularizer if any:\n            if hasattr(self, 'activity_regularizer') and self.activity_regularizer is not None:\n                regularization_losses = [self.activity_regularizer(x) for x in _to_list(output)]\n                self.add_loss(regularization_losses, _to_list(inputs))\n        return output",
        "begin_line": 527,
        "end_line": 647,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 1.0,
            "pseudo_dstar_susp": 0.0029585798816568047,
            "pseudo_tarantula_susp": 0.023255813953488372,
            "pseudo_op2_susp": 0.0029585798816568047,
            "pseudo_barinel_susp": 0.023255813953488372
        }
    },
    {
        "name": "keras.engine.topology.Layer._add_inbound_node#649",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer._add_inbound_node(self, input_tensors, output_tensors, input_masks, output_masks, input_shapes, output_shapes, arguments=None)",
        "snippet": "    def _add_inbound_node(self, input_tensors, output_tensors,\n                          input_masks, output_masks,\n                          input_shapes, output_shapes, arguments=None):\n        \"\"\"Internal method to create an inbound node for the layer.\n\n        # Arguments\n            input_tensors: list of input tensors.\n            output_tensors: list of output tensors.\n            input_masks: list of input masks (a mask can be a tensor, or None).\n            output_masks: list of output masks (a mask can be a tensor, or None).\n            input_shapes: list of input shape tuples.\n            output_shapes: list of output shape tuples.\n            arguments: dictionary of keyword arguments that were passed to the\n                `call` method of the layer at the call that created the node.\n        \"\"\"\n        input_tensors = _to_list(input_tensors)\n        output_tensors = _to_list(output_tensors)\n        input_masks = _to_list(input_masks)\n        output_masks = _to_list(output_masks)\n        input_shapes = _to_list(input_shapes)\n        output_shapes = _to_list(output_shapes)\n\n        # Collect input tensor(s) coordinates.\n        inbound_layers = []\n        node_indices = []\n        tensor_indices = []\n        for x in input_tensors:\n            if hasattr(x, '_keras_history'):\n                inbound_layer, node_index, tensor_index = x._keras_history\n                inbound_layers.append(inbound_layer)\n                node_indices.append(node_index)\n                tensor_indices.append(tensor_index)\n            else:\n                inbound_layers.append(None)\n                node_indices.append(None)\n                tensor_indices.append(None)\n\n        # Create node, add it to inbound nodes.\n        Node(\n            self,\n            inbound_layers=inbound_layers,\n            node_indices=node_indices,\n            tensor_indices=tensor_indices,\n            input_tensors=input_tensors,\n            output_tensors=output_tensors,\n            input_masks=input_masks,\n            output_masks=output_masks,\n            input_shapes=input_shapes,\n            output_shapes=output_shapes,\n            arguments=arguments\n        )\n\n        # Update tensor history, _keras_shape and _uses_learning_phase.\n        for i in range(len(output_tensors)):\n            output_tensors[i]._keras_shape = output_shapes[i]\n            uses_lp = any([getattr(x, '_uses_learning_phase', False) for x in input_tensors])\n            uses_lp = getattr(self, 'uses_learning_phase', False) or uses_lp\n            output_tensors[i]._uses_learning_phase = getattr(output_tensors[i], '_uses_learning_phase', False) or uses_lp\n            output_tensors[i]._keras_history = (self,\n                                                len(self.inbound_nodes) - 1,\n                                                i)",
        "begin_line": 649,
        "end_line": 709,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001564945226917058,
            "pseudo_dstar_susp": 0.002512562814070352,
            "pseudo_tarantula_susp": 0.0022172949002217295,
            "pseudo_op2_susp": 0.002512562814070352,
            "pseudo_barinel_susp": 0.0022172949002217295
        }
    },
    {
        "name": "keras.engine.topology.Layer.compute_output_shape#711",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        \"\"\"Computes the output shape of the layer.\n\n        Assumes that the layer will be built\n        to match that input shape provided.\n\n        # Arguments\n            input_shape: Shape tuple (tuple of integers)\n                or list of shape tuples (one per output tensor of the layer).\n                Shape tuples can include None for free dimensions,\n                instead of an integer.\n\n        # Returns\n            An input shape tuple.\n        \"\"\"\n        if hasattr(self, 'get_output_shape_for'):\n            msg = \"Class `{}.{}` defines `get_output_shape_for` but does not override `compute_output_shape`. \" + \\\n                  \"If this is a Keras 1 layer, please implement `compute_output_shape` to support Keras 2.\"\n            warnings.warn(msg.format(type(self).__module__, type(self).__name__), stacklevel=2)\n        return input_shape",
        "begin_line": 711,
        "end_line": 730,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.000777000777000777,
            "pseudo_dstar_susp": 0.0007686395080707148,
            "pseudo_tarantula_susp": 0.00078125,
            "pseudo_op2_susp": 0.0007686395080707148,
            "pseudo_barinel_susp": 0.00078125
        }
    },
    {
        "name": "keras.engine.topology.Layer.compute_mask#732",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.compute_mask(self, inputs, mask=None)",
        "snippet": "    def compute_mask(self, inputs, mask=None):\n        \"\"\"Computes an output mask tensor.\n\n        # Arguments\n            inputs: Tensor or list of tensors.\n            mask: Tensor or list of tensors.\n\n        # Returns\n            None or a tensor (or list of tensors,\n                one per output tensor of the layer).\n        \"\"\"\n        if not self.supports_masking:\n            if mask is not None:\n                if isinstance(mask, list):\n                    if any(m is not None for m in mask):\n                        raise TypeError('Layer ' + self.name +\n                                        ' does not support masking, '\n                                        'but was passed an input_mask: ' +\n                                        str(mask))\n                else:\n                    raise TypeError('Layer ' + self.name +\n                                    ' does not support masking, '\n                                    'but was passed an input_mask: ' +\n                                    str(mask))\n            # masking not explicitly supported: return None as mask\n            return None\n        # if masking is explicitly supported, by default\n        # carry over the input mask\n        return mask",
        "begin_line": 732,
        "end_line": 760,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007955449482895784,
            "pseudo_dstar_susp": 0.0007849293563579278,
            "pseudo_tarantula_susp": 0.0008097165991902834,
            "pseudo_op2_susp": 0.0007849293563579278,
            "pseudo_barinel_susp": 0.0008097165991902834
        }
    },
    {
        "name": "keras.engine.topology.Layer.build#762",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        \"\"\"Creates the layer weights.\n\n        Must be implemented on all layers that have weights.\n\n        # Arguments\n            input_shape: Keras tensor (future input to layer)\n                or list/tuple of Keras tensors to reference\n                for weight shape computations.\n        \"\"\"\n        self.built = True",
        "begin_line": 762,
        "end_line": 772,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.051412020275162e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.topology.Layer._get_node_attribute_at_index#774",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer._get_node_attribute_at_index(self, node_index, attr, attr_name)",
        "snippet": "    def _get_node_attribute_at_index(self, node_index, attr, attr_name):\n        \"\"\"Retrieves an attribute (e.g. input_tensors) from a node.\n\n        This is used to implement the methods:\n            - get_input_shape_at\n            - get_output_shape_at\n            - get_input_at\n            etc...\n\n        # Arguments\n            node_index: Integer index of the node from which\n                to retrieve the attribute.\n            attr: Exact node attribute name.\n            attr_name: Human-readable attribute name, for error messages.\n\n        # Returns\n            The layer's attribute `attr` at the node of index `node_index`.\n\n        # Raises\n            RuntimeError: If the layer has no inbound nodes.\n            ValueError: If the index is does not match any node.\n        \"\"\"\n        if not self.inbound_nodes:\n            raise RuntimeError('The layer has never been called '\n                               'and thus has no defined ' + attr_name + '.')\n        if not len(self.inbound_nodes) > node_index:\n            raise ValueError('Asked to get ' + attr_name +\n                             ' at node ' + str(node_index) +\n                             ', but the layer has only ' +\n                             str(len(self.inbound_nodes)) + ' inbound nodes.')\n        values = getattr(self.inbound_nodes[node_index], attr)\n        if len(values) == 1:\n            return values[0]\n        else:\n            return values",
        "begin_line": 774,
        "end_line": 808,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006105006105006105,
            "pseudo_dstar_susp": 0.0006105006105006105,
            "pseudo_tarantula_susp": 0.0006112469437652812,
            "pseudo_op2_susp": 0.0006105006105006105,
            "pseudo_barinel_susp": 0.0006112469437652812
        }
    },
    {
        "name": "keras.engine.topology.Layer.get_input_shape_at#810",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.get_input_shape_at(self, node_index)",
        "snippet": "    def get_input_shape_at(self, node_index):\n        \"\"\"Retrieves the input shape(s) of a layer at a given node.\n\n        # Arguments\n            node_index: Integer, index of the node\n                from which to retrieve the attribute.\n                E.g. `node_index=0` will correspond to the\n                first time the layer was called.\n\n        # Returns\n            A shape tuple\n            (or list of shape tuples if the layer has multiple inputs).\n        \"\"\"\n        return self._get_node_attribute_at_index(node_index,\n                                                 'input_shapes',\n                                                 'input shape')",
        "begin_line": 810,
        "end_line": 825,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.topology.Layer.get_output_shape_at#827",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.get_output_shape_at(self, node_index)",
        "snippet": "    def get_output_shape_at(self, node_index):\n        \"\"\"Retrieves the output shape(s) of a layer at a given node.\n\n        # Arguments\n            node_index: Integer, index of the node\n                from which to retrieve the attribute.\n                E.g. `node_index=0` will correspond to the\n                first time the layer was called.\n\n        # Returns\n            A shape tuple\n            (or list of shape tuples if the layer has multiple outputs).\n        \"\"\"\n        return self._get_node_attribute_at_index(node_index,\n                                                 'output_shapes',\n                                                 'output shape')",
        "begin_line": 827,
        "end_line": 842,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011147029316687103,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.topology.Layer.get_input_at#844",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.get_input_at(self, node_index)",
        "snippet": "    def get_input_at(self, node_index):\n        \"\"\"Retrieves the input tensor(s) of a layer at a given node.\n\n        # Arguments\n            node_index: Integer, index of the node\n                from which to retrieve the attribute.\n                E.g. `node_index=0` will correspond to the\n                first time the layer was called.\n\n        # Returns\n            A tensor (or list of tensors if the layer has multiple inputs).\n        \"\"\"\n        return self._get_node_attribute_at_index(node_index,\n                                                 'input_tensors',\n                                                 'input')",
        "begin_line": 844,
        "end_line": 858,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.topology.Layer.get_output_at#860",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.get_output_at(self, node_index)",
        "snippet": "    def get_output_at(self, node_index):\n        \"\"\"Retrieves the output tensor(s) of a layer at a given node.\n\n        # Arguments\n            node_index: Integer, index of the node\n                from which to retrieve the attribute.\n                E.g. `node_index=0` will correspond to the\n                first time the layer was called.\n\n        # Returns\n            A tensor (or list of tensors if the layer has multiple outputs).\n        \"\"\"\n        return self._get_node_attribute_at_index(node_index,\n                                                 'output_tensors',\n                                                 'output')",
        "begin_line": 860,
        "end_line": 874,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.topology.Layer.get_input_mask_at#876",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.get_input_mask_at(self, node_index)",
        "snippet": "    def get_input_mask_at(self, node_index):\n        \"\"\"Retrieves the input mask tensor(s) of a layer at a given node.\n\n        # Arguments\n            node_index: Integer, index of the node\n                from which to retrieve the attribute.\n                E.g. `node_index=0` will correspond to the\n                first time the layer was called.\n\n        # Returns\n            A mask tensor\n            (or list of tensors if the layer has multiple inputs).\n        \"\"\"\n        return self._get_node_attribute_at_index(node_index,\n                                                 'input_masks',\n                                                 'input mask')",
        "begin_line": 876,
        "end_line": 891,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.topology.Layer.get_output_mask_at#893",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.get_output_mask_at(self, node_index)",
        "snippet": "    def get_output_mask_at(self, node_index):\n        \"\"\"Retrieves the output mask tensor(s) of a layer at a given node.\n\n        # Arguments\n            node_index: Integer, index of the node\n                from which to retrieve the attribute.\n                E.g. `node_index=0` will correspond to the\n                first time the layer was called.\n\n        # Returns\n            A mask tensor\n            (or list of tensors if the layer has multiple outputs).\n        \"\"\"\n        return self._get_node_attribute_at_index(node_index,\n                                                 'output_masks',\n                                                 'output mask')",
        "begin_line": 893,
        "end_line": 908,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.topology.Layer.input#911",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.input(self)",
        "snippet": "    def input(self):\n        \"\"\"Retrieves the input tensor(s) of a layer.\n\n        Only applicable if the layer has exactly one inbound node,\n        i.e. if it is connected to one incoming layer.\n\n        # Returns\n            Input tensor or list of input tensors.\n\n        # Raises\n            AttributeError: if the layer is connected to\n            more than one incoming layers.\n        \"\"\"\n        if len(self.inbound_nodes) > 1:\n            raise AttributeError('Layer ' + self.name +\n                                 ' has multiple inbound nodes, '\n                                 'hence the notion of \"layer input\" '\n                                 'is ill-defined. '\n                                 'Use `get_input_at(node_index)` instead.')\n        elif not self.inbound_nodes:\n            raise AttributeError('Layer ' + self.name +\n                                 ' is not connected, no input to return.')\n        return self._get_node_attribute_at_index(0, 'input_tensors',\n                                                 'input')",
        "begin_line": 911,
        "end_line": 934,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006105006105006105,
            "pseudo_dstar_susp": 0.0006105006105006105,
            "pseudo_tarantula_susp": 0.0006112469437652812,
            "pseudo_op2_susp": 0.0006105006105006105,
            "pseudo_barinel_susp": 0.0006112469437652812
        }
    },
    {
        "name": "keras.engine.topology.Layer.output#937",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.output(self)",
        "snippet": "    def output(self):\n        \"\"\"Retrieves the output tensor(s) of a layer.\n\n        Only applicable if the layer has exactly one inbound node,\n        i.e. if it is connected to one incoming layer.\n\n        # Returns\n            Output tensor or list of output tensors.\n\n        # Raises\n            AttributeError: if the layer is connected to\n            more than one incoming layers.\n        \"\"\"\n        if not self.inbound_nodes:\n            raise AttributeError('Layer ' + self.name +\n                                 ' has no inbound nodes.')\n        if len(self.inbound_nodes) > 1:\n            raise AttributeError('Layer ' + self.name +\n                                 ' has multiple inbound nodes, '\n                                 'hence the notion of \"layer output\" '\n                                 'is ill-defined. '\n                                 'Use `get_output_at(node_index)` instead.')\n        return self._get_node_attribute_at_index(0, 'output_tensors',\n                                                 'output')",
        "begin_line": 937,
        "end_line": 960,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.topology.Layer.input_mask#963",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.input_mask(self)",
        "snippet": "    def input_mask(self):\n        \"\"\"Retrieves the input mask tensor(s) of a layer.\n\n        Only applicable if the layer has exactly one inbound node,\n        i.e. if it is connected to one incoming layer.\n\n        # Returns\n            Input mask tensor (potentially None) or list of input\n            mask tensors.\n\n        # Raises\n            AttributeError: if the layer is connected to\n            more than one incoming layers.\n        \"\"\"\n        if len(self.inbound_nodes) != 1:\n            raise AttributeError('Layer ' + self.name +\n                                 ' has multiple inbound nodes, ' +\n                                 'hence the notion of \"layer input mask\" '\n                                 'is ill-defined. '\n                                 'Use `get_input_mask_at(node_index)` '\n                                 'instead.')\n        return self._get_node_attribute_at_index(0, 'input_masks',\n                                                 'input mask')",
        "begin_line": 963,
        "end_line": 985,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.topology.Layer.output_mask#988",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.output_mask(self)",
        "snippet": "    def output_mask(self):\n        \"\"\"Retrieves the output mask tensor(s) of a layer.\n\n        Only applicable if the layer has exactly one inbound node,\n        i.e. if it is connected to one incoming layer.\n\n        # Returns\n            Output mask tensor (potentially None) or list of output\n            mask tensors.\n\n        # Raises\n            AttributeError: if the layer is connected to\n            more than one incoming layers.\n        \"\"\"\n        if len(self.inbound_nodes) != 1:\n            raise AttributeError('Layer ' + self.name +\n                                 ' has multiple inbound nodes, '\n                                 'hence the notion of \"layer output mask\" '\n                                 'is ill-defined. '\n                                 'Use `get_output_mask_at(node_index)` '\n                                 'instead.')\n        return self._get_node_attribute_at_index(0, 'output_masks',\n                                                 'output mask')",
        "begin_line": 988,
        "end_line": 1010,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.topology.Layer.input_shape#1013",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.input_shape(self)",
        "snippet": "    def input_shape(self):\n        \"\"\"Retrieves the input shape tuple(s) of a layer.\n\n        Only applicable if the layer has exactly one inbound node,\n        i.e. if it is connected to one incoming layer.\n\n        # Returns\n            Input shape tuple\n            (or list of input shape tuples, one tuple per input tensor).\n\n        # Raises\n            AttributeError: if the layer is connected to\n            more than one incoming layers.\n        \"\"\"\n        if not self.inbound_nodes:\n            raise AttributeError('The layer has never been called '\n                                 'and thus has no defined input shape.')\n        all_input_shapes = set([str(node.input_shapes) for node in self.inbound_nodes])\n        if len(all_input_shapes) == 1:\n            input_shapes = self.inbound_nodes[0].input_shapes\n            if len(input_shapes) == 1:\n                return input_shapes[0]\n            else:\n                return input_shapes\n        else:\n            raise AttributeError('The layer \"' + str(self.name) +\n                                 ' has multiple inbound nodes, '\n                                 'with different input shapes. Hence '\n                                 'the notion of \"input shape\" is '\n                                 'ill-defined for the layer. '\n                                 'Use `get_input_shape_at(node_index)` '\n                                 'instead.')",
        "begin_line": 1013,
        "end_line": 1044,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.topology.Layer.output_shape#1047",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.output_shape(self)",
        "snippet": "    def output_shape(self):\n        \"\"\"Retrieves the output shape tuple(s) of a layer.\n\n        Only applicable if the layer has one inbound node,\n        or if all inbound nodes have the same output shape.\n\n        # Returns\n            Output shape tuple\n            (or list of input shape tuples, one tuple per output tensor).\n\n        # Raises\n            AttributeError: if the layer is connected to\n            more than one incoming layers.\n        \"\"\"\n        if not self.inbound_nodes:\n            raise AttributeError('The layer has never been called '\n                                 'and thus has no defined output shape.')\n        all_output_shapes = set([str(node.output_shapes) for node in self.inbound_nodes])\n        if len(all_output_shapes) == 1:\n            output_shapes = self.inbound_nodes[0].output_shapes\n            if len(output_shapes) == 1:\n                return output_shapes[0]\n            else:\n                return output_shapes\n        else:\n            raise AttributeError('The layer \"' + str(self.name) +\n                                 ' has multiple inbound nodes, '\n                                 'with different output shapes. Hence '\n                                 'the notion of \"output shape\" is '\n                                 'ill-defined for the layer. '\n                                 'Use `get_output_shape_at(node_index)` '\n                                 'instead.')",
        "begin_line": 1047,
        "end_line": 1078,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009587727708533077,
            "pseudo_dstar_susp": 0.002702702702702703,
            "pseudo_tarantula_susp": 0.0011389521640091116,
            "pseudo_op2_susp": 0.002702702702702703,
            "pseudo_barinel_susp": 0.0011389521640091116
        }
    },
    {
        "name": "keras.engine.topology.Layer.add_loss#1080",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.add_loss(self, losses, inputs=None)",
        "snippet": "    def add_loss(self, losses, inputs=None):\n        \"\"\"Add losses to the layer.\n\n        The loss may potentially be conditional on some inputs tensors,\n        for instance activity losses are conditional on the layer's inputs.\n\n        # Arguments\n            losses: loss tensor or list of loss tensors\n                to add to the layer.\n            inputs: input tensor or list of inputs tensors to mark\n                the losses as conditional on these inputs.\n                If None is passed, the loss is assumed unconditional\n                (e.g. L2 weight regularization, which only depends\n                on the layer's weights variables, not on any inputs tensors).\n        \"\"\"\n        if losses is None or losses == []:\n            return\n        # Update self.losses\n        losses = _to_list(losses)\n        if hasattr(self, '_losses'):\n            self._losses += losses\n        # Update self._per_input_updates\n        if isinstance(inputs, list) and inputs == []:\n            inputs = None\n        if inputs is not None:\n            inputs_hash = _object_list_uid(inputs)\n        else:\n            # Updates indexed by None are unconditional\n            # rather than input-dependent\n            inputs_hash = None\n        if inputs_hash not in self._per_input_losses:\n            self._per_input_losses[inputs_hash] = []\n        self._per_input_losses[inputs_hash] += losses",
        "begin_line": 1080,
        "end_line": 1112,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0020876826722338203,
            "pseudo_dstar_susp": 0.0013679890560875513,
            "pseudo_tarantula_susp": 0.0028328611898017,
            "pseudo_op2_susp": 0.0013679890560875513,
            "pseudo_barinel_susp": 0.0028328611898017
        }
    },
    {
        "name": "keras.engine.topology.Layer.add_update#1114",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.add_update(self, updates, inputs=None)",
        "snippet": "    def add_update(self, updates, inputs=None):\n        \"\"\"Add updates to the layer.\n\n        The updates may potentially be conditional on some inputs tensors,\n        for instance batch norm updates are conditional on the layer's inputs.\n\n        # Arguments\n            updates: update op or list of update ops\n                to add to the layer.\n            inputs: input tensor or list of inputs tensors to mark\n                the updates as conditional on these inputs.\n                If None is passed, the updates are assumed unconditional.\n        \"\"\"\n        if updates is None or updates == []:\n            return\n        # Update self.updates\n        updates = _to_list(updates)\n        if hasattr(self, '_updates'):\n            self._updates += updates\n        # Update self._per_input_updates\n        if isinstance(inputs, list) and inputs == []:\n            inputs = None\n        if inputs is not None:\n            inputs_hash = _object_list_uid(inputs)\n        else:\n            # Updates indexed by None are unconditional\n            # rather than input-dependent\n            inputs_hash = None\n        if inputs_hash not in self._per_input_updates:\n            self._per_input_updates[inputs_hash] = []\n        self._per_input_updates[inputs_hash] += updates",
        "begin_line": 1114,
        "end_line": 1144,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0020876826722338203,
            "pseudo_dstar_susp": 0.0013679890560875513,
            "pseudo_tarantula_susp": 0.0028328611898017,
            "pseudo_op2_susp": 0.0013679890560875513,
            "pseudo_barinel_susp": 0.0028328611898017
        }
    },
    {
        "name": "keras.engine.topology.Layer.get_updates_for#1146",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.get_updates_for(self, inputs)",
        "snippet": "    def get_updates_for(self, inputs):\n        if inputs is not None:\n            inputs_hash = _object_list_uid(inputs)\n        else:\n            inputs_hash = None\n        if inputs_hash in self._per_input_updates:\n            return self._per_input_updates[inputs_hash]\n        return []",
        "begin_line": 1146,
        "end_line": 1153,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.000723589001447178,
            "pseudo_dstar_susp": 0.000723589001447178,
            "pseudo_tarantula_susp": 0.0007320644216691069,
            "pseudo_op2_susp": 0.000723589001447178,
            "pseudo_barinel_susp": 0.0007320644216691069
        }
    },
    {
        "name": "keras.engine.topology.Layer.get_losses_for#1155",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.get_losses_for(self, inputs)",
        "snippet": "    def get_losses_for(self, inputs):\n        if inputs is not None:\n            inputs_hash = _object_list_uid(inputs)\n        else:\n            inputs_hash = None\n        if inputs_hash in self._per_input_losses:\n            return self._per_input_losses[inputs_hash]\n        return []",
        "begin_line": 1155,
        "end_line": 1162,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007092198581560284,
            "pseudo_dstar_susp": 0.0007092198581560284,
            "pseudo_tarantula_susp": 0.0007163323782234957,
            "pseudo_op2_susp": 0.0007092198581560284,
            "pseudo_barinel_susp": 0.0007163323782234957
        }
    },
    {
        "name": "keras.engine.topology.Layer.weights#1165",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.weights(self)",
        "snippet": "    def weights(self):\n        return self.trainable_weights + self.non_trainable_weights",
        "begin_line": 1165,
        "end_line": 1166,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002793296089385475,
            "pseudo_dstar_susp": 0.018518518518518517,
            "pseudo_tarantula_susp": 0.0012690355329949238,
            "pseudo_op2_susp": 0.018518518518518517,
            "pseudo_barinel_susp": 0.0012690355329949238
        }
    },
    {
        "name": "keras.engine.topology.Layer.set_weights#1168",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.set_weights(self, weights)",
        "snippet": "    def set_weights(self, weights):\n        \"\"\"Sets the weights of the layer, from Numpy arrays.\n\n        # Arguments\n            weights: a list of Numpy arrays. The number\n                of arrays and their shape must match\n                number of the dimensions of the weights\n                of the layer (i.e. it should match the\n                output of `get_weights`).\n\n        # Raises\n            ValueError: If the provided weights list does not match the\n                layer's specifications.\n        \"\"\"\n        params = self.weights\n        if len(params) != len(weights):\n            raise ValueError('You called `set_weights(weights)` on layer \"' +\n                             self.name +\n                             '\" with a  weight list of length ' +\n                             str(len(weights)) +\n                             ', but the layer was expecting ' +\n                             str(len(params)) +\n                             ' weights. Provided weights: ' +\n                             str(weights)[:50] + '...')\n        if not params:\n            return\n        weight_value_tuples = []\n        param_values = K.batch_get_value(params)\n        for pv, p, w in zip(param_values, params, weights):\n            if pv.shape != w.shape:\n                raise ValueError('Layer weight shape ' +\n                                 str(pv.shape) +\n                                 ' not compatible with '\n                                 'provided weight shape ' + str(w.shape))\n            weight_value_tuples.append((p, w))\n        K.batch_set_value(weight_value_tuples)",
        "begin_line": 1168,
        "end_line": 1203,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.topology.Layer.get_weights#1205",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.get_weights(self)",
        "snippet": "    def get_weights(self):\n        \"\"\"Returns the current weights of the layer.\n\n        # Returns\n            Weights values as a list of numpy arrays.\n        \"\"\"\n        params = self.weights\n        return K.batch_get_value(params)",
        "begin_line": 1205,
        "end_line": 1212,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.337068160597572e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.topology.Layer.get_config#1214",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.get_config(self)",
        "snippet": "    def get_config(self):\n        \"\"\"Returns the config of the layer.\n\n        A layer config is a Python dictionary (serializable)\n        containing the configuration of a layer.\n        The same layer can be reinstantiated later\n        (without its trained weights) from this configuration.\n\n        The config of a layer does not include connectivity\n        information, nor the layer class name. These are handled\n        by `Container` (one layer of abstraction above).\n\n        # Returns\n            Python dictionary.\n        \"\"\"\n        config = {'name': self.name,\n                  'trainable': self.trainable}\n        if hasattr(self, 'batch_input_shape'):\n            config['batch_input_shape'] = self.batch_input_shape\n        if hasattr(self, 'dtype'):\n            config['dtype'] = self.dtype\n        return config",
        "begin_line": 1214,
        "end_line": 1235,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007385524372230429,
            "pseudo_dstar_susp": 0.0007374631268436578,
            "pseudo_tarantula_susp": 0.0007473841554559044,
            "pseudo_op2_susp": 0.0007374631268436578,
            "pseudo_barinel_susp": 0.0007473841554559044
        }
    },
    {
        "name": "keras.engine.topology.Layer.from_config#1238",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.from_config(cls, config)",
        "snippet": "    def from_config(cls, config):\n        \"\"\"Creates a layer from its config.\n\n        This method is the reverse of `get_config`,\n        capable of instantiating the same layer from the config\n        dictionary. It does not handle layer connectivity\n        (handled by Container), nor weights (handled by `set_weights`).\n\n        # Arguments\n            config: A Python dictionary, typically the\n                output of get_config.\n\n        # Returns\n            A layer instance.\n        \"\"\"\n        return cls(**config)",
        "begin_line": 1238,
        "end_line": 1253,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00078003120124805,
            "pseudo_dstar_susp": 0.0007704160246533128,
            "pseudo_tarantula_susp": 0.0007855459544383347,
            "pseudo_op2_susp": 0.0007704160246533128,
            "pseudo_barinel_susp": 0.0007855459544383347
        }
    },
    {
        "name": "keras.engine.topology.Layer.count_params#1255",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Layer",
        "signature": "keras.engine.topology.Layer.count_params(self)",
        "snippet": "    def count_params(self):\n        \"\"\"Count the total number of scalars composing the weights.\n\n        # Returns\n            An integer count.\n\n        # Raises\n            RuntimeError: if the layer isn't yet built\n                (in which case its weights aren't yet defined).\n        \"\"\"\n        if not self.built:\n            if self.__class__.__name__ == 'Sequential':\n                self.build()\n            else:\n                raise RuntimeError('You tried to call `count_params` on ' +\n                                   self.name + ', but the layer isn\\'t built. '\n                                   'You can build it manually via: `' +\n                                   self.name + '.build(batch_input_shape)`.')\n        return count_params(self.weights)",
        "begin_line": 1255,
        "end_line": 1273,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001455604075691412,
            "pseudo_dstar_susp": 0.0011933174224343676,
            "pseudo_tarantula_susp": 0.0021231422505307855,
            "pseudo_op2_susp": 0.0011933174224343676,
            "pseudo_barinel_susp": 0.0021231422505307855
        }
    },
    {
        "name": "keras.engine.topology.InputLayer.__init__#1296",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.InputLayer",
        "signature": "keras.engine.topology.InputLayer.__init__(self, input_shape=None, batch_size=None, batch_input_shape=None, dtype=None, input_tensor=None, sparse=False, name=None)",
        "snippet": "    def __init__(self, input_shape=None, batch_size=None,\n                 batch_input_shape=None,\n                 dtype=None, input_tensor=None, sparse=False, name=None):\n        if not name:\n            prefix = 'input'\n            name = prefix + '_' + str(K.get_uid(prefix))\n        super(InputLayer, self).__init__(dtype=dtype, name=name)\n\n        self.trainable = False\n        self.built = True\n        self.sparse = sparse\n\n        if input_shape and batch_input_shape:\n            raise ValueError('Only provide the input_shape OR '\n                             'batch_input_shape argument to '\n                             'InputLayer, not both at the same time.')\n        if input_tensor is not None and batch_input_shape is None:\n            # If input_tensor is set, and batch_input_shape is not set:\n            # Attempt automatic input shape inference.\n            try:\n                batch_input_shape = K.int_shape(input_tensor)\n            except TypeError:\n                if not input_shape and not batch_input_shape:\n                    raise ValueError('InputLayer was provided '\n                                     'an input_tensor argument, '\n                                     'but its input shape cannot be '\n                                     'automatically inferred. '\n                                     'You should pass an input_shape or '\n                                     'batch_input_shape argument.')\n        if not batch_input_shape:\n            if not input_shape:\n                raise ValueError('An Input layer should be passed either '\n                                 'a `batch_input_shape` or an `input_shape`.')\n            else:\n                batch_input_shape = (batch_size,) + tuple(input_shape)\n        else:\n            batch_input_shape = tuple(batch_input_shape)\n\n        if not dtype:\n            if input_tensor is None:\n                dtype = K.floatx()\n            else:\n                dtype = K.dtype(input_tensor)\n\n        self.batch_input_shape = batch_input_shape\n        self.dtype = dtype\n\n        if input_tensor is None:\n            self.is_placeholder = True\n            input_tensor = K.placeholder(shape=batch_input_shape,\n                                         dtype=dtype,\n                                         sparse=self.sparse,\n                                         name=self.name)\n        else:\n            self.is_placeholder = False\n            input_tensor._keras_shape = batch_input_shape\n        # Create an input node to add to self.outbound_node\n        # and set output_tensors' _keras_history.\n        input_tensor._uses_learning_phase = False\n        input_tensor._keras_history = (self, 0, 0)\n        Node(self,\n             inbound_layers=[],\n             node_indices=[],\n             tensor_indices=[],\n             input_tensors=[input_tensor],\n             output_tensors=[input_tensor],\n             input_masks=[None],\n             output_masks=[None],\n             input_shapes=[batch_input_shape],\n             output_shapes=[batch_input_shape])",
        "begin_line": 1296,
        "end_line": 1365,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0005652911249293386,
            "pseudo_dstar_susp": 0.0005652911249293386,
            "pseudo_tarantula_susp": 0.0005652911249293386,
            "pseudo_op2_susp": 0.0005652911249293386,
            "pseudo_barinel_susp": 0.0005652911249293386
        }
    },
    {
        "name": "keras.engine.topology.InputLayer.get_config#1367",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.InputLayer",
        "signature": "keras.engine.topology.InputLayer.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'batch_input_shape': self.batch_input_shape,\n                  'dtype': self.dtype,\n                  'sparse': self.sparse,\n                  'name': self.name}\n        return config",
        "begin_line": 1367,
        "end_line": 1372,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008025682182985554,
            "pseudo_dstar_susp": 0.000791765637371338,
            "pseudo_tarantula_susp": 0.0008496176720475786,
            "pseudo_op2_susp": 0.000791765637371338,
            "pseudo_barinel_susp": 0.0008496176720475786
        }
    },
    {
        "name": "keras.engine.topology.Input#1375",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology.Input(shape=None, batch_shape=None, name=None, dtype=None, sparse=False, tensor=None)",
        "snippet": "def Input(shape=None, batch_shape=None,\n          name=None, dtype=None, sparse=False,\n          tensor=None):\n    \"\"\"`Input()` is used to instantiate a Keras tensor.\n\n    A Keras tensor is a tensor object from the underlying backend\n    (Theano or TensorFlow), which we augment with certain\n    attributes that allow us to build a Keras model\n    just by knowing the inputs and outputs of the model.\n\n    For instance, if a, b and c are Keras tensors,\n    it becomes possible to do:\n    `model = Model(input=[a, b], output=c)`\n\n    The added Keras attributes are:\n        ._keras_shape: Integer shape tuple propagated\n            via Keras-side shape inference.\n        ._keras_history: Last layer applied to the tensor.\n            the entire layer graph is retrievable from that layer,\n            recursively.\n\n    # Arguments\n        shape: A shape tuple (integer), not including the batch size.\n            For instance, `shape=(32,)` indicates that the expected input\n            will be batches of 32-dimensional vectors.\n        batch_shape: A shape tuple (integer), including the batch size.\n            For instance, `batch_shape=(10, 32)` indicates that\n            the expected input will be batches of 10 32-dimensional vectors.\n            `batch_shape=(None, 32)` indicates batches of an arbitrary number\n            of 32-dimensional vectors.\n        name: An optional name string for the layer.\n            Should be unique in a model (do not reuse the same name twice).\n            It will be autogenerated if it isn't provided.\n        dtype: The data type expected by the input, as a string\n            (`float32`, `float64`, `int32`...)\n        sparse: A boolean specifying whether the placeholder\n            to be created is sparse.\n        tensor: Optional existing tensor to wrap into the `Input` layer.\n            If set, the layer will not create a placeholder tensor.\n\n    # Returns\n        A tensor.\n\n    # Example\n\n        ```python\n        # this is a logistic regression in Keras\n        x = Input(shape=(32,))\n        y = Dense(16, activation='softmax')(x)\n        model = Model(x, y)\n        ```\n    \"\"\"\n    if not batch_shape and tensor is None:\n        assert shape, ('Please provide to Input either a `shape`'\n                       ' or a `batch_shape` argument. Note that '\n                       '`shape` does not include the batch '\n                       'dimension.')\n    if shape and not batch_shape:\n        batch_shape = (None,) + tuple(shape)\n    if not dtype:\n        dtype = K.floatx()\n    input_layer = InputLayer(batch_input_shape=batch_shape,\n                             name=name, dtype=dtype,\n                             sparse=sparse,\n                             input_tensor=tensor)\n    # Return tensor including _keras_shape and _keras_history.\n    # Note that in this case train_output and test_output are the same pointer.\n    outputs = input_layer.inbound_nodes[0].output_tensors\n    if len(outputs) == 1:\n        return outputs[0]\n    else:\n        return outputs",
        "begin_line": 1375,
        "end_line": 1446,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007564296520423601,
            "pseudo_dstar_susp": 0.0007496251874062968,
            "pseudo_tarantula_susp": 0.0007604562737642585,
            "pseudo_op2_susp": 0.0007496251874062968,
            "pseudo_barinel_susp": 0.0007604562737642585
        }
    },
    {
        "name": "keras.engine.topology.Container.__init__#1489",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.__init__(self, inputs, outputs, name=None)",
        "snippet": "    def __init__(self, inputs, outputs, name=None):\n        # Handle `name` argument.\n        if not name:\n            prefix = self.__class__.__name__.lower()\n            name = prefix + '_' + str(K.get_uid(prefix))\n        self.name = name\n\n        self.supports_masking = False\n        self.trainable = True\n        self._per_input_losses = {}\n        self._per_input_updates = {}\n\n        # Container-specific properties.\n        if isinstance(inputs, (list, tuple)):\n            self.inputs = list(inputs)  # Tensor or list of tensors.\n        else:\n            self.inputs = [inputs]\n        if isinstance(outputs, (list, tuple)):\n            self.outputs = list(outputs)\n        else:\n            self.outputs = [outputs]\n\n        # Check for redundancy in inputs.\n        if len(set(self.inputs)) != len(self.inputs):\n            raise ValueError('The list of inputs passed to the model '\n                             'is redundant. '\n                             'All inputs should only appear once.'\n                             ' Found: ' + str(self.inputs))\n\n        # Check for redundancy in outputs.\n        if len(set(self.outputs)) != len(self.outputs):\n            warnings.warn('The list of outputs passed to the model '\n                          'is redundant. '\n                          'All outputs should only appear once.'\n                          ' Found: ' + str(self.outputs))\n\n        # List of initial layers (1 to 1 mapping with self.inputs,\n        # hence the same layer might appear twice)\n        self.input_layers = []\n        self.input_layers_node_indices = []\n        self.input_layers_tensor_indices = []\n        # list of layers (1 to 1 mapping with self.inputs,\n        # hence the same layer might appear twice)\n        self.output_layers = []\n        self.output_layers_node_indices = []\n        self.output_layers_tensor_indices = []\n        # all layers in order of horizontal graph traversal.\n        # Entries are unique. Includes input and output layers.\n        self.layers = []\n\n        # This is for performance optimization\n        # when calling the Container on new inputs.\n        # every time the Container is called on a set on input tensors,\n        # we compute the output tensors,\n        # output masks and output shapes in one pass,\n        # then cache them here. When one of these output is queried later,\n        # we retrieve it from there instead of recomputing it.\n        self._output_mask_cache = {}\n        self._output_tensor_cache = {}\n        self._output_shape_cache = {}\n\n        # User-provided arguments validation.\n        for x in self.inputs:\n            # Check that x is a Keras tensor.\n            if not hasattr(x, '_keras_history'):\n                cls_name = self.__class__.__name__\n                raise TypeError('Input tensors to a ' + cls_name + ' ' +\n                                'must be Keras tensors. Found: ' + str(x) +\n                                ' (missing Keras metadata).')\n            # Check that x is an input tensor.\n            layer, node_index, tensor_index = x._keras_history\n            if len(layer.inbound_nodes) > 1 or (layer.inbound_nodes and layer.inbound_nodes[0].inbound_layers):\n                cls_name = self.__class__.__name__\n                warnings.warn(cls_name + ' inputs must come from '\n                              'a Keras Input layer, '\n                              'they cannot be the output of '\n                              'a previous non-Input layer. '\n                              'Here, a tensor specified as '\n                              'input to \"' + self.name +\n                              '\" was not an Input tensor, '\n                              'it was generated by layer ' +\n                              layer.name + '.\\n'\n                              'Note that input tensors are '\n                              'instantiated via `tensor = Input(shape)`.\\n'\n                              'The tensor that caused the issue was: ' +\n                              str(x.name))\n        for x in self.outputs:\n            if not hasattr(x, '_keras_history'):\n                cls_name = self.__class__.__name__\n                raise TypeError('Output tensors to a ' + cls_name + ' must be '\n                                'Keras tensors. Found: ' + str(x))\n        # Build self.output_layers:\n        for x in self.outputs:\n            layer, node_index, tensor_index = x._keras_history\n            self.output_layers.append(layer)\n            self.output_layers_node_indices.append(node_index)\n            self.output_layers_tensor_indices.append(tensor_index)\n\n        # Fill in the output mask cache.\n        masks = []\n        for x in self.inputs:\n            layer, node_index, tensor_index = x._keras_history\n            node = layer.inbound_nodes[node_index]\n            mask = node.output_masks[tensor_index]\n            masks.append(mask)\n        mask_cache_key = ','.join([str(id(x)) for x in self.inputs])\n        mask_cache_key += '_' + ','.join([str(id(x)) for x in masks])\n        masks = []\n        for x in self.outputs:\n            layer, node_index, tensor_index = x._keras_history\n            node = layer.inbound_nodes[node_index]\n            mask = node.output_masks[tensor_index]\n            masks.append(mask)\n        if len(masks) == 1:\n            mask = masks[0]\n        else:\n            mask = masks\n        self._output_mask_cache[mask_cache_key] = mask\n\n        # Build self.input_layers:\n        for x in self.inputs:\n            layer, node_index, tensor_index = x._keras_history\n            # It's supposed to be an input layer, so only one node\n            # and one tensor output.\n            assert node_index == 0\n            assert tensor_index == 0\n            self.input_layers.append(layer)\n            self.input_layers_node_indices.append(node_index)\n            self.input_layers_tensor_indices.append(tensor_index)\n\n        # Build self.input_names and self.output_names.\n        self.input_names = []\n        self.output_names = []\n        self._feed_input_names = []\n        self._feed_inputs = []\n        self._feed_input_shapes = []\n        for i, layer in enumerate(self.input_layers):\n            # Check that layer is an InputLayer.\n            if not isinstance(layer, InputLayer):\n                raise TypeError(\n                    'Input layers to a `Model` must be `InputLayer` objects. '\n                    'Received inputs: {}. '\n                    'Input {} (0-based) originates '\n                    'from layer type `{}`.'.format(inputs,\n                                                   i,\n                                                   layer.__class__.__name__))\n            self.input_names.append(layer.name)\n            if layer.is_placeholder:\n                self._feed_input_names.append(layer.name)\n                self._feed_inputs.append(layer.input)\n                self._feed_input_shapes.append(self.inputs[i]._keras_shape)\n        for layer in self.output_layers:\n            self.output_names.append(layer.name)\n\n        self.internal_input_shapes = [x._keras_shape for x in self.inputs]\n        self.internal_output_shapes = [x._keras_shape for x in self.outputs]\n\n        # Container_nodes: set of nodes included in the graph\n        # (not all nodes included in the layers\n        # are relevant to the current graph).\n        container_nodes = set()  # ids of all nodes relevant to the Container\n        nodes_depths = {}  # dict {node: depth value}\n        layers_depths = {}  # dict {layer: depth value}\n        layer_indices = {}  # dict {layer: index in traversal}\n        nodes_in_decreasing_depth = []\n\n        def build_map_of_graph(tensor, finished_nodes, nodes_in_progress,\n                               layer=None, node_index=None, tensor_index=None):\n            \"\"\"Builds a map of the graph of layers.\n\n            This recursively updates the map `layer_indices`,\n            the list `nodes_in_decreasing_depth` and the set `container_nodes`.\n\n            # Arguments\n                tensor: Some tensor in a graph.\n                finished_nodes: Set of nodes whose subgraphs have been traversed\n                    completely. Useful to prevent duplicated work.\n                nodes_in_progress: Set of nodes that are currently active on the\n                    recursion stack. Useful to detect cycles.\n                layer: Layer from which `tensor` comes from. If not provided,\n                    will be obtained from `tensor._keras_history`.\n                node_index: Node index from which `tensor` comes from.\n                tensor_index: Tensor_index from which `tensor` comes from.\n\n            # Raises\n                RuntimeError: if a cycle is detected.\n            \"\"\"\n            if not layer or node_index is None or tensor_index is None:\n                layer, node_index, tensor_index = tensor._keras_history\n            node = layer.inbound_nodes[node_index]\n\n            # Prevent cycles.\n            if node in nodes_in_progress:\n                raise RuntimeError(\n                    'The tensor ' + str(tensor) + ' at layer \"' +\n                    layer.name + '\" is part of a cycle.')\n\n            # Don't repeat work for shared subgraphs\n            if node in finished_nodes:\n                return\n\n            # Update container_nodes.\n            container_nodes.add(self._node_key(layer, node_index))\n\n            # Store the traversal order for layer sorting.\n            if layer not in layer_indices:\n                layer_indices[layer] = len(layer_indices)\n\n            nodes_in_progress.add(node)\n\n            # Propagate to all previous tensors connected to this node.\n            for i in range(len(node.inbound_layers)):\n                x = node.input_tensors[i]\n                layer = node.inbound_layers[i]\n                node_index = node.node_indices[i]\n                tensor_index = node.tensor_indices[i]\n                build_map_of_graph(x, finished_nodes, nodes_in_progress,\n                                   layer, node_index, tensor_index)\n\n            finished_nodes.add(node)\n            nodes_in_progress.remove(node)\n\n            nodes_in_decreasing_depth.append(node)\n\n        finished_nodes = set()\n        nodes_in_progress = set()\n        for x in self.outputs:\n            build_map_of_graph(x, finished_nodes, nodes_in_progress)\n\n        for node in reversed(nodes_in_decreasing_depth):\n            # If the depth is not set, the node has no outbound nodes (depth 0).\n            depth = nodes_depths.setdefault(node, 0)\n\n            # Update the depth of the corresponding layer\n            previous_depth = layers_depths.get(node.outbound_layer, 0)\n            # If we've seen this layer before at a higher depth, we should use that depth instead\n            # of the node depth.  This is necessary for shared layers that have inputs at different\n            # depth levels in the graph.\n            depth = max(depth, previous_depth)\n            layers_depths[node.outbound_layer] = depth\n            nodes_depths[node] = depth\n\n            # Update the depth of inbound nodes.\n            for i in range(len(node.inbound_layers)):\n                inbound_layer = node.inbound_layers[i]\n                node_index = node.node_indices[i]\n                inbound_node = inbound_layer.inbound_nodes[node_index]\n                previous_depth = nodes_depths.get(inbound_node, 0)\n                nodes_depths[inbound_node] = max(depth + 1, previous_depth)\n\n        # Build a dict {depth: list of nodes with this depth}\n        nodes_by_depth = {}\n        for node, depth in nodes_depths.items():\n            if depth not in nodes_by_depth:\n                nodes_by_depth[depth] = []\n            nodes_by_depth[depth].append(node)\n\n        # Build a dict {depth: list of layers with this depth}\n        layers_by_depth = {}\n        for layer, depth in layers_depths.items():\n            if depth not in layers_by_depth:\n                layers_by_depth[depth] = []\n            layers_by_depth[depth].append(layer)\n\n        # Get sorted list of layer depths.\n        depth_keys = list(layers_by_depth.keys())\n        depth_keys.sort(reverse=True)\n\n        # Set self.layers and self.layers_by_depth.\n        layers = []\n        for depth in depth_keys:\n            layers_for_depth = layers_by_depth[depth]\n            # Container.layers needs to have a deterministic order:\n            # here we order them by traversal order.\n            layers_for_depth.sort(key=lambda x: layer_indices[x])\n            for layer in layers_for_depth:\n                layers.append(layer)\n        self.layers = layers\n        self.layers_by_depth = layers_by_depth\n\n        # Get sorted list of node depths.\n        depth_keys = list(nodes_by_depth.keys())\n        depth_keys.sort(reverse=True)\n\n        # Check that all tensors required are computable.\n        # computable_tensors: all tensors in the graph\n        # that can be computed from the inputs provided.\n        computable_tensors = []\n        for x in self.inputs:\n            computable_tensors.append(x)\n\n        layers_with_complete_input = []  # To provide a better error msg.\n        for depth in depth_keys:\n            for node in nodes_by_depth[depth]:\n                layer = node.outbound_layer\n                if layer:\n                    for x in node.input_tensors:\n                        if x not in computable_tensors:\n                            raise RuntimeError(\n                                'Graph disconnected: '\n                                'cannot obtain value for tensor ' +\n                                str(x) + ' at layer \"' + layer.name + '\". '\n                                'The following previous layers '\n                                'were accessed without issue: ' +\n                                str(layers_with_complete_input))\n                    for x in node.output_tensors:\n                        computable_tensors.append(x)\n                    layers_with_complete_input.append(layer.name)\n\n        # Set self.nodes and self.nodes_by_depth.\n        self.container_nodes = container_nodes\n        self.nodes_by_depth = nodes_by_depth\n\n        # Ensure name unicity, which will be crucial for serialization\n        # (since serialized nodes refer to layers by their name).\n        all_names = [layer.name for layer in self.layers]\n        for name in all_names:\n            if all_names.count(name) != 1:\n                raise RuntimeError('The name \"' + name + '\" is used ' +\n                                   str(all_names.count(name)) +\n                                   ' times in the model. '\n                                   'All layer names should be unique. '\n                                   'Layer names: ', all_names)\n\n        # Layer parameters.\n        # The new container starts with a single inbound node\n        # for its inputs, and no outbound nodes.\n        self.outbound_nodes = []  # Will be appended to by future calls to __call__\n        self.inbound_nodes = []  # Will be appended to below, and by future calls to __call__\n        # Create the node linking internal inputs to internal outputs.\n        Node(outbound_layer=self,\n             inbound_layers=[],\n             node_indices=[],\n             tensor_indices=[],\n             input_tensors=self.inputs,\n             output_tensors=self.outputs,\n             # No container-level masking for now.\n             input_masks=[None for _ in self.inputs],\n             output_masks=[None for _ in self.outputs],\n             input_shapes=[x._keras_shape for x in self.inputs],\n             output_shapes=[x._keras_shape for x in self.outputs])\n        self.built = True",
        "begin_line": 1489,
        "end_line": 1830,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02127659574468085,
            "pseudo_dstar_susp": 0.002551020408163265,
            "pseudo_tarantula_susp": 0.023255813953488372,
            "pseudo_op2_susp": 0.002551020408163265,
            "pseudo_barinel_susp": 0.023255813953488372
        }
    },
    {
        "name": "keras.engine.topology.Container.build_map_of_graph#1655",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.build_map_of_graph(tensor, finished_nodes, nodes_in_progress, layer=None, node_index=None, tensor_index=None)",
        "snippet": "        def build_map_of_graph(tensor, finished_nodes, nodes_in_progress,\n                               layer=None, node_index=None, tensor_index=None):\n            \"\"\"Builds a map of the graph of layers.\n\n            This recursively updates the map `layer_indices`,\n            the list `nodes_in_decreasing_depth` and the set `container_nodes`.\n\n            # Arguments\n                tensor: Some tensor in a graph.\n                finished_nodes: Set of nodes whose subgraphs have been traversed\n                    completely. Useful to prevent duplicated work.\n                nodes_in_progress: Set of nodes that are currently active on the\n                    recursion stack. Useful to detect cycles.\n                layer: Layer from which `tensor` comes from. If not provided,\n                    will be obtained from `tensor._keras_history`.\n                node_index: Node index from which `tensor` comes from.\n                tensor_index: Tensor_index from which `tensor` comes from.\n\n            # Raises\n                RuntimeError: if a cycle is detected.\n            \"\"\"\n            if not layer or node_index is None or tensor_index is None:\n                layer, node_index, tensor_index = tensor._keras_history\n            node = layer.inbound_nodes[node_index]\n\n            # Prevent cycles.\n            if node in nodes_in_progress:\n                raise RuntimeError(\n                    'The tensor ' + str(tensor) + ' at layer \"' +\n                    layer.name + '\" is part of a cycle.')\n\n            # Don't repeat work for shared subgraphs\n            if node in finished_nodes:\n                return\n\n            # Update container_nodes.\n            container_nodes.add(self._node_key(layer, node_index))\n\n            # Store the traversal order for layer sorting.\n            if layer not in layer_indices:\n                layer_indices[layer] = len(layer_indices)\n\n            nodes_in_progress.add(node)\n\n            # Propagate to all previous tensors connected to this node.\n            for i in range(len(node.inbound_layers)):\n                x = node.input_tensors[i]\n                layer = node.inbound_layers[i]\n                node_index = node.node_indices[i]\n                tensor_index = node.tensor_indices[i]\n                build_map_of_graph(x, finished_nodes, nodes_in_progress,\n                                   layer, node_index, tensor_index)\n\n            finished_nodes.add(node)\n            nodes_in_progress.remove(node)\n\n            nodes_in_decreasing_depth.append(node)",
        "begin_line": 1655,
        "end_line": 1711,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009389671361502347,
            "pseudo_dstar_susp": 0.0009140767824497258,
            "pseudo_tarantula_susp": 0.0012453300124533001,
            "pseudo_op2_susp": 0.0009140767824497258,
            "pseudo_barinel_susp": 0.0012453300124533001
        }
    },
    {
        "name": "keras.engine.topology.Container.get_layer#1837",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.get_layer(self, name=None, index=None)",
        "snippet": "    def get_layer(self, name=None, index=None):\n        \"\"\"Retrieves a layer based on either its name (unique) or index.\n\n        Indices are based on order of horizontal graph traversal (bottom-up).\n\n        # Arguments\n            name: String, name of layer.\n            index: Integer, index of layer.\n\n        # Returns\n            A layer instance.\n\n        # Raises\n            ValueError: In case of invalid layer name or index.\n        \"\"\"\n        # It would be unreliable to build a dictionary\n        # based on layer names, because names can potentially\n        # be changed at any point by the user\n        # without the container being notified of it.\n        if index is not None:\n            if len(self.layers) <= index:\n                raise ValueError('Was asked to retrieve layer at index ' +\n                                 str(index) + ' but model only has ' +\n                                 str(len(self.layers)) + ' layers.')\n            else:\n                return self.layers[index]\n        else:\n            if not name:\n                raise ValueError('Provide either a layer name or layer index.')\n\n        for layer in self.layers:\n            if layer.name == name:\n                return layer\n\n        raise ValueError('No such layer: ' + name)",
        "begin_line": 1837,
        "end_line": 1871,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.topology.Container.updates#1874",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.updates(self)",
        "snippet": "    def updates(self):\n        \"\"\"Retrieve the model's updates.\n\n        Will only include updates that are either\n        inconditional, or conditional on inputs to this model\n        (e.g. will not include updates that depend on tensors\n        that aren't inputs to this model).\n\n        # Returns\n            A list of update ops.\n        \"\"\"\n        updates = []\n        for layer in self.layers:\n            if hasattr(layer, 'updates'):\n                # Collect updates that are dependent on inputs\n                # that are part of the model.\n                for node_index, node in enumerate(layer.inbound_nodes):\n                    node_key = self._node_key(layer, node_index)\n                    if node_key in self.container_nodes:\n                        # The model owns this layer node.\n                        inputs = node.input_tensors\n                        updates += layer.get_updates_for(inputs)\n                # Collect unconditional updates.\n                updates += layer.get_updates_for(None)\n        return updates",
        "begin_line": 1874,
        "end_line": 1898,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 8.92140244446427e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.topology.Container.losses#1901",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.losses(self)",
        "snippet": "    def losses(self):\n        \"\"\"Retrieve the model's losses.\n\n        Will only include losses that are either\n        inconditional, or conditional on inputs to this model\n        (e.g. will not include losses that depend on tensors\n        that aren't inputs to this model).\n\n        # Returns\n            A list of loss tensors.\n        \"\"\"\n        losses = []\n        # Retrieve losses for all internal layers.\n        for layer in self.layers:\n            if hasattr(layer, 'losses'):\n                # Collect losses that are dependent on inputs\n                # that are part of the model.\n                for node_index, node in enumerate(layer.inbound_nodes):\n                    node_key = self._node_key(layer, node_index)\n                    if node_key in self.container_nodes:\n                        # The model owns this layer node.\n                        inputs = node.input_tensors\n                        losses += layer.get_losses_for(inputs)\n                # Collect unconditional losses.\n                losses += layer.get_losses_for(None)\n        # Add any potential unconditional model-level loss.\n        losses += self.get_losses_for(None)\n        return losses",
        "begin_line": 1901,
        "end_line": 1928,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 8.745845723281441e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.topology.Container.uses_learning_phase#1931",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.uses_learning_phase(self)",
        "snippet": "    def uses_learning_phase(self):\n        return any([x._uses_learning_phase for x in self.outputs])",
        "begin_line": 1931,
        "end_line": 1932,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007757951900698216,
            "pseudo_dstar_susp": 0.0025906735751295338,
            "pseudo_tarantula_susp": 0.0007122507122507123,
            "pseudo_op2_susp": 0.0025906735751295338,
            "pseudo_barinel_susp": 0.0007122507122507123
        }
    },
    {
        "name": "keras.engine.topology.Container.stateful#1935",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.stateful(self)",
        "snippet": "    def stateful(self):\n        return any([(hasattr(layer, 'stateful') and layer.stateful) for layer in self.layers])",
        "begin_line": 1935,
        "end_line": 1936,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 8.669267446900737e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.topology.Container.reset_states#1938",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.reset_states(self)",
        "snippet": "    def reset_states(self):\n        for layer in self.layers:\n            if hasattr(layer, 'reset_states') and getattr(layer, 'stateful', False):\n                layer.reset_states()",
        "begin_line": 1938,
        "end_line": 1941,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.topology.Container.state_updates#1944",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.state_updates(self)",
        "snippet": "    def state_updates(self):\n        \"\"\"Returns the `updates` from all layers that are stateful.\n\n        This is useful for separating training updates and\n        state updates, e.g. when we need to update a layer's internal state\n        during prediction.\n\n        # Returns\n            A list of update ops.\n        \"\"\"\n        state_updates = []\n        for layer in self.layers:\n            if getattr(layer, 'stateful', False):\n                if hasattr(layer, 'updates'):\n                    state_updates += layer.updates\n        return state_updates",
        "begin_line": 1944,
        "end_line": 1959,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.topology.Container.trainable_weights#1962",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.trainable_weights(self)",
        "snippet": "    def trainable_weights(self):\n        if not self.trainable:\n            return []\n        weights = []\n        for layer in self.layers:\n            weights += layer.trainable_weights\n        return weights",
        "begin_line": 1962,
        "end_line": 1968,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007122507122507123,
            "pseudo_dstar_susp": 0.0007122507122507123,
            "pseudo_tarantula_susp": 0.0007199424046076314,
            "pseudo_op2_susp": 0.0007122507122507123,
            "pseudo_barinel_susp": 0.0007199424046076314
        }
    },
    {
        "name": "keras.engine.topology.Container.non_trainable_weights#1971",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.non_trainable_weights(self)",
        "snippet": "    def non_trainable_weights(self):\n        weights = []\n        for layer in self.layers:\n            weights += layer.non_trainable_weights\n        if not self.trainable:\n            trainable_weights = []\n            for layer in self.layers:\n                trainable_weights += layer.trainable_weights\n            return trainable_weights + weights\n        return weights",
        "begin_line": 1971,
        "end_line": 1980,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008984725965858042,
            "pseudo_dstar_susp": 0.0008833922261484099,
            "pseudo_tarantula_susp": 0.0010214504596527069,
            "pseudo_op2_susp": 0.0008833922261484099,
            "pseudo_barinel_susp": 0.0010214504596527069
        }
    },
    {
        "name": "keras.engine.topology.Container.get_weights#1982",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.get_weights(self)",
        "snippet": "    def get_weights(self):\n        \"\"\"Retrieves the weights of the model.\n\n        # Returns\n            A flat list of Numpy arrays.\n        \"\"\"\n        weights = []\n        for layer in self.layers:\n            weights += layer.weights\n        return K.batch_get_value(weights)",
        "begin_line": 1982,
        "end_line": 1991,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.904912836767037e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.topology.Container.set_weights#1993",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.set_weights(self, weights)",
        "snippet": "    def set_weights(self, weights):\n        \"\"\"Sets the weights of the model.\n\n        # Arguments\n            weights: A list of Numpy arrays with shapes and types matching\n                the output of `model.get_weights()`.\n        \"\"\"\n        tuples = []\n        for layer in self.layers:\n            num_param = len(layer.weights)\n            layer_weights = weights[:num_param]\n            for sw, w in zip(layer.weights, layer_weights):\n                tuples.append((sw, w))\n            weights = weights[num_param:]\n        K.batch_set_value(tuples)",
        "begin_line": 1993,
        "end_line": 2007,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.92950054612253e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.topology.Container.input_spec#2010",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.input_spec(self)",
        "snippet": "    def input_spec(self):\n        \"\"\"Gets the model's input specs.\n\n        # Returns\n            A list of `InputSpec` instances (one per input to the model)\n                or a single instance if the model has only one input.\n        \"\"\"\n        specs = []\n        for layer in getattr(self, 'input_layers', []):\n            if layer.input_spec is None:\n                specs.append(None)\n            else:\n                if not isinstance(layer.input_spec, list):\n                    raise TypeError('Layer ' + layer.name +\n                                    ' has an input_spec attribute that '\n                                    'is not a list. We expect a list. '\n                                    'Found input_spec = ' +\n                                    str(layer.input_spec))\n                specs += layer.input_spec\n        if len(specs) == 1:\n            return specs[0]\n        return specs",
        "begin_line": 2010,
        "end_line": 2031,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.003663003663003663,
            "pseudo_dstar_susp": 0.0015873015873015873,
            "pseudo_tarantula_susp": 0.00411522633744856,
            "pseudo_op2_susp": 0.0015873015873015873,
            "pseudo_barinel_susp": 0.00411522633744856
        }
    },
    {
        "name": "keras.engine.topology.Container.call#2033",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.call(self, inputs, mask=None)",
        "snippet": "    def call(self, inputs, mask=None):\n        \"\"\"Call the model on new inputs.\n\n        In this case `call` just reapplies\n        all ops in the graph to the new inputs\n        (e.g. build a new computational graph from the provided inputs).\n\n        A model is callable on non-Keras tensors.\n\n        # Arguments\n            inputs: A tensor or list of tensors.\n            mask: A mask or list of masks. A mask can be\n                either a tensor or None (no mask).\n\n        # Returns\n            A tensor if there is a single output, or\n            a list of tensors if there are more than one outputs.\n        \"\"\"\n        inputs = _to_list(inputs)\n        if mask is None:\n            masks = [None for _ in range(len(inputs))]\n        else:\n            masks = _to_list(mask)\n        cache_key = ','.join([str(id(x)) for x in inputs])\n        cache_key += '_' + ','.join([str(id(x)) for x in masks])\n        if cache_key in self._output_tensor_cache:\n            return self._output_tensor_cache[cache_key]\n        else:\n            output_tensors, _, _ = self.run_internal_graph(inputs, masks)\n            return output_tensors",
        "begin_line": 2033,
        "end_line": 2062,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02127659574468085,
            "pseudo_dstar_susp": 0.0028169014084507044,
            "pseudo_tarantula_susp": 0.023255813953488372,
            "pseudo_op2_susp": 0.0028169014084507044,
            "pseudo_barinel_susp": 0.023255813953488372
        }
    },
    {
        "name": "keras.engine.topology.Container.compute_mask#2064",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.compute_mask(self, inputs, mask)",
        "snippet": "    def compute_mask(self, inputs, mask):\n        inputs = _to_list(inputs)\n        if mask is None:\n            masks = [None for _ in range(len(inputs))]\n        else:\n            masks = _to_list(mask)\n        cache_key = ','.join([str(id(x)) for x in inputs])\n        cache_key += '_' + ','.join([str(id(x)) for x in masks])\n        if cache_key in self._output_mask_cache:\n            return self._output_mask_cache[cache_key]\n        else:\n            _, output_masks, _ = self.run_internal_graph(inputs, masks)\n            return output_masks",
        "begin_line": 2064,
        "end_line": 2076,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004405286343612335,
            "pseudo_dstar_susp": 0.0026041666666666665,
            "pseudo_tarantula_susp": 0.0049261083743842365,
            "pseudo_op2_susp": 0.0026041666666666665,
            "pseudo_barinel_susp": 0.0049261083743842365
        }
    },
    {
        "name": "keras.engine.topology.Container.compute_output_shape#2078",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        input_shapes = _to_list(input_shape)\n        if len(input_shapes) != len(self.input_layers):\n            raise ValueError('Invalid input_shape argument ' +\n                             str(input_shape) + ': model has ' +\n                             str(len(self.input_layers)) + ' tensor inputs.')\n\n        cache_key = ','.join([str(x) for x in input_shapes])\n        if cache_key in self._output_shape_cache:\n            output_shapes = self._output_shape_cache[cache_key]\n            if isinstance(output_shapes, list) and len(output_shapes) == 1:\n                return output_shapes[0]\n            return output_shapes\n        else:\n            # Bad luck, we have to run the graph manually.\n            layers_to_output_shapes = {}\n            for i in range(len(input_shapes)):\n                layer = self.input_layers[i]\n                input_shape = input_shapes[i]\n                # It's an input layer: compute_output_shape is identity,\n                # and there is only one node and one tensor output.\n                shape_key = layer.name + '_0_0'\n                layers_to_output_shapes[shape_key] = input_shape\n\n            depth_keys = list(self.nodes_by_depth.keys())\n            depth_keys.sort(reverse=True)\n            # Iterate over nodes, by depth level.\n            if len(depth_keys) > 1:\n                for depth in depth_keys:\n                    nodes = self.nodes_by_depth[depth]\n                    for node in nodes:\n                        # This is always a single layer, never a list.\n                        layer = node.outbound_layer\n                        if layer in self.input_layers:\n                            # We've already covered the input layers\n                            # a few lines above.\n                            continue\n                        # Potentially redundant list,\n                        # same size of node.input_tensors.\n                        input_shapes = []\n                        for j in range(len(node.inbound_layers)):\n                            inbound_layer = node.inbound_layers[j]\n                            node_index = node.node_indices[j]\n                            tensor_index = node.tensor_indices[j]\n                            shape_key = inbound_layer.name + '_%s_%s' % (node_index, tensor_index)\n                            input_shape = layers_to_output_shapes[shape_key]\n                            input_shapes.append(input_shape)\n\n                        if len(input_shapes) == 1:\n                            output_shape = layer.compute_output_shape(input_shapes[0])\n                        else:\n                            output_shape = layer.compute_output_shape(input_shapes)\n\n                        output_shapes = _to_list(output_shape)\n                        node_index = layer.inbound_nodes.index(node)\n                        for j in range(len(output_shapes)):\n                            shape_key = layer.name + '_%s_%s' % (node_index, j)\n                            layers_to_output_shapes[shape_key] = output_shapes[j]\n\n            # Read final output shapes from layers_to_output_shapes.\n            output_shapes = []\n            output_shape_keys = []\n            for i in range(len(self.output_layers)):\n                layer = self.output_layers[i]\n                node_index = self.output_layers_node_indices[i]\n                tensor_index = self.output_layers_tensor_indices[i]\n                shape_key = layer.name + '_%s_%s' % (node_index, tensor_index)\n                output_shape_keys.append(shape_key)\n\n            for i, key in enumerate(output_shape_keys):\n                assert key in layers_to_output_shapes\n                output_shapes.append(layers_to_output_shapes[key])\n            # Store in cache.\n            self._output_shape_cache[cache_key] = output_shapes\n            if isinstance(output_shapes, list) and len(output_shapes) == 1:\n                return output_shapes[0]\n            return output_shapes",
        "begin_line": 2078,
        "end_line": 2154,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.007936507936507936,
            "pseudo_dstar_susp": 0.002785515320334262,
            "pseudo_tarantula_susp": 0.00847457627118644,
            "pseudo_op2_susp": 0.002785515320334262,
            "pseudo_barinel_susp": 0.00847457627118644
        }
    },
    {
        "name": "keras.engine.topology.Container.run_internal_graph#2156",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.run_internal_graph(self, inputs, masks=None)",
        "snippet": "    def run_internal_graph(self, inputs, masks=None):\n        \"\"\"Computes output tensors for new inputs.\n\n        # Note:\n            - Expects `inputs` to be a list (potentially with 1 element).\n            - Can be run on non-Keras tensors.\n\n        # Arguments\n            inputs: List of tensors\n            masks: List of masks (tensors or None).\n\n        # Returns\n            Three lists: output_tensors, output_masks, output_shapes\n        \"\"\"\n        if masks is None:\n            masks = [None for _ in range(len(inputs))]\n\n        # Dictionary mapping reference tensors to tuples\n        # (computed tensor, compute mask)\n        # we assume a 1:1 mapping from tensor to mask\n        # TODO: raise exception when a `.compute_mask()` call\n        # does not return a list the same size as `call`\n        tensor_map = {}\n        for x, y, mask in zip(self.inputs, inputs, masks):\n            tensor_map[str(id(x))] = (y, mask)\n\n        depth_keys = list(self.nodes_by_depth.keys())\n        depth_keys.sort(reverse=True)\n        for depth in depth_keys:\n            nodes = self.nodes_by_depth[depth]\n            for node in nodes:\n                # This is always a single layer, never a list.\n                layer = node.outbound_layer\n\n                reference_input_tensors = node.input_tensors\n                reference_output_tensors = node.output_tensors\n\n                # If all previous input tensors are available in tensor_map,\n                # then call node.inbound_layer on them.\n                computed_data = []  # List of tuples (input, mask).\n                for x in reference_input_tensors:\n                    if str(id(x)) in tensor_map:\n                        computed_data.append(tensor_map[str(id(x))])\n\n                if len(computed_data) == len(reference_input_tensors):\n                    # call layer\n                    with K.name_scope(layer.name):\n                        if node.arguments:\n                            kwargs = node.arguments\n                        else:\n                            kwargs = {}\n                        if len(computed_data) == 1:\n                            computed_tensor, computed_mask = computed_data[0]\n                            if has_arg(layer.call, 'mask'):\n                                if 'mask' not in kwargs:\n                                    kwargs['mask'] = computed_mask\n                            output_tensors = _to_list(layer.call(computed_tensor, **kwargs))\n                            output_masks = _to_list(layer.compute_mask(computed_tensor,\n                                                                       computed_mask))\n                            computed_tensors = [computed_tensor]\n                            computed_masks = [computed_mask]\n                        else:\n                            computed_tensors = [x[0] for x in computed_data]\n                            computed_masks = [x[1] for x in computed_data]\n                            if has_arg(layer.call, 'mask'):\n                                if 'mask' not in kwargs:\n                                    kwargs['mask'] = computed_masks\n                            output_tensors = _to_list(layer.call(computed_tensors, **kwargs))\n                            output_masks = _to_list(layer.compute_mask(computed_tensors,\n                                                                       computed_masks))\n\n                        # Apply activity regularizer if any:\n                        if hasattr(layer, 'activity_regularizer') and layer.activity_regularizer is not None:\n                            regularization_losses = [layer.activity_regularizer(x) for x in computed_tensors]\n                            layer.add_loss(regularization_losses, computed_tensors)\n\n                    # Update model updates and losses:\n                    # Keep track of updates that depend on the inputs\n                    # (e.g. BN updates).\n                    self.add_update(layer.get_updates_for(computed_tensors), inputs)\n                    # Keep track of unconditional updates (e.g. a counter).\n                    self.add_update(layer.get_updates_for(None), None)\n                    # Keep track of losses that depend on the inputs\n                    # (e.g. activity regularizers).\n                    self.add_loss(layer.get_losses_for(computed_tensors), inputs)\n                    # Keep track of unconditional losses\n                    # (e.g. weight regularizers).\n                    self.add_loss(layer.get_losses_for(None), None)\n\n                    # Update _keras_shape.\n                    if all([hasattr(x, '_keras_shape') for x in computed_tensors]):\n                        if len(computed_tensors) == 1:\n                            shapes = _to_list(layer.compute_output_shape(computed_tensors[0]._keras_shape))\n                            uses_learning_phase = computed_tensors[0]._uses_learning_phase\n                        else:\n                            shapes = _to_list(layer.compute_output_shape([x._keras_shape for x in computed_tensors]))\n                            uses_learning_phase = any([x._uses_learning_phase for x in computed_tensors])\n                        for x, s in zip(output_tensors, shapes):\n                            x._keras_shape = s\n                            x._uses_learning_phase = getattr(x, '_uses_learning_phase', False) or uses_learning_phase\n\n                    # Update tensor_map.\n                    for x, y, mask in zip(reference_output_tensors, output_tensors, output_masks):\n                        tensor_map[str(id(x))] = (y, mask)\n\n        output_tensors = []\n        output_masks = []\n        output_shapes = []\n        for x in self.outputs:\n            assert str(id(x)) in tensor_map, 'Could not compute output ' + str(x)\n            tensor, mask = tensor_map[str(id(x))]\n            if hasattr(tensor, '_keras_shape') and output_shapes is not None:\n                shape = tensor._keras_shape\n                output_shapes.append(shape)\n            else:\n                output_shapes = None\n            output_tensors.append(tensor)\n            output_masks.append(mask)\n\n        # Update cache;\n        # keys are based on ids on input tensors and inputs masks.\n        cache_key = ','.join([str(id(x)) for x in inputs])\n        cache_key += '_' + ','.join([str(id(x)) for x in masks])\n\n        if len(output_tensors) == 1:\n            output_tensors = output_tensors[0]\n            self._output_tensor_cache[cache_key] = output_tensors\n        else:\n            self._output_tensor_cache[cache_key] = output_tensors\n\n        if len(output_masks) == 1:\n            output_masks = output_masks[0]\n            self._output_mask_cache[cache_key] = output_masks\n        else:\n            self._output_mask_cache[cache_key] = output_masks\n\n        if output_shapes is not None:\n            input_shapes = [x._keras_shape for x in inputs]\n            cache_key = ','.join([str(x) for x in input_shapes])\n            if len(output_shapes) == 1:\n                output_shapes = output_shapes[0]\n                self._output_shape_cache[cache_key] = output_shapes\n            else:\n                self._output_shape_cache[cache_key] = output_shapes\n        return output_tensors, output_masks, output_shapes",
        "begin_line": 2156,
        "end_line": 2300,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.02127659574468085,
            "pseudo_dstar_susp": 0.0029239766081871343,
            "pseudo_tarantula_susp": 0.023255813953488372,
            "pseudo_op2_susp": 0.0029239766081871343,
            "pseudo_barinel_susp": 0.023255813953488372
        }
    },
    {
        "name": "keras.engine.topology.Container.get_config#2302",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {\n            'name': self.name,\n        }\n\n        # Build a map from a layer unique name (self._node_key)\n        # to the index of the nodes that are saved in the config.\n        # Only nodes in container_nodes are saved.\n        node_conversion_map = {}\n        for layer in self.layers:\n            if issubclass(layer.__class__, Container):\n                # Containers start with a pre-existing node\n                # linking their input to output.\n                kept_nodes = 1\n            else:\n                kept_nodes = 0\n            for original_node_index, node in enumerate(layer.inbound_nodes):\n                node_key = self._node_key(layer, original_node_index)\n                if node_key in self.container_nodes:\n                    # i.e. we mark it to be saved\n                    node_conversion_map[node_key] = kept_nodes\n                    kept_nodes += 1\n\n        # serialize and save the layers in layer_configs\n        layer_configs = []\n        for layer in self.layers:  # From the earliest layers on.\n            layer_class_name = layer.__class__.__name__\n            layer_config = layer.get_config()\n            filtered_inbound_nodes = []\n            for original_node_index, node in enumerate(layer.inbound_nodes):\n                node_key = self._node_key(layer, original_node_index)\n                if node_key in self.container_nodes:\n                    # The node is relevant to the model:\n                    # add to filtered_inbound_nodes.\n                    if node.arguments:\n                        try:\n                            json.dumps(node.arguments)\n                            kwargs = node.arguments\n                        except TypeError:\n                            warnings.warn(\n                                'Layer ' + layer.name +\n                                ' was passed non-serializable keyword arguments: ' +\n                                str(node.arguments) + '. They will not be included '\n                                'in the serialized model (and thus will be missing '\n                                'at deserialization time).')\n                            kwargs = {}\n                    else:\n                        kwargs = {}\n                    if node.inbound_layers:\n                        node_data = []\n                        for i in range(len(node.inbound_layers)):\n                            inbound_layer = node.inbound_layers[i]\n                            node_index = node.node_indices[i]\n                            tensor_index = node.tensor_indices[i]\n\n                            new_node_index = node_conversion_map.get(\n                                self._node_key(inbound_layer, node_index), 0)\n                            node_data.append([inbound_layer.name,\n                                              new_node_index,\n                                              tensor_index,\n                                              kwargs])\n                        filtered_inbound_nodes.append(node_data)\n            layer_configs.append({\n                'name': layer.name,\n                'class_name': layer_class_name,\n                'config': layer_config,\n                'inbound_nodes': filtered_inbound_nodes,\n            })\n        config['layers'] = layer_configs\n\n        # Gather info about inputs and outputs.\n        model_inputs = []\n        for i in range(len(self.input_layers)):\n            layer = self.input_layers[i]\n            node_index = self.input_layers_node_indices[i]\n\n            node_key = self._node_key(layer, node_index)\n            if node_key not in self.container_nodes:\n                continue\n            new_node_index = node_conversion_map[node_key]\n            tensor_index = self.input_layers_tensor_indices[i]\n            model_inputs.append([layer.name, new_node_index, tensor_index])\n        config['input_layers'] = model_inputs\n        model_outputs = []\n        for i in range(len(self.output_layers)):\n            layer = self.output_layers[i]\n            node_index = self.output_layers_node_indices[i]\n\n            node_key = self._node_key(layer, node_index)\n            if node_key not in self.container_nodes:\n                continue\n            new_node_index = node_conversion_map[node_key]\n            tensor_index = self.output_layers_tensor_indices[i]\n            model_outputs.append([layer.name, new_node_index, tensor_index])\n        config['output_layers'] = model_outputs\n        return copy.deepcopy(config)",
        "begin_line": 2302,
        "end_line": 2397,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.007936507936507936,
            "pseudo_dstar_susp": 0.001953125,
            "pseudo_tarantula_susp": 0.00847457627118644,
            "pseudo_op2_susp": 0.001953125,
            "pseudo_barinel_susp": 0.00847457627118644
        }
    },
    {
        "name": "keras.engine.topology.Container.from_config#2400",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.from_config(cls, config, custom_objects=None)",
        "snippet": "    def from_config(cls, config, custom_objects=None):\n        \"\"\"Instantiates a Model from its config (output of `get_config()`).\n\n        # Arguments\n            config: Model config dictionary.\n            custom_objects: Optional dictionary mapping names\n                (strings) to custom classes or functions to be\n                considered during deserialization.\n\n        # Returns\n            A model instance.\n\n        # Raises\n            ValueError: In case of improperly formatted config dict.\n        \"\"\"\n        # Layer instances created during\n        # the graph reconstruction process\n        created_layers = {}\n\n        # Dictionary mapping layer instances to\n        # node data that specifies a layer call.\n        # It acts as a queue that maintains any unprocessed\n        # layer call until it becomes possible to process it\n        # (i.e. until the input tensors to the call all exist).\n        unprocessed_nodes = {}\n\n        def add_unprocessed_node(layer, node_data):\n            if layer not in unprocessed_nodes:\n                unprocessed_nodes[layer] = [node_data]\n            else:\n                unprocessed_nodes[layer].append(node_data)\n\n        def process_node(layer, node_data):\n            input_tensors = []\n            for input_data in node_data:\n                inbound_layer_name = input_data[0]\n                inbound_node_index = input_data[1]\n                inbound_tensor_index = input_data[2]\n                if len(input_data) == 3:\n                    kwargs = {}\n                elif len(input_data) == 4:\n                    kwargs = input_data[3]\n                else:\n                    raise ValueError('Improperly formatted model config.')\n                if inbound_layer_name not in created_layers:\n                    add_unprocessed_node(layer, node_data)\n                    return\n                inbound_layer = created_layers[inbound_layer_name]\n                if len(inbound_layer.inbound_nodes) <= inbound_node_index:\n                    add_unprocessed_node(layer, node_data)\n                    return\n                inbound_node = inbound_layer.inbound_nodes[inbound_node_index]\n                input_tensors.append(inbound_node.output_tensors[inbound_tensor_index])\n            # Call layer on its inputs, thus creating the node\n            # and building the layer if needed.\n            if input_tensors:\n                if len(input_tensors) == 1:\n                    layer(input_tensors[0], **kwargs)\n                else:\n                    layer(input_tensors, **kwargs)\n\n        def process_layer(layer_data):\n            \"\"\"Deserialize a layer, then call it on appropriate inputs.\n\n            # Arguments\n                layer_data: layer config dict.\n\n            # Raises\n                ValueError: In case of improperly formatted `layer_data` dict.\n            \"\"\"\n            layer_name = layer_data['name']\n\n            # Instantiate layer.\n            from ..layers import deserialize as deserialize_layer\n\n            layer = deserialize_layer(layer_data,\n                                      custom_objects=custom_objects)\n            created_layers[layer_name] = layer\n\n            # Gather layer inputs.\n            inbound_nodes_data = layer_data['inbound_nodes']\n            for node_data in inbound_nodes_data:\n                # We don't process nodes (i.e. make layer calls)\n                # on the fly because the inbound node may not yet exist,\n                # in case of layer shared at different topological depths\n                # (e.g. a model such as A(B(A(B(x)))))\n                add_unprocessed_node(layer, node_data)\n\n        # First, we create all layers and enqueue nodes to be processed\n        for layer_data in config['layers']:\n            process_layer(layer_data)\n        # Then we process nodes in order of layer depth.\n        # Nodes that cannot yet be processed (if the inbound node\n        # does not yet exist) are re-enqueued, and the process\n        # is repeated until all nodes are processed.\n        while unprocessed_nodes:\n            for layer_data in config['layers']:\n                layer = created_layers[layer_data['name']]\n                if layer in unprocessed_nodes:\n                    for node_data in unprocessed_nodes.pop(layer):\n                        process_node(layer, node_data)\n\n        name = config.get('name')\n        input_tensors = []\n        output_tensors = []\n        for layer_data in config['input_layers']:\n            layer_name, node_index, tensor_index = layer_data\n            assert layer_name in created_layers\n            layer = created_layers[layer_name]\n            layer_output_tensors = layer.inbound_nodes[node_index].output_tensors\n            input_tensors.append(layer_output_tensors[tensor_index])\n        for layer_data in config['output_layers']:\n            layer_name, node_index, tensor_index = layer_data\n            assert layer_name in created_layers\n            layer = created_layers[layer_name]\n            layer_output_tensors = layer.inbound_nodes[node_index].output_tensors\n            output_tensors.append(layer_output_tensors[tensor_index])\n        return cls(inputs=input_tensors, outputs=output_tensors, name=name)",
        "begin_line": 2400,
        "end_line": 2517,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0008424599831508003,
            "pseudo_dstar_susp": 0.0008305647840531562,
            "pseudo_tarantula_susp": 0.0008960573476702509,
            "pseudo_op2_susp": 0.0008305647840531562,
            "pseudo_barinel_susp": 0.0008960573476702509
        }
    },
    {
        "name": "keras.engine.topology.Container.add_unprocessed_node#2426",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.add_unprocessed_node(layer, node_data)",
        "snippet": "        def add_unprocessed_node(layer, node_data):\n            if layer not in unprocessed_nodes:\n                unprocessed_nodes[layer] = [node_data]\n            else:\n                unprocessed_nodes[layer].append(node_data)",
        "begin_line": 2426,
        "end_line": 2430,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.004405286343612335,
            "pseudo_dstar_susp": 0.002688172043010753,
            "pseudo_tarantula_susp": 0.0049261083743842365,
            "pseudo_op2_susp": 0.002688172043010753,
            "pseudo_barinel_susp": 0.0049261083743842365
        }
    },
    {
        "name": "keras.engine.topology.Container.process_node#2432",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.process_node(layer, node_data)",
        "snippet": "        def process_node(layer, node_data):\n            input_tensors = []\n            for input_data in node_data:\n                inbound_layer_name = input_data[0]\n                inbound_node_index = input_data[1]\n                inbound_tensor_index = input_data[2]\n                if len(input_data) == 3:\n                    kwargs = {}\n                elif len(input_data) == 4:\n                    kwargs = input_data[3]\n                else:\n                    raise ValueError('Improperly formatted model config.')\n                if inbound_layer_name not in created_layers:\n                    add_unprocessed_node(layer, node_data)\n                    return\n                inbound_layer = created_layers[inbound_layer_name]\n                if len(inbound_layer.inbound_nodes) <= inbound_node_index:\n                    add_unprocessed_node(layer, node_data)\n                    return\n                inbound_node = inbound_layer.inbound_nodes[inbound_node_index]\n                input_tensors.append(inbound_node.output_tensors[inbound_tensor_index])\n            # Call layer on its inputs, thus creating the node\n            # and building the layer if needed.\n            if input_tensors:\n                if len(input_tensors) == 1:\n                    layer(input_tensors[0], **kwargs)\n                else:\n                    layer(input_tensors, **kwargs)",
        "begin_line": 2432,
        "end_line": 2459,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0033112582781456954,
            "pseudo_dstar_susp": 0.002688172043010753,
            "pseudo_tarantula_susp": 0.003816793893129771,
            "pseudo_op2_susp": 0.002688172043010753,
            "pseudo_barinel_susp": 0.003816793893129771
        }
    },
    {
        "name": "keras.engine.topology.Container.process_layer#2461",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.process_layer(layer_data)",
        "snippet": "        def process_layer(layer_data):\n            \"\"\"Deserialize a layer, then call it on appropriate inputs.\n\n            # Arguments\n                layer_data: layer config dict.\n\n            # Raises\n                ValueError: In case of improperly formatted `layer_data` dict.\n            \"\"\"\n            layer_name = layer_data['name']\n\n            # Instantiate layer.\n            from ..layers import deserialize as deserialize_layer\n\n            layer = deserialize_layer(layer_data,\n                                      custom_objects=custom_objects)\n            created_layers[layer_name] = layer\n\n            # Gather layer inputs.\n            inbound_nodes_data = layer_data['inbound_nodes']\n            for node_data in inbound_nodes_data:\n                # We don't process nodes (i.e. make layer calls)\n                # on the fly because the inbound node may not yet exist,\n                # in case of layer shared at different topological depths\n                # (e.g. a model such as A(B(A(B(x)))))\n                add_unprocessed_node(layer, node_data)",
        "begin_line": 2461,
        "end_line": 2486,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009354536950420954,
            "pseudo_dstar_susp": 0.002688172043010753,
            "pseudo_tarantula_susp": 0.0008960573476702509,
            "pseudo_op2_susp": 0.002688172043010753,
            "pseudo_barinel_susp": 0.0008960573476702509
        }
    },
    {
        "name": "keras.engine.topology.Container.save#2519",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.save(self, filepath, overwrite=True, include_optimizer=True)",
        "snippet": "    def save(self, filepath, overwrite=True, include_optimizer=True):\n        \"\"\"Save the model to a single HDF5 file.\n\n        The savefile includes:\n            - The model architecture, allowing to re-instantiate the model.\n            - The model weights.\n            - The state of the optimizer, allowing to resume training\n                exactly where you left off.\n\n        This allows you to save the entirety of the state of a model\n        in a single file.\n\n        Saved models can be reinstantiated via `keras.models.load_model`.\n        The model returned by `load_model`\n        is a compiled model ready to be used (unless the saved model\n        was never compiled in the first place).\n\n        # Arguments\n            filepath: String, path to the file to save the weights to.\n            overwrite: Whether to silently overwrite any existing file at the\n                target location, or provide the user with a manual prompt.\n            include_optimizer: If True, save optimizer's state together.\n\n        # Example\n\n        ```python\n        from keras.models import load_model\n\n        model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n        del model  # deletes the existing model\n\n        # returns a compiled model\n        # identical to the previous one\n        model = load_model('my_model.h5')\n        ```\n        \"\"\"\n        from ..models import save_model\n        save_model(self, filepath, overwrite, include_optimizer)",
        "begin_line": 2519,
        "end_line": 2556,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.topology.Container.load_weights#2591",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.load_weights(self, filepath, by_name=False)",
        "snippet": "    def load_weights(self, filepath, by_name=False):\n        \"\"\"Loads all layer weights from a HDF5 save file.\n\n        If `by_name` is False (default) weights are loaded\n        based on the network's topology, meaning the architecture\n        should be the same as when the weights were saved.\n        Note that layers that don't have weights are not taken\n        into account in the topological ordering, so adding or\n        removing layers is fine as long as they don't have weights.\n\n        If `by_name` is True, weights are loaded into layers\n        only if they share the same name. This is useful\n        for fine-tuning or transfer-learning models where\n        some of the layers have changed.\n\n        # Arguments\n            filepath: String, path to the weights file to load.\n            by_name: Boolean, whether to load weights by name\n                or by topological order.\n\n        # Raises\n            ImportError: If h5py is not available.\n        \"\"\"\n        if h5py is None:\n            raise ImportError('`load_weights` requires h5py.')\n        f = h5py.File(filepath, mode='r')\n        if 'layer_names' not in f.attrs and 'model_weights' in f:\n            f = f['model_weights']\n        if by_name:\n            load_weights_from_hdf5_group_by_name(f, self.layers)\n        else:\n            load_weights_from_hdf5_group(f, self.layers)\n\n        if hasattr(f, 'close'):\n            f.close()",
        "begin_line": 2591,
        "end_line": 2625,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.topology.Container._updated_config#2627",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container._updated_config(self)",
        "snippet": "    def _updated_config(self):\n        \"\"\"Util hared between different serialization methods.\n\n        # Returns\n            Model config with Keras version information added.\n        \"\"\"\n        from .. import __version__ as keras_version\n\n        config = self.get_config()\n        model_config = {\n            'class_name': self.__class__.__name__,\n            'config': config,\n            'keras_version': keras_version,\n            'backend': K.backend()\n        }\n        return model_config",
        "begin_line": 2627,
        "end_line": 2642,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002304147465437788,
            "pseudo_dstar_susp": 0.0014577259475218659,
            "pseudo_tarantula_susp": 0.003289473684210526,
            "pseudo_op2_susp": 0.0014577259475218659,
            "pseudo_barinel_susp": 0.003289473684210526
        }
    },
    {
        "name": "keras.engine.topology.Container.to_json#2644",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.to_json(self, **kwargs)",
        "snippet": "    def to_json(self, **kwargs):\n        \"\"\"Returns a JSON string containing the network configuration.\n\n        To load a network from a JSON save file, use\n        `keras.models.model_from_json(json_string, custom_objects={})`.\n\n        # Arguments\n            **kwargs: Additional keyword arguments\n                to be passed to `json.dumps()`.\n\n        # Returns\n            A JSON string.\n        \"\"\"\n        def get_json_type(obj):\n            # If obj is any numpy type\n            if type(obj).__module__ == np.__name__:\n                return obj.item()\n\n            # If obj is a python 'type'\n            if type(obj).__name__ == type.__name__:\n                return obj.__name__\n\n            raise TypeError('Not JSON Serializable:', obj)\n\n        model_config = self._updated_config()\n        return json.dumps(model_config, default=get_json_type, **kwargs)",
        "begin_line": 2644,
        "end_line": 2669,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002304147465437788,
            "pseudo_dstar_susp": 0.0014577259475218659,
            "pseudo_tarantula_susp": 0.003289473684210526,
            "pseudo_op2_susp": 0.0014577259475218659,
            "pseudo_barinel_susp": 0.003289473684210526
        }
    },
    {
        "name": "keras.engine.topology.Container.get_json_type#2657",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.get_json_type(obj)",
        "snippet": "        def get_json_type(obj):\n            # If obj is any numpy type\n            if type(obj).__module__ == np.__name__:\n                return obj.item()\n\n            # If obj is a python 'type'\n            if type(obj).__name__ == type.__name__:\n                return obj.__name__\n\n            raise TypeError('Not JSON Serializable:', obj)",
        "begin_line": 2657,
        "end_line": 2666,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.002304147465437788,
            "pseudo_dstar_susp": 0.0014577259475218659,
            "pseudo_tarantula_susp": 0.003289473684210526,
            "pseudo_op2_susp": 0.0014577259475218659,
            "pseudo_barinel_susp": 0.003289473684210526
        }
    },
    {
        "name": "keras.engine.topology.Container.to_yaml#2671",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.to_yaml(self, **kwargs)",
        "snippet": "    def to_yaml(self, **kwargs):\n        \"\"\"Returns a yaml string containing the network configuration.\n\n        To load a network from a yaml save file, use\n        `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n\n        `custom_objects` should be a dictionary mapping\n        the names of custom losses / layers / etc to the corresponding\n        functions / classes.\n\n        # Arguments\n            **kwargs: Additional keyword arguments\n                to be passed to `yaml.dump()`.\n\n        # Returns\n            A YAML string.\n        \"\"\"\n        return yaml.dump(self._updated_config(), **kwargs)",
        "begin_line": 2671,
        "end_line": 2688,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0033112582781456954,
            "pseudo_dstar_susp": 0.0015408320493066256,
            "pseudo_tarantula_susp": 0.003816793893129771,
            "pseudo_op2_susp": 0.0015408320493066256,
            "pseudo_barinel_susp": 0.003816793893129771
        }
    },
    {
        "name": "keras.engine.topology.Container.summary#2690",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology.Container",
        "signature": "keras.engine.topology.Container.summary(self, line_length=None, positions=None, print_fn=print)",
        "snippet": "    def summary(self, line_length=None, positions=None, print_fn=print):\n        \"\"\"Prints a string summary of the network.\n\n        # Arguments\n            line_length: Total length of printed lines\n                (e.g. set this to adapt the display to different\n                terminal window sizes).\n            positions: Relative or absolute positions of log elements\n                in each line. If not provided,\n                defaults to `[.33, .55, .67, 1.]`.\n            print_fn: Print function to use.\n                It will be called on each line of the summary.\n                You can set it to a custom function\n                in order to capture the string summary.\n        \"\"\"\n        return print_layer_summary(self,\n                                   line_length=line_length,\n                                   positions=positions,\n                                   print_fn=print_fn)",
        "begin_line": 2690,
        "end_line": 2708,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001564945226917058,
            "pseudo_dstar_susp": 0.001221001221001221,
            "pseudo_tarantula_susp": 0.0022172949002217295,
            "pseudo_op2_susp": 0.001221001221001221,
            "pseudo_barinel_susp": 0.0022172949002217295
        }
    },
    {
        "name": "keras.engine.topology.get_source_inputs#2711",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology.get_source_inputs(tensor, layer=None, node_index=None)",
        "snippet": "def get_source_inputs(tensor, layer=None, node_index=None):\n    \"\"\"Returns the list of input tensors necessary to compute `tensor`.\n\n    Output will always be a list of tensors\n    (potentially with 1 element).\n\n    # Arguments\n        tensor: The tensor to start from.\n        layer: Origin layer of the tensor. Will be\n            determined via tensor._keras_history if not provided.\n        node_index: Origin node index of the tensor.\n\n    # Returns\n        List of input tensors.\n    \"\"\"\n    if not hasattr(tensor, '_keras_history'):\n        return tensor\n\n    if layer is None or node_index:\n        layer, node_index, _ = tensor._keras_history\n    if not layer.inbound_nodes:\n        return [tensor]\n    else:\n        node = layer.inbound_nodes[node_index]\n        if not node.inbound_layers:\n            # Reached an Input layer, stop recursion.\n            return node.input_tensors\n        else:\n            source_tensors = []\n            for i in range(len(node.inbound_layers)):\n                x = node.input_tensors[i]\n                layer = node.inbound_layers[i]\n                node_index = node.node_indices[i]\n                previous_sources = get_source_inputs(x,\n                                                     layer,\n                                                     node_index)\n                # Avoid input redundancy.\n                for x in previous_sources:\n                    if x not in source_tensors:\n                        source_tensors.append(x)\n            return source_tensors",
        "begin_line": 2711,
        "end_line": 2751,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 8.961376467425397e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.topology._to_list#2754",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology._to_list(x)",
        "snippet": "def _to_list(x):\n    \"\"\"Normalizes a list/tensor into a list.\n\n    If a tensor is passed, we return\n    a list of size 1 containing the tensor.\n\n    # Arguments\n        x: target object to be normalized.\n\n    # Returns\n        A list.\n    \"\"\"\n    if isinstance(x, list):\n        return x\n    return [x]",
        "begin_line": 2754,
        "end_line": 2768,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0006821282401091405,
            "pseudo_dstar_susp": 0.0006821282401091405,
            "pseudo_tarantula_susp": 0.000687757909215956,
            "pseudo_op2_susp": 0.0006821282401091405,
            "pseudo_barinel_susp": 0.000687757909215956
        }
    },
    {
        "name": "keras.engine.topology._object_list_uid#2771",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology._object_list_uid(object_list)",
        "snippet": "def _object_list_uid(object_list):\n    object_list = _to_list(object_list)\n    return ', '.join([str(abs(id(x))) for x in object_list])",
        "begin_line": 2771,
        "end_line": 2773,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007739938080495357,
            "pseudo_dstar_susp": 0.002583979328165375,
            "pseudo_tarantula_susp": 0.0006944444444444445,
            "pseudo_op2_susp": 0.002583979328165375,
            "pseudo_barinel_susp": 0.0006944444444444445
        }
    },
    {
        "name": "keras.engine.topology._is_all_none#2776",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology._is_all_none(iterable_or_element)",
        "snippet": "def _is_all_none(iterable_or_element):\n    if not isinstance(iterable_or_element, (list, tuple)):\n        iterable = [iterable_or_element]\n    else:\n        iterable = iterable_or_element\n    for element in iterable:\n        if element is not None:\n            return False\n    return True",
        "begin_line": 2776,
        "end_line": 2784,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009090909090909091,
            "pseudo_dstar_susp": 0.0008920606601248885,
            "pseudo_tarantula_susp": 0.0011210762331838565,
            "pseudo_op2_susp": 0.0008920606601248885,
            "pseudo_barinel_susp": 0.0011210762331838565
        }
    },
    {
        "name": "keras.engine.topology._collect_previous_mask#2787",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology._collect_previous_mask(input_tensors)",
        "snippet": "def _collect_previous_mask(input_tensors):\n    \"\"\"Retrieves the output mask(s) of the previous node.\n\n    # Arguments\n        input_tensors: A tensor or list of tensors.\n\n    # Returns\n        A mask tensor or list of mask tensors.\n    \"\"\"\n    input_tensors = _to_list(input_tensors)\n    masks = []\n    for x in input_tensors:\n        if hasattr(x, '_keras_history'):\n            inbound_layer, node_index, tensor_index = x._keras_history\n            node = inbound_layer.inbound_nodes[node_index]\n            mask = node.output_masks[tensor_index]\n            masks.append(mask)\n        else:\n            masks.append(None)\n    if len(masks) == 1:\n        return masks[0]\n    return masks",
        "begin_line": 2787,
        "end_line": 2808,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001564945226917058,
            "pseudo_dstar_susp": 0.001221001221001221,
            "pseudo_tarantula_susp": 0.0022172949002217295,
            "pseudo_op2_susp": 0.001221001221001221,
            "pseudo_barinel_susp": 0.0022172949002217295
        }
    },
    {
        "name": "keras.engine.topology._to_snake_case#2811",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology._to_snake_case(name)",
        "snippet": "def _to_snake_case(name):\n    intermediate = re.sub('(.)([A-Z][a-z0-9]+)', r'\\1_\\2', name)\n    insecure = re.sub('([a-z])([A-Z])', r'\\1_\\2', intermediate).lower()\n    # If the class is private the name starts with \"_\" which is not secure\n    # for creating scopes. We prefix the name with \"private\" in this case.\n    if insecure[0] != '_':\n        return insecure\n    return 'private' + insecure",
        "begin_line": 2811,
        "end_line": 2818,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0014245014245014246,
            "pseudo_dstar_susp": 0.005952380952380952,
            "pseudo_tarantula_susp": 0.0009940357852882703,
            "pseudo_op2_susp": 0.005952380952380952,
            "pseudo_barinel_susp": 0.0009940357852882703
        }
    },
    {
        "name": "keras.engine.topology._collect_input_shape#2821",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology._collect_input_shape(input_tensors)",
        "snippet": "def _collect_input_shape(input_tensors):\n    \"\"\"Collects the output shape(s) of a list of Keras tensors.\n\n    # Arguments\n        input_tensors: list of input tensors (or single input tensor).\n\n    # Returns\n        List of shape tuples (or single tuple), one tuple per input.\n    \"\"\"\n    input_tensors = _to_list(input_tensors)\n    shapes = []\n    for x in input_tensors:\n        try:\n            shapes.append(K.int_shape(x))\n        except TypeError:\n            shapes.append(None)\n    if len(shapes) == 1:\n        return shapes[0]\n    return shapes",
        "begin_line": 2821,
        "end_line": 2839,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009090909090909091,
            "pseudo_dstar_susp": 0.0008920606601248885,
            "pseudo_tarantula_susp": 0.0011210762331838565,
            "pseudo_op2_susp": 0.0008920606601248885,
            "pseudo_barinel_susp": 0.0011210762331838565
        }
    },
    {
        "name": "keras.engine.topology.save_weights_to_hdf5_group#2842",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology.save_weights_to_hdf5_group(f, layers)",
        "snippet": "def save_weights_to_hdf5_group(f, layers):\n    from .. import __version__ as keras_version\n\n    f.attrs['layer_names'] = [layer.name.encode('utf8') for layer in layers]\n    f.attrs['backend'] = K.backend().encode('utf8')\n    f.attrs['keras_version'] = str(keras_version).encode('utf8')\n\n    for layer in layers:\n        g = f.create_group(layer.name)\n        symbolic_weights = layer.weights\n        weight_values = K.batch_get_value(symbolic_weights)\n        weight_names = []\n        for i, (w, val) in enumerate(zip(symbolic_weights, weight_values)):\n            if hasattr(w, 'name') and w.name:\n                name = str(w.name)\n            else:\n                name = 'param_' + str(i)\n            weight_names.append(name.encode('utf8'))\n        g.attrs['weight_names'] = weight_names\n        for name, val in zip(weight_names, weight_values):\n            param_dset = g.create_dataset(name, val.shape,\n                                          dtype=val.dtype)\n            if not val.shape:\n                # scalar\n                param_dset[()] = val\n            else:\n                param_dset[:] = val",
        "begin_line": 2842,
        "end_line": 2868,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010520778537611783,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.topology.preprocess_weights_for_loading#2871",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology.preprocess_weights_for_loading(layer, weights, original_keras_version=None, original_backend=None)",
        "snippet": "def preprocess_weights_for_loading(layer, weights,\n                                   original_keras_version=None,\n                                   original_backend=None):\n    \"\"\"Converts layers weights from Keras 1 format to Keras 2.\n\n    # Arguments\n        layer: Layer instance.\n        weights: List of weights values (Numpy arrays).\n        original_keras_version: Keras version for the weights, as a string.\n        original_backend: Keras backend the weights were trained with,\n            as a string.\n\n    # Returns\n        A list of weights values (Numpy arrays).\n    \"\"\"\n    if original_keras_version == '1':\n        if layer.__class__.__name__ == 'Bidirectional':\n            num_weights_per_layer = len(weights) // 2\n\n            forward_weights = preprocess_weights_for_loading(layer.forward_layer,\n                                                             weights[:num_weights_per_layer],\n                                                             original_keras_version,\n                                                             original_backend)\n            backward_weights = preprocess_weights_for_loading(layer.backward_layer,\n                                                              weights[num_weights_per_layer:],\n                                                              original_keras_version,\n                                                              original_backend)\n            weights = forward_weights + backward_weights\n\n        if layer.__class__.__name__ == 'TimeDistributed':\n            weights = preprocess_weights_for_loading(layer.layer,\n                                                     weights,\n                                                     original_keras_version,\n                                                     original_backend)\n\n        if layer.__class__.__name__ == 'Conv1D':\n            shape = weights[0].shape\n            # Handle Keras 1.1 format\n            if shape[:2] != (layer.kernel_size[0], 1) or shape[3] != layer.filters:\n                # Legacy shape:\n                # (filters, input_dim, filter_length, 1)\n                assert shape[0] == layer.filters and shape[2:] == (layer.kernel_size[0], 1)\n                weights[0] = np.transpose(weights[0], (2, 3, 1, 0))\n            weights[0] = weights[0][:, 0, :, :]\n\n        if layer.__class__.__name__ == 'Conv2D':\n            if layer.data_format == 'channels_first':\n                # old: (filters, stack_size, kernel_rows, kernel_cols)\n                # new: (kernel_rows, kernel_cols, stack_size, filters)\n                weights[0] = np.transpose(weights[0], (2, 3, 1, 0))\n\n        if layer.__class__.__name__ == 'Conv2DTranspose':\n            if layer.data_format == 'channels_last':\n                # old: (kernel_rows, kernel_cols, stack_size, filters)\n                # new: (kernel_rows, kernel_cols, filters, stack_size)\n                weights[0] = np.transpose(weights[0], (0, 1, 3, 2))\n            if layer.data_format == 'channels_first':\n                # old: (filters, stack_size, kernel_rows, kernel_cols)\n                # new: (kernel_rows, kernel_cols, filters, stack_size)\n                weights[0] = np.transpose(weights[0], (2, 3, 0, 1))\n\n        if layer.__class__.__name__ == 'Conv3D':\n            if layer.data_format == 'channels_first':\n                # old: (filters, stack_size, ...)\n                # new: (..., stack_size, filters)\n                weights[0] = np.transpose(weights[0], (2, 3, 4, 1, 0))\n\n        if layer.__class__.__name__ == 'GRU':\n            if len(weights) == 9:\n                kernel = np.concatenate([weights[0],\n                                         weights[3],\n                                         weights[6]], axis=-1)\n                recurrent_kernel = np.concatenate([weights[1],\n                                                   weights[4],\n                                                   weights[7]], axis=-1)\n                bias = np.concatenate([weights[2],\n                                       weights[5],\n                                       weights[8]], axis=-1)\n                weights = [kernel, recurrent_kernel, bias]\n\n        if layer.__class__.__name__ == 'LSTM':\n            if len(weights) == 12:\n                # old: i, c, f, o\n                # new: i, f, c, o\n                kernel = np.concatenate([weights[0],\n                                         weights[6],\n                                         weights[3],\n                                         weights[9]], axis=-1)\n                recurrent_kernel = np.concatenate([weights[1],\n                                                   weights[7],\n                                                   weights[4],\n                                                   weights[10]], axis=-1)\n                bias = np.concatenate([weights[2],\n                                       weights[8],\n                                       weights[5],\n                                       weights[11]], axis=-1)\n                weights = [kernel, recurrent_kernel, bias]\n\n        if layer.__class__.__name__ == 'ConvLSTM2D':\n            if len(weights) == 12:\n                kernel = np.concatenate([weights[0],\n                                         weights[6],\n                                         weights[3],\n                                         weights[9]], axis=-1)\n                recurrent_kernel = np.concatenate([weights[1],\n                                                   weights[7],\n                                                   weights[4],\n                                                   weights[10]], axis=-1)\n                bias = np.concatenate([weights[2],\n                                       weights[8],\n                                       weights[5],\n                                       weights[11]], axis=-1)\n                if layer.data_format == 'channels_first':\n                    # old: (filters, stack_size, kernel_rows, kernel_cols)\n                    # new: (kernel_rows, kernel_cols, stack_size, filters)\n                    kernel = np.transpose(kernel, (2, 3, 1, 0))\n                    recurrent_kernel = np.transpose(recurrent_kernel,\n                                                    (2, 3, 1, 0))\n                weights = [kernel, recurrent_kernel, bias]\n\n        if layer.__class__.__name__ in ['Model', 'Sequential']:\n            new_weights = []\n            # trainable weights\n            for sublayer in layer.layers:\n                num_weights = len(sublayer.trainable_weights)\n                if num_weights > 0:\n                    new_weights.extend(preprocess_weights_for_loading(\n                        layer=sublayer,\n                        weights=weights[:num_weights],\n                        original_keras_version=original_keras_version,\n                        original_backend=original_backend))\n                    weights = weights[num_weights:]\n\n            # non-trainable weights\n            for sublayer in layer.layers:\n                num_weights = len([l for l in sublayer.weights if l not in sublayer.trainable_weights])\n                if num_weights > 0:\n                    new_weights.extend(preprocess_weights_for_loading(\n                        layer=sublayer,\n                        weights=weights[:num_weights],\n                        original_keras_version=original_keras_version,\n                        original_backend=original_backend))\n                    weights = weights[num_weights:]\n            weights = new_weights\n\n    conv_layers = ['Conv1D',\n                   'Conv2D',\n                   'Conv3D',\n                   'Conv2DTranspose',\n                   'ConvLSTM2D']\n    if layer.__class__.__name__ in conv_layers:\n        if _need_convert_kernel(original_backend):\n            weights[0] = conv_utils.convert_kernel(weights[0])\n            if layer.__class__.__name__ == 'ConvLSTM2D':\n                weights[1] = conv_utils.convert_kernel(weights[1])\n        if K.int_shape(layer.weights[0]) != weights[0].shape:\n            weights[0] = np.transpose(weights[0], (3, 2, 0, 1))\n            if layer.__class__.__name__ == 'ConvLSTM2D':\n                weights[1] = np.transpose(weights[1], (3, 2, 0, 1))\n\n    # convert the weights of CuDNNLSTM so that they could be loaded into LSTM\n    if layer.__class__.__name__ == 'LSTM':\n        # determine if we're loading a CuDNNLSTM layer from the number of bias weights:\n        # CuDNNLSTM has (units * 8) weights; while LSTM has (units * 4)\n        units = weights[1].shape[0]\n        bias = weights[2]\n        if len(bias) == units * 8:\n            # reshape the kernels\n            kernels = np.split(weights[0], 4, axis=1)\n            kernels = [kernel.reshape(-1).reshape(kernel.shape, order='F') for kernel in kernels]\n            weights[0] = np.concatenate(kernels, axis=1)\n\n            # transpose the recurrent kernels\n            recurrent_kernels = np.split(weights[1], 4, axis=1)\n            recurrent_kernels = [kernel.T for kernel in recurrent_kernels]\n            weights[1] = np.concatenate(recurrent_kernels, axis=1)\n\n            # split the bias into half and merge\n            weights[2] = bias[:units * 4] + bias[units * 4:]\n\n    return weights",
        "begin_line": 2871,
        "end_line": 3051,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.topology._need_convert_kernel#3054",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology._need_convert_kernel(original_backend)",
        "snippet": "def _need_convert_kernel(original_backend):\n    \"\"\"Check if conversion on kernel matrices is required during weight loading.\n\n    The convolution operation is implemented differently in different backends.\n    While TH implements convolution, TF and CNTK implement the correlation operation.\n    So the channel axis needs to be flipped when we're loading TF weights onto a TH model,\n    or vice verca. However, there's no conversion required between TF and CNTK.\n\n    # Arguments\n        original_backend: Keras backend the weights were trained with, as a string.\n\n    # Returns\n        `True` if conversion on kernel matrices is required, otherwise `False`.\n    \"\"\"\n    if original_backend is None:\n        # backend information not available\n        return False\n    uses_correlation = {'tensorflow': True,\n                        'theano': False,\n                        'cntk': True}\n    return uses_correlation[original_backend] != uses_correlation[K.backend()]",
        "begin_line": 3054,
        "end_line": 3074,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.topology.load_weights_from_hdf5_group#3077",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology.load_weights_from_hdf5_group(f, layers)",
        "snippet": "def load_weights_from_hdf5_group(f, layers):\n    \"\"\"Implements topological (order-based) weight loading.\n\n    # Arguments\n        f: A pointer to a HDF5 group.\n        layers: a list of target layers.\n\n    # Raises\n        ValueError: in case of mismatch between provided layers\n            and weights file.\n    \"\"\"\n    if 'keras_version' in f.attrs:\n        original_keras_version = f.attrs['keras_version'].decode('utf8')\n    else:\n        original_keras_version = '1'\n    if 'backend' in f.attrs:\n        original_backend = f.attrs['backend'].decode('utf8')\n    else:\n        original_backend = None\n\n    filtered_layers = []\n    for layer in layers:\n        weights = layer.weights\n        if weights:\n            filtered_layers.append(layer)\n\n    layer_names = [n.decode('utf8') for n in f.attrs['layer_names']]\n    filtered_layer_names = []\n    for name in layer_names:\n        g = f[name]\n        weight_names = [n.decode('utf8') for n in g.attrs['weight_names']]\n        if weight_names:\n            filtered_layer_names.append(name)\n    layer_names = filtered_layer_names\n    if len(layer_names) != len(filtered_layers):\n        raise ValueError('You are trying to load a weight file '\n                         'containing ' + str(len(layer_names)) +\n                         ' layers into a model with ' +\n                         str(len(filtered_layers)) + ' layers.')\n\n    # We batch weight value assignments in a single backend call\n    # which provides a speedup in TensorFlow.\n    weight_value_tuples = []\n    for k, name in enumerate(layer_names):\n        g = f[name]\n        weight_names = [n.decode('utf8') for n in g.attrs['weight_names']]\n        weight_values = [g[weight_name] for weight_name in weight_names]\n        layer = filtered_layers[k]\n        symbolic_weights = layer.weights\n        weight_values = preprocess_weights_for_loading(layer,\n                                                       weight_values,\n                                                       original_keras_version,\n                                                       original_backend)\n        if len(weight_values) != len(symbolic_weights):\n            raise ValueError('Layer #' + str(k) +\n                             ' (named \"' + layer.name +\n                             '\" in the current model) was found to '\n                             'correspond to layer ' + name +\n                             ' in the save file. '\n                             'However the new layer ' + layer.name +\n                             ' expects ' + str(len(symbolic_weights)) +\n                             ' weights, but the saved weights have ' +\n                             str(len(weight_values)) +\n                             ' elements.')\n        weight_value_tuples += zip(symbolic_weights, weight_values)\n    K.batch_set_value(weight_value_tuples)",
        "begin_line": 3077,
        "end_line": 3142,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010694043417816276,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.engine.topology.load_weights_from_hdf5_group_by_name#3145",
        "src_path": "keras/engine/topology.py",
        "class_name": "keras.engine.topology",
        "signature": "keras.engine.topology.load_weights_from_hdf5_group_by_name(f, layers)",
        "snippet": "def load_weights_from_hdf5_group_by_name(f, layers):\n    \"\"\"Implements name-based weight loading.\n\n    (instead of topological weight loading).\n\n    Layers that have no matching name are skipped.\n\n    # Arguments\n        f: A pointer to a HDF5 group.\n        layers: a list of target layers.\n\n    # Raises\n        ValueError: in case of mismatch between provided layers\n            and weights file.\n    \"\"\"\n    if 'keras_version' in f.attrs:\n        original_keras_version = f.attrs['keras_version'].decode('utf8')\n    else:\n        original_keras_version = '1'\n    if 'backend' in f.attrs:\n        original_backend = f.attrs['backend'].decode('utf8')\n    else:\n        original_backend = None\n\n    # New file format.\n    layer_names = [n.decode('utf8') for n in f.attrs['layer_names']]\n\n    # Reverse index of layer name to list of layers with name.\n    index = {}\n    for layer in layers:\n        if layer.name:\n            index.setdefault(layer.name, []).append(layer)\n\n    # We batch weight value assignments in a single backend call\n    # which provides a speedup in TensorFlow.\n    weight_value_tuples = []\n    for k, name in enumerate(layer_names):\n        g = f[name]\n        weight_names = [n.decode('utf8') for n in g.attrs['weight_names']]\n        weight_values = [g[weight_name] for weight_name in weight_names]\n\n        for layer in index.get(name, []):\n            symbolic_weights = layer.weights\n            weight_values = preprocess_weights_for_loading(\n                layer,\n                weight_values,\n                original_keras_version,\n                original_backend)\n            if len(weight_values) != len(symbolic_weights):\n                raise ValueError('Layer #' + str(k) +\n                                 ' (named \"' + layer.name +\n                                 '\") expects ' +\n                                 str(len(symbolic_weights)) +\n                                 ' weight(s), but the saved weights' +\n                                 ' have ' + str(len(weight_values)) +\n                                 ' element(s).')\n            # Set values.\n            for i in range(len(weight_values)):\n                weight_value_tuples.append((symbolic_weights[i],\n                                            weight_values[i]))\n    K.batch_set_value(weight_value_tuples)",
        "begin_line": 3145,
        "end_line": 3205,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.regularizers.Regularizer.from_config#16",
        "src_path": "keras/regularizers.py",
        "class_name": "keras.regularizers.Regularizer",
        "signature": "keras.regularizers.Regularizer.from_config(cls, config)",
        "snippet": "    def from_config(cls, config):\n        return cls(**config)",
        "begin_line": 16,
        "end_line": 17,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010882576994232234,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.regularizers.L1L2.__init__#28",
        "src_path": "keras/regularizers.py",
        "class_name": "keras.regularizers.L1L2",
        "signature": "keras.regularizers.L1L2.__init__(self, l1=0.0, l2=0.0)",
        "snippet": "    def __init__(self, l1=0., l2=0.):\n        self.l1 = K.cast_to_floatx(l1)\n        self.l2 = K.cast_to_floatx(l2)",
        "begin_line": 28,
        "end_line": 30,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.898050084133426e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.regularizers.L1L2.__call__#32",
        "src_path": "keras/regularizers.py",
        "class_name": "keras.regularizers.L1L2",
        "signature": "keras.regularizers.L1L2.__call__(self, x)",
        "snippet": "    def __call__(self, x):\n        regularization = 0.\n        if self.l1:\n            regularization += K.sum(self.l1 * K.abs(x))\n        if self.l2:\n            regularization += K.sum(self.l2 * K.square(x))\n        return regularization",
        "begin_line": 32,
        "end_line": 38,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010882576994232234,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.regularizers.L1L2.get_config#40",
        "src_path": "keras/regularizers.py",
        "class_name": "keras.regularizers.L1L2",
        "signature": "keras.regularizers.L1L2.get_config(self)",
        "snippet": "    def get_config(self):\n        return {'l1': float(self.l1),\n                'l2': float(self.l2)}",
        "begin_line": 40,
        "end_line": 42,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010178117048346055,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.regularizers.l1#48",
        "src_path": "keras/regularizers.py",
        "class_name": "keras.regularizers",
        "signature": "keras.regularizers.l1(l=0.01)",
        "snippet": "def l1(l=0.01):\n    return L1L2(l1=l)",
        "begin_line": 48,
        "end_line": 49,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010219724067450178,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.regularizers.l2#52",
        "src_path": "keras/regularizers.py",
        "class_name": "keras.regularizers",
        "signature": "keras.regularizers.l2(l=0.01)",
        "snippet": "def l2(l=0.01):\n    return L1L2(l2=l)",
        "begin_line": 52,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001006947940791461,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.regularizers.l1_l2#56",
        "src_path": "keras/regularizers.py",
        "class_name": "keras.regularizers",
        "signature": "keras.regularizers.l1_l2(l1=0.01, l2=0.01)",
        "snippet": "def l1_l2(l1=0.01, l2=0.01):\n    return L1L2(l1=l1, l2=l2)",
        "begin_line": 56,
        "end_line": 57,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.regularizers.serialize#60",
        "src_path": "keras/regularizers.py",
        "class_name": "keras.regularizers",
        "signature": "keras.regularizers.serialize(regularizer)",
        "snippet": "def serialize(regularizer):\n    return serialize_keras_object(regularizer)",
        "begin_line": 60,
        "end_line": 61,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007987220447284345,
            "pseudo_dstar_susp": 0.0007880220646178094,
            "pseudo_tarantula_susp": 0.0008453085376162299,
            "pseudo_op2_susp": 0.0007880220646178094,
            "pseudo_barinel_susp": 0.0008453085376162299
        }
    },
    {
        "name": "keras.regularizers.deserialize#64",
        "src_path": "keras/regularizers.py",
        "class_name": "keras.regularizers",
        "signature": "keras.regularizers.deserialize(config, custom_objects=None)",
        "snippet": "def deserialize(config, custom_objects=None):\n    return deserialize_keras_object(config,\n                                    module_objects=globals(),\n                                    custom_objects=custom_objects,\n                                    printable_module_name='regularizer')",
        "begin_line": 64,
        "end_line": 68,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.9147332936744e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.regularizers.get#71",
        "src_path": "keras/regularizers.py",
        "class_name": "keras.regularizers",
        "signature": "keras.regularizers.get(identifier)",
        "snippet": "def get(identifier):\n    if identifier is None:\n        return None\n    if isinstance(identifier, dict):\n        return deserialize(identifier)\n    elif isinstance(identifier, six.string_types):\n        config = {'class_name': str(identifier), 'config': {}}\n        return deserialize(config)\n    elif callable(identifier):\n        return identifier\n    else:\n        raise ValueError('Could not interpret regularizer identifier:',\n                         identifier)",
        "begin_line": 71,
        "end_line": 83,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0014992503748125937,
            "pseudo_dstar_susp": 0.0072992700729927005,
            "pseudo_tarantula_susp": 0.0010427528675703858,
            "pseudo_op2_susp": 0.0072992700729927005,
            "pseudo_barinel_susp": 0.0010427528675703858
        }
    },
    {
        "name": "keras.applications.vgg16.VGG16#35",
        "src_path": "keras/applications/vgg16.py",
        "class_name": "keras.applications.vgg16",
        "signature": "keras.applications.vgg16.VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)",
        "snippet": "def VGG16(include_top=True, weights='imagenet',\n          input_tensor=None, input_shape=None,\n          pooling=None,\n          classes=1000):\n    \"\"\"Instantiates the VGG16 architecture.\n\n    Optionally loads weights pre-trained\n    on ImageNet. Note that when using TensorFlow,\n    for best performance you should set\n    `image_data_format='channels_last'` in your Keras config\n    at ~/.keras/keras.json.\n\n    The model and the weights are compatible with both\n    TensorFlow and Theano. The data format\n    convention used by the model is the one\n    specified in your Keras config file.\n\n    # Arguments\n        include_top: whether to include the 3 fully-connected\n            layers at the top of the network.\n        weights: one of `None` (random initialization)\n            or 'imagenet' (pre-training on ImageNet).\n        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n            to use as image input for the model.\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(224, 224, 3)` (with `channels_last` data format)\n            or `(3, 224, 224)` (with `channels_first` data format).\n            It should have exactly 3 input channels,\n            and width and height should be no smaller than 48.\n            E.g. `(200, 200, 3)` would be one valid value.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model will be\n                the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a 2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n\n    # Returns\n        A Keras model instance.\n\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n    \"\"\"\n    if weights not in {'imagenet', None}:\n        raise ValueError('The `weights` argument should be either '\n                         '`None` (random initialization) or `imagenet` '\n                         '(pre-training on ImageNet).')\n\n    if weights == 'imagenet' and include_top and classes != 1000:\n        raise ValueError('If using `weights` as imagenet with `include_top`'\n                         ' as true, `classes` should be 1000')\n    # Determine proper input shape\n    input_shape = _obtain_input_shape(input_shape,\n                                      default_size=224,\n                                      min_size=48,\n                                      data_format=K.image_data_format(),\n                                      require_flatten=include_top,\n                                      weights=weights)\n\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n    # Block 1\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n\n    # Block 2\n    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n\n    # Block 3\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n\n    # Block 4\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n\n    # Block 5\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n\n    if include_top:\n        # Classification block\n        x = Flatten(name='flatten')(x)\n        x = Dense(4096, activation='relu', name='fc1')(x)\n        x = Dense(4096, activation='relu', name='fc2')(x)\n        x = Dense(classes, activation='softmax', name='predictions')(x)\n    else:\n        if pooling == 'avg':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling == 'max':\n            x = GlobalMaxPooling2D()(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n    # Create model.\n    model = Model(inputs, x, name='vgg16')\n\n    # load weights\n    if weights == 'imagenet':\n        if include_top:\n            weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels.h5',\n                                    WEIGHTS_PATH,\n                                    cache_subdir='models',\n                                    file_hash='64373286793e3c8b2b4e3219cbf3544b')\n        else:\n            weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n                                    WEIGHTS_PATH_NO_TOP,\n                                    cache_subdir='models',\n                                    file_hash='6d6bbae143d832006294945121d1f1fc')\n        model.load_weights(weights_path)\n        if K.backend() == 'theano':\n            layer_utils.convert_all_kernels_in_model(model)\n\n        if K.image_data_format() == 'channels_first':\n            if include_top:\n                maxpool = model.get_layer(name='block5_pool')\n                shape = maxpool.output_shape[1:]\n                dense = model.get_layer(name='fc1')\n                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n\n            if K.backend() == 'tensorflow':\n                warnings.warn('You are using the TensorFlow backend, yet you '\n                              'are using the Theano '\n                              'image data format convention '\n                              '(`image_data_format=\"channels_first\"`). '\n                              'For best performance, set '\n                              '`image_data_format=\"channels_last\"` in '\n                              'your Keras config '\n                              'at ~/.keras/keras.json.')\n    return model",
        "begin_line": 35,
        "end_line": 192,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.Masking.__init__#53",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Masking",
        "signature": "keras.layers.core.Masking.__init__(self, mask_value=0.0, **kwargs)",
        "snippet": "    def __init__(self, mask_value=0., **kwargs):\n        super(Masking, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.mask_value = mask_value",
        "begin_line": 53,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001152604887044721,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.Masking.compute_mask#58",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Masking",
        "signature": "keras.layers.core.Masking.compute_mask(self, inputs, mask=None)",
        "snippet": "    def compute_mask(self, inputs, mask=None):\n        return K.any(K.not_equal(inputs, self.mask_value), axis=-1)",
        "begin_line": 58,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001152604887044721,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.Masking.call#61",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Masking",
        "signature": "keras.layers.core.Masking.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        boolean_mask = K.any(K.not_equal(inputs, self.mask_value),\n                             axis=-1, keepdims=True)\n        return inputs * K.cast(boolean_mask, K.dtype(inputs))",
        "begin_line": 61,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001152604887044721,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.Masking.get_config#66",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Masking",
        "signature": "keras.layers.core.Masking.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'mask_value': self.mask_value}\n        base_config = super(Masking, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 66,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.Dropout.__init__#93",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Dropout",
        "signature": "keras.layers.core.Dropout.__init__(self, rate, noise_shape=None, seed=None, **kwargs)",
        "snippet": "    def __init__(self, rate, noise_shape=None, seed=None, **kwargs):\n        super(Dropout, self).__init__(**kwargs)\n        self.rate = min(1., max(0., rate))\n        self.noise_shape = noise_shape\n        self.seed = seed\n        self.supports_masking = True",
        "begin_line": 93,
        "end_line": 98,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010299721907508497,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.Dropout._get_noise_shape#100",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Dropout",
        "signature": "keras.layers.core.Dropout._get_noise_shape(self, inputs)",
        "snippet": "    def _get_noise_shape(self, inputs):\n        if self.noise_shape is None:\n            return self.noise_shape\n\n        symbolic_shape = K.shape(inputs)\n        noise_shape = [symbolic_shape[axis] if shape is None else shape\n                       for axis, shape in enumerate(self.noise_shape)]\n        return tuple(noise_shape)",
        "begin_line": 100,
        "end_line": 107,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.Dropout.call#109",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Dropout",
        "signature": "keras.layers.core.Dropout.call(self, inputs, training=None)",
        "snippet": "    def call(self, inputs, training=None):\n        if 0. < self.rate < 1.:\n            noise_shape = self._get_noise_shape(inputs)\n\n            def dropped_inputs():\n                return K.dropout(inputs, self.rate, noise_shape,\n                                 seed=self.seed)\n            return K.in_train_phase(dropped_inputs, inputs,\n                                    training=training)\n        return inputs",
        "begin_line": 109,
        "end_line": 118,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010630381630700542,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.Dropout.dropped_inputs#113",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Dropout",
        "signature": "keras.layers.core.Dropout.dropped_inputs()",
        "snippet": "            def dropped_inputs():\n                return K.dropout(inputs, self.rate, noise_shape,\n                                 seed=self.seed)",
        "begin_line": 113,
        "end_line": 115,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010630381630700542,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.Dropout.get_config#120",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Dropout",
        "signature": "keras.layers.core.Dropout.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'rate': self.rate,\n                  'noise_shape': self.noise_shape,\n                  'seed': self.seed}\n        base_config = super(Dropout, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 120,
        "end_line": 125,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001152604887044721,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.SpatialDropout1D.__init__#154",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.SpatialDropout1D",
        "signature": "keras.layers.core.SpatialDropout1D.__init__(self, rate, **kwargs)",
        "snippet": "    def __init__(self, rate, **kwargs):\n        super(SpatialDropout1D, self).__init__(rate, **kwargs)\n        self.input_spec = InputSpec(ndim=3)",
        "begin_line": 154,
        "end_line": 156,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.SpatialDropout1D._get_noise_shape#158",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.SpatialDropout1D",
        "signature": "keras.layers.core.SpatialDropout1D._get_noise_shape(self, inputs)",
        "snippet": "    def _get_noise_shape(self, inputs):\n        input_shape = K.shape(inputs)\n        noise_shape = (input_shape[0], 1, input_shape[2])\n        return noise_shape",
        "begin_line": 158,
        "end_line": 161,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.SpatialDropout2D.__init__#199",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.SpatialDropout2D",
        "signature": "keras.layers.core.SpatialDropout2D.__init__(self, rate, data_format=None, **kwargs)",
        "snippet": "    def __init__(self, rate, data_format=None, **kwargs):\n        super(SpatialDropout2D, self).__init__(rate, **kwargs)\n        if data_format is None:\n            data_format = K.image_data_format()\n        if data_format not in {'channels_last', 'channels_first'}:\n            raise ValueError('`data_format` must be in '\n                             '{`\"channels_last\"`, `\"channels_first\"`}')\n        self.data_format = data_format\n        self.input_spec = InputSpec(ndim=4)",
        "begin_line": 199,
        "end_line": 207,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.SpatialDropout2D._get_noise_shape#209",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.SpatialDropout2D",
        "signature": "keras.layers.core.SpatialDropout2D._get_noise_shape(self, inputs)",
        "snippet": "    def _get_noise_shape(self, inputs):\n        input_shape = K.shape(inputs)\n        if self.data_format == 'channels_first':\n            noise_shape = (input_shape[0], input_shape[1], 1, 1)\n        else:\n            noise_shape = (input_shape[0], 1, 1, input_shape[3])\n        return noise_shape",
        "begin_line": 209,
        "end_line": 215,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.SpatialDropout3D.__init__#252",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.SpatialDropout3D",
        "signature": "keras.layers.core.SpatialDropout3D.__init__(self, rate, data_format=None, **kwargs)",
        "snippet": "    def __init__(self, rate, data_format=None, **kwargs):\n        super(SpatialDropout3D, self).__init__(rate, **kwargs)\n        if data_format is None:\n            data_format = K.image_data_format()\n        if data_format not in {'channels_last', 'channels_first'}:\n            raise ValueError('`data_format` must be in '\n                             '{`\"channels_last\"`, `\"channels_first\"`}')\n        self.data_format = data_format\n        self.input_spec = InputSpec(ndim=5)",
        "begin_line": 252,
        "end_line": 260,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.SpatialDropout3D._get_noise_shape#262",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.SpatialDropout3D",
        "signature": "keras.layers.core.SpatialDropout3D._get_noise_shape(self, inputs)",
        "snippet": "    def _get_noise_shape(self, inputs):\n        input_shape = K.shape(inputs)\n        if self.data_format == 'channels_first':\n            noise_shape = (input_shape[0], input_shape[1], 1, 1, 1)\n        else:\n            noise_shape = (input_shape[0], 1, 1, 1, input_shape[4])\n        return noise_shape",
        "begin_line": 262,
        "end_line": 268,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.Activation.__init__#288",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Activation",
        "signature": "keras.layers.core.Activation.__init__(self, activation, **kwargs)",
        "snippet": "    def __init__(self, activation, **kwargs):\n        super(Activation, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.activation = activations.get(activation)",
        "begin_line": 288,
        "end_line": 291,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.490367277213628e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.Activation.call#293",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Activation",
        "signature": "keras.layers.core.Activation.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        return self.activation(inputs)",
        "begin_line": 293,
        "end_line": 294,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.490367277213628e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.Activation.get_config#296",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Activation",
        "signature": "keras.layers.core.Activation.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'activation': activations.serialize(self.activation)}\n        base_config = super(Activation, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 296,
        "end_line": 299,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011301989150090416,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.Reshape.__init__#337",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Reshape",
        "signature": "keras.layers.core.Reshape.__init__(self, target_shape, **kwargs)",
        "snippet": "    def __init__(self, target_shape, **kwargs):\n        super(Reshape, self).__init__(**kwargs)\n        self.target_shape = tuple(target_shape)",
        "begin_line": 337,
        "end_line": 339,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.Reshape._fix_unknown_dimension#341",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Reshape",
        "signature": "keras.layers.core.Reshape._fix_unknown_dimension(self, input_shape, output_shape)",
        "snippet": "    def _fix_unknown_dimension(self, input_shape, output_shape):\n        \"\"\"Finds and replaces a missing dimension in an output shape.\n\n        This is a near direct port of the internal Numpy function\n        `_fix_unknown_dimension` in `numpy/core/src/multiarray/shape.c`\n\n        # Arguments\n            input_shape: original shape of array being reshaped\n            output_shape: target shape of the array, with at most\n                a single -1 which indicates a dimension that should be\n                derived from the input shape.\n\n        # Returns\n            The new output shape with a `-1` replaced with its computed value.\n\n        # Raises\n            ValueError: if `input_shape` and `output_shape` do not match.\n        \"\"\"\n        output_shape = list(output_shape)\n        msg = 'total size of new array must be unchanged'\n\n        known, unknown = 1, None\n        for index, dim in enumerate(output_shape):\n            if dim < 0:\n                if unknown is None:\n                    unknown = index\n                else:\n                    raise ValueError('Can only specify one unknown dimension.')\n            else:\n                known *= dim\n\n        original = np.prod(input_shape, dtype=int)\n        if unknown is not None:\n            if known == 0 or original % known != 0:\n                raise ValueError(msg)\n            output_shape[unknown] = original // known\n        elif original != known:\n            raise ValueError(msg)\n\n        return tuple(output_shape)",
        "begin_line": 341,
        "end_line": 380,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.Reshape.compute_output_shape#382",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Reshape",
        "signature": "keras.layers.core.Reshape.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if None in input_shape[1:]:\n            # input shape (partially) unknown? replace -1's with None's\n            return ((input_shape[0],) +\n                    tuple(s if s != -1 else None for s in self.target_shape))\n        else:\n            # input shape known? then we can compute the output shape\n            return (input_shape[0],) + self._fix_unknown_dimension(\n                input_shape[1:], self.target_shape)",
        "begin_line": 382,
        "end_line": 390,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.Reshape.call#392",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Reshape",
        "signature": "keras.layers.core.Reshape.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        return K.reshape(inputs, (K.shape(inputs)[0],) + self.target_shape)",
        "begin_line": 392,
        "end_line": 393,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.Reshape.get_config#395",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Reshape",
        "signature": "keras.layers.core.Reshape.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'target_shape': self.target_shape}\n        base_config = super(Reshape, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 395,
        "end_line": 398,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.Permute.__init__#431",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Permute",
        "signature": "keras.layers.core.Permute.__init__(self, dims, **kwargs)",
        "snippet": "    def __init__(self, dims, **kwargs):\n        super(Permute, self).__init__(**kwargs)\n        self.dims = tuple(dims)\n        self.input_spec = InputSpec(ndim=len(self.dims) + 1)",
        "begin_line": 431,
        "end_line": 434,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.Permute.compute_output_shape#436",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Permute",
        "signature": "keras.layers.core.Permute.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        input_shape = list(input_shape)\n        output_shape = copy.copy(input_shape)\n        for i, dim in enumerate(self.dims):\n            target_dim = input_shape[dim]\n            output_shape[i + 1] = target_dim\n        return tuple(output_shape)",
        "begin_line": 436,
        "end_line": 442,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.Permute.call#444",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Permute",
        "signature": "keras.layers.core.Permute.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        return K.permute_dimensions(inputs, (0,) + self.dims)",
        "begin_line": 444,
        "end_line": 445,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.Permute.get_config#447",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Permute",
        "signature": "keras.layers.core.Permute.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'dims': self.dims}\n        base_config = super(Permute, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 447,
        "end_line": 450,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.Flatten.__init__#470",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Flatten",
        "signature": "keras.layers.core.Flatten.__init__(self, **kwargs)",
        "snippet": "    def __init__(self, **kwargs):\n        super(Flatten, self).__init__(**kwargs)\n        self.input_spec = InputSpec(min_ndim=3)",
        "begin_line": 470,
        "end_line": 472,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00012818869375721061,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.Flatten.compute_output_shape#474",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Flatten",
        "signature": "keras.layers.core.Flatten.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if not all(input_shape[1:]):\n            raise ValueError('The shape of the input to \"Flatten\" '\n                             'is not fully defined '\n                             '(got ' + str(input_shape[1:]) + '. '\n                             'Make sure to pass a complete \"input_shape\" '\n                             'or \"batch_input_shape\" argument to the first '\n                             'layer in your model.')\n        return (input_shape[0], np.prod(input_shape[1:]))",
        "begin_line": 474,
        "end_line": 482,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00012818869375721061,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.Flatten.call#484",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Flatten",
        "signature": "keras.layers.core.Flatten.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        return K.batch_flatten(inputs)",
        "begin_line": 484,
        "end_line": 485,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00012818869375721061,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.RepeatVector.__init__#513",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.RepeatVector",
        "signature": "keras.layers.core.RepeatVector.__init__(self, n, **kwargs)",
        "snippet": "    def __init__(self, n, **kwargs):\n        super(RepeatVector, self).__init__(**kwargs)\n        self.n = n\n        self.input_spec = InputSpec(ndim=2)",
        "begin_line": 513,
        "end_line": 516,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.RepeatVector.compute_output_shape#518",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.RepeatVector",
        "signature": "keras.layers.core.RepeatVector.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        return (input_shape[0], self.n, input_shape[1])",
        "begin_line": 518,
        "end_line": 519,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.RepeatVector.call#521",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.RepeatVector",
        "signature": "keras.layers.core.RepeatVector.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        return K.repeat(inputs, self.n)",
        "begin_line": 521,
        "end_line": 522,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.RepeatVector.get_config#524",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.RepeatVector",
        "signature": "keras.layers.core.RepeatVector.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'n': self.n}\n        base_config = super(RepeatVector, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 524,
        "end_line": 527,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.Lambda.__init__#589",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Lambda",
        "signature": "keras.layers.core.Lambda.__init__(self, function, output_shape=None, mask=None, arguments=None, **kwargs)",
        "snippet": "    def __init__(self, function, output_shape=None,\n                 mask=None, arguments=None, **kwargs):\n        super(Lambda, self).__init__(**kwargs)\n        self.function = function\n        self.arguments = arguments if arguments else {}\n        if mask is not None:\n            self.supports_masking = True\n        self.mask = mask\n\n        if output_shape is None:\n            self._output_shape = None\n        elif isinstance(output_shape, (tuple, list)):\n            self._output_shape = tuple(output_shape)\n        else:\n            if not callable(output_shape):\n                raise TypeError('In Lambda, `output_shape` '\n                                'must be a list, a tuple, or a function.')\n            self._output_shape = output_shape",
        "begin_line": 589,
        "end_line": 606,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.Lambda.compute_output_shape#608",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Lambda",
        "signature": "keras.layers.core.Lambda.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self._output_shape is None:\n            # With TensorFlow, we can infer the output shape directly:\n            if K.backend() == 'tensorflow':\n                if isinstance(input_shape, list):\n                    xs = [K.placeholder(shape=shape) for shape in input_shape]\n                    x = self.call(xs)\n                else:\n                    x = K.placeholder(shape=input_shape)\n                    x = self.call(x)\n                if isinstance(x, list):\n                    return [K.int_shape(x_elem) for x_elem in x]\n                else:\n                    return K.int_shape(x)\n            # Otherwise, we default to the input shape.\n            warnings.warn('`output_shape` argument not specified for layer {} '\n                          'and cannot be automatically inferred '\n                          'with the Theano backend. '\n                          'Defaulting to output shape `{}` '\n                          '(same as input shape). '\n                          'If the expected output shape is different, '\n                          'specify it via the `output_shape` argument.'\n                          .format(self.name, input_shape))\n            return input_shape\n        elif isinstance(self._output_shape, (tuple, list)):\n            if isinstance(input_shape, list):\n                num_samples = input_shape[0][0]\n            else:\n                num_samples = input_shape[0] if input_shape else None\n            return (num_samples,) + tuple(self._output_shape)\n        else:\n            shape = self._output_shape(input_shape)\n            if not isinstance(shape, (list, tuple)):\n                raise ValueError('`output_shape` function must return a tuple or a list of tuples.')\n            if isinstance(shape, list):\n                if isinstance(shape[0], int) or shape[0] is None:\n                    shape = tuple(shape)\n            return shape",
        "begin_line": 608,
        "end_line": 645,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.Lambda.call#647",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Lambda",
        "signature": "keras.layers.core.Lambda.call(self, inputs, mask=None)",
        "snippet": "    def call(self, inputs, mask=None):\n        arguments = self.arguments\n        if has_arg(self.function, 'mask'):\n            arguments['mask'] = mask\n        return self.function(inputs, **arguments)",
        "begin_line": 647,
        "end_line": 651,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001152604887044721,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.Lambda.compute_mask#653",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Lambda",
        "signature": "keras.layers.core.Lambda.compute_mask(self, inputs, mask=None)",
        "snippet": "    def compute_mask(self, inputs, mask=None):\n        if callable(self.mask):\n            return self.mask(inputs, mask)\n        return self.mask",
        "begin_line": 653,
        "end_line": 656,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.Lambda.get_config#658",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Lambda",
        "signature": "keras.layers.core.Lambda.get_config(self)",
        "snippet": "    def get_config(self):\n        if isinstance(self.function, python_types.LambdaType):\n            function = func_dump(self.function)\n            function_type = 'lambda'\n        else:\n            function = self.function.__name__\n            function_type = 'function'\n\n        if isinstance(self._output_shape, python_types.LambdaType):\n            output_shape = func_dump(self._output_shape)\n            output_shape_type = 'lambda'\n        elif callable(self._output_shape):\n            output_shape = self._output_shape.__name__\n            output_shape_type = 'function'\n        else:\n            output_shape = self._output_shape\n            output_shape_type = 'raw'\n\n        config = {'function': function,\n                  'function_type': function_type,\n                  'output_shape': output_shape,\n                  'output_shape_type': output_shape_type,\n                  'arguments': self.arguments}\n        base_config = super(Lambda, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 658,
        "end_line": 682,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.Lambda.from_config#685",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Lambda",
        "signature": "keras.layers.core.Lambda.from_config(cls, config, custom_objects=None)",
        "snippet": "    def from_config(cls, config, custom_objects=None):\n        config = config.copy()\n        globs = globals()\n        if custom_objects:\n            globs = dict(list(globs.items()) + list(custom_objects.items()))\n        function_type = config.pop('function_type')\n        if function_type == 'function':\n            # Simple lookup in custom objects\n            function = deserialize_keras_object(\n                config['function'],\n                custom_objects=custom_objects,\n                printable_module_name='function in Lambda layer')\n        elif function_type == 'lambda':\n            # Unsafe deserialization from bytecode\n            function = func_load(config['function'], globs=globs)\n        else:\n            raise TypeError('Unknown function type:', function_type)\n\n        output_shape_type = config.pop('output_shape_type')\n        if output_shape_type == 'function':\n            # Simple lookup in custom objects\n            output_shape = deserialize_keras_object(\n                config['output_shape'],\n                custom_objects=custom_objects,\n                printable_module_name='output_shape function in Lambda layer')\n        elif output_shape_type == 'lambda':\n            # Unsafe deserialization from bytecode\n            output_shape = func_load(config['output_shape'], globs=globs)\n        else:\n            output_shape = config['output_shape']\n\n        # If arguments were numpy array, they have been saved as\n        # list. We need to recover the ndarray\n        if 'arguments' in config:\n            for key in config['arguments']:\n                if isinstance(config['arguments'][key], dict):\n                    arg_dict = config['arguments'][key]\n                    if 'type' in arg_dict and arg_dict['type'] == 'ndarray':\n                        # Overwrite the argument with its numpy translation\n                        config['arguments'][key] = np.array(arg_dict['value'])\n\n        config['function'] = function\n        config['output_shape'] = output_shape\n        return cls(**config)",
        "begin_line": 685,
        "end_line": 728,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.Dense.__init__#795",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Dense",
        "signature": "keras.layers.core.Dense.__init__(self, units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)",
        "snippet": "    def __init__(self, units,\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n        super(Dense, self).__init__(**kwargs)\n        self.units = units\n        self.activation = activations.get(activation)\n        self.use_bias = use_bias\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n        self.input_spec = InputSpec(min_ndim=2)\n        self.supports_masking = True",
        "begin_line": 795,
        "end_line": 820,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007518796992481203,
            "pseudo_dstar_susp": 0.0007451564828614009,
            "pseudo_tarantula_susp": 0.0007558578987150416,
            "pseudo_op2_susp": 0.0007451564828614009,
            "pseudo_barinel_susp": 0.0007558578987150416
        }
    },
    {
        "name": "keras.layers.core.Dense.build#822",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Dense",
        "signature": "keras.layers.core.Dense.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        assert len(input_shape) >= 2\n        input_dim = input_shape[-1]\n\n        self.kernel = self.add_weight(shape=(input_dim, self.units),\n                                      initializer=self.kernel_initializer,\n                                      name='kernel',\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(self.units,),\n                                        initializer=self.bias_initializer,\n                                        name='bias',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        self.input_spec = InputSpec(min_ndim=2, axes={-1: input_dim})\n        self.built = True",
        "begin_line": 822,
        "end_line": 840,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007651109410864575,
            "pseudo_dstar_susp": 0.000758150113722517,
            "pseudo_tarantula_susp": 0.0007692307692307692,
            "pseudo_op2_susp": 0.000758150113722517,
            "pseudo_barinel_susp": 0.0007692307692307692
        }
    },
    {
        "name": "keras.layers.core.Dense.call#842",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Dense",
        "signature": "keras.layers.core.Dense.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        output = K.dot(inputs, self.kernel)\n        if self.use_bias:\n            output = K.bias_add(output, self.bias)\n        if self.activation is not None:\n            output = self.activation(output)\n        return output",
        "begin_line": 842,
        "end_line": 848,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007651109410864575,
            "pseudo_dstar_susp": 0.000758150113722517,
            "pseudo_tarantula_susp": 0.0007692307692307692,
            "pseudo_op2_susp": 0.000758150113722517,
            "pseudo_barinel_susp": 0.0007692307692307692
        }
    },
    {
        "name": "keras.layers.core.Dense.compute_output_shape#850",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Dense",
        "signature": "keras.layers.core.Dense.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        assert input_shape and len(input_shape) >= 2\n        assert input_shape[-1]\n        output_shape = list(input_shape)\n        output_shape[-1] = self.units\n        return tuple(output_shape)",
        "begin_line": 850,
        "end_line": 855,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0007651109410864575,
            "pseudo_dstar_susp": 0.000758150113722517,
            "pseudo_tarantula_susp": 0.0007692307692307692,
            "pseudo_op2_susp": 0.000758150113722517,
            "pseudo_barinel_susp": 0.0007692307692307692
        }
    },
    {
        "name": "keras.layers.core.Dense.get_config#857",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Dense",
        "signature": "keras.layers.core.Dense.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {\n            'units': self.units,\n            'activation': activations.serialize(self.activation),\n            'use_bias': self.use_bias,\n            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n            'bias_initializer': initializers.serialize(self.bias_initializer),\n            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n            'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n            'bias_constraint': constraints.serialize(self.bias_constraint)\n        }\n        base_config = super(Dense, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 857,
        "end_line": 871,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0009514747859181732,
            "pseudo_dstar_susp": 0.0009225092250922509,
            "pseudo_tarantula_susp": 0.0012690355329949238,
            "pseudo_op2_susp": 0.0009225092250922509,
            "pseudo_barinel_susp": 0.0012690355329949238
        }
    },
    {
        "name": "keras.layers.core.ActivityRegularization.__init__#890",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.ActivityRegularization",
        "signature": "keras.layers.core.ActivityRegularization.__init__(self, l1=0.0, l2=0.0, **kwargs)",
        "snippet": "    def __init__(self, l1=0., l2=0., **kwargs):\n        super(ActivityRegularization, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.l1 = l1\n        self.l2 = l2\n        self.activity_regularizer = regularizers.L1L2(l1=l1, l2=l2)",
        "begin_line": 890,
        "end_line": 895,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.core.ActivityRegularization.get_config#897",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.ActivityRegularization",
        "signature": "keras.layers.core.ActivityRegularization.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'l1': self.l1,\n                  'l2': self.l2}\n        base_config = super(ActivityRegularization, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 897,
        "end_line": 901,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.applications.imagenet_utils.preprocess_input#11",
        "src_path": "keras/applications/imagenet_utils.py",
        "class_name": "keras.applications.imagenet_utils",
        "signature": "keras.applications.imagenet_utils.preprocess_input(x, data_format=None, mode='caffe')",
        "snippet": "def preprocess_input(x, data_format=None, mode='caffe'):\n    \"\"\"Preprocesses a tensor encoding a batch of images.\n\n    # Arguments\n        x: input Numpy tensor, 4D.\n        data_format: data format of the image tensor.\n        mode: One of \"caffe\", \"tf\".\n            - caffe: will convert the images from RGB to BGR,\n                then will zero-center each color channel with\n                respect to the ImageNet dataset,\n                without scaling.\n            - tf: will scale pixels between -1 and 1,\n                sample-wise.\n\n    # Returns\n        Preprocessed tensor.\n    \"\"\"\n    if data_format is None:\n        data_format = K.image_data_format()\n    assert data_format in {'channels_last', 'channels_first'}\n\n    if mode == 'tf':\n        x /= 255.\n        x -= 0.5\n        x *= 2.\n        return x\n\n    if data_format == 'channels_first':\n        if x.ndim == 3:\n            # 'RGB'->'BGR'\n            x = x[::-1, ...]\n            # Zero-center by mean pixel\n            x[0, :, :] -= 103.939\n            x[1, :, :] -= 116.779\n            x[2, :, :] -= 123.68\n        else:\n            x = x[:, ::-1, ...]\n            x[:, 0, :, :] -= 103.939\n            x[:, 1, :, :] -= 116.779\n            x[:, 2, :, :] -= 123.68\n    else:\n        # 'RGB'->'BGR'\n        x = x[..., ::-1]\n        # Zero-center by mean pixel\n        x[..., 0] -= 103.939\n        x[..., 1] -= 116.779\n        x[..., 2] -= 123.68\n    return x",
        "begin_line": 11,
        "end_line": 58,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.applications.imagenet_utils.decode_predictions#61",
        "src_path": "keras/applications/imagenet_utils.py",
        "class_name": "keras.applications.imagenet_utils",
        "signature": "keras.applications.imagenet_utils.decode_predictions(preds, top=5)",
        "snippet": "def decode_predictions(preds, top=5):\n    \"\"\"Decodes the prediction of an ImageNet model.\n\n    # Arguments\n        preds: Numpy tensor encoding a batch of predictions.\n        top: integer, how many top-guesses to return.\n\n    # Returns\n        A list of lists of top class prediction tuples\n        `(class_name, class_description, score)`.\n        One list of tuples per sample in batch input.\n\n    # Raises\n        ValueError: in case of invalid shape of the `pred` array\n            (must be 2D).\n    \"\"\"\n    global CLASS_INDEX\n    if len(preds.shape) != 2 or preds.shape[1] != 1000:\n        raise ValueError('`decode_predictions` expects '\n                         'a batch of predictions '\n                         '(i.e. a 2D array of shape (samples, 1000)). '\n                         'Found array with shape: ' + str(preds.shape))\n    if CLASS_INDEX is None:\n        fpath = get_file('imagenet_class_index.json',\n                         CLASS_INDEX_PATH,\n                         cache_subdir='models',\n                         file_hash='c2c37ea517e94d9795004a39431a14cb')\n        CLASS_INDEX = json.load(open(fpath))\n    results = []\n    for pred in preds:\n        top_indices = pred.argsort()[-top:][::-1]\n        result = [tuple(CLASS_INDEX[str(i)]) + (pred[i],) for i in top_indices]\n        result.sort(key=lambda x: x[2], reverse=True)\n        results.append(result)\n    return results",
        "begin_line": 61,
        "end_line": 95,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.applications.imagenet_utils._obtain_input_shape#98",
        "src_path": "keras/applications/imagenet_utils.py",
        "class_name": "keras.applications.imagenet_utils",
        "signature": "keras.applications.imagenet_utils._obtain_input_shape(input_shape, default_size, min_size, data_format, require_flatten, weights=None)",
        "snippet": "def _obtain_input_shape(input_shape,\n                        default_size,\n                        min_size,\n                        data_format,\n                        require_flatten,\n                        weights=None):\n    \"\"\"Internal utility to compute/validate an ImageNet model's input shape.\n\n    # Arguments\n        input_shape: either None (will return the default network input shape),\n            or a user-provided shape to be validated.\n        default_size: default input width/height for the model.\n        min_size: minimum input width/height accepted by the model.\n        data_format: image data format to use.\n        require_flatten: whether the model is expected to\n            be linked to a classifier via a Flatten layer.\n        weights: one of `None` (random initialization)\n            or 'imagenet' (pre-training on ImageNet).\n            If weights='imagenet' input channels must be equal to 3.\n\n    # Returns\n        An integer shape tuple (may include None entries).\n\n    # Raises\n        ValueError: in case of invalid argument values.\n    \"\"\"\n    if weights != 'imagenet' and input_shape and len(input_shape) == 3:\n        if data_format == 'channels_first':\n            if input_shape[0] not in {1, 3}:\n                warnings.warn(\n                    'This model usually expects 1 or 3 input channels. '\n                    'However, it was passed an input_shape with ' +\n                    str(input_shape[0]) + ' input channels.')\n            default_shape = (input_shape[0], default_size, default_size)\n        else:\n            if input_shape[-1] not in {1, 3}:\n                warnings.warn(\n                    'This model usually expects 1 or 3 input channels. '\n                    'However, it was passed an input_shape with ' +\n                    str(input_shape[-1]) + ' input channels.')\n            default_shape = (default_size, default_size, input_shape[-1])\n    else:\n        if data_format == 'channels_first':\n            default_shape = (3, default_size, default_size)\n        else:\n            default_shape = (default_size, default_size, 3)\n    if weights == 'imagenet' and require_flatten:\n        if input_shape is not None:\n            if input_shape != default_shape:\n                raise ValueError('When setting`include_top=True` '\n                                 'and loading `imagenet` weights, '\n                                 '`input_shape` should be ' +\n                                 str(default_shape) + '.')\n        return default_shape\n    if input_shape:\n        if data_format == 'channels_first':\n            if input_shape is not None:\n                if len(input_shape) != 3:\n                    raise ValueError(\n                        '`input_shape` must be a tuple of three integers.')\n                if input_shape[0] != 3 and weights == 'imagenet':\n                    raise ValueError('The input must have 3 channels; got '\n                                     '`input_shape=' + str(input_shape) + '`')\n                if ((input_shape[1] is not None and input_shape[1] < min_size) or\n                   (input_shape[2] is not None and input_shape[2] < min_size)):\n                    raise ValueError('Input size must be at least ' +\n                                     str(min_size) + 'x' + str(min_size) + '; got '\n                                     '`input_shape=' + str(input_shape) + '`')\n        else:\n            if input_shape is not None:\n                if len(input_shape) != 3:\n                    raise ValueError(\n                        '`input_shape` must be a tuple of three integers.')\n                if input_shape[-1] != 3 and weights == 'imagenet':\n                    raise ValueError('The input must have 3 channels; got '\n                                     '`input_shape=' + str(input_shape) + '`')\n                if ((input_shape[0] is not None and input_shape[0] < min_size) or\n                   (input_shape[1] is not None and input_shape[1] < min_size)):\n                    raise ValueError('Input size must be at least ' +\n                                     str(min_size) + 'x' + str(min_size) + '; got '\n                                     '`input_shape=' + str(input_shape) + '`')\n    else:\n        if require_flatten:\n            input_shape = default_shape\n        else:\n            if data_format == 'channels_first':\n                input_shape = (3, None, None)\n            else:\n                input_shape = (None, None, 3)\n    if require_flatten:\n        if None in input_shape:\n            raise ValueError('If `include_top` is True, '\n                             'you should specify a static `input_shape`. '\n                             'Got `input_shape=' + str(input_shape) + '`')\n    return input_shape",
        "begin_line": 98,
        "end_line": 192,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.local.LocallyConnected1D.__init__#77",
        "src_path": "keras/layers/local.py",
        "class_name": "keras.layers.local.LocallyConnected1D",
        "signature": "keras.layers.local.LocallyConnected1D.__init__(self, filters, kernel_size, strides=1, padding='valid', data_format=None, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)",
        "snippet": "    def __init__(self, filters,\n                 kernel_size,\n                 strides=1,\n                 padding='valid',\n                 data_format=None,\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(LocallyConnected1D, self).__init__(**kwargs)\n        self.filters = filters\n        self.kernel_size = conv_utils.normalize_tuple(kernel_size, 1, 'kernel_size')\n        self.strides = conv_utils.normalize_tuple(strides, 1, 'strides')\n        self.padding = conv_utils.normalize_padding(padding)\n        if self.padding != 'valid':\n            raise ValueError('Invalid border mode for LocallyConnected1D '\n                             '(only \"valid\" is supported): ' + padding)\n        self.data_format = conv_utils.normalize_data_format(data_format)\n        self.activation = activations.get(activation)\n        self.use_bias = use_bias\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n        self.input_spec = InputSpec(ndim=3)",
        "begin_line": 77,
        "end_line": 110,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.local.LocallyConnected1D.build#112",
        "src_path": "keras/layers/local.py",
        "class_name": "keras.layers.local.LocallyConnected1D",
        "signature": "keras.layers.local.LocallyConnected1D.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        input_dim = input_shape[2]\n        if input_dim is None:\n            raise ValueError('Axis 2 of input should be fully-defined. '\n                             'Found shape:', input_shape)\n        output_length = conv_utils.conv_output_length(input_shape[1],\n                                                      self.kernel_size[0],\n                                                      self.padding,\n                                                      self.strides[0])\n        self.kernel_shape = (output_length,\n                             self.kernel_size[0] * input_dim,\n                             self.filters)\n        self.kernel = self.add_weight(\n            shape=self.kernel_shape,\n            initializer=self.kernel_initializer,\n            name='kernel',\n            regularizer=self.kernel_regularizer,\n            constraint=self.kernel_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(\n                shape=(output_length, self.filters),\n                initializer=self.bias_initializer,\n                name='bias',\n                regularizer=self.bias_regularizer,\n                constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        self.input_spec = InputSpec(ndim=3, axes={2: input_dim})\n        self.built = True",
        "begin_line": 112,
        "end_line": 140,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.local.LocallyConnected1D.compute_output_shape#142",
        "src_path": "keras/layers/local.py",
        "class_name": "keras.layers.local.LocallyConnected1D",
        "signature": "keras.layers.local.LocallyConnected1D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        length = conv_utils.conv_output_length(input_shape[1],\n                                               self.kernel_size[0],\n                                               self.padding,\n                                               self.strides[0])\n        return (input_shape[0], length, self.filters)",
        "begin_line": 142,
        "end_line": 147,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.local.LocallyConnected1D.call#149",
        "src_path": "keras/layers/local.py",
        "class_name": "keras.layers.local.LocallyConnected1D",
        "signature": "keras.layers.local.LocallyConnected1D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        output_length, _, filters = self.kernel_shape\n\n        output = K.local_conv1d(inputs, self.kernel, self.kernel_size, self.strides)\n        if self.use_bias:\n            output = K.bias_add(output, self.bias)\n        if self.activation is not None:\n            output = self.activation(output)\n        return output",
        "begin_line": 149,
        "end_line": 157,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.local.LocallyConnected1D.get_config#159",
        "src_path": "keras/layers/local.py",
        "class_name": "keras.layers.local.LocallyConnected1D",
        "signature": "keras.layers.local.LocallyConnected1D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {\n            'filters': self.filters,\n            'kernel_size': self.kernel_size,\n            'strides': self.strides,\n            'padding': self.padding,\n            'activation': activations.serialize(self.activation),\n            'use_bias': self.use_bias,\n            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n            'bias_initializer': initializers.serialize(self.bias_initializer),\n            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n            'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n            'bias_constraint': constraints.serialize(self.bias_constraint)\n        }\n        base_config = super(LocallyConnected1D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 159,
        "end_line": 176,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.local.LocallyConnected2D.__init__#261",
        "src_path": "keras/layers/local.py",
        "class_name": "keras.layers.local.LocallyConnected2D",
        "signature": "keras.layers.local.LocallyConnected2D.__init__(self, filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)",
        "snippet": "    def __init__(self, filters,\n                 kernel_size,\n                 strides=(1, 1),\n                 padding='valid',\n                 data_format=None,\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(LocallyConnected2D, self).__init__(**kwargs)\n        self.filters = filters\n        self.kernel_size = conv_utils.normalize_tuple(kernel_size, 2, 'kernel_size')\n        self.strides = conv_utils.normalize_tuple(strides, 2, 'strides')\n        self.padding = conv_utils.normalize_padding(padding)\n        if self.padding != 'valid':\n            raise ValueError('Invalid border mode for LocallyConnected2D '\n                             '(only \"valid\" is supported): ' + padding)\n        self.data_format = conv_utils.normalize_data_format(data_format)\n        self.activation = activations.get(activation)\n        self.use_bias = use_bias\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n        self.input_spec = InputSpec(ndim=4)",
        "begin_line": 261,
        "end_line": 294,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.local.LocallyConnected2D.build#296",
        "src_path": "keras/layers/local.py",
        "class_name": "keras.layers.local.LocallyConnected2D",
        "signature": "keras.layers.local.LocallyConnected2D.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        if self.data_format == 'channels_last':\n            input_row, input_col = input_shape[1:-1]\n            input_filter = input_shape[3]\n        else:\n            input_row, input_col = input_shape[2:]\n            input_filter = input_shape[1]\n        if input_row is None or input_col is None:\n            raise ValueError('The spatial dimensions of the inputs to '\n                             ' a LocallyConnected2D layer '\n                             'should be fully-defined, but layer received '\n                             'the inputs shape ' + str(input_shape))\n        output_row = conv_utils.conv_output_length(input_row, self.kernel_size[0],\n                                                   self.padding, self.strides[0])\n        output_col = conv_utils.conv_output_length(input_col, self.kernel_size[1],\n                                                   self.padding, self.strides[1])\n        self.output_row = output_row\n        self.output_col = output_col\n        self.kernel_shape = (output_row * output_col,\n                             self.kernel_size[0] * self.kernel_size[1] * input_filter,\n                             self.filters)\n        self.kernel = self.add_weight(shape=self.kernel_shape,\n                                      initializer=self.kernel_initializer,\n                                      name='kernel',\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(output_row, output_col, self.filters),\n                                        initializer=self.bias_initializer,\n                                        name='bias',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        if self.data_format == 'channels_first':\n            self.input_spec = InputSpec(ndim=4, axes={1: input_filter})\n        else:\n            self.input_spec = InputSpec(ndim=4, axes={-1: input_filter})\n        self.built = True",
        "begin_line": 296,
        "end_line": 334,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.local.LocallyConnected2D.compute_output_shape#336",
        "src_path": "keras/layers/local.py",
        "class_name": "keras.layers.local.LocallyConnected2D",
        "signature": "keras.layers.local.LocallyConnected2D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self.data_format == 'channels_first':\n            rows = input_shape[2]\n            cols = input_shape[3]\n        elif self.data_format == 'channels_last':\n            rows = input_shape[1]\n            cols = input_shape[2]\n\n        rows = conv_utils.conv_output_length(rows, self.kernel_size[0],\n                                             self.padding, self.strides[0])\n        cols = conv_utils.conv_output_length(cols, self.kernel_size[1],\n                                             self.padding, self.strides[1])\n\n        if self.data_format == 'channels_first':\n            return (input_shape[0], self.filters, rows, cols)\n        elif self.data_format == 'channels_last':\n            return (input_shape[0], rows, cols, self.filters)",
        "begin_line": 336,
        "end_line": 352,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.local.LocallyConnected2D.call#354",
        "src_path": "keras/layers/local.py",
        "class_name": "keras.layers.local.LocallyConnected2D",
        "signature": "keras.layers.local.LocallyConnected2D.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        _, _, filters = self.kernel_shape\n\n        output = K.local_conv2d(inputs,\n                                self.kernel,\n                                self.kernel_size,\n                                self.strides,\n                                (self.output_row, self.output_col),\n                                self.data_format)\n\n        if self.use_bias:\n            if self.data_format == 'channels_first' or self.data_format == 'channels_last':\n                output = K.bias_add(output, self.bias, data_format=self.data_format)\n\n        output = self.activation(output)\n        return output",
        "begin_line": 354,
        "end_line": 369,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.local.LocallyConnected2D.get_config#371",
        "src_path": "keras/layers/local.py",
        "class_name": "keras.layers.local.LocallyConnected2D",
        "signature": "keras.layers.local.LocallyConnected2D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {\n            'filters': self.filters,\n            'kernel_size': self.kernel_size,\n            'strides': self.strides,\n            'padding': self.padding,\n            'data_format': self.data_format,\n            'activation': activations.serialize(self.activation),\n            'use_bias': self.use_bias,\n            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n            'bias_initializer': initializers.serialize(self.bias_initializer),\n            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n            'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n            'bias_constraint': constraints.serialize(self.bias_constraint)\n        }\n        base_config = super(LocallyConnected2D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 371,
        "end_line": 389,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.embeddings.Embedding.__init__#70",
        "src_path": "keras/layers/embeddings.py",
        "class_name": "keras.layers.embeddings.Embedding",
        "signature": "keras.layers.embeddings.Embedding.__init__(self, input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None, **kwargs)",
        "snippet": "    def __init__(self, input_dim, output_dim,\n                 embeddings_initializer='uniform',\n                 embeddings_regularizer=None,\n                 activity_regularizer=None,\n                 embeddings_constraint=None,\n                 mask_zero=False,\n                 input_length=None,\n                 **kwargs):\n        if 'input_shape' not in kwargs:\n            if input_length:\n                kwargs['input_shape'] = (input_length,)\n            else:\n                kwargs['input_shape'] = (None,)\n        super(Embedding, self).__init__(**kwargs)\n\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.embeddings_initializer = initializers.get(embeddings_initializer)\n        self.embeddings_regularizer = regularizers.get(embeddings_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n        self.embeddings_constraint = constraints.get(embeddings_constraint)\n        self.mask_zero = mask_zero\n        self.input_length = input_length",
        "begin_line": 70,
        "end_line": 92,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.embeddings.Embedding.build#94",
        "src_path": "keras/layers/embeddings.py",
        "class_name": "keras.layers.embeddings.Embedding",
        "signature": "keras.layers.embeddings.Embedding.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        self.embeddings = self.add_weight(\n            shape=(self.input_dim, self.output_dim),\n            initializer=self.embeddings_initializer,\n            name='embeddings',\n            regularizer=self.embeddings_regularizer,\n            constraint=self.embeddings_constraint,\n            dtype=self.dtype)\n        self.built = True",
        "begin_line": 94,
        "end_line": 102,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010882576994232234,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.embeddings.Embedding.compute_mask#104",
        "src_path": "keras/layers/embeddings.py",
        "class_name": "keras.layers.embeddings.Embedding",
        "signature": "keras.layers.embeddings.Embedding.compute_mask(self, inputs, mask=None)",
        "snippet": "    def compute_mask(self, inputs, mask=None):\n        if not self.mask_zero:\n            return None\n        else:\n            return K.not_equal(inputs, 0)",
        "begin_line": 104,
        "end_line": 108,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.embeddings.Embedding.compute_output_shape#110",
        "src_path": "keras/layers/embeddings.py",
        "class_name": "keras.layers.embeddings.Embedding",
        "signature": "keras.layers.embeddings.Embedding.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self.input_length is None:\n            return input_shape + (self.output_dim,)\n        else:\n            # input_length can be tuple if input is 3D or higher\n            if isinstance(self.input_length, (list, tuple)):\n                in_lens = list(self.input_length)\n            else:\n                in_lens = [self.input_length]\n            if len(in_lens) != len(input_shape) - 1:\n                ValueError('\"input_length\" is %s, but received input has shape %s' %\n                           (str(self.input_length), str(input_shape)))\n            else:\n                for i, (s1, s2) in enumerate(zip(in_lens, input_shape[1:])):\n                    if s1 is not None and s2 is not None and s1 != s2:\n                        ValueError('\"input_length\" is %s, but received input has shape %s' %\n                                   (str(self.input_length), str(input_shape)))\n                    elif s1 is None:\n                        in_lens[i] = s2\n            return (input_shape[0],) + tuple(in_lens) + (self.output_dim,)",
        "begin_line": 110,
        "end_line": 129,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.embeddings.Embedding.call#131",
        "src_path": "keras/layers/embeddings.py",
        "class_name": "keras.layers.embeddings.Embedding",
        "signature": "keras.layers.embeddings.Embedding.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        if K.dtype(inputs) != 'int32':\n            inputs = K.cast(inputs, 'int32')\n        out = K.gather(self.embeddings, inputs)\n        return out",
        "begin_line": 131,
        "end_line": 135,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011059500110595002,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.layers.embeddings.Embedding.get_config#137",
        "src_path": "keras/layers/embeddings.py",
        "class_name": "keras.layers.embeddings.Embedding",
        "signature": "keras.layers.embeddings.Embedding.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'input_dim': self.input_dim,\n                  'output_dim': self.output_dim,\n                  'embeddings_initializer': initializers.serialize(self.embeddings_initializer),\n                  'embeddings_regularizer': regularizers.serialize(self.embeddings_regularizer),\n                  'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n                  'embeddings_constraint': constraints.serialize(self.embeddings_constraint),\n                  'mask_zero': self.mask_zero,\n                  'input_length': self.input_length}\n        base_config = super(Embedding, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 137,
        "end_line": 147,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.metrics.binary_accuracy#20",
        "src_path": "keras/metrics.py",
        "class_name": "keras.metrics",
        "signature": "keras.metrics.binary_accuracy(y_true, y_pred)",
        "snippet": "def binary_accuracy(y_true, y_pred):\n    return K.mean(K.equal(y_true, K.round(y_pred)), axis=-1)",
        "begin_line": 20,
        "end_line": 21,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011770244821092278,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.metrics.categorical_accuracy#24",
        "src_path": "keras/metrics.py",
        "class_name": "keras.metrics",
        "signature": "keras.metrics.categorical_accuracy(y_true, y_pred)",
        "snippet": "def categorical_accuracy(y_true, y_pred):\n    return K.cast(K.equal(K.argmax(y_true, axis=-1),\n                          K.argmax(y_pred, axis=-1)),\n                  K.floatx())",
        "begin_line": 24,
        "end_line": 27,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.853187506158242e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.metrics.sparse_categorical_accuracy#30",
        "src_path": "keras/metrics.py",
        "class_name": "keras.metrics",
        "signature": "keras.metrics.sparse_categorical_accuracy(y_true, y_pred)",
        "snippet": "def sparse_categorical_accuracy(y_true, y_pred):\n    return K.cast(K.equal(K.max(y_true, axis=-1),\n                          K.cast(K.argmax(y_pred, axis=-1), K.floatx())),\n                  K.floatx())",
        "begin_line": 30,
        "end_line": 33,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.metrics.top_k_categorical_accuracy#36",
        "src_path": "keras/metrics.py",
        "class_name": "keras.metrics",
        "signature": "keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=5)",
        "snippet": "def top_k_categorical_accuracy(y_true, y_pred, k=5):\n    return K.mean(K.in_top_k(y_pred, K.argmax(y_true, axis=-1), k), axis=-1)",
        "begin_line": 36,
        "end_line": 37,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.metrics.sparse_top_k_categorical_accuracy#40",
        "src_path": "keras/metrics.py",
        "class_name": "keras.metrics",
        "signature": "keras.metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=5)",
        "snippet": "def sparse_top_k_categorical_accuracy(y_true, y_pred, k=5):\n    return K.mean(K.in_top_k(y_pred, K.cast(K.max(y_true, axis=-1), 'int32'), k), axis=-1)",
        "begin_line": 40,
        "end_line": 41,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.metrics.serialize#53",
        "src_path": "keras/metrics.py",
        "class_name": "keras.metrics",
        "signature": "keras.metrics.serialize(metric)",
        "snippet": "def serialize(metric):\n    return metric.__name__",
        "begin_line": 53,
        "end_line": 54,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.metrics.deserialize#57",
        "src_path": "keras/metrics.py",
        "class_name": "keras.metrics",
        "signature": "keras.metrics.deserialize(name, custom_objects=None)",
        "snippet": "def deserialize(name, custom_objects=None):\n    return deserialize_keras_object(name,\n                                    module_objects=globals(),\n                                    custom_objects=custom_objects,\n                                    printable_module_name='metric function')",
        "begin_line": 57,
        "end_line": 61,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00011059500110595002,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.metrics.get#64",
        "src_path": "keras/metrics.py",
        "class_name": "keras.metrics",
        "signature": "keras.metrics.get(identifier)",
        "snippet": "def get(identifier):\n    if isinstance(identifier, six.string_types):\n        identifier = str(identifier)\n        return deserialize(identifier)\n    elif callable(identifier):\n        return identifier\n    else:\n        raise ValueError('Could not interpret '\n                         'metric function identifier:', identifier)",
        "begin_line": 64,
        "end_line": 72,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.CallbackList.__init__#34",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CallbackList",
        "signature": "keras.callbacks.CallbackList.__init__(self, callbacks=None, queue_length=10)",
        "snippet": "    def __init__(self, callbacks=None, queue_length=10):\n        callbacks = callbacks or []\n        self.callbacks = [c for c in callbacks]\n        self.queue_length = queue_length",
        "begin_line": 34,
        "end_line": 37,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.153318077803204e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.CallbackList.set_params#42",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CallbackList",
        "signature": "keras.callbacks.CallbackList.set_params(self, params)",
        "snippet": "    def set_params(self, params):\n        for callback in self.callbacks:\n            callback.set_params(params)",
        "begin_line": 42,
        "end_line": 44,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.153318077803204e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.CallbackList.set_model#46",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CallbackList",
        "signature": "keras.callbacks.CallbackList.set_model(self, model)",
        "snippet": "    def set_model(self, model):\n        for callback in self.callbacks:\n            callback.set_model(model)",
        "begin_line": 46,
        "end_line": 48,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.153318077803204e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.CallbackList.on_epoch_begin#50",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CallbackList",
        "signature": "keras.callbacks.CallbackList.on_epoch_begin(self, epoch, logs=None)",
        "snippet": "    def on_epoch_begin(self, epoch, logs=None):\n        \"\"\"Called at the start of an epoch.\n\n        # Arguments\n            epoch: integer, index of epoch.\n            logs: dictionary of logs.\n        \"\"\"\n        logs = logs or {}\n        for callback in self.callbacks:\n            callback.on_epoch_begin(epoch, logs)\n        self._delta_t_batch = 0.\n        self._delta_ts_batch_begin = deque([], maxlen=self.queue_length)\n        self._delta_ts_batch_end = deque([], maxlen=self.queue_length)",
        "begin_line": 50,
        "end_line": 62,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.153318077803204e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.CallbackList.on_epoch_end#64",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CallbackList",
        "signature": "keras.callbacks.CallbackList.on_epoch_end(self, epoch, logs=None)",
        "snippet": "    def on_epoch_end(self, epoch, logs=None):\n        \"\"\"Called at the end of an epoch.\n\n        # Arguments\n            epoch: integer, index of epoch.\n            logs: dictionary of logs.\n        \"\"\"\n        logs = logs or {}\n        for callback in self.callbacks:\n            callback.on_epoch_end(epoch, logs)",
        "begin_line": 64,
        "end_line": 73,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.190331770976932e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.CallbackList.on_batch_begin#75",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CallbackList",
        "signature": "keras.callbacks.CallbackList.on_batch_begin(self, batch, logs=None)",
        "snippet": "    def on_batch_begin(self, batch, logs=None):\n        \"\"\"Called right before processing a batch.\n\n        # Arguments\n            batch: integer, index of batch within the current epoch.\n            logs: dictionary of logs.\n        \"\"\"\n        logs = logs or {}\n        t_before_callbacks = time.time()\n        for callback in self.callbacks:\n            callback.on_batch_begin(batch, logs)\n        self._delta_ts_batch_begin.append(time.time() - t_before_callbacks)\n        delta_t_median = np.median(self._delta_ts_batch_begin)\n        if (self._delta_t_batch > 0. and\n           delta_t_median > 0.95 * self._delta_t_batch and\n           delta_t_median > 0.1):\n            warnings.warn('Method on_batch_begin() is slow compared '\n                          'to the batch update (%f). Check your callbacks.'\n                          % delta_t_median)\n        self._t_enter_batch = time.time()",
        "begin_line": 75,
        "end_line": 94,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.42151874882231e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.CallbackList.on_batch_end#96",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CallbackList",
        "signature": "keras.callbacks.CallbackList.on_batch_end(self, batch, logs=None)",
        "snippet": "    def on_batch_end(self, batch, logs=None):\n        \"\"\"Called at the end of a batch.\n\n        # Arguments\n            batch: integer, index of batch within the current epoch.\n            logs: dictionary of logs.\n        \"\"\"\n        logs = logs or {}\n        if not hasattr(self, '_t_enter_batch'):\n            self._t_enter_batch = time.time()\n        self._delta_t_batch = time.time() - self._t_enter_batch\n        t_before_callbacks = time.time()\n        for callback in self.callbacks:\n            callback.on_batch_end(batch, logs)\n        self._delta_ts_batch_end.append(time.time() - t_before_callbacks)\n        delta_t_median = np.median(self._delta_ts_batch_end)\n        if (self._delta_t_batch > 0. and\n           (delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1)):\n            warnings.warn('Method on_batch_end() is slow compared '\n                          'to the batch update (%f). Check your callbacks.'\n                          % delta_t_median)",
        "begin_line": 96,
        "end_line": 116,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.CallbackList.on_train_begin#118",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CallbackList",
        "signature": "keras.callbacks.CallbackList.on_train_begin(self, logs=None)",
        "snippet": "    def on_train_begin(self, logs=None):\n        \"\"\"Called at the beginning of training.\n\n        # Arguments\n            logs: dictionary of logs.\n        \"\"\"\n        logs = logs or {}\n        for callback in self.callbacks:\n            callback.on_train_begin(logs)",
        "begin_line": 118,
        "end_line": 126,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.153318077803204e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.CallbackList.on_train_end#128",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CallbackList",
        "signature": "keras.callbacks.CallbackList.on_train_end(self, logs=None)",
        "snippet": "    def on_train_end(self, logs=None):\n        \"\"\"Called at the end of training.\n\n        # Arguments\n            logs: dictionary of logs.\n        \"\"\"\n        logs = logs or {}\n        for callback in self.callbacks:\n            callback.on_train_end(logs)",
        "begin_line": 128,
        "end_line": 136,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.212344541685859e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.CallbackList.__iter__#138",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CallbackList",
        "signature": "keras.callbacks.CallbackList.__iter__(self)",
        "snippet": "    def __iter__(self):\n        return iter(self.callbacks)",
        "begin_line": 138,
        "end_line": 139,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.227646027498385e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.Callback.__init__#169",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.Callback",
        "signature": "keras.callbacks.Callback.__init__(self)",
        "snippet": "    def __init__(self):\n        self.validation_data = None",
        "begin_line": 169,
        "end_line": 170,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.130752373995617e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.Callback.set_params#172",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.Callback",
        "signature": "keras.callbacks.Callback.set_params(self, params)",
        "snippet": "    def set_params(self, params):\n        self.params = params",
        "begin_line": 172,
        "end_line": 173,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.153318077803204e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.Callback.set_model#175",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.Callback",
        "signature": "keras.callbacks.Callback.set_model(self, model)",
        "snippet": "    def set_model(self, model):\n        self.model = model",
        "begin_line": 175,
        "end_line": 176,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.153318077803204e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.Callback.on_epoch_begin#178",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.Callback",
        "signature": "keras.callbacks.Callback.on_epoch_begin(self, epoch, logs=None)",
        "snippet": "    def on_epoch_begin(self, epoch, logs=None):\n        pass",
        "begin_line": 178,
        "end_line": 179,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.153318077803204e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.Callback.on_epoch_end#181",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.Callback",
        "signature": "keras.callbacks.Callback.on_epoch_end(self, epoch, logs=None)",
        "snippet": "    def on_epoch_end(self, epoch, logs=None):\n        pass",
        "begin_line": 181,
        "end_line": 182,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.Callback.on_batch_begin#184",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.Callback",
        "signature": "keras.callbacks.Callback.on_batch_begin(self, batch, logs=None)",
        "snippet": "    def on_batch_begin(self, batch, logs=None):\n        pass",
        "begin_line": 184,
        "end_line": 185,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.190331770976932e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.Callback.on_batch_end#187",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.Callback",
        "signature": "keras.callbacks.Callback.on_batch_end(self, batch, logs=None)",
        "snippet": "    def on_batch_end(self, batch, logs=None):\n        pass",
        "begin_line": 187,
        "end_line": 188,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.190331770976932e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.Callback.on_train_begin#190",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.Callback",
        "signature": "keras.callbacks.Callback.on_train_begin(self, logs=None)",
        "snippet": "    def on_train_begin(self, logs=None):\n        pass",
        "begin_line": 190,
        "end_line": 191,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.153318077803204e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.Callback.on_train_end#193",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.Callback",
        "signature": "keras.callbacks.Callback.on_train_end(self, logs=None)",
        "snippet": "    def on_train_end(self, logs=None):\n        pass",
        "begin_line": 193,
        "end_line": 194,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.212344541685859e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.BaseLogger.on_epoch_begin#203",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.BaseLogger",
        "signature": "keras.callbacks.BaseLogger.on_epoch_begin(self, epoch, logs=None)",
        "snippet": "    def on_epoch_begin(self, epoch, logs=None):\n        self.seen = 0\n        self.totals = {}",
        "begin_line": 203,
        "end_line": 205,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.153318077803204e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.BaseLogger.on_batch_end#207",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.BaseLogger",
        "signature": "keras.callbacks.BaseLogger.on_batch_end(self, batch, logs=None)",
        "snippet": "    def on_batch_end(self, batch, logs=None):\n        logs = logs or {}\n        batch_size = logs.get('size', 0)\n        self.seen += batch_size\n\n        for k, v in logs.items():\n            if k in self.totals:\n                self.totals[k] += v * batch_size\n            else:\n                self.totals[k] = v * batch_size",
        "begin_line": 207,
        "end_line": 216,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.42151874882231e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.BaseLogger.on_epoch_end#218",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.BaseLogger",
        "signature": "keras.callbacks.BaseLogger.on_epoch_end(self, epoch, logs=None)",
        "snippet": "    def on_epoch_end(self, epoch, logs=None):\n        if logs is not None:\n            for k in self.params['metrics']:\n                if k in self.totals:\n                    # Make value available to next callbacks.\n                    logs[k] = self.totals[k] / self.seen",
        "begin_line": 218,
        "end_line": 223,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.190331770976932e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.TerminateOnNaN.__init__#230",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.TerminateOnNaN",
        "signature": "keras.callbacks.TerminateOnNaN.__init__(self)",
        "snippet": "    def __init__(self):\n        super(TerminateOnNaN, self).__init__()",
        "begin_line": 230,
        "end_line": 231,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.TerminateOnNaN.on_batch_end#233",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.TerminateOnNaN",
        "signature": "keras.callbacks.TerminateOnNaN.on_batch_end(self, batch, logs=None)",
        "snippet": "    def on_batch_end(self, batch, logs=None):\n        logs = logs or {}\n        loss = logs.get('loss')\n        if loss is not None:\n            if np.isnan(loss) or np.isinf(loss):\n                print('Batch %d: Invalid loss, terminating training' % (batch))\n                self.model.stop_training = True",
        "begin_line": 233,
        "end_line": 239,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.ProgbarLogger.__init__#254",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.ProgbarLogger",
        "signature": "keras.callbacks.ProgbarLogger.__init__(self, count_mode='samples')",
        "snippet": "    def __init__(self, count_mode='samples'):\n        super(ProgbarLogger, self).__init__()\n        if count_mode == 'samples':\n            self.use_steps = False\n        elif count_mode == 'steps':\n            self.use_steps = True\n        else:\n            raise ValueError('Unknown `count_mode`: ' + str(count_mode))",
        "begin_line": 254,
        "end_line": 261,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010793308148947653,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.ProgbarLogger.on_train_begin#263",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.ProgbarLogger",
        "signature": "keras.callbacks.ProgbarLogger.on_train_begin(self, logs=None)",
        "snippet": "    def on_train_begin(self, logs=None):\n        self.verbose = self.params['verbose']\n        self.epochs = self.params['epochs']",
        "begin_line": 263,
        "end_line": 265,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.577626664112633e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.ProgbarLogger.on_epoch_begin#267",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.ProgbarLogger",
        "signature": "keras.callbacks.ProgbarLogger.on_epoch_begin(self, epoch, logs=None)",
        "snippet": "    def on_epoch_begin(self, epoch, logs=None):\n        if self.verbose:\n            print('Epoch %d/%d' % (epoch + 1, self.epochs))\n            if self.use_steps:\n                target = self.params['steps']\n            else:\n                target = self.params['samples']\n            self.target = target\n            self.progbar = Progbar(target=self.target,\n                                   verbose=self.verbose)\n        self.seen = 0",
        "begin_line": 267,
        "end_line": 277,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010793308148947653,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.ProgbarLogger.on_batch_begin#279",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.ProgbarLogger",
        "signature": "keras.callbacks.ProgbarLogger.on_batch_begin(self, batch, logs=None)",
        "snippet": "    def on_batch_begin(self, batch, logs=None):\n        if self.seen < self.target:\n            self.log_values = []",
        "begin_line": 279,
        "end_line": 281,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.616309260505818e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.ProgbarLogger.on_batch_end#283",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.ProgbarLogger",
        "signature": "keras.callbacks.ProgbarLogger.on_batch_end(self, batch, logs=None)",
        "snippet": "    def on_batch_end(self, batch, logs=None):\n        logs = logs or {}\n        batch_size = logs.get('size', 0)\n        if self.use_steps:\n            self.seen += 1\n        else:\n            self.seen += batch_size\n\n        for k in self.params['metrics']:\n            if k in logs:\n                self.log_values.append((k, logs[k]))\n\n        # Skip progbar update for the last batch;\n        # will be handled by on_epoch_end.\n        if self.verbose and self.seen < self.target:\n            self.progbar.update(self.seen, self.log_values)",
        "begin_line": 283,
        "end_line": 298,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00010882576994232234,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.ProgbarLogger.on_epoch_end#300",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.ProgbarLogger",
        "signature": "keras.callbacks.ProgbarLogger.on_epoch_end(self, epoch, logs=None)",
        "snippet": "    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        for k in self.params['metrics']:\n            if k in logs:\n                self.log_values.append((k, logs[k]))\n        if self.verbose:\n            self.progbar.update(self.seen, self.log_values, force=True)",
        "begin_line": 300,
        "end_line": 306,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.645061728395061e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.History.on_train_begin#317",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.History",
        "signature": "keras.callbacks.History.on_train_begin(self, logs=None)",
        "snippet": "    def on_train_begin(self, logs=None):\n        self.epoch = []\n        self.history = {}",
        "begin_line": 317,
        "end_line": 319,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.153318077803204e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.History.on_epoch_end#321",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.History",
        "signature": "keras.callbacks.History.on_epoch_end(self, epoch, logs=None)",
        "snippet": "    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        self.epoch.append(epoch)\n        for k, v in logs.items():\n            self.history.setdefault(k, []).append(v)",
        "begin_line": 321,
        "end_line": 325,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 9.212344541685859e-05,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.ModelCheckpoint.__init__#360",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.ModelCheckpoint",
        "signature": "keras.callbacks.ModelCheckpoint.__init__(self, filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)",
        "snippet": "    def __init__(self, filepath, monitor='val_loss', verbose=0,\n                 save_best_only=False, save_weights_only=False,\n                 mode='auto', period=1):\n        super(ModelCheckpoint, self).__init__()\n        self.monitor = monitor\n        self.verbose = verbose\n        self.filepath = filepath\n        self.save_best_only = save_best_only\n        self.save_weights_only = save_weights_only\n        self.period = period\n        self.epochs_since_last_save = 0\n\n        if mode not in ['auto', 'min', 'max']:\n            warnings.warn('ModelCheckpoint mode %s is unknown, '\n                          'fallback to auto mode.' % (mode),\n                          RuntimeWarning)\n            mode = 'auto'\n\n        if mode == 'min':\n            self.monitor_op = np.less\n            self.best = np.Inf\n        elif mode == 'max':\n            self.monitor_op = np.greater\n            self.best = -np.Inf\n        else:\n            if 'acc' in self.monitor or self.monitor.startswith('fmeasure'):\n                self.monitor_op = np.greater\n                self.best = -np.Inf\n            else:\n                self.monitor_op = np.less\n                self.best = np.Inf",
        "begin_line": 360,
        "end_line": 390,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.ModelCheckpoint.on_epoch_end#392",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.ModelCheckpoint",
        "signature": "keras.callbacks.ModelCheckpoint.on_epoch_end(self, epoch, logs=None)",
        "snippet": "    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        self.epochs_since_last_save += 1\n        if self.epochs_since_last_save >= self.period:\n            self.epochs_since_last_save = 0\n            filepath = self.filepath.format(epoch=epoch + 1, **logs)\n            if self.save_best_only:\n                current = logs.get(self.monitor)\n                if current is None:\n                    warnings.warn('Can save best model only with %s available, '\n                                  'skipping.' % (self.monitor), RuntimeWarning)\n                else:\n                    if self.monitor_op(current, self.best):\n                        if self.verbose > 0:\n                            print('Epoch %05d: %s improved from %0.5f to %0.5f,'\n                                  ' saving model to %s'\n                                  % (epoch + 1, self.monitor, self.best,\n                                     current, filepath))\n                        self.best = current\n                        if self.save_weights_only:\n                            self.model.save_weights(filepath, overwrite=True)\n                        else:\n                            self.model.save(filepath, overwrite=True)\n                    else:\n                        if self.verbose > 0:\n                            print('Epoch %05d: %s did not improve' %\n                                  (epoch + 1, self.monitor))\n            else:\n                if self.verbose > 0:\n                    print('Epoch %05d: saving model to %s' % (epoch + 1, filepath))\n                if self.save_weights_only:\n                    self.model.save_weights(filepath, overwrite=True)\n                else:\n                    self.model.save(filepath, overwrite=True)",
        "begin_line": 392,
        "end_line": 425,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.EarlyStopping.__init__#449",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.EarlyStopping",
        "signature": "keras.callbacks.EarlyStopping.__init__(self, monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto')",
        "snippet": "    def __init__(self, monitor='val_loss',\n                 min_delta=0, patience=0, verbose=0, mode='auto'):\n        super(EarlyStopping, self).__init__()\n\n        self.monitor = monitor\n        self.patience = patience\n        self.verbose = verbose\n        self.min_delta = min_delta\n        self.wait = 0\n        self.stopped_epoch = 0\n\n        if mode not in ['auto', 'min', 'max']:\n            warnings.warn('EarlyStopping mode %s is unknown, '\n                          'fallback to auto mode.' % mode,\n                          RuntimeWarning)\n            mode = 'auto'\n\n        if mode == 'min':\n            self.monitor_op = np.less\n        elif mode == 'max':\n            self.monitor_op = np.greater\n        else:\n            if 'acc' in self.monitor:\n                self.monitor_op = np.greater\n            else:\n                self.monitor_op = np.less\n\n        if self.monitor_op == np.greater:\n            self.min_delta *= 1\n        else:\n            self.min_delta *= -1",
        "begin_line": 449,
        "end_line": 479,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.EarlyStopping.on_train_begin#481",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.EarlyStopping",
        "signature": "keras.callbacks.EarlyStopping.on_train_begin(self, logs=None)",
        "snippet": "    def on_train_begin(self, logs=None):\n        # Allow instances to be re-used\n        self.wait = 0\n        self.stopped_epoch = 0\n        self.best = np.Inf if self.monitor_op == np.less else -np.Inf",
        "begin_line": 481,
        "end_line": 485,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.EarlyStopping.on_epoch_end#487",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.EarlyStopping",
        "signature": "keras.callbacks.EarlyStopping.on_epoch_end(self, epoch, logs=None)",
        "snippet": "    def on_epoch_end(self, epoch, logs=None):\n        current = logs.get(self.monitor)\n        if current is None:\n            warnings.warn(\n                'Early stopping conditioned on metric `%s` '\n                'which is not available. Available metrics are: %s' %\n                (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n            )\n            return\n        if self.monitor_op(current - self.min_delta, self.best):\n            self.best = current\n            self.wait = 0\n        else:\n            self.wait += 1\n            if self.wait >= self.patience:\n                self.stopped_epoch = epoch\n                self.model.stop_training = True",
        "begin_line": 487,
        "end_line": 503,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.EarlyStopping.on_train_end#505",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.EarlyStopping",
        "signature": "keras.callbacks.EarlyStopping.on_train_end(self, logs=None)",
        "snippet": "    def on_train_end(self, logs=None):\n        if self.stopped_epoch > 0 and self.verbose > 0:\n            print('Epoch %05d: early stopping' % (self.stopped_epoch + 1))",
        "begin_line": 505,
        "end_line": 507,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.LearningRateScheduler.__init__#564",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.LearningRateScheduler",
        "signature": "keras.callbacks.LearningRateScheduler.__init__(self, schedule)",
        "snippet": "    def __init__(self, schedule):\n        super(LearningRateScheduler, self).__init__()\n        self.schedule = schedule",
        "begin_line": 564,
        "end_line": 566,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.LearningRateScheduler.on_epoch_begin#568",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.LearningRateScheduler",
        "signature": "keras.callbacks.LearningRateScheduler.on_epoch_begin(self, epoch, logs=None)",
        "snippet": "    def on_epoch_begin(self, epoch, logs=None):\n        if not hasattr(self.model.optimizer, 'lr'):\n            raise ValueError('Optimizer must have a \"lr\" attribute.')\n        lr = self.schedule(epoch)\n        if not isinstance(lr, (float, np.float32, np.float64)):\n            raise ValueError('The output of the \"schedule\" function '\n                             'should be float.')\n        K.set_value(self.model.optimizer.lr, lr)",
        "begin_line": 568,
        "end_line": 575,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.TensorBoard.__init__#622",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.TensorBoard",
        "signature": "keras.callbacks.TensorBoard.__init__(self, log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)",
        "snippet": "    def __init__(self, log_dir='./logs',\n                 histogram_freq=0,\n                 batch_size=32,\n                 write_graph=True,\n                 write_grads=False,\n                 write_images=False,\n                 embeddings_freq=0,\n                 embeddings_layer_names=None,\n                 embeddings_metadata=None):\n        super(TensorBoard, self).__init__()\n        if K.backend() != 'tensorflow':\n            raise RuntimeError('TensorBoard callback only works '\n                               'with the TensorFlow backend.')\n        global tf, projector\n        import tensorflow as tf\n        from tensorflow.contrib.tensorboard.plugins import projector\n        self.log_dir = log_dir\n        self.histogram_freq = histogram_freq\n        self.merged = None\n        self.write_graph = write_graph\n        self.write_grads = write_grads\n        self.write_images = write_images\n        self.embeddings_freq = embeddings_freq\n        self.embeddings_layer_names = embeddings_layer_names\n        self.embeddings_metadata = embeddings_metadata or {}\n        self.batch_size = batch_size",
        "begin_line": 622,
        "end_line": 647,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00012818869375721061,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.TensorBoard.set_model#649",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.TensorBoard",
        "signature": "keras.callbacks.TensorBoard.set_model(self, model)",
        "snippet": "    def set_model(self, model):\n        self.model = model\n        self.sess = K.get_session()\n        if self.histogram_freq and self.merged is None:\n            for layer in self.model.layers:\n\n                for weight in layer.weights:\n                    mapped_weight_name = weight.name.replace(':', '_')\n                    tf.summary.histogram(mapped_weight_name, weight)\n                    if self.write_grads:\n                        grads = model.optimizer.get_gradients(model.total_loss,\n                                                              weight)\n\n                        def is_indexed_slices(grad):\n                            return type(grad).__name__ == 'IndexedSlices'\n                        grads = [\n                            grad.values if is_indexed_slices(grad) else grad\n                            for grad in grads]\n                        tf.summary.histogram('{}_grad'.format(mapped_weight_name), grads)\n                    if self.write_images:\n                        w_img = tf.squeeze(weight)\n                        shape = K.int_shape(w_img)\n                        if len(shape) == 2:  # dense layer kernel case\n                            if shape[0] > shape[1]:\n                                w_img = tf.transpose(w_img)\n                                shape = K.int_shape(w_img)\n                            w_img = tf.reshape(w_img, [1,\n                                                       shape[0],\n                                                       shape[1],\n                                                       1])\n                        elif len(shape) == 3:  # convnet case\n                            if K.image_data_format() == 'channels_last':\n                                # switch to channels_first to display\n                                # every kernel as a separate image\n                                w_img = tf.transpose(w_img, perm=[2, 0, 1])\n                                shape = K.int_shape(w_img)\n                            w_img = tf.reshape(w_img, [shape[0],\n                                                       shape[1],\n                                                       shape[2],\n                                                       1])\n                        elif len(shape) == 1:  # bias case\n                            w_img = tf.reshape(w_img, [1,\n                                                       shape[0],\n                                                       1,\n                                                       1])\n                        else:\n                            # not possible to handle 3D convnets etc.\n                            continue\n\n                        shape = K.int_shape(w_img)\n                        assert len(shape) == 4 and shape[-1] in [1, 3, 4]\n                        tf.summary.image(mapped_weight_name, w_img)\n\n                if hasattr(layer, 'output'):\n                    tf.summary.histogram('{}_out'.format(layer.name),\n                                         layer.output)\n        self.merged = tf.summary.merge_all()\n\n        if self.write_graph:\n            self.writer = tf.summary.FileWriter(self.log_dir,\n                                                self.sess.graph)\n        else:\n            self.writer = tf.summary.FileWriter(self.log_dir)\n\n        if self.embeddings_freq:\n            embeddings_layer_names = self.embeddings_layer_names\n\n            if not embeddings_layer_names:\n                embeddings_layer_names = [layer.name for layer in self.model.layers\n                                          if type(layer).__name__ == 'Embedding']\n\n            embeddings = {layer.name: layer.weights[0]\n                          for layer in self.model.layers\n                          if layer.name in embeddings_layer_names}\n\n            self.saver = tf.train.Saver(list(embeddings.values()))\n\n            embeddings_metadata = {}\n\n            if not isinstance(self.embeddings_metadata, str):\n                embeddings_metadata = self.embeddings_metadata\n            else:\n                embeddings_metadata = {layer_name: self.embeddings_metadata\n                                       for layer_name in embeddings.keys()}\n\n            config = projector.ProjectorConfig()\n            self.embeddings_ckpt_path = os.path.join(self.log_dir,\n                                                     'keras_embedding.ckpt')\n\n            for layer_name, tensor in embeddings.items():\n                embedding = config.embeddings.add()\n                embedding.tensor_name = tensor.name\n\n                if layer_name in embeddings_metadata:\n                    embedding.metadata_path = embeddings_metadata[layer_name]\n\n            projector.visualize_embeddings(self.writer, config)",
        "begin_line": 649,
        "end_line": 745,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.000160926939169617,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.TensorBoard.is_indexed_slices#662",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.TensorBoard",
        "signature": "keras.callbacks.TensorBoard.is_indexed_slices(grad)",
        "snippet": "                        def is_indexed_slices(grad):\n                            return type(grad).__name__ == 'IndexedSlices'",
        "begin_line": 662,
        "end_line": 663,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.TensorBoard.on_epoch_end#747",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.TensorBoard",
        "signature": "keras.callbacks.TensorBoard.on_epoch_end(self, epoch, logs=None)",
        "snippet": "    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n\n        if not self.validation_data and self.histogram_freq:\n            raise ValueError('If printing histograms, validation_data must be '\n                             'provided, and cannot be a generator.')\n        if self.validation_data and self.histogram_freq:\n            if epoch % self.histogram_freq == 0:\n\n                val_data = self.validation_data\n                tensors = (self.model.inputs +\n                           self.model.targets +\n                           self.model.sample_weights)\n\n                if self.model.uses_learning_phase:\n                    tensors += [K.learning_phase()]\n\n                assert len(val_data) == len(tensors)\n                val_size = val_data[0].shape[0]\n                i = 0\n                while i < val_size:\n                    step = min(self.batch_size, val_size - i)\n                    if self.model.uses_learning_phase:\n                        # do not slice the learning phase\n                        batch_val = [x[i:i + step] for x in val_data[:-1]]\n                        batch_val.append(val_data[-1])\n                    else:\n                        batch_val = [x[i:i + step] for x in val_data]\n                    assert len(batch_val) == len(tensors)\n                    feed_dict = dict(zip(tensors, batch_val))\n                    result = self.sess.run([self.merged], feed_dict=feed_dict)\n                    summary_str = result[0]\n                    self.writer.add_summary(summary_str, epoch)\n                    i += self.batch_size\n\n        if self.embeddings_freq and self.embeddings_ckpt_path:\n            if epoch % self.embeddings_freq == 0:\n                self.saver.save(self.sess,\n                                self.embeddings_ckpt_path,\n                                epoch)\n\n        for name, value in logs.items():\n            if name in ['batch', 'size']:\n                continue\n            summary = tf.Summary()\n            summary_value = summary.value.add()\n            summary_value.simple_value = value.item()\n            summary_value.tag = name\n            self.writer.add_summary(summary, epoch)\n        self.writer.flush()",
        "begin_line": 747,
        "end_line": 796,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.TensorBoard.on_train_end#798",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.TensorBoard",
        "signature": "keras.callbacks.TensorBoard.on_train_end(self, _)",
        "snippet": "    def on_train_end(self, _):\n        self.writer.close()",
        "begin_line": 798,
        "end_line": 799,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00014039028499227853,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.ReduceLROnPlateau.__init__#838",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.ReduceLROnPlateau",
        "signature": "keras.callbacks.ReduceLROnPlateau.__init__(self, monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)",
        "snippet": "    def __init__(self, monitor='val_loss', factor=0.1, patience=10,\n                 verbose=0, mode='auto', epsilon=1e-4, cooldown=0, min_lr=0):\n        super(ReduceLROnPlateau, self).__init__()\n\n        self.monitor = monitor\n        if factor >= 1.0:\n            raise ValueError('ReduceLROnPlateau '\n                             'does not support a factor >= 1.0.')\n        self.factor = factor\n        self.min_lr = min_lr\n        self.epsilon = epsilon\n        self.patience = patience\n        self.verbose = verbose\n        self.cooldown = cooldown\n        self.cooldown_counter = 0  # Cooldown counter.\n        self.wait = 0\n        self.best = 0\n        self.mode = mode\n        self.monitor_op = None\n        self._reset()",
        "begin_line": 838,
        "end_line": 857,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.ReduceLROnPlateau._reset#859",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.ReduceLROnPlateau",
        "signature": "keras.callbacks.ReduceLROnPlateau._reset(self)",
        "snippet": "    def _reset(self):\n        \"\"\"Resets wait counter and cooldown counter.\n        \"\"\"\n        if self.mode not in ['auto', 'min', 'max']:\n            warnings.warn('Learning Rate Plateau Reducing mode %s is unknown, '\n                          'fallback to auto mode.' % (self.mode),\n                          RuntimeWarning)\n            self.mode = 'auto'\n        if (self.mode == 'min' or\n           (self.mode == 'auto' and 'acc' not in self.monitor)):\n            self.monitor_op = lambda a, b: np.less(a, b - self.epsilon)\n            self.best = np.Inf\n        else:\n            self.monitor_op = lambda a, b: np.greater(a, b + self.epsilon)\n            self.best = -np.Inf\n        self.cooldown_counter = 0\n        self.wait = 0\n        self.lr_epsilon = self.min_lr * 1e-4",
        "begin_line": 859,
        "end_line": 876,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.ReduceLROnPlateau.on_train_begin#878",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.ReduceLROnPlateau",
        "signature": "keras.callbacks.ReduceLROnPlateau.on_train_begin(self, logs=None)",
        "snippet": "    def on_train_begin(self, logs=None):\n        self._reset()",
        "begin_line": 878,
        "end_line": 879,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.ReduceLROnPlateau.on_epoch_end#881",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.ReduceLROnPlateau",
        "signature": "keras.callbacks.ReduceLROnPlateau.on_epoch_end(self, epoch, logs=None)",
        "snippet": "    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        logs['lr'] = K.get_value(self.model.optimizer.lr)\n        current = logs.get(self.monitor)\n        if current is None:\n            warnings.warn(\n                'Reduce LR on plateau conditioned on metric `%s` '\n                'which is not available. Available metrics are: %s' %\n                (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n            )\n\n        else:\n            if self.in_cooldown():\n                self.cooldown_counter -= 1\n                self.wait = 0\n\n            if self.monitor_op(current, self.best):\n                self.best = current\n                self.wait = 0\n            elif not self.in_cooldown():\n                if self.wait >= self.patience:\n                    old_lr = float(K.get_value(self.model.optimizer.lr))\n                    if old_lr > self.min_lr + self.lr_epsilon:\n                        new_lr = old_lr * self.factor\n                        new_lr = max(new_lr, self.min_lr)\n                        K.set_value(self.model.optimizer.lr, new_lr)\n                        if self.verbose > 0:\n                            print('\\nEpoch %05d: reducing learning rate to %s.' % (epoch + 1, new_lr))\n                        self.cooldown_counter = self.cooldown\n                        self.wait = 0\n                self.wait += 1",
        "begin_line": 881,
        "end_line": 911,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.ReduceLROnPlateau.in_cooldown#913",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.ReduceLROnPlateau",
        "signature": "keras.callbacks.ReduceLROnPlateau.in_cooldown(self)",
        "snippet": "    def in_cooldown(self):\n        return self.cooldown_counter > 0",
        "begin_line": 913,
        "end_line": 914,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.CSVLogger.__init__#936",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CSVLogger",
        "signature": "keras.callbacks.CSVLogger.__init__(self, filename, separator=',', append=False)",
        "snippet": "    def __init__(self, filename, separator=',', append=False):\n        self.sep = separator\n        self.filename = filename\n        self.append = append\n        self.writer = None\n        self.keys = None\n        self.append_header = True\n        self.file_flags = 'b' if six.PY2 and os.name == 'nt' else ''\n        super(CSVLogger, self).__init__()",
        "begin_line": 936,
        "end_line": 944,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.CSVLogger.on_train_begin#946",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CSVLogger",
        "signature": "keras.callbacks.CSVLogger.on_train_begin(self, logs=None)",
        "snippet": "    def on_train_begin(self, logs=None):\n        if self.append:\n            if os.path.exists(self.filename):\n                with open(self.filename, 'r' + self.file_flags) as f:\n                    self.append_header = not bool(len(f.readline()))\n            self.csv_file = open(self.filename, 'a' + self.file_flags)\n        else:\n            self.csv_file = open(self.filename, 'w' + self.file_flags)",
        "begin_line": 946,
        "end_line": 953,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.CSVLogger.on_epoch_end#955",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CSVLogger",
        "signature": "keras.callbacks.CSVLogger.on_epoch_end(self, epoch, logs=None)",
        "snippet": "    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n\n        def handle_value(k):\n            is_zero_dim_ndarray = isinstance(k, np.ndarray) and k.ndim == 0\n            if isinstance(k, six.string_types):\n                return k\n            elif isinstance(k, Iterable) and not is_zero_dim_ndarray:\n                return '\"[%s]\"' % (', '.join(map(str, k)))\n            else:\n                return k\n\n        if self.model.stop_training:\n            # We set NA so that csv parsers do not fail for this last epoch.\n            logs = dict([(k, logs[k]) if k in logs else (k, 'NA') for k in self.keys])\n\n        if not self.writer:\n            self.keys = sorted(logs.keys())\n\n            class CustomDialect(csv.excel):\n                delimiter = self.sep\n\n            self.writer = csv.DictWriter(self.csv_file,\n                                         fieldnames=['epoch'] + self.keys, dialect=CustomDialect)\n            if self.append_header:\n                self.writer.writeheader()\n\n        row_dict = OrderedDict({'epoch': epoch})\n        row_dict.update((key, handle_value(logs[key])) for key in self.keys)\n        self.writer.writerow(row_dict)\n        self.csv_file.flush()",
        "begin_line": 955,
        "end_line": 985,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.CSVLogger.handle_value#958",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CSVLogger",
        "signature": "keras.callbacks.CSVLogger.handle_value(k)",
        "snippet": "        def handle_value(k):\n            is_zero_dim_ndarray = isinstance(k, np.ndarray) and k.ndim == 0\n            if isinstance(k, six.string_types):\n                return k\n            elif isinstance(k, Iterable) and not is_zero_dim_ndarray:\n                return '\"[%s]\"' % (', '.join(map(str, k)))\n            else:\n                return k",
        "begin_line": 958,
        "end_line": 965,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.CustomDialect.on_epoch_end#955",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CustomDialect",
        "signature": "keras.callbacks.CustomDialect.on_epoch_end(self, epoch, logs=None)",
        "snippet": "    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n\n        def handle_value(k):\n            is_zero_dim_ndarray = isinstance(k, np.ndarray) and k.ndim == 0\n            if isinstance(k, six.string_types):\n                return k\n            elif isinstance(k, Iterable) and not is_zero_dim_ndarray:\n                return '\"[%s]\"' % (', '.join(map(str, k)))\n            else:\n                return k\n\n        if self.model.stop_training:\n            # We set NA so that csv parsers do not fail for this last epoch.\n            logs = dict([(k, logs[k]) if k in logs else (k, 'NA') for k in self.keys])\n\n        if not self.writer:\n            self.keys = sorted(logs.keys())\n\n            class CustomDialect(csv.excel):\n                delimiter = self.sep\n\n            self.writer = csv.DictWriter(self.csv_file,\n                                         fieldnames=['epoch'] + self.keys, dialect=CustomDialect)\n            if self.append_header:\n                self.writer.writeheader()\n\n        row_dict = OrderedDict({'epoch': epoch})\n        row_dict.update((key, handle_value(logs[key])) for key in self.keys)\n        self.writer.writerow(row_dict)\n        self.csv_file.flush()",
        "begin_line": 955,
        "end_line": 985,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.CSVLogger.on_train_end#987",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.CSVLogger",
        "signature": "keras.callbacks.CSVLogger.on_train_end(self, logs=None)",
        "snippet": "    def on_train_end(self, logs=None):\n        self.csv_file.close()\n        self.writer = None",
        "begin_line": 987,
        "end_line": 989,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001967729240456513,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.callbacks.LambdaCallback.__init__#1043",
        "src_path": "keras/callbacks.py",
        "class_name": "keras.callbacks.LambdaCallback",
        "signature": "keras.callbacks.LambdaCallback.__init__(self, on_epoch_begin=None, on_epoch_end=None, on_batch_begin=None, on_batch_end=None, on_train_begin=None, on_train_end=None, **kwargs)",
        "snippet": "    def __init__(self,\n                 on_epoch_begin=None,\n                 on_epoch_end=None,\n                 on_batch_begin=None,\n                 on_batch_end=None,\n                 on_train_begin=None,\n                 on_train_end=None,\n                 **kwargs):\n        super(LambdaCallback, self).__init__()\n        self.__dict__.update(kwargs)\n        if on_epoch_begin is not None:\n            self.on_epoch_begin = on_epoch_begin\n        else:\n            self.on_epoch_begin = lambda epoch, logs: None\n        if on_epoch_end is not None:\n            self.on_epoch_end = on_epoch_end\n        else:\n            self.on_epoch_end = lambda epoch, logs: None\n        if on_batch_begin is not None:\n            self.on_batch_begin = on_batch_begin\n        else:\n            self.on_batch_begin = lambda batch, logs: None\n        if on_batch_end is not None:\n            self.on_batch_end = on_batch_end\n        else:\n            self.on_batch_end = lambda batch, logs: None\n        if on_train_begin is not None:\n            self.on_train_begin = on_train_begin\n        else:\n            self.on_train_begin = lambda logs: None\n        if on_train_end is not None:\n            self.on_train_end = on_train_end\n        else:\n            self.on_train_end = lambda logs: None",
        "begin_line": 1043,
        "end_line": 1076,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.applications.mobilenet.relu6#83",
        "src_path": "keras/applications/mobilenet.py",
        "class_name": "keras.applications.mobilenet",
        "signature": "keras.applications.mobilenet.relu6(x)",
        "snippet": "def relu6(x):\n    return K.relu(x, max_value=6)",
        "begin_line": 83,
        "end_line": 84,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00012818869375721061,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.applications.mobilenet.DepthwiseConv2D.__init__#171",
        "src_path": "keras/applications/mobilenet.py",
        "class_name": "keras.applications.mobilenet.DepthwiseConv2D",
        "signature": "keras.applications.mobilenet.DepthwiseConv2D.__init__(self, kernel_size, strides=(1, 1), padding='valid', depth_multiplier=1, data_format=None, activation=None, use_bias=True, depthwise_initializer='glorot_uniform', bias_initializer='zeros', depthwise_regularizer=None, bias_regularizer=None, activity_regularizer=None, depthwise_constraint=None, bias_constraint=None, **kwargs)",
        "snippet": "    def __init__(self,\n                 kernel_size,\n                 strides=(1, 1),\n                 padding='valid',\n                 depth_multiplier=1,\n                 data_format=None,\n                 activation=None,\n                 use_bias=True,\n                 depthwise_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n                 depthwise_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 depthwise_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(DepthwiseConv2D, self).__init__(\n            filters=None,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=padding,\n            data_format=data_format,\n            activation=activation,\n            use_bias=use_bias,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            bias_constraint=bias_constraint,\n            **kwargs)\n        self.depth_multiplier = depth_multiplier\n        self.depthwise_initializer = initializers.get(depthwise_initializer)\n        self.depthwise_regularizer = regularizers.get(depthwise_regularizer)\n        self.depthwise_constraint = constraints.get(depthwise_constraint)\n        self.bias_initializer = initializers.get(bias_initializer)",
        "begin_line": 171,
        "end_line": 203,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0001218769043266301,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.applications.mobilenet.DepthwiseConv2D.build#205",
        "src_path": "keras/applications/mobilenet.py",
        "class_name": "keras.applications.mobilenet.DepthwiseConv2D",
        "signature": "keras.applications.mobilenet.DepthwiseConv2D.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        if len(input_shape) < 4:\n            raise ValueError('Inputs to `DepthwiseConv2D` should have rank 4. '\n                             'Received input shape:', str(input_shape))\n        if self.data_format == 'channels_first':\n            channel_axis = 1\n        else:\n            channel_axis = 3\n        if input_shape[channel_axis] is None:\n            raise ValueError('The channel dimension of the inputs to '\n                             '`DepthwiseConv2D` '\n                             'should be defined. Found `None`.')\n        input_dim = int(input_shape[channel_axis])\n        depthwise_kernel_shape = (self.kernel_size[0],\n                                  self.kernel_size[1],\n                                  input_dim,\n                                  self.depth_multiplier)\n\n        self.depthwise_kernel = self.add_weight(\n            shape=depthwise_kernel_shape,\n            initializer=self.depthwise_initializer,\n            name='depthwise_kernel',\n            regularizer=self.depthwise_regularizer,\n            constraint=self.depthwise_constraint)\n\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(input_dim * self.depth_multiplier,),\n                                        initializer=self.bias_initializer,\n                                        name='bias',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        # Set input spec.\n        self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})\n        self.built = True",
        "begin_line": 205,
        "end_line": 240,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.applications.mobilenet.DepthwiseConv2D.call#242",
        "src_path": "keras/applications/mobilenet.py",
        "class_name": "keras.applications.mobilenet.DepthwiseConv2D",
        "signature": "keras.applications.mobilenet.DepthwiseConv2D.call(self, inputs, training=None)",
        "snippet": "    def call(self, inputs, training=None):\n        outputs = K.depthwise_conv2d(\n            inputs,\n            self.depthwise_kernel,\n            strides=self.strides,\n            padding=self.padding,\n            dilation_rate=self.dilation_rate,\n            data_format=self.data_format)\n\n        if self.bias:\n            outputs = K.bias_add(\n                outputs,\n                self.bias,\n                data_format=self.data_format)\n\n        if self.activation is not None:\n            return self.activation(outputs)\n\n        return outputs",
        "begin_line": 242,
        "end_line": 260,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.applications.mobilenet.DepthwiseConv2D.compute_output_shape#262",
        "src_path": "keras/applications/mobilenet.py",
        "class_name": "keras.applications.mobilenet.DepthwiseConv2D",
        "signature": "keras.applications.mobilenet.DepthwiseConv2D.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self.data_format == 'channels_first':\n            rows = input_shape[2]\n            cols = input_shape[3]\n            out_filters = input_shape[1] * self.depth_multiplier\n        elif self.data_format == 'channels_last':\n            rows = input_shape[1]\n            cols = input_shape[2]\n            out_filters = input_shape[3] * self.depth_multiplier\n\n        rows = conv_utils.conv_output_length(rows, self.kernel_size[0],\n                                             self.padding,\n                                             self.strides[0])\n        cols = conv_utils.conv_output_length(cols, self.kernel_size[1],\n                                             self.padding,\n                                             self.strides[1])\n\n        if self.data_format == 'channels_first':\n            return (input_shape[0], out_filters, rows, cols)\n        elif self.data_format == 'channels_last':\n            return (input_shape[0], rows, cols, out_filters)",
        "begin_line": 262,
        "end_line": 282,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.applications.mobilenet.DepthwiseConv2D.get_config#284",
        "src_path": "keras/applications/mobilenet.py",
        "class_name": "keras.applications.mobilenet.DepthwiseConv2D",
        "signature": "keras.applications.mobilenet.DepthwiseConv2D.get_config(self)",
        "snippet": "    def get_config(self):\n        config = super(DepthwiseConv2D, self).get_config()\n        config.pop('filters')\n        config.pop('kernel_initializer')\n        config.pop('kernel_regularizer')\n        config.pop('kernel_constraint')\n        config['depth_multiplier'] = self.depth_multiplier\n        config['depthwise_initializer'] = initializers.serialize(self.depthwise_initializer)\n        config['depthwise_regularizer'] = regularizers.serialize(self.depthwise_regularizer)\n        config['depthwise_constraint'] = constraints.serialize(self.depthwise_constraint)\n        return config",
        "begin_line": 284,
        "end_line": 294,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.applications.mobilenet.MobileNet#297",
        "src_path": "keras/applications/mobilenet.py",
        "class_name": "keras.applications.mobilenet",
        "signature": "keras.applications.mobilenet.MobileNet(input_shape=None, alpha=1.0, depth_multiplier=1, dropout=0.001, include_top=True, weights='imagenet', input_tensor=None, pooling=None, classes=1000)",
        "snippet": "def MobileNet(input_shape=None,\n              alpha=1.0,\n              depth_multiplier=1,\n              dropout=1e-3,\n              include_top=True,\n              weights='imagenet',\n              input_tensor=None,\n              pooling=None,\n              classes=1000):\n    \"\"\"Instantiates the MobileNet architecture.\n\n    Note that only TensorFlow is supported for now,\n    therefore it only works with the data format\n    `image_data_format='channels_last'` in your Keras config\n    at `~/.keras/keras.json`.\n\n    To load a MobileNet model via `load_model`, import the custom\n    objects `relu6` and `DepthwiseConv2D` and pass them to the\n    `custom_objects` parameter.\n    E.g.\n    model = load_model('mobilenet.h5', custom_objects={\n                       'relu6': mobilenet.relu6,\n                       'DepthwiseConv2D': mobilenet.DepthwiseConv2D})\n\n    # Arguments\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(224, 224, 3)` (with `channels_last` data format)\n            or (3, 224, 224) (with `channels_first` data format).\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 32.\n            E.g. `(200, 200, 3)` would be one valid value.\n        alpha: controls the width of the network.\n            - If `alpha` < 1.0, proportionally decreases the number\n                of filters in each layer.\n            - If `alpha` > 1.0, proportionally increases the number\n                of filters in each layer.\n            - If `alpha` = 1, default number of filters from the paper\n                 are used at each layer.\n        depth_multiplier: depth multiplier for depthwise convolution\n            (also called the resolution multiplier)\n        dropout: dropout rate\n        include_top: whether to include the fully-connected\n            layer at the top of the network.\n        weights: `None` (random initialization) or\n            `imagenet` (ImageNet weights)\n        input_tensor: optional Keras tensor (i.e. output of\n            `layers.Input()`)\n            to use as image input for the model.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model\n                will be the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a\n                2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n\n    # Returns\n        A Keras model instance.\n\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n        RuntimeError: If attempting to run this model with a\n            backend that does not support separable convolutions.\n    \"\"\"\n\n    if K.backend() != 'tensorflow':\n        raise RuntimeError('Only TensorFlow backend is currently supported, '\n                           'as other backends do not support '\n                           'depthwise convolution.')\n\n    if weights not in {'imagenet', None}:\n        raise ValueError('The `weights` argument should be either '\n                         '`None` (random initialization) or `imagenet` '\n                         '(pre-training on ImageNet).')\n\n    if weights == 'imagenet' and include_top and classes != 1000:\n        raise ValueError('If using `weights` as ImageNet with `include_top` '\n                         'as true, `classes` should be 1000')\n\n    # Determine proper input shape and default size.\n    if input_shape is None:\n        default_size = 224\n    else:\n        if K.image_data_format() == 'channels_first':\n            rows = input_shape[1]\n            cols = input_shape[2]\n        else:\n            rows = input_shape[0]\n            cols = input_shape[1]\n\n        if rows == cols and rows in [128, 160, 192, 224]:\n            default_size = rows\n        else:\n            default_size = 224\n\n    input_shape = _obtain_input_shape(input_shape,\n                                      default_size=default_size,\n                                      min_size=32,\n                                      data_format=K.image_data_format(),\n                                      require_flatten=include_top,\n                                      weights=weights)\n\n    if K.image_data_format() == 'channels_last':\n        row_axis, col_axis = (0, 1)\n    else:\n        row_axis, col_axis = (1, 2)\n    rows = input_shape[row_axis]\n    cols = input_shape[col_axis]\n\n    if weights == 'imagenet':\n        if depth_multiplier != 1:\n            raise ValueError('If imagenet weights are being loaded, '\n                             'depth multiplier must be 1')\n\n        if alpha not in [0.25, 0.50, 0.75, 1.0]:\n            raise ValueError('If imagenet weights are being loaded, '\n                             'alpha can be one of'\n                             '`0.25`, `0.50`, `0.75` or `1.0` only.')\n\n        if rows != cols or rows not in [128, 160, 192, 224]:\n            raise ValueError('If imagenet weights are being loaded, '\n                             'input must have a static square shape (one of '\n                             '(128,128), (160,160), (192,192), or (224, 224)).'\n                             ' Input shape provided = %s' % (input_shape,))\n\n    if K.image_data_format() != 'channels_last':\n        warnings.warn('The MobileNet family of models is only available '\n                      'for the input data format \"channels_last\" '\n                      '(width, height, channels). '\n                      'However your settings specify the default '\n                      'data format \"channels_first\" (channels, width, height).'\n                      ' You should set `image_data_format=\"channels_last\"` '\n                      'in your Keras config located at ~/.keras/keras.json. '\n                      'The model being returned right now will expect inputs '\n                      'to follow the \"channels_last\" data format.')\n        K.set_image_data_format('channels_last')\n        old_data_format = 'channels_first'\n    else:\n        old_data_format = None\n\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n\n    x = _conv_block(img_input, 32, alpha, strides=(2, 2))\n    x = _depthwise_conv_block(x, 64, alpha, depth_multiplier, block_id=1)\n\n    x = _depthwise_conv_block(x, 128, alpha, depth_multiplier,\n                              strides=(2, 2), block_id=2)\n    x = _depthwise_conv_block(x, 128, alpha, depth_multiplier, block_id=3)\n\n    x = _depthwise_conv_block(x, 256, alpha, depth_multiplier,\n                              strides=(2, 2), block_id=4)\n    x = _depthwise_conv_block(x, 256, alpha, depth_multiplier, block_id=5)\n\n    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier,\n                              strides=(2, 2), block_id=6)\n    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=7)\n    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=8)\n    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=9)\n    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=10)\n    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=11)\n\n    x = _depthwise_conv_block(x, 1024, alpha, depth_multiplier,\n                              strides=(2, 2), block_id=12)\n    x = _depthwise_conv_block(x, 1024, alpha, depth_multiplier, block_id=13)\n\n    if include_top:\n        if K.image_data_format() == 'channels_first':\n            shape = (int(1024 * alpha), 1, 1)\n        else:\n            shape = (1, 1, int(1024 * alpha))\n\n        x = GlobalAveragePooling2D()(x)\n        x = Reshape(shape, name='reshape_1')(x)\n        x = Dropout(dropout, name='dropout')(x)\n        x = Conv2D(classes, (1, 1),\n                   padding='same', name='conv_preds')(x)\n        x = Activation('softmax', name='act_softmax')(x)\n        x = Reshape((classes,), name='reshape_2')(x)\n    else:\n        if pooling == 'avg':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling == 'max':\n            x = GlobalMaxPooling2D()(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n\n    # Create model.\n    model = Model(inputs, x, name='mobilenet_%0.2f_%s' % (alpha, rows))\n\n    # load weights\n    if weights == 'imagenet':\n        if K.image_data_format() == 'channels_first':\n            raise ValueError('Weights for \"channels_last\" format '\n                             'are not available.')\n        if alpha == 1.0:\n            alpha_text = '1_0'\n        elif alpha == 0.75:\n            alpha_text = '7_5'\n        elif alpha == 0.50:\n            alpha_text = '5_0'\n        else:\n            alpha_text = '2_5'\n\n        if include_top:\n            model_name = 'mobilenet_%s_%d_tf.h5' % (alpha_text, rows)\n            weigh_path = BASE_WEIGHT_PATH + model_name\n            weights_path = get_file(model_name,\n                                    weigh_path,\n                                    cache_subdir='models')\n        else:\n            model_name = 'mobilenet_%s_%d_tf_no_top.h5' % (alpha_text, rows)\n            weigh_path = BASE_WEIGHT_PATH + model_name\n            weights_path = get_file(model_name,\n                                    weigh_path,\n                                    cache_subdir='models')\n        model.load_weights(weights_path)\n\n    if old_data_format:\n        K.set_image_data_format(old_data_format)\n    return model",
        "begin_line": 297,
        "end_line": 537,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.0003224766204450177,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.applications.mobilenet._conv_block#540",
        "src_path": "keras/applications/mobilenet.py",
        "class_name": "keras.applications.mobilenet",
        "signature": "keras.applications.mobilenet._conv_block(inputs, filters, alpha, kernel=(3, 3), strides=(1, 1))",
        "snippet": "def _conv_block(inputs, filters, alpha, kernel=(3, 3), strides=(1, 1)):\n    \"\"\"Adds an initial convolution layer (with batch normalization and relu6).\n\n    # Arguments\n        inputs: Input tensor of shape `(rows, cols, 3)`\n            (with `channels_last` data format) or\n            (3, rows, cols) (with `channels_first` data format).\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 32.\n            E.g. `(224, 224, 3)` would be one valid value.\n        filters: Integer, the dimensionality of the output space\n            (i.e. the number output of filters in the convolution).\n        alpha: controls the width of the network.\n            - If `alpha` < 1.0, proportionally decreases the number\n                of filters in each layer.\n            - If `alpha` > 1.0, proportionally increases the number\n                of filters in each layer.\n            - If `alpha` = 1, default number of filters from the paper\n                 are used at each layer.\n        kernel: An integer or tuple/list of 2 integers, specifying the\n            width and height of the 2D convolution window.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n        strides: An integer or tuple/list of 2 integers,\n            specifying the strides of the convolution along the width and height.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n            Specifying any stride value != 1 is incompatible with specifying\n            any `dilation_rate` value != 1.\n\n    # Input shape\n        4D tensor with shape:\n        `(samples, channels, rows, cols)` if data_format='channels_first'\n        or 4D tensor with shape:\n        `(samples, rows, cols, channels)` if data_format='channels_last'.\n\n    # Output shape\n        4D tensor with shape:\n        `(samples, filters, new_rows, new_cols)` if data_format='channels_first'\n        or 4D tensor with shape:\n        `(samples, new_rows, new_cols, filters)` if data_format='channels_last'.\n        `rows` and `cols` values might have changed due to stride.\n\n    # Returns\n        Output tensor of block.\n    \"\"\"\n    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n    filters = int(filters * alpha)\n    x = Conv2D(filters, kernel,\n               padding='same',\n               use_bias=False,\n               strides=strides,\n               name='conv1')(inputs)\n    x = BatchNormalization(axis=channel_axis, name='conv1_bn')(x)\n    return Activation(relu6, name='conv1_relu')(x)",
        "begin_line": 540,
        "end_line": 594,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00012818869375721061,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    },
    {
        "name": "keras.applications.mobilenet._depthwise_conv_block#597",
        "src_path": "keras/applications/mobilenet.py",
        "class_name": "keras.applications.mobilenet",
        "signature": "keras.applications.mobilenet._depthwise_conv_block(inputs, pointwise_conv_filters, alpha, depth_multiplier=1, strides=(1, 1), block_id=1)",
        "snippet": "def _depthwise_conv_block(inputs, pointwise_conv_filters, alpha,\n                          depth_multiplier=1, strides=(1, 1), block_id=1):\n    \"\"\"Adds a depthwise convolution block.\n\n    A depthwise convolution block consists of a depthwise conv,\n    batch normalization, relu6, pointwise convolution,\n    batch normalization and relu6 activation.\n\n    # Arguments\n        inputs: Input tensor of shape `(rows, cols, channels)`\n            (with `channels_last` data format) or\n            (channels, rows, cols) (with `channels_first` data format).\n        pointwise_conv_filters: Integer, the dimensionality of the output space\n            (i.e. the number output of filters in the pointwise convolution).\n        alpha: controls the width of the network.\n            - If `alpha` < 1.0, proportionally decreases the number\n                of filters in each layer.\n            - If `alpha` > 1.0, proportionally increases the number\n                of filters in each layer.\n            - If `alpha` = 1, default number of filters from the paper\n                 are used at each layer.\n        depth_multiplier: The number of depthwise convolution output channels\n            for each input channel.\n            The total number of depthwise convolution output\n            channels will be equal to `filters_in * depth_multiplier`.\n        strides: An integer or tuple/list of 2 integers,\n            specifying the strides of the convolution along the width and height.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n            Specifying any stride value != 1 is incompatible with specifying\n            any `dilation_rate` value != 1.\n        block_id: Integer, a unique identification designating the block number.\n\n    # Input shape\n        4D tensor with shape:\n        `(batch, channels, rows, cols)` if data_format='channels_first'\n        or 4D tensor with shape:\n        `(batch, rows, cols, channels)` if data_format='channels_last'.\n\n    # Output shape\n        4D tensor with shape:\n        `(batch, filters, new_rows, new_cols)` if data_format='channels_first'\n        or 4D tensor with shape:\n        `(batch, new_rows, new_cols, filters)` if data_format='channels_last'.\n        `rows` and `cols` values might have changed due to stride.\n\n    # Returns\n        Output tensor of block.\n    \"\"\"\n    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n    pointwise_conv_filters = int(pointwise_conv_filters * alpha)\n\n    x = DepthwiseConv2D((3, 3),\n                        padding='same',\n                        depth_multiplier=depth_multiplier,\n                        strides=strides,\n                        use_bias=False,\n                        name='conv_dw_%d' % block_id)(inputs)\n    x = BatchNormalization(axis=channel_axis, name='conv_dw_%d_bn' % block_id)(x)\n    x = Activation(relu6, name='conv_dw_%d_relu' % block_id)(x)\n\n    x = Conv2D(pointwise_conv_filters, (1, 1),\n               padding='same',\n               use_bias=False,\n               strides=(1, 1),\n               name='conv_pw_%d' % block_id)(x)\n    x = BatchNormalization(axis=channel_axis, name='conv_pw_%d_bn' % block_id)(x)\n    return Activation(relu6, name='conv_pw_%d_relu' % block_id)(x)",
        "begin_line": 597,
        "end_line": 664,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0001497454327643007,
            "pseudo_dstar_susp": 0.0001497454327643007,
            "pseudo_tarantula_susp": 0.0001497454327643007,
            "pseudo_op2_susp": 0.00012818869375721061,
            "pseudo_barinel_susp": 0.0001497454327643007
        }
    }
]