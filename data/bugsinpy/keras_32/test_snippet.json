[
    {
        "name": "tests.keras.test_callbacks.test_TerminateOnNaN#35",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_TerminateOnNaN()",
        "snippet": "def test_TerminateOnNaN():\n    np.random.seed(1337)\n    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,\n                                                         num_test=test_samples,\n                                                         input_shape=(input_dim,),\n                                                         classification=True,\n                                                         num_classes=num_classes)\n\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n    cbks = [callbacks.TerminateOnNaN()]\n    model = Sequential()\n    initializer = initializers.Constant(value=1e5)\n    for _ in range(5):\n        model.add(Dense(num_hidden, input_dim=input_dim, activation='relu',\n                        kernel_initializer=initializer))\n    model.add(Dense(num_classes, activation='linear'))\n    model.compile(loss='mean_squared_error',\n                  optimizer='rmsprop')\n\n    # case 1 fit\n    history = model.fit(X_train, y_train, batch_size=batch_size,\n                        validation_data=(X_test, y_test), callbacks=cbks, epochs=20)\n    loss = history.history['loss']\n    assert len(loss) == 1\n    assert loss[0] == np.inf\n\n    # case 2 fit_generator\n    def data_generator():\n        max_batch_index = len(X_train) // batch_size\n        i = 0\n        while 1:\n            yield (X_train[i * batch_size: (i + 1) * batch_size],\n                   y_train[i * batch_size: (i + 1) * batch_size])\n            i += 1\n            i = i % max_batch_index\n    history = model.fit_generator(data_generator(),\n                                  len(X_train),\n                                  validation_data=(X_test, y_test),\n                                  callbacks=cbks,\n                                  epochs=20)\n    loss = history.history['loss']\n    assert len(loss) == 1\n    assert loss[0] == np.inf or np.isnan(loss[0])",
        "begin_line": 35,
        "end_line": 78,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.data_generator#63",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.data_generator()",
        "snippet": "    def data_generator():\n        max_batch_index = len(X_train) // batch_size\n        i = 0\n        while 1:\n            yield (X_train[i * batch_size: (i + 1) * batch_size],\n                   y_train[i * batch_size: (i + 1) * batch_size])\n            i += 1\n            i = i % max_batch_index",
        "begin_line": 63,
        "end_line": 70,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_stop_training_csv#82",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_stop_training_csv(tmpdir)",
        "snippet": "def test_stop_training_csv(tmpdir):\n    np.random.seed(1337)\n    fp = str(tmpdir / 'test.csv')\n    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,\n                                                         num_test=test_samples,\n                                                         input_shape=(input_dim,),\n                                                         classification=True,\n                                                         num_classes=num_classes)\n\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n    cbks = [callbacks.TerminateOnNaN(), callbacks.CSVLogger(fp)]\n    model = Sequential()\n    for _ in range(5):\n        model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))\n    model.add(Dense(num_classes, activation='linear'))\n    model.compile(loss='mean_squared_error',\n                  optimizer='rmsprop')\n\n    def data_generator():\n        i = 0\n        max_batch_index = len(X_train) // batch_size\n        tot = 0\n        while 1:\n            if tot > 3 * len(X_train):\n                yield np.ones([batch_size, input_dim]) * np.nan, np.ones([batch_size, num_classes]) * np.nan\n            else:\n                yield (X_train[i * batch_size: (i + 1) * batch_size],\n                       y_train[i * batch_size: (i + 1) * batch_size])\n            i += 1\n            tot += 1\n            i = i % max_batch_index\n\n    history = model.fit_generator(data_generator(),\n                                  len(X_train) // batch_size,\n                                  validation_data=(X_test, y_test),\n                                  callbacks=cbks,\n                                  epochs=20)\n    loss = history.history['loss']\n    assert len(loss) > 1\n    assert loss[-1] == np.inf or np.isnan(loss[-1])\n\n    values = []\n    with open(fp) as f:\n        for x in reader(f):\n            values.append(x)\n\n    assert 'nan' in values[-1], 'The last epoch was not logged.'\n    os.remove(fp)",
        "begin_line": 82,
        "end_line": 130,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.data_generator#101",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.data_generator()",
        "snippet": "    def data_generator():\n        i = 0\n        max_batch_index = len(X_train) // batch_size\n        tot = 0\n        while 1:\n            if tot > 3 * len(X_train):\n                yield np.ones([batch_size, input_dim]) * np.nan, np.ones([batch_size, num_classes]) * np.nan\n            else:\n                yield (X_train[i * batch_size: (i + 1) * batch_size],\n                       y_train[i * batch_size: (i + 1) * batch_size])\n            i += 1\n            tot += 1\n            i = i % max_batch_index",
        "begin_line": 101,
        "end_line": 113,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_ModelCheckpoint#134",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_ModelCheckpoint(tmpdir)",
        "snippet": "def test_ModelCheckpoint(tmpdir):\n    np.random.seed(1337)\n    filepath = str(tmpdir / 'checkpoint.h5')\n    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,\n                                                         num_test=test_samples,\n                                                         input_shape=(input_dim,),\n                                                         classification=True,\n                                                         num_classes=num_classes)\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n    # case 1\n    monitor = 'val_loss'\n    save_best_only = False\n    mode = 'auto'\n\n    model = Sequential()\n    model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))\n    model.add(Dense(num_classes, activation='softmax'))\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='rmsprop',\n                  metrics=['accuracy'])\n\n    cbks = [callbacks.ModelCheckpoint(filepath, monitor=monitor,\n                                      save_best_only=save_best_only, mode=mode)]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=1)\n    assert os.path.isfile(filepath)\n    os.remove(filepath)\n\n    # case 2\n    mode = 'min'\n    cbks = [callbacks.ModelCheckpoint(filepath, monitor=monitor,\n                                      save_best_only=save_best_only, mode=mode)]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=1)\n    assert os.path.isfile(filepath)\n    os.remove(filepath)\n\n    # case 3\n    mode = 'max'\n    monitor = 'val_acc'\n    cbks = [callbacks.ModelCheckpoint(filepath, monitor=monitor,\n                                      save_best_only=save_best_only, mode=mode)]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=1)\n    assert os.path.isfile(filepath)\n    os.remove(filepath)\n\n    # case 4\n    save_best_only = True\n    cbks = [callbacks.ModelCheckpoint(filepath, monitor=monitor,\n                                      save_best_only=save_best_only, mode=mode)]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=1)\n    assert os.path.isfile(filepath)\n    os.remove(filepath)\n\n    # case 5\n    save_best_only = False\n    period = 2\n    mode = 'auto'\n    filepath = 'checkpoint.{epoch:02d}.h5'\n    cbks = [callbacks.ModelCheckpoint(filepath, monitor=monitor,\n                                      save_best_only=save_best_only, mode=mode,\n                                      period=period)]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=4)\n    assert os.path.isfile(filepath.format(epoch=2))\n    assert os.path.isfile(filepath.format(epoch=4))\n    assert not os.path.exists(filepath.format(epoch=1))\n    assert not os.path.exists(filepath.format(epoch=3))\n    os.remove(filepath.format(epoch=2))\n    os.remove(filepath.format(epoch=4))\n    assert not tmpdir.listdir()",
        "begin_line": 134,
        "end_line": 207,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_EarlyStopping#211",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_EarlyStopping()",
        "snippet": "def test_EarlyStopping():\n    np.random.seed(1337)\n    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,\n                                                         num_test=test_samples,\n                                                         input_shape=(input_dim,),\n                                                         classification=True,\n                                                         num_classes=num_classes)\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n    model = Sequential()\n    model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))\n    model.add(Dense(num_classes, activation='softmax'))\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='rmsprop',\n                  metrics=['accuracy'])\n    mode = 'max'\n    monitor = 'val_acc'\n    patience = 0\n    cbks = [callbacks.EarlyStopping(patience=patience, monitor=monitor, mode=mode)]\n    history = model.fit(X_train, y_train, batch_size=batch_size,\n                        validation_data=(X_test, y_test), callbacks=cbks, epochs=20)\n\n    mode = 'auto'\n    monitor = 'val_acc'\n    patience = 2\n    cbks = [callbacks.EarlyStopping(patience=patience, monitor=monitor, mode=mode)]\n    history = model.fit(X_train, y_train, batch_size=batch_size,\n                        validation_data=(X_test, y_test), callbacks=cbks, epochs=20)",
        "begin_line": 211,
        "end_line": 238,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_EarlyStopping_reuse#242",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_EarlyStopping_reuse()",
        "snippet": "def test_EarlyStopping_reuse():\n    np.random.seed(1337)\n    patience = 3\n    data = np.random.random((100, 1))\n    labels = np.where(data > 0.5, 1, 0)\n    model = Sequential((\n        Dense(1, input_dim=1, activation='relu'),\n        Dense(1, activation='sigmoid'),\n    ))\n    model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n    stopper = callbacks.EarlyStopping(monitor='acc', patience=patience)\n    weights = model.get_weights()\n\n    hist = model.fit(data, labels, callbacks=[stopper], epochs=20)\n    assert len(hist.epoch) >= patience\n\n    # This should allow training to go for at least `patience` epochs\n    model.set_weights(weights)\n    hist = model.fit(data, labels, callbacks=[stopper], epochs=20)\n    assert len(hist.epoch) >= patience",
        "begin_line": 242,
        "end_line": 261,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_EarlyStopping_patience#265",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_EarlyStopping_patience()",
        "snippet": "def test_EarlyStopping_patience():\n    class DummyModel(object):\n        def __init__(self):\n            self.stop_training = False\n\n    early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=2)\n    early_stop.model = DummyModel()\n\n    losses = [0.0860, 0.1096, 0.1040, 0.1019]\n\n    # Should stop after epoch 3, as the loss has not improved after patience=2 epochs.\n    epochs_trained = 0\n    early_stop.on_train_begin()\n\n    for epoch in range(len(losses)):\n        epochs_trained += 1\n        early_stop.on_epoch_end(epoch, logs={'val_loss': losses[epoch]})\n\n        if early_stop.model.stop_training:\n            break\n\n    assert epochs_trained == 3",
        "begin_line": 265,
        "end_line": 286,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.DummyModel.test_EarlyStopping_patience#265",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks.DummyModel",
        "signature": "tests.keras.test_callbacks.DummyModel.test_EarlyStopping_patience()",
        "snippet": "def test_EarlyStopping_patience():\n    class DummyModel(object):\n        def __init__(self):\n            self.stop_training = False\n\n    early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=2)\n    early_stop.model = DummyModel()\n\n    losses = [0.0860, 0.1096, 0.1040, 0.1019]\n\n    # Should stop after epoch 3, as the loss has not improved after patience=2 epochs.\n    epochs_trained = 0\n    early_stop.on_train_begin()\n\n    for epoch in range(len(losses)):\n        epochs_trained += 1\n        early_stop.on_epoch_end(epoch, logs={'val_loss': losses[epoch]})\n\n        if early_stop.model.stop_training:\n            break\n\n    assert epochs_trained == 3",
        "begin_line": 265,
        "end_line": 286,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.DummyModel.__init__#267",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks.DummyModel",
        "signature": "tests.keras.test_callbacks.DummyModel.__init__(self)",
        "snippet": "        def __init__(self):\n            self.stop_training = False",
        "begin_line": 267,
        "end_line": 268,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_LearningRateScheduler#290",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_LearningRateScheduler()",
        "snippet": "def test_LearningRateScheduler():\n    np.random.seed(1337)\n    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,\n                                                         num_test=test_samples,\n                                                         input_shape=(input_dim,),\n                                                         classification=True,\n                                                         num_classes=num_classes)\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n    model = Sequential()\n    model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))\n    model.add(Dense(num_classes, activation='softmax'))\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='sgd',\n                  metrics=['accuracy'])\n\n    cbks = [callbacks.LearningRateScheduler(lambda x: 1. / (1. + x))]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=5)\n    assert (float(K.get_value(model.optimizer.lr)) - 0.2) < K.epsilon()",
        "begin_line": 290,
        "end_line": 309,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_ReduceLROnPlateau#313",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_ReduceLROnPlateau()",
        "snippet": "def test_ReduceLROnPlateau():\n    np.random.seed(1337)\n    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,\n                                                         num_test=test_samples,\n                                                         input_shape=(input_dim,),\n                                                         classification=True,\n                                                         num_classes=num_classes)\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n\n    def make_model():\n        np.random.seed(1337)\n        model = Sequential()\n        model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))\n        model.add(Dense(num_classes, activation='softmax'))\n\n        model.compile(loss='categorical_crossentropy',\n                      optimizer=optimizers.SGD(lr=0.1),\n                      metrics=['accuracy'])\n        return model\n\n    model = make_model()\n\n    # This should reduce the LR after the first epoch (due to high epsilon).\n    cbks = [callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, min_delta=10, patience=1, cooldown=5)]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=5, verbose=2)\n    assert np.allclose(float(K.get_value(model.optimizer.lr)), 0.01, atol=K.epsilon())\n\n    model = make_model()\n    cbks = [callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, min_delta=0, patience=1, cooldown=5)]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=5, verbose=2)\n    assert np.allclose(float(K.get_value(model.optimizer.lr)), 0.1, atol=K.epsilon())",
        "begin_line": 313,
        "end_line": 346,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.make_model#323",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.make_model()",
        "snippet": "    def make_model():\n        np.random.seed(1337)\n        model = Sequential()\n        model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))\n        model.add(Dense(num_classes, activation='softmax'))\n\n        model.compile(loss='categorical_crossentropy',\n                      optimizer=optimizers.SGD(lr=0.1),\n                      metrics=['accuracy'])\n        return model",
        "begin_line": 323,
        "end_line": 332,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_ReduceLROnPlateau_patience#350",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_ReduceLROnPlateau_patience()",
        "snippet": "def test_ReduceLROnPlateau_patience():\n    class DummyOptimizer(object):\n        def __init__(self):\n            self.lr = K.variable(1.0)\n\n    class DummyModel(object):\n        def __init__(self):\n            self.optimizer = DummyOptimizer()\n\n    reduce_on_plateau = callbacks.ReduceLROnPlateau(monitor='val_loss',\n                                                    patience=2)\n    reduce_on_plateau.model = DummyModel()\n\n    losses = [0.0860, 0.1096, 0.1040]\n    lrs = []\n\n    for epoch in range(len(losses)):\n        reduce_on_plateau.on_epoch_end(epoch, logs={'val_loss': losses[epoch]})\n        lrs.append(K.get_value(reduce_on_plateau.model.optimizer.lr))\n\n    # The learning rates should be 1.0 except the last one\n    assert all([lr == 1.0 for lr in lrs[:-1]]) and lrs[-1] < 1.0",
        "begin_line": 350,
        "end_line": 371,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.DummyOptimizer.test_ReduceLROnPlateau_patience#350",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks.DummyOptimizer",
        "signature": "tests.keras.test_callbacks.DummyOptimizer.test_ReduceLROnPlateau_patience()",
        "snippet": "def test_ReduceLROnPlateau_patience():\n    class DummyOptimizer(object):\n        def __init__(self):\n            self.lr = K.variable(1.0)\n\n    class DummyModel(object):\n        def __init__(self):\n            self.optimizer = DummyOptimizer()\n\n    reduce_on_plateau = callbacks.ReduceLROnPlateau(monitor='val_loss',\n                                                    patience=2)\n    reduce_on_plateau.model = DummyModel()\n\n    losses = [0.0860, 0.1096, 0.1040]\n    lrs = []\n\n    for epoch in range(len(losses)):\n        reduce_on_plateau.on_epoch_end(epoch, logs={'val_loss': losses[epoch]})\n        lrs.append(K.get_value(reduce_on_plateau.model.optimizer.lr))\n\n    # The learning rates should be 1.0 except the last one\n    assert all([lr == 1.0 for lr in lrs[:-1]]) and lrs[-1] < 1.0",
        "begin_line": 350,
        "end_line": 371,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.DummyOptimizer.__init__#352",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks.DummyOptimizer",
        "signature": "tests.keras.test_callbacks.DummyOptimizer.__init__(self)",
        "snippet": "        def __init__(self):\n            self.lr = K.variable(1.0)",
        "begin_line": 352,
        "end_line": 353,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.DummyModel.test_ReduceLROnPlateau_patience#350",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks.DummyModel",
        "signature": "tests.keras.test_callbacks.DummyModel.test_ReduceLROnPlateau_patience()",
        "snippet": "def test_ReduceLROnPlateau_patience():\n    class DummyOptimizer(object):\n        def __init__(self):\n            self.lr = K.variable(1.0)\n\n    class DummyModel(object):\n        def __init__(self):\n            self.optimizer = DummyOptimizer()\n\n    reduce_on_plateau = callbacks.ReduceLROnPlateau(monitor='val_loss',\n                                                    patience=2)\n    reduce_on_plateau.model = DummyModel()\n\n    losses = [0.0860, 0.1096, 0.1040]\n    lrs = []\n\n    for epoch in range(len(losses)):\n        reduce_on_plateau.on_epoch_end(epoch, logs={'val_loss': losses[epoch]})\n        lrs.append(K.get_value(reduce_on_plateau.model.optimizer.lr))\n\n    # The learning rates should be 1.0 except the last one\n    assert all([lr == 1.0 for lr in lrs[:-1]]) and lrs[-1] < 1.0",
        "begin_line": 350,
        "end_line": 371,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.DummyModel.__init__#356",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks.DummyModel",
        "signature": "tests.keras.test_callbacks.DummyModel.__init__(self)",
        "snippet": "        def __init__(self):\n            self.optimizer = DummyOptimizer()",
        "begin_line": 356,
        "end_line": 357,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_ReduceLROnPlateau_backwards_compatibility#375",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_ReduceLROnPlateau_backwards_compatibility()",
        "snippet": "def test_ReduceLROnPlateau_backwards_compatibility():\n    import warnings\n    with warnings.catch_warnings(record=True) as ws:\n        reduce_on_plateau = callbacks.ReduceLROnPlateau(epsilon=1e-13)\n        # Check if warnings are disabled\n        if os.environ.get(\"PYTHONWARNINGS\") != \"ignore\":\n            assert \"`epsilon` argument is deprecated\" in str(ws[0].message)\n    assert not hasattr(reduce_on_plateau, 'epsilon')\n    assert hasattr(reduce_on_plateau, 'min_delta')\n    assert reduce_on_plateau.min_delta == 1e-13",
        "begin_line": 375,
        "end_line": 384,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_CSVLogger#388",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_CSVLogger(tmpdir)",
        "snippet": "def test_CSVLogger(tmpdir):\n    np.random.seed(1337)\n    filepath = str(tmpdir / 'log.tsv')\n    sep = '\\t'\n    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,\n                                                         num_test=test_samples,\n                                                         input_shape=(input_dim,),\n                                                         classification=True,\n                                                         num_classes=num_classes)\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n\n    def make_model():\n        np.random.seed(1337)\n        model = Sequential()\n        model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))\n        model.add(Dense(num_classes, activation='softmax'))\n\n        model.compile(loss='categorical_crossentropy',\n                      optimizer=optimizers.SGD(lr=0.1),\n                      metrics=['accuracy'])\n        return model\n\n    # case 1, create new file with defined separator\n    model = make_model()\n    cbks = [callbacks.CSVLogger(filepath, separator=sep)]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=1)\n\n    assert os.path.isfile(filepath)\n    with open(filepath) as csvfile:\n        dialect = Sniffer().sniff(csvfile.read())\n    assert dialect.delimiter == sep\n    del model\n    del cbks\n\n    # case 2, append data to existing file, skip header\n    model = make_model()\n    cbks = [callbacks.CSVLogger(filepath, separator=sep, append=True)]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=1)\n\n    # case 3, reuse of CSVLogger object\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=1)\n\n    import re\n    with open(filepath) as csvfile:\n        output = \" \".join(csvfile.readlines())\n        assert len(re.findall('epoch', output)) == 1\n\n    os.remove(filepath)\n    assert not tmpdir.listdir()",
        "begin_line": 388,
        "end_line": 440,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.make_model#400",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.make_model()",
        "snippet": "    def make_model():\n        np.random.seed(1337)\n        model = Sequential()\n        model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))\n        model.add(Dense(num_classes, activation='softmax'))\n\n        model.compile(loss='categorical_crossentropy',\n                      optimizer=optimizers.SGD(lr=0.1),\n                      metrics=['accuracy'])\n        return model",
        "begin_line": 400,
        "end_line": 409,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_TensorBoard#444",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_TensorBoard(tmpdir)",
        "snippet": "def test_TensorBoard(tmpdir):\n    np.random.seed(np.random.randint(1, 1e7))\n    filepath = str(tmpdir / 'logs')\n\n    (X_train, y_train), (X_test, y_test) = get_test_data(\n        num_train=train_samples,\n        num_test=test_samples,\n        input_shape=(input_dim,),\n        classification=True,\n        num_classes=num_classes)\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n\n    def data_generator(train):\n        if train:\n            max_batch_index = len(X_train) // batch_size\n        else:\n            max_batch_index = len(X_test) // batch_size\n        i = 0\n        while 1:\n            if train:\n                # simulate multi-input/output models\n                yield (X_train[i * batch_size: (i + 1) * batch_size],\n                       y_train[i * batch_size: (i + 1) * batch_size])\n            else:\n                yield (X_test[i * batch_size: (i + 1) * batch_size],\n                       y_test[i * batch_size: (i + 1) * batch_size])\n            i += 1\n            i = i % max_batch_index\n\n    inp = Input((input_dim,))\n    hidden = Dense(num_hidden, activation='relu')(inp)\n    hidden = Dropout(0.1)(hidden)\n    output = Dense(num_classes, activation='softmax')(hidden)\n    model = Model(inputs=inp, outputs=output)\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='sgd',\n                  metrics=['accuracy'])\n\n    # we must generate new callbacks for each test, as they aren't stateless\n    def callbacks_factory(histogram_freq):\n        return [callbacks.TensorBoard(log_dir=filepath,\n                                      histogram_freq=histogram_freq,\n                                      write_images=True, write_grads=True,\n                                      embeddings_freq=1,\n                                      embeddings_layer_names=['dense_1'],\n                                      batch_size=5)]\n\n    # fit without validation data\n    model.fit(X_train, y_train, batch_size=batch_size,\n              callbacks=callbacks_factory(histogram_freq=0), epochs=3)\n\n    # fit with validation data and accuracy\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test),\n              callbacks=callbacks_factory(histogram_freq=0), epochs=2)\n\n    # fit generator without validation data\n    model.fit_generator(data_generator(True), len(X_train), epochs=2,\n                        callbacks=callbacks_factory(histogram_freq=0))\n\n    # fit generator with validation data and accuracy\n    model.fit_generator(data_generator(True), len(X_train), epochs=2,\n                        validation_data=(X_test, y_test),\n                        callbacks=callbacks_factory(histogram_freq=1))\n\n    assert os.path.isdir(filepath)\n    shutil.rmtree(filepath)\n    assert not tmpdir.listdir()",
        "begin_line": 444,
        "end_line": 512,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.data_generator#457",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.data_generator(train)",
        "snippet": "    def data_generator(train):\n        if train:\n            max_batch_index = len(X_train) // batch_size\n        else:\n            max_batch_index = len(X_test) // batch_size\n        i = 0\n        while 1:\n            if train:\n                # simulate multi-input/output models\n                yield (X_train[i * batch_size: (i + 1) * batch_size],\n                       y_train[i * batch_size: (i + 1) * batch_size])\n            else:\n                yield (X_test[i * batch_size: (i + 1) * batch_size],\n                       y_test[i * batch_size: (i + 1) * batch_size])\n            i += 1\n            i = i % max_batch_index",
        "begin_line": 457,
        "end_line": 472,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.callbacks_factory#484",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.callbacks_factory(histogram_freq)",
        "snippet": "    def callbacks_factory(histogram_freq):\n        return [callbacks.TensorBoard(log_dir=filepath,\n                                      histogram_freq=histogram_freq,\n                                      write_images=True, write_grads=True,\n                                      embeddings_freq=1,\n                                      embeddings_layer_names=['dense_1'],\n                                      batch_size=5)]",
        "begin_line": 484,
        "end_line": 490,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_TensorBoard_histogram_freq_must_have_validation_data#518",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_TensorBoard_histogram_freq_must_have_validation_data(tmpdir)",
        "snippet": "def test_TensorBoard_histogram_freq_must_have_validation_data(tmpdir):\n    np.random.seed(np.random.randint(1, 1e7))\n    filepath = str(tmpdir / 'logs')\n\n    (X_train, y_train), (X_test, y_test) = get_test_data(\n        num_train=train_samples,\n        num_test=test_samples,\n        input_shape=(input_dim,),\n        classification=True,\n        num_classes=num_classes)\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n\n    def data_generator(train):\n        if train:\n            max_batch_index = len(X_train) // batch_size\n        else:\n            max_batch_index = len(X_test) // batch_size\n        i = 0\n        while 1:\n            if train:\n                # simulate multi-input/output models\n                yield (X_train[i * batch_size: (i + 1) * batch_size],\n                       y_train[i * batch_size: (i + 1) * batch_size])\n            else:\n                yield (X_test[i * batch_size: (i + 1) * batch_size],\n                       y_test[i * batch_size: (i + 1) * batch_size])\n            i += 1\n            i = i % max_batch_index\n\n    inp = Input((input_dim,))\n    hidden = Dense(num_hidden, activation='relu')(inp)\n    hidden = Dropout(0.1)(hidden)\n    output = Dense(num_classes, activation='softmax')(hidden)\n    model = Model(inputs=inp, outputs=output)\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='sgd',\n                  metrics=['accuracy'])\n\n    # we must generate new callbacks for each test, as they aren't stateless\n    def callbacks_factory(histogram_freq):\n        return [callbacks.TensorBoard(log_dir=filepath,\n                                      histogram_freq=histogram_freq,\n                                      write_images=True, write_grads=True,\n                                      embeddings_freq=1,\n                                      embeddings_layer_names=['dense_1'],\n                                      batch_size=5)]\n\n    # fit without validation data should raise ValueError if histogram_freq > 0\n    with pytest.raises(ValueError) as raised_exception:\n        model.fit(X_train, y_train, batch_size=batch_size,\n                  callbacks=callbacks_factory(histogram_freq=1), epochs=3)\n    assert 'validation_data must be provided' in str(raised_exception.value)\n\n    # fit generator without validation data should raise ValueError if\n    # histogram_freq > 0\n    with pytest.raises(ValueError) as raised_exception:\n        model.fit_generator(data_generator(True), len(X_train), epochs=2,\n                            callbacks=callbacks_factory(histogram_freq=1))\n    assert 'validation_data must be provided' in str(raised_exception.value)\n\n    # fit generator with validation data generator should raise ValueError if\n    # histogram_freq > 0\n    with pytest.raises(ValueError) as raised_exception:\n        model.fit_generator(data_generator(True), len(X_train), epochs=2,\n                            validation_data=data_generator(False),\n                            validation_steps=1,\n                            callbacks=callbacks_factory(histogram_freq=1))\n    assert 'validation_data must be provided' in str(raised_exception.value)",
        "begin_line": 518,
        "end_line": 586,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.data_generator#531",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.data_generator(train)",
        "snippet": "    def data_generator(train):\n        if train:\n            max_batch_index = len(X_train) // batch_size\n        else:\n            max_batch_index = len(X_test) // batch_size\n        i = 0\n        while 1:\n            if train:\n                # simulate multi-input/output models\n                yield (X_train[i * batch_size: (i + 1) * batch_size],\n                       y_train[i * batch_size: (i + 1) * batch_size])\n            else:\n                yield (X_test[i * batch_size: (i + 1) * batch_size],\n                       y_test[i * batch_size: (i + 1) * batch_size])\n            i += 1\n            i = i % max_batch_index",
        "begin_line": 531,
        "end_line": 546,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.callbacks_factory#558",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.callbacks_factory(histogram_freq)",
        "snippet": "    def callbacks_factory(histogram_freq):\n        return [callbacks.TensorBoard(log_dir=filepath,\n                                      histogram_freq=histogram_freq,\n                                      write_images=True, write_grads=True,\n                                      embeddings_freq=1,\n                                      embeddings_layer_names=['dense_1'],\n                                      batch_size=5)]",
        "begin_line": 558,
        "end_line": 564,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_TensorBoard_multi_input_output#590",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_TensorBoard_multi_input_output(tmpdir)",
        "snippet": "def test_TensorBoard_multi_input_output(tmpdir):\n    np.random.seed(np.random.randint(1, 1e7))\n    filepath = str(tmpdir / 'logs')\n\n    (X_train, y_train), (X_test, y_test) = get_test_data(\n        num_train=train_samples,\n        num_test=test_samples,\n        input_shape=(input_dim,),\n        classification=True,\n        num_classes=num_classes)\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n\n    def data_generator(train):\n        if train:\n            max_batch_index = len(X_train) // batch_size\n        else:\n            max_batch_index = len(X_test) // batch_size\n        i = 0\n        while 1:\n            if train:\n                # simulate multi-input/output models\n                yield ([X_train[i * batch_size: (i + 1) * batch_size]] * 2,\n                       [y_train[i * batch_size: (i + 1) * batch_size]] * 2)\n            else:\n                yield ([X_test[i * batch_size: (i + 1) * batch_size]] * 2,\n                       [y_test[i * batch_size: (i + 1) * batch_size]] * 2)\n            i += 1\n            i = i % max_batch_index\n\n    inp1 = Input((input_dim,))\n    inp2 = Input((input_dim,))\n    inp = add([inp1, inp2])\n    hidden = Dense(num_hidden, activation='relu')(inp)\n    hidden = Dropout(0.1)(hidden)\n    output1 = Dense(num_classes, activation='softmax')(hidden)\n    output2 = Dense(num_classes, activation='softmax')(hidden)\n    model = Model(inputs=[inp1, inp2], outputs=[output1, output2])\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='sgd',\n                  metrics=['accuracy'])\n\n    # we must generate new callbacks for each test, as they aren't stateless\n    def callbacks_factory(histogram_freq):\n        return [callbacks.TensorBoard(log_dir=filepath,\n                                      histogram_freq=histogram_freq,\n                                      write_images=True, write_grads=True,\n                                      embeddings_freq=1,\n                                      embeddings_layer_names=['dense_1'],\n                                      batch_size=5)]\n\n    # fit without validation data\n    model.fit([X_train] * 2, [y_train] * 2, batch_size=batch_size,\n              callbacks=callbacks_factory(histogram_freq=0), epochs=3)\n\n    # fit with validation data and accuracy\n    model.fit([X_train] * 2, [y_train] * 2, batch_size=batch_size,\n              validation_data=([X_test] * 2, [y_test] * 2),\n              callbacks=callbacks_factory(histogram_freq=1), epochs=2)\n\n    # fit generator without validation data\n    model.fit_generator(data_generator(True), len(X_train), epochs=2,\n                        callbacks=callbacks_factory(histogram_freq=0))\n\n    # fit generator with validation data and accuracy\n    model.fit_generator(data_generator(True), len(X_train), epochs=2,\n                        validation_data=([X_test] * 2, [y_test] * 2),\n                        callbacks=callbacks_factory(histogram_freq=1))\n\n    assert os.path.isdir(filepath)\n    shutil.rmtree(filepath)\n    assert not tmpdir.listdir()",
        "begin_line": 590,
        "end_line": 661,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.data_generator#603",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.data_generator(train)",
        "snippet": "    def data_generator(train):\n        if train:\n            max_batch_index = len(X_train) // batch_size\n        else:\n            max_batch_index = len(X_test) // batch_size\n        i = 0\n        while 1:\n            if train:\n                # simulate multi-input/output models\n                yield ([X_train[i * batch_size: (i + 1) * batch_size]] * 2,\n                       [y_train[i * batch_size: (i + 1) * batch_size]] * 2)\n            else:\n                yield ([X_test[i * batch_size: (i + 1) * batch_size]] * 2,\n                       [y_test[i * batch_size: (i + 1) * batch_size]] * 2)\n            i += 1\n            i = i % max_batch_index",
        "begin_line": 603,
        "end_line": 618,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.callbacks_factory#633",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.callbacks_factory(histogram_freq)",
        "snippet": "    def callbacks_factory(histogram_freq):\n        return [callbacks.TensorBoard(log_dir=filepath,\n                                      histogram_freq=histogram_freq,\n                                      write_images=True, write_grads=True,\n                                      embeddings_freq=1,\n                                      embeddings_layer_names=['dense_1'],\n                                      batch_size=5)]",
        "begin_line": 633,
        "end_line": 639,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_TensorBoard_convnet#665",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_TensorBoard_convnet(tmpdir)",
        "snippet": "def test_TensorBoard_convnet(tmpdir):\n    np.random.seed(np.random.randint(1, 1e7))\n    filepath = str(tmpdir / 'logs')\n\n    input_shape = (16, 16, 3)\n    (x_train, y_train), (x_test, y_test) = get_test_data(num_train=500,\n                                                         num_test=200,\n                                                         input_shape=input_shape,\n                                                         classification=True,\n                                                         num_classes=num_classes)\n    y_train = np_utils.to_categorical(y_train)\n    y_test = np_utils.to_categorical(y_test)\n\n    model = Sequential([\n        Conv2D(filters=8, kernel_size=3,\n               activation='relu',\n               input_shape=input_shape),\n        MaxPooling2D(pool_size=2),\n        Conv2D(filters=4, kernel_size=(3, 3),\n               activation='relu', padding='same'),\n        GlobalAveragePooling2D(),\n        Dense(num_classes, activation='softmax')\n    ])\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='rmsprop',\n                  metrics=['accuracy'])\n    tsb = callbacks.TensorBoard(log_dir=filepath, histogram_freq=1,\n                                write_images=True, write_grads=True,\n                                batch_size=16)\n    cbks = [tsb]\n    model.summary()\n    history = model.fit(x_train, y_train, epochs=2, batch_size=16,\n                        validation_data=(x_test, y_test),\n                        callbacks=cbks,\n                        verbose=0)\n    assert os.path.isdir(filepath)\n    shutil.rmtree(filepath)\n    assert not tmpdir.listdir()",
        "begin_line": 665,
        "end_line": 702,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_CallbackValData#706",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_CallbackValData()",
        "snippet": "def test_CallbackValData():\n    np.random.seed(1337)\n    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,\n                                                         num_test=test_samples,\n                                                         input_shape=(input_dim,),\n                                                         classification=True,\n                                                         num_classes=num_classes)\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n    model = Sequential()\n    model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))\n    model.add(Dense(num_classes, activation='softmax'))\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='sgd',\n                  metrics=['accuracy'])\n\n    cbk = callbacks.LambdaCallback(on_train_end=lambda x: 1)\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=[cbk], epochs=1)\n\n    def data_generator(train):\n        if train:\n            max_batch_index = len(X_train) // batch_size\n        else:\n            max_batch_index = len(X_test) // batch_size\n        i = 0\n        while 1:\n            if train:\n                yield (X_train[i * batch_size: (i + 1) * batch_size],\n                       y_train[i * batch_size: (i + 1) * batch_size])\n            else:\n                yield (X_test[i * batch_size: (i + 1) * batch_size],\n                       y_test[i * batch_size: (i + 1) * batch_size])\n            i += 1\n            i = i % max_batch_index\n\n    cbk2 = callbacks.LambdaCallback(on_train_end=lambda x: 1)\n    model.fit_generator(data_generator(True), len(X_train), epochs=1,\n                        validation_data=(X_test, y_test),\n                        callbacks=[cbk2])\n\n    # callback validation data should always have x, y, and sample weights\n    assert len(cbk.validation_data) == len(cbk2.validation_data) == 3\n    assert cbk.validation_data[0] is cbk2.validation_data[0]\n    assert cbk.validation_data[1] is cbk2.validation_data[1]\n    assert cbk.validation_data[2].shape == cbk2.validation_data[2].shape",
        "begin_line": 706,
        "end_line": 751,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.data_generator#726",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.data_generator(train)",
        "snippet": "    def data_generator(train):\n        if train:\n            max_batch_index = len(X_train) // batch_size\n        else:\n            max_batch_index = len(X_test) // batch_size\n        i = 0\n        while 1:\n            if train:\n                yield (X_train[i * batch_size: (i + 1) * batch_size],\n                       y_train[i * batch_size: (i + 1) * batch_size])\n            else:\n                yield (X_test[i * batch_size: (i + 1) * batch_size],\n                       y_test[i * batch_size: (i + 1) * batch_size])\n            i += 1\n            i = i % max_batch_index",
        "begin_line": 726,
        "end_line": 740,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_LambdaCallback#755",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_LambdaCallback()",
        "snippet": "def test_LambdaCallback():\n    np.random.seed(1337)\n    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,\n                                                         num_test=test_samples,\n                                                         input_shape=(input_dim,),\n                                                         classification=True,\n                                                         num_classes=num_classes)\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n    model = Sequential()\n    model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))\n    model.add(Dense(num_classes, activation='softmax'))\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='sgd',\n                  metrics=['accuracy'])\n\n    # Start an arbitrary process that should run during model training and be terminated after training has completed.\n    def f():\n        while True:\n            pass\n\n    p = multiprocessing.Process(target=f)\n    p.start()\n    cleanup_callback = callbacks.LambdaCallback(on_train_end=lambda logs: p.terminate())\n\n    cbks = [cleanup_callback]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=5)\n    p.join()\n    assert not p.is_alive()",
        "begin_line": 755,
        "end_line": 784,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.f#772",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.f()",
        "snippet": "    def f():\n        while True:\n            pass",
        "begin_line": 772,
        "end_line": 774,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.test_TensorBoard_with_ReduceLROnPlateau#788",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.test_TensorBoard_with_ReduceLROnPlateau(tmpdir)",
        "snippet": "def test_TensorBoard_with_ReduceLROnPlateau(tmpdir):\n    import shutil\n    np.random.seed(np.random.randint(1, 1e7))\n    filepath = str(tmpdir / 'logs')\n\n    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,\n                                                         num_test=test_samples,\n                                                         input_shape=(input_dim,),\n                                                         classification=True,\n                                                         num_classes=num_classes)\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n\n    model = Sequential()\n    model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))\n    model.add(Dense(num_classes, activation='softmax'))\n    model.compile(loss='binary_crossentropy',\n                  optimizer='sgd',\n                  metrics=['accuracy'])\n\n    cbks = [\n        callbacks.ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.5,\n            patience=4,\n            verbose=1),\n        callbacks.TensorBoard(\n            log_dir=filepath)]\n\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=2)\n\n    assert os.path.isdir(filepath)\n    shutil.rmtree(filepath)\n    assert not tmpdir.listdir()",
        "begin_line": 788,
        "end_line": 822,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "tests.keras.test_callbacks.tests_RemoteMonitor#826",
        "src_path": "tests/keras/test_callbacks.py",
        "class_name": "tests.keras.test_callbacks",
        "signature": "tests.keras.test_callbacks.tests_RemoteMonitor()",
        "snippet": "def tests_RemoteMonitor():\n    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,\n                                                         num_test=test_samples,\n                                                         input_shape=(input_dim,),\n                                                         classification=True,\n                                                         num_classes=num_classes)\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n    model = Sequential()\n    model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))\n    model.add(Dense(num_classes, activation='softmax'))\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='rmsprop',\n                  metrics=['accuracy'])\n    cbks = [callbacks.RemoteMonitor()]\n\n    with patch('requests.post'):\n        model.fit(X_train, y_train, batch_size=batch_size,\n                  validation_data=(X_test, y_test), callbacks=cbks, epochs=1)",
        "begin_line": 826,
        "end_line": 844,
        "comment": "",
        "is_bug": false
    }
]