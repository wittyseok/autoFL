[
    {
        "name": "spacy.tests.conftest.pytest_runtest_setup#12",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.pytest_runtest_setup(item)",
        "snippet": "def pytest_runtest_setup(item):\n    def getopt(opt):\n        # When using 'pytest --pyargs spacy' to test an installed copy of\n        # spacy, pytest skips running our pytest_addoption() hook. Later, when\n        # we call getoption(), pytest raises an error, because it doesn't\n        # recognize the option we're asking about. To avoid this, we need to\n        # pass a default value. We default to False, i.e., we act like all the\n        # options weren't given.\n        return item.config.getoption(\"--%s\" % opt, False)\n\n    for opt in [\"slow\"]:\n        if opt in item.keywords and not getopt(opt):\n            pytest.skip(\"need --%s option to run\" % opt)",
        "begin_line": 12,
        "end_line": 24,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.getopt#13",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.getopt(opt)",
        "snippet": "    def getopt(opt):\n        # When using 'pytest --pyargs spacy' to test an installed copy of\n        # spacy, pytest skips running our pytest_addoption() hook. Later, when\n        # we call getoption(), pytest raises an error, because it doesn't\n        # recognize the option we're asking about. To avoid this, we need to\n        # pass a default value. We default to False, i.e., we act like all the\n        # options weren't given.\n        return item.config.getoption(\"--%s\" % opt, False)",
        "begin_line": 13,
        "end_line": 20,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.tokenizer#31",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.tokenizer()",
        "snippet": "def tokenizer():\n    return get_lang_class(\"xx\").Defaults.create_tokenizer()",
        "begin_line": 31,
        "end_line": 32,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.ar_tokenizer#36",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.ar_tokenizer()",
        "snippet": "def ar_tokenizer():\n    return get_lang_class(\"ar\").Defaults.create_tokenizer()",
        "begin_line": 36,
        "end_line": 37,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.bn_tokenizer#41",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.bn_tokenizer()",
        "snippet": "def bn_tokenizer():\n    return get_lang_class(\"bn\").Defaults.create_tokenizer()",
        "begin_line": 41,
        "end_line": 42,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.ca_tokenizer#46",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.ca_tokenizer()",
        "snippet": "def ca_tokenizer():\n    return get_lang_class(\"ca\").Defaults.create_tokenizer()",
        "begin_line": 46,
        "end_line": 47,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.da_tokenizer#51",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.da_tokenizer()",
        "snippet": "def da_tokenizer():\n    return get_lang_class(\"da\").Defaults.create_tokenizer()",
        "begin_line": 51,
        "end_line": 52,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.de_tokenizer#56",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.de_tokenizer()",
        "snippet": "def de_tokenizer():\n    return get_lang_class(\"de\").Defaults.create_tokenizer()",
        "begin_line": 56,
        "end_line": 57,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.el_tokenizer#61",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.el_tokenizer()",
        "snippet": "def el_tokenizer():\n    return get_lang_class(\"el\").Defaults.create_tokenizer()",
        "begin_line": 61,
        "end_line": 62,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.en_tokenizer#66",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.en_tokenizer()",
        "snippet": "def en_tokenizer():\n    return get_lang_class(\"en\").Defaults.create_tokenizer()",
        "begin_line": 66,
        "end_line": 67,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.en_vocab#71",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.en_vocab()",
        "snippet": "def en_vocab():\n    return get_lang_class(\"en\").Defaults.create_vocab()",
        "begin_line": 71,
        "end_line": 72,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.es_tokenizer#82",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.es_tokenizer()",
        "snippet": "def es_tokenizer():\n    return get_lang_class(\"es\").Defaults.create_tokenizer()",
        "begin_line": 82,
        "end_line": 83,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.fi_tokenizer#87",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.fi_tokenizer()",
        "snippet": "def fi_tokenizer():\n    return get_lang_class(\"fi\").Defaults.create_tokenizer()",
        "begin_line": 87,
        "end_line": 88,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.fr_tokenizer#92",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.fr_tokenizer()",
        "snippet": "def fr_tokenizer():\n    return get_lang_class(\"fr\").Defaults.create_tokenizer()",
        "begin_line": 92,
        "end_line": 93,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.ga_tokenizer#97",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.ga_tokenizer()",
        "snippet": "def ga_tokenizer():\n    return get_lang_class(\"ga\").Defaults.create_tokenizer()",
        "begin_line": 97,
        "end_line": 98,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.he_tokenizer#102",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.he_tokenizer()",
        "snippet": "def he_tokenizer():\n    return get_lang_class(\"he\").Defaults.create_tokenizer()",
        "begin_line": 102,
        "end_line": 103,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.hu_tokenizer#112",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.hu_tokenizer()",
        "snippet": "def hu_tokenizer():\n    return get_lang_class(\"hu\").Defaults.create_tokenizer()",
        "begin_line": 112,
        "end_line": 113,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.id_tokenizer#117",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.id_tokenizer()",
        "snippet": "def id_tokenizer():\n    return get_lang_class(\"id\").Defaults.create_tokenizer()",
        "begin_line": 117,
        "end_line": 118,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.it_tokenizer#122",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.it_tokenizer()",
        "snippet": "def it_tokenizer():\n    return get_lang_class(\"it\").Defaults.create_tokenizer()",
        "begin_line": 122,
        "end_line": 123,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.lt_tokenizer#139",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.lt_tokenizer()",
        "snippet": "def lt_tokenizer():\n    return get_lang_class(\"lt\").Defaults.create_tokenizer()",
        "begin_line": 139,
        "end_line": 140,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.nb_tokenizer#144",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.nb_tokenizer()",
        "snippet": "def nb_tokenizer():\n    return get_lang_class(\"nb\").Defaults.create_tokenizer()",
        "begin_line": 144,
        "end_line": 145,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.nl_tokenizer#149",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.nl_tokenizer()",
        "snippet": "def nl_tokenizer():\n    return get_lang_class(\"nl\").Defaults.create_tokenizer()",
        "begin_line": 149,
        "end_line": 150,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.pl_tokenizer#154",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.pl_tokenizer()",
        "snippet": "def pl_tokenizer():\n    return get_lang_class(\"pl\").Defaults.create_tokenizer()",
        "begin_line": 154,
        "end_line": 155,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.ro_tokenizer#164",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.ro_tokenizer()",
        "snippet": "def ro_tokenizer():\n    return get_lang_class(\"ro\").Defaults.create_tokenizer()",
        "begin_line": 164,
        "end_line": 165,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.sr_tokenizer#181",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.sr_tokenizer()",
        "snippet": "def sr_tokenizer():\n    return get_lang_class(\"sr\").Defaults.create_tokenizer()",
        "begin_line": 181,
        "end_line": 182,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.sv_tokenizer#186",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.sv_tokenizer()",
        "snippet": "def sv_tokenizer():\n    return get_lang_class(\"sv\").Defaults.create_tokenizer()",
        "begin_line": 186,
        "end_line": 187,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.tt_tokenizer#202",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.tt_tokenizer()",
        "snippet": "def tt_tokenizer():\n    return get_lang_class(\"tt\").Defaults.create_tokenizer()",
        "begin_line": 202,
        "end_line": 203,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.ur_tokenizer#214",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.ur_tokenizer()",
        "snippet": "def ur_tokenizer():\n    return get_lang_class(\"ur\").Defaults.create_tokenizer()",
        "begin_line": 214,
        "end_line": 215,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_logic.text#32",
        "src_path": "spacy/tests/matcher/test_matcher_logic.py",
        "class_name": "spacy.tests.matcher.test_matcher_logic",
        "signature": "spacy.tests.matcher.test_matcher_logic.text()",
        "snippet": "def text():\n    return \"(ABBAAAAAB).\"",
        "begin_line": 32,
        "end_line": 33,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_logic.doc#37",
        "src_path": "spacy/tests/matcher/test_matcher_logic.py",
        "class_name": "spacy.tests.matcher.test_matcher_logic",
        "signature": "spacy.tests.matcher.test_matcher_logic.doc(en_tokenizer, text)",
        "snippet": "def doc(en_tokenizer, text):\n    doc = en_tokenizer(\" \".join(text))\n    return doc",
        "begin_line": 37,
        "end_line": 39,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_logic.test_greedy_matching#52",
        "src_path": "spacy/tests/matcher/test_matcher_logic.py",
        "class_name": "spacy.tests.matcher.test_matcher_logic",
        "signature": "spacy.tests.matcher.test_matcher_logic.test_greedy_matching(doc, text, pattern, re_pattern)",
        "snippet": "def test_greedy_matching(doc, text, pattern, re_pattern):\n    \"\"\"Test that the greedy matching behavior of the * op is consistant with\n    other re implementations.\"\"\"\n    matcher = Matcher(doc.vocab)\n    matcher.add(re_pattern, None, pattern)\n    matches = matcher(doc)\n    re_matches = [m.span() for m in re.finditer(re_pattern, text)]\n    for match, re_match in zip(matches, re_matches):\n        assert match[1:] == re_match",
        "begin_line": 52,
        "end_line": 60,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_logic.test_match_consuming#74",
        "src_path": "spacy/tests/matcher/test_matcher_logic.py",
        "class_name": "spacy.tests.matcher.test_matcher_logic",
        "signature": "spacy.tests.matcher.test_matcher_logic.test_match_consuming(doc, text, pattern, re_pattern)",
        "snippet": "def test_match_consuming(doc, text, pattern, re_pattern):\n    \"\"\"Test that matcher.__call__ consumes tokens on a match similar to\n    re.findall.\"\"\"\n    matcher = Matcher(doc.vocab)\n    matcher.add(re_pattern, None, pattern)\n    matches = matcher(doc)\n    re_matches = [m.span() for m in re.finditer(re_pattern, text)]\n    assert len(matches) == len(re_matches)",
        "begin_line": 74,
        "end_line": 81,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_logic.test_operator_combos#84",
        "src_path": "spacy/tests/matcher/test_matcher_logic.py",
        "class_name": "spacy.tests.matcher.test_matcher_logic",
        "signature": "spacy.tests.matcher.test_matcher_logic.test_operator_combos(en_vocab)",
        "snippet": "def test_operator_combos(en_vocab):\n    cases = [\n        (\"aaab\", \"a a a b\", True),\n        (\"aaab\", \"a+ b\", True),\n        (\"aaab\", \"a+ a+ b\", True),\n        (\"aaab\", \"a+ a+ a b\", True),\n        (\"aaab\", \"a+ a+ a+ b\", True),\n        (\"aaab\", \"a+ a a b\", True),\n        (\"aaab\", \"a+ a a\", True),\n        (\"aaab\", \"a+\", True),\n        (\"aaa\", \"a+ b\", False),\n        (\"aaa\", \"a+ a+ b\", False),\n        (\"aaa\", \"a+ a+ a+ b\", False),\n        (\"aaa\", \"a+ a b\", False),\n        (\"aaa\", \"a+ a a b\", False),\n        (\"aaab\", \"a+ a a\", True),\n        (\"aaab\", \"a+\", True),\n        (\"aaab\", \"a+ a b\", True),\n    ]\n    for string, pattern_str, result in cases:\n        matcher = Matcher(en_vocab)\n        doc = Doc(matcher.vocab, words=list(string))\n        pattern = []\n        for part in pattern_str.split():\n            if part.endswith(\"+\"):\n                pattern.append({\"ORTH\": part[0], \"OP\": \"+\"})\n            else:\n                pattern.append({\"ORTH\": part})\n        matcher.add(\"PATTERN\", None, pattern)\n        matches = matcher(doc)\n        if result:\n            assert matches, (string, pattern_str)\n        else:\n            assert not matches, (string, pattern_str)",
        "begin_line": 84,
        "end_line": 117,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_logic.test_matcher_end_zero_plus#120",
        "src_path": "spacy/tests/matcher/test_matcher_logic.py",
        "class_name": "spacy.tests.matcher.test_matcher_logic",
        "signature": "spacy.tests.matcher.test_matcher_logic.test_matcher_end_zero_plus(en_vocab)",
        "snippet": "def test_matcher_end_zero_plus(en_vocab):\n    \"\"\"Test matcher works when patterns end with * operator. (issue 1450)\"\"\"\n    matcher = Matcher(en_vocab)\n    pattern = [{\"ORTH\": \"a\"}, {\"ORTH\": \"b\", \"OP\": \"*\"}]\n    matcher.add(\"TSTEND\", None, pattern)\n    nlp = lambda string: Doc(matcher.vocab, words=string.split())\n    assert len(matcher(nlp(\"a\"))) == 1\n    assert len(matcher(nlp(\"a b\"))) == 2\n    assert len(matcher(nlp(\"a c\"))) == 1\n    assert len(matcher(nlp(\"a b c\"))) == 2\n    assert len(matcher(nlp(\"a b b c\"))) == 3\n    assert len(matcher(nlp(\"a b b\"))) == 3",
        "begin_line": 120,
        "end_line": 131,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_logic.test_matcher_sets_return_correct_tokens#134",
        "src_path": "spacy/tests/matcher/test_matcher_logic.py",
        "class_name": "spacy.tests.matcher.test_matcher_logic",
        "signature": "spacy.tests.matcher.test_matcher_logic.test_matcher_sets_return_correct_tokens(en_vocab)",
        "snippet": "def test_matcher_sets_return_correct_tokens(en_vocab):\n    matcher = Matcher(en_vocab)\n    patterns = [\n        [{\"LOWER\": {\"IN\": [\"zero\"]}}],\n        [{\"LOWER\": {\"IN\": [\"one\"]}}],\n        [{\"LOWER\": {\"IN\": [\"two\"]}}],\n    ]\n    matcher.add(\"TEST\", None, *patterns)\n    doc = Doc(en_vocab, words=\"zero one two three\".split())\n    matches = matcher(doc)\n    texts = [Span(doc, s, e, label=L).text for L, s, e in matches]\n    assert texts == [\"zero\", \"one\", \"two\"]",
        "begin_line": 134,
        "end_line": 145,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_logic.test_matcher_remove#148",
        "src_path": "spacy/tests/matcher/test_matcher_logic.py",
        "class_name": "spacy.tests.matcher.test_matcher_logic",
        "signature": "spacy.tests.matcher.test_matcher_logic.test_matcher_remove(en_vocab)",
        "snippet": "def test_matcher_remove(en_vocab):\n    matcher = Matcher(en_vocab)\n    pattern = [{\"ORTH\": \"test\"}, {\"OP\": \"?\"}]\n    assert len(matcher) == 0\n    matcher.add(\"Rule\", None, pattern)\n    assert \"Rule\" in matcher\n\n    # removing once should work\n    matcher.remove(\"Rule\")\n\n    # removing again should throw an error\n    with pytest.raises(ValueError):\n        matcher.remove(\"Rule\")",
        "begin_line": 148,
        "end_line": 160,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.util.make_tempdir#23",
        "src_path": "spacy/tests/util.py",
        "class_name": "spacy.tests.util",
        "signature": "spacy.tests.util.make_tempdir()",
        "snippet": "def make_tempdir():\n    d = Path(tempfile.mkdtemp())\n    yield d\n    shutil.rmtree(path2str(d))",
        "begin_line": 23,
        "end_line": 26,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.util.get_doc#29",
        "src_path": "spacy/tests/util.py",
        "class_name": "spacy.tests.util",
        "signature": "spacy.tests.util.get_doc(vocab, words=[], pos=None, heads=None, deps=None, tags=None, ents=None)",
        "snippet": "def get_doc(vocab, words=[], pos=None, heads=None, deps=None, tags=None, ents=None):\n    \"\"\"Create Doc object from given vocab, words and annotations.\"\"\"\n    pos = pos or [\"\"] * len(words)\n    tags = tags or [\"\"] * len(words)\n    heads = heads or [0] * len(words)\n    deps = deps or [\"\"] * len(words)\n    for value in deps + tags + pos:\n        vocab.strings.add(value)\n\n    doc = Doc(vocab, words=words)\n    attrs = doc.to_array([POS, HEAD, DEP])\n    for i, (p, head, dep) in enumerate(zip(pos, heads, deps)):\n        attrs[i, 0] = doc.vocab.strings[p]\n        attrs[i, 1] = head\n        attrs[i, 2] = doc.vocab.strings[dep]\n    doc.from_array([POS, HEAD, DEP], attrs)\n    if ents:\n        doc.ents = [\n            Span(doc, start, end, label=doc.vocab.strings[label])\n            for start, end, label in ents\n        ]\n    if tags:\n        for token in doc:\n            token.tag_ = tags[token.i]\n    return doc",
        "begin_line": 29,
        "end_line": 53,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.util.add_vecs_to_vocab#68",
        "src_path": "spacy/tests/util.py",
        "class_name": "spacy.tests.util",
        "signature": "spacy.tests.util.add_vecs_to_vocab(vocab, vectors)",
        "snippet": "def add_vecs_to_vocab(vocab, vectors):\n    \"\"\"Add list of vector tuples to given vocab. All vectors need to have the\n    same length. Format: [(\"text\", [1, 2, 3])]\"\"\"\n    length = len(vectors[0][1])\n    vocab.reset_vectors(width=length)\n    for word, vec in vectors:\n        vocab.set_vector(word, vector=vec)\n    return vocab",
        "begin_line": 68,
        "end_line": 75,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.util.get_cosine#78",
        "src_path": "spacy/tests/util.py",
        "class_name": "spacy.tests.util",
        "signature": "spacy.tests.util.get_cosine(vec1, vec2)",
        "snippet": "def get_cosine(vec1, vec2):\n    \"\"\"Get cosine for two given vectors\"\"\"\n    return numpy.dot(vec1, vec2) / (numpy.linalg.norm(vec1) * numpy.linalg.norm(vec2))",
        "begin_line": 78,
        "end_line": 80,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.util.assert_docs_equal#83",
        "src_path": "spacy/tests/util.py",
        "class_name": "spacy.tests.util",
        "signature": "spacy.tests.util.assert_docs_equal(doc1, doc2)",
        "snippet": "def assert_docs_equal(doc1, doc2):\n    \"\"\"Compare two Doc objects and assert that they're equal. Tests for tokens,\n    tags, dependencies and entities.\"\"\"\n    assert [t.orth for t in doc1] == [t.orth for t in doc2]\n\n    assert [t.pos for t in doc1] == [t.pos for t in doc2]\n    assert [t.tag for t in doc1] == [t.tag for t in doc2]\n\n    assert [t.head.i for t in doc1] == [t.head.i for t in doc2]\n    assert [t.dep for t in doc1] == [t.dep for t in doc2]\n    if doc1.is_parsed and doc2.is_parsed:\n        assert [s for s in doc1.sents] == [s for s in doc2.sents]\n\n    assert [t.ent_type for t in doc1] == [t.ent_type for t in doc2]\n    assert [t.ent_iob for t in doc1] == [t.ent_iob for t in doc2]\n    assert [ent for ent in doc1.ents] == [ent for ent in doc2.ents]",
        "begin_line": 83,
        "end_line": 98,
        "comment": "",
        "is_bug": false
    }
]