[
    {
        "name": "scrapy.utils.deprecate.create_deprecated_class#15",
        "src_path": "scrapy/utils/deprecate.py",
        "class_name": "scrapy.utils.deprecate",
        "signature": "scrapy.utils.deprecate.create_deprecated_class(name, new_class, clsdict=None, warn_category=ScrapyDeprecationWarning, warn_once=True, old_class_path=None, new_class_path=None, subclass_warn_message='{cls} inherits from deprecated class {old}, please inherit from {new}.', instance_warn_message='{cls} is deprecated, instantiate {new} instead.')",
        "snippet": "def create_deprecated_class(name, new_class, clsdict=None,\n                            warn_category=ScrapyDeprecationWarning,\n                            warn_once=True,\n                            old_class_path=None,\n                            new_class_path=None,\n                            subclass_warn_message=\"{cls} inherits from \"\\\n                                    \"deprecated class {old}, please inherit \"\\\n                                    \"from {new}.\",\n                            instance_warn_message=\"{cls} is deprecated, \"\\\n                                    \"instantiate {new} instead.\"):\n    \"\"\"\n    Return a \"deprecated\" class that causes its subclasses to issue a warning.\n    Subclasses of ``new_class`` are considered subclasses of this class.\n    It also warns when the deprecated class is instantiated, but do not when\n    its subclasses are instantiated.\n\n    It can be used to rename a base class in a library. For example, if we\n    have\n\n        class OldName(SomeClass):\n            # ...\n\n    and we want to rename it to NewName, we can do the following::\n\n        class NewName(SomeClass):\n            # ...\n\n        OldName = create_deprecated_class('OldName', NewName)\n\n    Then, if user class inherits from OldName, warning is issued. Also, if\n    some code uses ``issubclass(sub, OldName)`` or ``isinstance(sub(), OldName)``\n    checks they'll still return True if sub is a subclass of NewName instead of\n    OldName.\n    \"\"\"\n\n    class DeprecatedClass(new_class.__class__):\n\n        deprecated_class = None\n        warned_on_subclass = False\n\n        def __new__(metacls, name, bases, clsdict_):\n            cls = super(DeprecatedClass, metacls).__new__(metacls, name, bases, clsdict_)\n            if metacls.deprecated_class is None:\n                metacls.deprecated_class = cls\n            return cls\n\n        def __init__(cls, name, bases, clsdict_):\n            meta = cls.__class__\n            old = meta.deprecated_class\n            if old in bases and not (warn_once and meta.warned_on_subclass):\n                meta.warned_on_subclass = True\n                msg = subclass_warn_message.format(cls=_clspath(cls),\n                                                   old=_clspath(old, old_class_path),\n                                                   new=_clspath(new_class, new_class_path))\n                if warn_once:\n                    msg += ' (warning only on first subclass, there may be others)'\n                warnings.warn(msg, warn_category, stacklevel=2)\n            super(DeprecatedClass, cls).__init__(name, bases, clsdict_)\n\n        # see http://www.python.org/dev/peps/pep-3119/#overloading-isinstance-and-issubclass\n        # and http://docs.python.org/2/reference/datamodel.html#customizing-instance-and-subclass-checks\n        # for implementation details\n        def __instancecheck__(cls, inst):\n            return any(cls.__subclasscheck__(c)\n                       for c in {type(inst), inst.__class__})\n\n        def __subclasscheck__(cls, sub):\n            if cls is not DeprecatedClass.deprecated_class:\n                # we should do the magic only if second `issubclass` argument\n                # is the deprecated class itself - subclasses of the\n                # deprecated class should not use custom `__subclasscheck__`\n                # method.\n                return super(DeprecatedClass, cls).__subclasscheck__(sub)\n\n            if not inspect.isclass(sub):\n                raise TypeError(\"issubclass() arg 1 must be a class\")\n\n            mro = getattr(sub, '__mro__', ())\n            return any(c in {cls, new_class} for c in mro)\n\n        def __call__(cls, *args, **kwargs):\n            old = DeprecatedClass.deprecated_class\n            if cls is old:\n                msg = instance_warn_message.format(cls=_clspath(cls, old_class_path),\n                                                   new=_clspath(new_class, new_class_path))\n                warnings.warn(msg, warn_category, stacklevel=2)\n            return super(DeprecatedClass, cls).__call__(*args, **kwargs)\n\n    deprecated_cls = DeprecatedClass(name, (new_class,), clsdict or {})\n\n    try:\n        frm = inspect.stack()[1]\n        parent_module = inspect.getmodule(frm[0])\n        if parent_module is not None:\n            deprecated_cls.__module__ = parent_module.__name__\n    except Exception as e:\n        # Sometimes inspect.stack() fails (e.g. when the first import of\n        # deprecated class is in jinja2 template). __module__ attribute is not\n        # important enough to raise an exception as users may be unable\n        # to fix inspect.stack() errors.\n        warnings.warn(\"Error detecting parent module: %r\" % e)\n\n    return deprecated_cls",
        "begin_line": 15,
        "end_line": 117,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.deprecate.DeprecatedClass.create_deprecated_class#15",
        "src_path": "scrapy/utils/deprecate.py",
        "class_name": "scrapy.utils.deprecate.DeprecatedClass",
        "signature": "scrapy.utils.deprecate.DeprecatedClass.create_deprecated_class(name, new_class, clsdict=None, warn_category=ScrapyDeprecationWarning, warn_once=True, old_class_path=None, new_class_path=None, subclass_warn_message='{cls} inherits from deprecated class {old}, please inherit from {new}.', instance_warn_message='{cls} is deprecated, instantiate {new} instead.')",
        "snippet": "def create_deprecated_class(name, new_class, clsdict=None,\n                            warn_category=ScrapyDeprecationWarning,\n                            warn_once=True,\n                            old_class_path=None,\n                            new_class_path=None,\n                            subclass_warn_message=\"{cls} inherits from \"\\\n                                    \"deprecated class {old}, please inherit \"\\\n                                    \"from {new}.\",\n                            instance_warn_message=\"{cls} is deprecated, \"\\\n                                    \"instantiate {new} instead.\"):\n    \"\"\"\n    Return a \"deprecated\" class that causes its subclasses to issue a warning.\n    Subclasses of ``new_class`` are considered subclasses of this class.\n    It also warns when the deprecated class is instantiated, but do not when\n    its subclasses are instantiated.\n\n    It can be used to rename a base class in a library. For example, if we\n    have\n\n        class OldName(SomeClass):\n            # ...\n\n    and we want to rename it to NewName, we can do the following::\n\n        class NewName(SomeClass):\n            # ...\n\n        OldName = create_deprecated_class('OldName', NewName)\n\n    Then, if user class inherits from OldName, warning is issued. Also, if\n    some code uses ``issubclass(sub, OldName)`` or ``isinstance(sub(), OldName)``\n    checks they'll still return True if sub is a subclass of NewName instead of\n    OldName.\n    \"\"\"\n\n    class DeprecatedClass(new_class.__class__):\n\n        deprecated_class = None\n        warned_on_subclass = False\n\n        def __new__(metacls, name, bases, clsdict_):\n            cls = super(DeprecatedClass, metacls).__new__(metacls, name, bases, clsdict_)\n            if metacls.deprecated_class is None:\n                metacls.deprecated_class = cls\n            return cls\n\n        def __init__(cls, name, bases, clsdict_):\n            meta = cls.__class__\n            old = meta.deprecated_class\n            if old in bases and not (warn_once and meta.warned_on_subclass):\n                meta.warned_on_subclass = True\n                msg = subclass_warn_message.format(cls=_clspath(cls),\n                                                   old=_clspath(old, old_class_path),\n                                                   new=_clspath(new_class, new_class_path))\n                if warn_once:\n                    msg += ' (warning only on first subclass, there may be others)'\n                warnings.warn(msg, warn_category, stacklevel=2)\n            super(DeprecatedClass, cls).__init__(name, bases, clsdict_)\n\n        # see http://www.python.org/dev/peps/pep-3119/#overloading-isinstance-and-issubclass\n        # and http://docs.python.org/2/reference/datamodel.html#customizing-instance-and-subclass-checks\n        # for implementation details\n        def __instancecheck__(cls, inst):\n            return any(cls.__subclasscheck__(c)\n                       for c in {type(inst), inst.__class__})\n\n        def __subclasscheck__(cls, sub):\n            if cls is not DeprecatedClass.deprecated_class:\n                # we should do the magic only if second `issubclass` argument\n                # is the deprecated class itself - subclasses of the\n                # deprecated class should not use custom `__subclasscheck__`\n                # method.\n                return super(DeprecatedClass, cls).__subclasscheck__(sub)\n\n            if not inspect.isclass(sub):\n                raise TypeError(\"issubclass() arg 1 must be a class\")\n\n            mro = getattr(sub, '__mro__', ())\n            return any(c in {cls, new_class} for c in mro)\n\n        def __call__(cls, *args, **kwargs):\n            old = DeprecatedClass.deprecated_class\n            if cls is old:\n                msg = instance_warn_message.format(cls=_clspath(cls, old_class_path),\n                                                   new=_clspath(new_class, new_class_path))\n                warnings.warn(msg, warn_category, stacklevel=2)\n            return super(DeprecatedClass, cls).__call__(*args, **kwargs)\n\n    deprecated_cls = DeprecatedClass(name, (new_class,), clsdict or {})\n\n    try:\n        frm = inspect.stack()[1]\n        parent_module = inspect.getmodule(frm[0])\n        if parent_module is not None:\n            deprecated_cls.__module__ = parent_module.__name__\n    except Exception as e:\n        # Sometimes inspect.stack() fails (e.g. when the first import of\n        # deprecated class is in jinja2 template). __module__ attribute is not\n        # important enough to raise an exception as users may be unable\n        # to fix inspect.stack() errors.\n        warnings.warn(\"Error detecting parent module: %r\" % e)\n\n    return deprecated_cls",
        "begin_line": 15,
        "end_line": 117,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0010775862068965517,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.deprecate.DeprecatedClass.__new__#55",
        "src_path": "scrapy/utils/deprecate.py",
        "class_name": "scrapy.utils.deprecate.DeprecatedClass",
        "signature": "scrapy.utils.deprecate.DeprecatedClass.__new__(metacls, name, bases, clsdict_)",
        "snippet": "        def __new__(metacls, name, bases, clsdict_):\n            cls = super(DeprecatedClass, metacls).__new__(metacls, name, bases, clsdict_)\n            if metacls.deprecated_class is None:\n                metacls.deprecated_class = cls\n            return cls",
        "begin_line": 55,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0010775862068965517,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.deprecate.DeprecatedClass.__init__#61",
        "src_path": "scrapy/utils/deprecate.py",
        "class_name": "scrapy.utils.deprecate.DeprecatedClass",
        "signature": "scrapy.utils.deprecate.DeprecatedClass.__init__(cls, name, bases, clsdict_)",
        "snippet": "        def __init__(cls, name, bases, clsdict_):\n            meta = cls.__class__\n            old = meta.deprecated_class\n            if old in bases and not (warn_once and meta.warned_on_subclass):\n                meta.warned_on_subclass = True\n                msg = subclass_warn_message.format(cls=_clspath(cls),\n                                                   old=_clspath(old, old_class_path),\n                                                   new=_clspath(new_class, new_class_path))\n                if warn_once:\n                    msg += ' (warning only on first subclass, there may be others)'\n                warnings.warn(msg, warn_category, stacklevel=2)\n            super(DeprecatedClass, cls).__init__(name, bases, clsdict_)",
        "begin_line": 61,
        "end_line": 72,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0011273957158962795,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.deprecate.DeprecatedClass.__instancecheck__#77",
        "src_path": "scrapy/utils/deprecate.py",
        "class_name": "scrapy.utils.deprecate.DeprecatedClass",
        "signature": "scrapy.utils.deprecate.DeprecatedClass.__instancecheck__(cls, inst)",
        "snippet": "        def __instancecheck__(cls, inst):\n            return any(cls.__subclasscheck__(c)\n                       for c in {type(inst), inst.__class__})",
        "begin_line": 77,
        "end_line": 79,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.deprecate.DeprecatedClass.__subclasscheck__#81",
        "src_path": "scrapy/utils/deprecate.py",
        "class_name": "scrapy.utils.deprecate.DeprecatedClass",
        "signature": "scrapy.utils.deprecate.DeprecatedClass.__subclasscheck__(cls, sub)",
        "snippet": "        def __subclasscheck__(cls, sub):\n            if cls is not DeprecatedClass.deprecated_class:\n                # we should do the magic only if second `issubclass` argument\n                # is the deprecated class itself - subclasses of the\n                # deprecated class should not use custom `__subclasscheck__`\n                # method.\n                return super(DeprecatedClass, cls).__subclasscheck__(sub)\n\n            if not inspect.isclass(sub):\n                raise TypeError(\"issubclass() arg 1 must be a class\")\n\n            mro = getattr(sub, '__mro__', ())\n            return any(c in {cls, new_class} for c in mro)",
        "begin_line": 81,
        "end_line": 93,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.deprecate.DeprecatedClass.__call__#95",
        "src_path": "scrapy/utils/deprecate.py",
        "class_name": "scrapy.utils.deprecate.DeprecatedClass",
        "signature": "scrapy.utils.deprecate.DeprecatedClass.__call__(cls, *args, **kwargs)",
        "snippet": "        def __call__(cls, *args, **kwargs):\n            old = DeprecatedClass.deprecated_class\n            if cls is old:\n                msg = instance_warn_message.format(cls=_clspath(cls, old_class_path),\n                                                   new=_clspath(new_class, new_class_path))\n                warnings.warn(msg, warn_category, stacklevel=2)\n            return super(DeprecatedClass, cls).__call__(*args, **kwargs)",
        "begin_line": 95,
        "end_line": 101,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.deprecate._clspath#120",
        "src_path": "scrapy/utils/deprecate.py",
        "class_name": "scrapy.utils.deprecate",
        "signature": "scrapy.utils.deprecate._clspath(cls, forced=None)",
        "snippet": "def _clspath(cls, forced=None):\n    if forced is not None:\n        return forced\n    return '{}.{}'.format(cls.__module__, cls.__name__)",
        "begin_line": 120,
        "end_line": 123,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0024630541871921183,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.spiderloader.SpiderLoader.__init__#17",
        "src_path": "scrapy/spiderloader.py",
        "class_name": "scrapy.spiderloader.SpiderLoader",
        "signature": "scrapy.spiderloader.SpiderLoader.__init__(self, settings)",
        "snippet": "    def __init__(self, settings):\n        self.spider_modules = settings.getlist('SPIDER_MODULES')\n        self._spiders = {}\n        for name in self.spider_modules:\n            for module in walk_modules(name):\n                self._load_spiders(module)",
        "begin_line": 17,
        "end_line": 22,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.spiderloader.SpiderLoader._load_spiders#24",
        "src_path": "scrapy/spiderloader.py",
        "class_name": "scrapy.spiderloader.SpiderLoader",
        "signature": "scrapy.spiderloader.SpiderLoader._load_spiders(self, module)",
        "snippet": "    def _load_spiders(self, module):\n        for spcls in iter_spider_classes(module):\n            self._spiders[spcls.name] = spcls",
        "begin_line": 24,
        "end_line": 26,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.spiderloader.SpiderLoader.from_settings#29",
        "src_path": "scrapy/spiderloader.py",
        "class_name": "scrapy.spiderloader.SpiderLoader",
        "signature": "scrapy.spiderloader.SpiderLoader.from_settings(cls, settings)",
        "snippet": "    def from_settings(cls, settings):\n        return cls(settings)",
        "begin_line": 29,
        "end_line": 30,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.spiderloader.SpiderLoader.load#32",
        "src_path": "scrapy/spiderloader.py",
        "class_name": "scrapy.spiderloader.SpiderLoader",
        "signature": "scrapy.spiderloader.SpiderLoader.load(self, spider_name)",
        "snippet": "    def load(self, spider_name):\n        \"\"\"\n        Return the Spider class for the given spider name. If the spider\n        name is not found, raise a KeyError.\n        \"\"\"\n        try:\n            return self._spiders[spider_name]\n        except KeyError:\n            raise KeyError(\"Spider not found: {}\".format(spider_name))",
        "begin_line": 32,
        "end_line": 40,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.spiderloader.SpiderLoader.find_by_request#42",
        "src_path": "scrapy/spiderloader.py",
        "class_name": "scrapy.spiderloader.SpiderLoader",
        "signature": "scrapy.spiderloader.SpiderLoader.find_by_request(self, request)",
        "snippet": "    def find_by_request(self, request):\n        \"\"\"\n        Return the list of spider names that can handle the given request.\n        \"\"\"\n        return [name for name, cls in self._spiders.items()\n                if cls.handles_request(request)]",
        "begin_line": 42,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.spiderloader.SpiderLoader.list#49",
        "src_path": "scrapy/spiderloader.py",
        "class_name": "scrapy.spiderloader.SpiderLoader",
        "signature": "scrapy.spiderloader.SpiderLoader.list(self)",
        "snippet": "    def list(self):\n        \"\"\"\n        Return a list with the names of all spiders available in the project.\n        \"\"\"\n        return list(self._spiders.keys())",
        "begin_line": 49,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.contracts.default.UrlContract.adjust_request_args#16",
        "src_path": "scrapy/contracts/default.py",
        "class_name": "scrapy.contracts.default.UrlContract",
        "signature": "scrapy.contracts.default.UrlContract.adjust_request_args(self, args)",
        "snippet": "    def adjust_request_args(self, args):\n        args['url'] = self.args[0]\n        return args",
        "begin_line": 16,
        "end_line": 18,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.contracts.default.ReturnsContract.__init__#42",
        "src_path": "scrapy/contracts/default.py",
        "class_name": "scrapy.contracts.default.ReturnsContract",
        "signature": "scrapy.contracts.default.ReturnsContract.__init__(self, *args, **kwargs)",
        "snippet": "    def __init__(self, *args, **kwargs):\n        super(ReturnsContract, self).__init__(*args, **kwargs)\n\n        assert len(self.args) in [1, 2, 3]\n        self.obj_name = self.args[0] or None\n        self.obj_type = self.objects[self.obj_name]\n\n        try:\n            self.min_bound = int(self.args[1])\n        except IndexError:\n            self.min_bound = 1\n\n        try:\n            self.max_bound = int(self.args[2])\n        except IndexError:\n            self.max_bound = float('inf')",
        "begin_line": 42,
        "end_line": 57,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0024630541871921183,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.contracts.default.ReturnsContract.post_process#59",
        "src_path": "scrapy/contracts/default.py",
        "class_name": "scrapy.contracts.default.ReturnsContract",
        "signature": "scrapy.contracts.default.ReturnsContract.post_process(self, output)",
        "snippet": "    def post_process(self, output):\n        occurrences = 0\n        for x in output:\n            if isinstance(x, self.obj_type):\n                occurrences += 1\n\n        assertion = (self.min_bound <= occurrences <= self.max_bound)\n\n        if not assertion:\n            if self.min_bound == self.max_bound:\n                expected = self.min_bound\n            else:\n                expected = '%s..%s' % (self.min_bound, self.max_bound)\n\n            raise ContractFail(\"Returned %s %s, expected %s\" % \\\n                (occurrences, self.obj_name, expected))",
        "begin_line": 59,
        "end_line": 74,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.contracts.default.ScrapesContract.post_process#84",
        "src_path": "scrapy/contracts/default.py",
        "class_name": "scrapy.contracts.default.ScrapesContract",
        "signature": "scrapy.contracts.default.ScrapesContract.post_process(self, output)",
        "snippet": "    def post_process(self, output):\n        for x in output:\n            if isinstance(x, (BaseItem, dict)):\n                for arg in self.args:\n                    if not arg in x:\n                        raise ContractFail(\"'%s' field is missing\" % arg)",
        "begin_line": 84,
        "end_line": 89,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.item.ItemMeta.__new__#27",
        "src_path": "scrapy/item.py",
        "class_name": "scrapy.item.ItemMeta",
        "signature": "scrapy.item.ItemMeta.__new__(mcs, class_name, bases, attrs)",
        "snippet": "    def __new__(mcs, class_name, bases, attrs):\n        new_bases = tuple(base._class for base in bases if hasattr(base, '_class'))\n        _class = super(ItemMeta, mcs).__new__(mcs, 'x_' + class_name, new_bases, attrs)\n\n        fields = getattr(_class, 'fields', {})\n        new_attrs = {}\n        for n in dir(_class):\n            v = getattr(_class, n)\n            if isinstance(v, Field):\n                fields[n] = v\n            elif n in attrs:\n                new_attrs[n] = attrs[n]\n\n        new_attrs['fields'] = fields\n        new_attrs['_class'] = _class\n        return super(ItemMeta, mcs).__new__(mcs, class_name, bases, new_attrs)",
        "begin_line": 27,
        "end_line": 42,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0010615711252653928,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.item.DictItem.__init__#49",
        "src_path": "scrapy/item.py",
        "class_name": "scrapy.item.DictItem",
        "signature": "scrapy.item.DictItem.__init__(self, *args, **kwargs)",
        "snippet": "    def __init__(self, *args, **kwargs):\n        self._values = {}\n        if args or kwargs:  # avoid creating dict for most common case\n            for k, v in six.iteritems(dict(*args, **kwargs)):\n                self[k] = v",
        "begin_line": 49,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0010660980810234541,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.item.DictItem.__getitem__#55",
        "src_path": "scrapy/item.py",
        "class_name": "scrapy.item.DictItem",
        "signature": "scrapy.item.DictItem.__getitem__(self, key)",
        "snippet": "    def __getitem__(self, key):\n        return self._values[key]",
        "begin_line": 55,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.001,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.item.DictItem.__setitem__#58",
        "src_path": "scrapy/item.py",
        "class_name": "scrapy.item.DictItem",
        "signature": "scrapy.item.DictItem.__setitem__(self, key, value)",
        "snippet": "    def __setitem__(self, key, value):\n        if key in self.fields:\n            self._values[key] = value\n        else:\n            raise KeyError(\"%s does not support field: %s\" %\n                (self.__class__.__name__, key))",
        "begin_line": 58,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.item.DictItem.__getattr__#68",
        "src_path": "scrapy/item.py",
        "class_name": "scrapy.item.DictItem",
        "signature": "scrapy.item.DictItem.__getattr__(self, name)",
        "snippet": "    def __getattr__(self, name):\n        if name in self.fields:\n            raise AttributeError(\"Use item[%r] to get field value\" % name)\n        raise AttributeError(name)",
        "begin_line": 68,
        "end_line": 71,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.item.DictItem.__setattr__#73",
        "src_path": "scrapy/item.py",
        "class_name": "scrapy.item.DictItem",
        "signature": "scrapy.item.DictItem.__setattr__(self, name, value)",
        "snippet": "    def __setattr__(self, name, value):\n        if not name.startswith('_'):\n            raise AttributeError(\"Use item[%r] = %r to set field value\" %\n                (name, value))\n        super(DictItem, self).__setattr__(name, value)",
        "begin_line": 73,
        "end_line": 77,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.item.DictItem.__len__#79",
        "src_path": "scrapy/item.py",
        "class_name": "scrapy.item.DictItem",
        "signature": "scrapy.item.DictItem.__len__(self)",
        "snippet": "    def __len__(self):\n        return len(self._values)",
        "begin_line": 79,
        "end_line": 80,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.item.DictItem.__iter__#82",
        "src_path": "scrapy/item.py",
        "class_name": "scrapy.item.DictItem",
        "signature": "scrapy.item.DictItem.__iter__(self)",
        "snippet": "    def __iter__(self):\n        return iter(self._values)",
        "begin_line": 82,
        "end_line": 83,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0011273957158962795,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.item.DictItem.keys#87",
        "src_path": "scrapy/item.py",
        "class_name": "scrapy.item.DictItem",
        "signature": "scrapy.item.DictItem.keys(self)",
        "snippet": "    def keys(self):\n        return self._values.keys()",
        "begin_line": 87,
        "end_line": 88,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.item.DictItem.__repr__#90",
        "src_path": "scrapy/item.py",
        "class_name": "scrapy.item.DictItem",
        "signature": "scrapy.item.DictItem.__repr__(self)",
        "snippet": "    def __repr__(self):\n        return pformat(dict(self))",
        "begin_line": 90,
        "end_line": 91,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.item.DictItem.copy#93",
        "src_path": "scrapy/item.py",
        "class_name": "scrapy.item.DictItem",
        "signature": "scrapy.item.DictItem.copy(self)",
        "snippet": "    def copy(self):\n        return self.__class__(self)",
        "begin_line": 93,
        "end_line": 94,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.pipelines.media.SpiderInfo.__init__#20",
        "src_path": "scrapy/pipelines/media.py",
        "class_name": "scrapy.pipelines.media.SpiderInfo",
        "signature": "scrapy.pipelines.media.SpiderInfo.__init__(self, spider)",
        "snippet": "        def __init__(self, spider):\n            self.spider = spider\n            self.downloading = set()\n            self.downloaded = {}\n            self.waiting = defaultdict(list)",
        "begin_line": 20,
        "end_line": 24,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.05555555555555555,
            "pseudo_dstar_susp": 0.05555555555555555,
            "pseudo_tarantula_susp": 0.05555555555555555,
            "pseudo_op2_susp": 0.05555555555555555,
            "pseudo_barinel_susp": 0.05555555555555555
        }
    },
    {
        "name": "scrapy.pipelines.media.MediaPipeline.__init__#26",
        "src_path": "scrapy/pipelines/media.py",
        "class_name": "scrapy.pipelines.media.MediaPipeline",
        "signature": "scrapy.pipelines.media.MediaPipeline.__init__(self, download_func=None)",
        "snippet": "    def __init__(self, download_func=None):\n        self.download_func = download_func",
        "begin_line": 26,
        "end_line": 27,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.05555555555555555,
            "pseudo_dstar_susp": 0.05555555555555555,
            "pseudo_tarantula_susp": 0.05555555555555555,
            "pseudo_op2_susp": 0.05555555555555555,
            "pseudo_barinel_susp": 0.05555555555555555
        }
    },
    {
        "name": "scrapy.pipelines.media.MediaPipeline.open_spider#38",
        "src_path": "scrapy/pipelines/media.py",
        "class_name": "scrapy.pipelines.media.MediaPipeline",
        "signature": "scrapy.pipelines.media.MediaPipeline.open_spider(self, spider)",
        "snippet": "    def open_spider(self, spider):\n        self.spiderinfo = self.SpiderInfo(spider)",
        "begin_line": 38,
        "end_line": 39,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.05555555555555555,
            "pseudo_dstar_susp": 0.05555555555555555,
            "pseudo_tarantula_susp": 0.05555555555555555,
            "pseudo_op2_susp": 0.05555555555555555,
            "pseudo_barinel_susp": 0.05555555555555555
        }
    },
    {
        "name": "scrapy.pipelines.media.MediaPipeline.process_item#41",
        "src_path": "scrapy/pipelines/media.py",
        "class_name": "scrapy.pipelines.media.MediaPipeline",
        "signature": "scrapy.pipelines.media.MediaPipeline.process_item(self, item, spider)",
        "snippet": "    def process_item(self, item, spider):\n        info = self.spiderinfo\n        requests = arg_to_iter(self.get_media_requests(item, info))\n        dlist = [self._process_request(r, info) for r in requests]\n        dfd = DeferredList(dlist, consumeErrors=1)\n        return dfd.addCallback(self.item_completed, item, info)",
        "begin_line": 41,
        "end_line": 46,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0024630541871921183,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.pipelines.media.MediaPipeline.media_to_download#106",
        "src_path": "scrapy/pipelines/media.py",
        "class_name": "scrapy.pipelines.media.MediaPipeline",
        "signature": "scrapy.pipelines.media.MediaPipeline.media_to_download(self, request, info)",
        "snippet": "    def media_to_download(self, request, info):\n        \"\"\"Check request before starting download\"\"\"\n        pass",
        "begin_line": 106,
        "end_line": 108,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0024630541871921183,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.pipelines.media.MediaPipeline.get_media_requests#110",
        "src_path": "scrapy/pipelines/media.py",
        "class_name": "scrapy.pipelines.media.MediaPipeline",
        "signature": "scrapy.pipelines.media.MediaPipeline.get_media_requests(self, item, info)",
        "snippet": "    def get_media_requests(self, item, info):\n        \"\"\"Returns the media requests to download\"\"\"\n        pass",
        "begin_line": 110,
        "end_line": 112,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0024630541871921183,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.pipelines.media.MediaPipeline.media_downloaded#114",
        "src_path": "scrapy/pipelines/media.py",
        "class_name": "scrapy.pipelines.media.MediaPipeline",
        "signature": "scrapy.pipelines.media.MediaPipeline.media_downloaded(self, response, request, info)",
        "snippet": "    def media_downloaded(self, response, request, info):\n        \"\"\"Handler for success downloads\"\"\"\n        return response",
        "begin_line": 114,
        "end_line": 116,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0024630541871921183,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.pipelines.media.MediaPipeline.media_failed#118",
        "src_path": "scrapy/pipelines/media.py",
        "class_name": "scrapy.pipelines.media.MediaPipeline",
        "signature": "scrapy.pipelines.media.MediaPipeline.media_failed(self, failure, request, info)",
        "snippet": "    def media_failed(self, failure, request, info):\n        \"\"\"Handler for failed downloads\"\"\"\n        return failure",
        "begin_line": 118,
        "end_line": 120,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0024630541871921183,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.pipelines.media.MediaPipeline.item_completed#122",
        "src_path": "scrapy/pipelines/media.py",
        "class_name": "scrapy.pipelines.media.MediaPipeline",
        "signature": "scrapy.pipelines.media.MediaPipeline.item_completed(self, results, item, info)",
        "snippet": "    def item_completed(self, results, item, info):\n        \"\"\"Called per item when all media requests has been processed\"\"\"\n        if self.LOG_FAILED_RESULTS:\n            for ok, value in results:\n                if not ok:\n                    logger.error(\n                        '%(class)s found errors processing %(item)s',\n                        {'class': self.__class__.__name__, 'item': item},\n                        extra={'spider': info.spider, 'failure': value}\n                    )\n        return item",
        "begin_line": 122,
        "end_line": 132,
        "comment": "",
        "is_bug": true,
        "susp": {
            "pseudo_ochiai_susp": 0.3333333333333333,
            "pseudo_dstar_susp": 0.3333333333333333,
            "pseudo_tarantula_susp": 0.3333333333333333,
            "pseudo_op2_susp": 0.3333333333333333,
            "pseudo_barinel_susp": 0.3333333333333333
        }
    },
    {
        "name": "scrapy.http.request.__init__.Request.__init__#18",
        "src_path": "scrapy/http/request/__init__.py",
        "class_name": "scrapy.http.request.__init__.Request",
        "signature": "scrapy.http.request.__init__.Request.__init__(self, url, callback=None, method='GET', headers=None, body=None, cookies=None, meta=None, encoding='utf-8', priority=0, dont_filter=False, errback=None)",
        "snippet": "    def __init__(self, url, callback=None, method='GET', headers=None, body=None,\n                 cookies=None, meta=None, encoding='utf-8', priority=0,\n                 dont_filter=False, errback=None):\n\n        self._encoding = encoding  # this one has to be set first\n        self.method = str(method).upper()\n        self._set_url(url)\n        self._set_body(body)\n        assert isinstance(priority, int), \"Request priority not an integer: %r\" % priority\n        self.priority = priority\n\n        assert callback or not errback, \"Cannot use errback without a callback\"\n        self.callback = callback\n        self.errback = errback\n\n        self.cookies = cookies or {}\n        self.headers = Headers(headers or {}, encoding=encoding)\n        self.dont_filter = dont_filter\n\n        self._meta = dict(meta) if meta else None",
        "begin_line": 18,
        "end_line": 37,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0010330578512396695,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.http.request.__init__.Request.meta#40",
        "src_path": "scrapy/http/request/__init__.py",
        "class_name": "scrapy.http.request.__init__.Request",
        "signature": "scrapy.http.request.__init__.Request.meta(self)",
        "snippet": "    def meta(self):\n        if self._meta is None:\n            self._meta = {}\n        return self._meta",
        "begin_line": 40,
        "end_line": 43,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0011627906976744186,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.http.request.__init__.Request._get_url#45",
        "src_path": "scrapy/http/request/__init__.py",
        "class_name": "scrapy.http.request.__init__.Request",
        "signature": "scrapy.http.request.__init__.Request._get_url(self)",
        "snippet": "    def _get_url(self):\n        return self._url",
        "begin_line": 45,
        "end_line": 46,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.http.request.__init__.Request._set_url#48",
        "src_path": "scrapy/http/request/__init__.py",
        "class_name": "scrapy.http.request.__init__.Request",
        "signature": "scrapy.http.request.__init__.Request._set_url(self, url)",
        "snippet": "    def _set_url(self, url):\n        if isinstance(url, str):\n            self._url = escape_ajax(safe_url_string(url))\n        elif isinstance(url, six.text_type):\n            if self.encoding is None:\n                raise TypeError('Cannot convert unicode url - %s has no encoding' %\n                                type(self).__name__)\n            self._set_url(url.encode(self.encoding))\n        else:\n            raise TypeError('Request url must be str or unicode, got %s:' % type(url).__name__)\n        if ':' not in self._url:\n            raise ValueError('Missing scheme in request url: %s' % self._url)",
        "begin_line": 48,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0010330578512396695,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.http.request.__init__.Request._set_body#66",
        "src_path": "scrapy/http/request/__init__.py",
        "class_name": "scrapy.http.request.__init__.Request",
        "signature": "scrapy.http.request.__init__.Request._set_body(self, body)",
        "snippet": "    def _set_body(self, body):\n        if isinstance(body, str):\n            self._body = body\n        elif isinstance(body, six.text_type):\n            if self.encoding is None:\n                raise TypeError('Cannot convert unicode body - %s has no encoding' %\n                                type(self).__name__)\n            self._body = body.encode(self.encoding)\n        elif body is None:\n            self._body = ''\n        else:\n            raise TypeError(\"Request body must either str or unicode. Got: '%s'\" % type(body).__name__)",
        "begin_line": 66,
        "end_line": 77,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0010330578512396695,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.misc.arg_to_iter#17",
        "src_path": "scrapy/utils/misc.py",
        "class_name": "scrapy.utils.misc",
        "signature": "scrapy.utils.misc.arg_to_iter(arg)",
        "snippet": "def arg_to_iter(arg):\n    \"\"\"Convert an argument to an iterable. The argument can be a None, single\n    value, or an iterable.\n\n    Exception: if arg is a dict, [arg] will be returned\n    \"\"\"\n    if arg is None:\n        return []\n    elif not isinstance(arg, _ITERABLE_SINGLE_VALUES) and hasattr(arg, '__iter__'):\n        return arg\n    else:\n        return [arg]",
        "begin_line": 17,
        "end_line": 28,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.misc.load_object#31",
        "src_path": "scrapy/utils/misc.py",
        "class_name": "scrapy.utils.misc",
        "signature": "scrapy.utils.misc.load_object(path)",
        "snippet": "def load_object(path):\n    \"\"\"Load an object given its absolute object path, and return it.\n\n    object can be a class, function, variable o instance.\n    path ie: 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware'\n    \"\"\"\n\n    try:\n        dot = path.rindex('.')\n    except ValueError:\n        raise ValueError(\"Error loading object '%s': not a full path\" % path)\n\n    module, name = path[:dot], path[dot+1:]\n    mod = import_module(module)\n\n    try:\n        obj = getattr(mod, name)\n    except AttributeError:\n        raise NameError(\"Module '%s' doesn't define any object named '%s'\" % (module, name))\n\n    return obj",
        "begin_line": 31,
        "end_line": 51,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.misc.walk_modules#54",
        "src_path": "scrapy/utils/misc.py",
        "class_name": "scrapy.utils.misc",
        "signature": "scrapy.utils.misc.walk_modules(path)",
        "snippet": "def walk_modules(path):\n    \"\"\"Loads a module and all its submodules from a the given module path and\n    returns them. If *any* module throws an exception while importing, that\n    exception is thrown back.\n\n    For example: walk_modules('scrapy.utils')\n    \"\"\"\n\n    mods = []\n    mod = import_module(path)\n    mods.append(mod)\n    if hasattr(mod, '__path__'):\n        for _, subpath, ispkg in iter_modules(mod.__path__):\n            fullpath = path + '.' + subpath\n            if ispkg:\n                mods += walk_modules(fullpath)\n            else:\n                submod = import_module(fullpath)\n                mods.append(submod)\n    return mods",
        "begin_line": 54,
        "end_line": 73,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0024630541871921183,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.telnet.TelnetConsole.__init__#39",
        "src_path": "scrapy/telnet.py",
        "class_name": "scrapy.telnet.TelnetConsole",
        "signature": "scrapy.telnet.TelnetConsole.__init__(self, crawler)",
        "snippet": "    def __init__(self, crawler):\n        if not crawler.settings.getbool('TELNETCONSOLE_ENABLED'):\n            raise NotConfigured\n        if not TWISTED_CONCH_AVAILABLE:\n            raise NotConfigured\n        self.crawler = crawler\n        self.noisy = False\n        self.portrange = [int(x) for x in crawler.settings.getlist('TELNETCONSOLE_PORT')]\n        self.host = crawler.settings['TELNETCONSOLE_HOST']\n        self.crawler.signals.connect(self.start_listening, signals.engine_started)\n        self.crawler.signals.connect(self.stop_listening, signals.engine_stopped)",
        "begin_line": 39,
        "end_line": 49,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.telnet.TelnetConsole.from_crawler#52",
        "src_path": "scrapy/telnet.py",
        "class_name": "scrapy.telnet.TelnetConsole",
        "signature": "scrapy.telnet.TelnetConsole.from_crawler(cls, crawler)",
        "snippet": "    def from_crawler(cls, crawler):\n        return cls(crawler)",
        "begin_line": 52,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.telnet.TelnetConsole.start_listening#55",
        "src_path": "scrapy/telnet.py",
        "class_name": "scrapy.telnet.TelnetConsole",
        "signature": "scrapy.telnet.TelnetConsole.start_listening(self)",
        "snippet": "    def start_listening(self):\n        self.port = listen_tcp(self.portrange, self.host, self)\n        h = self.port.getHost()\n        logger.debug(\"Telnet console listening on %(host)s:%(port)d\",\n                     {'host': h.host, 'port': h.port},\n                     extra={'crawler': self.crawler})",
        "begin_line": 55,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.telnet.TelnetConsole.stop_listening#62",
        "src_path": "scrapy/telnet.py",
        "class_name": "scrapy.telnet.TelnetConsole",
        "signature": "scrapy.telnet.TelnetConsole.stop_listening(self)",
        "snippet": "    def stop_listening(self):\n        self.port.stopListening()",
        "begin_line": 62,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.telnet.TelnetConsole.protocol#65",
        "src_path": "scrapy/telnet.py",
        "class_name": "scrapy.telnet.TelnetConsole",
        "signature": "scrapy.telnet.TelnetConsole.protocol(self)",
        "snippet": "    def protocol(self):\n        telnet_vars = self._get_telnet_vars()\n        return telnet.TelnetTransport(telnet.TelnetBootstrapProtocol,\n            insults.ServerProtocol, manhole.Manhole, telnet_vars)",
        "begin_line": 65,
        "end_line": 68,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.telnet.TelnetConsole._get_telnet_vars#70",
        "src_path": "scrapy/telnet.py",
        "class_name": "scrapy.telnet.TelnetConsole",
        "signature": "scrapy.telnet.TelnetConsole._get_telnet_vars(self)",
        "snippet": "    def _get_telnet_vars(self):\n        # Note: if you add entries here also update topics/telnetconsole.rst\n        telnet_vars = {\n            'engine': self.crawler.engine,\n            'spider': self.crawler.engine.spider,\n            'slot': self.crawler.engine.slot,\n            'crawler': self.crawler,\n            'extensions': self.crawler.extensions,\n            'stats': self.crawler.stats,\n            'settings': self.crawler.settings,\n            'est': lambda: print_engine_status(self.crawler.engine),\n            'p': pprint.pprint,\n            'prefs': print_live_refs,\n            'hpy': hpy,\n            'help': \"This is Scrapy telnet console. For more info see: \" \\\n                \"http://doc.scrapy.org/en/latest/topics/telnetconsole.html\",\n        }\n        self.crawler.signals.send_catch_log(update_telnet_vars, telnet_vars=telnet_vars)\n        return telnet_vars",
        "begin_line": 70,
        "end_line": 88,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.link.Link.__init__#15",
        "src_path": "scrapy/link.py",
        "class_name": "scrapy.link.Link",
        "signature": "scrapy.link.Link.__init__(self, url, text='', fragment='', nofollow=False)",
        "snippet": "    def __init__(self, url, text='', fragment='', nofollow=False):\n        if isinstance(url, six.text_type):\n            import warnings\n            warnings.warn(\"Do not instantiate Link objects with unicode urls. \"\n                \"Assuming utf-8 encoding (which could be wrong)\")\n            url = url.encode('utf-8')\n        self.url = url\n        self.text = text\n        self.fragment = fragment\n        self.nofollow = nofollow",
        "begin_line": 15,
        "end_line": 24,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.link.Link.__eq__#26",
        "src_path": "scrapy/link.py",
        "class_name": "scrapy.link.Link",
        "signature": "scrapy.link.Link.__eq__(self, other)",
        "snippet": "    def __eq__(self, other):\n        return self.url == other.url and self.text == other.text and \\\n            self.fragment == other.fragment and self.nofollow == other.nofollow",
        "begin_line": 26,
        "end_line": 28,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0024630541871921183,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.link.Link.__hash__#30",
        "src_path": "scrapy/link.py",
        "class_name": "scrapy.link.Link",
        "signature": "scrapy.link.Link.__hash__(self)",
        "snippet": "    def __hash__(self):\n        return hash(self.url) ^ hash(self.text) ^ hash(self.fragment) ^ hash(self.nofollow)",
        "begin_line": 30,
        "end_line": 31,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0024630541871921183,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.link.Link.__repr__#33",
        "src_path": "scrapy/link.py",
        "class_name": "scrapy.link.Link",
        "signature": "scrapy.link.Link.__repr__(self)",
        "snippet": "    def __repr__(self):\n        return 'Link(url=%r, text=%r, fragment=%r, nofollow=%r)' % \\\n            (self.url, self.text, self.fragment, self.nofollow)",
        "begin_line": 33,
        "end_line": 35,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.spider.iterate_spider_output#12",
        "src_path": "scrapy/utils/spider.py",
        "class_name": "scrapy.utils.spider",
        "signature": "scrapy.utils.spider.iterate_spider_output(result)",
        "snippet": "def iterate_spider_output(result):\n    return arg_to_iter(result)",
        "begin_line": 12,
        "end_line": 13,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.spider.iter_spider_classes#16",
        "src_path": "scrapy/utils/spider.py",
        "class_name": "scrapy.utils.spider",
        "signature": "scrapy.utils.spider.iter_spider_classes(module)",
        "snippet": "def iter_spider_classes(module):\n    \"\"\"Return an iterator over all spider classes defined in the given module\n    that can be instantiated (ie. which have name)\n    \"\"\"\n    # this needs to be imported here until get rid of the spider manager\n    # singleton in scrapy.spider.spiders\n    from scrapy.spiders import Spider\n\n    for obj in six.itervalues(vars(module)):\n        if inspect.isclass(obj) and \\\n           issubclass(obj, Spider) and \\\n           obj.__module__ == module.__name__ and \\\n           getattr(obj, 'name', None):\n            yield obj",
        "begin_line": 16,
        "end_line": 29,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.http.response.__init__.Response.__init__#18",
        "src_path": "scrapy/http/response/__init__.py",
        "class_name": "scrapy.http.response.__init__.Response",
        "signature": "scrapy.http.response.__init__.Response.__init__(self, url, status=200, headers=None, body='', flags=None, request=None)",
        "snippet": "    def __init__(self, url, status=200, headers=None, body='', flags=None, request=None):\n        self.headers = Headers(headers or {})\n        self.status = int(status)\n        self._set_body(body)\n        self._set_url(url)\n        self.request = request\n        self.flags = [] if flags is None else list(flags)",
        "begin_line": 18,
        "end_line": 24,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.http.response.__init__.Response._set_url#37",
        "src_path": "scrapy/http/response/__init__.py",
        "class_name": "scrapy.http.response.__init__.Response",
        "signature": "scrapy.http.response.__init__.Response._set_url(self, url)",
        "snippet": "    def _set_url(self, url):\n        if isinstance(url, str):\n            self._url = url\n        else:\n            raise TypeError('%s url must be str, got %s:' % (type(self).__name__, \\\n                type(url).__name__))",
        "begin_line": 37,
        "end_line": 42,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.http.response.__init__.Response._set_body#49",
        "src_path": "scrapy/http/response/__init__.py",
        "class_name": "scrapy.http.response.__init__.Response",
        "signature": "scrapy.http.response.__init__.Response._set_body(self, body)",
        "snippet": "    def _set_body(self, body):\n        if isinstance(body, str):\n            self._body = body\n        elif isinstance(body, unicode):\n            raise TypeError(\"Cannot assign a unicode body to a raw Response. \" \\\n                \"Use TextResponse, HtmlResponse, etc\")\n        elif body is None:\n            self._body = ''\n        else:\n            raise TypeError(\"Response body must either be str or unicode. Got: '%s'\" \\\n                % type(body).__name__)",
        "begin_line": 49,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.statscollectors.StatsCollector.__init__#12",
        "src_path": "scrapy/statscollectors.py",
        "class_name": "scrapy.statscollectors.StatsCollector",
        "signature": "scrapy.statscollectors.StatsCollector.__init__(self, crawler)",
        "snippet": "    def __init__(self, crawler):\n        self._dump = crawler.settings.getbool('STATS_DUMP')\n        self._stats = {}",
        "begin_line": 12,
        "end_line": 14,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.statscollectors.StatsCollector.get_value#16",
        "src_path": "scrapy/statscollectors.py",
        "class_name": "scrapy.statscollectors.StatsCollector",
        "signature": "scrapy.statscollectors.StatsCollector.get_value(self, key, default=None, spider=None)",
        "snippet": "    def get_value(self, key, default=None, spider=None):\n        return self._stats.get(key, default)",
        "begin_line": 16,
        "end_line": 17,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.statscollectors.StatsCollector.get_stats#19",
        "src_path": "scrapy/statscollectors.py",
        "class_name": "scrapy.statscollectors.StatsCollector",
        "signature": "scrapy.statscollectors.StatsCollector.get_stats(self, spider=None)",
        "snippet": "    def get_stats(self, spider=None):\n        return self._stats",
        "begin_line": 19,
        "end_line": 20,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.statscollectors.StatsCollector.set_value#22",
        "src_path": "scrapy/statscollectors.py",
        "class_name": "scrapy.statscollectors.StatsCollector",
        "signature": "scrapy.statscollectors.StatsCollector.set_value(self, key, value, spider=None)",
        "snippet": "    def set_value(self, key, value, spider=None):\n        self._stats[key] = value",
        "begin_line": 22,
        "end_line": 23,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.statscollectors.StatsCollector.set_stats#25",
        "src_path": "scrapy/statscollectors.py",
        "class_name": "scrapy.statscollectors.StatsCollector",
        "signature": "scrapy.statscollectors.StatsCollector.set_stats(self, stats, spider=None)",
        "snippet": "    def set_stats(self, stats, spider=None):\n        self._stats = stats",
        "begin_line": 25,
        "end_line": 26,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.statscollectors.StatsCollector.inc_value#28",
        "src_path": "scrapy/statscollectors.py",
        "class_name": "scrapy.statscollectors.StatsCollector",
        "signature": "scrapy.statscollectors.StatsCollector.inc_value(self, key, count=1, start=0, spider=None)",
        "snippet": "    def inc_value(self, key, count=1, start=0, spider=None):\n        d = self._stats\n        d[key] = d.setdefault(key, start) + count",
        "begin_line": 28,
        "end_line": 30,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.statscollectors.StatsCollector.max_value#32",
        "src_path": "scrapy/statscollectors.py",
        "class_name": "scrapy.statscollectors.StatsCollector",
        "signature": "scrapy.statscollectors.StatsCollector.max_value(self, key, value, spider=None)",
        "snippet": "    def max_value(self, key, value, spider=None):\n        self._stats[key] = max(self._stats.setdefault(key, value), value)",
        "begin_line": 32,
        "end_line": 33,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.statscollectors.StatsCollector.min_value#35",
        "src_path": "scrapy/statscollectors.py",
        "class_name": "scrapy.statscollectors.StatsCollector",
        "signature": "scrapy.statscollectors.StatsCollector.min_value(self, key, value, spider=None)",
        "snippet": "    def min_value(self, key, value, spider=None):\n        self._stats[key] = min(self._stats.setdefault(key, value), value)",
        "begin_line": 35,
        "end_line": 36,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.statscollectors.StatsCollector.clear_stats#38",
        "src_path": "scrapy/statscollectors.py",
        "class_name": "scrapy.statscollectors.StatsCollector",
        "signature": "scrapy.statscollectors.StatsCollector.clear_stats(self, spider=None)",
        "snippet": "    def clear_stats(self, spider=None):\n        self._stats.clear()",
        "begin_line": 38,
        "end_line": 39,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.statscollectors.StatsCollector.open_spider#41",
        "src_path": "scrapy/statscollectors.py",
        "class_name": "scrapy.statscollectors.StatsCollector",
        "signature": "scrapy.statscollectors.StatsCollector.open_spider(self, spider)",
        "snippet": "    def open_spider(self, spider):\n        pass",
        "begin_line": 41,
        "end_line": 42,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.statscollectors.StatsCollector.close_spider#44",
        "src_path": "scrapy/statscollectors.py",
        "class_name": "scrapy.statscollectors.StatsCollector",
        "signature": "scrapy.statscollectors.StatsCollector.close_spider(self, spider, reason)",
        "snippet": "    def close_spider(self, spider, reason):\n        if self._dump:\n            logger.info(\"Dumping Scrapy stats:\\n\" + pprint.pformat(self._stats),\n                        extra={'spider': spider})\n        self._persist_stats(self._stats, spider)",
        "begin_line": 44,
        "end_line": 48,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.statscollectors.StatsCollector._persist_stats#50",
        "src_path": "scrapy/statscollectors.py",
        "class_name": "scrapy.statscollectors.StatsCollector",
        "signature": "scrapy.statscollectors.StatsCollector._persist_stats(self, stats, spider)",
        "snippet": "    def _persist_stats(self, stats, spider):\n        pass",
        "begin_line": 50,
        "end_line": 51,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.statscollectors.MemoryStatsCollector.__init__#55",
        "src_path": "scrapy/statscollectors.py",
        "class_name": "scrapy.statscollectors.MemoryStatsCollector",
        "signature": "scrapy.statscollectors.MemoryStatsCollector.__init__(self, crawler)",
        "snippet": "    def __init__(self, crawler):\n        super(MemoryStatsCollector, self).__init__(crawler)\n        self.spider_stats = {}",
        "begin_line": 55,
        "end_line": 57,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.statscollectors.MemoryStatsCollector._persist_stats#59",
        "src_path": "scrapy/statscollectors.py",
        "class_name": "scrapy.statscollectors.MemoryStatsCollector",
        "signature": "scrapy.statscollectors.MemoryStatsCollector._persist_stats(self, stats, spider)",
        "snippet": "    def _persist_stats(self, stats, spider):\n        self.spider_stats[spider.name] = stats",
        "begin_line": 59,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.statscollectors.DummyStatsCollector.get_value#65",
        "src_path": "scrapy/statscollectors.py",
        "class_name": "scrapy.statscollectors.DummyStatsCollector",
        "signature": "scrapy.statscollectors.DummyStatsCollector.get_value(self, key, default=None, spider=None)",
        "snippet": "    def get_value(self, key, default=None, spider=None):\n        return default",
        "begin_line": 65,
        "end_line": 66,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.statscollectors.DummyStatsCollector.set_value#68",
        "src_path": "scrapy/statscollectors.py",
        "class_name": "scrapy.statscollectors.DummyStatsCollector",
        "signature": "scrapy.statscollectors.DummyStatsCollector.set_value(self, key, value, spider=None)",
        "snippet": "    def set_value(self, key, value, spider=None):\n        pass",
        "begin_line": 68,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.statscollectors.DummyStatsCollector.set_stats#71",
        "src_path": "scrapy/statscollectors.py",
        "class_name": "scrapy.statscollectors.DummyStatsCollector",
        "signature": "scrapy.statscollectors.DummyStatsCollector.set_stats(self, stats, spider=None)",
        "snippet": "    def set_stats(self, stats, spider=None):\n        pass",
        "begin_line": 71,
        "end_line": 72,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.statscollectors.DummyStatsCollector.inc_value#74",
        "src_path": "scrapy/statscollectors.py",
        "class_name": "scrapy.statscollectors.DummyStatsCollector",
        "signature": "scrapy.statscollectors.DummyStatsCollector.inc_value(self, key, count=1, start=0, spider=None)",
        "snippet": "    def inc_value(self, key, count=1, start=0, spider=None):\n        pass",
        "begin_line": 74,
        "end_line": 75,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.statscollectors.DummyStatsCollector.max_value#77",
        "src_path": "scrapy/statscollectors.py",
        "class_name": "scrapy.statscollectors.DummyStatsCollector",
        "signature": "scrapy.statscollectors.DummyStatsCollector.max_value(self, key, value, spider=None)",
        "snippet": "    def max_value(self, key, value, spider=None):\n        pass",
        "begin_line": 77,
        "end_line": 78,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.statscollectors.DummyStatsCollector.min_value#80",
        "src_path": "scrapy/statscollectors.py",
        "class_name": "scrapy.statscollectors.DummyStatsCollector",
        "signature": "scrapy.statscollectors.DummyStatsCollector.min_value(self, key, value, spider=None)",
        "snippet": "    def min_value(self, key, value, spider=None):\n        pass",
        "begin_line": 80,
        "end_line": 81,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.job.job_dir#3",
        "src_path": "scrapy/utils/job.py",
        "class_name": "scrapy.utils.job",
        "signature": "scrapy.utils.job.job_dir(settings)",
        "snippet": "def job_dir(settings):\n    path = settings['JOBDIR']\n    if path and not os.path.exists(path):\n        os.makedirs(path)\n    return path",
        "begin_line": 3,
        "end_line": 7,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.memusage.MemoryUsage.__init__#24",
        "src_path": "scrapy/extensions/memusage.py",
        "class_name": "scrapy.extensions.memusage.MemoryUsage",
        "signature": "scrapy.extensions.memusage.MemoryUsage.__init__(self, crawler)",
        "snippet": "    def __init__(self, crawler):\n        if not crawler.settings.getbool('MEMUSAGE_ENABLED'):\n            raise NotConfigured\n        try:\n            # stdlib's resource module is only available on unix platforms.\n            self.resource = import_module('resource')\n        except ImportError:\n            raise NotConfigured\n\n        self.crawler = crawler\n        self.warned = False\n        self.notify_mails = crawler.settings.getlist('MEMUSAGE_NOTIFY_MAIL')\n        self.limit = crawler.settings.getint('MEMUSAGE_LIMIT_MB')*1024*1024\n        self.warning = crawler.settings.getint('MEMUSAGE_WARNING_MB')*1024*1024\n        self.report = crawler.settings.getbool('MEMUSAGE_REPORT')\n        self.mail = MailSender.from_settings(crawler.settings)\n        crawler.signals.connect(self.engine_started, signal=signals.engine_started)\n        crawler.signals.connect(self.engine_stopped, signal=signals.engine_stopped)",
        "begin_line": 24,
        "end_line": 41,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.memusage.MemoryUsage.from_crawler#44",
        "src_path": "scrapy/extensions/memusage.py",
        "class_name": "scrapy.extensions.memusage.MemoryUsage",
        "signature": "scrapy.extensions.memusage.MemoryUsage.from_crawler(cls, crawler)",
        "snippet": "    def from_crawler(cls, crawler):\n        return cls(crawler)",
        "begin_line": 44,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.memusage.MemoryUsage.get_virtual_size#47",
        "src_path": "scrapy/extensions/memusage.py",
        "class_name": "scrapy.extensions.memusage.MemoryUsage",
        "signature": "scrapy.extensions.memusage.MemoryUsage.get_virtual_size(self)",
        "snippet": "    def get_virtual_size(self):\n        size = self.resource.getrusage(self.resource.RUSAGE_SELF).ru_maxrss\n        if sys.platform != 'darwin':\n            # on Mac OS X ru_maxrss is in bytes, on Linux it is in KB\n            size *= 1024\n        return size",
        "begin_line": 47,
        "end_line": 52,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.memusage.MemoryUsage.engine_started#54",
        "src_path": "scrapy/extensions/memusage.py",
        "class_name": "scrapy.extensions.memusage.MemoryUsage",
        "signature": "scrapy.extensions.memusage.MemoryUsage.engine_started(self)",
        "snippet": "    def engine_started(self):\n        self.crawler.stats.set_value('memusage/startup', self.get_virtual_size())\n        self.tasks = []\n        tsk = task.LoopingCall(self.update)\n        self.tasks.append(tsk)\n        tsk.start(60.0, now=True)\n        if self.limit:\n            tsk = task.LoopingCall(self._check_limit)\n            self.tasks.append(tsk)\n            tsk.start(60.0, now=True)\n        if self.warning:\n            tsk = task.LoopingCall(self._check_warning)\n            self.tasks.append(tsk)\n            tsk.start(60.0, now=True)",
        "begin_line": 54,
        "end_line": 67,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.memusage.MemoryUsage.engine_stopped#69",
        "src_path": "scrapy/extensions/memusage.py",
        "class_name": "scrapy.extensions.memusage.MemoryUsage",
        "signature": "scrapy.extensions.memusage.MemoryUsage.engine_stopped(self)",
        "snippet": "    def engine_stopped(self):\n        for tsk in self.tasks:\n            if tsk.running:\n                tsk.stop()",
        "begin_line": 69,
        "end_line": 72,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.memusage.MemoryUsage.update#74",
        "src_path": "scrapy/extensions/memusage.py",
        "class_name": "scrapy.extensions.memusage.MemoryUsage",
        "signature": "scrapy.extensions.memusage.MemoryUsage.update(self)",
        "snippet": "    def update(self):\n        self.crawler.stats.max_value('memusage/max', self.get_virtual_size())",
        "begin_line": 74,
        "end_line": 75,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.memusage.MemoryUsage._check_limit#77",
        "src_path": "scrapy/extensions/memusage.py",
        "class_name": "scrapy.extensions.memusage.MemoryUsage",
        "signature": "scrapy.extensions.memusage.MemoryUsage._check_limit(self)",
        "snippet": "    def _check_limit(self):\n        if self.get_virtual_size() > self.limit:\n            self.crawler.stats.set_value('memusage/limit_reached', 1)\n            mem = self.limit/1024/1024\n            logger.error(\"Memory usage exceeded %(memusage)dM. Shutting down Scrapy...\",\n                         {'memusage': mem}, extra={'crawler': self.crawler})\n            if self.notify_mails:\n                subj = \"%s terminated: memory usage exceeded %dM at %s\" % \\\n                        (self.crawler.settings['BOT_NAME'], mem, socket.gethostname())\n                self._send_report(self.notify_mails, subj)\n                self.crawler.stats.set_value('memusage/limit_notified', 1)\n\n            open_spiders = self.crawler.engine.open_spiders\n            if open_spiders:\n                for spider in open_spiders:\n                    self.crawler.engine.close_spider(spider, 'memusage_exceeded')\n            else:\n                self.crawler.stop()",
        "begin_line": 77,
        "end_line": 94,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.memusage.MemoryUsage._check_warning#96",
        "src_path": "scrapy/extensions/memusage.py",
        "class_name": "scrapy.extensions.memusage.MemoryUsage",
        "signature": "scrapy.extensions.memusage.MemoryUsage._check_warning(self)",
        "snippet": "    def _check_warning(self):\n        if self.warned: # warn only once\n            return\n        if self.get_virtual_size() > self.warning:\n            self.crawler.stats.set_value('memusage/warning_reached', 1)\n            mem = self.warning/1024/1024\n            logger.warning(\"Memory usage reached %(memusage)dM\",\n                           {'memusage': mem}, extra={'crawler': self.crawler})\n            if self.notify_mails:\n                subj = \"%s warning: memory usage reached %dM at %s\" % \\\n                        (self.crawler.settings['BOT_NAME'], mem, socket.gethostname())\n                self._send_report(self.notify_mails, subj)\n                self.crawler.stats.set_value('memusage/warning_notified', 1)\n            self.warned = True",
        "begin_line": 96,
        "end_line": 109,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.memusage.MemoryUsage._send_report#111",
        "src_path": "scrapy/extensions/memusage.py",
        "class_name": "scrapy.extensions.memusage.MemoryUsage",
        "signature": "scrapy.extensions.memusage.MemoryUsage._send_report(self, rcpts, subject)",
        "snippet": "    def _send_report(self, rcpts, subject):\n        \"\"\"send notification mail with some additional useful info\"\"\"\n        stats = self.crawler.stats\n        s = \"Memory usage at engine startup : %dM\\r\\n\" % (stats.get_value('memusage/startup')/1024/1024)\n        s += \"Maximum memory usage           : %dM\\r\\n\" % (stats.get_value('memusage/max')/1024/1024)\n        s += \"Current memory usage           : %dM\\r\\n\" % (self.get_virtual_size()/1024/1024)\n\n        s += \"ENGINE STATUS ------------------------------------------------------- \\r\\n\"\n        s += \"\\r\\n\"\n        s += pformat(get_engine_status(self.crawler.engine))\n        s += \"\\r\\n\"\n        self.mail.send(rcpts, subject, s)",
        "begin_line": 111,
        "end_line": 122,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.python.get_spec#167",
        "src_path": "scrapy/utils/python.py",
        "class_name": "scrapy.utils.python",
        "signature": "scrapy.utils.python.get_spec(func)",
        "snippet": "def get_spec(func):\n    \"\"\"Returns (args, kwargs) tuple for a function\n    >>> import re\n    >>> get_spec(re.match)\n    (['pattern', 'string'], {'flags': 0})\n\n    >>> class Test(object):\n    ...     def __call__(self, val):\n    ...         pass\n    ...     def method(self, val, flags=0):\n    ...         pass\n\n    >>> get_spec(Test)\n    (['self', 'val'], {})\n\n    >>> get_spec(Test.method)\n    (['self', 'val'], {'flags': 0})\n\n    >>> get_spec(Test().method)\n    (['self', 'val'], {'flags': 0})\n    \"\"\"\n\n    if inspect.isfunction(func) or inspect.ismethod(func):\n        spec = inspect.getargspec(func)\n    elif hasattr(func, '__call__'):\n        spec = inspect.getargspec(func.__call__)\n    else:\n        raise TypeError('%s is not callable' % type(func))\n\n    defaults = spec.defaults or []\n\n    firstdefault = len(spec.args) - len(defaults)\n    args = spec.args[:firstdefault]\n    kwargs = dict(zip(spec.args[firstdefault:], defaults))\n    return args, kwargs",
        "begin_line": 167,
        "end_line": 201,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.loader.__init__.ItemLoader.__init__#27",
        "src_path": "scrapy/loader/__init__.py",
        "class_name": "scrapy.loader.__init__.ItemLoader",
        "signature": "scrapy.loader.__init__.ItemLoader.__init__(self, item=None, selector=None, response=None, **context)",
        "snippet": "    def __init__(self, item=None, selector=None, response=None, **context):\n        if selector is None and response is not None:\n            selector = self.default_selector_class(response)\n        self.selector = selector\n        context.update(selector=selector, response=response)\n        if item is None:\n            item = self.default_item_class()\n        self.item = context['item'] = item\n        self.context = context\n        self._values = defaultdict(list)",
        "begin_line": 27,
        "end_line": 36,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0011792452830188679,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.httpobj.urlparse_cached#8",
        "src_path": "scrapy/utils/httpobj.py",
        "class_name": "scrapy.utils.httpobj",
        "signature": "scrapy.utils.httpobj.urlparse_cached(request_or_response)",
        "snippet": "def urlparse_cached(request_or_response):\n    \"\"\"Return urlparse.urlparse caching the result, where the argument can be a\n    Request or Response object\n    \"\"\"\n    if request_or_response not in _urlparse_cache:\n        _urlparse_cache[request_or_response] = urlparse(request_or_response.url)\n    return _urlparse_cache[request_or_response]",
        "begin_line": 8,
        "end_line": 14,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.memdebug.MemoryDebugger.__init__#17",
        "src_path": "scrapy/extensions/memdebug.py",
        "class_name": "scrapy.extensions.memdebug.MemoryDebugger",
        "signature": "scrapy.extensions.memdebug.MemoryDebugger.__init__(self, stats)",
        "snippet": "    def __init__(self, stats):\n        self.stats = stats",
        "begin_line": 17,
        "end_line": 18,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.memdebug.MemoryDebugger.from_crawler#21",
        "src_path": "scrapy/extensions/memdebug.py",
        "class_name": "scrapy.extensions.memdebug.MemoryDebugger",
        "signature": "scrapy.extensions.memdebug.MemoryDebugger.from_crawler(cls, crawler)",
        "snippet": "    def from_crawler(cls, crawler):\n        if not crawler.settings.getbool('MEMDEBUG_ENABLED'):\n            raise NotConfigured\n        o = cls(crawler.stats)\n        crawler.signals.connect(o.spider_closed, signal=signals.spider_closed)\n        return o",
        "begin_line": 21,
        "end_line": 26,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.memdebug.MemoryDebugger.spider_closed#28",
        "src_path": "scrapy/extensions/memdebug.py",
        "class_name": "scrapy.extensions.memdebug.MemoryDebugger",
        "signature": "scrapy.extensions.memdebug.MemoryDebugger.spider_closed(self, spider, reason)",
        "snippet": "    def spider_closed(self, spider, reason):\n        gc.collect()\n        self.stats.set_value('memdebug/gc_garbage_count', len(gc.garbage), spider=spider)\n        for cls, wdict in six.iteritems(live_refs):\n            if not wdict:\n                continue\n            self.stats.set_value('memdebug/live_refs/%s' % cls.__name__, len(wdict), spider=spider)",
        "begin_line": 28,
        "end_line": 34,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.throttle.AutoThrottle.__init__#11",
        "src_path": "scrapy/extensions/throttle.py",
        "class_name": "scrapy.extensions.throttle.AutoThrottle",
        "signature": "scrapy.extensions.throttle.AutoThrottle.__init__(self, crawler)",
        "snippet": "    def __init__(self, crawler):\n        self.crawler = crawler\n        if not crawler.settings.getbool('AUTOTHROTTLE_ENABLED'):\n            raise NotConfigured\n\n        self.debug = crawler.settings.getbool(\"AUTOTHROTTLE_DEBUG\")\n        crawler.signals.connect(self._spider_opened, signal=signals.spider_opened)\n        crawler.signals.connect(self._response_downloaded, signal=signals.response_downloaded)",
        "begin_line": 11,
        "end_line": 18,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.throttle.AutoThrottle.from_crawler#21",
        "src_path": "scrapy/extensions/throttle.py",
        "class_name": "scrapy.extensions.throttle.AutoThrottle",
        "signature": "scrapy.extensions.throttle.AutoThrottle.from_crawler(cls, crawler)",
        "snippet": "    def from_crawler(cls, crawler):\n        return cls(crawler)",
        "begin_line": 21,
        "end_line": 22,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.throttle.AutoThrottle._spider_opened#24",
        "src_path": "scrapy/extensions/throttle.py",
        "class_name": "scrapy.extensions.throttle.AutoThrottle",
        "signature": "scrapy.extensions.throttle.AutoThrottle._spider_opened(self, spider)",
        "snippet": "    def _spider_opened(self, spider):\n        self.mindelay = self._min_delay(spider)\n        self.maxdelay = self._max_delay(spider)\n        spider.download_delay = self._start_delay(spider)",
        "begin_line": 24,
        "end_line": 27,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.throttle.AutoThrottle._min_delay#29",
        "src_path": "scrapy/extensions/throttle.py",
        "class_name": "scrapy.extensions.throttle.AutoThrottle",
        "signature": "scrapy.extensions.throttle.AutoThrottle._min_delay(self, spider)",
        "snippet": "    def _min_delay(self, spider):\n        s = self.crawler.settings\n        return getattr(spider, 'download_delay', 0.0) or \\\n            s.getfloat('AUTOTHROTTLE_MIN_DOWNLOAD_DELAY') or \\\n            s.getfloat('DOWNLOAD_DELAY')",
        "begin_line": 29,
        "end_line": 33,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.throttle.AutoThrottle._max_delay#35",
        "src_path": "scrapy/extensions/throttle.py",
        "class_name": "scrapy.extensions.throttle.AutoThrottle",
        "signature": "scrapy.extensions.throttle.AutoThrottle._max_delay(self, spider)",
        "snippet": "    def _max_delay(self, spider):\n        return self.crawler.settings.getfloat('AUTOTHROTTLE_MAX_DELAY', 60.0)",
        "begin_line": 35,
        "end_line": 36,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.throttle.AutoThrottle._start_delay#38",
        "src_path": "scrapy/extensions/throttle.py",
        "class_name": "scrapy.extensions.throttle.AutoThrottle",
        "signature": "scrapy.extensions.throttle.AutoThrottle._start_delay(self, spider)",
        "snippet": "    def _start_delay(self, spider):\n        return max(self.mindelay, self.crawler.settings.getfloat('AUTOTHROTTLE_START_DELAY', 5.0))",
        "begin_line": 38,
        "end_line": 39,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.throttle.AutoThrottle._response_downloaded#41",
        "src_path": "scrapy/extensions/throttle.py",
        "class_name": "scrapy.extensions.throttle.AutoThrottle",
        "signature": "scrapy.extensions.throttle.AutoThrottle._response_downloaded(self, response, request, spider)",
        "snippet": "    def _response_downloaded(self, response, request, spider):\n        key, slot = self._get_slot(request, spider)\n        latency = request.meta.get('download_latency')\n        if latency is None or slot is None:\n            return\n\n        olddelay = slot.delay\n        self._adjust_delay(slot, latency, response)\n        if self.debug:\n            diff = slot.delay - olddelay\n            size = len(response.body)\n            conc = len(slot.transferring)\n            logger.info(\n                \"slot: %(slot)s | conc:%(concurrency)2d | \"\n                \"delay:%(delay)5d ms (%(delaydiff)+d) | \"\n                \"latency:%(latency)5d ms | size:%(size)6d bytes\",\n                {\n                    'slot': key, 'concurrency': conc,\n                    'delay': slot.delay * 1000, 'delaydiff': diff * 1000,\n                    'latency': latency * 1000, 'size': size\n                },\n                extra={'spider': spider}\n            )",
        "begin_line": 41,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.throttle.AutoThrottle._get_slot#65",
        "src_path": "scrapy/extensions/throttle.py",
        "class_name": "scrapy.extensions.throttle.AutoThrottle",
        "signature": "scrapy.extensions.throttle.AutoThrottle._get_slot(self, request, spider)",
        "snippet": "    def _get_slot(self, request, spider):\n        key = request.meta.get('download_slot')\n        return key, self.crawler.engine.downloader.slots.get(key)",
        "begin_line": 65,
        "end_line": 67,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.throttle.AutoThrottle._adjust_delay#69",
        "src_path": "scrapy/extensions/throttle.py",
        "class_name": "scrapy.extensions.throttle.AutoThrottle",
        "signature": "scrapy.extensions.throttle.AutoThrottle._adjust_delay(self, slot, latency, response)",
        "snippet": "    def _adjust_delay(self, slot, latency, response):\n        \"\"\"Define delay adjustment policy\"\"\"\n        # If latency is bigger than old delay, then use latency instead of mean.\n        # It works better with problematic sites\n        new_delay = min(max(self.mindelay, latency, (slot.delay + latency) / 2.0), self.maxdelay)\n\n        # Dont adjust delay if response status != 200 and new delay is smaller\n        # than old one, as error pages (and redirections) are usually small and\n        # so tend to reduce latency, thus provoking a positive feedback by\n        # reducing delay instead of increase.\n        if response.status == 200 or new_delay > slot.delay:\n            slot.delay = new_delay",
        "begin_line": 69,
        "end_line": 80,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.spiderstate.SpiderState.__init__#10",
        "src_path": "scrapy/extensions/spiderstate.py",
        "class_name": "scrapy.extensions.spiderstate.SpiderState",
        "signature": "scrapy.extensions.spiderstate.SpiderState.__init__(self, jobdir=None)",
        "snippet": "    def __init__(self, jobdir=None):\n        self.jobdir = jobdir",
        "begin_line": 10,
        "end_line": 11,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0011792452830188679,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.spiderstate.SpiderState.from_crawler#14",
        "src_path": "scrapy/extensions/spiderstate.py",
        "class_name": "scrapy.extensions.spiderstate.SpiderState",
        "signature": "scrapy.extensions.spiderstate.SpiderState.from_crawler(cls, crawler)",
        "snippet": "    def from_crawler(cls, crawler):\n        obj = cls(job_dir(crawler.settings))\n        crawler.signals.connect(obj.spider_closed, signal=signals.spider_closed)\n        crawler.signals.connect(obj.spider_opened, signal=signals.spider_opened)\n        return obj",
        "begin_line": 14,
        "end_line": 18,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.spiderstate.SpiderState.spider_closed#20",
        "src_path": "scrapy/extensions/spiderstate.py",
        "class_name": "scrapy.extensions.spiderstate.SpiderState",
        "signature": "scrapy.extensions.spiderstate.SpiderState.spider_closed(self, spider)",
        "snippet": "    def spider_closed(self, spider):\n        if self.jobdir:\n            with open(self.statefn, 'wb') as f:\n                pickle.dump(spider.state, f, protocol=2)",
        "begin_line": 20,
        "end_line": 23,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.spiderstate.SpiderState.spider_opened#25",
        "src_path": "scrapy/extensions/spiderstate.py",
        "class_name": "scrapy.extensions.spiderstate.SpiderState",
        "signature": "scrapy.extensions.spiderstate.SpiderState.spider_opened(self, spider)",
        "snippet": "    def spider_opened(self, spider):\n        if self.jobdir and os.path.exists(self.statefn):\n            with open(self.statefn, 'rb') as f:\n                spider.state = pickle.load(f)\n        else:\n            spider.state = {}",
        "begin_line": 25,
        "end_line": 30,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.spiderstate.SpiderState.statefn#33",
        "src_path": "scrapy/extensions/spiderstate.py",
        "class_name": "scrapy.extensions.spiderstate.SpiderState",
        "signature": "scrapy.extensions.spiderstate.SpiderState.statefn(self)",
        "snippet": "    def statefn(self):\n        return os.path.join(self.jobdir, 'spider.state')",
        "begin_line": 33,
        "end_line": 34,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.http.decode_chunked_transfer#9",
        "src_path": "scrapy/utils/http.py",
        "class_name": "scrapy.utils.http",
        "signature": "scrapy.utils.http.decode_chunked_transfer(chunked_body)",
        "snippet": "def decode_chunked_transfer(chunked_body):\n    \"\"\"Parsed body received with chunked transfer encoding, and return the\n    decoded body.\n\n    For more info see:\n    http://en.wikipedia.org/wiki/Chunked_transfer_encoding\n\n    \"\"\"\n    body, h, t = '', '', chunked_body\n    while t:\n        h, t = t.split('\\r\\n', 1)\n        if h == '0':\n            break\n        size = int(h, 16)\n        body += t[:size]\n        t = t[size+2:]\n    return body",
        "begin_line": 9,
        "end_line": 25,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.signalmanager.SignalManager.__init__#6",
        "src_path": "scrapy/signalmanager.py",
        "class_name": "scrapy.signalmanager.SignalManager",
        "signature": "scrapy.signalmanager.SignalManager.__init__(self, sender=dispatcher.Anonymous)",
        "snippet": "    def __init__(self, sender=dispatcher.Anonymous):\n        self.sender = sender",
        "begin_line": 6,
        "end_line": 7,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.signalmanager.SignalManager.connect#9",
        "src_path": "scrapy/signalmanager.py",
        "class_name": "scrapy.signalmanager.SignalManager",
        "signature": "scrapy.signalmanager.SignalManager.connect(self, *a, **kw)",
        "snippet": "    def connect(self, *a, **kw):\n        kw.setdefault('sender', self.sender)\n        return dispatcher.connect(*a, **kw)",
        "begin_line": 9,
        "end_line": 11,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.closespider.CloseSpider.__init__#16",
        "src_path": "scrapy/extensions/closespider.py",
        "class_name": "scrapy.extensions.closespider.CloseSpider",
        "signature": "scrapy.extensions.closespider.CloseSpider.__init__(self, crawler)",
        "snippet": "    def __init__(self, crawler):\n        self.crawler = crawler\n\n        self.close_on = {\n            'timeout': crawler.settings.getfloat('CLOSESPIDER_TIMEOUT'),\n            'itemcount': crawler.settings.getint('CLOSESPIDER_ITEMCOUNT'),\n            'pagecount': crawler.settings.getint('CLOSESPIDER_PAGECOUNT'),\n            'errorcount': crawler.settings.getint('CLOSESPIDER_ERRORCOUNT'),\n            }\n\n        self.counter = defaultdict(int)\n\n        if self.close_on.get('errorcount'):\n            crawler.signals.connect(self.error_count, signal=signals.spider_error)\n        if self.close_on.get('pagecount'):\n            crawler.signals.connect(self.page_count, signal=signals.response_received)\n        if self.close_on.get('timeout'):\n            crawler.signals.connect(self.spider_opened, signal=signals.spider_opened)\n        if self.close_on.get('itemcount'):\n            crawler.signals.connect(self.item_scraped, signal=signals.item_scraped)\n        crawler.signals.connect(self.spider_closed, signal=signals.spider_closed)",
        "begin_line": 16,
        "end_line": 36,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.closespider.CloseSpider.from_crawler#39",
        "src_path": "scrapy/extensions/closespider.py",
        "class_name": "scrapy.extensions.closespider.CloseSpider",
        "signature": "scrapy.extensions.closespider.CloseSpider.from_crawler(cls, crawler)",
        "snippet": "    def from_crawler(cls, crawler):\n        return cls(crawler)",
        "begin_line": 39,
        "end_line": 40,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.closespider.CloseSpider.error_count#42",
        "src_path": "scrapy/extensions/closespider.py",
        "class_name": "scrapy.extensions.closespider.CloseSpider",
        "signature": "scrapy.extensions.closespider.CloseSpider.error_count(self, failure, response, spider)",
        "snippet": "    def error_count(self, failure, response, spider):\n        self.counter['errorcount'] += 1\n        if self.counter['errorcount'] == self.close_on['errorcount']:\n            self.crawler.engine.close_spider(spider, 'closespider_errorcount')",
        "begin_line": 42,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.closespider.CloseSpider.page_count#47",
        "src_path": "scrapy/extensions/closespider.py",
        "class_name": "scrapy.extensions.closespider.CloseSpider",
        "signature": "scrapy.extensions.closespider.CloseSpider.page_count(self, response, request, spider)",
        "snippet": "    def page_count(self, response, request, spider):\n        self.counter['pagecount'] += 1\n        if self.counter['pagecount'] == self.close_on['pagecount']:\n            self.crawler.engine.close_spider(spider, 'closespider_pagecount')",
        "begin_line": 47,
        "end_line": 50,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.closespider.CloseSpider.spider_opened#52",
        "src_path": "scrapy/extensions/closespider.py",
        "class_name": "scrapy.extensions.closespider.CloseSpider",
        "signature": "scrapy.extensions.closespider.CloseSpider.spider_opened(self, spider)",
        "snippet": "    def spider_opened(self, spider):\n        self.task = reactor.callLater(self.close_on['timeout'], \\\n            self.crawler.engine.close_spider, spider, \\\n            reason='closespider_timeout')",
        "begin_line": 52,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.closespider.CloseSpider.item_scraped#57",
        "src_path": "scrapy/extensions/closespider.py",
        "class_name": "scrapy.extensions.closespider.CloseSpider",
        "signature": "scrapy.extensions.closespider.CloseSpider.item_scraped(self, item, spider)",
        "snippet": "    def item_scraped(self, item, spider):\n        self.counter['itemcount'] += 1\n        if self.counter['itemcount'] == self.close_on['itemcount']:\n            self.crawler.engine.close_spider(spider, 'closespider_itemcount')",
        "begin_line": 57,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.closespider.CloseSpider.spider_closed#62",
        "src_path": "scrapy/extensions/closespider.py",
        "class_name": "scrapy.extensions.closespider.CloseSpider",
        "signature": "scrapy.extensions.closespider.CloseSpider.spider_closed(self, spider)",
        "snippet": "    def spider_closed(self, spider):\n        task = getattr(self, 'task', False)\n        if task and task.active():\n            task.cancel()",
        "begin_line": 62,
        "end_line": 65,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.mail.MailSender.__init__#30",
        "src_path": "scrapy/mail.py",
        "class_name": "scrapy.mail.MailSender",
        "signature": "scrapy.mail.MailSender.__init__(self, smtphost='localhost', mailfrom='scrapy@localhost', smtpuser=None, smtppass=None, smtpport=25, smtptls=False, smtpssl=False, debug=False)",
        "snippet": "    def __init__(self, smtphost='localhost', mailfrom='scrapy@localhost',\n            smtpuser=None, smtppass=None, smtpport=25, smtptls=False, smtpssl=False, debug=False):\n        self.smtphost = smtphost\n        self.smtpport = smtpport\n        self.smtpuser = smtpuser\n        self.smtppass = smtppass\n        self.smtptls = smtptls\n        self.smtpssl = smtpssl\n        self.mailfrom = mailfrom\n        self.debug = debug",
        "begin_line": 30,
        "end_line": 39,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.mail.MailSender.from_settings#42",
        "src_path": "scrapy/mail.py",
        "class_name": "scrapy.mail.MailSender",
        "signature": "scrapy.mail.MailSender.from_settings(cls, settings)",
        "snippet": "    def from_settings(cls, settings):\n        return cls(settings['MAIL_HOST'], settings['MAIL_FROM'], settings['MAIL_USER'],\n            settings['MAIL_PASS'], settings.getint('MAIL_PORT'),\n            settings.getbool('MAIL_TLS'), settings.getbool('MAIL_SSL'))",
        "begin_line": 42,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.mail.MailSender.send#47",
        "src_path": "scrapy/mail.py",
        "class_name": "scrapy.mail.MailSender",
        "signature": "scrapy.mail.MailSender.send(self, to, subject, body, cc=None, attachs=(), mimetype='text/plain', _callback=None)",
        "snippet": "    def send(self, to, subject, body, cc=None, attachs=(), mimetype='text/plain', _callback=None):\n        if attachs:\n            msg = MIMEMultipart()\n        else:\n            msg = MIMENonMultipart(*mimetype.split('/', 1))\n        msg['From'] = self.mailfrom\n        msg['To'] = COMMASPACE.join(to)\n        msg['Date'] = formatdate(localtime=True)\n        msg['Subject'] = subject\n        rcpts = to[:]\n        if cc:\n            rcpts.extend(cc)\n            msg['Cc'] = COMMASPACE.join(cc)\n\n        if attachs:\n            msg.attach(MIMEText(body))\n            for attach_name, mimetype, f in attachs:\n                part = MIMEBase(*mimetype.split('/'))\n                part.set_payload(f.read())\n                Encoders.encode_base64(part)\n                part.add_header('Content-Disposition', 'attachment; filename=\"%s\"' \\\n                    % attach_name)\n                msg.attach(part)\n        else:\n            msg.set_payload(body)\n\n        if _callback:\n            _callback(to=to, subject=subject, body=body, cc=cc, attach=attachs, msg=msg)\n\n        if self.debug:\n            logger.debug('Debug mail sent OK: To=%(mailto)s Cc=%(mailcc)s '\n                         'Subject=\"%(mailsubject)s\" Attachs=%(mailattachs)d',\n                         {'mailto': to, 'mailcc': cc, 'mailsubject': subject,\n                          'mailattachs': len(attachs)})\n            return\n\n        dfd = self._sendmail(rcpts, msg.as_string())\n        dfd.addCallbacks(self._sent_ok, self._sent_failed,\n            callbackArgs=[to, cc, subject, len(attachs)],\n            errbackArgs=[to, cc, subject, len(attachs)])\n        reactor.addSystemEventTrigger('before', 'shutdown', lambda: dfd)\n        return dfd",
        "begin_line": 47,
        "end_line": 88,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.mail.MailSender._sent_ok#90",
        "src_path": "scrapy/mail.py",
        "class_name": "scrapy.mail.MailSender",
        "signature": "scrapy.mail.MailSender._sent_ok(self, result, to, cc, subject, nattachs)",
        "snippet": "    def _sent_ok(self, result, to, cc, subject, nattachs):\n        logger.info('Mail sent OK: To=%(mailto)s Cc=%(mailcc)s '\n                    'Subject=\"%(mailsubject)s\" Attachs=%(mailattachs)d',\n                    {'mailto': to, 'mailcc': cc, 'mailsubject': subject,\n                     'mailattachs': nattachs})",
        "begin_line": 90,
        "end_line": 94,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.mail.MailSender._sent_failed#96",
        "src_path": "scrapy/mail.py",
        "class_name": "scrapy.mail.MailSender",
        "signature": "scrapy.mail.MailSender._sent_failed(self, failure, to, cc, subject, nattachs)",
        "snippet": "    def _sent_failed(self, failure, to, cc, subject, nattachs):\n        errstr = str(failure.value)\n        logger.error('Unable to send mail: To=%(mailto)s Cc=%(mailcc)s '\n                     'Subject=\"%(mailsubject)s\" Attachs=%(mailattachs)d'\n                     '- %(mailerr)s',\n                     {'mailto': to, 'mailcc': cc, 'mailsubject': subject,\n                      'mailattachs': nattachs, 'mailerr': errstr})",
        "begin_line": 96,
        "end_line": 102,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.mail.MailSender._sendmail#104",
        "src_path": "scrapy/mail.py",
        "class_name": "scrapy.mail.MailSender",
        "signature": "scrapy.mail.MailSender._sendmail(self, to_addrs, msg)",
        "snippet": "    def _sendmail(self, to_addrs, msg):\n        msg = StringIO(msg)\n        d = defer.Deferred()\n        factory = ESMTPSenderFactory(self.smtpuser, self.smtppass, self.mailfrom, \\\n            to_addrs, msg, d, heloFallback=True, requireAuthentication=False, \\\n            requireTransportSecurity=self.smtptls)\n        factory.noisy = False\n\n        if self.smtpssl:\n            reactor.connectSSL(self.smtphost, self.smtpport, factory, ssl.ClientContextFactory())\n        else:\n            reactor.connectTCP(self.smtphost, self.smtpport, factory)\n\n        return d",
        "begin_line": 104,
        "end_line": 117,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.signal.disconnect_all#66",
        "src_path": "scrapy/utils/signal.py",
        "class_name": "scrapy.utils.signal",
        "signature": "scrapy.utils.signal.disconnect_all(signal=Any, sender=Any)",
        "snippet": "def disconnect_all(signal=Any, sender=Any):\n    \"\"\"Disconnect all signal handlers. Useful for cleaning up after running\n    tests\n    \"\"\"\n    for receiver in liveReceivers(getAllReceivers(sender, signal)):\n        disconnect(receiver, signal=signal, sender=sender)",
        "begin_line": 66,
        "end_line": 71,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.05555555555555555,
            "pseudo_dstar_susp": 0.05555555555555555,
            "pseudo_tarantula_susp": 0.05555555555555555,
            "pseudo_op2_susp": 0.05555555555555555,
            "pseudo_barinel_susp": 0.05555555555555555
        }
    },
    {
        "name": "scrapy.utils.test.get_crawler#23",
        "src_path": "scrapy/utils/test.py",
        "class_name": "scrapy.utils.test",
        "signature": "scrapy.utils.test.get_crawler(spidercls=None, settings_dict=None)",
        "snippet": "def get_crawler(spidercls=None, settings_dict=None):\n    \"\"\"Return an unconfigured Crawler object. If settings_dict is given, it\n    will be used to populate the crawler settings with a project level\n    priority.\n    \"\"\"\n    from scrapy.crawler import CrawlerRunner\n    from scrapy.settings import Settings\n    from scrapy.spiders import Spider\n\n    runner = CrawlerRunner(Settings(settings_dict))\n    return runner._create_crawler(spidercls or Spider)",
        "begin_line": 23,
        "end_line": 33,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.trackref.object_ref.__new__#28",
        "src_path": "scrapy/utils/trackref.py",
        "class_name": "scrapy.utils.trackref.object_ref",
        "signature": "scrapy.utils.trackref.object_ref.__new__(cls, *args, **kwargs)",
        "snippet": "    def __new__(cls, *args, **kwargs):\n        obj = object.__new__(cls)\n        live_refs[cls][obj] = time()\n        return obj",
        "begin_line": 28,
        "end_line": 31,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.03225806451612903,
            "pseudo_dstar_susp": 0.03225806451612903,
            "pseudo_tarantula_susp": 0.03225806451612903,
            "pseudo_op2_susp": 0.03225806451612903,
            "pseudo_barinel_susp": 0.03225806451612903
        }
    },
    {
        "name": "scrapy.settings.__init__.SettingsAttribute.__init__#31",
        "src_path": "scrapy/settings/__init__.py",
        "class_name": "scrapy.settings.__init__.SettingsAttribute",
        "signature": "scrapy.settings.__init__.SettingsAttribute.__init__(self, value, priority)",
        "snippet": "    def __init__(self, value, priority):\n        self.value = value\n        self.priority = priority",
        "begin_line": 31,
        "end_line": 33,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.settings.__init__.SettingsAttribute.set#35",
        "src_path": "scrapy/settings/__init__.py",
        "class_name": "scrapy.settings.__init__.SettingsAttribute",
        "signature": "scrapy.settings.__init__.SettingsAttribute.set(self, value, priority)",
        "snippet": "    def set(self, value, priority):\n        \"\"\"Sets value if priority is higher or equal than current priority.\"\"\"\n        if priority >= self.priority:\n            self.value = value\n            self.priority = priority",
        "begin_line": 35,
        "end_line": 39,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.settings.__init__.Settings.__init__#50",
        "src_path": "scrapy/settings/__init__.py",
        "class_name": "scrapy.settings.__init__.Settings",
        "signature": "scrapy.settings.__init__.Settings.__init__(self, values=None, priority='project')",
        "snippet": "    def __init__(self, values=None, priority='project'):\n        self.frozen = False\n        self.attributes = {}\n        self.setmodule(default_settings, priority='default')\n        if values is not None:\n            self.setdict(values, priority)",
        "begin_line": 50,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.settings.__init__.Settings.__getitem__#57",
        "src_path": "scrapy/settings/__init__.py",
        "class_name": "scrapy.settings.__init__.Settings",
        "signature": "scrapy.settings.__init__.Settings.__getitem__(self, opt_name)",
        "snippet": "    def __getitem__(self, opt_name):\n        value = None\n        if opt_name in self.attributes:\n            value = self.attributes[opt_name].value\n        return value",
        "begin_line": 57,
        "end_line": 61,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.settings.__init__.Settings.get#63",
        "src_path": "scrapy/settings/__init__.py",
        "class_name": "scrapy.settings.__init__.Settings",
        "signature": "scrapy.settings.__init__.Settings.get(self, name, default=None)",
        "snippet": "    def get(self, name, default=None):\n        return self[name] if self[name] is not None else default",
        "begin_line": 63,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.settings.__init__.Settings.getbool#66",
        "src_path": "scrapy/settings/__init__.py",
        "class_name": "scrapy.settings.__init__.Settings",
        "signature": "scrapy.settings.__init__.Settings.getbool(self, name, default=False)",
        "snippet": "    def getbool(self, name, default=False):\n        \"\"\"\n        True is: 1, '1', True\n        False is: 0, '0', False, None\n        \"\"\"\n        return bool(int(self.get(name, default)))",
        "begin_line": 66,
        "end_line": 71,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.settings.__init__.Settings.getint#73",
        "src_path": "scrapy/settings/__init__.py",
        "class_name": "scrapy.settings.__init__.Settings",
        "signature": "scrapy.settings.__init__.Settings.getint(self, name, default=0)",
        "snippet": "    def getint(self, name, default=0):\n        return int(self.get(name, default))",
        "begin_line": 73,
        "end_line": 74,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.settings.__init__.Settings.getfloat#76",
        "src_path": "scrapy/settings/__init__.py",
        "class_name": "scrapy.settings.__init__.Settings",
        "signature": "scrapy.settings.__init__.Settings.getfloat(self, name, default=0.0)",
        "snippet": "    def getfloat(self, name, default=0.0):\n        return float(self.get(name, default))",
        "begin_line": 76,
        "end_line": 77,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.settings.__init__.Settings.getlist#79",
        "src_path": "scrapy/settings/__init__.py",
        "class_name": "scrapy.settings.__init__.Settings",
        "signature": "scrapy.settings.__init__.Settings.getlist(self, name, default=None)",
        "snippet": "    def getlist(self, name, default=None):\n        value = self.get(name, default or [])\n        if isinstance(value, six.string_types):\n            value = value.split(',')\n        return list(value)",
        "begin_line": 79,
        "end_line": 83,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.settings.__init__.Settings.set#91",
        "src_path": "scrapy/settings/__init__.py",
        "class_name": "scrapy.settings.__init__.Settings",
        "signature": "scrapy.settings.__init__.Settings.set(self, name, value, priority='project')",
        "snippet": "    def set(self, name, value, priority='project'):\n        self._assert_mutability()\n        if isinstance(priority, six.string_types):\n            priority = SETTINGS_PRIORITIES[priority]\n        if name not in self.attributes:\n            self.attributes[name] = SettingsAttribute(value, priority)\n        else:\n            self.attributes[name].set(value, priority)",
        "begin_line": 91,
        "end_line": 98,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.settings.__init__.Settings.setdict#100",
        "src_path": "scrapy/settings/__init__.py",
        "class_name": "scrapy.settings.__init__.Settings",
        "signature": "scrapy.settings.__init__.Settings.setdict(self, values, priority='project')",
        "snippet": "    def setdict(self, values, priority='project'):\n        self._assert_mutability()\n        for name, value in six.iteritems(values):\n            self.set(name, value, priority)",
        "begin_line": 100,
        "end_line": 103,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.settings.__init__.Settings.setmodule#105",
        "src_path": "scrapy/settings/__init__.py",
        "class_name": "scrapy.settings.__init__.Settings",
        "signature": "scrapy.settings.__init__.Settings.setmodule(self, module, priority='project')",
        "snippet": "    def setmodule(self, module, priority='project'):\n        self._assert_mutability()\n        if isinstance(module, six.string_types):\n            module = import_module(module)\n        for key in dir(module):\n            if key.isupper():\n                self.set(key, getattr(module, key), priority)",
        "begin_line": 105,
        "end_line": 111,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.settings.__init__.Settings._assert_mutability#113",
        "src_path": "scrapy/settings/__init__.py",
        "class_name": "scrapy.settings.__init__.Settings",
        "signature": "scrapy.settings.__init__.Settings._assert_mutability(self)",
        "snippet": "    def _assert_mutability(self):\n        if self.frozen:\n            raise TypeError(\"Trying to modify an immutable Settings object\")",
        "begin_line": 113,
        "end_line": 115,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.settings.__init__.Settings.copy#117",
        "src_path": "scrapy/settings/__init__.py",
        "class_name": "scrapy.settings.__init__.Settings",
        "signature": "scrapy.settings.__init__.Settings.copy(self)",
        "snippet": "    def copy(self):\n        return copy.deepcopy(self)",
        "begin_line": 117,
        "end_line": 118,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.settings.__init__.Settings.freeze#120",
        "src_path": "scrapy/settings/__init__.py",
        "class_name": "scrapy.settings.__init__.Settings",
        "signature": "scrapy.settings.__init__.Settings.freeze(self)",
        "snippet": "    def freeze(self):\n        self.frozen = True",
        "begin_line": 120,
        "end_line": 121,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.settings.__init__.Settings.frozencopy#123",
        "src_path": "scrapy/settings/__init__.py",
        "class_name": "scrapy.settings.__init__.Settings",
        "signature": "scrapy.settings.__init__.Settings.frozencopy(self)",
        "snippet": "    def frozencopy(self):\n        copy = self.copy()\n        copy.freeze()\n        return copy",
        "begin_line": 123,
        "end_line": 126,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.gz.gunzip#10",
        "src_path": "scrapy/utils/gz.py",
        "class_name": "scrapy.utils.gz",
        "signature": "scrapy.utils.gz.gunzip(data)",
        "snippet": "def gunzip(data):\n    \"\"\"Gunzip the given data and return as much data as possible.\n\n    This is resilient to CRC checksum errors.\n    \"\"\"\n    f = GzipFile(fileobj=BytesIO(data))\n    output = b''\n    chunk = b'.'\n    while chunk:\n        try:\n            chunk = f.read(8196)\n            output += chunk\n        except (IOError, EOFError, struct.error):\n            # complete only if there is some data, otherwise re-raise\n            # see issue 87 about catching struct.error\n            # some pages are quite small so output is '' and f.extrabuf\n            # contains the whole page content\n            if output or f.extrabuf:\n                output += f.extrabuf\n                break\n            else:\n                raise\n    return output",
        "begin_line": 10,
        "end_line": 32,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.log.TopLevelFormatter.filter#52",
        "src_path": "scrapy/utils/log.py",
        "class_name": "scrapy.utils.log.TopLevelFormatter",
        "signature": "scrapy.utils.log.TopLevelFormatter.filter(self, record)",
        "snippet": "    def filter(self, record):\n        if any(record.name.startswith(l + '.') for l in self.loggers):\n            record.name = record.name.split('.', 1)[0]\n        return True",
        "begin_line": 52,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0012330456226880395,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.log.StreamLogger.write#147",
        "src_path": "scrapy/utils/log.py",
        "class_name": "scrapy.utils.log.StreamLogger",
        "signature": "scrapy.utils.log.StreamLogger.write(self, buf)",
        "snippet": "    def write(self, buf):\n        for line in buf.rstrip().splitlines():\n            self.logger.log(self.log_level, line.rstrip())",
        "begin_line": 147,
        "end_line": 149,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.log.LogCounterHandler.emit#159",
        "src_path": "scrapy/utils/log.py",
        "class_name": "scrapy.utils.log.LogCounterHandler",
        "signature": "scrapy.utils.log.LogCounterHandler.emit(self, record)",
        "snippet": "    def emit(self, record):\n        sname = 'log_count/{}'.format(record.levelname)\n        self.crawler.stats.inc_value(sname)",
        "begin_line": 159,
        "end_line": 161,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.log.logformatter_adapter#164",
        "src_path": "scrapy/utils/log.py",
        "class_name": "scrapy.utils.log",
        "signature": "scrapy.utils.log.logformatter_adapter(logkws)",
        "snippet": "def logformatter_adapter(logkws):\n    \"\"\"\n    Helper that takes the dictionary output from the methods in LogFormatter\n    and adapts it into a tuple of positional arguments for logger.log calls,\n    handling backward compatibility as well.\n    \"\"\"\n    if not {'level', 'msg', 'args'} <= set(logkws):\n        warnings.warn('Missing keys in LogFormatter method',\n                      ScrapyDeprecationWarning)\n\n    if 'format' in logkws:\n        warnings.warn('`format` key in LogFormatter methods has been '\n                      'deprecated, use `msg` instead',\n                      ScrapyDeprecationWarning)\n\n    level = logkws.get('level', logging.INFO)\n    message = logkws.get('format', logkws.get('msg'))\n    # NOTE: This also handles 'args' being an empty dict, that case doesn't\n    # play well in logger.log calls\n    args = logkws if not logkws.get('args') else logkws['args']\n\n    return (level, message, args)",
        "begin_line": 164,
        "end_line": 185,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.url.escape_ajax#79",
        "src_path": "scrapy/utils/url.py",
        "class_name": "scrapy.utils.url",
        "signature": "scrapy.utils.url.escape_ajax(url)",
        "snippet": "def escape_ajax(url):\n    \"\"\"\n    Return the crawleable url according to:\n    http://code.google.com/web/ajaxcrawling/docs/getting-started.html\n\n    >>> escape_ajax(\"www.example.com/ajax.html#!key=value\")\n    'www.example.com/ajax.html?_escaped_fragment_=key%3Dvalue'\n    >>> escape_ajax(\"www.example.com/ajax.html?k1=v1&k2=v2#!key=value\")\n    'www.example.com/ajax.html?k1=v1&k2=v2&_escaped_fragment_=key%3Dvalue'\n    >>> escape_ajax(\"www.example.com/ajax.html?#!key=value\")\n    'www.example.com/ajax.html?_escaped_fragment_=key%3Dvalue'\n    >>> escape_ajax(\"www.example.com/ajax.html#!\")\n    'www.example.com/ajax.html?_escaped_fragment_='\n\n    URLs that are not \"AJAX crawlable\" (according to Google) returned as-is:\n\n    >>> escape_ajax(\"www.example.com/ajax.html#key=value\")\n    'www.example.com/ajax.html#key=value'\n    >>> escape_ajax(\"www.example.com/ajax.html#\")\n    'www.example.com/ajax.html#'\n    >>> escape_ajax(\"www.example.com/ajax.html\")\n    'www.example.com/ajax.html'\n    \"\"\"\n    defrag, frag = urldefrag(url)\n    if not frag.startswith('!'):\n        return url\n    return add_or_replace_parameter(defrag, '_escaped_fragment_', frag[1:])",
        "begin_line": 79,
        "end_line": 105,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0010330578512396695,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.middleware.MiddlewareManager.__init__#16",
        "src_path": "scrapy/middleware.py",
        "class_name": "scrapy.middleware.MiddlewareManager",
        "signature": "scrapy.middleware.MiddlewareManager.__init__(self, *middlewares)",
        "snippet": "    def __init__(self, *middlewares):\n        self.middlewares = middlewares\n        self.methods = defaultdict(list)\n        for mw in middlewares:\n            self._add_middleware(mw)",
        "begin_line": 16,
        "end_line": 20,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.middleware.MiddlewareManager.from_settings#27",
        "src_path": "scrapy/middleware.py",
        "class_name": "scrapy.middleware.MiddlewareManager",
        "signature": "scrapy.middleware.MiddlewareManager.from_settings(cls, settings, crawler=None)",
        "snippet": "    def from_settings(cls, settings, crawler=None):\n        mwlist = cls._get_mwlist_from_settings(settings)\n        middlewares = []\n        for clspath in mwlist:\n            try:\n                mwcls = load_object(clspath)\n                if crawler and hasattr(mwcls, 'from_crawler'):\n                    mw = mwcls.from_crawler(crawler)\n                elif hasattr(mwcls, 'from_settings'):\n                    mw = mwcls.from_settings(settings)\n                else:\n                    mw = mwcls()\n                middlewares.append(mw)\n            except NotConfigured as e:\n                if e.args:\n                    clsname = clspath.split('.')[-1]\n                    logger.warning(\"Disabled %(clsname)s: %(eargs)s\",\n                                   {'clsname': clsname, 'eargs': e.args[0]},\n                                   extra={'crawler': crawler})\n\n        enabled = [x.__class__.__name__ for x in middlewares]\n        logger.info(\"Enabled %(componentname)ss: %(enabledlist)s\",\n                    {'componentname': cls.component_name,\n                     'enabledlist': ', '.join(enabled)},\n                    extra={'crawler': crawler})\n        return cls(*middlewares)",
        "begin_line": 27,
        "end_line": 52,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.middleware.MiddlewareManager.from_crawler#55",
        "src_path": "scrapy/middleware.py",
        "class_name": "scrapy.middleware.MiddlewareManager",
        "signature": "scrapy.middleware.MiddlewareManager.from_crawler(cls, crawler)",
        "snippet": "    def from_crawler(cls, crawler):\n        return cls.from_settings(crawler.settings, crawler)",
        "begin_line": 55,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.middleware.MiddlewareManager._add_middleware#58",
        "src_path": "scrapy/middleware.py",
        "class_name": "scrapy.middleware.MiddlewareManager",
        "signature": "scrapy.middleware.MiddlewareManager._add_middleware(self, mw)",
        "snippet": "    def _add_middleware(self, mw):\n        if hasattr(mw, 'open_spider'):\n            self.methods['open_spider'].append(mw.open_spider)\n        if hasattr(mw, 'close_spider'):\n            self.methods['close_spider'].insert(0, mw.close_spider)",
        "begin_line": 58,
        "end_line": 62,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.crawler.Crawler.__init__#26",
        "src_path": "scrapy/crawler.py",
        "class_name": "scrapy.crawler.Crawler",
        "signature": "scrapy.crawler.Crawler.__init__(self, spidercls, settings)",
        "snippet": "    def __init__(self, spidercls, settings):\n        if isinstance(settings, dict):\n            settings = Settings(settings)\n\n        self.spidercls = spidercls\n        self.settings = settings.copy()\n\n        self.signals = SignalManager(self)\n        self.stats = load_object(self.settings['STATS_CLASS'])(self)\n\n        handler = LogCounterHandler(self, level=settings.get('LOG_LEVEL'))\n        logging.root.addHandler(handler)\n        self.signals.connect(lambda: logging.root.removeHandler(handler),\n                             signals.engine_stopped)\n\n        lf_cls = load_object(self.settings['LOG_FORMATTER'])\n        self.logformatter = lf_cls.from_crawler(self)\n        self.extensions = ExtensionManager.from_crawler(self)\n\n        self.spidercls.update_settings(self.settings)\n        self.settings.freeze()\n\n        self.crawling = False\n        self.spider = None\n        self.engine = None",
        "begin_line": 26,
        "end_line": 50,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.crawler.CrawlerRunner.__init__#110",
        "src_path": "scrapy/crawler.py",
        "class_name": "scrapy.crawler.CrawlerRunner",
        "signature": "scrapy.crawler.CrawlerRunner.__init__(self, settings)",
        "snippet": "    def __init__(self, settings):\n        if isinstance(settings, dict):\n            settings = Settings(settings)\n        self.settings = settings\n        self.spider_loader = _get_spider_loader(settings)\n        self._crawlers = set()\n        self._active = set()",
        "begin_line": 110,
        "end_line": 116,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.crawler.CrawlerRunner._create_crawler#162",
        "src_path": "scrapy/crawler.py",
        "class_name": "scrapy.crawler.CrawlerRunner",
        "signature": "scrapy.crawler.CrawlerRunner._create_crawler(self, spidercls)",
        "snippet": "    def _create_crawler(self, spidercls):\n        if isinstance(spidercls, six.string_types):\n            spidercls = self.spider_loader.load(spidercls)\n        return Crawler(spidercls, self.settings)",
        "begin_line": 162,
        "end_line": 165,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.crawler._get_spider_loader#262",
        "src_path": "scrapy/crawler.py",
        "class_name": "scrapy.crawler",
        "signature": "scrapy.crawler._get_spider_loader(settings)",
        "snippet": "def _get_spider_loader(settings):\n    \"\"\" Get SpiderLoader instance from settings \"\"\"\n    if settings.get('SPIDER_MANAGER_CLASS'):\n        warnings.warn(\n            'SPIDER_MANAGER_CLASS option is deprecated. '\n            'Please use SPIDER_LOADER_CLASS.',\n            category=ScrapyDeprecationWarning, stacklevel=2\n        )\n    cls_path = settings.get('SPIDER_MANAGER_CLASS',\n                            settings.get('SPIDER_LOADER_CLASS'))\n    loader_cls = load_object(cls_path)\n    try:\n        verifyClass(ISpiderLoader, loader_cls)\n    except DoesNotImplement:\n        warnings.warn(\n            'SPIDER_LOADER_CLASS (previously named SPIDER_MANAGER_CLASS) does '\n            'not fully implement scrapy.interfaces.ISpiderLoader interface. '\n            'Please add all missing methods to avoid unexpected runtime errors.',\n            category=ScrapyDeprecationWarning, stacklevel=2\n        )\n    return loader_cls.from_settings(settings.frozencopy())",
        "begin_line": 262,
        "end_line": 282,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.spiders.__init__.Spider.__init__#25",
        "src_path": "scrapy/spiders/__init__.py",
        "class_name": "scrapy.spiders.__init__.Spider",
        "signature": "scrapy.spiders.__init__.Spider.__init__(self, name=None, **kwargs)",
        "snippet": "    def __init__(self, name=None, **kwargs):\n        if name is not None:\n            self.name = name\n        elif not getattr(self, 'name', None):\n            raise ValueError(\"%s must have a name\" % type(self).__name__)\n        self.__dict__.update(kwargs)\n        if not hasattr(self, 'start_urls'):\n            self.start_urls = []",
        "begin_line": 25,
        "end_line": 32,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.041666666666666664,
            "pseudo_dstar_susp": 0.041666666666666664,
            "pseudo_tarantula_susp": 0.041666666666666664,
            "pseudo_op2_susp": 0.041666666666666664,
            "pseudo_barinel_susp": 0.041666666666666664
        }
    },
    {
        "name": "scrapy.spiders.__init__.Spider.update_settings#79",
        "src_path": "scrapy/spiders/__init__.py",
        "class_name": "scrapy.spiders.__init__.Spider",
        "signature": "scrapy.spiders.__init__.Spider.update_settings(cls, settings)",
        "snippet": "    def update_settings(cls, settings):\n        settings.setdict(cls.custom_settings or {}, priority='spider')",
        "begin_line": 79,
        "end_line": 80,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.sitemap.Sitemap.__init__#14",
        "src_path": "scrapy/utils/sitemap.py",
        "class_name": "scrapy.utils.sitemap.Sitemap",
        "signature": "scrapy.utils.sitemap.Sitemap.__init__(self, xmltext)",
        "snippet": "    def __init__(self, xmltext):\n        xmlp = lxml.etree.XMLParser(recover=True, remove_comments=True, resolve_entities=False)\n        self._root = lxml.etree.fromstring(xmltext, parser=xmlp)\n        rt = self._root.tag\n        self.type = self._root.tag.split('}', 1)[1] if '}' in rt else rt",
        "begin_line": 14,
        "end_line": 18,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0011273957158962795,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.sitemap.Sitemap.__iter__#20",
        "src_path": "scrapy/utils/sitemap.py",
        "class_name": "scrapy.utils.sitemap.Sitemap",
        "signature": "scrapy.utils.sitemap.Sitemap.__iter__(self)",
        "snippet": "    def __iter__(self):\n        for elem in self._root.getchildren():\n            d = {}\n            for el in elem.getchildren():\n                tag = el.tag\n                name = tag.split('}', 1)[1] if '}' in tag else tag\n\n                if name == 'link':\n                    if 'href' in el.attrib:\n                        d.setdefault('alternate', []).append(el.get('href'))\n                else:\n                    d[name] = el.text.strip() if el.text else ''\n\n            if 'loc' in d:\n                yield d",
        "begin_line": 20,
        "end_line": 34,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.sitemap.sitemap_urls_from_robots#37",
        "src_path": "scrapy/utils/sitemap.py",
        "class_name": "scrapy.utils.sitemap",
        "signature": "scrapy.utils.sitemap.sitemap_urls_from_robots(robots_text)",
        "snippet": "def sitemap_urls_from_robots(robots_text):\n    \"\"\"Return an iterator over all sitemap urls contained in the given\n    robots.txt file\n    \"\"\"\n    for line in robots_text.splitlines():\n        if line.lstrip().startswith('Sitemap:'):\n            yield line.split(':', 1)[1].strip()",
        "begin_line": 37,
        "end_line": 43,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.logstats.LogStats.__init__#14",
        "src_path": "scrapy/extensions/logstats.py",
        "class_name": "scrapy.extensions.logstats.LogStats",
        "signature": "scrapy.extensions.logstats.LogStats.__init__(self, stats, interval=60.0)",
        "snippet": "    def __init__(self, stats, interval=60.0):\n        self.stats = stats\n        self.interval = interval\n        self.multiplier = 60.0 / self.interval",
        "begin_line": 14,
        "end_line": 17,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.logstats.LogStats.from_crawler#20",
        "src_path": "scrapy/extensions/logstats.py",
        "class_name": "scrapy.extensions.logstats.LogStats",
        "signature": "scrapy.extensions.logstats.LogStats.from_crawler(cls, crawler)",
        "snippet": "    def from_crawler(cls, crawler):\n        interval = crawler.settings.getfloat('LOGSTATS_INTERVAL')\n        if not interval:\n            raise NotConfigured\n        o = cls(crawler.stats, interval)\n        crawler.signals.connect(o.spider_opened, signal=signals.spider_opened)\n        crawler.signals.connect(o.spider_closed, signal=signals.spider_closed)\n        return o",
        "begin_line": 20,
        "end_line": 27,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.logstats.LogStats.spider_opened#29",
        "src_path": "scrapy/extensions/logstats.py",
        "class_name": "scrapy.extensions.logstats.LogStats",
        "signature": "scrapy.extensions.logstats.LogStats.spider_opened(self, spider)",
        "snippet": "    def spider_opened(self, spider):\n        self.pagesprev = 0\n        self.itemsprev = 0\n\n        self.task = task.LoopingCall(self.log, spider)\n        self.task.start(self.interval)",
        "begin_line": 29,
        "end_line": 34,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.logstats.LogStats.log#36",
        "src_path": "scrapy/extensions/logstats.py",
        "class_name": "scrapy.extensions.logstats.LogStats",
        "signature": "scrapy.extensions.logstats.LogStats.log(self, spider)",
        "snippet": "    def log(self, spider):\n        items = self.stats.get_value('item_scraped_count', 0)\n        pages = self.stats.get_value('response_received_count', 0)\n        irate = (items - self.itemsprev) * self.multiplier\n        prate = (pages - self.pagesprev) * self.multiplier\n        self.pagesprev, self.itemsprev = pages, items\n\n        msg = (\"Crawled %(pages)d pages (at %(pagerate)d pages/min), \"\n               \"scraped %(items)d items (at %(itemrate)d items/min)\")\n        log_args = {'pages': pages, 'pagerate': prate,\n                    'items': items, 'itemrate': irate}\n        logger.info(msg, log_args, extra={'spider': spider})",
        "begin_line": 36,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.logstats.LogStats.spider_closed#49",
        "src_path": "scrapy/extensions/logstats.py",
        "class_name": "scrapy.extensions.logstats.LogStats",
        "signature": "scrapy.extensions.logstats.LogStats.spider_closed(self, spider, reason)",
        "snippet": "    def spider_closed(self, spider, reason):\n        if self.task.running:\n            self.task.stop()",
        "begin_line": 49,
        "end_line": 51,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extension.ExtensionManager._get_mwlist_from_settings#14",
        "src_path": "scrapy/extension.py",
        "class_name": "scrapy.extension.ExtensionManager",
        "signature": "scrapy.extension.ExtensionManager._get_mwlist_from_settings(cls, settings)",
        "snippet": "    def _get_mwlist_from_settings(cls, settings):\n        return build_component_list(settings['EXTENSIONS_BASE'], \\\n            settings['EXTENSIONS'])",
        "begin_line": 14,
        "end_line": 16,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.corestats.CoreStats.__init__#10",
        "src_path": "scrapy/extensions/corestats.py",
        "class_name": "scrapy.extensions.corestats.CoreStats",
        "signature": "scrapy.extensions.corestats.CoreStats.__init__(self, stats)",
        "snippet": "    def __init__(self, stats):\n        self.stats = stats",
        "begin_line": 10,
        "end_line": 11,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.corestats.CoreStats.from_crawler#14",
        "src_path": "scrapy/extensions/corestats.py",
        "class_name": "scrapy.extensions.corestats.CoreStats",
        "signature": "scrapy.extensions.corestats.CoreStats.from_crawler(cls, crawler)",
        "snippet": "    def from_crawler(cls, crawler):\n        o = cls(crawler.stats)\n        crawler.signals.connect(o.spider_opened, signal=signals.spider_opened)\n        crawler.signals.connect(o.spider_closed, signal=signals.spider_closed)\n        crawler.signals.connect(o.item_scraped, signal=signals.item_scraped)\n        crawler.signals.connect(o.item_dropped, signal=signals.item_dropped)\n        crawler.signals.connect(o.response_received, signal=signals.response_received)\n        return o",
        "begin_line": 14,
        "end_line": 21,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.corestats.CoreStats.spider_opened#23",
        "src_path": "scrapy/extensions/corestats.py",
        "class_name": "scrapy.extensions.corestats.CoreStats",
        "signature": "scrapy.extensions.corestats.CoreStats.spider_opened(self, spider)",
        "snippet": "    def spider_opened(self, spider):\n        self.stats.set_value('start_time', datetime.datetime.utcnow(), spider=spider)",
        "begin_line": 23,
        "end_line": 24,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.corestats.CoreStats.spider_closed#26",
        "src_path": "scrapy/extensions/corestats.py",
        "class_name": "scrapy.extensions.corestats.CoreStats",
        "signature": "scrapy.extensions.corestats.CoreStats.spider_closed(self, spider, reason)",
        "snippet": "    def spider_closed(self, spider, reason):\n        self.stats.set_value('finish_time', datetime.datetime.utcnow(), spider=spider)\n        self.stats.set_value('finish_reason', reason, spider=spider)",
        "begin_line": 26,
        "end_line": 28,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.corestats.CoreStats.item_scraped#30",
        "src_path": "scrapy/extensions/corestats.py",
        "class_name": "scrapy.extensions.corestats.CoreStats",
        "signature": "scrapy.extensions.corestats.CoreStats.item_scraped(self, item, spider)",
        "snippet": "    def item_scraped(self, item, spider):\n        self.stats.inc_value('item_scraped_count', spider=spider)",
        "begin_line": 30,
        "end_line": 31,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.corestats.CoreStats.response_received#33",
        "src_path": "scrapy/extensions/corestats.py",
        "class_name": "scrapy.extensions.corestats.CoreStats",
        "signature": "scrapy.extensions.corestats.CoreStats.response_received(self, spider)",
        "snippet": "    def response_received(self, spider):\n        self.stats.inc_value('response_received_count', spider=spider)",
        "begin_line": 33,
        "end_line": 34,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.corestats.CoreStats.item_dropped#36",
        "src_path": "scrapy/extensions/corestats.py",
        "class_name": "scrapy.extensions.corestats.CoreStats",
        "signature": "scrapy.extensions.corestats.CoreStats.item_dropped(self, item, spider, exception)",
        "snippet": "    def item_dropped(self, item, spider, exception):\n        reason = exception.__class__.__name__\n        self.stats.inc_value('item_dropped_count', spider=spider)\n        self.stats.inc_value('item_dropped_reasons_count/%s' % reason, spider=spider)",
        "begin_line": 36,
        "end_line": 39,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.contracts.__init__.ContractsManager.__init__#14",
        "src_path": "scrapy/contracts/__init__.py",
        "class_name": "scrapy.contracts.__init__.ContractsManager",
        "signature": "scrapy.contracts.__init__.ContractsManager.__init__(self, contracts)",
        "snippet": "    def __init__(self, contracts):\n        for contract in contracts:\n            self.contracts[contract.name] = contract",
        "begin_line": 14,
        "end_line": 16,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.contracts.__init__.ContractsManager.extract_contracts#27",
        "src_path": "scrapy/contracts/__init__.py",
        "class_name": "scrapy.contracts.__init__.ContractsManager",
        "signature": "scrapy.contracts.__init__.ContractsManager.extract_contracts(self, method)",
        "snippet": "    def extract_contracts(self, method):\n        contracts = []\n        for line in method.__doc__.split('\\n'):\n            line = line.strip()\n\n            if line.startswith('@'):\n                name, args = re.match(r'@(\\w+)\\s*(.*)', line).groups()\n                args = re.split(r'\\s+', args)\n\n                contracts.append(self.contracts[name](method, *args))\n\n        return contracts",
        "begin_line": 27,
        "end_line": 38,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.contracts.__init__.ContractsManager.from_method#48",
        "src_path": "scrapy/contracts/__init__.py",
        "class_name": "scrapy.contracts.__init__.ContractsManager",
        "signature": "scrapy.contracts.__init__.ContractsManager.from_method(self, method, results)",
        "snippet": "    def from_method(self, method, results):\n        contracts = self.extract_contracts(method)\n        if contracts:\n            # calculate request args\n            args, kwargs = get_spec(Request.__init__)\n            kwargs['callback'] = method\n            for contract in contracts:\n                kwargs = contract.adjust_request_args(kwargs)\n\n            # create and prepare request\n            args.remove('self')\n            if set(args).issubset(set(kwargs)):\n                request = Request(**kwargs)\n\n                # execute pre and post hooks in order\n                for contract in reversed(contracts):\n                    request = contract.add_pre_hook(request, results)\n                for contract in contracts:\n                    request = contract.add_post_hook(request, results)\n\n                self._clean_req(request, method, results)\n                return request",
        "begin_line": 48,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.contracts.__init__.ContractsManager._clean_req#71",
        "src_path": "scrapy/contracts/__init__.py",
        "class_name": "scrapy.contracts.__init__.ContractsManager",
        "signature": "scrapy.contracts.__init__.ContractsManager._clean_req(self, request, method, results)",
        "snippet": "    def _clean_req(self, request, method, results):\n        \"\"\" stop the request from returning objects and records any errors \"\"\"\n\n        cb = request.callback\n\n        @wraps(cb)\n        def cb_wrapper(response):\n            try:\n                output = cb(response)\n                output = list(iterate_spider_output(output))\n            except:\n                case = _create_testcase(method, 'callback')\n                results.addError(case, sys.exc_info())\n\n        def eb_wrapper(failure):\n            case = _create_testcase(method, 'errback')\n            exc_info = failure.value, failure.type, failure.getTracebackObject()\n            results.addError(case, exc_info)\n\n        request.callback = cb_wrapper\n        request.errback = eb_wrapper",
        "begin_line": 71,
        "end_line": 91,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.contracts.__init__.ContractsManager.cb_wrapper#77",
        "src_path": "scrapy/contracts/__init__.py",
        "class_name": "scrapy.contracts.__init__.ContractsManager",
        "signature": "scrapy.contracts.__init__.ContractsManager.cb_wrapper(response)",
        "snippet": "        def cb_wrapper(response):\n            try:\n                output = cb(response)\n                output = list(iterate_spider_output(output))\n            except:\n                case = _create_testcase(method, 'callback')\n                results.addError(case, sys.exc_info())",
        "begin_line": 77,
        "end_line": 83,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0024630541871921183,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.contracts.__init__.ContractsManager.eb_wrapper#85",
        "src_path": "scrapy/contracts/__init__.py",
        "class_name": "scrapy.contracts.__init__.ContractsManager",
        "signature": "scrapy.contracts.__init__.ContractsManager.eb_wrapper(failure)",
        "snippet": "        def eb_wrapper(failure):\n            case = _create_testcase(method, 'errback')\n            exc_info = failure.value, failure.type, failure.getTracebackObject()\n            results.addError(case, exc_info)",
        "begin_line": 85,
        "end_line": 88,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.contracts.__init__.Contract.__init__#97",
        "src_path": "scrapy/contracts/__init__.py",
        "class_name": "scrapy.contracts.__init__.Contract",
        "signature": "scrapy.contracts.__init__.Contract.__init__(self, method, *args)",
        "snippet": "    def __init__(self, method, *args):\n        self.testcase_pre = _create_testcase(method, '@%s pre-hook' % self.name)\n        self.testcase_post = _create_testcase(method, '@%s post-hook' % self.name)\n        self.args = args",
        "begin_line": 97,
        "end_line": 100,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.contracts.__init__.Contract.add_pre_hook#102",
        "src_path": "scrapy/contracts/__init__.py",
        "class_name": "scrapy.contracts.__init__.Contract",
        "signature": "scrapy.contracts.__init__.Contract.add_pre_hook(self, request, results)",
        "snippet": "    def add_pre_hook(self, request, results):\n        if hasattr(self, 'pre_process'):\n            cb = request.callback\n\n            @wraps(cb)\n            def wrapper(response):\n                try:\n                    results.startTest(self.testcase_pre)\n                    self.pre_process(response)\n                    results.stopTest(self.testcase_pre)\n                except AssertionError:\n                    results.addFailure(self.testcase_pre, sys.exc_info())\n                except Exception:\n                    results.addError(self.testcase_pre, sys.exc_info())\n                else:\n                    results.addSuccess(self.testcase_pre)\n                finally:\n                    return list(iterate_spider_output(cb(response)))\n\n            request.callback = wrapper\n\n        return request",
        "begin_line": 102,
        "end_line": 123,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.contracts.__init__.Contract.add_post_hook#125",
        "src_path": "scrapy/contracts/__init__.py",
        "class_name": "scrapy.contracts.__init__.Contract",
        "signature": "scrapy.contracts.__init__.Contract.add_post_hook(self, request, results)",
        "snippet": "    def add_post_hook(self, request, results):\n        if hasattr(self, 'post_process'):\n            cb = request.callback\n\n            @wraps(cb)\n            def wrapper(response):\n                output = list(iterate_spider_output(cb(response)))\n                try:\n                    results.startTest(self.testcase_post)\n                    self.post_process(output)\n                    results.stopTest(self.testcase_post)\n                except AssertionError:\n                    results.addFailure(self.testcase_post, sys.exc_info())\n                except Exception:\n                    results.addError(self.testcase_post, sys.exc_info())\n                else:\n                    results.addSuccess(self.testcase_post)\n                finally:\n                    return output\n\n            request.callback = wrapper\n\n        return request",
        "begin_line": 125,
        "end_line": 147,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.contracts.__init__.Contract.wrapper#130",
        "src_path": "scrapy/contracts/__init__.py",
        "class_name": "scrapy.contracts.__init__.Contract",
        "signature": "scrapy.contracts.__init__.Contract.wrapper(response)",
        "snippet": "            def wrapper(response):\n                output = list(iterate_spider_output(cb(response)))\n                try:\n                    results.startTest(self.testcase_post)\n                    self.post_process(output)\n                    results.stopTest(self.testcase_post)\n                except AssertionError:\n                    results.addFailure(self.testcase_post, sys.exc_info())\n                except Exception:\n                    results.addError(self.testcase_post, sys.exc_info())\n                else:\n                    results.addSuccess(self.testcase_post)\n                finally:\n                    return output",
        "begin_line": 130,
        "end_line": 143,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0024630541871921183,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.contracts.__init__.Contract.adjust_request_args#149",
        "src_path": "scrapy/contracts/__init__.py",
        "class_name": "scrapy.contracts.__init__.Contract",
        "signature": "scrapy.contracts.__init__.Contract.adjust_request_args(self, args)",
        "snippet": "    def adjust_request_args(self, args):\n        return args",
        "begin_line": 149,
        "end_line": 150,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.contracts.__init__._create_testcase#153",
        "src_path": "scrapy/contracts/__init__.py",
        "class_name": "scrapy.contracts.__init__",
        "signature": "scrapy.contracts.__init__._create_testcase(method, desc)",
        "snippet": "def _create_testcase(method, desc):\n    spider = method.__self__.name\n\n    class ContractTestCase(TestCase):\n        def __str__(_self):\n            return \"[%s] %s (%s)\" % (spider, method.__name__, desc)\n\n    name = '%s_%s' % (spider, method.__name__)\n    setattr(ContractTestCase, name, lambda x: x)\n    return ContractTestCase(name)",
        "begin_line": 153,
        "end_line": 162,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.contracts.__init__.ContractTestCase._create_testcase#153",
        "src_path": "scrapy/contracts/__init__.py",
        "class_name": "scrapy.contracts.__init__.ContractTestCase",
        "signature": "scrapy.contracts.__init__.ContractTestCase._create_testcase(method, desc)",
        "snippet": "def _create_testcase(method, desc):\n    spider = method.__self__.name\n\n    class ContractTestCase(TestCase):\n        def __str__(_self):\n            return \"[%s] %s (%s)\" % (spider, method.__name__, desc)\n\n    name = '%s_%s' % (spider, method.__name__)\n    setattr(ContractTestCase, name, lambda x: x)\n    return ContractTestCase(name)",
        "begin_line": 153,
        "end_line": 162,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0011627906976744186,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.contracts.__init__.ContractTestCase.__str__#157",
        "src_path": "scrapy/contracts/__init__.py",
        "class_name": "scrapy.contracts.__init__.ContractTestCase",
        "signature": "scrapy.contracts.__init__.ContractTestCase.__str__(_self)",
        "snippet": "        def __str__(_self):\n            return \"[%s] %s (%s)\" % (spider, method.__name__, desc)",
        "begin_line": 157,
        "end_line": 158,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.engine.get_engine_status#6",
        "src_path": "scrapy/utils/engine.py",
        "class_name": "scrapy.utils.engine",
        "signature": "scrapy.utils.engine.get_engine_status(engine)",
        "snippet": "def get_engine_status(engine):\n    \"\"\"Return a report of the current engine status\"\"\"\n    tests = [\n        \"time()-engine.start_time\",\n        \"engine.has_capacity()\",\n        \"len(engine.downloader.active)\",\n        \"engine.scraper.is_idle()\",\n        \"engine.spider.name\",\n        \"engine.spider_is_idle(engine.spider)\",\n        \"engine.slot.closing\",\n        \"len(engine.slot.inprogress)\",\n        \"len(engine.slot.scheduler.dqs or [])\",\n        \"len(engine.slot.scheduler.mqs)\",\n        \"len(engine.scraper.slot.queue)\",\n        \"len(engine.scraper.slot.active)\",\n        \"engine.scraper.slot.active_size\",\n        \"engine.scraper.slot.itemproc_size\",\n        \"engine.scraper.slot.needs_backout()\",\n    ]\n\n    checks = []\n    for test in tests:\n        try:\n            checks += [(test, eval(test))]\n        except Exception as e:\n            checks += [(test, \"%s (exception)\" % type(e).__name__)]\n\n    return checks",
        "begin_line": 6,
        "end_line": 33,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.engine.format_engine_status#35",
        "src_path": "scrapy/utils/engine.py",
        "class_name": "scrapy.utils.engine",
        "signature": "scrapy.utils.engine.format_engine_status(engine=None)",
        "snippet": "def format_engine_status(engine=None):\n    checks = get_engine_status(engine)\n    s = \"Execution engine status\\n\\n\"\n    for test, result in checks:\n        s += \"%-47s : %s\\n\" % (test, result)\n    s += \"\\n\"\n\n    return s",
        "begin_line": 35,
        "end_line": 42,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.engine.print_engine_status#44",
        "src_path": "scrapy/utils/engine.py",
        "class_name": "scrapy.utils.engine",
        "signature": "scrapy.utils.engine.print_engine_status(engine)",
        "snippet": "def print_engine_status(engine):\n    print(format_engine_status(engine))",
        "begin_line": 44,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.http.headers.Headers.__init__#9",
        "src_path": "scrapy/http/headers.py",
        "class_name": "scrapy.http.headers.Headers",
        "signature": "scrapy.http.headers.Headers.__init__(self, seq=None, encoding='utf-8')",
        "snippet": "    def __init__(self, seq=None, encoding='utf-8'):\n        self.encoding = encoding\n        super(Headers, self).__init__(seq)",
        "begin_line": 9,
        "end_line": 11,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0009852216748768472,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.http.headers.Headers.normkey#13",
        "src_path": "scrapy/http/headers.py",
        "class_name": "scrapy.http.headers.Headers",
        "signature": "scrapy.http.headers.Headers.normkey(self, key)",
        "snippet": "    def normkey(self, key):\n        \"\"\"Normalize key to bytes\"\"\"\n        return self._tobytes(key.title())",
        "begin_line": 13,
        "end_line": 15,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0010330578512396695,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.http.headers.Headers.normvalue#17",
        "src_path": "scrapy/http/headers.py",
        "class_name": "scrapy.http.headers.Headers",
        "signature": "scrapy.http.headers.Headers.normvalue(self, value)",
        "snippet": "    def normvalue(self, value):\n        \"\"\"Normalize values to bytes\"\"\"\n        if value is None:\n            value = []\n        elif isinstance(value, (six.text_type, bytes)):\n            value = [value]\n        elif not hasattr(value, '__iter__'):\n            value = [value]\n\n        return [self._tobytes(x) for x in value]",
        "begin_line": 17,
        "end_line": 26,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.http.headers.Headers._tobytes#28",
        "src_path": "scrapy/http/headers.py",
        "class_name": "scrapy.http.headers.Headers",
        "signature": "scrapy.http.headers.Headers._tobytes(self, x)",
        "snippet": "    def _tobytes(self, x):\n        if isinstance(x, bytes):\n            return x\n        elif isinstance(x, six.text_type):\n            return x.encode(self.encoding)\n        elif isinstance(x, int):\n            return six.text_type(x).encode(self.encoding)\n        else:\n            raise TypeError('Unsupported value type: {}'.format(type(x)))",
        "begin_line": 28,
        "end_line": 36,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.http.headers.Headers.__getitem__#38",
        "src_path": "scrapy/http/headers.py",
        "class_name": "scrapy.http.headers.Headers",
        "signature": "scrapy.http.headers.Headers.__getitem__(self, key)",
        "snippet": "    def __getitem__(self, key):\n        try:\n            return super(Headers, self).__getitem__(key)[-1]\n        except IndexError:\n            return None",
        "begin_line": 38,
        "end_line": 42,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.http.headers.Headers.get#44",
        "src_path": "scrapy/http/headers.py",
        "class_name": "scrapy.http.headers.Headers",
        "signature": "scrapy.http.headers.Headers.get(self, key, def_val=None)",
        "snippet": "    def get(self, key, def_val=None):\n        try:\n            return super(Headers, self).get(key, def_val)[-1]\n        except IndexError:\n            return None",
        "begin_line": 44,
        "end_line": 48,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0024630541871921183,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.http.headers.Headers.getlist#50",
        "src_path": "scrapy/http/headers.py",
        "class_name": "scrapy.http.headers.Headers",
        "signature": "scrapy.http.headers.Headers.getlist(self, key, def_val=None)",
        "snippet": "    def getlist(self, key, def_val=None):\n        try:\n            return super(Headers, self).__getitem__(key)\n        except KeyError:\n            if def_val is not None:\n                return self.normvalue(def_val)\n            return []",
        "begin_line": 50,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.http.headers.Headers.setlist#58",
        "src_path": "scrapy/http/headers.py",
        "class_name": "scrapy.http.headers.Headers",
        "signature": "scrapy.http.headers.Headers.setlist(self, key, list_)",
        "snippet": "    def setlist(self, key, list_):\n        self[key] = list_",
        "begin_line": 58,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.http.headers.Headers.setlistdefault#61",
        "src_path": "scrapy/http/headers.py",
        "class_name": "scrapy.http.headers.Headers",
        "signature": "scrapy.http.headers.Headers.setlistdefault(self, key, default_list=())",
        "snippet": "    def setlistdefault(self, key, default_list=()):\n        return self.setdefault(key, default_list)",
        "begin_line": 61,
        "end_line": 62,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.http.headers.Headers.appendlist#64",
        "src_path": "scrapy/http/headers.py",
        "class_name": "scrapy.http.headers.Headers",
        "signature": "scrapy.http.headers.Headers.appendlist(self, key, value)",
        "snippet": "    def appendlist(self, key, value):\n        lst = self.getlist(key)\n        lst.extend(self.normvalue(value))\n        self[key] = lst",
        "begin_line": 64,
        "end_line": 67,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.http.headers.Headers.items#69",
        "src_path": "scrapy/http/headers.py",
        "class_name": "scrapy.http.headers.Headers",
        "signature": "scrapy.http.headers.Headers.items(self)",
        "snippet": "    def items(self):\n        return list(self.iteritems())",
        "begin_line": 69,
        "end_line": 70,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.http.headers.Headers.iteritems#72",
        "src_path": "scrapy/http/headers.py",
        "class_name": "scrapy.http.headers.Headers",
        "signature": "scrapy.http.headers.Headers.iteritems(self)",
        "snippet": "    def iteritems(self):\n        return ((k, self.getlist(k)) for k in self.keys())",
        "begin_line": 72,
        "end_line": 73,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.http.headers.Headers.values#75",
        "src_path": "scrapy/http/headers.py",
        "class_name": "scrapy.http.headers.Headers",
        "signature": "scrapy.http.headers.Headers.values(self)",
        "snippet": "    def values(self):\n        return [self[k] for k in self.keys()]",
        "begin_line": 75,
        "end_line": 76,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.http.headers.Headers.__copy__#81",
        "src_path": "scrapy/http/headers.py",
        "class_name": "scrapy.http.headers.Headers",
        "signature": "scrapy.http.headers.Headers.__copy__(self)",
        "snippet": "    def __copy__(self):\n        return self.__class__(self)",
        "begin_line": 81,
        "end_line": 82,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.spidermiddlewares.urllength.UrlLengthMiddleware.__init__#17",
        "src_path": "scrapy/spidermiddlewares/urllength.py",
        "class_name": "scrapy.spidermiddlewares.urllength.UrlLengthMiddleware",
        "signature": "scrapy.spidermiddlewares.urllength.UrlLengthMiddleware.__init__(self, maxlength)",
        "snippet": "    def __init__(self, maxlength):\n        self.maxlength = maxlength",
        "begin_line": 17,
        "end_line": 18,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.spidermiddlewares.urllength.UrlLengthMiddleware.process_spider_output#27",
        "src_path": "scrapy/spidermiddlewares/urllength.py",
        "class_name": "scrapy.spidermiddlewares.urllength.UrlLengthMiddleware",
        "signature": "scrapy.spidermiddlewares.urllength.UrlLengthMiddleware.process_spider_output(self, response, result, spider)",
        "snippet": "    def process_spider_output(self, response, result, spider):\n        def _filter(request):\n            if isinstance(request, Request) and len(request.url) > self.maxlength:\n                logger.debug(\"Ignoring link (url length > %(maxlength)d): %(url)s \",\n                             {'maxlength': self.maxlength, 'url': request.url},\n                             extra={'spider': spider})\n                return False\n            else:\n                return True\n\n        return (r for r in result or () if _filter(r))",
        "begin_line": 27,
        "end_line": 37,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.spidermiddlewares.urllength.UrlLengthMiddleware._filter#28",
        "src_path": "scrapy/spidermiddlewares/urllength.py",
        "class_name": "scrapy.spidermiddlewares.urllength.UrlLengthMiddleware",
        "signature": "scrapy.spidermiddlewares.urllength.UrlLengthMiddleware._filter(request)",
        "snippet": "        def _filter(request):\n            if isinstance(request, Request) and len(request.url) > self.maxlength:\n                logger.debug(\"Ignoring link (url length > %(maxlength)d): %(url)s \",\n                             {'maxlength': self.maxlength, 'url': request.url},\n                             extra={'spider': spider})\n                return False\n            else:\n                return True",
        "begin_line": 28,
        "end_line": 35,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.conf.build_component_list#9",
        "src_path": "scrapy/utils/conf.py",
        "class_name": "scrapy.utils.conf",
        "signature": "scrapy.utils.conf.build_component_list(base, custom)",
        "snippet": "def build_component_list(base, custom):\n    \"\"\"Compose a component list based on a custom and base dict of components\n    (typically middlewares or extensions), unless custom is already a list, in\n    which case it's returned.\n    \"\"\"\n    if isinstance(custom, (list, tuple)):\n        return custom\n    compdict = base.copy()\n    compdict.update(custom)\n    items = (x for x in six.iteritems(compdict) if x[1] is not None)\n    return [x[0] for x in sorted(items, key=itemgetter(1))]",
        "begin_line": 9,
        "end_line": 19,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.conf.arglist_to_dict#22",
        "src_path": "scrapy/utils/conf.py",
        "class_name": "scrapy.utils.conf",
        "signature": "scrapy.utils.conf.arglist_to_dict(arglist)",
        "snippet": "def arglist_to_dict(arglist):\n    \"\"\"Convert a list of arguments like ['arg1=val1', 'arg2=val2', ...] to a\n    dict\n    \"\"\"\n    return dict(x.split('=', 1) for x in arglist)",
        "begin_line": 22,
        "end_line": 26,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.logformatter.LogFormatter.crawled#33",
        "src_path": "scrapy/logformatter.py",
        "class_name": "scrapy.logformatter.LogFormatter",
        "signature": "scrapy.logformatter.LogFormatter.crawled(self, request, response, spider)",
        "snippet": "    def crawled(self, request, response, spider):\n        flags = ' %s' % str(response.flags) if response.flags else ''\n        return {\n            'level': logging.DEBUG,\n            'msg': CRAWLEDMSG,\n            'args': {\n                'status': response.status,\n                'request': request,\n                'referer': request.headers.get('Referer'),\n                'flags': flags,\n            }\n        }",
        "begin_line": 33,
        "end_line": 44,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.logformatter.LogFormatter.scraped#46",
        "src_path": "scrapy/logformatter.py",
        "class_name": "scrapy.logformatter.LogFormatter",
        "signature": "scrapy.logformatter.LogFormatter.scraped(self, item, response, spider)",
        "snippet": "    def scraped(self, item, response, spider):\n        src = response.getErrorMessage() if isinstance(response, Failure) else response\n        return {\n            'level': logging.DEBUG,\n            'msg': SCRAPEDMSG,\n            'args': {\n                'src': src,\n                'item': item,\n            }\n        }",
        "begin_line": 46,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.logformatter.LogFormatter.dropped#57",
        "src_path": "scrapy/logformatter.py",
        "class_name": "scrapy.logformatter.LogFormatter",
        "signature": "scrapy.logformatter.LogFormatter.dropped(self, item, exception, response, spider)",
        "snippet": "    def dropped(self, item, exception, response, spider):\n        return {\n            'level': logging.WARNING,\n            'msg': DROPPEDMSG,\n            'args': {\n                'exception': exception,\n                'item': item,\n            }\n        }",
        "begin_line": 57,
        "end_line": 65,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.logformatter.LogFormatter.from_crawler#68",
        "src_path": "scrapy/logformatter.py",
        "class_name": "scrapy.logformatter.LogFormatter",
        "signature": "scrapy.logformatter.LogFormatter.from_crawler(cls, crawler)",
        "snippet": "    def from_crawler(cls, crawler):\n        return cls()",
        "begin_line": 68,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.datatypes.CaselessDict.__init__#167",
        "src_path": "scrapy/utils/datatypes.py",
        "class_name": "scrapy.utils.datatypes.CaselessDict",
        "signature": "scrapy.utils.datatypes.CaselessDict.__init__(self, seq=None)",
        "snippet": "    def __init__(self, seq=None):\n        super(CaselessDict, self).__init__()\n        if seq:\n            self.update(seq)",
        "begin_line": 167,
        "end_line": 170,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0010330578512396695,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.datatypes.CaselessDict.__getitem__#172",
        "src_path": "scrapy/utils/datatypes.py",
        "class_name": "scrapy.utils.datatypes.CaselessDict",
        "signature": "scrapy.utils.datatypes.CaselessDict.__getitem__(self, key)",
        "snippet": "    def __getitem__(self, key):\n        return dict.__getitem__(self, self.normkey(key))",
        "begin_line": 172,
        "end_line": 173,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.001004016064257028,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.datatypes.CaselessDict.__setitem__#175",
        "src_path": "scrapy/utils/datatypes.py",
        "class_name": "scrapy.utils.datatypes.CaselessDict",
        "signature": "scrapy.utils.datatypes.CaselessDict.__setitem__(self, key, value)",
        "snippet": "    def __setitem__(self, key, value):\n        dict.__setitem__(self, self.normkey(key), self.normvalue(value))",
        "begin_line": 175,
        "end_line": 176,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0010660980810234541,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.datatypes.CaselessDict.__delitem__#178",
        "src_path": "scrapy/utils/datatypes.py",
        "class_name": "scrapy.utils.datatypes.CaselessDict",
        "signature": "scrapy.utils.datatypes.CaselessDict.__delitem__(self, key)",
        "snippet": "    def __delitem__(self, key):\n        dict.__delitem__(self, self.normkey(key))",
        "begin_line": 178,
        "end_line": 179,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0024630541871921183,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.datatypes.CaselessDict.__contains__#181",
        "src_path": "scrapy/utils/datatypes.py",
        "class_name": "scrapy.utils.datatypes.CaselessDict",
        "signature": "scrapy.utils.datatypes.CaselessDict.__contains__(self, key)",
        "snippet": "    def __contains__(self, key):\n        return dict.__contains__(self, self.normkey(key))",
        "begin_line": 181,
        "end_line": 182,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0024630541871921183,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.datatypes.CaselessDict.__copy__#185",
        "src_path": "scrapy/utils/datatypes.py",
        "class_name": "scrapy.utils.datatypes.CaselessDict",
        "signature": "scrapy.utils.datatypes.CaselessDict.__copy__(self)",
        "snippet": "    def __copy__(self):\n        return self.__class__(self)",
        "begin_line": 185,
        "end_line": 186,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.datatypes.CaselessDict.normkey#189",
        "src_path": "scrapy/utils/datatypes.py",
        "class_name": "scrapy.utils.datatypes.CaselessDict",
        "signature": "scrapy.utils.datatypes.CaselessDict.normkey(self, key)",
        "snippet": "    def normkey(self, key):\n        \"\"\"Method to normalize dictionary key access\"\"\"\n        return key.lower()",
        "begin_line": 189,
        "end_line": 191,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0011074197120708748,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.datatypes.CaselessDict.normvalue#193",
        "src_path": "scrapy/utils/datatypes.py",
        "class_name": "scrapy.utils.datatypes.CaselessDict",
        "signature": "scrapy.utils.datatypes.CaselessDict.normvalue(self, value)",
        "snippet": "    def normvalue(self, value):\n        \"\"\"Method to normalize values prior to be setted\"\"\"\n        return value",
        "begin_line": 193,
        "end_line": 195,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0011074197120708748,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.datatypes.CaselessDict.get#197",
        "src_path": "scrapy/utils/datatypes.py",
        "class_name": "scrapy.utils.datatypes.CaselessDict",
        "signature": "scrapy.utils.datatypes.CaselessDict.get(self, key, def_val=None)",
        "snippet": "    def get(self, key, def_val=None):\n        return dict.get(self, self.normkey(key), self.normvalue(def_val))",
        "begin_line": 197,
        "end_line": 198,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.001141552511415525,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.datatypes.CaselessDict.setdefault#200",
        "src_path": "scrapy/utils/datatypes.py",
        "class_name": "scrapy.utils.datatypes.CaselessDict",
        "signature": "scrapy.utils.datatypes.CaselessDict.setdefault(self, key, def_val=None)",
        "snippet": "    def setdefault(self, key, def_val=None):\n        return dict.setdefault(self, self.normkey(key), self.normvalue(def_val))",
        "begin_line": 200,
        "end_line": 201,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0011507479861910242,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.datatypes.CaselessDict.update#203",
        "src_path": "scrapy/utils/datatypes.py",
        "class_name": "scrapy.utils.datatypes.CaselessDict",
        "signature": "scrapy.utils.datatypes.CaselessDict.update(self, seq)",
        "snippet": "    def update(self, seq):\n        seq = seq.items() if isinstance(seq, dict) else seq\n        iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)\n        super(CaselessDict, self).update(iseq)",
        "begin_line": 203,
        "end_line": 206,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.001004016064257028,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.datatypes.CaselessDict.fromkeys#209",
        "src_path": "scrapy/utils/datatypes.py",
        "class_name": "scrapy.utils.datatypes.CaselessDict",
        "signature": "scrapy.utils.datatypes.CaselessDict.fromkeys(cls, keys, value=None)",
        "snippet": "    def fromkeys(cls, keys, value=None):\n        return cls((k, value) for k in keys)",
        "begin_line": 209,
        "end_line": 210,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0012330456226880395,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.utils.datatypes.CaselessDict.pop#212",
        "src_path": "scrapy/utils/datatypes.py",
        "class_name": "scrapy.utils.datatypes.CaselessDict",
        "signature": "scrapy.utils.datatypes.CaselessDict.pop(self, key, *args)",
        "snippet": "    def pop(self, key, *args):\n        return dict.pop(self, self.normkey(key), *args)",
        "begin_line": 212,
        "end_line": 213,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.squeues.SerializableQueue.push#14",
        "src_path": "scrapy/squeues.py",
        "class_name": "scrapy.squeues.SerializableQueue",
        "signature": "scrapy.squeues.SerializableQueue.push(self, obj)",
        "snippet": "        def push(self, obj):\n            s = serialize(obj)\n            super(SerializableQueue, self).push(s)",
        "begin_line": 14,
        "end_line": 16,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.000975609756097561,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.squeues.SerializableQueue.pop#18",
        "src_path": "scrapy/squeues.py",
        "class_name": "scrapy.squeues.SerializableQueue",
        "signature": "scrapy.squeues.SerializableQueue.pop(self)",
        "snippet": "        def pop(self):\n            s = super(SerializableQueue, self).pop()\n            if s:\n                return deserialize(s)",
        "begin_line": 18,
        "end_line": 21,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.000975609756097561,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.squeues._pickle_serialize#25",
        "src_path": "scrapy/squeues.py",
        "class_name": "scrapy.squeues",
        "signature": "scrapy.squeues._pickle_serialize(obj)",
        "snippet": "def _pickle_serialize(obj):\n    try:\n        return pickle.dumps(obj, protocol=2)\n    except pickle.PicklingError as e:\n        raise ValueError(str(e))",
        "begin_line": 25,
        "end_line": 29,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0009775171065493646,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "conftest.chdir#33",
        "src_path": "conftest.py",
        "class_name": "conftest",
        "signature": "conftest.chdir(tmpdir)",
        "snippet": "def chdir(tmpdir):\n    \"\"\"Change to pytest-provided temporary directory\"\"\"\n    tmpdir.chdir()",
        "begin_line": 33,
        "end_line": 35,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.029411764705882353,
            "pseudo_dstar_susp": 0.029411764705882353,
            "pseudo_tarantula_susp": 0.029411764705882353,
            "pseudo_op2_susp": 0.029411764705882353,
            "pseudo_barinel_susp": 0.029411764705882353
        }
    },
    {
        "name": "scrapy.extensions.feedexport.StdoutFeedStorage.__init__#59",
        "src_path": "scrapy/extensions/feedexport.py",
        "class_name": "scrapy.extensions.feedexport.StdoutFeedStorage",
        "signature": "scrapy.extensions.feedexport.StdoutFeedStorage.__init__(self, uri, _stdout=sys.stdout)",
        "snippet": "    def __init__(self, uri, _stdout=sys.stdout):\n        self._stdout = _stdout",
        "begin_line": 59,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.feedexport.StdoutFeedStorage.open#62",
        "src_path": "scrapy/extensions/feedexport.py",
        "class_name": "scrapy.extensions.feedexport.StdoutFeedStorage",
        "signature": "scrapy.extensions.feedexport.StdoutFeedStorage.open(self, spider)",
        "snippet": "    def open(self, spider):\n        return self._stdout",
        "begin_line": 62,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.feedexport.StdoutFeedStorage.store#65",
        "src_path": "scrapy/extensions/feedexport.py",
        "class_name": "scrapy.extensions.feedexport.StdoutFeedStorage",
        "signature": "scrapy.extensions.feedexport.StdoutFeedStorage.store(self, file)",
        "snippet": "    def store(self, file):\n        pass",
        "begin_line": 65,
        "end_line": 66,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.feedexport.FileFeedStorage.__init__#72",
        "src_path": "scrapy/extensions/feedexport.py",
        "class_name": "scrapy.extensions.feedexport.FileFeedStorage",
        "signature": "scrapy.extensions.feedexport.FileFeedStorage.__init__(self, uri)",
        "snippet": "    def __init__(self, uri):\n        self.path = file_uri_to_path(uri)",
        "begin_line": 72,
        "end_line": 73,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0011792452830188679,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.feedexport.FileFeedStorage.open#75",
        "src_path": "scrapy/extensions/feedexport.py",
        "class_name": "scrapy.extensions.feedexport.FileFeedStorage",
        "signature": "scrapy.extensions.feedexport.FileFeedStorage.open(self, spider)",
        "snippet": "    def open(self, spider):\n        dirname = os.path.dirname(self.path)\n        if dirname and not os.path.exists(dirname):\n            os.makedirs(dirname)\n        return open(self.path, 'ab')",
        "begin_line": 75,
        "end_line": 79,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.005208333333333333,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.feedexport.FileFeedStorage.store#81",
        "src_path": "scrapy/extensions/feedexport.py",
        "class_name": "scrapy.extensions.feedexport.FileFeedStorage",
        "signature": "scrapy.extensions.feedexport.FileFeedStorage.store(self, file)",
        "snippet": "    def store(self, file):\n        file.close()",
        "begin_line": 81,
        "end_line": 82,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0012330456226880395,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.feedexport.FeedExporter.__init__#141",
        "src_path": "scrapy/extensions/feedexport.py",
        "class_name": "scrapy.extensions.feedexport.FeedExporter",
        "signature": "scrapy.extensions.feedexport.FeedExporter.__init__(self, settings)",
        "snippet": "    def __init__(self, settings):\n        self.settings = settings\n        self.urifmt = settings['FEED_URI']\n        if not self.urifmt:\n            raise NotConfigured\n        self.format = settings['FEED_FORMAT'].lower()\n        self.storages = self._load_components('FEED_STORAGES')\n        self.exporters = self._load_components('FEED_EXPORTERS')\n        if not self._storage_supported(self.urifmt):\n            raise NotConfigured\n        if not self._exporter_supported(self.format):\n            raise NotConfigured\n        self.store_empty = settings.getbool('FEED_STORE_EMPTY')\n        self.export_fields = settings.getlist('FEED_EXPORT_FIELDS')\n        uripar = settings['FEED_URI_PARAMS']\n        self._uripar = load_object(uripar) if uripar else lambda x, y: None",
        "begin_line": 141,
        "end_line": 156,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    },
    {
        "name": "scrapy.extensions.feedexport.FeedExporter.from_crawler#159",
        "src_path": "scrapy/extensions/feedexport.py",
        "class_name": "scrapy.extensions.feedexport.FeedExporter",
        "signature": "scrapy.extensions.feedexport.FeedExporter.from_crawler(cls, crawler)",
        "snippet": "    def from_crawler(cls, crawler):\n        o = cls(crawler.settings)\n        crawler.signals.connect(o.open_spider, signals.spider_opened)\n        crawler.signals.connect(o.close_spider, signals.spider_closed)\n        crawler.signals.connect(o.item_scraped, signals.item_scraped)\n        return o",
        "begin_line": 159,
        "end_line": 164,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.001876172607879925,
            "pseudo_dstar_susp": 0.001876172607879925,
            "pseudo_tarantula_susp": 0.001876172607879925,
            "pseudo_op2_susp": 0.0016051364365971107,
            "pseudo_barinel_susp": 0.001876172607879925
        }
    }
]