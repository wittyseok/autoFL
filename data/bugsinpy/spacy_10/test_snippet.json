[
    {
        "name": "spacy.tests.conftest.pytest_runtest_setup#12",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.pytest_runtest_setup(item)",
        "snippet": "def pytest_runtest_setup(item):\n    def getopt(opt):\n        # When using 'pytest --pyargs spacy' to test an installed copy of\n        # spacy, pytest skips running our pytest_addoption() hook. Later, when\n        # we call getoption(), pytest raises an error, because it doesn't\n        # recognize the option we're asking about. To avoid this, we need to\n        # pass a default value. We default to False, i.e., we act like all the\n        # options weren't given.\n        return item.config.getoption(\"--%s\" % opt, False)\n\n    for opt in [\"slow\"]:\n        if opt in item.keywords and not getopt(opt):\n            pytest.skip(\"need --%s option to run\" % opt)",
        "begin_line": 12,
        "end_line": 24,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.getopt#13",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.getopt(opt)",
        "snippet": "    def getopt(opt):\n        # When using 'pytest --pyargs spacy' to test an installed copy of\n        # spacy, pytest skips running our pytest_addoption() hook. Later, when\n        # we call getoption(), pytest raises an error, because it doesn't\n        # recognize the option we're asking about. To avoid this, we need to\n        # pass a default value. We default to False, i.e., we act like all the\n        # options weren't given.\n        return item.config.getoption(\"--%s\" % opt, False)",
        "begin_line": 13,
        "end_line": 20,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.tokenizer#31",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.tokenizer()",
        "snippet": "def tokenizer():\n    return get_lang_class(\"xx\").Defaults.create_tokenizer()",
        "begin_line": 31,
        "end_line": 32,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.ar_tokenizer#36",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.ar_tokenizer()",
        "snippet": "def ar_tokenizer():\n    return get_lang_class(\"ar\").Defaults.create_tokenizer()",
        "begin_line": 36,
        "end_line": 37,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.bn_tokenizer#41",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.bn_tokenizer()",
        "snippet": "def bn_tokenizer():\n    return get_lang_class(\"bn\").Defaults.create_tokenizer()",
        "begin_line": 41,
        "end_line": 42,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.ca_tokenizer#46",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.ca_tokenizer()",
        "snippet": "def ca_tokenizer():\n    return get_lang_class(\"ca\").Defaults.create_tokenizer()",
        "begin_line": 46,
        "end_line": 47,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.da_tokenizer#51",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.da_tokenizer()",
        "snippet": "def da_tokenizer():\n    return get_lang_class(\"da\").Defaults.create_tokenizer()",
        "begin_line": 51,
        "end_line": 52,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.de_tokenizer#56",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.de_tokenizer()",
        "snippet": "def de_tokenizer():\n    return get_lang_class(\"de\").Defaults.create_tokenizer()",
        "begin_line": 56,
        "end_line": 57,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.el_tokenizer#61",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.el_tokenizer()",
        "snippet": "def el_tokenizer():\n    return get_lang_class(\"el\").Defaults.create_tokenizer()",
        "begin_line": 61,
        "end_line": 62,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.en_tokenizer#66",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.en_tokenizer()",
        "snippet": "def en_tokenizer():\n    return get_lang_class(\"en\").Defaults.create_tokenizer()",
        "begin_line": 66,
        "end_line": 67,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.en_vocab#71",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.en_vocab()",
        "snippet": "def en_vocab():\n    return get_lang_class(\"en\").Defaults.create_vocab()",
        "begin_line": 71,
        "end_line": 72,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.es_tokenizer#82",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.es_tokenizer()",
        "snippet": "def es_tokenizer():\n    return get_lang_class(\"es\").Defaults.create_tokenizer()",
        "begin_line": 82,
        "end_line": 83,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.fi_tokenizer#87",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.fi_tokenizer()",
        "snippet": "def fi_tokenizer():\n    return get_lang_class(\"fi\").Defaults.create_tokenizer()",
        "begin_line": 87,
        "end_line": 88,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.fr_tokenizer#92",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.fr_tokenizer()",
        "snippet": "def fr_tokenizer():\n    return get_lang_class(\"fr\").Defaults.create_tokenizer()",
        "begin_line": 92,
        "end_line": 93,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.ga_tokenizer#97",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.ga_tokenizer()",
        "snippet": "def ga_tokenizer():\n    return get_lang_class(\"ga\").Defaults.create_tokenizer()",
        "begin_line": 97,
        "end_line": 98,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.he_tokenizer#102",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.he_tokenizer()",
        "snippet": "def he_tokenizer():\n    return get_lang_class(\"he\").Defaults.create_tokenizer()",
        "begin_line": 102,
        "end_line": 103,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.hr_tokenizer#107",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.hr_tokenizer()",
        "snippet": "def hr_tokenizer():\n    return get_lang_class(\"hr\").Defaults.create_tokenizer()",
        "begin_line": 107,
        "end_line": 108,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.hu_tokenizer#112",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.hu_tokenizer()",
        "snippet": "def hu_tokenizer():\n    return get_lang_class(\"hu\").Defaults.create_tokenizer()",
        "begin_line": 112,
        "end_line": 113,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.id_tokenizer#117",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.id_tokenizer()",
        "snippet": "def id_tokenizer():\n    return get_lang_class(\"id\").Defaults.create_tokenizer()",
        "begin_line": 117,
        "end_line": 118,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.it_tokenizer#122",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.it_tokenizer()",
        "snippet": "def it_tokenizer():\n    return get_lang_class(\"it\").Defaults.create_tokenizer()",
        "begin_line": 122,
        "end_line": 123,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.lt_tokenizer#139",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.lt_tokenizer()",
        "snippet": "def lt_tokenizer():\n    return get_lang_class(\"lt\").Defaults.create_tokenizer()",
        "begin_line": 139,
        "end_line": 140,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.lt_lemmatizer#144",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.lt_lemmatizer()",
        "snippet": "def lt_lemmatizer():\n    lang_cls = get_lang_class(\"lt\")\n    lookups = lang_cls.Defaults.create_lookups()\n    return lang_cls.Defaults.create_lemmatizer(lookups=lookups)",
        "begin_line": 144,
        "end_line": 147,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.nb_tokenizer#151",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.nb_tokenizer()",
        "snippet": "def nb_tokenizer():\n    return get_lang_class(\"nb\").Defaults.create_tokenizer()",
        "begin_line": 151,
        "end_line": 152,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.nl_tokenizer#156",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.nl_tokenizer()",
        "snippet": "def nl_tokenizer():\n    return get_lang_class(\"nl\").Defaults.create_tokenizer()",
        "begin_line": 156,
        "end_line": 157,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.nl_lemmatizer#161",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.nl_lemmatizer(scope='session')",
        "snippet": "def nl_lemmatizer(scope=\"session\"):\n    lang_cls = get_lang_class(\"nl\")\n    lookups = lang_cls.Defaults.create_lookups()\n    return lang_cls.Defaults.create_lemmatizer(lookups=lookups)",
        "begin_line": 161,
        "end_line": 164,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.pl_tokenizer#168",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.pl_tokenizer()",
        "snippet": "def pl_tokenizer():\n    return get_lang_class(\"pl\").Defaults.create_tokenizer()",
        "begin_line": 168,
        "end_line": 169,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.ro_tokenizer#178",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.ro_tokenizer()",
        "snippet": "def ro_tokenizer():\n    return get_lang_class(\"ro\").Defaults.create_tokenizer()",
        "begin_line": 178,
        "end_line": 179,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.sr_tokenizer#189",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.sr_tokenizer()",
        "snippet": "def sr_tokenizer():\n    return get_lang_class(\"sr\").Defaults.create_tokenizer()",
        "begin_line": 189,
        "end_line": 190,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.sv_tokenizer#194",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.sv_tokenizer()",
        "snippet": "def sv_tokenizer():\n    return get_lang_class(\"sv\").Defaults.create_tokenizer()",
        "begin_line": 194,
        "end_line": 195,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.tr_tokenizer#205",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.tr_tokenizer()",
        "snippet": "def tr_tokenizer():\n    return get_lang_class(\"tr\").Defaults.create_tokenizer()",
        "begin_line": 205,
        "end_line": 206,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.tt_tokenizer#210",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.tt_tokenizer()",
        "snippet": "def tt_tokenizer():\n    return get_lang_class(\"tt\").Defaults.create_tokenizer()",
        "begin_line": 210,
        "end_line": 211,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.conftest.ur_tokenizer#222",
        "src_path": "spacy/tests/conftest.py",
        "class_name": "spacy.tests.conftest",
        "signature": "spacy.tests.conftest.ur_tokenizer()",
        "snippet": "def ur_tokenizer():\n    return get_lang_class(\"ur\").Defaults.create_tokenizer()",
        "begin_line": 222,
        "end_line": 223,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_api.matcher#11",
        "src_path": "spacy/tests/matcher/test_matcher_api.py",
        "class_name": "spacy.tests.matcher.test_matcher_api",
        "signature": "spacy.tests.matcher.test_matcher_api.matcher(en_vocab)",
        "snippet": "def matcher(en_vocab):\n    rules = {\n        \"JS\": [[{\"ORTH\": \"JavaScript\"}]],\n        \"GoogleNow\": [[{\"ORTH\": \"Google\"}, {\"ORTH\": \"Now\"}]],\n        \"Java\": [[{\"LOWER\": \"java\"}]],\n    }\n    matcher = Matcher(en_vocab)\n    for key, patterns in rules.items():\n        matcher.add(key, None, *patterns)\n    return matcher",
        "begin_line": 11,
        "end_line": 20,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_api.test_matcher_from_api_docs#23",
        "src_path": "spacy/tests/matcher/test_matcher_api.py",
        "class_name": "spacy.tests.matcher.test_matcher_api",
        "signature": "spacy.tests.matcher.test_matcher_api.test_matcher_from_api_docs(en_vocab)",
        "snippet": "def test_matcher_from_api_docs(en_vocab):\n    matcher = Matcher(en_vocab)\n    pattern = [{\"ORTH\": \"test\"}]\n    assert len(matcher) == 0\n    matcher.add(\"Rule\", None, pattern)\n    assert len(matcher) == 1\n    matcher.remove(\"Rule\")\n    assert \"Rule\" not in matcher\n    matcher.add(\"Rule\", None, pattern)\n    assert \"Rule\" in matcher\n    on_match, patterns = matcher.get(\"Rule\")\n    assert len(patterns[0])",
        "begin_line": 23,
        "end_line": 34,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_api.test_matcher_from_usage_docs#37",
        "src_path": "spacy/tests/matcher/test_matcher_api.py",
        "class_name": "spacy.tests.matcher.test_matcher_api",
        "signature": "spacy.tests.matcher.test_matcher_api.test_matcher_from_usage_docs(en_vocab)",
        "snippet": "def test_matcher_from_usage_docs(en_vocab):\n    text = \"Wow \ud83d\ude00 This is really cool! \ud83d\ude02 \ud83d\ude02\"\n    doc = Doc(en_vocab, words=text.split(\" \"))\n    pos_emoji = [\"\ud83d\ude00\", \"\ud83d\ude03\", \"\ud83d\ude02\", \"\ud83e\udd23\", \"\ud83d\ude0a\", \"\ud83d\ude0d\"]\n    pos_patterns = [[{\"ORTH\": emoji}] for emoji in pos_emoji]\n\n    def label_sentiment(matcher, doc, i, matches):\n        match_id, start, end = matches[i]\n        if doc.vocab.strings[match_id] == \"HAPPY\":\n            doc.sentiment += 0.1\n        span = doc[start:end]\n        with doc.retokenize() as retokenizer:\n            retokenizer.merge(span)\n        token = doc[start]\n        token.vocab[token.text].norm_ = \"happy emoji\"\n\n    matcher = Matcher(en_vocab)\n    matcher.add(\"HAPPY\", label_sentiment, *pos_patterns)\n    matcher(doc)\n    assert doc.sentiment != 0\n    assert doc[1].norm_ == \"happy emoji\"",
        "begin_line": 37,
        "end_line": 57,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_api.label_sentiment#43",
        "src_path": "spacy/tests/matcher/test_matcher_api.py",
        "class_name": "spacy.tests.matcher.test_matcher_api",
        "signature": "spacy.tests.matcher.test_matcher_api.label_sentiment(matcher, doc, i, matches)",
        "snippet": "    def label_sentiment(matcher, doc, i, matches):\n        match_id, start, end = matches[i]\n        if doc.vocab.strings[match_id] == \"HAPPY\":\n            doc.sentiment += 0.1\n        span = doc[start:end]\n        with doc.retokenize() as retokenizer:\n            retokenizer.merge(span)\n        token = doc[start]\n        token.vocab[token.text].norm_ = \"happy emoji\"",
        "begin_line": 43,
        "end_line": 51,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_api.test_matcher_len_contains#60",
        "src_path": "spacy/tests/matcher/test_matcher_api.py",
        "class_name": "spacy.tests.matcher.test_matcher_api",
        "signature": "spacy.tests.matcher.test_matcher_api.test_matcher_len_contains(matcher)",
        "snippet": "def test_matcher_len_contains(matcher):\n    assert len(matcher) == 3\n    matcher.add(\"TEST\", None, [{\"ORTH\": \"test\"}])\n    assert \"TEST\" in matcher\n    assert \"TEST2\" not in matcher",
        "begin_line": 60,
        "end_line": 64,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_api.test_matcher_no_match#67",
        "src_path": "spacy/tests/matcher/test_matcher_api.py",
        "class_name": "spacy.tests.matcher.test_matcher_api",
        "signature": "spacy.tests.matcher.test_matcher_api.test_matcher_no_match(matcher)",
        "snippet": "def test_matcher_no_match(matcher):\n    doc = Doc(matcher.vocab, words=[\"I\", \"like\", \"cheese\", \".\"])\n    assert matcher(doc) == []",
        "begin_line": 67,
        "end_line": 69,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_api.test_matcher_match_start#72",
        "src_path": "spacy/tests/matcher/test_matcher_api.py",
        "class_name": "spacy.tests.matcher.test_matcher_api",
        "signature": "spacy.tests.matcher.test_matcher_api.test_matcher_match_start(matcher)",
        "snippet": "def test_matcher_match_start(matcher):\n    doc = Doc(matcher.vocab, words=[\"JavaScript\", \"is\", \"good\"])\n    assert matcher(doc) == [(matcher.vocab.strings[\"JS\"], 0, 1)]",
        "begin_line": 72,
        "end_line": 74,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_api.test_matcher_match_end#77",
        "src_path": "spacy/tests/matcher/test_matcher_api.py",
        "class_name": "spacy.tests.matcher.test_matcher_api",
        "signature": "spacy.tests.matcher.test_matcher_api.test_matcher_match_end(matcher)",
        "snippet": "def test_matcher_match_end(matcher):\n    words = [\"I\", \"like\", \"java\"]\n    doc = Doc(matcher.vocab, words=words)\n    assert matcher(doc) == [(doc.vocab.strings[\"Java\"], 2, 3)]",
        "begin_line": 77,
        "end_line": 80,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_api.test_matcher_match_middle#83",
        "src_path": "spacy/tests/matcher/test_matcher_api.py",
        "class_name": "spacy.tests.matcher.test_matcher_api",
        "signature": "spacy.tests.matcher.test_matcher_api.test_matcher_match_middle(matcher)",
        "snippet": "def test_matcher_match_middle(matcher):\n    words = [\"I\", \"like\", \"Google\", \"Now\", \"best\"]\n    doc = Doc(matcher.vocab, words=words)\n    assert matcher(doc) == [(doc.vocab.strings[\"GoogleNow\"], 2, 4)]",
        "begin_line": 83,
        "end_line": 86,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_api.test_matcher_match_multi#89",
        "src_path": "spacy/tests/matcher/test_matcher_api.py",
        "class_name": "spacy.tests.matcher.test_matcher_api",
        "signature": "spacy.tests.matcher.test_matcher_api.test_matcher_match_multi(matcher)",
        "snippet": "def test_matcher_match_multi(matcher):\n    words = [\"I\", \"like\", \"Google\", \"Now\", \"and\", \"java\", \"best\"]\n    doc = Doc(matcher.vocab, words=words)\n    assert matcher(doc) == [\n        (doc.vocab.strings[\"GoogleNow\"], 2, 4),\n        (doc.vocab.strings[\"Java\"], 5, 6),\n    ]",
        "begin_line": 89,
        "end_line": 95,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_api.test_matcher_empty_dict#98",
        "src_path": "spacy/tests/matcher/test_matcher_api.py",
        "class_name": "spacy.tests.matcher.test_matcher_api",
        "signature": "spacy.tests.matcher.test_matcher_api.test_matcher_empty_dict(en_vocab)",
        "snippet": "def test_matcher_empty_dict(en_vocab):\n    \"\"\"Test matcher allows empty token specs, meaning match on any token.\"\"\"\n    matcher = Matcher(en_vocab)\n    doc = Doc(matcher.vocab, words=[\"a\", \"b\", \"c\"])\n    matcher.add(\"A.C\", None, [{\"ORTH\": \"a\"}, {}, {\"ORTH\": \"c\"}])\n    matches = matcher(doc)\n    assert len(matches) == 1\n    assert matches[0][1:] == (0, 3)\n    matcher = Matcher(en_vocab)\n    matcher.add(\"A.\", None, [{\"ORTH\": \"a\"}, {}])\n    matches = matcher(doc)\n    assert matches[0][1:] == (0, 2)",
        "begin_line": 98,
        "end_line": 109,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_api.test_matcher_operator_shadow#112",
        "src_path": "spacy/tests/matcher/test_matcher_api.py",
        "class_name": "spacy.tests.matcher.test_matcher_api",
        "signature": "spacy.tests.matcher.test_matcher_api.test_matcher_operator_shadow(en_vocab)",
        "snippet": "def test_matcher_operator_shadow(en_vocab):\n    matcher = Matcher(en_vocab)\n    doc = Doc(matcher.vocab, words=[\"a\", \"b\", \"c\"])\n    pattern = [{\"ORTH\": \"a\"}, {\"IS_ALPHA\": True, \"OP\": \"+\"}, {\"ORTH\": \"c\"}]\n    matcher.add(\"A.C\", None, pattern)\n    matches = matcher(doc)\n    assert len(matches) == 1\n    assert matches[0][1:] == (0, 3)",
        "begin_line": 112,
        "end_line": 119,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_api.test_matcher_match_zero#122",
        "src_path": "spacy/tests/matcher/test_matcher_api.py",
        "class_name": "spacy.tests.matcher.test_matcher_api",
        "signature": "spacy.tests.matcher.test_matcher_api.test_matcher_match_zero(matcher)",
        "snippet": "def test_matcher_match_zero(matcher):\n    words1 = 'He said , \" some words \" ...'.split()\n    words2 = 'He said , \" some three words \" ...'.split()\n    pattern1 = [\n        {\"ORTH\": '\"'},\n        {\"OP\": \"!\", \"IS_PUNCT\": True},\n        {\"OP\": \"!\", \"IS_PUNCT\": True},\n        {\"ORTH\": '\"'},\n    ]\n    pattern2 = [\n        {\"ORTH\": '\"'},\n        {\"IS_PUNCT\": True},\n        {\"IS_PUNCT\": True},\n        {\"IS_PUNCT\": True},\n        {\"ORTH\": '\"'},\n    ]\n    matcher.add(\"Quote\", None, pattern1)\n    doc = Doc(matcher.vocab, words=words1)\n    assert len(matcher(doc)) == 1\n    doc = Doc(matcher.vocab, words=words2)\n    assert len(matcher(doc)) == 0\n    matcher.add(\"Quote\", None, pattern2)\n    assert len(matcher(doc)) == 0",
        "begin_line": 122,
        "end_line": 144,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_api.test_matcher_match_zero_plus#147",
        "src_path": "spacy/tests/matcher/test_matcher_api.py",
        "class_name": "spacy.tests.matcher.test_matcher_api",
        "signature": "spacy.tests.matcher.test_matcher_api.test_matcher_match_zero_plus(matcher)",
        "snippet": "def test_matcher_match_zero_plus(matcher):\n    words = 'He said , \" some words \" ...'.split()\n    pattern = [{\"ORTH\": '\"'}, {\"OP\": \"*\", \"IS_PUNCT\": False}, {\"ORTH\": '\"'}]\n    matcher = Matcher(matcher.vocab)\n    matcher.add(\"Quote\", None, pattern)\n    doc = Doc(matcher.vocab, words=words)\n    assert len(matcher(doc)) == 1",
        "begin_line": 147,
        "end_line": 153,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_api.test_matcher_match_one_plus#156",
        "src_path": "spacy/tests/matcher/test_matcher_api.py",
        "class_name": "spacy.tests.matcher.test_matcher_api",
        "signature": "spacy.tests.matcher.test_matcher_api.test_matcher_match_one_plus(matcher)",
        "snippet": "def test_matcher_match_one_plus(matcher):\n    control = Matcher(matcher.vocab)\n    control.add(\"BasicPhilippe\", None, [{\"ORTH\": \"Philippe\"}])\n    doc = Doc(control.vocab, words=[\"Philippe\", \"Philippe\"])\n    m = control(doc)\n    assert len(m) == 2\n    matcher.add(\n        \"KleenePhilippe\",\n        None,\n        [{\"ORTH\": \"Philippe\", \"OP\": \"1\"}, {\"ORTH\": \"Philippe\", \"OP\": \"+\"}],\n    )\n    m = matcher(doc)\n    assert len(m) == 1",
        "begin_line": 156,
        "end_line": 168,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_api.test_matcher_any_token_operator#171",
        "src_path": "spacy/tests/matcher/test_matcher_api.py",
        "class_name": "spacy.tests.matcher.test_matcher_api",
        "signature": "spacy.tests.matcher.test_matcher_api.test_matcher_any_token_operator(en_vocab)",
        "snippet": "def test_matcher_any_token_operator(en_vocab):\n    \"\"\"Test that patterns with \"any token\" {} work with operators.\"\"\"\n    matcher = Matcher(en_vocab)\n    matcher.add(\"TEST\", None, [{\"ORTH\": \"test\"}, {\"OP\": \"*\"}])\n    doc = Doc(en_vocab, words=[\"test\", \"hello\", \"world\"])\n    matches = [doc[start:end].text for _, start, end in matcher(doc)]\n    assert len(matches) == 3\n    assert matches[0] == \"test\"\n    assert matches[1] == \"test hello\"\n    assert matches[2] == \"test hello world\"",
        "begin_line": 171,
        "end_line": 180,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_api.test_matcher_extension_attribute#183",
        "src_path": "spacy/tests/matcher/test_matcher_api.py",
        "class_name": "spacy.tests.matcher.test_matcher_api",
        "signature": "spacy.tests.matcher.test_matcher_api.test_matcher_extension_attribute(en_vocab)",
        "snippet": "def test_matcher_extension_attribute(en_vocab):\n    matcher = Matcher(en_vocab)\n    get_is_fruit = lambda token: token.text in (\"apple\", \"banana\")\n    Token.set_extension(\"is_fruit\", getter=get_is_fruit, force=True)\n    pattern = [{\"ORTH\": \"an\"}, {\"_\": {\"is_fruit\": True}}]\n    matcher.add(\"HAVING_FRUIT\", None, pattern)\n    doc = Doc(en_vocab, words=[\"an\", \"apple\"])\n    matches = matcher(doc)\n    assert len(matches) == 1\n    doc = Doc(en_vocab, words=[\"an\", \"aardvark\"])\n    matches = matcher(doc)\n    assert len(matches) == 0",
        "begin_line": 183,
        "end_line": 194,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_api.test_matcher_set_value#197",
        "src_path": "spacy/tests/matcher/test_matcher_api.py",
        "class_name": "spacy.tests.matcher.test_matcher_api",
        "signature": "spacy.tests.matcher.test_matcher_api.test_matcher_set_value(en_vocab)",
        "snippet": "def test_matcher_set_value(en_vocab):\n    matcher = Matcher(en_vocab)\n    pattern = [{\"ORTH\": {\"IN\": [\"an\", \"a\"]}}]\n    matcher.add(\"A_OR_AN\", None, pattern)\n    doc = Doc(en_vocab, words=[\"an\", \"a\", \"apple\"])\n    matches = matcher(doc)\n    assert len(matches) == 2\n    doc = Doc(en_vocab, words=[\"aardvark\"])\n    matches = matcher(doc)\n    assert len(matches) == 0",
        "begin_line": 197,
        "end_line": 206,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_api.test_matcher_set_value_operator#209",
        "src_path": "spacy/tests/matcher/test_matcher_api.py",
        "class_name": "spacy.tests.matcher.test_matcher_api",
        "signature": "spacy.tests.matcher.test_matcher_api.test_matcher_set_value_operator(en_vocab)",
        "snippet": "def test_matcher_set_value_operator(en_vocab):\n    matcher = Matcher(en_vocab)\n    pattern = [{\"ORTH\": {\"IN\": [\"a\", \"the\"]}, \"OP\": \"?\"}, {\"ORTH\": \"house\"}]\n    matcher.add(\"DET_HOUSE\", None, pattern)\n    doc = Doc(en_vocab, words=[\"In\", \"a\", \"house\"])\n    matches = matcher(doc)\n    assert len(matches) == 2\n    doc = Doc(en_vocab, words=[\"my\", \"house\"])\n    matches = matcher(doc)\n    assert len(matches) == 1",
        "begin_line": 209,
        "end_line": 218,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_api.test_matcher_regex#221",
        "src_path": "spacy/tests/matcher/test_matcher_api.py",
        "class_name": "spacy.tests.matcher.test_matcher_api",
        "signature": "spacy.tests.matcher.test_matcher_api.test_matcher_regex(en_vocab)",
        "snippet": "def test_matcher_regex(en_vocab):\n    matcher = Matcher(en_vocab)\n    pattern = [{\"ORTH\": {\"REGEX\": r\"(?:a|an)\"}}]\n    matcher.add(\"A_OR_AN\", None, pattern)\n    doc = Doc(en_vocab, words=[\"an\", \"a\", \"hi\"])\n    matches = matcher(doc)\n    assert len(matches) == 2\n    doc = Doc(en_vocab, words=[\"bye\"])\n    matches = matcher(doc)\n    assert len(matches) == 0",
        "begin_line": 221,
        "end_line": 230,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_api.test_matcher_regex_shape#233",
        "src_path": "spacy/tests/matcher/test_matcher_api.py",
        "class_name": "spacy.tests.matcher.test_matcher_api",
        "signature": "spacy.tests.matcher.test_matcher_api.test_matcher_regex_shape(en_vocab)",
        "snippet": "def test_matcher_regex_shape(en_vocab):\n    matcher = Matcher(en_vocab)\n    pattern = [{\"SHAPE\": {\"REGEX\": r\"^[^x]+$\"}}]\n    matcher.add(\"NON_ALPHA\", None, pattern)\n    doc = Doc(en_vocab, words=[\"99\", \"problems\", \"!\"])\n    matches = matcher(doc)\n    assert len(matches) == 2\n    doc = Doc(en_vocab, words=[\"bye\"])\n    matches = matcher(doc)\n    assert len(matches) == 0",
        "begin_line": 233,
        "end_line": 242,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_api.test_matcher_compare_length#245",
        "src_path": "spacy/tests/matcher/test_matcher_api.py",
        "class_name": "spacy.tests.matcher.test_matcher_api",
        "signature": "spacy.tests.matcher.test_matcher_api.test_matcher_compare_length(en_vocab)",
        "snippet": "def test_matcher_compare_length(en_vocab):\n    matcher = Matcher(en_vocab)\n    pattern = [{\"LENGTH\": {\">=\": 2}}]\n    matcher.add(\"LENGTH_COMPARE\", None, pattern)\n    doc = Doc(en_vocab, words=[\"a\", \"aa\", \"aaa\"])\n    matches = matcher(doc)\n    assert len(matches) == 2\n    doc = Doc(en_vocab, words=[\"a\"])\n    matches = matcher(doc)\n    assert len(matches) == 0",
        "begin_line": 245,
        "end_line": 254,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_api.test_matcher_extension_set_membership#257",
        "src_path": "spacy/tests/matcher/test_matcher_api.py",
        "class_name": "spacy.tests.matcher.test_matcher_api",
        "signature": "spacy.tests.matcher.test_matcher_api.test_matcher_extension_set_membership(en_vocab)",
        "snippet": "def test_matcher_extension_set_membership(en_vocab):\n    matcher = Matcher(en_vocab)\n    get_reversed = lambda token: \"\".join(reversed(token.text))\n    Token.set_extension(\"reversed\", getter=get_reversed, force=True)\n    pattern = [{\"_\": {\"reversed\": {\"IN\": [\"eyb\", \"ih\"]}}}]\n    matcher.add(\"REVERSED\", None, pattern)\n    doc = Doc(en_vocab, words=[\"hi\", \"bye\", \"hello\"])\n    matches = matcher(doc)\n    assert len(matches) == 2\n    doc = Doc(en_vocab, words=[\"aardvark\"])\n    matches = matcher(doc)\n    assert len(matches) == 0",
        "begin_line": 257,
        "end_line": 268,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_api.text#272",
        "src_path": "spacy/tests/matcher/test_matcher_api.py",
        "class_name": "spacy.tests.matcher.test_matcher_api",
        "signature": "spacy.tests.matcher.test_matcher_api.text()",
        "snippet": "def text():\n    return \"The quick brown fox jumped over the lazy fox\"",
        "begin_line": 272,
        "end_line": 273,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_api.heads#277",
        "src_path": "spacy/tests/matcher/test_matcher_api.py",
        "class_name": "spacy.tests.matcher.test_matcher_api",
        "signature": "spacy.tests.matcher.test_matcher_api.heads()",
        "snippet": "def heads():\n    return [3, 2, 1, 1, 0, -1, 2, 1, -3]",
        "begin_line": 277,
        "end_line": 278,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_api.deps#282",
        "src_path": "spacy/tests/matcher/test_matcher_api.py",
        "class_name": "spacy.tests.matcher.test_matcher_api",
        "signature": "spacy.tests.matcher.test_matcher_api.deps()",
        "snippet": "def deps():\n    return [\"det\", \"amod\", \"amod\", \"nsubj\", \"prep\", \"pobj\", \"det\", \"amod\"]",
        "begin_line": 282,
        "end_line": 283,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_api.dependency_matcher#287",
        "src_path": "spacy/tests/matcher/test_matcher_api.py",
        "class_name": "spacy.tests.matcher.test_matcher_api",
        "signature": "spacy.tests.matcher.test_matcher_api.dependency_matcher(en_vocab)",
        "snippet": "def dependency_matcher(en_vocab):\n    def is_brown_yellow(text):\n        return bool(re.compile(r\"brown|yellow|over\").match(text))\n\n    IS_BROWN_YELLOW = en_vocab.add_flag(is_brown_yellow)\n\n    pattern1 = [\n        {\"SPEC\": {\"NODE_NAME\": \"fox\"}, \"PATTERN\": {\"ORTH\": \"fox\"}},\n        {\n            \"SPEC\": {\"NODE_NAME\": \"q\", \"NBOR_RELOP\": \">\", \"NBOR_NAME\": \"fox\"},\n            \"PATTERN\": {\"ORTH\": \"quick\", \"DEP\": \"amod\"},\n        },\n        {\n            \"SPEC\": {\"NODE_NAME\": \"r\", \"NBOR_RELOP\": \">\", \"NBOR_NAME\": \"fox\"},\n            \"PATTERN\": {IS_BROWN_YELLOW: True},\n        },\n    ]\n\n    pattern2 = [\n        {\"SPEC\": {\"NODE_NAME\": \"jumped\"}, \"PATTERN\": {\"ORTH\": \"jumped\"}},\n        {\n            \"SPEC\": {\"NODE_NAME\": \"fox\", \"NBOR_RELOP\": \">\", \"NBOR_NAME\": \"jumped\"},\n            \"PATTERN\": {\"ORTH\": \"fox\"},\n        },\n        {\n            \"SPEC\": {\"NODE_NAME\": \"quick\", \"NBOR_RELOP\": \".\", \"NBOR_NAME\": \"jumped\"},\n            \"PATTERN\": {\"ORTH\": \"fox\"},\n        },\n    ]\n\n    pattern3 = [\n        {\"SPEC\": {\"NODE_NAME\": \"jumped\"}, \"PATTERN\": {\"ORTH\": \"jumped\"}},\n        {\n            \"SPEC\": {\"NODE_NAME\": \"fox\", \"NBOR_RELOP\": \">\", \"NBOR_NAME\": \"jumped\"},\n            \"PATTERN\": {\"ORTH\": \"fox\"},\n        },\n        {\n            \"SPEC\": {\"NODE_NAME\": \"r\", \"NBOR_RELOP\": \">>\", \"NBOR_NAME\": \"fox\"},\n            \"PATTERN\": {\"ORTH\": \"brown\"},\n        },\n    ]\n\n    matcher = DependencyMatcher(en_vocab)\n    matcher.add(\"pattern1\", None, pattern1)\n    matcher.add(\"pattern2\", None, pattern2)\n    matcher.add(\"pattern3\", None, pattern3)\n\n    return matcher",
        "begin_line": 287,
        "end_line": 334,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_api.is_brown_yellow#288",
        "src_path": "spacy/tests/matcher/test_matcher_api.py",
        "class_name": "spacy.tests.matcher.test_matcher_api",
        "signature": "spacy.tests.matcher.test_matcher_api.is_brown_yellow(text)",
        "snippet": "    def is_brown_yellow(text):\n        return bool(re.compile(r\"brown|yellow|over\").match(text))",
        "begin_line": 288,
        "end_line": 289,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_api.test_dependency_matcher_compile#337",
        "src_path": "spacy/tests/matcher/test_matcher_api.py",
        "class_name": "spacy.tests.matcher.test_matcher_api",
        "signature": "spacy.tests.matcher.test_matcher_api.test_dependency_matcher_compile(dependency_matcher)",
        "snippet": "def test_dependency_matcher_compile(dependency_matcher):\n    assert len(dependency_matcher) == 3",
        "begin_line": 337,
        "end_line": 338,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_api.test_attr_pipeline_checks#349",
        "src_path": "spacy/tests/matcher/test_matcher_api.py",
        "class_name": "spacy.tests.matcher.test_matcher_api",
        "signature": "spacy.tests.matcher.test_matcher_api.test_attr_pipeline_checks(en_vocab)",
        "snippet": "def test_attr_pipeline_checks(en_vocab):\n    doc1 = Doc(en_vocab, words=[\"Test\"])\n    doc1.is_parsed = True\n    doc2 = Doc(en_vocab, words=[\"Test\"])\n    doc2.is_tagged = True\n    doc3 = Doc(en_vocab, words=[\"Test\"])\n    # DEP requires is_parsed\n    matcher = Matcher(en_vocab)\n    matcher.add(\"TEST\", None, [{\"DEP\": \"a\"}])\n    matcher(doc1)\n    with pytest.raises(ValueError):\n        matcher(doc2)\n    with pytest.raises(ValueError):\n        matcher(doc3)\n    # TAG, POS, LEMMA require is_tagged\n    for attr in (\"TAG\", \"POS\", \"LEMMA\"):\n        matcher = Matcher(en_vocab)\n        matcher.add(\"TEST\", None, [{attr: \"a\"}])\n        matcher(doc2)\n        with pytest.raises(ValueError):\n            matcher(doc1)\n        with pytest.raises(ValueError):\n            matcher(doc3)\n    # TEXT/ORTH only require tokens\n    matcher = Matcher(en_vocab)\n    matcher.add(\"TEST\", None, [{\"ORTH\": \"a\"}])\n    matcher(doc1)\n    matcher(doc2)\n    matcher(doc3)\n    matcher = Matcher(en_vocab)\n    matcher.add(\"TEST\", None, [{\"TEXT\": \"a\"}])\n    matcher(doc1)\n    matcher(doc2)\n    matcher(doc3)",
        "begin_line": 349,
        "end_line": 382,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_api.test_matcher_schema_token_attributes#406",
        "src_path": "spacy/tests/matcher/test_matcher_api.py",
        "class_name": "spacy.tests.matcher.test_matcher_api",
        "signature": "spacy.tests.matcher.test_matcher_api.test_matcher_schema_token_attributes(en_vocab, pattern, text)",
        "snippet": "def test_matcher_schema_token_attributes(en_vocab, pattern, text):\n    matcher = Matcher(en_vocab)\n    doc = Doc(en_vocab, words=text.split(\" \"))\n    matcher.add(\"Rule\", None, pattern)\n    assert len(matcher) == 1\n    matches = matcher(doc)\n    assert len(matches) == 1",
        "begin_line": 406,
        "end_line": 412,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.matcher.test_matcher_api.test_matcher_valid_callback#415",
        "src_path": "spacy/tests/matcher/test_matcher_api.py",
        "class_name": "spacy.tests.matcher.test_matcher_api",
        "signature": "spacy.tests.matcher.test_matcher_api.test_matcher_valid_callback(en_vocab)",
        "snippet": "def test_matcher_valid_callback(en_vocab):\n    \"\"\"Test that on_match can only be None or callable.\"\"\"\n    matcher = Matcher(en_vocab)\n    with pytest.raises(ValueError):\n        matcher.add(\"TEST\", [], [{\"TEXT\": \"test\"}])\n    matcher(Doc(en_vocab, words=[\"test\"]))",
        "begin_line": 415,
        "end_line": 420,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.util.make_tempdir#23",
        "src_path": "spacy/tests/util.py",
        "class_name": "spacy.tests.util",
        "signature": "spacy.tests.util.make_tempdir()",
        "snippet": "def make_tempdir():\n    d = Path(tempfile.mkdtemp())\n    yield d\n    shutil.rmtree(path2str(d))",
        "begin_line": 23,
        "end_line": 26,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.util.get_doc#29",
        "src_path": "spacy/tests/util.py",
        "class_name": "spacy.tests.util",
        "signature": "spacy.tests.util.get_doc(vocab, words=[], pos=None, heads=None, deps=None, tags=None, ents=None)",
        "snippet": "def get_doc(vocab, words=[], pos=None, heads=None, deps=None, tags=None, ents=None):\n    \"\"\"Create Doc object from given vocab, words and annotations.\"\"\"\n    pos = pos or [\"\"] * len(words)\n    tags = tags or [\"\"] * len(words)\n    heads = heads or [0] * len(words)\n    deps = deps or [\"\"] * len(words)\n    for value in deps + tags + pos:\n        vocab.strings.add(value)\n\n    doc = Doc(vocab, words=words)\n    attrs = doc.to_array([POS, HEAD, DEP])\n    for i, (p, head, dep) in enumerate(zip(pos, heads, deps)):\n        attrs[i, 0] = doc.vocab.strings[p]\n        attrs[i, 1] = head\n        attrs[i, 2] = doc.vocab.strings[dep]\n    doc.from_array([POS, HEAD, DEP], attrs)\n    if ents:\n        doc.ents = [\n            Span(doc, start, end, label=doc.vocab.strings[label])\n            for start, end, label in ents\n        ]\n    if tags:\n        for token in doc:\n            token.tag_ = tags[token.i]\n    return doc",
        "begin_line": 29,
        "end_line": 53,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.util.add_vecs_to_vocab#68",
        "src_path": "spacy/tests/util.py",
        "class_name": "spacy.tests.util",
        "signature": "spacy.tests.util.add_vecs_to_vocab(vocab, vectors)",
        "snippet": "def add_vecs_to_vocab(vocab, vectors):\n    \"\"\"Add list of vector tuples to given vocab. All vectors need to have the\n    same length. Format: [(\"text\", [1, 2, 3])]\"\"\"\n    length = len(vectors[0][1])\n    vocab.reset_vectors(width=length)\n    for word, vec in vectors:\n        vocab.set_vector(word, vector=vec)\n    return vocab",
        "begin_line": 68,
        "end_line": 75,
        "comment": "",
        "is_bug": false
    },
    {
        "name": "spacy.tests.util.get_cosine#78",
        "src_path": "spacy/tests/util.py",
        "class_name": "spacy.tests.util",
        "signature": "spacy.tests.util.get_cosine(vec1, vec2)",
        "snippet": "def get_cosine(vec1, vec2):\n    \"\"\"Get cosine for two given vectors\"\"\"\n    return numpy.dot(vec1, vec2) / (numpy.linalg.norm(vec1) * numpy.linalg.norm(vec2))",
        "begin_line": 78,
        "end_line": 80,
        "comment": "",
        "is_bug": false
    }
]