coverage run -m pytest tests/keras/engine/test_training.py::test_model_with_external_loss
============================= test session starts ==============================
platform linux -- Python 3.7.3, pytest-5.4.3, py-1.8.1, pluggy-0.13.1 -- /opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/bin/python
cachedir: .pytest_cache
rootdir: /home/user/BugsInPy/temp/projects/keras, inifile: pytest.ini
plugins: forked-1.1.3, xdist-1.32.0
gw0 I / gw1 I

[gw0] linux Python 3.7.3 cwd: /home/user/BugsInPy/temp/projects/keras

[gw1] linux Python 3.7.3 cwd: /home/user/BugsInPy/temp/projects/keras

[gw0] Python 3.7.3 (default, Mar 27 2019, 22:11:17)  -- [GCC 7.3.0]

[gw1] Python 3.7.3 (default, Mar 27 2019, 22:11:17)  -- [GCC 7.3.0]
gw0 [1] / gw1 [1]

scheduling tests via LoadScheduling

tests/keras/engine/test_training.py::test_model_with_external_loss 
[gw0] [100%] FAILED tests/keras/engine/test_training.py::test_model_with_external_loss 

=================================== FAILURES ===================================
________________________ test_model_with_external_loss _________________________
[gw0] linux -- Python 3.7.3 /opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/bin/python

    @keras_test
    @pytest.mark.skipif((K.backend() == 'cntk'),
                        reason='cntk does not support external loss yet')
    def test_model_with_external_loss():
        # None loss, only regularization loss.
        a = Input(shape=(3,), name='input_a')
        a_2 = Dense(4, name='dense_1',
                    kernel_regularizer='l1',
                    bias_regularizer='l2')(a)
        dp = Dropout(0.5, name='dropout')
        a_3 = dp(a_2)
    
        model = Model(a, [a_2, a_3])
    
        optimizer = 'rmsprop'
        loss = None
        model.compile(optimizer, loss, metrics=['mae'])
    
        input_a_np = np.random.random((10, 3))
    
        # test train_on_batch
        out = model.train_on_batch(input_a_np, None)
        out = model.test_on_batch(input_a_np, None)
        # fit
        out = model.fit(input_a_np, None)
        # evaluate
        out = model.evaluate(input_a_np, None)
    
        # No dropout, external loss.
        a = Input(shape=(3,), name='input_a')
        a_2 = Dense(4, name='dense_1')(a)
        a_3 = Dense(4, name='dense_2')(a)
    
        model = Model(a, [a_2, a_3])
        model.add_loss(K.mean(a_3 + a_2))
    
        optimizer = 'rmsprop'
        loss = None
        model.compile(optimizer, loss, metrics=['mae'])
    
        # test train_on_batch
        out = model.train_on_batch(input_a_np, None)
        out = model.test_on_batch(input_a_np, None)
        # fit
        out = model.fit(input_a_np, None)
        # evaluate
        out = model.evaluate(input_a_np, None)
    
        # Test fit with no external data at all.
        if K.backend() == 'tensorflow':
            import tensorflow as tf
    
            a = Input(tensor=tf.Variable(input_a_np, dtype=tf.float32))
            a_2 = Dense(4, name='dense_1')(a)
            a_2 = Dropout(0.5, name='dropout')(a_2)
            model = Model(a, a_2)
            model.add_loss(K.mean(a_2))
    
            model.compile(optimizer='rmsprop',
                          loss=None,
                          metrics=['mean_squared_error'])
    
            # test train_on_batch
            out = model.train_on_batch(None, None)
            out = model.test_on_batch(None, None)
            out = model.predict_on_batch(None)
    
            # test fit
            with pytest.raises(ValueError):
                out = model.fit(None, None, epochs=1, batch_size=10)
            out = model.fit(None, None, epochs=1, steps_per_epoch=1)
    
            # define a generator to produce x=None and y=None
            def data_tensors_generator():
                while True:
                    yield (None, None)
    
            generator = data_tensors_generator()
    
            # test fit_generator for framework-native data tensors
            out = model.fit_generator(generator, epochs=1,
>                                     steps_per_epoch=3)

tests/keras/engine/test_training.py:879: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
keras/legacy/interfaces.py:91: in wrapper
    return func(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <keras.engine.training.Model object at 0x7faed45d8cc0>
generator = <generator object test_model_with_external_loss.<locals>.data_tensors_generator at 0x7faed6148a98>
steps_per_epoch = 3, epochs = 1, verbose = 1
callbacks = <keras.callbacks.CallbackList object at 0x7faed45d8a20>
validation_data = None, validation_steps = None, class_weight = None
max_queue_size = 10, workers = 1, use_multiprocessing = False, shuffle = True
initial_epoch = 0

    @interfaces.legacy_generator_methods_support
    def fit_generator(self,
                      generator,
                      steps_per_epoch=None,
                      epochs=1,
                      verbose=1,
                      callbacks=None,
                      validation_data=None,
                      validation_steps=None,
                      class_weight=None,
                      max_queue_size=10,
                      workers=1,
                      use_multiprocessing=False,
                      shuffle=True,
                      initial_epoch=0):
        """Trains the model on data generated batch-by-batch by a Python generator or an instance of `Sequence`.
    
        The generator is run in parallel to the model, for efficiency.
        For instance, this allows you to do real-time data augmentation
        on images on CPU in parallel to training your model on GPU.
    
        The use of `keras.utils.Sequence` guarantees the ordering
        and guarantees the single use of every input per epoch when
        using `use_multiprocessing=True`.
    
        # Arguments
            generator: A generator or an instance of `Sequence`
                (`keras.utils.Sequence`) object in order to avoid
                duplicate data when using multiprocessing.
                The output of the generator must be either
                - a tuple `(inputs, targets)`
                - a tuple `(inputs, targets, sample_weights)`.
                This tuple (a single output of the generator) makes a single
                batch. Therefore, all arrays in this tuple must have the same
                length (equal to the size of this batch). Different batches may
                have different sizes. For example, the last batch of the epoch
                is commonly smaller than the others, if the size of the dataset
                is not divisible by the batch size.
                The generator is expected to loop over its data
                indefinitely. An epoch finishes when `steps_per_epoch`
                batches have been seen by the model.
            steps_per_epoch: Integer.
                Total number of steps (batches of samples)
                to yield from `generator` before declaring one epoch
                finished and starting the next epoch. It should typically
                be equal to the number of samples of your dataset
                divided by the batch size.
                Optional for `Sequence`: if unspecified, will use
                the `len(generator)` as a number of steps.
            epochs: Integer. Number of epochs to train the model.
                An epoch is an iteration over the entire data provided,
                as defined by `steps_per_epoch`.
                Note that in conjunction with `initial_epoch`,
                `epochs` is to be understood as "final epoch".
                The model is not trained for a number of iterations
                given by `epochs`, but merely until the epoch
                of index `epochs` is reached.
            verbose: Integer. 0, 1, or 2. Verbosity mode.
                0 = silent, 1 = progress bar, 2 = one line per epoch.
            callbacks: List of `keras.callbacks.Callback` instances.
                List of callbacks to apply during training.
                See [callbacks](/callbacks).
            validation_data: This can be either
                - a generator for the validation data
                - tuple `(x_val, y_val)`
                - tuple `(x_val, y_val, val_sample_weights)`
                on which to evaluate
                the loss and any model metrics at the end of each epoch.
                The model will not be trained on this data.
            validation_steps: Only relevant if `validation_data`
                is a generator. Total number of steps (batches of samples)
                to yield from `validation_data` generator before stopping
                at the end of every epoch. It should typically
                be equal to the number of samples of your
                validation dataset divided by the batch size.
                Optional for `Sequence`: if unspecified, will use
                the `len(validation_data)` as a number of steps.
            class_weight: Optional dictionary mapping class indices (integers)
                to a weight (float) value, used for weighting the loss function
                (during training only). This can be useful to tell the model to
                "pay more attention" to samples from an under-represented class.
            max_queue_size: Integer. Maximum size for the generator queue.
                If unspecified, `max_queue_size` will default to 10.
            workers: Integer. Maximum number of processes to spin up
                when using process-based threading.
                If unspecified, `workers` will default to 1. If 0, will
                execute the generator on the main thread.
            use_multiprocessing: Boolean.
                If `True`, use process-based threading.
                If unspecified, `use_multiprocessing` will default to `False`.
                Note that because this implementation relies on multiprocessing,
                you should not pass non-picklable arguments to the generator
                as they can't be passed easily to children processes.
            shuffle: Boolean. Whether to shuffle the order of the batches at
                the beginning of each epoch. Only used with instances
                of `Sequence` (`keras.utils.Sequence`).
                Has no effect when `steps_per_epoch` is not `None`.
            initial_epoch: Integer.
                Epoch at which to start training
                (useful for resuming a previous training run).
    
        # Returns
            A `History` object. Its `History.history` attribute is
            a record of training loss values and metrics values
            at successive epochs, as well as validation loss values
            and validation metrics values (if applicable).
    
        # Raises
            ValueError: In case the generator yields data in an invalid format.
    
        # Example
    
        ```python
            def generate_arrays_from_file(path):
                while True:
                    with open(path) as f:
                        for line in f:
                            # create numpy arrays of input data
                            # and labels, from each line in the file
                            x1, x2, y = process_line(line)
                            yield ({'input_1': x1, 'input_2': x2}, {'output': y})
    
            model.fit_generator(generate_arrays_from_file('/my_file.txt'),
                                steps_per_epoch=10000, epochs=10)
        ```
        """
        wait_time = 0.01  # in seconds
        epoch = initial_epoch
    
        do_validation = bool(validation_data)
        self._make_train_function()
        if do_validation:
            self._make_test_function()
    
        is_sequence = isinstance(generator, Sequence)
        if not is_sequence and use_multiprocessing and workers > 1:
            warnings.warn(
                UserWarning('Using a generator with `use_multiprocessing=True`'
                            ' and multiple workers may duplicate your data.'
                            ' Please consider using the`keras.utils.Sequence'
                            ' class.'))
        if steps_per_epoch is None:
            if is_sequence:
                steps_per_epoch = len(generator)
            else:
                raise ValueError('`steps_per_epoch=None` is only valid for a'
                                 ' generator based on the `keras.utils.Sequence`'
                                 ' class. Please specify `steps_per_epoch` or use'
                                 ' the `keras.utils.Sequence` class.')
    
        # python 2 has 'next', 3 has '__next__'
        # avoid any explicit version checks
        val_gen = (hasattr(validation_data, 'next') or
                   hasattr(validation_data, '__next__') or
                   isinstance(validation_data, Sequence))
        if (val_gen and not isinstance(validation_data, Sequence) and
                not validation_steps):
            raise ValueError('`validation_steps=None` is only valid for a'
                             ' generator based on the `keras.utils.Sequence`'
                             ' class. Please specify `validation_steps` or use'
                             ' the `keras.utils.Sequence` class.')
    
        # Prepare display labels.
        out_labels = self.metrics_names
        callback_metrics = out_labels + ['val_' + n for n in out_labels]
    
        # prepare callbacks
        self.history = cbks.History()
        _callbacks = [cbks.BaseLogger(
            stateful_metrics=self.stateful_metric_names)]
        if verbose:
            _callbacks.append(
                cbks.ProgbarLogger(
                    count_mode='steps',
                    stateful_metrics=self.stateful_metric_names))
        _callbacks += (callbacks or []) + [self.history]
        callbacks = cbks.CallbackList(_callbacks)
    
        # it's possible to callback a different model than self:
        if hasattr(self, 'callback_model') and self.callback_model:
            callback_model = self.callback_model
        else:
            callback_model = self
        callbacks.set_model(callback_model)
        callbacks.set_params({
            'epochs': epochs,
            'steps': steps_per_epoch,
            'verbose': verbose,
            'do_validation': do_validation,
            'metrics': callback_metrics,
        })
        callbacks.on_train_begin()
    
        enqueuer = None
        val_enqueuer = None
    
        try:
            if do_validation and not val_gen:
                # Prepare data for validation
                if len(validation_data) == 2:
                    val_x, val_y = validation_data
                    val_sample_weight = None
                elif len(validation_data) == 3:
                    val_x, val_y, val_sample_weight = validation_data
                else:
                    raise ValueError('`validation_data` should be a tuple '
                                     '`(val_x, val_y, val_sample_weight)` '
                                     'or `(val_x, val_y)`. Found: ' +
                                     str(validation_data))
                val_x, val_y, val_sample_weights = self._standardize_user_data(
                    val_x, val_y, val_sample_weight)
                val_data = val_x + val_y + val_sample_weights
                if self.uses_learning_phase and not isinstance(K.learning_phase(), int):
                    val_data += [0.]
                for cbk in callbacks:
                    cbk.validation_data = val_data
    
            if workers > 0:
                if is_sequence:
                    enqueuer = OrderedEnqueuer(generator,
                                               use_multiprocessing=use_multiprocessing,
                                               shuffle=shuffle)
                else:
                    enqueuer = GeneratorEnqueuer(generator,
                                                 use_multiprocessing=use_multiprocessing,
                                                 wait_time=wait_time)
                enqueuer.start(workers=workers, max_queue_size=max_queue_size)
                output_generator = enqueuer.get()
            else:
                if is_sequence:
                    output_generator = iter(generator)
                else:
                    output_generator = generator
    
            callback_model.stop_training = False
            # Construct epoch logs.
            epoch_logs = {}
            while epoch < epochs:
                for m in self.metrics:
                    if isinstance(m, Layer) and m.stateful:
                        m.reset_states()
                callbacks.on_epoch_begin(epoch)
                steps_done = 0
                batch_index = 0
                while steps_done < steps_per_epoch:
                    generator_output = next(output_generator)
    
                    if not hasattr(generator_output, '__len__'):
                        raise ValueError('Output of generator should be '
                                         'a tuple `(x, y, sample_weight)` '
                                         'or `(x, y)`. Found: ' +
                                         str(generator_output))
    
                    if len(generator_output) == 2:
                        x, y = generator_output
                        sample_weight = None
                    elif len(generator_output) == 3:
                        x, y, sample_weight = generator_output
                    else:
                        raise ValueError('Output of generator should be '
                                         'a tuple `(x, y, sample_weight)` '
                                         'or `(x, y)`. Found: ' +
                                         str(generator_output))
                    # build batch logs
                    batch_logs = {}
                    if isinstance(x, list):
                        batch_size = x[0].shape[0]
                    elif isinstance(x, dict):
                        batch_size = list(x.values())[0].shape[0]
                    else:
>                       batch_size = x.shape[0]
E                       AttributeError: 'NoneType' object has no attribute 'shape'

keras/engine/training.py:2220: AttributeError
----------------------------- Captured stdout call -----------------------------
Epoch 1/1

10/10 [==============================] - 0s 76us/step - loss: 0.0654

10/10 [==============================] - 0s 36us/step
Epoch 1/1

10/10 [==============================] - 0s 76us/step - loss: -0.2788

10/10 [==============================] - 0s 33us/step
Epoch 1/1

1/1 [==============================] - 0s 850us/step - loss: 0.2023
Epoch 1/1
----------------------------- Captured stderr call -----------------------------
WARNING:tensorflow:From /opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/user/BugsInPy/temp/projects/keras/keras/backend/tensorflow_backend.py:3141: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2023-09-01 19:06:07.151184: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2023-09-01 19:06:07.172994: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3399905000 Hz
2023-09-01 19:06:07.173708: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x558b60352710 executing computations on platform Host. Devices:
2023-09-01 19:06:07.173726: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
------------------------------ Captured log call -------------------------------
WARNING  tensorflow:deprecation.py:323 From /opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING  tensorflow:deprecation.py:506 From /home/user/BugsInPy/temp/projects/keras/keras/backend/tensorflow_backend.py:3141: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
=============================== warnings summary ===============================
/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:10
/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:10
  /opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:10: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    _nlv = LooseVersion(_np_version)

/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:11
/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:11
  /opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:11: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    _np_version_under1p14 = _nlv < LooseVersion("1.14")

/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:12
/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:12
  /opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:12: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    _np_version_under1p15 = _nlv < LooseVersion("1.15")

/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:13
/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:13
  /opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:13: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    _np_version_under1p16 = _nlv < LooseVersion("1.16")

/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:14
/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:14
  /opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:14: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    _np_version_under1p17 = _nlv < LooseVersion("1.17")

/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:15
/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:15
  /opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:15: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    _np_version_under1p18 = _nlv < LooseVersion("1.18")

/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/setuptools/_distutils/version.py:346
/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/setuptools/_distutils/version.py:346
  /opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/setuptools/_distutils/version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    other = LooseVersion(other)

/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/pandas/compat/numpy/function.py:114
/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/pandas/compat/numpy/function.py:114
/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/pandas/compat/numpy/function.py:114
/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/pandas/compat/numpy/function.py:114
  /opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/pandas/compat/numpy/function.py:114: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    if LooseVersion(_np_version) >= LooseVersion("1.17.0"):

/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py:15
/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py:15
  /opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py:15: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
    import imp

/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526
/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526
  /opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
    _np_qint8 = np.dtype([("qint8", np.int8, 1)])

/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527
/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527
  /opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
    _np_quint8 = np.dtype([("quint8", np.uint8, 1)])

/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528
/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528
  /opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
    _np_qint16 = np.dtype([("qint16", np.int16, 1)])

/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529
/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529
  /opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
    _np_quint16 = np.dtype([("quint16", np.uint16, 1)])

/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530
/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530
  /opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
    _np_qint32 = np.dtype([("qint32", np.int32, 1)])

/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535
/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535
  /opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
    np_resource = np.dtype([("resource", np.ubyte, 1)])

/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/util/nest.py:823
/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/util/nest.py:823
  /opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/util/nest.py:823: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working
    _pywrap_tensorflow.RegisterType("Mapping", _collections.Mapping)

/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/util/nest.py:824
/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/util/nest.py:824
  /opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/util/nest.py:824: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working
    _pywrap_tensorflow.RegisterType("Sequence", _collections.Sequence)

/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/training/checkpointable/data_structures.py:312
/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/training/checkpointable/data_structures.py:312
  /opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/training/checkpointable/data_structures.py:312: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working
    class _ListWrapper(List, collections.MutableSequence,

/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/training/checkpointable/data_structures.py:546
/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/training/checkpointable/data_structures.py:546
  /opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/training/checkpointable/data_structures.py:546: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working
    class _DictWrapper(Mapping, collections.MutableMapping):

/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/training/checkpointable/util.py:448
/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/training/checkpointable/util.py:448
  /opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/training/checkpointable/util.py:448: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working
    class _ObjectIdentitySet(collections.MutableSet):

keras/callbacks.py:18
keras/callbacks.py:18
  /home/user/BugsInPy/temp/projects/keras/keras/callbacks.py:18: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working
    from collections import Iterable

/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py:573
  /opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py:573: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead
    append_fn(tensor_proto, proto_values)

tests/keras/engine/test_training.py:814
  /home/user/BugsInPy/temp/projects/keras/tests/keras/engine/test_training.py:814: UserWarning: Output "dense_1" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to "dense_1" during training.
    model.compile(optimizer, loss, metrics=['mae'])

tests/keras/engine/test_training.py:814
  /home/user/BugsInPy/temp/projects/keras/tests/keras/engine/test_training.py:814: UserWarning: Output "dropout" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to "dropout" during training.
    model.compile(optimizer, loss, metrics=['mae'])

tests/keras/engine/test_training.py:836
  /home/user/BugsInPy/temp/projects/keras/tests/keras/engine/test_training.py:836: UserWarning: Output "dense_1" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to "dense_1" during training.
    model.compile(optimizer, loss, metrics=['mae'])

tests/keras/engine/test_training.py:836
  /home/user/BugsInPy/temp/projects/keras/tests/keras/engine/test_training.py:836: UserWarning: Output "dense_2" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to "dense_2" during training.
    model.compile(optimizer, loss, metrics=['mae'])

tests/keras/engine/test_training.py:858
  /home/user/BugsInPy/temp/projects/keras/tests/keras/engine/test_training.py:858: UserWarning: Output "dropout" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to "dropout" during training.
    metrics=['mean_squared_error'])

-- Docs: https://docs.pytest.org/en/latest/warnings.html
========================== slowest 10 test durations ===========================
0.49s call     tests/keras/engine/test_training.py::test_model_with_external_loss

(0.00 durations hidden.  Use -vv to show these durations.)
=========================== short test summary info ============================
FAILED tests/keras/engine/test_training.py::test_model_with_external_loss - A...
======================== 1 failed, 50 warnings in 2.56s ========================
/opt/conda/envs/91f454ccae25459b57a9f2959f457e5b/lib/python3.7/site-packages/coverage/control.py:793: CoverageWarning: No data was collected. (no-data-collected)
  self._warn("No data was collected.", slug="no-data-collected")
