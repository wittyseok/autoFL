[
    {
        "name": "keras.backend.load_backend.backend#112",
        "src_path": "keras/backend/load_backend.py",
        "class_name": "keras.backend.load_backend",
        "signature": "keras.backend.load_backend.backend()",
        "snippet": "def backend():\n    \"\"\"Returns the name of the current backend (e.g. \"tensorflow\").\n\n    # Returns\n        String, the name of the backend Keras is currently using.\n\n    # Example\n    ```python\n        >>> keras.backend.backend()\n        'tensorflow'\n    ```\n    \"\"\"\n    return _BACKEND",
        "begin_line": 112,
        "end_line": 124,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.000243605359317905,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.utils.io_utils.H5Dict.__init__#185",
        "src_path": "keras/utils/io_utils.py",
        "class_name": "keras.utils.io_utils.H5Dict",
        "signature": "keras.utils.io_utils.H5Dict.__init__(self, path, mode='a')",
        "snippet": "    def __init__(self, path, mode='a'):\n        def is_path_instance(path):\n            # We can't use isinstance here because it would require\n            # us to add pathlib2 to the Python 2 dependencies.\n            class_name = type(path).__name__\n            return class_name == 'PosixPath' or class_name == 'WindowsPath'\n\n        if isinstance(path, h5py.Group):\n            self.data = path\n            self._is_file = False\n        elif isinstance(path, six.string_types) or is_path_instance(path):\n            self.data = h5py.File(path, mode=mode)\n            self._is_file = True\n        elif isinstance(path, dict):\n            self.data = path\n            self._is_file = False\n            if mode == 'w':\n                self.data.clear()\n            # Flag to check if a dict is user defined data or a sub group:\n            self.data['_is_group'] = True\n        else:\n            raise TypeError('Required Group, str, Path or dict. '\n                            'Received: {}.'.format(type(path)))\n        self.read_only = mode == 'r'",
        "begin_line": 185,
        "end_line": 208,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005574136008918618,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.utils.io_utils.H5Dict.is_path_instance#186",
        "src_path": "keras/utils/io_utils.py",
        "class_name": "keras.utils.io_utils.H5Dict",
        "signature": "keras.utils.io_utils.H5Dict.is_path_instance(path)",
        "snippet": "        def is_path_instance(path):\n            # We can't use isinstance here because it would require\n            # us to add pathlib2 to the Python 2 dependencies.\n            class_name = type(path).__name__\n            return class_name == 'PosixPath' or class_name == 'WindowsPath'",
        "begin_line": 186,
        "end_line": 190,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005574136008918618,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.utils.io_utils.H5Dict.__setitem__#210",
        "src_path": "keras/utils/io_utils.py",
        "class_name": "keras.utils.io_utils.H5Dict",
        "signature": "keras.utils.io_utils.H5Dict.__setitem__(self, attr, val)",
        "snippet": "    def __setitem__(self, attr, val):\n        if self.read_only:\n            raise ValueError('Cannot set item in read-only mode.')\n        is_np = type(val).__module__ == np.__name__\n        if isinstance(self.data, dict):\n            if isinstance(attr, bytes):\n                attr = attr.decode('utf-8')\n            if is_np:\n                self.data[attr] = pickle.dumps(val)\n                # We have to remember to unpickle in __getitem__\n                self.data['_{}_pickled'.format(attr)] = True\n            else:\n                self.data[attr] = val\n            return\n        if isinstance(self.data, h5py.Group) and attr in self.data:\n            raise KeyError('Cannot set attribute. '\n                           'Group with name \"{}\" exists.'.format(attr))\n        if is_np:\n            dataset = self.data.create_dataset(attr, val.shape, dtype=val.dtype)\n            if not val.shape:\n                # scalar\n                dataset[()] = val\n            else:\n                dataset[:] = val\n        elif isinstance(val, (list, tuple)):\n            # Check that no item in `data` is larger than `HDF5_OBJECT_HEADER_LIMIT`\n            # because in that case even chunking the array would not make the saving\n            # possible.\n            bad_attributes = [x for x in val if len(x) > HDF5_OBJECT_HEADER_LIMIT]\n\n            # Expecting this to never be true.\n            if bad_attributes:\n                raise RuntimeError('The following attributes cannot be saved to '\n                                   'HDF5 file because they are larger than '\n                                   '%d bytes: %s' % (HDF5_OBJECT_HEADER_LIMIT,\n                                                     ', '.join(bad_attributes)))\n\n            if (val and sys.version_info[0] == 3 and isinstance(\n                    val[0], six.string_types)):\n                # convert to bytes\n                val = [x.encode('utf-8') for x in val]\n\n            data_npy = np.asarray(val)\n\n            num_chunks = 1\n            chunked_data = np.array_split(data_npy, num_chunks)\n\n            # This will never loop forever thanks to the test above.\n            is_too_big = lambda x: x.nbytes > HDF5_OBJECT_HEADER_LIMIT\n            while any(map(is_too_big, chunked_data)):\n                num_chunks += 1\n                chunked_data = np.array_split(data_npy, num_chunks)\n\n            if num_chunks > 1:\n                for chunk_id, chunk_data in enumerate(chunked_data):\n                    self.data.attrs['%s%d' % (attr, chunk_id)] = chunk_data\n            else:\n                self.data.attrs[attr] = val\n        else:\n            self.data.attrs[attr] = val",
        "begin_line": 210,
        "end_line": 269,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.utils.io_utils.H5Dict.__getitem__#271",
        "src_path": "keras/utils/io_utils.py",
        "class_name": "keras.utils.io_utils.H5Dict",
        "signature": "keras.utils.io_utils.H5Dict.__getitem__(self, attr)",
        "snippet": "    def __getitem__(self, attr):\n        if isinstance(self.data, dict):\n            if isinstance(attr, bytes):\n                attr = attr.decode('utf-8')\n            if attr in self.data:\n                val = self.data[attr]\n                if isinstance(val, dict) and val.get('_is_group'):\n                    val = H5Dict(val)\n                elif '_{}_pickled'.format(attr) in self.data:\n                    val = pickle.loads(val)\n                return val\n            else:\n                if self.read_only:\n                    raise ValueError('Cannot create group in read-only mode.')\n                val = {'_is_group': True}\n                self.data[attr] = val\n                return H5Dict(val)\n        if attr in self.data.attrs:\n            val = self.data.attrs[attr]\n            if type(val).__module__ == np.__name__:\n                if val.dtype.type == np.string_:\n                    val = val.tolist()\n        elif attr in self.data:\n            val = self.data[attr]\n            if isinstance(val, h5py.Dataset):\n                val = np.asarray(val)\n            else:\n                val = H5Dict(val)\n        else:\n            # could be chunked\n            chunk_attr = '%s%d' % (attr, 0)\n            is_chunked = chunk_attr in self.data.attrs\n            if is_chunked:\n                val = []\n                chunk_id = 0\n                while chunk_attr in self.data.attrs:\n                    chunk = self.data.attrs[chunk_attr]\n                    val.extend([x.decode('utf8') for x in chunk])\n                    chunk_id += 1\n                    chunk_attr = '%s%d' % (attr, chunk_id)\n            else:\n                if self.read_only:\n                    raise ValueError('Cannot create group in read-only mode.')\n                val = H5Dict(self.data.create_group(attr))\n        return val",
        "begin_line": 271,
        "end_line": 315,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.utils.io_utils.H5Dict.close#339",
        "src_path": "keras/utils/io_utils.py",
        "class_name": "keras.utils.io_utils.H5Dict",
        "signature": "keras.utils.io_utils.H5Dict.close(self)",
        "snippet": "    def close(self):\n        if isinstance(self.data, h5py.Group):\n            self.data.file.flush()\n            if self._is_file:\n                self.data.close()",
        "begin_line": 339,
        "end_line": 343,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0004144218814753419,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.utils.io_utils.H5Dict.__contains__#350",
        "src_path": "keras/utils/io_utils.py",
        "class_name": "keras.utils.io_utils.H5Dict",
        "signature": "keras.utils.io_utils.H5Dict.__contains__(self, key)",
        "snippet": "    def __contains__(self, key):\n        if isinstance(self.data, dict):\n            return key in self.data\n        else:\n            return (key in self.data) or (key in self.data.attrs)",
        "begin_line": 350,
        "end_line": 354,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005574136008918618,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.utils.io_utils.H5Dict.get#356",
        "src_path": "keras/utils/io_utils.py",
        "class_name": "keras.utils.io_utils.H5Dict",
        "signature": "keras.utils.io_utils.H5Dict.get(self, key, default=None)",
        "snippet": "    def get(self, key, default=None):\n        if key in self:\n            return self[key]\n        return default",
        "begin_line": 356,
        "end_line": 359,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005083884087442806,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.__init__#29",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.__init__(self, layer, **kwargs)",
        "snippet": "    def __init__(self, layer, **kwargs):\n        self.layer = layer\n        # Tracks mapping of Wrapper inputs to inner layer inputs. Useful when\n        # the inner layer has update ops that depend on its inputs (as opposed\n        # to the inputs to the Wrapper layer).\n        self._input_map = {}\n        super(Wrapper, self).__init__(**kwargs)",
        "begin_line": 29,
        "end_line": 35,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0006176652254478073,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.build#37",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.build(self, input_shape=None)",
        "snippet": "    def build(self, input_shape=None):\n        self.built = True",
        "begin_line": 37,
        "end_line": 38,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0006176652254478073,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.activity_regularizer#41",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.activity_regularizer(self)",
        "snippet": "    def activity_regularizer(self):\n        if hasattr(self.layer, 'activity_regularizer'):\n            return self.layer.activity_regularizer\n        else:\n            return None",
        "begin_line": 41,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0006176652254478073,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.trainable#48",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.trainable(self)",
        "snippet": "    def trainable(self):\n        return self.layer.trainable",
        "begin_line": 48,
        "end_line": 49,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0006176652254478073,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.trainable#52",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.trainable(self, value)",
        "snippet": "    def trainable(self, value):\n        self.layer.trainable = value",
        "begin_line": 52,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0006176652254478073,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.trainable_weights#56",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.trainable_weights(self)",
        "snippet": "    def trainable_weights(self):\n        return self.layer.trainable_weights",
        "begin_line": 56,
        "end_line": 57,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0006176652254478073,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.non_trainable_weights#60",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.non_trainable_weights(self)",
        "snippet": "    def non_trainable_weights(self):\n        return self.layer.non_trainable_weights",
        "begin_line": 60,
        "end_line": 61,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.updates#64",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.updates(self)",
        "snippet": "    def updates(self):\n        if hasattr(self.layer, 'updates'):\n            return self.layer.updates\n        return []",
        "begin_line": 64,
        "end_line": 67,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0006176652254478073,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.get_updates_for#69",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.get_updates_for(self, inputs=None)",
        "snippet": "    def get_updates_for(self, inputs=None):\n        # If the wrapper modifies the inputs, use the modified inputs to\n        # get the updates from the inner layer.\n        inner_inputs = inputs\n        if inputs is not None:\n            uid = object_list_uid(inputs)\n            if uid in self._input_map:\n                inner_inputs = self._input_map[uid]\n\n        updates = self.layer.get_updates_for(inner_inputs)\n        updates += super(Wrapper, self).get_updates_for(inputs)\n        return updates",
        "begin_line": 69,
        "end_line": 80,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0006176652254478073,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.losses#83",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.losses(self)",
        "snippet": "    def losses(self):\n        if hasattr(self.layer, 'losses'):\n            return self.layer.losses\n        return []",
        "begin_line": 83,
        "end_line": 86,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0006176652254478073,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.get_losses_for#88",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.get_losses_for(self, inputs=None)",
        "snippet": "    def get_losses_for(self, inputs=None):\n        if inputs is None:\n            losses = self.layer.get_losses_for(None)\n            return losses + super(Wrapper, self).get_losses_for(None)\n        return super(Wrapper, self).get_losses_for(inputs)",
        "begin_line": 88,
        "end_line": 92,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0006176652254478073,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.get_config#100",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'layer': {'class_name': self.layer.__class__.__name__,\n                            'config': self.layer.get_config()}}\n        base_config = super(Wrapper, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 100,
        "end_line": 104,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.wrappers.Wrapper.from_config#107",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.Wrapper",
        "signature": "keras.layers.wrappers.Wrapper.from_config(cls, config, custom_objects=None)",
        "snippet": "    def from_config(cls, config, custom_objects=None):\n        from . import deserialize as deserialize_layer\n        layer = deserialize_layer(config.pop('layer'),\n                                  custom_objects=custom_objects)\n        return cls(layer, **config)",
        "begin_line": 107,
        "end_line": 111,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.wrappers.TimeDistributed.__init__#159",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.TimeDistributed",
        "signature": "keras.layers.wrappers.TimeDistributed.__init__(self, layer, **kwargs)",
        "snippet": "    def __init__(self, layer, **kwargs):\n        super(TimeDistributed, self).__init__(layer, **kwargs)\n        self.supports_masking = True",
        "begin_line": 159,
        "end_line": 161,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0006176652254478073,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.wrappers.TimeDistributed._get_shape_tuple#163",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.TimeDistributed",
        "signature": "keras.layers.wrappers.TimeDistributed._get_shape_tuple(self, init_tuple, tensor, start_idx, int_shape=None)",
        "snippet": "    def _get_shape_tuple(self, init_tuple, tensor, start_idx, int_shape=None):\n        \"\"\"Finds non-specific dimensions in the static shapes\n        and replaces them by the corresponding dynamic shapes of the tensor.\n\n        # Arguments\n            init_tuple: a tuple, the first part of the output shape\n            tensor: the tensor from which to get the (static and dynamic) shapes\n                as the last part of the output shape\n            start_idx: int, which indicate the first dimension to take from\n                the static shape of the tensor\n            int_shape: an alternative static shape to take as the last part\n                of the output shape\n\n        # Returns\n            The new int_shape with the first part from init_tuple\n            and the last part from either `int_shape` (if provided)\n            or K.int_shape(tensor), where every `None` is replaced by\n            the corresponding dimension from K.shape(tensor)\n        \"\"\"\n        # replace all None in int_shape by K.shape\n        if int_shape is None:\n            int_shape = K.int_shape(tensor)[start_idx:]\n        if not any(not s for s in int_shape):\n            return init_tuple + int_shape\n        tensor_shape = K.shape(tensor)\n        int_shape = list(int_shape)\n        for i, s in enumerate(int_shape):\n            if not s:\n                int_shape[i] = tensor_shape[start_idx + i]\n        return init_tuple + tuple(int_shape)",
        "begin_line": 163,
        "end_line": 192,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0006176652254478073,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.wrappers.TimeDistributed.build#194",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.TimeDistributed",
        "signature": "keras.layers.wrappers.TimeDistributed.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        assert len(input_shape) >= 3\n        self.input_spec = InputSpec(shape=input_shape)\n        child_input_shape = (input_shape[0],) + input_shape[2:]\n        if not self.layer.built:\n            self.layer.build(child_input_shape)\n            self.layer.built = True\n        super(TimeDistributed, self).build()",
        "begin_line": 194,
        "end_line": 201,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0006176652254478073,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.wrappers.TimeDistributed.compute_output_shape#203",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.TimeDistributed",
        "signature": "keras.layers.wrappers.TimeDistributed.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        child_input_shape = (input_shape[0],) + input_shape[2:]\n        child_output_shape = self.layer.compute_output_shape(child_input_shape)\n        timesteps = input_shape[1]\n        return (child_output_shape[0], timesteps) + child_output_shape[1:]",
        "begin_line": 203,
        "end_line": 207,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0006176652254478073,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.wrappers.TimeDistributed.call#209",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.TimeDistributed",
        "signature": "keras.layers.wrappers.TimeDistributed.call(self, inputs, training=None, mask=None)",
        "snippet": "    def call(self, inputs, training=None, mask=None):\n        kwargs = {}\n        if has_arg(self.layer.call, 'training'):\n            kwargs['training'] = training\n        uses_learning_phase = False\n\n        input_shape = K.int_shape(inputs)\n        if input_shape[0]:\n            # batch size matters, use rnn-based implementation\n            def step(x, _):\n                global uses_learning_phase\n                output = self.layer.call(x, **kwargs)\n                if hasattr(output, '_uses_learning_phase'):\n                    uses_learning_phase = (output._uses_learning_phase or\n                                           uses_learning_phase)\n                return output, []\n\n            _, outputs, _ = K.rnn(step, inputs,\n                                  initial_states=[],\n                                  input_length=input_shape[1],\n                                  unroll=False)\n            y = outputs\n        else:\n            # No batch size specified, therefore the layer will be able\n            # to process batches of any size.\n            # We can go with reshape-based implementation for performance.\n            input_length = input_shape[1]\n            if not input_length:\n                input_length = K.shape(inputs)[1]\n            inner_input_shape = self._get_shape_tuple((-1,), inputs, 2)\n            # Shape: (num_samples * timesteps, ...). And track the\n            # transformation in self._input_map.\n            input_uid = object_list_uid(inputs)\n            inputs = K.reshape(inputs, inner_input_shape)\n            self._input_map[input_uid] = inputs\n            # (num_samples * timesteps, ...)\n            if has_arg(self.layer.call, 'mask') and mask is not None:\n                inner_mask_shape = self._get_shape_tuple((-1,), mask, 2)\n                kwargs['mask'] = K.reshape(mask, inner_mask_shape)\n            y = self.layer.call(inputs, **kwargs)\n            if hasattr(y, '_uses_learning_phase'):\n                uses_learning_phase = y._uses_learning_phase\n            # Shape: (num_samples, timesteps, ...)\n            output_shape = self.compute_output_shape(input_shape)\n            output_shape = self._get_shape_tuple(\n                (-1, input_length), y, 1, output_shape[2:])\n            y = K.reshape(y, output_shape)\n\n        # Apply activity regularizer if any:\n        if (hasattr(self.layer, 'activity_regularizer') and\n           self.layer.activity_regularizer is not None):\n            regularization_loss = self.layer.activity_regularizer(y)\n            self.add_loss(regularization_loss, inputs)\n\n        if uses_learning_phase:\n            y._uses_learning_phase = True\n        return y",
        "begin_line": 209,
        "end_line": 265,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.wrappers.TimeDistributed.compute_mask#267",
        "src_path": "keras/layers/wrappers.py",
        "class_name": "keras.layers.wrappers.TimeDistributed",
        "signature": "keras.layers.wrappers.TimeDistributed.compute_mask(self, inputs, mask=None)",
        "snippet": "    def compute_mask(self, inputs, mask=None):\n        \"\"\"Computes an output mask tensor for Embedding layer\n        based on the inputs, mask, and the inner layer.\n\n        If batch size is specified:\n        Simply return the input `mask`. (An rnn-based implementation with\n        more than one rnn inputs is required but not supported in Keras yet.)\n\n        Otherwise we call `compute_mask` of the inner layer at each time step.\n        If the output mask at each time step is not `None`:\n        (E.g., inner layer is Masking or RNN)\n        Concatenate all of them and return the concatenation.\n        If the output mask at each time step is `None` and\n        the input mask is not `None`:\n        (E.g., inner layer is Dense)\n        Reduce the input_mask to 2 dimensions and return it.\n        Otherwise (both the output mask and the input mask are `None`):\n        (E.g., `mask` is not used at all)\n        Return `None`.\n\n        # Arguments\n            inputs: Tensor\n            mask: Tensor\n        # Returns\n            None or a tensor\n        \"\"\"\n        # cases need to call the layer.compute_mask when input_mask is None:\n        # Masking layer and Embedding layer with mask_zero\n        input_shape = K.int_shape(inputs)\n        if input_shape[0]:\n            # batch size matters, we currently do not handle mask explicitly\n            return mask\n        inner_mask = mask\n        if inner_mask is not None:\n            inner_mask_shape = self._get_shape_tuple((-1,), mask, 2)\n            inner_mask = K.reshape(inner_mask, inner_mask_shape)\n        input_uid = object_list_uid(inputs)\n        inner_inputs = self._input_map[input_uid]\n        output_mask = self.layer.compute_mask(inner_inputs, inner_mask)\n        if output_mask is None:\n            if mask is None:\n                return None\n            # input_mask is not None, and output_mask is None:\n            # we should return a not-None mask\n            output_mask = mask\n            for _ in range(2, len(K.int_shape(mask))):\n                output_mask = K.any(output_mask, axis=-1)\n        else:\n            # output_mask is not None. We need to reshape it\n            input_length = input_shape[1]\n            if not input_length:\n                input_length = K.shape(inputs)[1]\n            output_mask_int_shape = K.int_shape(output_mask)\n            if output_mask_int_shape is None:\n                # if the output_mask does not have a static shape,\n                # its shape must be the same as mask's\n                if mask is not None:\n                    output_mask_int_shape = K.int_shape(mask)\n                else:\n                    output_mask_int_shape = K.compute_output_shape(input_shape)[:-1]\n            output_mask_shape = self._get_shape_tuple(\n                (-1, input_length), output_mask, 1, output_mask_int_shape[1:])\n            output_mask = K.reshape(output_mask, output_mask_shape)\n        return output_mask",
        "begin_line": 267,
        "end_line": 330,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.__init__#392",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.__init__(self, cell, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False, **kwargs)",
        "snippet": "    def __init__(self, cell,\n                 return_sequences=False,\n                 return_state=False,\n                 go_backwards=False,\n                 stateful=False,\n                 unroll=False,\n                 **kwargs):\n        if isinstance(cell, (list, tuple)):\n            cell = StackedRNNCells(cell)\n        if not hasattr(cell, 'call'):\n            raise ValueError('`cell` should have a `call` method. '\n                             'The RNN was passed:', cell)\n        if not hasattr(cell, 'state_size'):\n            raise ValueError('The RNN cell should have '\n                             'an attribute `state_size` '\n                             '(tuple of integers, '\n                             'one integer per RNN state).')\n        super(RNN, self).__init__(**kwargs)\n        self.cell = cell\n        self.return_sequences = return_sequences\n        self.return_state = return_state\n        self.go_backwards = go_backwards\n        self.stateful = stateful\n        self.unroll = unroll\n\n        self.supports_masking = True\n        self.input_spec = [InputSpec(ndim=3)]\n        self.state_spec = None\n        self._states = None\n        self.constants_spec = None\n        self._num_constants = None",
        "begin_line": 392,
        "end_line": 422,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.states#425",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.states(self)",
        "snippet": "    def states(self):\n        if self._states is None:\n            if isinstance(self.cell.state_size, int):\n                num_states = 1\n            else:\n                num_states = len(self.cell.state_size)\n            return [None for _ in range(num_states)]\n        return self._states",
        "begin_line": 425,
        "end_line": 432,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.compute_output_shape#438",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n\n        if hasattr(self.cell.state_size, '__len__'):\n            state_size = self.cell.state_size\n        else:\n            state_size = [self.cell.state_size]\n\n        if getattr(self.cell, 'output_size', None) is not None:\n            output_dim = self.cell.output_size\n        else:\n            output_dim = state_size[0]\n\n        if self.return_sequences:\n            output_shape = (input_shape[0], input_shape[1], output_dim)\n        else:\n            output_shape = (input_shape[0], output_dim)\n\n        if self.return_state:\n            state_shape = [(input_shape[0], dim) for dim in state_size]\n            return [output_shape] + state_shape\n        else:\n            return output_shape",
        "begin_line": 438,
        "end_line": 461,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.compute_mask#463",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.compute_mask(self, inputs, mask)",
        "snippet": "    def compute_mask(self, inputs, mask):\n        if isinstance(mask, list):\n            mask = mask[0]\n        output_mask = mask if self.return_sequences else None\n        if self.return_state:\n            state_mask = [None for _ in self.states]\n            return [output_mask] + state_mask\n        else:\n            return output_mask",
        "begin_line": 463,
        "end_line": 471,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.build#473",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        # Note input_shape will be list of shapes of initial states and\n        # constants if these are passed in __call__.\n        if self._num_constants is not None:\n            constants_shape = input_shape[-self._num_constants:]\n        else:\n            constants_shape = None\n\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n\n        batch_size = input_shape[0] if self.stateful else None\n        input_dim = input_shape[-1]\n        self.input_spec[0] = InputSpec(shape=(batch_size, None, input_dim))\n\n        # allow cell (if layer) to build before we set or validate state_spec\n        if isinstance(self.cell, Layer):\n            step_input_shape = (input_shape[0],) + input_shape[2:]\n            if constants_shape is not None:\n                self.cell.build([step_input_shape] + constants_shape)\n            else:\n                self.cell.build(step_input_shape)\n\n        # set or validate state_spec\n        if hasattr(self.cell.state_size, '__len__'):\n            state_size = list(self.cell.state_size)\n        else:\n            state_size = [self.cell.state_size]\n\n        if self.state_spec is not None:\n            # initial_state was passed in call, check compatibility\n            if [spec.shape[-1] for spec in self.state_spec] != state_size:\n                raise ValueError(\n                    'An `initial_state` was passed that is not compatible with '\n                    '`cell.state_size`. Received `state_spec`={}; '\n                    'however `cell.state_size` is '\n                    '{}'.format(self.state_spec, self.cell.state_size))\n        else:\n            self.state_spec = [InputSpec(shape=(None, dim))\n                               for dim in state_size]\n        if self.stateful:\n            self.reset_states()\n        self.built = True",
        "begin_line": 473,
        "end_line": 515,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.get_initial_state#517",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.get_initial_state(self, inputs)",
        "snippet": "    def get_initial_state(self, inputs):\n        # build an all-zero tensor of shape (samples, output_dim)\n        initial_state = K.zeros_like(inputs)  # (samples, timesteps, input_dim)\n        initial_state = K.sum(initial_state, axis=(1, 2))  # (samples,)\n        initial_state = K.expand_dims(initial_state)  # (samples, 1)\n        if hasattr(self.cell.state_size, '__len__'):\n            return [K.tile(initial_state, [1, dim])\n                    for dim in self.cell.state_size]\n        else:\n            return [K.tile(initial_state, [1, self.cell.state_size])]",
        "begin_line": 517,
        "end_line": 526,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.__call__#528",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.__call__(self, inputs, initial_state=None, constants=None, **kwargs)",
        "snippet": "    def __call__(self, inputs, initial_state=None, constants=None, **kwargs):\n        inputs, initial_state, constants = _standardize_args(\n            inputs, initial_state, constants, self._num_constants)\n\n        if initial_state is None and constants is None:\n            return super(RNN, self).__call__(inputs, **kwargs)\n\n        # If any of `initial_state` or `constants` are specified and are Keras\n        # tensors, then add them to the inputs and temporarily modify the\n        # input_spec to include them.\n\n        additional_inputs = []\n        additional_specs = []\n        if initial_state is not None:\n            kwargs['initial_state'] = initial_state\n            additional_inputs += initial_state\n            self.state_spec = [InputSpec(shape=K.int_shape(state))\n                               for state in initial_state]\n            additional_specs += self.state_spec\n        if constants is not None:\n            kwargs['constants'] = constants\n            additional_inputs += constants\n            self.constants_spec = [InputSpec(shape=K.int_shape(constant))\n                                   for constant in constants]\n            self._num_constants = len(constants)\n            additional_specs += self.constants_spec\n        # at this point additional_inputs cannot be empty\n        is_keras_tensor = K.is_keras_tensor(additional_inputs[0])\n        for tensor in additional_inputs:\n            if K.is_keras_tensor(tensor) != is_keras_tensor:\n                raise ValueError('The initial state or constants of an RNN'\n                                 ' layer cannot be specified with a mix of'\n                                 ' Keras tensors and non-Keras tensors'\n                                 ' (a \"Keras tensor\" is a tensor that was'\n                                 ' returned by a Keras layer, or by `Input`)')\n\n        if is_keras_tensor:\n            # Compute the full input spec, including state and constants\n            full_input = [inputs] + additional_inputs\n            full_input_spec = self.input_spec + additional_specs\n            # Perform the call with temporarily replaced input_spec\n            original_input_spec = self.input_spec\n            self.input_spec = full_input_spec\n            output = super(RNN, self).__call__(full_input, **kwargs)\n            self.input_spec = original_input_spec\n            return output\n        else:\n            return super(RNN, self).__call__(inputs, **kwargs)",
        "begin_line": 528,
        "end_line": 575,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.call#577",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.call(self, inputs, mask=None, training=None, initial_state=None, constants=None)",
        "snippet": "    def call(self,\n             inputs,\n             mask=None,\n             training=None,\n             initial_state=None,\n             constants=None):\n        # input shape: `(samples, time (padded with zeros), input_dim)`\n        # note that the .build() method of subclasses MUST define\n        # self.input_spec and self.state_spec with complete input shapes.\n        if isinstance(inputs, list):\n            # get initial_state from full input spec\n            # as they could be copied to multiple GPU.\n            if self._num_constants is None:\n                initial_state = inputs[1:]\n            else:\n                initial_state = inputs[1:-self._num_constants]\n            if len(initial_state) == 0:\n                initial_state = None\n            inputs = inputs[0]\n        if initial_state is not None:\n            pass\n        elif self.stateful:\n            initial_state = self.states\n        else:\n            initial_state = self.get_initial_state(inputs)\n\n        if isinstance(mask, list):\n            mask = mask[0]\n\n        if len(initial_state) != len(self.states):\n            raise ValueError('Layer has ' + str(len(self.states)) +\n                             ' states but was passed ' +\n                             str(len(initial_state)) +\n                             ' initial states.')\n        input_shape = K.int_shape(inputs)\n        timesteps = input_shape[1]\n        if self.unroll and timesteps in [None, 1]:\n            raise ValueError('Cannot unroll a RNN if the '\n                             'time dimension is undefined or equal to 1. \\n'\n                             '- If using a Sequential model, '\n                             'specify the time dimension by passing '\n                             'an `input_shape` or `batch_input_shape` '\n                             'argument to your first layer. If your '\n                             'first layer is an Embedding, you can '\n                             'also use the `input_length` argument.\\n'\n                             '- If using the functional API, specify '\n                             'the time dimension by passing a `shape` '\n                             'or `batch_shape` argument to your Input layer.')\n\n        kwargs = {}\n        if has_arg(self.cell.call, 'training'):\n            kwargs['training'] = training\n\n        if constants:\n            if not has_arg(self.cell.call, 'constants'):\n                raise ValueError('RNN cell does not support constants')\n\n            def step(inputs, states):\n                constants = states[-self._num_constants:]\n                states = states[:-self._num_constants]\n                return self.cell.call(inputs, states, constants=constants,\n                                      **kwargs)\n        else:\n            def step(inputs, states):\n                return self.cell.call(inputs, states, **kwargs)\n\n        last_output, outputs, states = K.rnn(step,\n                                             inputs,\n                                             initial_state,\n                                             constants=constants,\n                                             go_backwards=self.go_backwards,\n                                             mask=mask,\n                                             unroll=self.unroll,\n                                             input_length=timesteps)\n        if self.stateful:\n            updates = []\n            for i in range(len(states)):\n                updates.append((self.states[i], states[i]))\n            self.add_update(updates, inputs)\n\n        if self.return_sequences:\n            output = outputs\n        else:\n            output = last_output\n\n        # Properly set learning phase\n        if getattr(last_output, '_uses_learning_phase', False):\n            output._uses_learning_phase = True\n            for state in states:\n                state._uses_learning_phase = True\n\n        if self.return_state:\n            states = to_list(states, allow_tuple=True)\n            return [output] + states\n        else:\n            return output",
        "begin_line": 577,
        "end_line": 672,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.step#640",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.step(inputs, states)",
        "snippet": "            def step(inputs, states):\n                return self.cell.call(inputs, states, **kwargs)",
        "begin_line": 640,
        "end_line": 641,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.get_config#725",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'return_sequences': self.return_sequences,\n                  'return_state': self.return_state,\n                  'go_backwards': self.go_backwards,\n                  'stateful': self.stateful,\n                  'unroll': self.unroll}\n        if self._num_constants is not None:\n            config['num_constants'] = self._num_constants\n\n        cell_config = self.cell.get_config()\n        config['cell'] = {'class_name': self.cell.__class__.__name__,\n                          'config': cell_config}\n        base_config = super(RNN, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 725,
        "end_line": 738,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.trainable_weights#751",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.trainable_weights(self)",
        "snippet": "    def trainable_weights(self):\n        if not self.trainable:\n            return []\n        if isinstance(self.cell, Layer):\n            return self.cell.trainable_weights\n        return []",
        "begin_line": 751,
        "end_line": 756,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.non_trainable_weights#759",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.non_trainable_weights(self)",
        "snippet": "    def non_trainable_weights(self):\n        if isinstance(self.cell, Layer):\n            if not self.trainable:\n                return self.cell.weights\n            return self.cell.non_trainable_weights\n        return []",
        "begin_line": 759,
        "end_line": 764,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.losses#767",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.losses(self)",
        "snippet": "    def losses(self):\n        layer_losses = super(RNN, self).losses\n        if isinstance(self.cell, Layer):\n            return self.cell.losses + layer_losses\n        return layer_losses",
        "begin_line": 767,
        "end_line": 771,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.RNN.get_losses_for#773",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.RNN",
        "signature": "keras.layers.recurrent.RNN.get_losses_for(self, inputs=None)",
        "snippet": "    def get_losses_for(self, inputs=None):\n        if isinstance(self.cell, Layer):\n            cell_losses = self.cell.get_losses_for(inputs)\n            return cell_losses + super(RNN, self).get_losses_for(inputs)\n        return super(RNN, self).get_losses_for(inputs)",
        "begin_line": 773,
        "end_line": 777,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.GRUCell.__init__#1223",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRUCell",
        "signature": "keras.layers.recurrent.GRUCell.__init__(self, units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, reset_after=False, **kwargs)",
        "snippet": "    def __init__(self, units,\n                 activation='tanh',\n                 recurrent_activation='hard_sigmoid',\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 recurrent_initializer='orthogonal',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n                 kernel_constraint=None,\n                 recurrent_constraint=None,\n                 bias_constraint=None,\n                 dropout=0.,\n                 recurrent_dropout=0.,\n                 implementation=1,\n                 reset_after=False,\n                 **kwargs):\n        super(GRUCell, self).__init__(**kwargs)\n        self.units = units\n        self.activation = activations.get(activation)\n        self.recurrent_activation = activations.get(recurrent_activation)\n        self.use_bias = use_bias\n\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.recurrent_initializer = initializers.get(recurrent_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.recurrent_constraint = constraints.get(recurrent_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n\n        self.dropout = min(1., max(0., dropout))\n        self.recurrent_dropout = min(1., max(0., recurrent_dropout))\n        self.implementation = implementation\n        self.reset_after = reset_after\n        self.state_size = self.units\n        self.output_size = self.units\n        self._dropout_mask = None\n        self._recurrent_dropout_mask = None",
        "begin_line": 1223,
        "end_line": 1266,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.GRUCell.build#1268",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRUCell",
        "signature": "keras.layers.recurrent.GRUCell.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        input_dim = input_shape[-1]\n\n        if isinstance(self.recurrent_initializer, initializers.Identity):\n            def recurrent_identity(shape, gain=1.):\n                return gain * np.concatenate(\n                    [np.identity(shape[0])] * (shape[1] // shape[0]), axis=1)\n\n            self.recurrent_initializer = recurrent_identity\n\n        self.kernel = self.add_weight(shape=(input_dim, self.units * 3),\n                                      name='kernel',\n                                      initializer=self.kernel_initializer,\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        self.recurrent_kernel = self.add_weight(\n            shape=(self.units, self.units * 3),\n            name='recurrent_kernel',\n            initializer=self.recurrent_initializer,\n            regularizer=self.recurrent_regularizer,\n            constraint=self.recurrent_constraint)\n\n        if self.use_bias:\n            if not self.reset_after:\n                bias_shape = (3 * self.units,)\n            else:\n                # separate biases for input and recurrent kernels\n                # Note: the shape is intentionally different from CuDNNGRU biases\n                # `(2 * 3 * self.units,)`, so that we can distinguish the classes\n                # when loading and converting saved weights.\n                bias_shape = (2, 3 * self.units)\n            self.bias = self.add_weight(shape=bias_shape,\n                                        name='bias',\n                                        initializer=self.bias_initializer,\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n            if not self.reset_after:\n                self.input_bias, self.recurrent_bias = self.bias, None\n            else:\n                # NOTE: need to flatten, since slicing in CNTK gives 2D array\n                self.input_bias = K.flatten(self.bias[0])\n                self.recurrent_bias = K.flatten(self.bias[1])\n        else:\n            self.bias = None\n\n        # update gate\n        self.kernel_z = self.kernel[:, :self.units]\n        self.recurrent_kernel_z = self.recurrent_kernel[:, :self.units]\n        # reset gate\n        self.kernel_r = self.kernel[:, self.units: self.units * 2]\n        self.recurrent_kernel_r = self.recurrent_kernel[:,\n                                                        self.units:\n                                                        self.units * 2]\n        # new gate\n        self.kernel_h = self.kernel[:, self.units * 2:]\n        self.recurrent_kernel_h = self.recurrent_kernel[:, self.units * 2:]\n\n        if self.use_bias:\n            # bias for inputs\n            self.input_bias_z = self.input_bias[:self.units]\n            self.input_bias_r = self.input_bias[self.units: self.units * 2]\n            self.input_bias_h = self.input_bias[self.units * 2:]\n            # bias for hidden state - just for compatibility with CuDNN\n            if self.reset_after:\n                self.recurrent_bias_z = self.recurrent_bias[:self.units]\n                self.recurrent_bias_r = (\n                    self.recurrent_bias[self.units: self.units * 2])\n                self.recurrent_bias_h = self.recurrent_bias[self.units * 2:]\n        else:\n            self.input_bias_z = None\n            self.input_bias_r = None\n            self.input_bias_h = None\n            if self.reset_after:\n                self.recurrent_bias_z = None\n                self.recurrent_bias_r = None\n                self.recurrent_bias_h = None\n        self.built = True",
        "begin_line": 1268,
        "end_line": 1344,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.GRUCell.call#1346",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRUCell",
        "signature": "keras.layers.recurrent.GRUCell.call(self, inputs, states, training=None)",
        "snippet": "    def call(self, inputs, states, training=None):\n        h_tm1 = states[0]  # previous memory\n\n        if 0 < self.dropout < 1 and self._dropout_mask is None:\n            self._dropout_mask = _generate_dropout_mask(\n                K.ones_like(inputs),\n                self.dropout,\n                training=training,\n                count=3)\n        if (0 < self.recurrent_dropout < 1 and\n                self._recurrent_dropout_mask is None):\n            self._recurrent_dropout_mask = _generate_dropout_mask(\n                K.ones_like(h_tm1),\n                self.recurrent_dropout,\n                training=training,\n                count=3)\n\n        # dropout matrices for input units\n        dp_mask = self._dropout_mask\n        # dropout matrices for recurrent units\n        rec_dp_mask = self._recurrent_dropout_mask\n\n        if self.implementation == 1:\n            if 0. < self.dropout < 1.:\n                inputs_z = inputs * dp_mask[0]\n                inputs_r = inputs * dp_mask[1]\n                inputs_h = inputs * dp_mask[2]\n            else:\n                inputs_z = inputs\n                inputs_r = inputs\n                inputs_h = inputs\n\n            x_z = K.dot(inputs_z, self.kernel_z)\n            x_r = K.dot(inputs_r, self.kernel_r)\n            x_h = K.dot(inputs_h, self.kernel_h)\n            if self.use_bias:\n                x_z = K.bias_add(x_z, self.input_bias_z)\n                x_r = K.bias_add(x_r, self.input_bias_r)\n                x_h = K.bias_add(x_h, self.input_bias_h)\n\n            if 0. < self.recurrent_dropout < 1.:\n                h_tm1_z = h_tm1 * rec_dp_mask[0]\n                h_tm1_r = h_tm1 * rec_dp_mask[1]\n                h_tm1_h = h_tm1 * rec_dp_mask[2]\n            else:\n                h_tm1_z = h_tm1\n                h_tm1_r = h_tm1\n                h_tm1_h = h_tm1\n\n            recurrent_z = K.dot(h_tm1_z, self.recurrent_kernel_z)\n            recurrent_r = K.dot(h_tm1_r, self.recurrent_kernel_r)\n            if self.reset_after and self.use_bias:\n                recurrent_z = K.bias_add(recurrent_z, self.recurrent_bias_z)\n                recurrent_r = K.bias_add(recurrent_r, self.recurrent_bias_r)\n\n            z = self.recurrent_activation(x_z + recurrent_z)\n            r = self.recurrent_activation(x_r + recurrent_r)\n\n            # reset gate applied after/before matrix multiplication\n            if self.reset_after:\n                recurrent_h = K.dot(h_tm1_h, self.recurrent_kernel_h)\n                if self.use_bias:\n                    recurrent_h = K.bias_add(recurrent_h, self.recurrent_bias_h)\n                recurrent_h = r * recurrent_h\n            else:\n                recurrent_h = K.dot(r * h_tm1_h, self.recurrent_kernel_h)\n\n            hh = self.activation(x_h + recurrent_h)\n        else:\n            if 0. < self.dropout < 1.:\n                inputs *= dp_mask[0]\n\n            # inputs projected by all gate matrices at once\n            matrix_x = K.dot(inputs, self.kernel)\n            if self.use_bias:\n                # biases: bias_z_i, bias_r_i, bias_h_i\n                matrix_x = K.bias_add(matrix_x, self.input_bias)\n            x_z = matrix_x[:, :self.units]\n            x_r = matrix_x[:, self.units: 2 * self.units]\n            x_h = matrix_x[:, 2 * self.units:]\n\n            if 0. < self.recurrent_dropout < 1.:\n                h_tm1 *= rec_dp_mask[0]\n\n            if self.reset_after:\n                # hidden state projected by all gate matrices at once\n                matrix_inner = K.dot(h_tm1, self.recurrent_kernel)\n                if self.use_bias:\n                    matrix_inner = K.bias_add(matrix_inner, self.recurrent_bias)\n            else:\n                # hidden state projected separately for update/reset and new\n                matrix_inner = K.dot(h_tm1,\n                                     self.recurrent_kernel[:, :2 * self.units])\n\n            recurrent_z = matrix_inner[:, :self.units]\n            recurrent_r = matrix_inner[:, self.units: 2 * self.units]\n\n            z = self.recurrent_activation(x_z + recurrent_z)\n            r = self.recurrent_activation(x_r + recurrent_r)\n\n            if self.reset_after:\n                recurrent_h = r * matrix_inner[:, 2 * self.units:]\n            else:\n                recurrent_h = K.dot(r * h_tm1,\n                                    self.recurrent_kernel[:, 2 * self.units:])\n\n            hh = self.activation(x_h + recurrent_h)\n\n        # previous and candidate state mixed by update gate\n        h = z * h_tm1 + (1 - z) * hh\n\n        if 0 < self.dropout + self.recurrent_dropout:\n            if training is None:\n                h._uses_learning_phase = True\n\n        return h, [h]",
        "begin_line": 1346,
        "end_line": 1461,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.__init__#1589",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.__init__(self, units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False, reset_after=False, **kwargs)",
        "snippet": "    def __init__(self, units,\n                 activation='tanh',\n                 recurrent_activation='hard_sigmoid',\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 recurrent_initializer='orthogonal',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 recurrent_constraint=None,\n                 bias_constraint=None,\n                 dropout=0.,\n                 recurrent_dropout=0.,\n                 implementation=1,\n                 return_sequences=False,\n                 return_state=False,\n                 go_backwards=False,\n                 stateful=False,\n                 unroll=False,\n                 reset_after=False,\n                 **kwargs):\n        if implementation == 0:\n            warnings.warn('`implementation=0` has been deprecated, '\n                          'and now defaults to `implementation=1`.'\n                          'Please update your layer call.')\n        if K.backend() == 'theano' and (dropout or recurrent_dropout):\n            warnings.warn(\n                'RNN dropout is no longer supported with the Theano backend '\n                'due to technical limitations. '\n                'You can either set `dropout` and `recurrent_dropout` to 0, '\n                'or use the TensorFlow backend.')\n            dropout = 0.\n            recurrent_dropout = 0.\n\n        cell = GRUCell(units,\n                       activation=activation,\n                       recurrent_activation=recurrent_activation,\n                       use_bias=use_bias,\n                       kernel_initializer=kernel_initializer,\n                       recurrent_initializer=recurrent_initializer,\n                       bias_initializer=bias_initializer,\n                       kernel_regularizer=kernel_regularizer,\n                       recurrent_regularizer=recurrent_regularizer,\n                       bias_regularizer=bias_regularizer,\n                       kernel_constraint=kernel_constraint,\n                       recurrent_constraint=recurrent_constraint,\n                       bias_constraint=bias_constraint,\n                       dropout=dropout,\n                       recurrent_dropout=recurrent_dropout,\n                       implementation=implementation,\n                       reset_after=reset_after)\n        super(GRU, self).__init__(cell,\n                                  return_sequences=return_sequences,\n                                  return_state=return_state,\n                                  go_backwards=go_backwards,\n                                  stateful=stateful,\n                                  unroll=unroll,\n                                  **kwargs)\n        self.activity_regularizer = regularizers.get(activity_regularizer)",
        "begin_line": 1589,
        "end_line": 1650,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.GRU.call#1652",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.GRU",
        "signature": "keras.layers.recurrent.GRU.call(self, inputs, mask=None, training=None, initial_state=None)",
        "snippet": "    def call(self, inputs, mask=None, training=None, initial_state=None):\n        self.cell._dropout_mask = None\n        self.cell._recurrent_dropout_mask = None\n        return super(GRU, self).call(inputs,\n                                     mask=mask,\n                                     training=training,\n                                     initial_state=initial_state)",
        "begin_line": 1652,
        "end_line": 1658,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.LSTMCell.__init__#1826",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTMCell",
        "signature": "keras.layers.recurrent.LSTMCell.__init__(self, units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, **kwargs)",
        "snippet": "    def __init__(self, units,\n                 activation='tanh',\n                 recurrent_activation='hard_sigmoid',\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 recurrent_initializer='orthogonal',\n                 bias_initializer='zeros',\n                 unit_forget_bias=True,\n                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n                 kernel_constraint=None,\n                 recurrent_constraint=None,\n                 bias_constraint=None,\n                 dropout=0.,\n                 recurrent_dropout=0.,\n                 implementation=1,\n                 **kwargs):\n        super(LSTMCell, self).__init__(**kwargs)\n        self.units = units\n        self.activation = activations.get(activation)\n        self.recurrent_activation = activations.get(recurrent_activation)\n        self.use_bias = use_bias\n\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.recurrent_initializer = initializers.get(recurrent_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.unit_forget_bias = unit_forget_bias\n\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.recurrent_constraint = constraints.get(recurrent_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n\n        self.dropout = min(1., max(0., dropout))\n        self.recurrent_dropout = min(1., max(0., recurrent_dropout))\n        self.implementation = implementation\n        self.state_size = (self.units, self.units)\n        self.output_size = self.units\n        self._dropout_mask = None\n        self._recurrent_dropout_mask = None",
        "begin_line": 1826,
        "end_line": 1869,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.LSTMCell.build#1871",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTMCell",
        "signature": "keras.layers.recurrent.LSTMCell.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        input_dim = input_shape[-1]\n\n        if type(self.recurrent_initializer).__name__ == 'Identity':\n            def recurrent_identity(shape, gain=1.):\n                return gain * np.concatenate(\n                    [np.identity(shape[0])] * (shape[1] // shape[0]), axis=1)\n\n            self.recurrent_initializer = recurrent_identity\n\n        self.kernel = self.add_weight(shape=(input_dim, self.units * 4),\n                                      name='kernel',\n                                      initializer=self.kernel_initializer,\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        self.recurrent_kernel = self.add_weight(\n            shape=(self.units, self.units * 4),\n            name='recurrent_kernel',\n            initializer=self.recurrent_initializer,\n            regularizer=self.recurrent_regularizer,\n            constraint=self.recurrent_constraint)\n\n        if self.use_bias:\n            if self.unit_forget_bias:\n                @K.eager\n                def bias_initializer(_, *args, **kwargs):\n                    return K.concatenate([\n                        self.bias_initializer((self.units,), *args, **kwargs),\n                        initializers.Ones()((self.units,), *args, **kwargs),\n                        self.bias_initializer((self.units * 2,), *args, **kwargs),\n                    ])\n            else:\n                bias_initializer = self.bias_initializer\n            self.bias = self.add_weight(shape=(self.units * 4,),\n                                        name='bias',\n                                        initializer=bias_initializer,\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n\n        self.kernel_i = self.kernel[:, :self.units]\n        self.kernel_f = self.kernel[:, self.units: self.units * 2]\n        self.kernel_c = self.kernel[:, self.units * 2: self.units * 3]\n        self.kernel_o = self.kernel[:, self.units * 3:]\n\n        self.recurrent_kernel_i = self.recurrent_kernel[:, :self.units]\n        self.recurrent_kernel_f = (\n            self.recurrent_kernel[:, self.units: self.units * 2])\n        self.recurrent_kernel_c = (\n            self.recurrent_kernel[:, self.units * 2: self.units * 3])\n        self.recurrent_kernel_o = self.recurrent_kernel[:, self.units * 3:]\n\n        if self.use_bias:\n            self.bias_i = self.bias[:self.units]\n            self.bias_f = self.bias[self.units: self.units * 2]\n            self.bias_c = self.bias[self.units * 2: self.units * 3]\n            self.bias_o = self.bias[self.units * 3:]\n        else:\n            self.bias_i = None\n            self.bias_f = None\n            self.bias_c = None\n            self.bias_o = None\n        self.built = True",
        "begin_line": 1871,
        "end_line": 1934,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.LSTMCell.bias_initializer#1896",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTMCell",
        "signature": "keras.layers.recurrent.LSTMCell.bias_initializer(_, *args, **kwargs)",
        "snippet": "                def bias_initializer(_, *args, **kwargs):\n                    return K.concatenate([\n                        self.bias_initializer((self.units,), *args, **kwargs),\n                        initializers.Ones()((self.units,), *args, **kwargs),\n                        self.bias_initializer((self.units * 2,), *args, **kwargs),\n                    ])",
        "begin_line": 1896,
        "end_line": 1901,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.LSTMCell.call#1936",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTMCell",
        "signature": "keras.layers.recurrent.LSTMCell.call(self, inputs, states, training=None)",
        "snippet": "    def call(self, inputs, states, training=None):\n        if 0 < self.dropout < 1 and self._dropout_mask is None:\n            self._dropout_mask = _generate_dropout_mask(\n                K.ones_like(inputs),\n                self.dropout,\n                training=training,\n                count=4)\n        if (0 < self.recurrent_dropout < 1 and\n                self._recurrent_dropout_mask is None):\n            self._recurrent_dropout_mask = _generate_dropout_mask(\n                K.ones_like(states[0]),\n                self.recurrent_dropout,\n                training=training,\n                count=4)\n\n        # dropout matrices for input units\n        dp_mask = self._dropout_mask\n        # dropout matrices for recurrent units\n        rec_dp_mask = self._recurrent_dropout_mask\n\n        h_tm1 = states[0]  # previous memory state\n        c_tm1 = states[1]  # previous carry state\n\n        if self.implementation == 1:\n            if 0 < self.dropout < 1.:\n                inputs_i = inputs * dp_mask[0]\n                inputs_f = inputs * dp_mask[1]\n                inputs_c = inputs * dp_mask[2]\n                inputs_o = inputs * dp_mask[3]\n            else:\n                inputs_i = inputs\n                inputs_f = inputs\n                inputs_c = inputs\n                inputs_o = inputs\n            x_i = K.dot(inputs_i, self.kernel_i)\n            x_f = K.dot(inputs_f, self.kernel_f)\n            x_c = K.dot(inputs_c, self.kernel_c)\n            x_o = K.dot(inputs_o, self.kernel_o)\n            if self.use_bias:\n                x_i = K.bias_add(x_i, self.bias_i)\n                x_f = K.bias_add(x_f, self.bias_f)\n                x_c = K.bias_add(x_c, self.bias_c)\n                x_o = K.bias_add(x_o, self.bias_o)\n\n            if 0 < self.recurrent_dropout < 1.:\n                h_tm1_i = h_tm1 * rec_dp_mask[0]\n                h_tm1_f = h_tm1 * rec_dp_mask[1]\n                h_tm1_c = h_tm1 * rec_dp_mask[2]\n                h_tm1_o = h_tm1 * rec_dp_mask[3]\n            else:\n                h_tm1_i = h_tm1\n                h_tm1_f = h_tm1\n                h_tm1_c = h_tm1\n                h_tm1_o = h_tm1\n            i = self.recurrent_activation(x_i + K.dot(h_tm1_i,\n                                                      self.recurrent_kernel_i))\n            f = self.recurrent_activation(x_f + K.dot(h_tm1_f,\n                                                      self.recurrent_kernel_f))\n            c = f * c_tm1 + i * self.activation(x_c + K.dot(h_tm1_c,\n                                                            self.recurrent_kernel_c))\n            o = self.recurrent_activation(x_o + K.dot(h_tm1_o,\n                                                      self.recurrent_kernel_o))\n        else:\n            if 0. < self.dropout < 1.:\n                inputs *= dp_mask[0]\n            z = K.dot(inputs, self.kernel)\n            if 0. < self.recurrent_dropout < 1.:\n                h_tm1 *= rec_dp_mask[0]\n            z += K.dot(h_tm1, self.recurrent_kernel)\n            if self.use_bias:\n                z = K.bias_add(z, self.bias)\n\n            z0 = z[:, :self.units]\n            z1 = z[:, self.units: 2 * self.units]\n            z2 = z[:, 2 * self.units: 3 * self.units]\n            z3 = z[:, 3 * self.units:]\n\n            i = self.recurrent_activation(z0)\n            f = self.recurrent_activation(z1)\n            c = f * c_tm1 + i * self.activation(z2)\n            o = self.recurrent_activation(z3)\n\n        h = o * self.activation(c)\n        if 0 < self.dropout + self.recurrent_dropout:\n            if training is None:\n                h._uses_learning_phase = True\n        return h, [h, c]",
        "begin_line": 1936,
        "end_line": 2022,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.LSTMCell.get_config#2024",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTMCell",
        "signature": "keras.layers.recurrent.LSTMCell.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'units': self.units,\n                  'activation': activations.serialize(self.activation),\n                  'recurrent_activation':\n                      activations.serialize(self.recurrent_activation),\n                  'use_bias': self.use_bias,\n                  'kernel_initializer':\n                      initializers.serialize(self.kernel_initializer),\n                  'recurrent_initializer':\n                      initializers.serialize(self.recurrent_initializer),\n                  'bias_initializer': initializers.serialize(self.bias_initializer),\n                  'unit_forget_bias': self.unit_forget_bias,\n                  'kernel_regularizer':\n                      regularizers.serialize(self.kernel_regularizer),\n                  'recurrent_regularizer':\n                      regularizers.serialize(self.recurrent_regularizer),\n                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n                  'recurrent_constraint':\n                      constraints.serialize(self.recurrent_constraint),\n                  'bias_constraint': constraints.serialize(self.bias_constraint),\n                  'dropout': self.dropout,\n                  'recurrent_dropout': self.recurrent_dropout,\n                  'implementation': self.implementation}\n        base_config = super(LSTMCell, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 2024,
        "end_line": 2049,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.__init__#2144",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.__init__(self, units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False, **kwargs)",
        "snippet": "    def __init__(self, units,\n                 activation='tanh',\n                 recurrent_activation='hard_sigmoid',\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 recurrent_initializer='orthogonal',\n                 bias_initializer='zeros',\n                 unit_forget_bias=True,\n                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 recurrent_constraint=None,\n                 bias_constraint=None,\n                 dropout=0.,\n                 recurrent_dropout=0.,\n                 implementation=1,\n                 return_sequences=False,\n                 return_state=False,\n                 go_backwards=False,\n                 stateful=False,\n                 unroll=False,\n                 **kwargs):\n        if implementation == 0:\n            warnings.warn('`implementation=0` has been deprecated, '\n                          'and now defaults to `implementation=1`.'\n                          'Please update your layer call.')\n        if K.backend() == 'theano' and (dropout or recurrent_dropout):\n            warnings.warn(\n                'RNN dropout is no longer supported with the Theano backend '\n                'due to technical limitations. '\n                'You can either set `dropout` and `recurrent_dropout` to 0, '\n                'or use the TensorFlow backend.')\n            dropout = 0.\n            recurrent_dropout = 0.\n\n        cell = LSTMCell(units,\n                        activation=activation,\n                        recurrent_activation=recurrent_activation,\n                        use_bias=use_bias,\n                        kernel_initializer=kernel_initializer,\n                        recurrent_initializer=recurrent_initializer,\n                        unit_forget_bias=unit_forget_bias,\n                        bias_initializer=bias_initializer,\n                        kernel_regularizer=kernel_regularizer,\n                        recurrent_regularizer=recurrent_regularizer,\n                        bias_regularizer=bias_regularizer,\n                        kernel_constraint=kernel_constraint,\n                        recurrent_constraint=recurrent_constraint,\n                        bias_constraint=bias_constraint,\n                        dropout=dropout,\n                        recurrent_dropout=recurrent_dropout,\n                        implementation=implementation)\n        super(LSTM, self).__init__(cell,\n                                   return_sequences=return_sequences,\n                                   return_state=return_state,\n                                   go_backwards=go_backwards,\n                                   stateful=stateful,\n                                   unroll=unroll,\n                                   **kwargs)\n        self.activity_regularizer = regularizers.get(activity_regularizer)",
        "begin_line": 2144,
        "end_line": 2205,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.call#2207",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.call(self, inputs, mask=None, training=None, initial_state=None)",
        "snippet": "    def call(self, inputs, mask=None, training=None, initial_state=None):\n        self.cell._dropout_mask = None\n        self.cell._recurrent_dropout_mask = None\n        return super(LSTM, self).call(inputs,\n                                      mask=mask,\n                                      training=training,\n                                      initial_state=initial_state)",
        "begin_line": 2207,
        "end_line": 2213,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.units#2216",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.units(self)",
        "snippet": "    def units(self):\n        return self.cell.units",
        "begin_line": 2216,
        "end_line": 2217,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.activation#2220",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.activation(self)",
        "snippet": "    def activation(self):\n        return self.cell.activation",
        "begin_line": 2220,
        "end_line": 2221,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.recurrent_activation#2224",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.recurrent_activation(self)",
        "snippet": "    def recurrent_activation(self):\n        return self.cell.recurrent_activation",
        "begin_line": 2224,
        "end_line": 2225,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.use_bias#2228",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.use_bias(self)",
        "snippet": "    def use_bias(self):\n        return self.cell.use_bias",
        "begin_line": 2228,
        "end_line": 2229,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.kernel_initializer#2232",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.kernel_initializer(self)",
        "snippet": "    def kernel_initializer(self):\n        return self.cell.kernel_initializer",
        "begin_line": 2232,
        "end_line": 2233,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.recurrent_initializer#2236",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.recurrent_initializer(self)",
        "snippet": "    def recurrent_initializer(self):\n        return self.cell.recurrent_initializer",
        "begin_line": 2236,
        "end_line": 2237,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.bias_initializer#2240",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.bias_initializer(self)",
        "snippet": "    def bias_initializer(self):\n        return self.cell.bias_initializer",
        "begin_line": 2240,
        "end_line": 2241,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.unit_forget_bias#2244",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.unit_forget_bias(self)",
        "snippet": "    def unit_forget_bias(self):\n        return self.cell.unit_forget_bias",
        "begin_line": 2244,
        "end_line": 2245,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.kernel_regularizer#2248",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.kernel_regularizer(self)",
        "snippet": "    def kernel_regularizer(self):\n        return self.cell.kernel_regularizer",
        "begin_line": 2248,
        "end_line": 2249,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.recurrent_regularizer#2252",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.recurrent_regularizer(self)",
        "snippet": "    def recurrent_regularizer(self):\n        return self.cell.recurrent_regularizer",
        "begin_line": 2252,
        "end_line": 2253,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.bias_regularizer#2256",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.bias_regularizer(self)",
        "snippet": "    def bias_regularizer(self):\n        return self.cell.bias_regularizer",
        "begin_line": 2256,
        "end_line": 2257,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.kernel_constraint#2260",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.kernel_constraint(self)",
        "snippet": "    def kernel_constraint(self):\n        return self.cell.kernel_constraint",
        "begin_line": 2260,
        "end_line": 2261,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.recurrent_constraint#2264",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.recurrent_constraint(self)",
        "snippet": "    def recurrent_constraint(self):\n        return self.cell.recurrent_constraint",
        "begin_line": 2264,
        "end_line": 2265,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.bias_constraint#2268",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.bias_constraint(self)",
        "snippet": "    def bias_constraint(self):\n        return self.cell.bias_constraint",
        "begin_line": 2268,
        "end_line": 2269,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.dropout#2272",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.dropout(self)",
        "snippet": "    def dropout(self):\n        return self.cell.dropout",
        "begin_line": 2272,
        "end_line": 2273,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.recurrent_dropout#2276",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.recurrent_dropout(self)",
        "snippet": "    def recurrent_dropout(self):\n        return self.cell.recurrent_dropout",
        "begin_line": 2276,
        "end_line": 2277,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.implementation#2280",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.implementation(self)",
        "snippet": "    def implementation(self):\n        return self.cell.implementation",
        "begin_line": 2280,
        "end_line": 2281,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.get_config#2283",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'units': self.units,\n                  'activation': activations.serialize(self.activation),\n                  'recurrent_activation':\n                      activations.serialize(self.recurrent_activation),\n                  'use_bias': self.use_bias,\n                  'kernel_initializer':\n                      initializers.serialize(self.kernel_initializer),\n                  'recurrent_initializer':\n                      initializers.serialize(self.recurrent_initializer),\n                  'bias_initializer': initializers.serialize(self.bias_initializer),\n                  'unit_forget_bias': self.unit_forget_bias,\n                  'kernel_regularizer':\n                      regularizers.serialize(self.kernel_regularizer),\n                  'recurrent_regularizer':\n                      regularizers.serialize(self.recurrent_regularizer),\n                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n                  'activity_regularizer':\n                      regularizers.serialize(self.activity_regularizer),\n                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n                  'recurrent_constraint':\n                      constraints.serialize(self.recurrent_constraint),\n                  'bias_constraint': constraints.serialize(self.bias_constraint),\n                  'dropout': self.dropout,\n                  'recurrent_dropout': self.recurrent_dropout,\n                  'implementation': self.implementation}\n        base_config = super(LSTM, self).get_config()\n        del base_config['cell']\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 2283,
        "end_line": 2311,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.LSTM.from_config#2314",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent.LSTM",
        "signature": "keras.layers.recurrent.LSTM.from_config(cls, config)",
        "snippet": "    def from_config(cls, config):\n        if 'implementation' in config and config['implementation'] == 0:\n            config['implementation'] = 1\n        return cls(**config)",
        "begin_line": 2314,
        "end_line": 2317,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent._standardize_args#2335",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent",
        "signature": "keras.layers.recurrent._standardize_args(inputs, initial_state, constants, num_constants)",
        "snippet": "def _standardize_args(inputs, initial_state, constants, num_constants):\n    \"\"\"Standardize `__call__` to a single list of tensor inputs.\n\n    When running a model loaded from file, the input tensors\n    `initial_state` and `constants` can be passed to `RNN.__call__` as part\n    of `inputs` instead of by the dedicated keyword arguments. This method\n    makes sure the arguments are separated and that `initial_state` and\n    `constants` are lists of tensors (or None).\n\n    # Arguments\n        inputs: tensor or list/tuple of tensors\n        initial_state: tensor or list of tensors or None\n        constants: tensor or list of tensors or None\n\n    # Returns\n        inputs: tensor\n        initial_state: list of tensors or None\n        constants: list of tensors or None\n    \"\"\"\n    if isinstance(inputs, list):\n        assert initial_state is None and constants is None\n        if num_constants is not None:\n            constants = inputs[-num_constants:]\n            inputs = inputs[:-num_constants]\n        if len(inputs) > 1:\n            initial_state = inputs[1:]\n        inputs = inputs[0]\n\n    def to_list_or_none(x):\n        if x is None or isinstance(x, list):\n            return x\n        if isinstance(x, tuple):\n            return list(x)\n        return [x]\n\n    initial_state = to_list_or_none(initial_state)\n    constants = to_list_or_none(constants)\n\n    return inputs, initial_state, constants",
        "begin_line": 2335,
        "end_line": 2373,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.recurrent.to_list_or_none#2363",
        "src_path": "keras/layers/recurrent.py",
        "class_name": "keras.layers.recurrent",
        "signature": "keras.layers.recurrent.to_list_or_none(x)",
        "snippet": "    def to_list_or_none(x):\n        if x is None or isinstance(x, list):\n            return x\n        if isinstance(x, tuple):\n            return list(x)\n        return [x]",
        "begin_line": 2363,
        "end_line": 2368,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network.Network.__init__#87",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network.Network",
        "signature": "keras.engine.network.Network.__init__(self, *args, **kwargs)",
        "snippet": "    def __init__(self, *args, **kwargs):\n        # Signature detection\n        if (len(args) == 2 or\n            len(args) == 1 and 'outputs' in kwargs or\n                'inputs' in kwargs and 'outputs' in kwargs):\n            # Graph network\n            self._init_graph_network(*args, **kwargs)\n        else:\n            # Subclassed network\n            self._init_subclassed_network(**kwargs)",
        "begin_line": 87,
        "end_line": 96,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00040225261464199515,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network.Network._base_init#98",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network.Network",
        "signature": "keras.engine.network.Network._base_init(self, name=None)",
        "snippet": "    def _base_init(self, name=None):\n        # The following are implemented as property functions:\n        # self.trainable_weights\n        # self.non_trainable_weights\n        # self.input_spec\n        # self.losses\n        # self.updates\n\n        # Handle `name` argument.\n        if not name:\n            prefix = self.__class__.__name__.lower()\n            name = prefix + '_' + str(K.get_uid(prefix))\n        self.name = name\n\n        # This acts just like the `trainable` attribute of any layer instance.\n        # It does not affect users of the underlying layers, only users of the\n        # Network instance.\n        self.trainable = True\n        self._is_compiled = False\n        self._expects_training_arg = False\n        self._initial_weights = None\n\n        self.supports_masking = False\n        if not hasattr(self, 'optimizer'):\n            # Don't reset optimizer if already set.\n            self.optimizer = None\n\n        # Private attributes to implement compatibility with Layer.\n        self._updates = []\n        self._losses = []\n        self._per_input_losses = {}\n        self._per_input_updates = {}\n\n        # All layers in order of horizontal graph traversal.\n        # Entries are unique. Includes input and output layers.\n        self._layers = []\n\n        # Used only in conjunction with graph-networks\n        self._outbound_nodes = []\n        self._inbound_nodes = []",
        "begin_line": 98,
        "end_line": 137,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002613012803762738,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network.Network._init_graph_network#139",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network.Network",
        "signature": "keras.engine.network.Network._init_graph_network(self, inputs, outputs, name=None)",
        "snippet": "    def _init_graph_network(self, inputs, outputs, name=None):\n        self._uses_inputs_arg = True\n        # Normalize and set self.inputs, self.outputs.\n        self.inputs = to_list(inputs, allow_tuple=True)\n        self.outputs = to_list(outputs, allow_tuple=True)\n\n        # User-provided argument validation.\n        # Check for redundancy in inputs.\n        if len(set(self.inputs)) != len(self.inputs):\n            raise ValueError('The list of inputs passed to the model '\n                             'is redundant. '\n                             'All inputs should only appear once.'\n                             ' Found: ' + str(self.inputs))\n        for x in self.inputs:\n            # Check that x has appropriate `_keras_history` metadata.\n            if not hasattr(x, '_keras_history'):\n                cls_name = self.__class__.__name__\n                raise ValueError('Input tensors to a ' + cls_name + ' ' +\n                                 'must come from `keras.layers.Input`. '\n                                 'Received: ' + str(x) +\n                                 ' (missing previous layer metadata).')\n            # Check that x is an input tensor.\n            layer, node_index, tensor_index = x._keras_history\n            if (len(layer._inbound_nodes) > 1 or\n                    (layer._inbound_nodes and\n                     layer._inbound_nodes[0].inbound_layers)):\n                cls_name = self.__class__.__name__\n                warnings.warn(cls_name + ' inputs must come from '\n                              '`keras.layers.Input` '\n                              '(thus holding past layer metadata), '\n                              'they cannot be the output of '\n                              'a previous non-Input layer. '\n                              'Here, a tensor specified as '\n                              'input to your model '\n                              'was not an Input tensor, '\n                              'it was generated by layer ' +\n                              layer.name + '.\\n'\n                              'Note that input tensors are '\n                              'instantiated via '\n                              '`tensor = keras.layers.Input(shape)`.\\n'\n                              'The tensor that caused the issue was: ' +\n                              str(x.name))\n        for x in self.outputs:\n            if not hasattr(x, '_keras_history'):\n                cls_name = self.__class__.__name__\n                raise ValueError('Output tensors to a ' + cls_name +\n                                 ' must be '\n                                 'the output of a Keras `Layer` '\n                                 '(thus holding past layer metadata). '\n                                 'Found: ' + str(x))\n        self._base_init(name=name)\n        self._compute_previous_mask = (\n            has_arg(self.call, 'mask') or\n            hasattr(self, 'compute_mask'))\n        # A Network does not create weights of its own,\n        # thus it is already built.\n        self.built = True\n        self._is_graph_network = True\n\n        self._input_layers = []\n        self._output_layers = []\n        self._input_coordinates = []\n        self._output_coordinates = []\n\n        # This is for performance optimization when calling the Network on new\n        # inputs. Every time the Network is called on a set on input tensors,\n        # we compute the output tensors,\n        # output masks and output shapes in one pass,\n        # then cache them here. When any of these outputs is queried later, we\n        # retrieve it from there instead of recomputing it.\n        self._output_mask_cache = {}\n        self._output_tensor_cache = {}\n        self._output_shape_cache = {}\n\n        # Build self._output_layers:\n        for x in self.outputs:\n            layer, node_index, tensor_index = x._keras_history\n            self._output_layers.append(layer)\n            self._output_coordinates.append((layer, node_index, tensor_index))\n\n        # Build self._input_layers:\n        for x in self.inputs:\n            layer, node_index, tensor_index = x._keras_history\n            # It's supposed to be an input layer, so only one node\n            # and one tensor output.\n            assert node_index == 0\n            assert tensor_index == 0\n            self._input_layers.append(layer)\n            self._input_coordinates.append((layer, node_index, tensor_index))\n\n        # Keep track of the network's nodes and layers.\n        nodes, nodes_by_depth, layers, layers_by_depth = _map_graph_network(\n            self.inputs, self.outputs)\n        self._network_nodes = nodes\n        self._nodes_by_depth = nodes_by_depth\n        self._layers = layers\n        self._layers_by_depth = layers_by_depth\n\n        # Create the node linking internal inputs to internal outputs.\n        Node(outbound_layer=self,\n             inbound_layers=[],\n             node_indices=[],\n             tensor_indices=[],\n             input_tensors=self.inputs,\n             output_tensors=self.outputs,\n             # No network-level masking for now.\n             input_masks=[None for _ in self.inputs],\n             output_masks=[None for _ in self.outputs],\n             input_shapes=[x._keras_shape for x in self.inputs],\n             output_shapes=[x._keras_shape for x in self.outputs])\n\n        # Fill in the output mask cache.\n        masks = []\n        for x in self.inputs:\n            layer, node_index, tensor_index = x._keras_history\n            node = layer._inbound_nodes[node_index]\n            mask = node.output_masks[tensor_index]\n            masks.append(mask)\n        mask_cache_key = object_list_uid(inputs)\n        mask_cache_key += '_' + object_list_uid(masks)\n        masks = []\n        for x in self.outputs:\n            layer, node_index, tensor_index = x._keras_history\n            node = layer._inbound_nodes[node_index]\n            mask = node.output_masks[tensor_index]\n            masks.append(mask)\n        mask = unpack_singleton(masks)\n        self._output_mask_cache[mask_cache_key] = mask\n\n        # Build self.input_names and self.output_names.\n        self.input_names = []\n        self.output_names = []\n        self._feed_input_names = []\n        self._feed_inputs = []\n        self._feed_input_shapes = []\n        for i, layer in enumerate(self._input_layers):\n            # Check that layer is an InputLayer.\n            if not isinstance(layer, InputLayer):\n                raise TypeError(\n                    'Input layers to a `Model` must be `InputLayer` objects. '\n                    'Received inputs: {}. '\n                    'Input {} (0-based) originates '\n                    'from layer type `{}`.'.format(inputs,\n                                                   i,\n                                                   layer.__class__.__name__))\n            self.input_names.append(layer.name)\n            if layer.is_placeholder:\n                self._feed_inputs.append(layer.input)\n                self._feed_input_names.append(layer.name)\n                self._feed_input_shapes.append(self.inputs[i]._keras_shape)\n\n        for layer in self._output_layers:\n            self.output_names.append(layer.name)",
        "begin_line": 139,
        "end_line": 291,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002613012803762738,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network.Network._init_subclassed_network#293",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network.Network",
        "signature": "keras.engine.network.Network._init_subclassed_network(self, name=None)",
        "snippet": "    def _init_subclassed_network(self, name=None):\n        self._base_init(name=name)\n        self._is_graph_network = False\n        self._expects_training_arg = has_arg(self.call, 'training')\n        self._uses_inputs_arg = has_arg(self.call, 'inputs')\n        self.outputs = None\n        self.inputs = None\n        self.built = False",
        "begin_line": 293,
        "end_line": 300,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00032948929159802305,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network.Network.__setattr__#302",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network.Network",
        "signature": "keras.engine.network.Network.__setattr__(self, name, value)",
        "snippet": "    def __setattr__(self, name, value):\n        # Automatically track layers set as Model\n        # attributes for subclassed Models.\n        if isinstance(value, (Layer, Network)):\n            try:\n                is_graph_network = self._is_graph_network\n            except AttributeError:\n                raise RuntimeError(\n                    'It looks like you are subclassing `Model` and you '\n                    'forgot to call `super(YourClass, self).__init__()`.'\n                    ' Always start with this line.')\n            if not is_graph_network:\n                if value not in self._layers:\n                    self._layers.append(value)\n        super(Network, self).__setattr__(name, value)",
        "begin_line": 302,
        "end_line": 316,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002613012803762738,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network.Network.layers#319",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network.Network",
        "signature": "keras.engine.network.Network.layers(self)",
        "snippet": "    def layers(self):\n        return self._layers",
        "begin_line": 319,
        "end_line": 320,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0004144218814753419,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network.Network.updates#361",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network.Network",
        "signature": "keras.engine.network.Network.updates(self)",
        "snippet": "    def updates(self):\n        \"\"\"Retrieves the model's updates.\n\n        Will only include updates that are either\n        unconditional, or conditional on inputs to this model\n        (e.g. will not include updates that depend on tensors\n        that aren't inputs to this model).\n\n        # Returns\n            A list of update ops.\n        \"\"\"\n        if not self.trainable and not self.stateful:\n            return []\n        updates = []\n        for layer in self.layers:\n            if hasattr(layer, 'updates'):\n                if self._is_graph_network:\n                    # Collect updates that are dependent on inputs\n                    # that are part of the model.\n                    for node_index, node in enumerate(layer._inbound_nodes):\n                        node_key = self._node_key(layer, node_index)\n                        if node_key in self._network_nodes:\n                            # The model owns this layer node.\n                            inputs = node.input_tensors\n                            updates += layer.get_updates_for(inputs)\n                    # Collect unconditional updates.\n                    updates += layer.get_updates_for(None)\n                else:\n                    updates += layer.updates\n        return updates",
        "begin_line": 361,
        "end_line": 390,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00034164673727365904,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network.Network.losses#393",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network.Network",
        "signature": "keras.engine.network.Network.losses(self)",
        "snippet": "    def losses(self):\n        \"\"\"Retrieves the model's losses.\n\n        Will only include losses that are either\n        unconditional, or conditional on inputs to this model\n        (e.g. will not include losses that depend on tensors\n        that aren't inputs to this model).\n\n        # Returns\n            A list of loss tensors.\n        \"\"\"\n        losses = []\n        for layer in self.layers:\n            if hasattr(layer, 'losses'):\n                if self._is_graph_network:\n                    # Collect losses that are dependent on inputs\n                    # that are part of the model.\n                    for node_index, node in enumerate(layer._inbound_nodes):\n                        node_key = self._node_key(layer, node_index)\n                        if node_key in self._network_nodes:\n                            # The model owns this layer node.\n                            inputs = node.input_tensors\n                            losses += layer.get_losses_for(inputs)\n                    # Collect unconditional losses.\n                    losses += layer.get_losses_for(None)\n                else:\n                    losses += layer.losses\n\n        # Add any potential unconditional model-level loss.\n        losses += self.get_losses_for(None)\n\n        unique_tensors = list(\n            set(x for x in losses if not isinstance(x, (float, int))))\n        non_tensors = [x for x in losses if isinstance(x, (float, int))]\n        return unique_tensors + non_tensors",
        "begin_line": 393,
        "end_line": 427,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00030731407498463427,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network.Network.uses_learning_phase#430",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network.Network",
        "signature": "keras.engine.network.Network.uses_learning_phase(self)",
        "snippet": "    def uses_learning_phase(self):\n        if not self.outputs:\n            return False\n        return any([x._uses_learning_phase for x in self.outputs])",
        "begin_line": 430,
        "end_line": 433,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00031655587211142766,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network.Network.stateful#436",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network.Network",
        "signature": "keras.engine.network.Network.stateful(self)",
        "snippet": "    def stateful(self):\n        return any([(hasattr(layer, 'stateful') and\n                    layer.stateful) for layer in self.layers])",
        "begin_line": 436,
        "end_line": 438,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00034164673727365904,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network.Network.state_updates#446",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network.Network",
        "signature": "keras.engine.network.Network.state_updates(self)",
        "snippet": "    def state_updates(self):\n        \"\"\"Returns the `updates` from all layers that are stateful.\n\n        This is useful for separating training updates and\n        state updates, e.g. when we need to update a layer's internal state\n        during prediction.\n\n        # Returns\n            A list of update ops.\n        \"\"\"\n        state_updates = []\n        for layer in self.layers:\n            if layer.stateful:\n                state_updates += layer.updates\n        return state_updates",
        "begin_line": 446,
        "end_line": 460,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00038387715930902113,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network.Network.trainable_weights#463",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network.Network",
        "signature": "keras.engine.network.Network.trainable_weights(self)",
        "snippet": "    def trainable_weights(self):\n        if not self.trainable:\n            return []\n        weights = []\n        for layer in self.layers:\n            weights += layer.trainable_weights\n        return weights",
        "begin_line": 463,
        "end_line": 469,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network.Network.non_trainable_weights#472",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network.Network",
        "signature": "keras.engine.network.Network.non_trainable_weights(self)",
        "snippet": "    def non_trainable_weights(self):\n        weights = []\n        for layer in self.layers:\n            weights += layer.non_trainable_weights\n        if not self.trainable:\n            trainable_weights = []\n            for layer in self.layers:\n                trainable_weights += layer.trainable_weights\n            return trainable_weights + weights\n        return weights",
        "begin_line": 472,
        "end_line": 481,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network.Network.get_weights#483",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network.Network",
        "signature": "keras.engine.network.Network.get_weights(self)",
        "snippet": "    def get_weights(self):\n        \"\"\"Retrieves the weights of the model.\n\n        # Returns\n            A flat list of Numpy arrays.\n        \"\"\"\n        weights = []\n        for layer in self.layers:\n            weights += layer.weights\n        return K.batch_get_value(weights)",
        "begin_line": 483,
        "end_line": 492,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network.Network.set_weights#494",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network.Network",
        "signature": "keras.engine.network.Network.set_weights(self, weights)",
        "snippet": "    def set_weights(self, weights):\n        \"\"\"Sets the weights of the model.\n\n        # Arguments\n            weights: A list of Numpy arrays with shapes and types matching\n                the output of `model.get_weights()`.\n        \"\"\"\n        tuples = []\n        for layer in self.layers:\n            num_param = len(layer.weights)\n            layer_weights = weights[:num_param]\n            for sw, w in zip(layer.weights, layer_weights):\n                tuples.append((sw, w))\n            weights = weights[num_param:]\n        K.batch_set_value(tuples)",
        "begin_line": 494,
        "end_line": 508,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network.Network.input_spec#511",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network.Network",
        "signature": "keras.engine.network.Network.input_spec(self)",
        "snippet": "    def input_spec(self):\n        \"\"\"Gets the model's input specs.\n\n        # Returns\n            A list of `InputSpec` instances (one per input to the model)\n                or a single instance if the model has only one input.\n        \"\"\"\n        if not self._is_graph_network:\n            # TODO: support it in subclassed networks after inputs are set.\n            return None\n\n        specs = []\n        for layer in getattr(self, '_input_layers', []):\n            if layer.input_spec is None:\n                specs.append(None)\n            else:\n                if not isinstance(layer.input_spec, list):\n                    raise TypeError('Layer ' + layer.name +\n                                    ' has an input_spec attribute that '\n                                    'is not a list. We expect a list. '\n                                    'Found input_spec = ' +\n                                    str(layer.input_spec))\n                specs += layer.input_spec\n        return unpack_singleton(specs)",
        "begin_line": 511,
        "end_line": 534,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network.Network.call#536",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network.Network",
        "signature": "keras.engine.network.Network.call(self, inputs, mask=None)",
        "snippet": "    def call(self, inputs, mask=None):\n        \"\"\"Calls the model on new inputs.\n\n        In this case `call` just reapplies\n        all ops in the graph to the new inputs\n        (e.g. build a new computational graph from the provided inputs).\n\n        A model is callable on non-Keras tensors.\n\n        # Arguments\n            inputs: A tensor or list of tensors.\n            mask: A mask or list of masks. A mask can be\n                either a tensor or None (no mask).\n\n        # Returns\n            A tensor if there is a single output, or\n            a list of tensors if there are more than one outputs.\n        \"\"\"\n        inputs = to_list(inputs)\n        if mask is None:\n            masks = [None for _ in range(len(inputs))]\n        else:\n            masks = to_list(mask)\n        cache_key = object_list_uid(inputs)\n        cache_key += '_' + object_list_uid(masks)\n        if cache_key in self._output_tensor_cache:\n            return self._output_tensor_cache[cache_key]\n        else:\n            output_tensors, _, _ = self.run_internal_graph(inputs, masks)\n            return output_tensors",
        "begin_line": 536,
        "end_line": 565,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network.Network.compute_mask#567",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network.Network",
        "signature": "keras.engine.network.Network.compute_mask(self, inputs, mask)",
        "snippet": "    def compute_mask(self, inputs, mask):\n        if not self._is_graph_network:\n            return None\n\n        inputs = to_list(inputs)\n        if mask is None:\n            masks = [None for _ in range(len(inputs))]\n        else:\n            masks = to_list(mask)\n        cache_key = object_list_uid(inputs)\n        cache_key += '_' + object_list_uid(masks)\n        if cache_key in self._output_mask_cache:\n            return self._output_mask_cache[cache_key]\n        else:\n            _, output_masks, _ = self.run_internal_graph(inputs, masks)\n            return output_masks",
        "begin_line": 567,
        "end_line": 582,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00029859659599880563,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network.Network.compute_output_shape#584",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network.Network",
        "signature": "keras.engine.network.Network.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if not self._is_graph_network:\n            # Must be implemented by subclasses.\n            raise NotImplementedError\n\n        input_shapes = to_list(input_shape)\n        if len(input_shapes) != len(self._input_layers):\n            raise ValueError('Invalid input_shape argument ' +\n                             str(input_shape) + ': model has ' +\n                             str(len(self._input_layers)) + ' tensor inputs.')\n\n        cache_key = ', '.join([str(x) for x in input_shapes])\n        if cache_key in self._output_shape_cache:\n            output_shapes = self._output_shape_cache[cache_key]\n            if isinstance(output_shapes, list):\n                return unpack_singleton(output_shapes)\n            return output_shapes\n        else:\n            # Bad luck, we have to run the graph manually.\n            layers_to_output_shapes = {}\n            for i in range(len(input_shapes)):\n                layer = self._input_layers[i]\n                input_shape = input_shapes[i]\n                # It's an input layer: compute_output_shape is identity,\n                # and there is only one node and one tensor output.\n                shape_key = layer.name + '_0_0'\n                layers_to_output_shapes[shape_key] = input_shape\n\n            depth_keys = list(self._nodes_by_depth.keys())\n            depth_keys.sort(reverse=True)\n            # Iterate over nodes, by depth level.\n            if len(depth_keys) > 1:\n                for depth in depth_keys:\n                    nodes = self._nodes_by_depth[depth]\n                    for node in nodes:\n                        # This is always a single layer, never a list.\n                        layer = node.outbound_layer\n                        if layer in self._input_layers:\n                            # We've already covered the input layers\n                            # a few lines above.\n                            continue\n                        # Potentially redundant list,\n                        # same size of node.input_tensors.\n                        input_shapes = []\n                        for j in range(len(node.inbound_layers)):\n                            inbound_layer = node.inbound_layers[j]\n                            node_index = node.node_indices[j]\n                            tensor_index = node.tensor_indices[j]\n                            shape_key = inbound_layer.name\n                            shape_key += '_%s_%s' % (node_index, tensor_index)\n                            input_shape = layers_to_output_shapes[shape_key]\n                            input_shapes.append(input_shape)\n\n                        output_shape = layer.compute_output_shape(\n                            unpack_singleton(input_shapes))\n\n                        output_shapes = to_list(output_shape)\n                        node_index = layer._inbound_nodes.index(node)\n                        for j in range(len(output_shapes)):\n                            shape_key = layer.name + '_%s_%s' % (node_index, j)\n                            layers_to_output_shapes[shape_key] = output_shapes[j]\n\n            # Read final output shapes from layers_to_output_shapes.\n            output_shapes = []\n            output_shape_keys = []\n            for i in range(len(self._output_layers)):\n                layer = self._output_layers[i]\n                node_index = self._output_coordinates[i][1]\n                tensor_index = self._output_coordinates[i][2]\n                shape_key = layer.name + '_%s_%s' % (node_index, tensor_index)\n                output_shape_keys.append(shape_key)\n\n            for i, key in enumerate(output_shape_keys):\n                assert key in layers_to_output_shapes\n                output_shapes.append(layers_to_output_shapes[key])\n            # Store in cache.\n            self._output_shape_cache[cache_key] = output_shapes\n            if isinstance(output_shapes, list):\n                return unpack_singleton(output_shapes)\n            return output_shapes",
        "begin_line": 584,
        "end_line": 663,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network.Network.run_internal_graph#665",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network.Network",
        "signature": "keras.engine.network.Network.run_internal_graph(self, inputs, masks=None)",
        "snippet": "    def run_internal_graph(self, inputs, masks=None):\n        \"\"\"Computes output tensors for new inputs.\n\n        # Note:\n            - Expects `inputs` to be a list (potentially with 1 element).\n            - Can be run on non-Keras tensors.\n\n        # Arguments\n            inputs: List of tensors\n            masks: List of masks (tensors or None).\n\n        # Returns\n            Three lists: output_tensors, output_masks, output_shapes\n        \"\"\"\n        if masks is None:\n            masks = [None for _ in range(len(inputs))]\n\n        # Dictionary mapping reference tensors to tuples\n        # (computed tensor, compute mask)\n        # we assume a 1:1 mapping from tensor to mask\n        # TODO: raise exception when a `.compute_mask()` call\n        # does not return a list the same size as `call`\n        tensor_map = {}\n        for x, y, mask in zip(self.inputs, inputs, masks):\n            tensor_map[str(id(x))] = (y, mask)\n\n        depth_keys = list(self._nodes_by_depth.keys())\n        depth_keys.sort(reverse=True)\n        for depth in depth_keys:\n            nodes = self._nodes_by_depth[depth]\n            for node in nodes:\n                # This is always a single layer, never a list.\n                layer = node.outbound_layer\n                reference_input_tensors = node.input_tensors\n                reference_output_tensors = node.output_tensors\n\n                # If all previous input tensors are available in tensor_map,\n                # then call node.inbound_layer on them.\n                computed_data = []  # List of tuples (input, mask).\n                for x in reference_input_tensors:\n                    if str(id(x)) in tensor_map:\n                        computed_data.append(tensor_map[str(id(x))])\n\n                if len(computed_data) == len(reference_input_tensors):\n                    # call layer\n                    with K.name_scope(layer.name):\n                        if node.arguments:\n                            kwargs = node.arguments\n                        else:\n                            kwargs = {}\n                        if len(computed_data) == 1:\n                            computed_tensor, computed_mask = computed_data[0]\n                            if has_arg(layer.call, 'mask'):\n                                if 'mask' not in kwargs:\n                                    kwargs['mask'] = computed_mask\n                            output_tensors = to_list(\n                                layer.call(computed_tensor, **kwargs))\n                            output_masks = layer.compute_mask(computed_tensor,\n                                                              computed_mask)\n                            if output_masks is None:\n                                output_masks = [None for _ in output_tensors]\n                            else:\n                                output_masks = to_list(output_masks)\n                            computed_tensors = [computed_tensor]\n\n                            # computed_masks might be used in the future.\n                            computed_masks = [computed_mask]\n                        else:\n                            computed_tensors = [x[0] for x in computed_data]\n                            computed_masks = [x[1] for x in computed_data]\n                            if has_arg(layer.call, 'mask'):\n                                if 'mask' not in kwargs:\n                                    kwargs['mask'] = computed_masks\n                            output_tensors = to_list(\n                                layer.call(computed_tensors, **kwargs))\n                            output_masks = layer.compute_mask(computed_tensors,\n                                                              computed_masks)\n                            if output_masks is None:\n                                output_masks = [None for _ in output_tensors]\n                            else:\n                                output_masks = to_list(output_masks)\n                        # Apply activity regularizer if any:\n                        if (hasattr(layer, 'activity_regularizer') and\n                                layer.activity_regularizer is not None):\n                            with K.name_scope('activity_regularizer'):\n                                regularization_losses = [\n                                    layer.activity_regularizer(x)\n                                    for x in output_tensors]\n                            layer.add_loss(regularization_losses,\n                                           inputs=computed_tensors)\n\n                        if len(output_masks) != len(output_tensors):\n                            raise Exception(\n                                'Layers should have equal number of output tensors '\n                                'and output masks. Layer ' + str(layer.name) + ' has'\n                                ' ' + str(len(output_tensors)) + ' output tensors '\n                                'and ' + str(len(output_masks)) + ' output masks.')\n                    # Update model updates and losses:\n                    # Keep track of updates that depend on the inputs\n                    # (e.g. BN updates).\n                    self.add_update(layer.get_updates_for(computed_tensors), inputs)\n                    # Keep track of unconditional updates (e.g. a counter).\n                    self.add_update(layer.get_updates_for(None), None)\n                    # Keep track of losses that depend on the inputs\n                    # (e.g. activity regularizers).\n                    self.add_loss(layer.get_losses_for(computed_tensors), inputs)\n                    # Keep track of unconditional losses\n                    # (e.g. weight regularizers).\n                    self.add_loss(layer.get_losses_for(None), None)\n\n                    # Update _keras_shape.\n                    if all([hasattr(x, '_keras_shape') for x in computed_tensors]):\n                        input_shapes = unpack_singleton(\n                            [x._keras_shape for x in computed_tensors])\n                        shapes = to_list(layer.compute_output_shape(input_shapes))\n                        uses_learning_phase = any(\n                            [x._uses_learning_phase for x in computed_tensors])\n\n                        for x, s in zip(output_tensors, shapes):\n                            x._keras_shape = s\n                            _u = getattr(x, '_uses_learning_phase', False)\n                            x._uses_learning_phase = _u or uses_learning_phase\n\n                    # Update tensor_map.\n                    for x, y, mask in zip(reference_output_tensors,\n                                          output_tensors,\n                                          output_masks):\n                        tensor_map[str(id(x))] = (y, mask)\n\n        output_tensors = []\n        output_masks = []\n        output_shapes = []\n        for x in self.outputs:\n            assert str(id(x)) in tensor_map, 'Could not compute output ' + str(x)\n            tensor, mask = tensor_map[str(id(x))]\n            if hasattr(tensor, '_keras_shape') and output_shapes is not None:\n                shape = tensor._keras_shape\n                output_shapes.append(shape)\n            else:\n                output_shapes = None\n            output_tensors.append(tensor)\n            output_masks.append(mask)\n\n        # Update cache;\n        # keys are based on ids on input tensors and inputs masks.\n        cache_key = object_list_uid(inputs)\n        cache_key += '_' + object_list_uid(masks)\n\n        output_tensors = unpack_singleton(output_tensors)\n        self._output_tensor_cache[cache_key] = output_tensors\n\n        output_masks = unpack_singleton(output_masks)\n        self._output_mask_cache[cache_key] = output_masks\n\n        if output_shapes is not None:\n            input_shapes = [x._keras_shape for x in inputs]\n            cache_key = ', '.join([str(x) for x in input_shapes])\n\n            output_shapes = unpack_singleton(output_shapes)\n            self._output_shape_cache[cache_key] = output_shapes\n        return output_tensors, output_masks, output_shapes",
        "begin_line": 665,
        "end_line": 825,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network.Network.get_config#827",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network.Network",
        "signature": "keras.engine.network.Network.get_config(self)",
        "snippet": "    def get_config(self):\n        if not self._is_graph_network:\n            # Subclassed networks are not serializable\n            # (unless serialization is implemented by\n            # the author of the subclassed network).\n            raise NotImplementedError\n\n        config = {\n            'name': self.name,\n        }\n\n        # Build a map from a layer unique name (self._node_key)\n        # to the index of the nodes that are saved in the config.\n        # Only nodes in network_nodes are saved.\n        node_conversion_map = {}\n        for layer in self.layers:\n            if issubclass(layer.__class__, Network):\n                # Networks start with a pre-existing node\n                # linking their input to output.\n                kept_nodes = 1\n            else:\n                kept_nodes = 0\n            for original_node_index, node in enumerate(layer._inbound_nodes):\n                node_key = self._node_key(layer, original_node_index)\n                if node_key in self._network_nodes:\n                    # i.e. we mark it to be saved\n                    node_conversion_map[node_key] = kept_nodes\n                    kept_nodes += 1\n\n        # serialize and save the layers in layer_configs\n        layer_configs = []\n        for layer in self.layers:  # From the earliest layers on.\n            layer_class_name = layer.__class__.__name__\n            layer_config = layer.get_config()\n            filtered_inbound_nodes = []\n            for original_node_index, node in enumerate(layer._inbound_nodes):\n                node_key = self._node_key(layer, original_node_index)\n                if node_key in self._network_nodes:\n                    # The node is relevant to the model:\n                    # add to filtered_inbound_nodes.\n                    if node.arguments:\n                        try:\n                            json.dumps(node.arguments)\n                            kwargs = node.arguments\n                        except TypeError:\n                            warnings.warn(\n                                'Layer ' + layer.name +\n                                ' was passed non-serializable '\n                                'keyword arguments: ' +\n                                str(node.arguments) +\n                                '. They will not be included '\n                                'in the serialized model '\n                                '(and thus will be missing '\n                                'at deserialization time).')\n                            kwargs = {}\n                    else:\n                        kwargs = {}\n                    if node.inbound_layers:\n                        node_data = []\n                        for i in range(len(node.inbound_layers)):\n                            inbound_layer = node.inbound_layers[i]\n                            node_index = node.node_indices[i]\n                            tensor_index = node.tensor_indices[i]\n\n                            new_node_index = node_conversion_map.get(\n                                self._node_key(inbound_layer, node_index), 0)\n                            node_data.append([inbound_layer.name,\n                                              new_node_index,\n                                              tensor_index,\n                                              kwargs])\n                        filtered_inbound_nodes.append(node_data)\n            layer_configs.append({\n                'name': layer.name,\n                'class_name': layer_class_name,\n                'config': layer_config,\n                'inbound_nodes': filtered_inbound_nodes,\n            })\n        config['layers'] = layer_configs\n\n        # Gather info about inputs and outputs.\n        model_inputs = []\n        for i in range(len(self._input_layers)):\n            layer = self._input_layers[i]\n            node_index = self._input_coordinates[i][1]\n\n            node_key = self._node_key(layer, node_index)\n            if node_key not in self._network_nodes:\n                continue\n            new_node_index = node_conversion_map[node_key]\n            tensor_index = self._input_coordinates[i][2]\n            model_inputs.append([layer.name, new_node_index, tensor_index])\n        config['input_layers'] = model_inputs\n        model_outputs = []\n        for i in range(len(self._output_layers)):\n            layer = self._output_layers[i]\n            node_index = self._output_coordinates[i][1]\n\n            node_key = self._node_key(layer, node_index)\n            if node_key not in self._network_nodes:\n                continue\n            new_node_index = node_conversion_map[node_key]\n            tensor_index = self._output_coordinates[i][2]\n            model_outputs.append([layer.name, new_node_index, tensor_index])\n        config['output_layers'] = model_outputs\n        return copy.deepcopy(config)",
        "begin_line": 827,
        "end_line": 931,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network.Network.from_config#934",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network.Network",
        "signature": "keras.engine.network.Network.from_config(cls, config, custom_objects=None)",
        "snippet": "    def from_config(cls, config, custom_objects=None):\n        \"\"\"Instantiates a Model from its config (output of `get_config()`).\n\n        # Arguments\n            config: Model config dictionary.\n            custom_objects: Optional dictionary mapping names\n                (strings) to custom classes or functions to be\n                considered during deserialization.\n\n        # Returns\n            A model instance.\n\n        # Raises\n            ValueError: In case of improperly formatted config dict.\n        \"\"\"\n        # Layer instances created during\n        # the graph reconstruction process\n        created_layers = {}\n\n        # Dictionary mapping layer instances to\n        # node data that specifies a layer call.\n        # It acts as a queue that maintains any unprocessed\n        # layer call until it becomes possible to process it\n        # (i.e. until the input tensors to the call all exist).\n        unprocessed_nodes = {}\n\n        def add_unprocessed_node(layer, node_data):\n            \"\"\"Add node to layer list\n\n            Args:\n                layer: layer object\n                node_data: Node data specifying layer call\n            \"\"\"\n            if layer not in unprocessed_nodes:\n                unprocessed_nodes[layer] = [node_data]\n            else:\n                unprocessed_nodes[layer].append(node_data)\n\n        def process_node(layer, node_data):\n            \"\"\"Reconstruct node by linking to inbound layers\n\n            Args:\n                layer: Layer to process\n                node_data: List of layer configs\n\n            Raises:\n                ValueError: For incorrect layer config\n                LookupError: If layer required is not found\n            \"\"\"\n            input_tensors = []\n            for input_data in node_data:\n                inbound_layer_name = input_data[0]\n                inbound_node_index = input_data[1]\n                inbound_tensor_index = input_data[2]\n                if len(input_data) == 3:\n                    kwargs = {}\n                elif len(input_data) == 4:\n                    kwargs = input_data[3]\n                else:\n                    raise ValueError('Improperly formatted model config.')\n                inbound_layer = created_layers[inbound_layer_name]\n                # Raise an error if the corresponding layer node\n                # has not yet been created\n                if len(inbound_layer._inbound_nodes) <= inbound_node_index:\n                    raise LookupError\n                inbound_node = inbound_layer._inbound_nodes[inbound_node_index]\n                input_tensors.append(\n                    inbound_node.output_tensors[inbound_tensor_index])\n\n            # Call layer on its inputs, thus creating the node\n            # and building the layer if needed.\n            if input_tensors:\n                layer(unpack_singleton(input_tensors), **kwargs)\n\n        def process_layer(layer_data):\n            \"\"\"Deserializes a layer, then call it on appropriate inputs.\n\n            # Arguments\n                layer_data: layer config dict.\n\n            # Raises\n                ValueError: In case of improperly formatted `layer_data` dict.\n            \"\"\"\n            layer_name = layer_data['name']\n\n            # Instantiate layer.\n            from ..layers import deserialize as deserialize_layer\n\n            layer = deserialize_layer(layer_data,\n                                      custom_objects=custom_objects)\n            created_layers[layer_name] = layer\n\n            # Gather layer inputs.\n            inbound_nodes_data = layer_data['inbound_nodes']\n            for node_data in inbound_nodes_data:\n                # We don't process nodes (i.e. make layer calls)\n                # on the fly because the inbound node may not yet exist,\n                # in case of layer shared at different topological depths\n                # (e.g. a model such as A(B(A(B(x)))))\n                add_unprocessed_node(layer, node_data)\n\n        # First, we create all layers and enqueue nodes to be processed\n        for layer_data in config['layers']:\n            process_layer(layer_data)\n\n        # Then we process nodes in order of layer depth.\n        # Nodes that cannot yet be processed (if the inbound node\n        # does not yet exist) are re-enqueued, and the process\n        # is repeated until all nodes are processed.\n        while unprocessed_nodes:\n            for layer_data in config['layers']:\n                layer = created_layers[layer_data['name']]\n\n                # Process all nodes in layer, if not yet processed\n                if layer in unprocessed_nodes:\n                    node_data_list = unprocessed_nodes[layer]\n\n                    # Process nodes in order\n                    node_index = 0\n                    while node_index < len(node_data_list):\n                        node_data = node_data_list[node_index]\n                        try:\n                            process_node(layer, node_data)\n\n                        # If the node does not have all inbound layers\n                        # available, stop processing and continue later\n                        except LookupError:\n                            break\n\n                        node_index += 1\n\n                    # If not all nodes processed then store unprocessed nodes\n                    if node_index < len(node_data_list):\n                        unprocessed_nodes[layer] = node_data_list[node_index:]\n                    # If all nodes processed remove the layer\n                    else:\n                        del unprocessed_nodes[layer]\n\n        # Create lits of input and output tensors and return new class\n        name = config.get('name')\n        input_tensors = []\n        output_tensors = []\n        for layer_data in config['input_layers']:\n            layer_name, node_index, tensor_index = layer_data\n            assert layer_name in created_layers\n            layer = created_layers[layer_name]\n            layer_output_tensors = layer._inbound_nodes[node_index].output_tensors\n            input_tensors.append(layer_output_tensors[tensor_index])\n        for layer_data in config['output_layers']:\n            layer_name, node_index, tensor_index = layer_data\n            assert layer_name in created_layers\n            layer = created_layers[layer_name]\n            layer_output_tensors = layer._inbound_nodes[node_index].output_tensors\n            output_tensors.append(layer_output_tensors[tensor_index])\n        return cls(inputs=input_tensors, outputs=output_tensors, name=name)",
        "begin_line": 934,
        "end_line": 1088,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00044863167339614175,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network.Network.add_unprocessed_node#960",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network.Network",
        "signature": "keras.engine.network.Network.add_unprocessed_node(layer, node_data)",
        "snippet": "        def add_unprocessed_node(layer, node_data):\n            \"\"\"Add node to layer list\n\n            Args:\n                layer: layer object\n                node_data: Node data specifying layer call\n            \"\"\"\n            if layer not in unprocessed_nodes:\n                unprocessed_nodes[layer] = [node_data]\n            else:\n                unprocessed_nodes[layer].append(node_data)",
        "begin_line": 960,
        "end_line": 970,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00044863167339614175,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network.Network.process_node#972",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network.Network",
        "signature": "keras.engine.network.Network.process_node(layer, node_data)",
        "snippet": "        def process_node(layer, node_data):\n            \"\"\"Reconstruct node by linking to inbound layers\n\n            Args:\n                layer: Layer to process\n                node_data: List of layer configs\n\n            Raises:\n                ValueError: For incorrect layer config\n                LookupError: If layer required is not found\n            \"\"\"\n            input_tensors = []\n            for input_data in node_data:\n                inbound_layer_name = input_data[0]\n                inbound_node_index = input_data[1]\n                inbound_tensor_index = input_data[2]\n                if len(input_data) == 3:\n                    kwargs = {}\n                elif len(input_data) == 4:\n                    kwargs = input_data[3]\n                else:\n                    raise ValueError('Improperly formatted model config.')\n                inbound_layer = created_layers[inbound_layer_name]\n                # Raise an error if the corresponding layer node\n                # has not yet been created\n                if len(inbound_layer._inbound_nodes) <= inbound_node_index:\n                    raise LookupError\n                inbound_node = inbound_layer._inbound_nodes[inbound_node_index]\n                input_tensors.append(\n                    inbound_node.output_tensors[inbound_tensor_index])\n\n            # Call layer on its inputs, thus creating the node\n            # and building the layer if needed.\n            if input_tensors:\n                layer(unpack_singleton(input_tensors), **kwargs)",
        "begin_line": 972,
        "end_line": 1006,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00044863167339614175,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network.Network.process_layer#1008",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network.Network",
        "signature": "keras.engine.network.Network.process_layer(layer_data)",
        "snippet": "        def process_layer(layer_data):\n            \"\"\"Deserializes a layer, then call it on appropriate inputs.\n\n            # Arguments\n                layer_data: layer config dict.\n\n            # Raises\n                ValueError: In case of improperly formatted `layer_data` dict.\n            \"\"\"\n            layer_name = layer_data['name']\n\n            # Instantiate layer.\n            from ..layers import deserialize as deserialize_layer\n\n            layer = deserialize_layer(layer_data,\n                                      custom_objects=custom_objects)\n            created_layers[layer_name] = layer\n\n            # Gather layer inputs.\n            inbound_nodes_data = layer_data['inbound_nodes']\n            for node_data in inbound_nodes_data:\n                # We don't process nodes (i.e. make layer calls)\n                # on the fly because the inbound node may not yet exist,\n                # in case of layer shared at different topological depths\n                # (e.g. a model such as A(B(A(B(x)))))\n                add_unprocessed_node(layer, node_data)",
        "begin_line": 1008,
        "end_line": 1033,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00044863167339614175,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network.Network.save#1090",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network.Network",
        "signature": "keras.engine.network.Network.save(self, filepath, overwrite=True, include_optimizer=True)",
        "snippet": "    def save(self, filepath, overwrite=True, include_optimizer=True):\n        \"\"\"Saves the model to a single HDF5 file.\n\n        The savefile includes:\n            - The model architecture, allowing to re-instantiate the model.\n            - The model weights.\n            - The state of the optimizer, allowing to resume training\n                exactly where you left off.\n\n        This allows you to save the entirety of the state of a model\n        in a single file.\n\n        Saved models can be reinstantiated via `keras.models.load_model`.\n        The model returned by `load_model`\n        is a compiled model ready to be used (unless the saved model\n        was never compiled in the first place).\n\n        # Arguments\n            filepath: String, path to the file to save the weights to.\n            overwrite: Whether to silently overwrite any existing file at the\n                target location, or provide the user with a manual prompt.\n            include_optimizer: If True, save optimizer's state together.\n\n        # Example\n\n        ```python\n        from keras.models import load_model\n\n        model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n        del model  # deletes the existing model\n\n        # returns a compiled model\n        # identical to the previous one\n        model = load_model('my_model.h5')\n        ```\n        \"\"\"\n        if not self._is_graph_network:\n            raise NotImplementedError\n        from ..models import save_model\n        save_model(self, filepath, overwrite, include_optimizer)",
        "begin_line": 1090,
        "end_line": 1129,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network.Network.save_weights#1132",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network.Network",
        "signature": "keras.engine.network.Network.save_weights(self, filepath, overwrite=True)",
        "snippet": "    def save_weights(self, filepath, overwrite=True):\n        \"\"\"Dumps all layer weights to a HDF5 file.\n\n        The weight file has:\n            - `layer_names` (attribute), a list of strings\n                (ordered names of model layers).\n            - For every layer, a `group` named `layer.name`\n                - For every such layer group, a group attribute `weight_names`,\n                    a list of strings\n                    (ordered names of weights tensor of the layer).\n                - For every weight in the layer, a dataset\n                    storing the weight value, named after the weight tensor.\n\n        # Arguments\n            filepath: String, path to the file to save the weights to.\n            overwrite: Whether to silently overwrite any existing file at the\n                target location, or provide the user with a manual prompt.\n\n        # Raises\n            ImportError: If h5py is not available.\n        \"\"\"\n        if h5py is None:\n            raise ImportError('`save_weights` requires h5py.')\n        # If file exists and should not be overwritten:\n        if not overwrite and os.path.isfile(filepath):\n            proceed = ask_to_proceed_with_overwrite(filepath)\n            if not proceed:\n                return\n        with h5py.File(filepath, 'w') as f:\n            saving.save_weights_to_hdf5_group(f, self.layers)\n            f.flush()",
        "begin_line": 1132,
        "end_line": 1162,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0006756756756756757,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network.Network.load_weights#1165",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network.Network",
        "signature": "keras.engine.network.Network.load_weights(self, filepath, by_name=False, skip_mismatch=False, reshape=False)",
        "snippet": "    def load_weights(self, filepath, by_name=False,\n                     skip_mismatch=False, reshape=False):\n        \"\"\"Loads all layer weights from a HDF5 save file.\n\n        If `by_name` is False (default) weights are loaded\n        based on the network's topology, meaning the architecture\n        should be the same as when the weights were saved.\n        Note that layers that don't have weights are not taken\n        into account in the topological ordering, so adding or\n        removing layers is fine as long as they don't have weights.\n\n        If `by_name` is True, weights are loaded into layers\n        only if they share the same name. This is useful\n        for fine-tuning or transfer-learning models where\n        some of the layers have changed.\n\n        # Arguments\n            filepath: String, path to the weights file to load.\n            by_name: Boolean, whether to load weights by name\n                or by topological order.\n            skip_mismatch: Boolean, whether to skip loading of layers\n                where there is a mismatch in the number of weights,\n                or a mismatch in the shape of the weight\n                (only valid when `by_name`=True).\n            reshape: Reshape weights to fit the layer when the correct number\n                of weight arrays is present but their shape does not match.\n\n\n        # Raises\n            ImportError: If h5py is not available.\n        \"\"\"\n        if h5py is None:\n            raise ImportError('`load_weights` requires h5py.')\n        with h5py.File(filepath, mode='r') as f:\n            if 'layer_names' not in f.attrs and 'model_weights' in f:\n                f = f['model_weights']\n            if by_name:\n                saving.load_weights_from_hdf5_group_by_name(\n                    f, self.layers, skip_mismatch=skip_mismatch,\n                    reshape=reshape)\n            else:\n                saving.load_weights_from_hdf5_group(\n                    f, self.layers, reshape=reshape)",
        "begin_line": 1165,
        "end_line": 1207,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network.Network.__getstate__#1303",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network.Network",
        "signature": "keras.engine.network.Network.__getstate__(self)",
        "snippet": "    def __getstate__(self):\n        return saving.pickle_model(self)",
        "begin_line": 1303,
        "end_line": 1304,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005574136008918618,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network.Network.__setstate__#1306",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network.Network",
        "signature": "keras.engine.network.Network.__setstate__(self, state)",
        "snippet": "    def __setstate__(self, state):\n        model = saving.unpickle_model(state)\n        self.__dict__.update(model.__dict__)",
        "begin_line": 1306,
        "end_line": 1308,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005574136008918618,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network._make_node_key#1311",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network",
        "signature": "keras.engine.network._make_node_key(layer_name, node_index)",
        "snippet": "def _make_node_key(layer_name, node_index):\n    return layer_name + '_ib-' + str(node_index)",
        "begin_line": 1311,
        "end_line": 1312,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002613012803762738,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network._map_graph_network#1315",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network",
        "signature": "keras.engine.network._map_graph_network(inputs, outputs)",
        "snippet": "def _map_graph_network(inputs, outputs):\n    \"\"\"Validates a network's topology and gather its layers and nodes.\n\n    # Arguments\n        inputs: List of input tensors.\n        outputs: List of outputs tensors.\n\n    # Returns\n        A tuple `(nodes, nodes_by_depth, layers, layers_by_depth)`.\n        - nodes: list of Node instances.\n        - nodes_by_depth: dict mapping ints (depth) to lists of node instances.\n        - layers: list of Layer instances.\n        - layers_by_depth: dict mapping ints (depth)\n            to lists of layer instances.\n\n    # Raises\n        ValueError: In case the network is not valid (e.g. disconnected graph).\n    \"\"\"\n    # Network_nodes: set of nodes included in the graph of layers\n    # (not all nodes included in the layers are relevant to the current graph).\n    network_nodes = set()  # ids of all nodes relevant to the Network\n    nodes_depths = {}  # dict {node: depth value}\n    layers_depths = {}  # dict {layer: depth value}\n    layer_indices = {}  # dict {layer: index in traversal}\n    nodes_in_decreasing_depth = []\n\n    def build_map(tensor,\n                  finished_nodes,\n                  nodes_in_progress,\n                  layer,\n                  node_index,\n                  tensor_index):\n        \"\"\"Builds a map of the graph of layers.\n\n        This recursively updates the map `layer_indices`,\n        the list `nodes_in_decreasing_depth` and the set `network_nodes`.\n\n        # Arguments\n            tensor: Some tensor in a graph.\n            finished_nodes: Set of nodes whose subgraphs have been traversed\n                completely. Useful to prevent duplicated work.\n            nodes_in_progress: Set of nodes that are currently active on the\n                recursion stack. Useful to detect cycles.\n            layer: Layer from which `tensor` comes from. If not provided,\n                will be obtained from `tensor._keras_history`.\n            node_index: Node index from which `tensor` comes from.\n            tensor_index: Tensor_index from which `tensor` comes from.\n\n        # Raises\n            ValueError: if a cycle is detected.\n        \"\"\"\n        node = layer._inbound_nodes[node_index]\n\n        # Prevent cycles.\n        if node in nodes_in_progress:\n            raise ValueError('The tensor ' + str(tensor) + ' at layer \"' +\n                             layer.name + '\" is part of a cycle.')\n\n        # Don't repeat work for shared subgraphs\n        if node in finished_nodes:\n            return\n\n        node_key = _make_node_key(layer.name, node_index)\n        # Update network_nodes.\n        network_nodes.add(node_key)\n\n        # Store the traversal order for layer sorting.\n        if layer not in layer_indices:\n            layer_indices[layer] = len(layer_indices)\n\n        nodes_in_progress.add(node)\n\n        # Propagate to all previous tensors connected to this node.\n        for i in range(len(node.inbound_layers)):\n            x = node.input_tensors[i]\n            layer = node.inbound_layers[i]\n            node_index = node.node_indices[i]\n            tensor_index = node.tensor_indices[i]\n            build_map(x, finished_nodes, nodes_in_progress, layer,\n                      node_index, tensor_index)\n\n        finished_nodes.add(node)\n        nodes_in_progress.remove(node)\n        nodes_in_decreasing_depth.append(node)\n\n    finished_nodes = set()\n    nodes_in_progress = set()\n    for x in outputs:\n        layer, node_index, tensor_index = x._keras_history\n        build_map(x, finished_nodes, nodes_in_progress,\n                  layer=layer,\n                  node_index=node_index,\n                  tensor_index=tensor_index)\n\n    for node in reversed(nodes_in_decreasing_depth):\n        # If the depth is not set, the node has no outbound nodes (depth 0).\n        depth = nodes_depths.setdefault(node, 0)\n\n        # Update the depth of the corresponding layer\n        previous_depth = layers_depths.get(node.outbound_layer, 0)\n        # If we've seen this layer before at a higher depth,\n        # we should use that depth instead of the node depth.\n        # This is necessary for shared layers that have inputs at different\n        # depth levels in the graph.\n        depth = max(depth, previous_depth)\n        layers_depths[node.outbound_layer] = depth\n        nodes_depths[node] = depth\n\n        # Update the depth of inbound nodes.\n        # The \"depth\" of a node is the max of the depths\n        # of all layers it is connected to.\n        for i in range(len(node.inbound_layers)):\n            inbound_layer = node.inbound_layers[i]\n            node_index = node.node_indices[i]\n            inbound_node = inbound_layer._inbound_nodes[node_index]\n            previous_depth = nodes_depths.get(inbound_node, 0)\n            nodes_depths[inbound_node] = max(depth + 1, previous_depth)\n\n    # Build a dict {depth: list of nodes with this depth}\n    nodes_by_depth = {}\n    for node, depth in nodes_depths.items():\n        if depth not in nodes_by_depth:\n            nodes_by_depth[depth] = []\n        nodes_by_depth[depth].append(node)\n\n    # Build a dict {depth: list of layers with this depth}\n    layers_by_depth = {}\n    for layer, depth in layers_depths.items():\n        if depth not in layers_by_depth:\n            layers_by_depth[depth] = []\n        layers_by_depth[depth].append(layer)\n\n    # Get sorted list of layer depths.\n    depth_keys = list(layers_by_depth.keys())\n    depth_keys.sort(reverse=True)\n\n    # Set self.layers and self._layers_by_depth.\n    layers = []\n    for depth in depth_keys:\n        layers_for_depth = layers_by_depth[depth]\n        # Network.layers needs to have a deterministic order:\n        # here we order them by traversal order.\n        layers_for_depth.sort(key=lambda x: layer_indices[x])\n        layers.extend(layers_for_depth)\n\n    # Get sorted list of node depths.\n    depth_keys = list(nodes_by_depth.keys())\n    depth_keys.sort(reverse=True)\n\n    # Check that all tensors required are computable.\n    # computable_tensors: all tensors in the graph\n    # that can be computed from the inputs provided.\n    computable_tensors = []\n    for x in inputs:\n        computable_tensors.append(x)\n\n    layers_with_complete_input = []  # To provide a better error msg.\n    for depth in depth_keys:\n        for node in nodes_by_depth[depth]:\n            layer = node.outbound_layer\n            if layer:\n                for x in node.input_tensors:\n                    if x not in computable_tensors:\n                        raise ValueError('Graph disconnected: '\n                                         'cannot obtain value for tensor ' +\n                                         str(x) + ' at layer \"' +\n                                         layer.name + '\". '\n                                         'The following previous layers '\n                                         'were accessed without issue: ' +\n                                         str(layers_with_complete_input))\n                for x in node.output_tensors:\n                    computable_tensors.append(x)\n                layers_with_complete_input.append(layer.name)\n\n    # Ensure name unicity, which will be crucial for serialization\n    # (since serialized nodes refer to layers by their name).\n    all_names = [layer.name for layer in layers]\n    for name in all_names:\n        if all_names.count(name) != 1:\n            raise ValueError('The name \"' + name + '\" is used ' +\n                             str(all_names.count(name)) +\n                             ' times in the model. '\n                             'All layer names should be unique.')\n    return network_nodes, nodes_by_depth, layers, layers_by_depth",
        "begin_line": 1315,
        "end_line": 1498,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002613012803762738,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.network.build_map#1341",
        "src_path": "keras/engine/network.py",
        "class_name": "keras.engine.network",
        "signature": "keras.engine.network.build_map(tensor, finished_nodes, nodes_in_progress, layer, node_index, tensor_index)",
        "snippet": "    def build_map(tensor,\n                  finished_nodes,\n                  nodes_in_progress,\n                  layer,\n                  node_index,\n                  tensor_index):\n        \"\"\"Builds a map of the graph of layers.\n\n        This recursively updates the map `layer_indices`,\n        the list `nodes_in_decreasing_depth` and the set `network_nodes`.\n\n        # Arguments\n            tensor: Some tensor in a graph.\n            finished_nodes: Set of nodes whose subgraphs have been traversed\n                completely. Useful to prevent duplicated work.\n            nodes_in_progress: Set of nodes that are currently active on the\n                recursion stack. Useful to detect cycles.\n            layer: Layer from which `tensor` comes from. If not provided,\n                will be obtained from `tensor._keras_history`.\n            node_index: Node index from which `tensor` comes from.\n            tensor_index: Tensor_index from which `tensor` comes from.\n\n        # Raises\n            ValueError: if a cycle is detected.\n        \"\"\"\n        node = layer._inbound_nodes[node_index]\n\n        # Prevent cycles.\n        if node in nodes_in_progress:\n            raise ValueError('The tensor ' + str(tensor) + ' at layer \"' +\n                             layer.name + '\" is part of a cycle.')\n\n        # Don't repeat work for shared subgraphs\n        if node in finished_nodes:\n            return\n\n        node_key = _make_node_key(layer.name, node_index)\n        # Update network_nodes.\n        network_nodes.add(node_key)\n\n        # Store the traversal order for layer sorting.\n        if layer not in layer_indices:\n            layer_indices[layer] = len(layer_indices)\n\n        nodes_in_progress.add(node)\n\n        # Propagate to all previous tensors connected to this node.\n        for i in range(len(node.inbound_layers)):\n            x = node.input_tensors[i]\n            layer = node.inbound_layers[i]\n            node_index = node.node_indices[i]\n            tensor_index = node.tensor_indices[i]\n            build_map(x, finished_nodes, nodes_in_progress, layer,\n                      node_index, tensor_index)\n\n        finished_nodes.add(node)\n        nodes_in_progress.remove(node)\n        nodes_in_decreasing_depth.append(node)",
        "begin_line": 1341,
        "end_line": 1398,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0006756756756756757,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.sequential.Sequential.__init__#87",
        "src_path": "keras/engine/sequential.py",
        "class_name": "keras.engine.sequential.Sequential",
        "signature": "keras.engine.sequential.Sequential.__init__(self, layers=None, name=None)",
        "snippet": "    def __init__(self, layers=None, name=None):\n        super(Sequential, self).__init__(name=name)\n        self._build_input_shape = None\n\n        # Add to the model any layers passed to the constructor.\n        if layers:\n            for layer in layers:\n                self.add(layer)",
        "begin_line": 87,
        "end_line": 94,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00032948929159802305,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.sequential.Sequential.layers#97",
        "src_path": "keras/engine/sequential.py",
        "class_name": "keras.engine.sequential.Sequential",
        "signature": "keras.engine.sequential.Sequential.layers(self)",
        "snippet": "    def layers(self):\n        # Historically, `sequential.layers` only returns layers that were added\n        # via `add`, and omits the auto-generated `InputLayer`\n        # that comes at the bottom of the stack.\n        if self._layers and isinstance(self._layers[0], InputLayer):\n            return self._layers[1:]\n        return self._layers",
        "begin_line": 97,
        "end_line": 103,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00034164673727365904,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.sequential.Sequential.add#116",
        "src_path": "keras/engine/sequential.py",
        "class_name": "keras.engine.sequential.Sequential",
        "signature": "keras.engine.sequential.Sequential.add(self, layer)",
        "snippet": "    def add(self, layer):\n        \"\"\"Adds a layer instance on top of the layer stack.\n\n        # Arguments\n            layer: layer instance.\n\n        # Raises\n            TypeError: If `layer` is not a layer instance.\n            ValueError: In case the `layer` argument does not\n                know its input shape.\n            ValueError: In case the `layer` argument has\n                multiple output tensors, or is already connected\n                somewhere else (forbidden in `Sequential` models).\n        \"\"\"\n        if not isinstance(layer, Layer):\n            raise TypeError('The added layer must be '\n                            'an instance of class Layer. '\n                            'Found: ' + str(layer))\n        self.built = False\n        if not self._layers:\n            set_inputs = False\n            # First layer in model: check that it is an input layer.\n            if not isinstance(layer, InputLayer):\n                # Create an input tensor and call `layer` on the input tensor.\n                # First, we need to infer the expected input shape and dtype.\n                first_layer = layer\n                if isinstance(layer, (Model, Sequential)):\n                    # We were passed a model as first layer.\n                    # This requires a specific way to figure out the\n                    # input shape and dtype.\n                    if not layer.layers:\n                        raise ValueError('Cannot add an empty model '\n                                         'to a `Sequential` model.')\n                    # In case of nested models: recover the first layer\n                    # of the deepest model to infer input shape and dtype.\n                    first_layer = layer.layers[0]\n                    while isinstance(first_layer, (Model, Sequential)):\n                        first_layer = first_layer.layers[0]\n\n                if hasattr(first_layer, 'batch_input_shape'):\n                    batch_shape = first_layer.batch_input_shape\n                    dtype = first_layer.dtype\n                    # Instantiate the input layer.\n                    x = Input(\n                        batch_shape=batch_shape,\n                        dtype=dtype,\n                        name=layer.name + '_input')\n                    # This will build the current layer\n                    # and create the node connecting the current layer\n                    # to the input layer we just created.\n                    layer(x)\n                    set_inputs = True\n            else:\n                # Corner case where the user passes an InputLayer via `add`.\n                assert len(layer._inbound_nodes[-1].output_tensors) == 1\n                set_inputs = True\n\n            if set_inputs:\n                if len(layer._inbound_nodes[-1].output_tensors) != 1:\n                    raise ValueError('All layers in a Sequential model '\n                                     'should have a single output tensor. '\n                                     'For multi-output layers, '\n                                     'use the functional API.')\n                self.outputs = [layer._inbound_nodes[-1].output_tensors[0]]\n                self.inputs = network.get_source_inputs(self.outputs[0])\n        elif self.outputs:\n            output_tensor = layer(self.outputs[0])\n            if isinstance(output_tensor, list):\n                raise TypeError('All layers in a Sequential model '\n                                'should have a single output tensor. '\n                                'For multi-output layers, '\n                                'use the functional API.')\n            self.outputs = [output_tensor]\n        if self.inputs:\n            self.build()\n        else:\n            self._layers.append(layer)",
        "begin_line": 116,
        "end_line": 192,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.sequential.Sequential.build#213",
        "src_path": "keras/engine/sequential.py",
        "class_name": "keras.engine.sequential.Sequential",
        "signature": "keras.engine.sequential.Sequential.build(self, input_shape=None)",
        "snippet": "    def build(self, input_shape=None):\n        if input_shape and not self.inputs:\n            batch_shape = tuple(input_shape)\n            dtype = K.floatx()\n            x = Input(batch_shape=batch_shape,\n                      dtype=dtype,\n                      name=self.name + '_input')\n            self.inputs = [x]\n            for layer in self._layers:\n                x = layer(x)\n            self.outputs = [x]\n            self._build_input_shape = input_shape\n\n        if self.inputs:\n            self._init_graph_network(self.inputs,\n                                     self.outputs,\n                                     name=self.name)\n            self.built = True",
        "begin_line": 213,
        "end_line": 230,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00032948929159802305,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.sequential.Sequential.get_config#274",
        "src_path": "keras/engine/sequential.py",
        "class_name": "keras.engine.sequential.Sequential",
        "signature": "keras.engine.sequential.Sequential.get_config(self)",
        "snippet": "    def get_config(self):\n        layer_configs = []\n        for layer in self.layers:\n            layer_configs.append({\n                'class_name': layer.__class__.__name__,\n                'config': layer.get_config()\n            })\n        config = {\n            'name': self.name,\n            'layers': copy.deepcopy(layer_configs)\n        }\n        if self._build_input_shape:\n            config['build_input_shape'] = self._build_input_shape\n        return config",
        "begin_line": 274,
        "end_line": 287,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0004692632566870014,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.sequential.Sequential.from_config#290",
        "src_path": "keras/engine/sequential.py",
        "class_name": "keras.engine.sequential.Sequential",
        "signature": "keras.engine.sequential.Sequential.from_config(cls, config, custom_objects=None)",
        "snippet": "    def from_config(cls, config, custom_objects=None):\n        if 'name' in config:\n            name = config['name']\n            build_input_shape = config.get('build_input_shape')\n            layer_configs = config['layers']\n        else:  # legacy config file\n            name = build_input_shape = None\n            layer_configs = config\n        model = cls(name=name)\n        for conf in layer_configs:\n            layer = layer_module.deserialize(conf,\n                                             custom_objects=custom_objects)\n            model.add(layer)\n        if not model.inputs and build_input_shape:\n            model.build(build_input_shape)\n        return model",
        "begin_line": 290,
        "end_line": 305,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0004692632566870014,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.utils.np_utils.to_categorical#9",
        "src_path": "keras/utils/np_utils.py",
        "class_name": "keras.utils.np_utils",
        "signature": "keras.utils.np_utils.to_categorical(y, num_classes=None, dtype='float32')",
        "snippet": "def to_categorical(y, num_classes=None, dtype='float32'):\n    \"\"\"Converts a class vector (integers) to binary class matrix.\n\n    E.g. for use with categorical_crossentropy.\n\n    # Arguments\n        y: class vector to be converted into a matrix\n            (integers from 0 to num_classes).\n        num_classes: total number of classes.\n        dtype: The data type expected by the input, as a string\n            (`float32`, `float64`, `int32`...)\n\n    # Returns\n        A binary matrix representation of the input. The classes axis\n        is placed last.\n\n    # Example\n\n    ```python\n    # Consider an array of 5 labels out of a set of 3 classes {0, 1, 2}:\n    > labels\n    array([0, 2, 1, 2, 0])\n    # `to_categorical` converts this into a matrix with as many\n    # columns as there are classes. The number of rows\n    # stays the same.\n    > to_categorical(labels)\n    array([[ 1.,  0.,  0.],\n           [ 0.,  0.,  1.],\n           [ 0.,  1.,  0.],\n           [ 0.,  0.,  1.],\n           [ 1.,  0.,  0.]], dtype=float32)\n    ```\n    \"\"\"\n\n    y = np.array(y, dtype='int')\n    input_shape = y.shape\n    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n        input_shape = tuple(input_shape[:-1])\n    y = y.ravel()\n    if not num_classes:\n        num_classes = np.max(y) + 1\n    n = y.shape[0]\n    categorical = np.zeros((n, num_classes), dtype=dtype)\n    categorical[np.arange(n), y] = 1\n    output_shape = input_shape + (num_classes,)\n    categorical = np.reshape(categorical, output_shape)\n    return categorical",
        "begin_line": 9,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005083884087442806,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.__init__.deserialize#150",
        "src_path": "keras/layers/__init__.py",
        "class_name": "keras.layers.__init__",
        "signature": "keras.layers.__init__.deserialize(config, custom_objects=None)",
        "snippet": "def deserialize(config, custom_objects=None):\n    \"\"\"Instantiate a layer from a config dictionary.\n\n    # Arguments\n        config: dict of the form {'class_name': str, 'config': dict}\n        custom_objects: dict mapping class names (or function names)\n            of custom (non-Keras) objects to class/functions\n\n    # Returns\n        Layer instance (may be Model, Sequential, Layer...)\n    \"\"\"\n    from .. import models\n    globs = globals()  # All layers.\n    globs['Model'] = models.Model\n    globs['Sequential'] = models.Sequential\n    return deserialize_keras_object(config,\n                                    module_objects=globs,\n                                    custom_objects=custom_objects,\n                                    printable_module_name='layer')",
        "begin_line": 150,
        "end_line": 168,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0003551136363636364,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.initializers.Initializer.get_config#21",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Initializer",
        "signature": "keras.initializers.Initializer.get_config(self)",
        "snippet": "    def get_config(self):\n        return {}",
        "begin_line": 21,
        "end_line": 22,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00037778617302606723,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.initializers.Initializer.from_config#25",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Initializer",
        "signature": "keras.initializers.Initializer.from_config(cls, config)",
        "snippet": "    def from_config(cls, config):\n        if 'dtype' in config:\n            # Initializers saved from `tf.keras`\n            # may contain an unused `dtype` argument.\n            config.pop('dtype')\n        return cls(**config)",
        "begin_line": 25,
        "end_line": 30,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.000281610813855252,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.initializers.Zeros.__call__#37",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Zeros",
        "signature": "keras.initializers.Zeros.__call__(self, shape, dtype=None)",
        "snippet": "    def __call__(self, shape, dtype=None):\n        return K.constant(0, shape=shape, dtype=dtype)",
        "begin_line": 37,
        "end_line": 38,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00028506271379703536,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.initializers.Ones.__call__#45",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Ones",
        "signature": "keras.initializers.Ones.__call__(self, shape, dtype=None)",
        "snippet": "    def __call__(self, shape, dtype=None):\n        return K.constant(1, shape=shape, dtype=dtype)",
        "begin_line": 45,
        "end_line": 46,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.initializers.Constant.__init__#56",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Constant",
        "signature": "keras.initializers.Constant.__init__(self, value=0)",
        "snippet": "    def __init__(self, value=0):\n        self.value = value",
        "begin_line": 56,
        "end_line": 57,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.initializers.Constant.__call__#59",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Constant",
        "signature": "keras.initializers.Constant.__call__(self, shape, dtype=None)",
        "snippet": "    def __call__(self, shape, dtype=None):\n        return K.constant(self.value, shape=shape, dtype=dtype)",
        "begin_line": 59,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.initializers.Constant.get_config#62",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Constant",
        "signature": "keras.initializers.Constant.get_config(self)",
        "snippet": "    def get_config(self):\n        return {'value': self.value}",
        "begin_line": 62,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.initializers.VarianceScaling.__init__#180",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.VarianceScaling",
        "signature": "keras.initializers.VarianceScaling.__init__(self, scale=1.0, mode='fan_in', distribution='normal', seed=None)",
        "snippet": "    def __init__(self, scale=1.0,\n                 mode='fan_in',\n                 distribution='normal',\n                 seed=None):\n        if scale <= 0.:\n            raise ValueError('`scale` must be a positive float. Got:', scale)\n        mode = mode.lower()\n        if mode not in {'fan_in', 'fan_out', 'fan_avg'}:\n            raise ValueError('Invalid `mode` argument: '\n                             'expected on of {\"fan_in\", \"fan_out\", \"fan_avg\"} '\n                             'but got', mode)\n        distribution = distribution.lower()\n        if distribution not in {'normal', 'uniform'}:\n            raise ValueError('Invalid `distribution` argument: '\n                             'expected one of {\"normal\", \"uniform\"} '\n                             'but got', distribution)\n        self.scale = scale\n        self.mode = mode\n        self.distribution = distribution\n        self.seed = seed",
        "begin_line": 180,
        "end_line": 199,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002901073397156948,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.initializers.VarianceScaling.__call__#201",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.VarianceScaling",
        "signature": "keras.initializers.VarianceScaling.__call__(self, shape, dtype=None)",
        "snippet": "    def __call__(self, shape, dtype=None):\n        fan_in, fan_out = _compute_fans(shape)\n        scale = self.scale\n        if self.mode == 'fan_in':\n            scale /= max(1., fan_in)\n        elif self.mode == 'fan_out':\n            scale /= max(1., fan_out)\n        else:\n            scale /= max(1., float(fan_in + fan_out) / 2)\n        if self.distribution == 'normal':\n            # 0.879... = scipy.stats.truncnorm.std(a=-2, b=2, loc=0., scale=1.)\n            stddev = np.sqrt(scale) / .87962566103423978\n            return K.truncated_normal(shape, 0., stddev,\n                                      dtype=dtype, seed=self.seed)\n        else:\n            limit = np.sqrt(3. * scale)\n            return K.random_uniform(shape, -limit, limit,\n                                    dtype=dtype, seed=self.seed)",
        "begin_line": 201,
        "end_line": 218,
        "comment": "",
        "is_bug": true,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002901073397156948,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.initializers.VarianceScaling.get_config#220",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.VarianceScaling",
        "signature": "keras.initializers.VarianceScaling.get_config(self)",
        "snippet": "    def get_config(self):\n        return {\n            'scale': self.scale,\n            'mode': self.mode,\n            'distribution': self.distribution,\n            'seed': self.seed\n        }",
        "begin_line": 220,
        "end_line": 226,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00037778617302606723,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.initializers.Orthogonal.__init__#241",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Orthogonal",
        "signature": "keras.initializers.Orthogonal.__init__(self, gain=1.0, seed=None)",
        "snippet": "    def __init__(self, gain=1., seed=None):\n        self.gain = gain\n        self.seed = seed",
        "begin_line": 241,
        "end_line": 243,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.initializers.Orthogonal.__call__#245",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Orthogonal",
        "signature": "keras.initializers.Orthogonal.__call__(self, shape, dtype=None)",
        "snippet": "    def __call__(self, shape, dtype=None):\n        num_rows = 1\n        for dim in shape[:-1]:\n            num_rows *= dim\n        num_cols = shape[-1]\n        flat_shape = (num_rows, num_cols)\n        rng = np.random\n        if self.seed is not None:\n            rng = np.random.RandomState(self.seed)\n        a = rng.normal(0.0, 1.0, flat_shape)\n        u, _, v = np.linalg.svd(a, full_matrices=False)\n        # Pick the one with the correct shape.\n        q = u if u.shape == flat_shape else v\n        q = q.reshape(shape)\n        return self.gain * q[:shape[0], :shape[1]]",
        "begin_line": 245,
        "end_line": 259,
        "comment": "",
        "is_bug": true,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.initializers.Orthogonal.get_config#261",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers.Orthogonal",
        "signature": "keras.initializers.Orthogonal.get_config(self)",
        "snippet": "    def get_config(self):\n        return {\n            'gain': self.gain,\n            'seed': self.seed\n        }",
        "begin_line": 261,
        "end_line": 265,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.initializers.glorot_uniform#341",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers",
        "signature": "keras.initializers.glorot_uniform(seed=None)",
        "snippet": "def glorot_uniform(seed=None):\n    \"\"\"Glorot uniform initializer, also called Xavier uniform initializer.\n\n    It draws samples from a uniform distribution within [-limit, limit]\n    where `limit` is `sqrt(6 / (fan_in + fan_out))`\n    where `fan_in` is the number of input units in the weight tensor\n    and `fan_out` is the number of output units in the weight tensor.\n\n    # Arguments\n        seed: A Python integer. Used to seed the random generator.\n\n    # Returns\n        An initializer.\n\n    # References\n        - [Understanding the difficulty of training deep feedforward neural\n           networks](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf)\n    \"\"\"\n    return VarianceScaling(scale=1.,\n                           mode='fan_avg',\n                           distribution='uniform',\n                           seed=seed)",
        "begin_line": 341,
        "end_line": 362,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002901073397156948,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.initializers._compute_fans#448",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers",
        "signature": "keras.initializers._compute_fans(shape, data_format='channels_last')",
        "snippet": "def _compute_fans(shape, data_format='channels_last'):\n    \"\"\"Computes the number of input and output units for a weight shape.\n\n    # Arguments\n        shape: Integer shape tuple.\n        data_format: Image data format to use for convolution kernels.\n            Note that all kernels in Keras are standardized on the\n            `channels_last` ordering (even when inputs are set\n            to `channels_first`).\n\n    # Returns\n        A tuple of scalars, `(fan_in, fan_out)`.\n\n    # Raises\n        ValueError: in case of invalid `data_format` argument.\n    \"\"\"\n    if len(shape) == 2:\n        fan_in = shape[0]\n        fan_out = shape[1]\n    elif len(shape) in {3, 4, 5}:\n        # Assuming convolution kernels (1D, 2D or 3D).\n        # TH kernel shape: (depth, input_depth, ...)\n        # TF kernel shape: (..., input_depth, depth)\n        if data_format == 'channels_first':\n            receptive_field_size = np.prod(shape[2:])\n            fan_in = shape[1] * receptive_field_size\n            fan_out = shape[0] * receptive_field_size\n        elif data_format == 'channels_last':\n            receptive_field_size = np.prod(shape[:-2])\n            fan_in = shape[-2] * receptive_field_size\n            fan_out = shape[-1] * receptive_field_size\n        else:\n            raise ValueError('Invalid data_format: ' + data_format)\n    else:\n        # No specific assumptions.\n        fan_in = np.sqrt(np.prod(shape))\n        fan_out = np.sqrt(np.prod(shape))\n    return fan_in, fan_out",
        "begin_line": 448,
        "end_line": 485,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.initializers.serialize#488",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers",
        "signature": "keras.initializers.serialize(initializer)",
        "snippet": "def serialize(initializer):\n    return serialize_keras_object(initializer)",
        "begin_line": 488,
        "end_line": 489,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00037778617302606723,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.initializers.deserialize#492",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers",
        "signature": "keras.initializers.deserialize(config, custom_objects=None)",
        "snippet": "def deserialize(config, custom_objects=None):\n    return deserialize_keras_object(config,\n                                    module_objects=globals(),\n                                    custom_objects=custom_objects,\n                                    printable_module_name='initializer')",
        "begin_line": 492,
        "end_line": 496,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.000281610813855252,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.initializers.get#499",
        "src_path": "keras/initializers.py",
        "class_name": "keras.initializers",
        "signature": "keras.initializers.get(identifier)",
        "snippet": "def get(identifier):\n    if isinstance(identifier, dict):\n        return deserialize(identifier)\n    elif isinstance(identifier, six.string_types):\n        config = {'class_name': str(identifier), 'config': {}}\n        return deserialize(config)\n    elif callable(identifier):\n        return identifier\n    else:\n        raise ValueError('Could not interpret initializer identifier: ' +\n                         str(identifier))",
        "begin_line": 499,
        "end_line": 509,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00037778617302606723,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.training_utils.standardize_single_array#18",
        "src_path": "keras/engine/training_utils.py",
        "class_name": "keras.engine.training_utils",
        "signature": "keras.engine.training_utils.standardize_single_array(x)",
        "snippet": "def standardize_single_array(x):\n    if x is None:\n        return None\n    elif K.is_tensor(x):\n        shape = K.int_shape(x)\n        if shape is None or shape[0] is None:\n            raise ValueError(\n                'When feeding symbolic tensors to a model, we expect the '\n                'tensors to have a static batch size. '\n                'Got tensor with shape: %s' % str(shape))\n        return x\n    elif x.ndim == 1:\n        x = np.expand_dims(x, 1)\n    return x",
        "begin_line": 18,
        "end_line": 31,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.training_utils.standardize_input_data#34",
        "src_path": "keras/engine/training_utils.py",
        "class_name": "keras.engine.training_utils",
        "signature": "keras.engine.training_utils.standardize_input_data(data, names, shapes=None, check_batch_axis=True, exception_prefix='')",
        "snippet": "def standardize_input_data(data,\n                           names,\n                           shapes=None,\n                           check_batch_axis=True,\n                           exception_prefix=''):\n    \"\"\"Normalizes inputs and targets provided by users.\n\n    Users may pass data as a list of arrays, dictionary of arrays,\n    or as a single array. We normalize this to an ordered list of\n    arrays (same order as `names`), while checking that the provided\n    arrays have shapes that match the network's expectations.\n\n    # Arguments\n        data: User-provided input data (polymorphic).\n        names: List of expected array names.\n        shapes: Optional list of expected array shapes.\n        check_batch_axis: Boolean; whether to check that\n            the batch axis of the arrays matches the expected\n            value found in `shapes`.\n        exception_prefix: String prefix used for exception formatting.\n\n    # Returns\n        List of standardized input arrays (one array per model input).\n\n    # Raises\n        ValueError: in case of improperly formatted user-provided data.\n    \"\"\"\n    if not names:\n        if data is not None and hasattr(data, '__len__') and len(data):\n            raise ValueError('Error when checking model ' +\n                             exception_prefix + ': '\n                             'expected no data, but got:', data)\n        return []\n    if data is None:\n        return [None for _ in range(len(names))]\n\n    if isinstance(data, dict):\n        try:\n            data = [\n                data[x].values\n                if data[x].__class__.__name__ == 'DataFrame' else data[x]\n                for x in names\n            ]\n        except KeyError as e:\n            raise ValueError('No data provided for \"' + e.args[0] +\n                             '\". Need data '\n                             'for each key in: ' + str(names))\n    elif isinstance(data, list):\n        if isinstance(data[0], list):\n            data = [np.asarray(d) for d in data]\n        elif len(names) == 1 and isinstance(data[0], (float, int)):\n            data = [np.asarray(data)]\n        else:\n            data = [\n                x.values if x.__class__.__name__ == 'DataFrame'\n                else x for x in data\n            ]\n    else:\n        data = data.values if data.__class__.__name__ == 'DataFrame' else data\n        data = [data]\n    data = [standardize_single_array(x) for x in data]\n\n    if len(data) != len(names):\n        if data and hasattr(data[0], 'shape'):\n            raise ValueError(\n                'Error when checking model ' + exception_prefix +\n                ': the list of Numpy arrays that you are passing to '\n                'your model is not the size the model expected. '\n                'Expected to see ' + str(len(names)) + ' array(s), '\n                'but instead got the following list of ' +\n                str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n        elif len(names) > 1:\n            raise ValueError(\n                'Error when checking model ' + exception_prefix +\n                ': you are passing a list as input to your model, '\n                'but the model expects a list of ' + str(len(names)) +\n                ' Numpy arrays instead. '\n                'The list you passed was: ' + str(data)[:200])\n        elif len(data) == 1 and not hasattr(data[0], 'shape'):\n            raise TypeError('Error when checking model ' + exception_prefix +\n                            ': data should be a Numpy array, or list/dict of '\n                            'Numpy arrays. Found: ' + str(data)[:200] + '...')\n        elif len(names) == 1:\n            data = [np.asarray(data)]\n\n    # Check shapes compatibility.\n    if shapes:\n        for i in range(len(names)):\n            if shapes[i] is not None and not K.is_tensor(data[i]):\n                data_shape = data[i].shape\n                shape = shapes[i]\n                if data[i].ndim != len(shape):\n                    raise ValueError(\n                        'Error when checking ' + exception_prefix +\n                        ': expected ' + names[i] + ' to have ' +\n                        str(len(shape)) + ' dimensions, but got array '\n                        'with shape ' + str(data_shape))\n                if not check_batch_axis:\n                    data_shape = data_shape[1:]\n                    shape = shape[1:]\n                for dim, ref_dim in zip(data_shape, shape):\n                    if ref_dim != dim and ref_dim:\n                        raise ValueError(\n                            'Error when checking ' + exception_prefix +\n                            ': expected ' + names[i] + ' to have shape ' +\n                            str(shape) + ' but got array with shape ' +\n                            str(data_shape))\n    return data",
        "begin_line": 34,
        "end_line": 141,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.training_utils.standardize_sample_or_class_weights#144",
        "src_path": "keras/engine/training_utils.py",
        "class_name": "keras.engine.training_utils",
        "signature": "keras.engine.training_utils.standardize_sample_or_class_weights(x_weight, output_names, weight_type)",
        "snippet": "def standardize_sample_or_class_weights(x_weight,\n                                        output_names,\n                                        weight_type):\n    \"\"\"Maps `sample_weight` or `class_weight` to model outputs.\n\n    # Arguments\n        x_weight: User-provided `sample_weight` or `class_weight` argument.\n        output_names: List of output names (strings) in the model.\n        weight_type: A string used purely for exception printing.\n\n    # Returns\n        A list of `sample_weight` or `class_weight` where there are exactly\n            one element per model output.\n\n    # Raises\n        ValueError: In case of invalid user-provided argument.\n    \"\"\"\n    if x_weight is None or len(x_weight) == 0:\n        return [None for _ in output_names]\n    if len(output_names) == 1:\n        if isinstance(x_weight, list) and len(x_weight) == 1:\n            return x_weight\n        if isinstance(x_weight, dict) and output_names[0] in x_weight:\n            return [x_weight[output_names[0]]]\n        else:\n            return [x_weight]\n    if isinstance(x_weight, list):\n        if len(x_weight) != len(output_names):\n            raise ValueError('Provided `' + weight_type + '` was a list of ' +\n                             str(len(x_weight)) +\n                             ' elements, but the model has ' +\n                             str(len(output_names)) + ' outputs. '\n                             'You should provide one `' + weight_type + '`'\n                             'array per model output.')\n        return x_weight\n    if isinstance(x_weight, dict):\n        x_weights = []\n        for name in output_names:\n            x_weights.append(x_weight.get(name))\n        return x_weights\n    else:\n        raise TypeError('The model has multiple outputs, so `' +\n                        weight_type + '` '\n                        'should be either a list or a dict. '\n                        'Provided `' + weight_type +\n                        '` type not understood: ' +\n                        str(x_weight))",
        "begin_line": 144,
        "end_line": 190,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.training_utils.standardize_class_weights#193",
        "src_path": "keras/engine/training_utils.py",
        "class_name": "keras.engine.training_utils",
        "signature": "keras.engine.training_utils.standardize_class_weights(class_weight, output_names)",
        "snippet": "def standardize_class_weights(class_weight, output_names):\n    return standardize_sample_or_class_weights(class_weight,\n                                               output_names,\n                                               'class_weight')",
        "begin_line": 193,
        "end_line": 196,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0003551136363636364,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.training_utils.standardize_sample_weights#199",
        "src_path": "keras/engine/training_utils.py",
        "class_name": "keras.engine.training_utils",
        "signature": "keras.engine.training_utils.standardize_sample_weights(sample_weight, output_names)",
        "snippet": "def standardize_sample_weights(sample_weight, output_names):\n    return standardize_sample_or_class_weights(sample_weight,\n                                               output_names,\n                                               'sample_weight')",
        "begin_line": 199,
        "end_line": 202,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0003551136363636364,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.training_utils.check_array_length_consistency#205",
        "src_path": "keras/engine/training_utils.py",
        "class_name": "keras.engine.training_utils",
        "signature": "keras.engine.training_utils.check_array_length_consistency(inputs, targets, weights=None)",
        "snippet": "def check_array_length_consistency(inputs, targets, weights=None):\n    \"\"\"Checks if batch axes are the same for Numpy arrays.\n\n    # Arguments\n        inputs: list of Numpy arrays of inputs.\n        targets: list of Numpy arrays of targets.\n        weights: list of Numpy arrays of sample weights.\n\n    # Raises\n        ValueError: in case of incorrectly formatted data.\n    \"\"\"\n    def set_of_lengths(x):\n        # return a set with the variation between\n        # different shapes, with None => 0\n        if x is None:\n            return {0}\n        else:\n            return set([0 if y is None else int(y.shape[0]) for y in x])\n\n    set_x = set_of_lengths(inputs)\n    set_y = set_of_lengths(targets)\n    set_w = set_of_lengths(weights)\n    if len(set_x) > 1:\n        raise ValueError('All input arrays (x) should have '\n                         'the same number of samples. Got array shapes: ' +\n                         str([x.shape for x in inputs]))\n    if len(set_y) > 1:\n        raise ValueError('All target arrays (y) should have '\n                         'the same number of samples. Got array shapes: ' +\n                         str([y.shape for y in targets]))\n    if set_x and set_y and list(set_x)[0] != list(set_y)[0]:\n        raise ValueError('Input arrays should have '\n                         'the same number of samples as target arrays. '\n                         'Found ' + str(list(set_x)[0]) + ' input samples '\n                         'and ' + str(list(set_y)[0]) + ' target samples.')\n    if len(set_w) > 1:\n        raise ValueError('All sample_weight arrays should have '\n                         'the same number of samples. Got array shapes: ' +\n                         str([w.shape for w in weights]))\n    if set_y and set_w and list(set_y)[0] != list(set_w)[0]:\n        raise ValueError('Sample_weight arrays should have '\n                         'the same number of samples as target arrays. Got ' +\n                         str(list(set_y)[0]) + ' input samples and ' +\n                         str(list(set_w)[0]) + ' target samples.')",
        "begin_line": 205,
        "end_line": 248,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00036913990402362494,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.training_utils.set_of_lengths#216",
        "src_path": "keras/engine/training_utils.py",
        "class_name": "keras.engine.training_utils",
        "signature": "keras.engine.training_utils.set_of_lengths(x)",
        "snippet": "    def set_of_lengths(x):\n        # return a set with the variation between\n        # different shapes, with None => 0\n        if x is None:\n            return {0}\n        else:\n            return set([0 if y is None else int(y.shape[0]) for y in x])",
        "begin_line": 216,
        "end_line": 222,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00036913990402362494,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.training_utils.check_loss_and_target_compatibility#251",
        "src_path": "keras/engine/training_utils.py",
        "class_name": "keras.engine.training_utils",
        "signature": "keras.engine.training_utils.check_loss_and_target_compatibility(targets, loss_fns, output_shapes)",
        "snippet": "def check_loss_and_target_compatibility(targets, loss_fns, output_shapes):\n    \"\"\"Does validation on the compatibility of targets and loss functions.\n\n    This helps prevent users from using loss functions incorrectly.\n\n    # Arguments\n        targets: list of Numpy arrays of targets.\n        loss_fns: list of loss functions.\n        output_shapes: list of shapes of model outputs.\n\n    # Raises\n        ValueError: if a loss function or target array\n            is incompatible with an output.\n    \"\"\"\n    key_losses = {losses.mean_squared_error,\n                  losses.binary_crossentropy,\n                  losses.categorical_crossentropy}\n    for y, loss, shape in zip(targets, loss_fns, output_shapes):\n        if y is None or loss is None:\n            continue\n        if loss is losses.categorical_crossentropy:\n            if y.shape[-1] == 1:\n                raise ValueError(\n                    'You are passing a target array of shape ' + str(y.shape) +\n                    ' while using as loss `categorical_crossentropy`. '\n                    '`categorical_crossentropy` expects '\n                    'targets to be binary matrices (1s and 0s) '\n                    'of shape (samples, classes). '\n                    'If your targets are integer classes, '\n                    'you can convert them to the expected format via:\\n'\n                    '```\\n'\n                    'from keras.utils import to_categorical\\n'\n                    'y_binary = to_categorical(y_int)\\n'\n                    '```\\n'\n                    '\\n'\n                    'Alternatively, you can use the loss function '\n                    '`sparse_categorical_crossentropy` instead, '\n                    'which does expect integer targets.')\n        if loss in key_losses:\n            for target_dim, out_dim in zip(y.shape[1:], shape[1:]):\n                if out_dim is not None and target_dim != out_dim:\n                    raise ValueError(\n                        'A target array with shape ' + str(y.shape) +\n                        ' was passed for an output of shape ' + str(shape) +\n                        ' while using as loss `' + loss.__name__ + '`. '\n                        'This loss expects '\n                        'targets to have the same shape '\n                        'as the output.')",
        "begin_line": 251,
        "end_line": 298,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00037778617302606723,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.training_utils.collect_metrics#301",
        "src_path": "keras/engine/training_utils.py",
        "class_name": "keras.engine.training_utils",
        "signature": "keras.engine.training_utils.collect_metrics(metrics, output_names)",
        "snippet": "def collect_metrics(metrics, output_names):\n    \"\"\"Maps metric functions to model outputs.\n\n    # Arguments\n        metrics: a list or dict of metric functions.\n        output_names: a list of the names (strings) of model outputs.\n\n    # Returns\n        A list (one entry per model output) of lists of metric functions.\n        For instance, if the model has 2 outputs, and for the first output\n        we want to compute \"binary_accuracy\" and \"binary_crossentropy\",\n        and just \"binary_accuracy\" for the second output,\n        the list would look like:\n            `[[binary_accuracy, binary_crossentropy], [binary_accuracy]]`\n\n    # Raises\n        TypeError: if an incorrect type is passed for the `metrics` argument.\n    \"\"\"\n    if not metrics:\n        return [[] for _ in output_names]\n    if isinstance(metrics, list):\n        # we then apply all metrics to all outputs.\n        return [copy.copy(metrics) for _ in output_names]\n    elif isinstance(metrics, dict):\n        nested_metrics = []\n        if not set(metrics.keys()).issubset(set(output_names)):\n            unknown_output_names = list(set(metrics.keys()) - set(output_names))\n            warnings.warn('Invalid layer name for metric computations: '\n                          '{}. Available names are {}.'\n                          .format(unknown_output_names, output_names))\n        for name in output_names:\n            output_metrics = metrics.get(name, [])\n            output_metrics = to_list(output_metrics)\n            nested_metrics.append(output_metrics)\n        return nested_metrics\n    else:\n        raise TypeError('Type of `metrics` argument not understood. '\n                        'Expected a list or dictionary, found: ' +\n                        str(metrics))",
        "begin_line": 301,
        "end_line": 339,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.training_utils.make_batches#366",
        "src_path": "keras/engine/training_utils.py",
        "class_name": "keras.engine.training_utils",
        "signature": "keras.engine.training_utils.make_batches(size, batch_size)",
        "snippet": "def make_batches(size, batch_size):\n    \"\"\"Returns a list of batch indices (tuples of indices).\n\n    # Arguments\n        size: Integer, total size of the data to slice into batches.\n        batch_size: Integer, batch size.\n\n    # Returns\n        A list of tuples of array indices.\n    \"\"\"\n    num_batches = (size + batch_size - 1) // batch_size  # round up\n    return [(i * batch_size, min(size, (i + 1) * batch_size))\n            for i in range(num_batches)]",
        "begin_line": 366,
        "end_line": 378,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00036913990402362494,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.training_utils.weighted_masked_objective#381",
        "src_path": "keras/engine/training_utils.py",
        "class_name": "keras.engine.training_utils",
        "signature": "keras.engine.training_utils.weighted_masked_objective(fn)",
        "snippet": "def weighted_masked_objective(fn):\n    \"\"\"Adds support for masking and sample-weighting to an objective function.\n\n    It transforms an objective function `fn(y_true, y_pred)`\n    into a sample-weighted, cost-masked objective function\n    `fn(y_true, y_pred, weights, mask)`.\n\n    # Arguments\n        fn: The objective function to wrap,\n            with signature `fn(y_true, y_pred)`.\n\n    # Returns\n        A function with signature `fn(y_true, y_pred, weights, mask)`.\n    \"\"\"\n    if fn is None:\n        return None\n\n    def weighted(y_true, y_pred, weights, mask=None):\n        \"\"\"Wrapper function.\n\n        # Arguments\n            y_true: `y_true` argument of `fn`.\n            y_pred: `y_pred` argument of `fn`.\n            weights: Weights tensor.\n            mask: Mask tensor.\n\n        # Returns\n            Scalar tensor.\n        \"\"\"\n        # score_array has ndim >= 2\n        score_array = fn(y_true, y_pred)\n        if mask is not None:\n            # Cast the mask to floatX to avoid float64 upcasting in Theano\n            mask = K.cast(mask, K.floatx())\n            # mask should have the same shape as score_array\n            score_array *= mask\n            #  the loss per batch should be proportional\n            #  to the number of unmasked samples.\n            score_array /= K.mean(mask) + K.epsilon()\n\n        # apply sample weighting\n        if weights is not None:\n            # reduce score_array to same ndim as weight array\n            ndim = K.ndim(score_array)\n            weight_ndim = K.ndim(weights)\n            score_array = K.mean(score_array,\n                                 axis=list(range(weight_ndim, ndim)))\n            score_array *= weights\n            score_array /= K.mean(K.cast(K.not_equal(weights, 0), K.floatx()))\n        return K.mean(score_array)\n    return weighted",
        "begin_line": 381,
        "end_line": 431,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00029859659599880563,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.training_utils.weighted#398",
        "src_path": "keras/engine/training_utils.py",
        "class_name": "keras.engine.training_utils",
        "signature": "keras.engine.training_utils.weighted(y_true, y_pred, weights, mask=None)",
        "snippet": "    def weighted(y_true, y_pred, weights, mask=None):\n        \"\"\"Wrapper function.\n\n        # Arguments\n            y_true: `y_true` argument of `fn`.\n            y_pred: `y_pred` argument of `fn`.\n            weights: Weights tensor.\n            mask: Mask tensor.\n\n        # Returns\n            Scalar tensor.\n        \"\"\"\n        # score_array has ndim >= 2\n        score_array = fn(y_true, y_pred)\n        if mask is not None:\n            # Cast the mask to floatX to avoid float64 upcasting in Theano\n            mask = K.cast(mask, K.floatx())\n            # mask should have the same shape as score_array\n            score_array *= mask\n            #  the loss per batch should be proportional\n            #  to the number of unmasked samples.\n            score_array /= K.mean(mask) + K.epsilon()\n\n        # apply sample weighting\n        if weights is not None:\n            # reduce score_array to same ndim as weight array\n            ndim = K.ndim(score_array)\n            weight_ndim = K.ndim(weights)\n            score_array = K.mean(score_array,\n                                 axis=list(range(weight_ndim, ndim)))\n            score_array *= weights\n            score_array /= K.mean(K.cast(K.not_equal(weights, 0), K.floatx()))\n        return K.mean(score_array)",
        "begin_line": 398,
        "end_line": 430,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.training_utils.standardize_weights#434",
        "src_path": "keras/engine/training_utils.py",
        "class_name": "keras.engine.training_utils",
        "signature": "keras.engine.training_utils.standardize_weights(y, sample_weight=None, class_weight=None, sample_weight_mode=None)",
        "snippet": "def standardize_weights(y,\n                        sample_weight=None,\n                        class_weight=None,\n                        sample_weight_mode=None):\n    \"\"\"Performs sample weight validation and standardization.\n\n    Everything gets normalized to a single sample-wise (or timestep-wise)\n    weight array. If both `sample_weights` and `class_weights` are provided,\n    the weights are multiplied together.\n\n    # Arguments\n        y: Numpy array of model targets to be weighted.\n        sample_weight: User-provided `sample_weight` argument.\n        class_weight: User-provided `class_weight` argument.\n        sample_weight_mode: One of `None` or `\"temporal\"`.\n            `\"temporal\"` indicated that we expect 2D weight data\n            that will be applied to the last 2 dimensions of\n            the targets (i.e. we are weighting timesteps, not samples).\n\n    # Returns\n        A Numpy array of target weights, one entry per sample to weight.\n\n    # Raises\n        ValueError: In case of invalid user-provided arguments.\n    \"\"\"\n    if sample_weight_mode is not None:\n        if sample_weight_mode != 'temporal':\n            raise ValueError('\"sample_weight_mode '\n                             'should be None or \"temporal\". '\n                             'Found: ' + str(sample_weight_mode))\n        if len(y.shape) < 3:\n            raise ValueError('Found a sample_weight array for '\n                             'an input with shape ' +\n                             str(y.shape) + '. '\n                             'Timestep-wise sample weighting (use of '\n                             'sample_weight_mode=\"temporal\") is restricted to '\n                             'outputs that are at least 3D, i.e. that have '\n                             'a time dimension.')\n        if sample_weight is not None and len(sample_weight.shape) != 2:\n            raise ValueError('Found a sample_weight array with shape ' +\n                             str(sample_weight.shape) + '. '\n                             'In order to use timestep-wise sample weighting, '\n                             'you should pass a 2D sample_weight array.')\n    else:\n        if sample_weight is not None and len(sample_weight.shape) != 1:\n            raise ValueError('Found a sample_weight array with shape ' +\n                             str(sample_weight.shape) + '. '\n                             'In order to use timestep-wise sample weights, '\n                             'you should specify '\n                             'sample_weight_mode=\"temporal\" '\n                             'in compile(). If you just mean to use '\n                             'sample-wise weights, make sure your '\n                             'sample_weight array is 1D.')\n\n    if sample_weight is not None:\n        if len(sample_weight.shape) > len(y.shape):\n            raise ValueError('Found a sample_weight with shape' +\n                             str(sample_weight.shape) + '.'\n                             'Expected sample_weight with rank '\n                             'less than or equal to ' + str(len(y.shape)))\n\n        if y.shape[:sample_weight.ndim] != sample_weight.shape:\n            raise ValueError('Found a sample_weight array with shape ' +\n                             str(sample_weight.shape) +\n                             ' for an input with shape ' +\n                             str(y.shape) + '. '\n                             'sample_weight cannot be broadcast.')\n\n    class_sample_weight = None\n    if isinstance(class_weight, dict):\n        if len(y.shape) > 2:\n            raise ValueError('`class_weight` not supported for '\n                             '3+ dimensional targets.')\n        if len(y.shape) == 2:\n            if y.shape[1] > 1:\n                y_classes = np.argmax(y, axis=1)\n            elif y.shape[1] == 1:\n                y_classes = np.reshape(y, y.shape[0])\n        else:\n            y_classes = y\n\n        class_sample_weight = np.asarray(\n            [class_weight[cls] for cls in y_classes if cls in class_weight])\n\n        if len(class_sample_weight) != len(y_classes):\n            # subtract the sets to pick all missing classes\n            existing_classes = set(y_classes)\n            existing_class_weight = set(class_weight.keys())\n            raise ValueError('`class_weight` must contain '\n                             'all classes in the data.'\n                             ' The classes %s exist in the data but not in '\n                             '`class_weight`.'\n                             % (existing_classes - existing_class_weight))\n\n    if sample_weight is not None and class_sample_weight is not None:\n        return sample_weight * class_sample_weight\n    if sample_weight is not None:\n        return sample_weight\n    if class_sample_weight is not None:\n        return class_sample_weight\n\n    # Everything has weight 1 by default.\n    if sample_weight_mode is None:\n        return np.ones((y.shape[0],), dtype=K.floatx())\n    else:\n        return np.ones((y.shape[0], y.shape[1]), dtype=K.floatx())",
        "begin_line": 434,
        "end_line": 539,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.training_utils.check_num_samples#542",
        "src_path": "keras/engine/training_utils.py",
        "class_name": "keras.engine.training_utils",
        "signature": "keras.engine.training_utils.check_num_samples(ins, batch_size=None, steps=None, steps_name='steps')",
        "snippet": "def check_num_samples(ins,\n                      batch_size=None,\n                      steps=None,\n                      steps_name='steps'):\n    \"\"\"Checks the number of samples provided for training and evaluation.\n\n    The number of samples is not defined when running with `steps`,\n    in which case the number of samples is set to `None`.\n\n    # Arguments\n        ins: List of tensors to be fed to the Keras function.\n        batch_size: Integer batch size or `None` if not defined.\n        steps: Total number of steps (batches of samples)\n            before declaring `predict_loop` finished.\n            Ignored with the default value of `None`.\n        steps_name: The public API's parameter name for `steps`.\n\n    # Raises\n        ValueError: when `steps` is `None` and the attribute `ins.shape`\n        does not exist. Also raises ValueError when `steps` is not `None`\n        and `batch_size` is not `None` because they are mutually\n        exclusive.\n\n    # Returns\n        When `steps` is `None`, returns the number of samples to be\n        processed based on the size of the first dimension of the\n        first input Numpy array. When `steps` is not `None` and\n        `batch_size` is `None`, returns `None`.\n\n    # Raises\n        ValueError: In case of invalid arguments.\n    \"\"\"\n    if steps is not None and batch_size is not None:\n        raise ValueError(\n            'If ' + steps_name + ' is set, the `batch_size` must be None.')\n\n    if not ins or any(K.is_tensor(x) for x in ins):\n        if steps is None:\n            raise ValueError(\n                'If your data is in the form of symbolic tensors, '\n                'you should specify the `' + steps_name + '` argument '\n                '(instead of the `batch_size` argument, '\n                'because symbolic tensors are expected to produce '\n                'batches of input data).')\n        return None\n\n    if hasattr(ins[0], 'shape'):\n        return int(ins[0].shape[0])\n    return None  # Edge case where ins == [static_learning_phase]",
        "begin_line": 542,
        "end_line": 590,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00036913990402362494,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.training_utils.should_run_validation#621",
        "src_path": "keras/engine/training_utils.py",
        "class_name": "keras.engine.training_utils",
        "signature": "keras.engine.training_utils.should_run_validation(validation_freq, epoch)",
        "snippet": "def should_run_validation(validation_freq, epoch):\n    \"\"\"Checks if validation should be run this epoch.\n\n    Arguments:\n    validation_freq: Integer or list. If an integer, specifies how many training\n      epochs to run before a new validation run is performed. If a list,\n      specifies the epochs on which to run validation.\n    epoch: Integer, the number of the training epoch just completed.\n\n    Returns:\n    Bool, True if validation should be run.\n\n    Raises:\n    ValueError: if `validation_freq` is an Integer and less than 1, or if\n    it is neither an Integer nor a Sequence.\n    \"\"\"\n    # `epoch` is 0-indexed internally but 1-indexed in the public API.\n    one_indexed_epoch = epoch + 1\n\n    if isinstance(validation_freq, int):\n        if validation_freq < 1:\n            raise ValueError('`validation_freq` can not be less than 1.')\n        return one_indexed_epoch % validation_freq == 0\n\n    if not isinstance(validation_freq, collections.Container):\n        raise ValueError('`validation_freq` must be an Integer or '\n                         '`collections.Container` (e.g. list, tuple, etc.)')\n    return one_indexed_epoch in validation_freq",
        "begin_line": 621,
        "end_line": 648,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0006176652254478073,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.training.Model.compile#38",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model.compile(self, optimizer, loss=None, metrics=None, loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None, **kwargs)",
        "snippet": "    def compile(self, optimizer,\n                loss=None,\n                metrics=None,\n                loss_weights=None,\n                sample_weight_mode=None,\n                weighted_metrics=None,\n                target_tensors=None,\n                **kwargs):\n        \"\"\"Configures the model for training.\n\n        # Arguments\n            optimizer: String (name of optimizer) or optimizer instance.\n                See [optimizers](/optimizers).\n            loss: String (name of objective function) or objective function.\n                See [losses](/losses).\n                If the model has multiple outputs, you can use a different loss\n                on each output by passing a dictionary or a list of losses.\n                The loss value that will be minimized by the model\n                will then be the sum of all individual losses.\n            metrics: List of metrics to be evaluated by the model\n                during training and testing.\n                Typically you will use `metrics=['accuracy']`.\n                To specify different metrics for different outputs of a\n                multi-output model, you could also pass a dictionary,\n                such as `metrics={'output_a': 'accuracy'}`.\n            loss_weights: Optional list or dictionary specifying scalar\n                coefficients (Python floats) to weight the loss contributions\n                of different model outputs.\n                The loss value that will be minimized by the model\n                will then be the *weighted sum* of all individual losses,\n                weighted by the `loss_weights` coefficients.\n                If a list, it is expected to have a 1:1 mapping\n                to the model's outputs. If a dict, it is expected to map\n                output names (strings) to scalar coefficients.\n            sample_weight_mode: If you need to do timestep-wise\n                sample weighting (2D weights), set this to `\"temporal\"`.\n                `None` defaults to sample-wise weights (1D).\n                If the model has multiple outputs, you can use a different\n                `sample_weight_mode` on each output by passing a\n                dictionary or a list of modes.\n            weighted_metrics: List of metrics to be evaluated and weighted\n                by sample_weight or class_weight during training and testing.\n            target_tensors: By default, Keras will create placeholders for the\n                model's target, which will be fed with the target data during\n                training. If instead you would like to use your own\n                target tensors (in turn, Keras will not expect external\n                Numpy data for these targets at training time), you\n                can specify them via the `target_tensors` argument. It can be\n                a single tensor (for a single-output model), a list of tensors,\n                or a dict mapping output names to target tensors.\n            **kwargs: When using the Theano/CNTK backends, these arguments\n                are passed into `K.function`.\n                When using the TensorFlow backend,\n                these arguments are passed into `tf.Session.run`.\n\n        # Raises\n            ValueError: In case of invalid arguments for\n                `optimizer`, `loss`, `metrics` or `sample_weight_mode`.\n        \"\"\"\n        self.optimizer = optimizers.get(optimizer)\n        self.loss = loss or []\n        self.metrics = metrics or []\n        self.loss_weights = loss_weights\n        self.sample_weight_mode = sample_weight_mode\n        self.weighted_metrics = weighted_metrics\n\n        if not self.built:\n            # Model is not compilable because\n            # it does not know its number of inputs\n            # and outputs, nor their shapes and names.\n            # We will compile after the first\n            # time the model gets called on training data.\n            return\n        self._is_compiled = True\n\n        # Prepare loss functions.\n        if isinstance(loss, dict):\n            for name in loss:\n                if name not in self.output_names:\n                    raise ValueError('Unknown entry in loss '\n                                     'dictionary: \"' + name + '\". '\n                                     'Only expected the following keys: ' +\n                                     str(self.output_names))\n            loss_functions = []\n            for name in self.output_names:\n                if name not in loss:\n                    warnings.warn('Output \"' + name +\n                                  '\" missing from loss dictionary. '\n                                  'We assume this was done on purpose, '\n                                  'and we will not be expecting '\n                                  'any data to be passed to \"' + name +\n                                  '\" during training.', stacklevel=2)\n                loss_functions.append(losses.get(loss.get(name)))\n        elif isinstance(loss, list):\n            if len(loss) != len(self.outputs):\n                raise ValueError('When passing a list as loss, '\n                                 'it should have one entry per model outputs. '\n                                 'The model has ' + str(len(self.outputs)) +\n                                 ' outputs, but you passed loss=' +\n                                 str(loss))\n            loss_functions = [losses.get(l) for l in loss]\n        else:\n            loss_function = losses.get(loss)\n            loss_functions = [loss_function for _ in range(len(self.outputs))]\n        self.loss_functions = loss_functions\n        weighted_losses = [\n            weighted_masked_objective(fn) for fn in loss_functions]\n        skip_target_indices = []\n        skip_target_weighing_indices = []\n        self._feed_outputs = []\n        self._feed_output_names = []\n        self._feed_output_shapes = []\n        self._feed_loss_fns = []\n        for i in range(len(weighted_losses)):\n            if weighted_losses[i] is None:\n                skip_target_indices.append(i)\n                skip_target_weighing_indices.append(i)\n\n        # Prepare output masks.\n        masks = self.compute_mask(self.inputs, mask=None)\n        if masks is None:\n            masks = [None for _ in self.outputs]\n        masks = to_list(masks)\n\n        # Prepare loss weights.\n        if loss_weights is None:\n            loss_weights_list = [1. for _ in range(len(self.outputs))]\n        elif isinstance(loss_weights, dict):\n            for name in loss_weights:\n                if name not in self.output_names:\n                    raise ValueError('Unknown entry in loss_weights '\n                                     'dictionary: \"' + name + '\". '\n                                     'Only expected the following keys: ' +\n                                     str(self.output_names))\n            loss_weights_list = []\n            for name in self.output_names:\n                loss_weights_list.append(loss_weights.get(name, 1.))\n        elif isinstance(loss_weights, list):\n            if len(loss_weights) != len(self.outputs):\n                raise ValueError('When passing a list as loss_weights, '\n                                 'it should have one entry per model output. '\n                                 'The model has ' + str(len(self.outputs)) +\n                                 ' outputs, but you passed loss_weights=' +\n                                 str(loss_weights))\n            loss_weights_list = loss_weights\n        else:\n            raise TypeError('Could not interpret loss_weights argument: ' +\n                            str(loss_weights) +\n                            ' - expected a list of dicts.')\n\n        # Prepare targets of model.\n        self.targets = []\n        self._feed_targets = []\n        if target_tensors is not None:\n            if isinstance(target_tensors, list):\n                if len(target_tensors) != len(self.outputs):\n                    raise ValueError(\n                        'When passing a list as `target_tensors`, '\n                        'it should have one entry per model output. '\n                        'The model has ' + str(len(self.outputs)) +\n                        ' outputs, but you passed target_tensors=' +\n                        str(target_tensors))\n            elif isinstance(target_tensors, dict):\n                for name in target_tensors:\n                    if name not in self.output_names:\n                        raise ValueError('Unknown entry in `target_tensors` '\n                                         'dictionary: \"' + name + '\". '\n                                         'Only expected the following keys: ' +\n                                         str(self.output_names))\n                tmp_target_tensors = []\n                for name in self.output_names:\n                    tmp_target_tensors.append(target_tensors.get(name, None))\n                target_tensors = tmp_target_tensors\n            elif K.is_tensor(target_tensors):\n                if len(self.outputs) != 1:\n                    raise ValueError('The model has ' + str(len(self.outputs)) +\n                                     ' outputs, but you passed a single tensor as '\n                                     '`target_tensors`. Expected a list or a dict '\n                                     'of tensors.')\n                target_tensors = [target_tensors]\n            else:\n                raise TypeError('Expected `target_tensors` to be a tensor, '\n                                'a list of tensors, or dict of tensors, but got:',\n                                target_tensors)\n\n        for i in range(len(self.outputs)):\n            if i in skip_target_indices:\n                self.targets.append(None)\n            else:\n                shape = K.int_shape(self.outputs[i])\n                name = self.output_names[i]\n                if target_tensors is not None:\n                    target = target_tensors[i]\n                else:\n                    target = None\n                if target is None or K.is_placeholder(target):\n                    if target is None:\n                        target = K.placeholder(\n                            ndim=len(shape),\n                            name=name + '_target',\n                            sparse=K.is_sparse(self.outputs[i]),\n                            dtype=K.dtype(self.outputs[i]))\n                    self._feed_targets.append(target)\n                    self._feed_outputs.append(self.outputs[i])\n                    self._feed_output_names.append(name)\n                    self._feed_output_shapes.append(shape)\n                    self._feed_loss_fns.append(self.loss_functions[i])\n                else:\n                    skip_target_weighing_indices.append(i)\n                self.targets.append(target)\n\n        # Prepare sample weights.\n        sample_weights = []\n        sample_weight_modes = []\n        if isinstance(sample_weight_mode, dict):\n            for name in sample_weight_mode:\n                if name not in self.output_names:\n                    raise ValueError('Unknown entry in '\n                                     'sample_weight_mode dictionary: \"' +\n                                     name + '\". '\n                                     'Only expected the following keys: ' +\n                                     str(self.output_names))\n            for i, name in enumerate(self.output_names):\n                if i in skip_target_weighing_indices:\n                    weight = None\n                    sample_weight_modes.append(None)\n                else:\n                    if name not in sample_weight_mode:\n                        raise ValueError('Output \"' + name +\n                                         '\" missing from sample_weight_modes '\n                                         'dictionary')\n                    if sample_weight_mode.get(name) == 'temporal':\n                        weight = K.placeholder(ndim=2,\n                                               name=name + '_sample_weights')\n                        sample_weight_modes.append('temporal')\n                    else:\n                        weight = K.placeholder(ndim=1,\n                                               name=name + '_sample_weights')\n                        sample_weight_modes.append(None)\n                sample_weights.append(weight)\n        elif isinstance(sample_weight_mode, list):\n            if len(sample_weight_mode) != len(self.outputs):\n                raise ValueError('When passing a list as sample_weight_mode, '\n                                 'it should have one entry per model output. '\n                                 'The model has ' + str(len(self.outputs)) +\n                                 ' outputs, but you passed '\n                                 'sample_weight_mode=' +\n                                 str(sample_weight_mode))\n            for i in range(len(self.output_names)):\n                if i in skip_target_weighing_indices:\n                    weight = None\n                    sample_weight_modes.append(None)\n                else:\n                    mode = sample_weight_mode[i]\n                    name = self.output_names[i]\n                    if mode == 'temporal':\n                        weight = K.placeholder(ndim=2,\n                                               name=name + '_sample_weights')\n                        sample_weight_modes.append('temporal')\n                    else:\n                        weight = K.placeholder(ndim=1,\n                                               name=name + '_sample_weights')\n                        sample_weight_modes.append(None)\n                sample_weights.append(weight)\n        else:\n            for i, name in enumerate(self.output_names):\n                if i in skip_target_weighing_indices:\n                    sample_weight_modes.append(None)\n                    sample_weights.append(None)\n                else:\n                    if sample_weight_mode == 'temporal':\n                        sample_weights.append(\n                            K.placeholder(ndim=2,\n                                          name=name + '_sample_weights'))\n                        sample_weight_modes.append('temporal')\n                    else:\n                        sample_weights.append(\n                            K.placeholder(ndim=1,\n                                          name=name + '_sample_weights'))\n                        sample_weight_modes.append(None)\n        self.sample_weight_modes = sample_weight_modes\n        self._feed_sample_weight_modes = []\n        for i in range(len(self.outputs)):\n            if i not in skip_target_weighing_indices:\n                self._feed_sample_weight_modes.append(\n                    self.sample_weight_modes[i])\n\n        # Prepare metrics.\n        self.metrics_names = ['loss']\n        self.metrics_tensors = []\n\n        # Compute total loss.\n        total_loss = None\n        with K.name_scope('loss'):\n            for i in range(len(self.outputs)):\n                if i in skip_target_indices:\n                    continue\n                y_true = self.targets[i]\n                y_pred = self.outputs[i]\n                weighted_loss = weighted_losses[i]\n                sample_weight = sample_weights[i]\n                mask = masks[i]\n                loss_weight = loss_weights_list[i]\n                with K.name_scope(self.output_names[i] + '_loss'):\n                    output_loss = weighted_loss(y_true, y_pred,\n                                                sample_weight, mask)\n                if len(self.outputs) > 1:\n                    self.metrics_tensors.append(output_loss)\n                    self.metrics_names.append(self.output_names[i] + '_loss')\n                if total_loss is None:\n                    total_loss = loss_weight * output_loss\n                else:\n                    total_loss += loss_weight * output_loss\n            if total_loss is None:\n                if not self.losses:\n                    raise ValueError('The model cannot be compiled '\n                                     'because it has no loss to optimize.')\n                else:\n                    total_loss = 0.\n\n            # Add regularization penalties\n            # and other layer-specific losses.\n            for loss_tensor in self.losses:\n                total_loss += loss_tensor\n\n        # List of same size as output_names.\n        # contains tuples (metrics for output, names of metrics).\n        nested_metrics = collect_metrics(metrics, self.output_names)\n        nested_weighted_metrics = collect_metrics(weighted_metrics,\n                                                  self.output_names)\n        self.metrics_updates = []\n        self.stateful_metric_names = []\n        self.stateful_metric_functions = []\n\n        def handle_metrics(metrics, weights=None):\n            metric_name_prefix = 'weighted_' if weights is not None else ''\n\n            for metric in metrics:\n                if metric in ('accuracy', 'acc', 'crossentropy', 'ce'):\n                    # custom handling of accuracy/crossentropy\n                    # (because of class mode duality)\n                    output_shape = K.int_shape(self.outputs[i])\n                    if (output_shape[-1] == 1 or\n                       self.loss_functions[i] == losses.binary_crossentropy):\n                        # case: binary accuracy/crossentropy\n                        if metric in ('accuracy', 'acc'):\n                            metric_fn = metrics_module.binary_accuracy\n                        elif metric in ('crossentropy', 'ce'):\n                            metric_fn = metrics_module.binary_crossentropy\n                    elif (self.loss_functions[i] ==\n                          losses.sparse_categorical_crossentropy):\n                        # case: categorical accuracy/crossentropy\n                        # with sparse targets\n                        if metric in ('accuracy', 'acc'):\n                            metric_fn = metrics_module.sparse_categorical_accuracy\n                        elif metric in ('crossentropy', 'ce'):\n                            metric_fn = (\n                                metrics_module.sparse_categorical_crossentropy)\n                    else:\n                        # case: categorical accuracy/crossentropy\n                        if metric in ('accuracy', 'acc'):\n                            metric_fn = metrics_module.categorical_accuracy\n                        elif metric in ('crossentropy', 'ce'):\n                            metric_fn = metrics_module.categorical_crossentropy\n                    if metric in ('accuracy', 'acc'):\n                            suffix = 'acc'\n                    elif metric in ('crossentropy', 'ce'):\n                            suffix = 'ce'\n                    weighted_metric_fn = weighted_masked_objective(metric_fn)\n                    metric_name = metric_name_prefix + suffix\n                else:\n                    metric_fn = metrics_module.get(metric)\n                    weighted_metric_fn = weighted_masked_objective(metric_fn)\n                    # Get metric name as string\n                    if hasattr(metric_fn, 'name'):\n                        metric_name = metric_fn.name\n                    else:\n                        metric_name = metric_fn.__name__\n                    metric_name = metric_name_prefix + metric_name\n\n                with K.name_scope(metric_name):\n                    metric_result = weighted_metric_fn(y_true, y_pred,\n                                                       weights=weights,\n                                                       mask=masks[i])\n\n                # Append to self.metrics_names, self.metric_tensors,\n                # self.stateful_metric_names\n                if len(self.output_names) > 1:\n                    metric_name = self.output_names[i] + '_' + metric_name\n                # Dedupe name\n                j = 1\n                base_metric_name = metric_name\n                while metric_name in self.metrics_names:\n                    metric_name = base_metric_name + '_' + str(j)\n                    j += 1\n                self.metrics_names.append(metric_name)\n                self.metrics_tensors.append(metric_result)\n\n                # Keep track of state updates created by\n                # stateful metrics (i.e. metrics layers).\n                if isinstance(metric_fn, Layer) and metric_fn.stateful:\n                    self.stateful_metric_names.append(metric_name)\n                    self.stateful_metric_functions.append(metric_fn)\n                    self.metrics_updates += metric_fn.updates\n        with K.name_scope('metrics'):\n            for i in range(len(self.outputs)):\n                if i in skip_target_indices:\n                    continue\n\n                y_true = self.targets[i]\n                y_pred = self.outputs[i]\n                weights = sample_weights[i]\n                output_metrics = nested_metrics[i]\n                output_weighted_metrics = nested_weighted_metrics[i]\n                handle_metrics(output_metrics)\n                handle_metrics(output_weighted_metrics, weights=weights)\n\n        # Prepare gradient updates and state updates.\n        self.total_loss = total_loss\n        self.sample_weights = sample_weights\n        self._feed_sample_weights = []\n        for i in range(len(self.sample_weights)):\n            if i not in skip_target_weighing_indices:\n                self._feed_sample_weights.append(sample_weights[i])\n\n        # Functions for train, test and predict will\n        # be compiled lazily when required.\n        # This saves time when the user is not using all functions.\n        self._function_kwargs = kwargs\n\n        self.train_function = None\n        self.test_function = None\n        self.predict_function = None\n\n        # Collected trainable weights, sorted in topological order.\n        trainable_weights = self.trainable_weights\n        self._collected_trainable_weights = trainable_weights",
        "begin_line": 38,
        "end_line": 474,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.training.Model.handle_metrics#372",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model.handle_metrics(metrics, weights=None)",
        "snippet": "        def handle_metrics(metrics, weights=None):\n            metric_name_prefix = 'weighted_' if weights is not None else ''\n\n            for metric in metrics:\n                if metric in ('accuracy', 'acc', 'crossentropy', 'ce'):\n                    # custom handling of accuracy/crossentropy\n                    # (because of class mode duality)\n                    output_shape = K.int_shape(self.outputs[i])\n                    if (output_shape[-1] == 1 or\n                       self.loss_functions[i] == losses.binary_crossentropy):\n                        # case: binary accuracy/crossentropy\n                        if metric in ('accuracy', 'acc'):\n                            metric_fn = metrics_module.binary_accuracy\n                        elif metric in ('crossentropy', 'ce'):\n                            metric_fn = metrics_module.binary_crossentropy\n                    elif (self.loss_functions[i] ==\n                          losses.sparse_categorical_crossentropy):\n                        # case: categorical accuracy/crossentropy\n                        # with sparse targets\n                        if metric in ('accuracy', 'acc'):\n                            metric_fn = metrics_module.sparse_categorical_accuracy\n                        elif metric in ('crossentropy', 'ce'):\n                            metric_fn = (\n                                metrics_module.sparse_categorical_crossentropy)\n                    else:\n                        # case: categorical accuracy/crossentropy\n                        if metric in ('accuracy', 'acc'):\n                            metric_fn = metrics_module.categorical_accuracy\n                        elif metric in ('crossentropy', 'ce'):\n                            metric_fn = metrics_module.categorical_crossentropy\n                    if metric in ('accuracy', 'acc'):\n                            suffix = 'acc'\n                    elif metric in ('crossentropy', 'ce'):\n                            suffix = 'ce'\n                    weighted_metric_fn = weighted_masked_objective(metric_fn)\n                    metric_name = metric_name_prefix + suffix\n                else:\n                    metric_fn = metrics_module.get(metric)\n                    weighted_metric_fn = weighted_masked_objective(metric_fn)\n                    # Get metric name as string\n                    if hasattr(metric_fn, 'name'):\n                        metric_name = metric_fn.name\n                    else:\n                        metric_name = metric_fn.__name__\n                    metric_name = metric_name_prefix + metric_name\n\n                with K.name_scope(metric_name):\n                    metric_result = weighted_metric_fn(y_true, y_pred,\n                                                       weights=weights,\n                                                       mask=masks[i])\n\n                # Append to self.metrics_names, self.metric_tensors,\n                # self.stateful_metric_names\n                if len(self.output_names) > 1:\n                    metric_name = self.output_names[i] + '_' + metric_name\n                # Dedupe name\n                j = 1\n                base_metric_name = metric_name\n                while metric_name in self.metrics_names:\n                    metric_name = base_metric_name + '_' + str(j)\n                    j += 1\n                self.metrics_names.append(metric_name)\n                self.metrics_tensors.append(metric_result)\n\n                # Keep track of state updates created by\n                # stateful metrics (i.e. metrics layers).\n                if isinstance(metric_fn, Layer) and metric_fn.stateful:\n                    self.stateful_metric_names.append(metric_name)\n                    self.stateful_metric_functions.append(metric_fn)\n                    self.metrics_updates += metric_fn.updates",
        "begin_line": 372,
        "end_line": 441,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.training.Model._check_trainable_weights_consistency#476",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model._check_trainable_weights_consistency(self)",
        "snippet": "    def _check_trainable_weights_consistency(self):\n        \"\"\"Check trainable weights count consistency.\n\n        This will raise a warning if `trainable_weights` and\n        `_collected_trainable_weights` are inconsistent (i.e. have different\n        number of parameters).\n        Inconsistency will typically arise when one modifies `model.trainable`\n        without calling `model.compile` again.\n        \"\"\"\n        if not hasattr(self, '_collected_trainable_weights'):\n            return\n\n        if (len(self.trainable_weights) !=\n                len(self._collected_trainable_weights)):\n            warnings.warn(UserWarning(\n                'Discrepancy between trainable weights and collected trainable'\n                ' weights, did you set `model.trainable` without calling'\n                ' `model.compile` after ?'))",
        "begin_line": 476,
        "end_line": 493,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00034164673727365904,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.training.Model._make_train_function#495",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model._make_train_function(self)",
        "snippet": "    def _make_train_function(self):\n        if not hasattr(self, 'train_function'):\n            raise RuntimeError('You must compile your model before using it.')\n        self._check_trainable_weights_consistency()\n        if self.train_function is None:\n            inputs = (self._feed_inputs +\n                      self._feed_targets +\n                      self._feed_sample_weights)\n            if self._uses_dynamic_learning_phase():\n                inputs += [K.learning_phase()]\n\n            with K.name_scope('training'):\n                with K.name_scope(self.optimizer.__class__.__name__):\n                    training_updates = self.optimizer.get_updates(\n                        params=self._collected_trainable_weights,\n                        loss=self.total_loss)\n                updates = (self.updates +\n                           training_updates +\n                           self.metrics_updates)\n                # Gets loss and metrics. Updates weights at each call.\n                self.train_function = K.function(\n                    inputs,\n                    [self.total_loss] + self.metrics_tensors,\n                    updates=updates,\n                    name='train_function',\n                    **self._function_kwargs)",
        "begin_line": 495,
        "end_line": 520,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00034164673727365904,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.training.Model._make_test_function#522",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model._make_test_function(self)",
        "snippet": "    def _make_test_function(self):\n        if not hasattr(self, 'test_function'):\n            raise RuntimeError('You must compile your model before using it.')\n        if self.test_function is None:\n            inputs = (self._feed_inputs +\n                      self._feed_targets +\n                      self._feed_sample_weights)\n            if self._uses_dynamic_learning_phase():\n                inputs += [K.learning_phase()]\n            # Return loss and metrics, no gradient updates.\n            # Does update the network states.\n            self.test_function = K.function(\n                inputs,\n                [self.total_loss] + self.metrics_tensors,\n                updates=self.state_updates + self.metrics_updates,\n                name='test_function',\n                **self._function_kwargs)",
        "begin_line": 522,
        "end_line": 538,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0006176652254478073,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.training.Model._make_predict_function#540",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model._make_predict_function(self)",
        "snippet": "    def _make_predict_function(self):\n        if not hasattr(self, 'predict_function'):\n            self.predict_function = None\n        if self.predict_function is None:\n            if self._uses_dynamic_learning_phase():\n                inputs = self._feed_inputs + [K.learning_phase()]\n            else:\n                inputs = self._feed_inputs\n            # Gets network outputs. Does not update weights.\n            # Does update the network states.\n            kwargs = getattr(self, '_function_kwargs', {})\n            self.predict_function = K.function(inputs,\n                                               self.outputs,\n                                               updates=self.state_updates,\n                                               name='predict_function',\n                                               **kwargs)",
        "begin_line": 540,
        "end_line": 555,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0004144218814753419,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.training.Model._uses_dynamic_learning_phase#557",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model._uses_dynamic_learning_phase(self)",
        "snippet": "    def _uses_dynamic_learning_phase(self):\n        return (self.uses_learning_phase and\n                not isinstance(K.learning_phase(), int))",
        "begin_line": 557,
        "end_line": 559,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00031969309462915604,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.training.Model._standardize_user_data#644",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model._standardize_user_data(self, x, y=None, sample_weight=None, class_weight=None, check_array_lengths=True, batch_size=None)",
        "snippet": "    def _standardize_user_data(self, x,\n                               y=None,\n                               sample_weight=None,\n                               class_weight=None,\n                               check_array_lengths=True,\n                               batch_size=None):\n        all_inputs = []\n        if not self.built:\n            # We need to use `x` to set the model inputs.\n            # We type-check that `x` and `y` are either single arrays\n            # or lists of arrays.\n            if isinstance(x, (list, tuple)):\n                if not all(isinstance(v, np.ndarray) or\n                           K.is_tensor(v) for v in x):\n                    raise ValueError('Please provide as model inputs '\n                                     'either a single '\n                                     'array or a list of arrays. '\n                                     'You passed: x=' + str(x))\n                all_inputs += list(x)\n            elif isinstance(x, dict):\n                raise ValueError('Please do not pass a dictionary '\n                                 'as model inputs.')\n            else:\n                if not isinstance(x, np.ndarray) and not K.is_tensor(x):\n                    raise ValueError('Please provide as model inputs '\n                                     'either a single '\n                                     'array or a list of arrays. '\n                                     'You passed: x=' + str(x))\n                all_inputs.append(x)\n\n            # Build the model using the retrieved inputs (value or symbolic).\n            # If values, then in symbolic-mode placeholders will be created\n            # to match the value shapes.\n            if not self.inputs:\n                self._set_inputs(x)\n\n        if y is not None:\n            if not self.optimizer:\n                raise RuntimeError('You must compile a model before '\n                                   'training/testing. '\n                                   'Use `model.compile(optimizer, loss)`.')\n            if not self._is_compiled:\n                # On-the-fly compilation of the model.\n                # We need to use `y` to set the model targets.\n                if isinstance(y, (list, tuple)):\n                    if not all(isinstance(v, np.ndarray) or\n                               K.is_tensor(v) for v in y):\n                        raise ValueError('Please provide as model targets '\n                                         'either a single '\n                                         'array or a list of arrays. '\n                                         'You passed: y=' + str(y))\n                elif isinstance(y, dict):\n                    raise ValueError('Please do not pass a dictionary '\n                                     'as model targets.')\n                else:\n                    if not isinstance(y, np.ndarray) and not K.is_tensor(y):\n                        raise ValueError('Please provide as model targets '\n                                         'either a single '\n                                         'array or a list of arrays. '\n                                         'You passed: y=' + str(y))\n                # Typecheck that all inputs are *either* value *or* symbolic.\n                if y is not None:\n                    all_inputs += to_list(y, allow_tuple=True)\n                if any(K.is_tensor(v) for v in all_inputs):\n                    if not all(K.is_tensor(v) for v in all_inputs):\n                        raise ValueError('Do not pass inputs that mix Numpy '\n                                         'arrays and symbolic tensors. '\n                                         'You passed: x=' + str(x) +\n                                         '; y=' + str(y))\n\n                # Handle target tensors if any passed.\n                y = to_list(y, allow_tuple=True)\n                target_tensors = [v for v in y if K.is_tensor(v)]\n                if not target_tensors:\n                    target_tensors = None\n                self.compile(optimizer=self.optimizer,\n                             loss=self.loss,\n                             metrics=self.metrics,\n                             loss_weights=self.loss_weights,\n                             target_tensors=target_tensors)\n\n        # If `x` and `y` were all symbolic,\n        # then the model should not be fed any inputs and targets.\n        # Note: in this case, `any` and `all` are equivalent since we disallow\n        # mixed symbolic/value inputs.\n        if any(K.is_tensor(v) for v in all_inputs):\n            return [], [], []\n\n        # What follows is input validation and standardization to list format,\n        # in the case where all inputs are value arrays.\n\n        if not self._is_graph_network:\n            # Case: symbolic-mode subclassed network.\n            # Do not do shape validation.\n            feed_input_names = self._feed_input_names\n            feed_input_shapes = None\n        else:\n            # Case: symbolic-mode graph network.\n            # In this case, we run extensive shape validation checks.\n            feed_input_names = self._feed_input_names\n            feed_input_shapes = self._feed_input_shapes\n\n        # Standardize the inputs.\n        x = standardize_input_data(\n            x,\n            feed_input_names,\n            feed_input_shapes,\n            check_batch_axis=False,  # Don't enforce the batch size.\n            exception_prefix='input')\n\n        if y is not None:\n            if not self._is_graph_network:\n                feed_output_names = self._feed_output_names\n                feed_output_shapes = None\n                # Sample weighting not supported in this case.\n                # TODO: consider supporting it.\n                feed_sample_weight_modes = [None for _ in self.outputs]\n            else:\n                feed_output_names = self._feed_output_names\n                feed_sample_weight_modes = self._feed_sample_weight_modes\n                feed_output_shapes = []\n                for output_shape, loss_fn in zip(self._feed_output_shapes,\n                                                 self._feed_loss_fns):\n                    if loss_fn is losses.sparse_categorical_crossentropy:\n                        if K.image_data_format() == 'channels_first' and len(\n                                output_shape) in [4, 5]:\n                            feed_output_shapes.append(\n                                (output_shape[0], 1) + output_shape[2:])\n                        else:\n                            feed_output_shapes.append(output_shape[:-1] + (1,))\n                    elif (not hasattr(loss_fn, '__name__') or\n                            getattr(losses, loss_fn.__name__, None) is None):\n                        # If `loss_fn` is not a function (e.g. callable class)\n                        # or if it not in the `losses` module, then\n                        # it is a user-defined loss and we make no assumptions\n                        # about it.\n                        feed_output_shapes.append(None)\n                    else:\n                        feed_output_shapes.append(output_shape)\n\n            # Standardize the outputs.\n            y = standardize_input_data(\n                y,\n                feed_output_names,\n                feed_output_shapes,\n                check_batch_axis=False,  # Don't enforce the batch size.\n                exception_prefix='target')\n\n            # Generate sample-wise weight values given the `sample_weight` and\n            # `class_weight` arguments.\n            sample_weights = standardize_sample_weights(\n                sample_weight, feed_output_names)\n            class_weights = standardize_class_weights(\n                class_weight, feed_output_names)\n            sample_weights = [\n                standardize_weights(ref, sw, cw, mode)\n                for (ref, sw, cw, mode) in\n                zip(y, sample_weights, class_weights,\n                    feed_sample_weight_modes)\n            ]\n            # Check that all arrays have the same length.\n            if check_array_lengths:\n                check_array_length_consistency(x, y, sample_weights)\n            if self._is_graph_network:\n                # Additional checks to avoid users mistakenly\n                # using improper loss fns.\n                check_loss_and_target_compatibility(\n                    y, self._feed_loss_fns, feed_output_shapes)\n        else:\n            y = []\n            sample_weights = []\n\n        if self.stateful and batch_size:\n            # Check that for stateful networks, number of samples is a multiple\n            # of the static batch size.\n            if x[0].shape[0] % batch_size != 0:\n                raise ValueError('In a stateful network, '\n                                 'you should only pass inputs with '\n                                 'a number of samples that can be '\n                                 'divided by the batch size. Found: ' +\n                                 str(x[0].shape[0]) + ' samples')\n        return x, y, sample_weights",
        "begin_line": 644,
        "end_line": 825,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.training.Model._get_callback_model#827",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model._get_callback_model(self)",
        "snippet": "    def _get_callback_model(self):\n        \"\"\"Returns the Callback Model for this Model.\"\"\"\n        if hasattr(self, 'callback_model') and self.callback_model:\n            return self.callback_model\n        return self",
        "begin_line": 827,
        "end_line": 831,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00036913990402362494,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.training.Model.fit#833",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model.fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_freq=1, **kwargs)",
        "snippet": "    def fit(self,\n            x=None,\n            y=None,\n            batch_size=None,\n            epochs=1,\n            verbose=1,\n            callbacks=None,\n            validation_split=0.,\n            validation_data=None,\n            shuffle=True,\n            class_weight=None,\n            sample_weight=None,\n            initial_epoch=0,\n            steps_per_epoch=None,\n            validation_steps=None,\n            validation_freq=1,\n            **kwargs):\n        \"\"\"Trains the model for a given number of epochs (iterations on a dataset).\n\n        # Arguments\n            x: Numpy array of training data (if the model has a single input),\n                or list of Numpy arrays (if the model has multiple inputs).\n                If input layers in the model are named, you can also pass a\n                dictionary mapping input names to Numpy arrays.\n                `x` can be `None` (default) if feeding from\n                framework-native tensors (e.g. TensorFlow data tensors).\n            y: Numpy array of target (label) data\n                (if the model has a single output),\n                or list of Numpy arrays (if the model has multiple outputs).\n                If output layers in the model are named, you can also pass a\n                dictionary mapping output names to Numpy arrays.\n                `y` can be `None` (default) if feeding from\n                framework-native tensors (e.g. TensorFlow data tensors).\n            batch_size: Integer or `None`.\n                Number of samples per gradient update.\n                If unspecified, `batch_size` will default to 32.\n            epochs: Integer. Number of epochs to train the model.\n                An epoch is an iteration over the entire `x` and `y`\n                data provided.\n                Note that in conjunction with `initial_epoch`,\n                `epochs` is to be understood as \"final epoch\".\n                The model is not trained for a number of iterations\n                given by `epochs`, but merely until the epoch\n                of index `epochs` is reached.\n            verbose: Integer. 0, 1, or 2. Verbosity mode.\n                0 = silent, 1 = progress bar, 2 = one line per epoch.\n            callbacks: List of `keras.callbacks.Callback` instances.\n                List of callbacks to apply during training and validation\n                (if ).\n                See [callbacks](/callbacks).\n            validation_split: Float between 0 and 1.\n                Fraction of the training data to be used as validation data.\n                The model will set apart this fraction of the training data,\n                will not train on it, and will evaluate\n                the loss and any model metrics\n                on this data at the end of each epoch.\n                The validation data is selected from the last samples\n                in the `x` and `y` data provided, before shuffling.\n            validation_data: tuple `(x_val, y_val)` or tuple\n                `(x_val, y_val, val_sample_weights)` on which to evaluate\n                the loss and any model metrics at the end of each epoch.\n                The model will not be trained on this data.\n                `validation_data` will override `validation_split`.\n            shuffle: Boolean (whether to shuffle the training data\n                before each epoch) or str (for 'batch').\n                'batch' is a special option for dealing with the\n                limitations of HDF5 data; it shuffles in batch-sized chunks.\n                Has no effect when `steps_per_epoch` is not `None`.\n            class_weight: Optional dictionary mapping class indices (integers)\n                to a weight (float) value, used for weighting the loss function\n                (during training only).\n                This can be useful to tell the model to\n                \"pay more attention\" to samples from\n                an under-represented class.\n            sample_weight: Optional Numpy array of weights for\n                the training samples, used for weighting the loss function\n                (during training only). You can either pass a flat (1D)\n                Numpy array with the same length as the input samples\n                (1:1 mapping between weights and samples),\n                or in the case of temporal data,\n                you can pass a 2D array with shape\n                `(samples, sequence_length)`,\n                to apply a different weight to every timestep of every sample.\n                In this case you should make sure to specify\n                `sample_weight_mode=\"temporal\"` in `compile()`.\n            initial_epoch: Integer.\n                Epoch at which to start training\n                (useful for resuming a previous training run).\n            steps_per_epoch: Integer or `None`.\n                Total number of steps (batches of samples)\n                before declaring one epoch finished and starting the\n                next epoch. When training with input tensors such as\n                TensorFlow data tensors, the default `None` is equal to\n                the number of samples in your dataset divided by\n                the batch size, or 1 if that cannot be determined.\n            validation_steps: Only relevant if `steps_per_epoch`\n                is specified. Total number of steps (batches of samples)\n                to validate before stopping.\n            validation_freq: Only relevant if validation data is provided. Integer\n                or list/tuple/set. If an integer, specifies how many training\n                epochs to run before a new validation run is performed, e.g.\n                `validation_freq=2` runs validation every 2 epochs. If a list,\n                tuple, or set, specifies the epochs on which to run validation,\n                e.g. `validation_freq=[1, 2, 10]` runs validation at the end\n                of the 1st, 2nd, and 10th epochs.\n\n        # Returns\n            A `History` object. Its `History.history` attribute is\n            a record of training loss values and metrics values\n            at successive epochs, as well as validation loss values\n            and validation metrics values (if applicable).\n\n        # Raises\n            RuntimeError: If the model was never compiled.\n            ValueError: In case of mismatch between the provided input data\n                and what the model expects.\n        \"\"\"\n        # Backwards compatibility\n        if batch_size is None and steps_per_epoch is None:\n            batch_size = 32\n        # Legacy support\n        if 'nb_epoch' in kwargs:\n            warnings.warn('The `nb_epoch` argument in `fit` '\n                          'has been renamed `epochs`.', stacklevel=2)\n            epochs = kwargs.pop('nb_epoch')\n        if kwargs:\n            raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\n        if x is None and y is None and steps_per_epoch is None:\n            raise ValueError('If fitting from data tensors, '\n                             'you should specify the `steps_per_epoch` '\n                             'argument.')\n        # Validate user data.\n        x, y, sample_weights = self._standardize_user_data(\n            x, y,\n            sample_weight=sample_weight,\n            class_weight=class_weight,\n            batch_size=batch_size)\n        # Prepare validation data.\n        do_validation = False\n        if validation_data:\n            do_validation = True\n            if len(validation_data) == 2:\n                val_x, val_y = validation_data\n                val_sample_weight = None\n            elif len(validation_data) == 3:\n                val_x, val_y, val_sample_weight = validation_data\n            else:\n                raise ValueError('When passing validation_data, '\n                                 'it must contain 2 (x_val, y_val) '\n                                 'or 3 (x_val, y_val, val_sample_weights) '\n                                 'items, however it contains %d items' %\n                                 len(validation_data))\n\n            val_x, val_y, val_sample_weights = self._standardize_user_data(\n                val_x, val_y,\n                sample_weight=val_sample_weight,\n                batch_size=batch_size)\n            if self._uses_dynamic_learning_phase():\n                val_inputs = val_x + val_y + val_sample_weights + [0]\n            else:\n                val_inputs = val_x + val_y + val_sample_weights\n\n        elif validation_split and 0. < validation_split < 1.:\n            if any(K.is_tensor(t) for t in x):\n                raise ValueError(\n                    'If your data is in the form of symbolic tensors, '\n                    'you cannot use `validation_split`.')\n            do_validation = True\n            if hasattr(x[0], 'shape'):\n                split_at = int(int(x[0].shape[0]) * (1. - validation_split))\n            else:\n                split_at = int(len(x[0]) * (1. - validation_split))\n            x, val_x = (slice_arrays(x, 0, split_at),\n                        slice_arrays(x, split_at))\n            y, val_y = (slice_arrays(y, 0, split_at),\n                        slice_arrays(y, split_at))\n            sample_weights, val_sample_weights = (\n                slice_arrays(sample_weights, 0, split_at),\n                slice_arrays(sample_weights, split_at))\n            if self._uses_dynamic_learning_phase():\n                val_inputs = val_x + val_y + val_sample_weights + [0]\n            else:\n                val_inputs = val_x + val_y + val_sample_weights\n\n        elif validation_steps:\n            do_validation = True\n            if self._uses_dynamic_learning_phase():\n                val_inputs = [0.]\n\n        # Prepare input arrays and training function.\n        if self._uses_dynamic_learning_phase():\n            fit_inputs = x + y + sample_weights + [1]\n        else:\n            fit_inputs = x + y + sample_weights\n        self._make_train_function()\n        fit_function = self.train_function\n\n        # Prepare display labels.\n        out_labels = self.metrics_names\n\n        if do_validation:\n            self._make_test_function()\n            val_function = self.test_function\n            callback_metrics = copy.copy(out_labels) + [\n                'val_' + n for n in out_labels]\n        else:\n            callback_metrics = copy.copy(out_labels)\n            val_function = None\n            val_inputs = []\n\n        # Delegate logic to `fit_loop`.\n        return training_arrays.fit_loop(self, fit_function, fit_inputs,\n                                        out_labels=out_labels,\n                                        batch_size=batch_size,\n                                        epochs=epochs,\n                                        verbose=verbose,\n                                        callbacks=callbacks,\n                                        val_function=val_function,\n                                        val_inputs=val_inputs,\n                                        shuffle=shuffle,\n                                        callback_metrics=callback_metrics,\n                                        initial_epoch=initial_epoch,\n                                        steps_per_epoch=steps_per_epoch,\n                                        validation_steps=validation_steps,\n                                        validation_freq=validation_freq)",
        "begin_line": 833,
        "end_line": 1057,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.training.Model.evaluate#1059",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model.evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None)",
        "snippet": "    def evaluate(self, x=None, y=None,\n                 batch_size=None,\n                 verbose=1,\n                 sample_weight=None,\n                 steps=None,\n                 callbacks=None):\n        \"\"\"Returns the loss value & metrics values for the model in test mode.\n\n        Computation is done in batches.\n\n        # Arguments\n            x: Numpy array of test data (if the model has a single input),\n                or list of Numpy arrays (if the model has multiple inputs).\n                If input layers in the model are named, you can also pass a\n                dictionary mapping input names to Numpy arrays.\n                `x` can be `None` (default) if feeding from\n                framework-native tensors (e.g. TensorFlow data tensors).\n            y: Numpy array of target (label) data\n                (if the model has a single output),\n                or list of Numpy arrays (if the model has multiple outputs).\n                If output layers in the model are named, you can also pass a\n                dictionary mapping output names to Numpy arrays.\n                `y` can be `None` (default) if feeding from\n                framework-native tensors (e.g. TensorFlow data tensors).\n            batch_size: Integer or `None`.\n                Number of samples per evaluation step.\n                If unspecified, `batch_size` will default to 32.\n            verbose: 0 or 1. Verbosity mode.\n                0 = silent, 1 = progress bar.\n            sample_weight: Optional Numpy array of weights for\n                the test samples, used for weighting the loss function.\n                You can either pass a flat (1D)\n                Numpy array with the same length as the input samples\n                (1:1 mapping between weights and samples),\n                or in the case of temporal data,\n                you can pass a 2D array with shape\n                `(samples, sequence_length)`,\n                to apply a different weight to every timestep of every sample.\n                In this case you should make sure to specify\n                `sample_weight_mode=\"temporal\"` in `compile()`.\n            steps: Integer or `None`.\n                Total number of steps (batches of samples)\n                before declaring the evaluation round finished.\n                Ignored with the default value of `None`.\n            callbacks: List of `keras.callbacks.Callback` instances.\n                List of callbacks to apply during evaluation.\n                See [callbacks](/callbacks).\n\n        # Returns\n            Scalar test loss (if the model has a single output and no metrics)\n            or list of scalars (if the model has multiple outputs\n            and/or metrics). The attribute `model.metrics_names` will give you\n            the display labels for the scalar outputs.\n        \"\"\"\n        # Backwards compatibility.\n        if batch_size is None and steps is None:\n            batch_size = 32\n        if x is None and y is None and steps is None:\n            raise ValueError('If evaluating from data tensors, '\n                             'you should specify the `steps` '\n                             'argument.')\n        # Validate user data.\n        x, y, sample_weights = self._standardize_user_data(\n            x, y,\n            sample_weight=sample_weight,\n            batch_size=batch_size)\n        # Prepare inputs, delegate logic to `test_loop`.\n        if self._uses_dynamic_learning_phase():\n            ins = x + y + sample_weights + [0]\n        else:\n            ins = x + y + sample_weights\n        self._make_test_function()\n        f = self.test_function\n        return training_arrays.test_loop(self, f, ins,\n                                         batch_size=batch_size,\n                                         verbose=verbose,\n                                         steps=steps,\n                                         callbacks=callbacks)",
        "begin_line": 1059,
        "end_line": 1136,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0006176652254478073,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.training.Model.predict#1138",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model.predict(self, x, batch_size=None, verbose=0, steps=None, callbacks=None)",
        "snippet": "    def predict(self, x,\n                batch_size=None,\n                verbose=0,\n                steps=None,\n                callbacks=None):\n        \"\"\"Generates output predictions for the input samples.\n\n        Computation is done in batches.\n\n        # Arguments\n            x: The input data, as a Numpy array\n                (or list of Numpy arrays if the model has multiple inputs).\n            batch_size: Integer. If unspecified, it will default to 32.\n            verbose: Verbosity mode, 0 or 1.\n            steps: Total number of steps (batches of samples)\n                before declaring the prediction round finished.\n                Ignored with the default value of `None`.\n            callbacks: List of `keras.callbacks.Callback` instances.\n                List of callbacks to apply during prediction.\n                See [callbacks](/callbacks).\n\n        # Returns\n            Numpy array(s) of predictions.\n\n        # Raises\n            ValueError: In case of mismatch between the provided\n                input data and the model's expectations,\n                or in case a stateful model receives a number of samples\n                that is not a multiple of the batch size.\n        \"\"\"\n        # Backwards compatibility.\n        if batch_size is None and steps is None:\n            batch_size = 32\n        if x is None and steps is None:\n            raise ValueError('If predicting from data tensors, '\n                             'you should specify the `steps` '\n                             'argument.')\n        # Validate user data.\n        x, _, _ = self._standardize_user_data(x)\n        if self.stateful:\n            if x[0].shape[0] > batch_size and x[0].shape[0] % batch_size != 0:\n                raise ValueError('In a stateful network, '\n                                 'you should only pass inputs with '\n                                 'a number of samples that can be '\n                                 'divided by the batch size. Found: ' +\n                                 str(x[0].shape[0]) + ' samples. '\n                                 'Batch size: ' + str(batch_size) + '.')\n\n        # Prepare inputs, delegate logic to `predict_loop`.\n        if self._uses_dynamic_learning_phase():\n            ins = x + [0]\n        else:\n            ins = x\n        self._make_predict_function()\n        f = self.predict_function\n        return training_arrays.predict_loop(self, f, ins,\n                                            batch_size=batch_size,\n                                            verbose=verbose,\n                                            steps=steps,\n                                            callbacks=callbacks)",
        "begin_line": 1138,
        "end_line": 1197,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0004144218814753419,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.training.Model.train_on_batch#1199",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model.train_on_batch(self, x, y, sample_weight=None, class_weight=None)",
        "snippet": "    def train_on_batch(self, x, y,\n                       sample_weight=None,\n                       class_weight=None):\n        \"\"\"Runs a single gradient update on a single batch of data.\n\n        # Arguments\n            x: Numpy array of training data,\n                or list of Numpy arrays if the model has multiple inputs.\n                If all inputs in the model are named,\n                you can also pass a dictionary\n                mapping input names to Numpy arrays.\n            y: Numpy array of target data,\n                or list of Numpy arrays if the model has multiple outputs.\n                If all outputs in the model are named,\n                you can also pass a dictionary\n                mapping output names to Numpy arrays.\n            sample_weight: Optional array of the same length as x, containing\n                weights to apply to the model's loss for each sample.\n                In the case of temporal data, you can pass a 2D array\n                with shape (samples, sequence_length),\n                to apply a different weight to every timestep of every sample.\n                In this case you should make sure to specify\n                sample_weight_mode=\"temporal\" in compile().\n            class_weight: Optional dictionary mapping\n                class indices (integers) to\n                a weight (float) to apply to the model's loss for the samples\n                from this class during training.\n                This can be useful to tell the model to \"pay more attention\" to\n                samples from an under-represented class.\n\n        # Returns\n            Scalar training loss\n            (if the model has a single output and no metrics)\n            or list of scalars (if the model has multiple outputs\n            and/or metrics). The attribute `model.metrics_names` will give you\n            the display labels for the scalar outputs.\n        \"\"\"\n        x, y, sample_weights = self._standardize_user_data(\n            x, y,\n            sample_weight=sample_weight,\n            class_weight=class_weight)\n        if self._uses_dynamic_learning_phase():\n            ins = x + y + sample_weights + [1]\n        else:\n            ins = x + y + sample_weights\n        self._make_train_function()\n        outputs = self.train_function(ins)\n        return unpack_singleton(outputs)",
        "begin_line": 1199,
        "end_line": 1246,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00038387715930902113,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.training.Model.test_on_batch#1248",
        "src_path": "keras/engine/training.py",
        "class_name": "keras.engine.training.Model",
        "signature": "keras.engine.training.Model.test_on_batch(self, x, y, sample_weight=None)",
        "snippet": "    def test_on_batch(self, x, y, sample_weight=None):\n        \"\"\"Test the model on a single batch of samples.\n\n        # Arguments\n            x: Numpy array of test data,\n                or list of Numpy arrays if the model has multiple inputs.\n                If all inputs in the model are named,\n                you can also pass a dictionary\n                mapping input names to Numpy arrays.\n            y: Numpy array of target data,\n                or list of Numpy arrays if the model has multiple outputs.\n                If all outputs in the model are named,\n                you can also pass a dictionary\n                mapping output names to Numpy arrays.\n            sample_weight: Optional array of the same length as x, containing\n                weights to apply to the model's loss for each sample.\n                In the case of temporal data, you can pass a 2D array\n                with shape (samples, sequence_length),\n                to apply a different weight to every timestep of every sample.\n                In this case you should make sure to specify\n                sample_weight_mode=\"temporal\" in compile().\n\n        # Returns\n            Scalar test loss (if the model has a single output and no metrics)\n            or list of scalars (if the model has multiple outputs\n            and/or metrics). The attribute `model.metrics_names` will give you\n            the display labels for the scalar outputs.\n        \"\"\"\n        x, y, sample_weights = self._standardize_user_data(\n            x, y,\n            sample_weight=sample_weight)\n        if self._uses_dynamic_learning_phase():\n            ins = x + y + sample_weights + [0]\n        else:\n            ins = x + y + sample_weights\n        self._make_test_function()\n        outputs = self.test_function(ins)\n        return unpack_singleton(outputs)",
        "begin_line": 1248,
        "end_line": 1285,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0006756756756756757,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.convolutional._Conv.__init__#88",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional._Conv",
        "signature": "keras.layers.convolutional._Conv.__init__(self, rank, filters, kernel_size, strides=1, padding='valid', data_format=None, dilation_rate=1, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)",
        "snippet": "    def __init__(self, rank,\n                 filters,\n                 kernel_size,\n                 strides=1,\n                 padding='valid',\n                 data_format=None,\n                 dilation_rate=1,\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(_Conv, self).__init__(**kwargs)\n        self.rank = rank\n        self.filters = filters\n        self.kernel_size = conv_utils.normalize_tuple(kernel_size, rank,\n                                                      'kernel_size')\n        self.strides = conv_utils.normalize_tuple(strides, rank, 'strides')\n        self.padding = conv_utils.normalize_padding(padding)\n        self.data_format = K.normalize_data_format(data_format)\n        self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, rank,\n                                                        'dilation_rate')\n        self.activation = activations.get(activation)\n        self.use_bias = use_bias\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n        self.input_spec = InputSpec(ndim=self.rank + 2)",
        "begin_line": 88,
        "end_line": 124,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.convolutional._Conv.build#126",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional._Conv",
        "signature": "keras.layers.convolutional._Conv.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        if self.data_format == 'channels_first':\n            channel_axis = 1\n        else:\n            channel_axis = -1\n        if input_shape[channel_axis] is None:\n            raise ValueError('The channel dimension of the inputs '\n                             'should be defined. Found `None`.')\n        input_dim = input_shape[channel_axis]\n        kernel_shape = self.kernel_size + (input_dim, self.filters)\n\n        self.kernel = self.add_weight(shape=kernel_shape,\n                                      initializer=self.kernel_initializer,\n                                      name='kernel',\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(self.filters,),\n                                        initializer=self.bias_initializer,\n                                        name='bias',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        # Set input spec.\n        self.input_spec = InputSpec(ndim=self.rank + 2,\n                                    axes={channel_axis: input_dim})\n        self.built = True",
        "begin_line": 126,
        "end_line": 153,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.convolutional._Conv.call#155",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional._Conv",
        "signature": "keras.layers.convolutional._Conv.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        if self.rank == 1:\n            outputs = K.conv1d(\n                inputs,\n                self.kernel,\n                strides=self.strides[0],\n                padding=self.padding,\n                data_format=self.data_format,\n                dilation_rate=self.dilation_rate[0])\n        if self.rank == 2:\n            outputs = K.conv2d(\n                inputs,\n                self.kernel,\n                strides=self.strides,\n                padding=self.padding,\n                data_format=self.data_format,\n                dilation_rate=self.dilation_rate)\n        if self.rank == 3:\n            outputs = K.conv3d(\n                inputs,\n                self.kernel,\n                strides=self.strides,\n                padding=self.padding,\n                data_format=self.data_format,\n                dilation_rate=self.dilation_rate)\n\n        if self.use_bias:\n            outputs = K.bias_add(\n                outputs,\n                self.bias,\n                data_format=self.data_format)\n\n        if self.activation is not None:\n            return self.activation(outputs)\n        return outputs",
        "begin_line": 155,
        "end_line": 189,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.convolutional._Conv.compute_output_shape#191",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional._Conv",
        "signature": "keras.layers.convolutional._Conv.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self.data_format == 'channels_last':\n            space = input_shape[1:-1]\n            new_space = []\n            for i in range(len(space)):\n                new_dim = conv_utils.conv_output_length(\n                    space[i],\n                    self.kernel_size[i],\n                    padding=self.padding,\n                    stride=self.strides[i],\n                    dilation=self.dilation_rate[i])\n                new_space.append(new_dim)\n            return (input_shape[0],) + tuple(new_space) + (self.filters,)\n        if self.data_format == 'channels_first':\n            space = input_shape[2:]\n            new_space = []\n            for i in range(len(space)):\n                new_dim = conv_utils.conv_output_length(\n                    space[i],\n                    self.kernel_size[i],\n                    padding=self.padding,\n                    stride=self.strides[i],\n                    dilation=self.dilation_rate[i])\n                new_space.append(new_dim)\n            return (input_shape[0], self.filters) + tuple(new_space)",
        "begin_line": 191,
        "end_line": 215,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.convolutional.Conv2D.__init__#458",
        "src_path": "keras/layers/convolutional.py",
        "class_name": "keras.layers.convolutional.Conv2D",
        "signature": "keras.layers.convolutional.Conv2D.__init__(self, filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)",
        "snippet": "    def __init__(self, filters,\n                 kernel_size,\n                 strides=(1, 1),\n                 padding='valid',\n                 data_format=None,\n                 dilation_rate=(1, 1),\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(Conv2D, self).__init__(\n            rank=2,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=padding,\n            data_format=data_format,\n            dilation_rate=dilation_rate,\n            activation=activation,\n            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            kernel_constraint=kernel_constraint,\n            bias_constraint=bias_constraint,\n            **kwargs)",
        "begin_line": 458,
        "end_line": 491,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.utils.layer_utils.get_source_inputs#252",
        "src_path": "keras/utils/layer_utils.py",
        "class_name": "keras.utils.layer_utils",
        "signature": "keras.utils.layer_utils.get_source_inputs(tensor, layer=None, node_index=None)",
        "snippet": "def get_source_inputs(tensor, layer=None, node_index=None):\n    \"\"\"Returns the list of input tensors necessary to compute `tensor`.\n\n    Output will always be a list of tensors\n    (potentially with 1 element).\n\n    # Arguments\n        tensor: The tensor to start from.\n        layer: Origin layer of the tensor. Will be\n            determined via tensor._keras_history if not provided.\n        node_index: Origin node index of the tensor.\n\n    # Returns\n        List of input tensors.\n    \"\"\"\n    if not hasattr(tensor, '_keras_history'):\n        return tensor\n\n    if layer is None or node_index:\n        layer, node_index, _ = tensor._keras_history\n    if not layer._inbound_nodes:\n        return [tensor]\n    else:\n        node = layer._inbound_nodes[node_index]\n        if not node.inbound_layers:\n            # Reached an Input layer, stop recursion.\n            return node.input_tensors\n        else:\n            source_tensors = []\n            for i in range(len(node.inbound_layers)):\n                x = node.input_tensors[i]\n                layer = node.inbound_layers[i]\n                node_index = node.node_indices[i]\n                previous_sources = get_source_inputs(x,\n                                                     layer,\n                                                     node_index)\n                # Avoid input redundancy.\n                for x in previous_sources:\n                    if x not in source_tensors:\n                        source_tensors.append(x)\n            return source_tensors",
        "begin_line": 252,
        "end_line": 292,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00032948929159802305,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.metrics.binary_accuracy#26",
        "src_path": "keras/metrics.py",
        "class_name": "keras.metrics",
        "signature": "keras.metrics.binary_accuracy(y_true, y_pred)",
        "snippet": "def binary_accuracy(y_true, y_pred):\n    return K.mean(K.equal(y_true, K.round(y_pred)), axis=-1)",
        "begin_line": 26,
        "end_line": 27,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.metrics.categorical_accuracy#30",
        "src_path": "keras/metrics.py",
        "class_name": "keras.metrics",
        "signature": "keras.metrics.categorical_accuracy(y_true, y_pred)",
        "snippet": "def categorical_accuracy(y_true, y_pred):\n    return K.cast(K.equal(K.argmax(y_true, axis=-1),\n                          K.argmax(y_pred, axis=-1)),\n                  K.floatx())",
        "begin_line": 30,
        "end_line": 33,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00038955979742890534,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.metrics.deserialize#69",
        "src_path": "keras/metrics.py",
        "class_name": "keras.metrics",
        "signature": "keras.metrics.deserialize(config, custom_objects=None)",
        "snippet": "def deserialize(config, custom_objects=None):\n    return deserialize_keras_object(config,\n                                    module_objects=globals(),\n                                    custom_objects=custom_objects,\n                                    printable_module_name='metric function')",
        "begin_line": 69,
        "end_line": 73,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00044863167339614175,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.metrics.get#76",
        "src_path": "keras/metrics.py",
        "class_name": "keras.metrics",
        "signature": "keras.metrics.get(identifier)",
        "snippet": "def get(identifier):\n    if isinstance(identifier, dict):\n        config = {'class_name': str(identifier), 'config': {}}\n        return deserialize(config)\n    elif isinstance(identifier, six.string_types):\n        return deserialize(str(identifier))\n    elif callable(identifier):\n        return identifier\n    else:\n        raise ValueError('Could not interpret '\n                         'metric function identifier:', identifier)",
        "begin_line": 76,
        "end_line": 86,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0004789272030651341,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.optimizers.Optimizer.__init__#74",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Optimizer",
        "signature": "keras.optimizers.Optimizer.__init__(self, **kwargs)",
        "snippet": "    def __init__(self, **kwargs):\n        allowed_kwargs = {'clipnorm', 'clipvalue'}\n        for k in kwargs:\n            if k not in allowed_kwargs:\n                raise TypeError('Unexpected keyword argument '\n                                'passed to optimizer: ' + str(k))\n        self.__dict__.update(kwargs)\n        self.updates = []\n        self.weights = []",
        "begin_line": 74,
        "end_line": 82,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00030731407498463427,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.optimizers.Optimizer.get_gradients#89",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Optimizer",
        "signature": "keras.optimizers.Optimizer.get_gradients(self, loss, params)",
        "snippet": "    def get_gradients(self, loss, params):\n        grads = K.gradients(loss, params)\n        if None in grads:\n            raise ValueError('An operation has `None` for gradient. '\n                             'Please make sure that all of your ops have a '\n                             'gradient defined (i.e. are differentiable). '\n                             'Common ops without gradient: '\n                             'K.argmax, K.round, K.eval.')\n        if hasattr(self, 'clipnorm') and self.clipnorm > 0:\n            norm = K.sqrt(sum([K.sum(K.square(g)) for g in grads]))\n            grads = [clip_norm(g, self.clipnorm, norm) for g in grads]\n        if hasattr(self, 'clipvalue') and self.clipvalue > 0:\n            grads = [K.clip(g, -self.clipvalue, self.clipvalue) for g in grads]\n        return grads",
        "begin_line": 89,
        "end_line": 102,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00034164673727365904,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.optimizers.Optimizer.set_weights#104",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Optimizer",
        "signature": "keras.optimizers.Optimizer.set_weights(self, weights)",
        "snippet": "    def set_weights(self, weights):\n        \"\"\"Sets the weights of the optimizer, from Numpy arrays.\n\n        Should only be called after computing the gradients\n        (otherwise the optimizer has no weights).\n\n        # Arguments\n            weights: a list of Numpy arrays. The number\n                of arrays and their shape must match\n                number of the dimensions of the weights\n                of the optimizer (i.e. it should match the\n                output of `get_weights`).\n\n        # Raises\n            ValueError: in case of incompatible weight shapes.\n        \"\"\"\n        params = self.weights\n        if len(params) != len(weights):\n            raise ValueError('Length of the specified weight list (' +\n                             str(len(weights)) +\n                             ') does not match the number of weights ' +\n                             'of the optimizer (' + str(len(params)) + ')')\n        weight_value_tuples = []\n        param_values = K.batch_get_value(params)\n        for pv, p, w in zip(param_values, params, weights):\n            if pv.shape != w.shape:\n                raise ValueError('Optimizer weight shape ' +\n                                 str(pv.shape) +\n                                 ' not compatible with '\n                                 'provided weight shape ' + str(w.shape))\n            weight_value_tuples.append((p, w))\n        K.batch_set_value(weight_value_tuples)",
        "begin_line": 104,
        "end_line": 135,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0004297378599054577,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.optimizers.Optimizer.get_config#145",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Optimizer",
        "signature": "keras.optimizers.Optimizer.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {}\n        if hasattr(self, 'clipnorm'):\n            config['clipnorm'] = self.clipnorm\n        if hasattr(self, 'clipvalue'):\n            config['clipvalue'] = self.clipvalue\n        return config",
        "begin_line": 145,
        "end_line": 151,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00040225261464199515,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.optimizers.Optimizer.from_config#154",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Optimizer",
        "signature": "keras.optimizers.Optimizer.from_config(cls, config)",
        "snippet": "    def from_config(cls, config):\n        return cls(**config)",
        "begin_line": 154,
        "end_line": 155,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00031969309462915604,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.optimizers.SGD.__init__#172",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.SGD",
        "signature": "keras.optimizers.SGD.__init__(self, lr=0.01, momentum=0.0, decay=0.0, nesterov=False, **kwargs)",
        "snippet": "    def __init__(self, lr=0.01, momentum=0., decay=0.,\n                 nesterov=False, **kwargs):\n        super(SGD, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.iterations = K.variable(0, dtype='int64', name='iterations')\n            self.lr = K.variable(lr, name='lr')\n            self.momentum = K.variable(momentum, name='momentum')\n            self.decay = K.variable(decay, name='decay')\n        self.initial_decay = decay\n        self.nesterov = nesterov",
        "begin_line": 172,
        "end_line": 181,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0004764173415912339,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.optimizers.SGD.get_updates#185",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.SGD",
        "signature": "keras.optimizers.SGD.get_updates(self, loss, params)",
        "snippet": "    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        self.updates = [K.update_add(self.iterations, 1)]\n\n        lr = self.lr\n        if self.initial_decay > 0:\n            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations,\n                                                      K.dtype(self.decay))))\n        # momentum\n        shapes = [K.int_shape(p) for p in params]\n        moments = [K.zeros(shape, name='moment_' + str(i))\n                   for (i, shape) in enumerate(shapes)]\n        self.weights = [self.iterations] + moments\n        for p, g, m in zip(params, grads, moments):\n            v = self.momentum * m - lr * g  # velocity\n            self.updates.append(K.update(m, v))\n\n            if self.nesterov:\n                new_p = p + self.momentum * v - lr * g\n            else:\n                new_p = p + v\n\n            # Apply constraints.\n            if getattr(p, 'constraint', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n        return self.updates",
        "begin_line": 185,
        "end_line": 212,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005574136008918618,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.optimizers.SGD.get_config#214",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.SGD",
        "signature": "keras.optimizers.SGD.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'lr': float(K.get_value(self.lr)),\n                  'momentum': float(K.get_value(self.momentum)),\n                  'decay': float(K.get_value(self.decay)),\n                  'nesterov': self.nesterov}\n        base_config = super(SGD, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 214,
        "end_line": 220,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005083884087442806,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.optimizers.RMSprop.__init__#244",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.RMSprop",
        "signature": "keras.optimizers.RMSprop.__init__(self, lr=0.001, rho=0.9, epsilon=None, decay=0.0, **kwargs)",
        "snippet": "    def __init__(self, lr=0.001, rho=0.9, epsilon=None, decay=0.,\n                 **kwargs):\n        super(RMSprop, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.lr = K.variable(lr, name='lr')\n            self.rho = K.variable(rho, name='rho')\n            self.decay = K.variable(decay, name='decay')\n            self.iterations = K.variable(0, dtype='int64', name='iterations')\n        if epsilon is None:\n            epsilon = K.epsilon()\n        self.epsilon = epsilon\n        self.initial_decay = decay",
        "begin_line": 244,
        "end_line": 255,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0004246284501061571,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.optimizers.RMSprop.get_updates#259",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.RMSprop",
        "signature": "keras.optimizers.RMSprop.get_updates(self, loss, params)",
        "snippet": "    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        accumulators = [K.zeros(K.int_shape(p),\n                        dtype=K.dtype(p),\n                        name='accumulator_' + str(i))\n                        for (i, p) in enumerate(params)]\n        self.weights = accumulators\n        self.updates = [K.update_add(self.iterations, 1)]\n\n        lr = self.lr\n        if self.initial_decay > 0:\n            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations,\n                                                      K.dtype(self.decay))))\n\n        for p, g, a in zip(params, grads, accumulators):\n            # update accumulator\n            new_a = self.rho * a + (1. - self.rho) * K.square(g)\n            self.updates.append(K.update(a, new_a))\n            new_p = p - lr * g / (K.sqrt(new_a) + self.epsilon)\n\n            # Apply constraints.\n            if getattr(p, 'constraint', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n        return self.updates",
        "begin_line": 259,
        "end_line": 284,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0004297378599054577,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.optimizers.RMSprop.get_config#286",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.RMSprop",
        "signature": "keras.optimizers.RMSprop.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'lr': float(K.get_value(self.lr)),\n                  'rho': float(K.get_value(self.rho)),\n                  'decay': float(K.get_value(self.decay)),\n                  'epsilon': self.epsilon}\n        base_config = super(RMSprop, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 286,
        "end_line": 292,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005574136008918618,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.optimizers.Adam.__init__#470",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Adam",
        "signature": "keras.optimizers.Adam.__init__(self, lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False, **kwargs)",
        "snippet": "    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999,\n                 epsilon=None, decay=0., amsgrad=False, **kwargs):\n        super(Adam, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.iterations = K.variable(0, dtype='int64', name='iterations')\n            self.lr = K.variable(lr, name='lr')\n            self.beta_1 = K.variable(beta_1, name='beta_1')\n            self.beta_2 = K.variable(beta_2, name='beta_2')\n            self.decay = K.variable(decay, name='decay')\n        if epsilon is None:\n            epsilon = K.epsilon()\n        self.epsilon = epsilon\n        self.initial_decay = decay\n        self.amsgrad = amsgrad",
        "begin_line": 470,
        "end_line": 483,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005574136008918618,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.optimizers.Adam.get_updates#487",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Adam",
        "signature": "keras.optimizers.Adam.get_updates(self, loss, params)",
        "snippet": "    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        self.updates = [K.update_add(self.iterations, 1)]\n\n        lr = self.lr\n        if self.initial_decay > 0:\n            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations,\n                                                      K.dtype(self.decay))))\n\n        t = K.cast(self.iterations, K.floatx()) + 1\n        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) /\n                     (1. - K.pow(self.beta_1, t)))\n\n        ms = [K.zeros(K.int_shape(p),\n              dtype=K.dtype(p),\n              name='m_' + str(i))\n              for (i, p) in enumerate(params)]\n        vs = [K.zeros(K.int_shape(p),\n              dtype=K.dtype(p),\n              name='v_' + str(i))\n              for (i, p) in enumerate(params)]\n\n        if self.amsgrad:\n            vhats = [K.zeros(K.int_shape(p),\n                     dtype=K.dtype(p),\n                     name='vhat_' + str(i))\n                     for (i, p) in enumerate(params)]\n        else:\n            vhats = [K.zeros(1, name='vhat_' + str(i))\n                     for i in range(len(params))]\n        self.weights = [self.iterations] + ms + vs + vhats\n\n        for p, g, m, v, vhat in zip(params, grads, ms, vs, vhats):\n            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n            if self.amsgrad:\n                vhat_t = K.maximum(vhat, v_t)\n                p_t = p - lr_t * m_t / (K.sqrt(vhat_t) + self.epsilon)\n                self.updates.append(K.update(vhat, vhat_t))\n            else:\n                p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon)\n\n            self.updates.append(K.update(m, m_t))\n            self.updates.append(K.update(v, v_t))\n            new_p = p_t\n\n            # Apply constraints.\n            if getattr(p, 'constraint', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n        return self.updates",
        "begin_line": 487,
        "end_line": 538,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005574136008918618,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.optimizers.Adam.get_config#540",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers.Adam",
        "signature": "keras.optimizers.Adam.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'lr': float(K.get_value(self.lr)),\n                  'beta_1': float(K.get_value(self.beta_1)),\n                  'beta_2': float(K.get_value(self.beta_2)),\n                  'decay': float(K.get_value(self.decay)),\n                  'epsilon': self.epsilon,\n                  'amsgrad': self.amsgrad}\n        base_config = super(Adam, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 540,
        "end_line": 548,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005574136008918618,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.optimizers.deserialize#786",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers",
        "signature": "keras.optimizers.deserialize(config, custom_objects=None)",
        "snippet": "def deserialize(config, custom_objects=None):\n    \"\"\"Inverse of the `serialize` function.\n\n    # Arguments\n        config: Optimizer configuration dictionary.\n        custom_objects: Optional dictionary mapping\n            names (strings) to custom objects\n            (classes and functions)\n            to be considered during deserialization.\n\n    # Returns\n        A Keras Optimizer instance.\n    \"\"\"\n    all_classes = {\n        'sgd': SGD,\n        'rmsprop': RMSprop,\n        'adagrad': Adagrad,\n        'adadelta': Adadelta,\n        'adam': Adam,\n        'adamax': Adamax,\n        'nadam': Nadam,\n        'tfoptimizer': TFOptimizer,\n    }\n    # Make deserialization case-insensitive for built-in optimizers.\n    if config['class_name'].lower() in all_classes:\n        config['class_name'] = config['class_name'].lower()\n    return deserialize_keras_object(config,\n                                    module_objects=all_classes,\n                                    custom_objects=custom_objects,\n                                    printable_module_name='optimizer')",
        "begin_line": 786,
        "end_line": 815,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00032948929159802305,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.optimizers.get#818",
        "src_path": "keras/optimizers.py",
        "class_name": "keras.optimizers",
        "signature": "keras.optimizers.get(identifier)",
        "snippet": "def get(identifier):\n    \"\"\"Retrieves a Keras Optimizer instance.\n\n    # Arguments\n        identifier: Optimizer identifier, one of\n            - String: name of an optimizer\n            - Dictionary: configuration dictionary.\n            - Keras Optimizer instance (it will be returned unchanged).\n            - TensorFlow Optimizer instance\n                (it will be wrapped as a Keras Optimizer).\n\n    # Returns\n        A Keras Optimizer instance.\n\n    # Raises\n        ValueError: If `identifier` cannot be interpreted.\n    \"\"\"\n    if K.backend() == 'tensorflow':\n        # Wrap TF optimizer instances\n        if tf.__version__.startswith('1.'):\n            if isinstance(identifier, tf.train.Optimizer):\n                return TFOptimizer(identifier)\n        elif isinstance(identifier, tf.keras.optimizers.Optimizer):\n            return TFOptimizer(identifier)\n    if isinstance(identifier, dict):\n        return deserialize(identifier)\n    elif isinstance(identifier, six.string_types):\n        config = {'class_name': str(identifier), 'config': {}}\n        return deserialize(config)\n    if isinstance(identifier, Optimizer):\n        return identifier\n    else:\n        raise ValueError('Could not interpret optimizer identifier: ' +\n                         str(identifier))",
        "begin_line": 818,
        "end_line": 851,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0004144218814753419,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.losses.mean_squared_error#13",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.mean_squared_error(y_true, y_pred)",
        "snippet": "def mean_squared_error(y_true, y_pred):\n    return K.mean(K.square(y_pred - y_true), axis=-1)",
        "begin_line": 13,
        "end_line": 14,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00030731407498463427,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.losses.mean_absolute_error#17",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.mean_absolute_error(y_true, y_pred)",
        "snippet": "def mean_absolute_error(y_true, y_pred):\n    return K.mean(K.abs(y_pred - y_true), axis=-1)",
        "begin_line": 17,
        "end_line": 18,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.losses.deserialize#110",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.deserialize(name, custom_objects=None)",
        "snippet": "def deserialize(name, custom_objects=None):\n    return deserialize_keras_object(name,\n                                    module_objects=globals(),\n                                    custom_objects=custom_objects,\n                                    printable_module_name='loss function')",
        "begin_line": 110,
        "end_line": 114,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00031655587211142766,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.losses.get#117",
        "src_path": "keras/losses.py",
        "class_name": "keras.losses",
        "signature": "keras.losses.get(identifier)",
        "snippet": "def get(identifier):\n    \"\"\"Get the `identifier` loss function.\n\n    # Arguments\n        identifier: None or str, name of the function.\n\n    # Returns\n        The loss function or None if `identifier` is None.\n\n    # Raises\n        ValueError if unknown identifier.\n    \"\"\"\n    if identifier is None:\n        return None\n    if isinstance(identifier, six.string_types):\n        identifier = str(identifier)\n        return deserialize(identifier)\n    if isinstance(identifier, dict):\n        return deserialize(identifier)\n    elif callable(identifier):\n        return identifier\n    else:\n        raise ValueError('Could not interpret '\n                         'loss function identifier:', identifier)",
        "begin_line": 117,
        "end_line": 140,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00044863167339614175,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.utils.generic_utils.CustomObjectScope.__init__#41",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils.CustomObjectScope",
        "signature": "keras.utils.generic_utils.CustomObjectScope.__init__(self, *args)",
        "snippet": "    def __init__(self, *args):\n        self.custom_objects = args\n        self.backup = None",
        "begin_line": 41,
        "end_line": 43,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002613012803762738,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.utils.generic_utils.CustomObjectScope.__enter__#45",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils.CustomObjectScope",
        "signature": "keras.utils.generic_utils.CustomObjectScope.__enter__(self)",
        "snippet": "    def __enter__(self):\n        self.backup = _GLOBAL_CUSTOM_OBJECTS.copy()\n        for objects in self.custom_objects:\n            _GLOBAL_CUSTOM_OBJECTS.update(objects)\n        return self",
        "begin_line": 45,
        "end_line": 49,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002613012803762738,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.utils.generic_utils.CustomObjectScope.__exit__#51",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils.CustomObjectScope",
        "signature": "keras.utils.generic_utils.CustomObjectScope.__exit__(self, *args, **kwargs)",
        "snippet": "    def __exit__(self, *args, **kwargs):\n        _GLOBAL_CUSTOM_OBJECTS.clear()\n        _GLOBAL_CUSTOM_OBJECTS.update(self.backup)",
        "begin_line": 51,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002613012803762738,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.utils.generic_utils.serialize_keras_object#106",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils",
        "signature": "keras.utils.generic_utils.serialize_keras_object(instance)",
        "snippet": "def serialize_keras_object(instance):\n    if instance is None:\n        return None\n    if hasattr(instance, 'get_config'):\n        return {\n            'class_name': instance.__class__.__name__,\n            'config': instance.get_config()\n        }\n    if hasattr(instance, '__name__'):\n        return instance.__name__\n    else:\n        raise ValueError('Cannot serialize', instance)",
        "begin_line": 106,
        "end_line": 117,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00037778617302606723,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.utils.generic_utils.deserialize_keras_object#120",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils",
        "signature": "keras.utils.generic_utils.deserialize_keras_object(identifier, module_objects=None, custom_objects=None, printable_module_name='object')",
        "snippet": "def deserialize_keras_object(identifier, module_objects=None,\n                             custom_objects=None,\n                             printable_module_name='object'):\n    if identifier is None:\n        return None\n    if isinstance(identifier, dict):\n        # In this case we are dealing with a Keras config dictionary.\n        config = identifier\n        if 'class_name' not in config or 'config' not in config:\n            raise ValueError('Improper config format: ' + str(config))\n        class_name = config['class_name']\n        if custom_objects and class_name in custom_objects:\n            cls = custom_objects[class_name]\n        elif class_name in _GLOBAL_CUSTOM_OBJECTS:\n            cls = _GLOBAL_CUSTOM_OBJECTS[class_name]\n        else:\n            module_objects = module_objects or {}\n            cls = module_objects.get(class_name)\n            if cls is None:\n                raise ValueError('Unknown ' + printable_module_name +\n                                 ': ' + class_name)\n        if hasattr(cls, 'from_config'):\n            custom_objects = custom_objects or {}\n            if has_arg(cls.from_config, 'custom_objects'):\n                return cls.from_config(\n                    config['config'],\n                    custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n                                        list(custom_objects.items())))\n            with CustomObjectScope(custom_objects):\n                return cls.from_config(config['config'])\n        else:\n            # Then `cls` may be a function returning a class.\n            # in this case by convention `config` holds\n            # the kwargs of the function.\n            custom_objects = custom_objects or {}\n            with CustomObjectScope(custom_objects):\n                return cls(**config['config'])\n    elif isinstance(identifier, six.string_types):\n        function_name = identifier\n        if custom_objects and function_name in custom_objects:\n            fn = custom_objects.get(function_name)\n        elif function_name in _GLOBAL_CUSTOM_OBJECTS:\n            fn = _GLOBAL_CUSTOM_OBJECTS[function_name]\n        else:\n            fn = module_objects.get(function_name)\n            if fn is None:\n                raise ValueError('Unknown ' + printable_module_name +\n                                 ':' + function_name)\n        return fn\n    else:\n        raise ValueError('Could not interpret serialized ' +\n                         printable_module_name + ': ' + identifier)",
        "begin_line": 120,
        "end_line": 171,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.utils.generic_utils.func_dump#174",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils",
        "signature": "keras.utils.generic_utils.func_dump(func)",
        "snippet": "def func_dump(func):\n    \"\"\"Serializes a user defined function.\n\n    # Arguments\n        func: the function to serialize.\n\n    # Returns\n        A tuple `(code, defaults, closure)`.\n    \"\"\"\n    raw_code = marshal.dumps(func.__code__)\n    code = codecs.encode(raw_code, 'base64').decode('ascii')\n    defaults = func.__defaults__\n    if func.__closure__:\n        closure = tuple(c.cell_contents for c in func.__closure__)\n    else:\n        closure = None\n    return code, defaults, closure",
        "begin_line": 174,
        "end_line": 190,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.utils.generic_utils.func_load#193",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils",
        "signature": "keras.utils.generic_utils.func_load(code, defaults=None, closure=None, globs=None)",
        "snippet": "def func_load(code, defaults=None, closure=None, globs=None):\n    \"\"\"Deserializes a user defined function.\n\n    # Arguments\n        code: bytecode of the function.\n        defaults: defaults of the function.\n        closure: closure of the function.\n        globs: dictionary of global objects.\n\n    # Returns\n        A function object.\n    \"\"\"\n    if isinstance(code, (tuple, list)):  # unpack previous dump\n        code, defaults, closure = code\n        if isinstance(defaults, list):\n            defaults = tuple(defaults)\n\n    def ensure_value_to_cell(value):\n        \"\"\"Ensures that a value is converted to a python cell object.\n\n        # Arguments\n            value: Any value that needs to be casted to the cell type\n\n        # Returns\n            A value wrapped as a cell object (see function \"func_load\")\n\n        \"\"\"\n        def dummy_fn():\n            value  # just access it so it gets captured in .__closure__\n\n        cell_value = dummy_fn.__closure__[0]\n        if not isinstance(value, type(cell_value)):\n            return cell_value\n        else:\n            return value\n\n    if closure is not None:\n        closure = tuple(ensure_value_to_cell(_) for _ in closure)\n    try:\n        raw_code = codecs.decode(code.encode('ascii'), 'base64')\n        code = marshal.loads(raw_code)\n    except (UnicodeEncodeError, binascii.Error, ValueError):\n        # backwards compatibility for models serialized prior to 2.1.2\n        raw_code = code.encode('raw_unicode_escape')\n        code = marshal.loads(raw_code)\n    if globs is None:\n        globs = globals()\n    return python_types.FunctionType(code, globs,\n                                     name=code.co_name,\n                                     argdefs=defaults,\n                                     closure=closure)",
        "begin_line": 193,
        "end_line": 243,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.utils.generic_utils.ensure_value_to_cell#210",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils",
        "signature": "keras.utils.generic_utils.ensure_value_to_cell(value)",
        "snippet": "    def ensure_value_to_cell(value):\n        \"\"\"Ensures that a value is converted to a python cell object.\n\n        # Arguments\n            value: Any value that needs to be casted to the cell type\n\n        # Returns\n            A value wrapped as a cell object (see function \"func_load\")\n\n        \"\"\"\n        def dummy_fn():\n            value  # just access it so it gets captured in .__closure__\n\n        cell_value = dummy_fn.__closure__[0]\n        if not isinstance(value, type(cell_value)):\n            return cell_value\n        else:\n            return value",
        "begin_line": 210,
        "end_line": 227,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.utils.generic_utils.has_arg#273",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils",
        "signature": "keras.utils.generic_utils.has_arg(fn, name, accept_all=False)",
        "snippet": "def has_arg(fn, name, accept_all=False):\n    \"\"\"Checks if a callable accepts a given keyword argument.\n\n    For Python 2, checks if there is an argument with the given name.\n\n    For Python 3, checks if there is an argument with the given name, and\n    also whether this argument can be called with a keyword (i.e. if it is\n    not a positional-only argument).\n\n    # Arguments\n        fn: Callable to inspect.\n        name: Check if `fn` can be called with `name` as a keyword argument.\n        accept_all: What to return if there is no parameter called `name`\n                    but the function accepts a `**kwargs` argument.\n\n    # Returns\n        bool, whether `fn` accepts a `name` keyword argument.\n    \"\"\"\n    if sys.version_info < (3,):\n        arg_spec = inspect.getargspec(fn)\n        if accept_all and arg_spec.keywords is not None:\n            return True\n        return (name in arg_spec.args)\n    elif sys.version_info < (3, 3):\n        arg_spec = inspect.getfullargspec(fn)\n        if accept_all and arg_spec.varkw is not None:\n            return True\n        return (name in arg_spec.args or\n                name in arg_spec.kwonlyargs)\n    else:\n        signature = inspect.signature(fn)\n        parameter = signature.parameters.get(name)\n        if parameter is None:\n            if accept_all:\n                for param in signature.parameters.values():\n                    if param.kind == inspect.Parameter.VAR_KEYWORD:\n                        return True\n            return False\n        return (parameter.kind in (inspect.Parameter.POSITIONAL_OR_KEYWORD,\n                                   inspect.Parameter.KEYWORD_ONLY))",
        "begin_line": 273,
        "end_line": 312,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002613012803762738,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.utils.generic_utils.Progbar.__init__#329",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils.Progbar",
        "signature": "keras.utils.generic_utils.Progbar.__init__(self, target, width=30, verbose=1, interval=0.05, stateful_metrics=None)",
        "snippet": "    def __init__(self, target, width=30, verbose=1, interval=0.05,\n                 stateful_metrics=None):\n        self.target = target\n        self.width = width\n        self.verbose = verbose\n        self.interval = interval\n        if stateful_metrics:\n            self.stateful_metrics = set(stateful_metrics)\n        else:\n            self.stateful_metrics = set()\n\n        self._dynamic_display = ((hasattr(sys.stdout, 'isatty') and\n                                  sys.stdout.isatty()) or\n                                 'ipykernel' in sys.modules)\n        self._total_width = 0\n        self._seen_so_far = 0\n        self._values = collections.OrderedDict()\n        self._start = time.time()\n        self._last_update = 0",
        "begin_line": 329,
        "end_line": 347,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.utils.generic_utils.Progbar.update#349",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils.Progbar",
        "signature": "keras.utils.generic_utils.Progbar.update(self, current, values=None)",
        "snippet": "    def update(self, current, values=None):\n        \"\"\"Updates the progress bar.\n\n        # Arguments\n            current: Index of current step.\n            values: List of tuples:\n                `(name, value_for_last_step)`.\n                If `name` is in `stateful_metrics`,\n                `value_for_last_step` will be displayed as-is.\n                Else, an average of the metric over time will be displayed.\n        \"\"\"\n        values = values or []\n        for k, v in values:\n            if k not in self.stateful_metrics:\n                if k not in self._values:\n                    self._values[k] = [v * (current - self._seen_so_far),\n                                       current - self._seen_so_far]\n                else:\n                    self._values[k][0] += v * (current - self._seen_so_far)\n                    self._values[k][1] += (current - self._seen_so_far)\n            else:\n                # Stateful metrics output a numeric value.  This representation\n                # means \"take an average from a single value\" but keeps the\n                # numeric formatting.\n                self._values[k] = [v, 1]\n        self._seen_so_far = current\n\n        now = time.time()\n        info = ' - %.0fs' % (now - self._start)\n        if self.verbose == 1:\n            if (now - self._last_update < self.interval and\n                    self.target is not None and current < self.target):\n                return\n\n            prev_total_width = self._total_width\n            if self._dynamic_display:\n                sys.stdout.write('\\b' * prev_total_width)\n                sys.stdout.write('\\r')\n            else:\n                sys.stdout.write('\\n')\n\n            if self.target is not None:\n                numdigits = int(np.floor(np.log10(self.target))) + 1\n                barstr = '%%%dd/%d [' % (numdigits, self.target)\n                bar = barstr % current\n                prog = float(current) / self.target\n                prog_width = int(self.width * prog)\n                if prog_width > 0:\n                    bar += ('=' * (prog_width - 1))\n                    if current < self.target:\n                        bar += '>'\n                    else:\n                        bar += '='\n                bar += ('.' * (self.width - prog_width))\n                bar += ']'\n            else:\n                bar = '%7d/Unknown' % current\n\n            self._total_width = len(bar)\n            sys.stdout.write(bar)\n\n            if current:\n                time_per_unit = (now - self._start) / current\n            else:\n                time_per_unit = 0\n            if self.target is not None and current < self.target:\n                eta = time_per_unit * (self.target - current)\n                if eta > 3600:\n                    eta_format = ('%d:%02d:%02d' %\n                                  (eta // 3600, (eta % 3600) // 60, eta % 60))\n                elif eta > 60:\n                    eta_format = '%d:%02d' % (eta // 60, eta % 60)\n                else:\n                    eta_format = '%ds' % eta\n\n                info = ' - ETA: %s' % eta_format\n            else:\n                if time_per_unit >= 1:\n                    info += ' %.0fs/step' % time_per_unit\n                elif time_per_unit >= 1e-3:\n                    info += ' %.0fms/step' % (time_per_unit * 1e3)\n                else:\n                    info += ' %.0fus/step' % (time_per_unit * 1e6)\n\n            for k in self._values:\n                info += ' - %s:' % k\n                if isinstance(self._values[k], list):\n                    avg = np.mean(\n                        self._values[k][0] / max(1, self._values[k][1]))\n                    if abs(avg) > 1e-3:\n                        info += ' %.4f' % avg\n                    else:\n                        info += ' %.4e' % avg\n                else:\n                    info += ' %s' % self._values[k]\n\n            self._total_width += len(info)\n            if prev_total_width > self._total_width:\n                info += (' ' * (prev_total_width - self._total_width))\n\n            if self.target is not None and current >= self.target:\n                info += '\\n'\n\n            sys.stdout.write(info)\n            sys.stdout.flush()\n\n        elif self.verbose == 2:\n            if self.target is None or current >= self.target:\n                for k in self._values:\n                    info += ' - %s:' % k\n                    avg = np.mean(\n                        self._values[k][0] / max(1, self._values[k][1]))\n                    if avg > 1e-3:\n                        info += ' %.4f' % avg\n                    else:\n                        info += ' %.4e' % avg\n                info += '\\n'\n\n                sys.stdout.write(info)\n                sys.stdout.flush()\n\n        self._last_update = now",
        "begin_line": 349,
        "end_line": 470,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.utils.generic_utils.to_list#476",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils",
        "signature": "keras.utils.generic_utils.to_list(x, allow_tuple=False)",
        "snippet": "def to_list(x, allow_tuple=False):\n    \"\"\"Normalizes a list/tensor into a list.\n\n    If a tensor is passed, we return\n    a list of size 1 containing the tensor.\n\n    # Arguments\n        x: target object to be normalized.\n        allow_tuple: If False and x is a tuple,\n            it will be converted into a list\n            with a single element (the tuple).\n            Else converts the tuple to a list.\n\n    # Returns\n        A list.\n    \"\"\"\n    if isinstance(x, list):\n        return x\n    if allow_tuple and isinstance(x, tuple):\n        return list(x)\n    return [x]",
        "begin_line": 476,
        "end_line": 496,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002613012803762738,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.utils.generic_utils.unpack_singleton#499",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils",
        "signature": "keras.utils.generic_utils.unpack_singleton(x)",
        "snippet": "def unpack_singleton(x):\n    \"\"\"Gets the first element if the iterable has only one value.\n\n    Otherwise return the iterable.\n\n    # Argument\n        x: A list or tuple.\n\n    # Returns\n        The same iterable or the first element.\n    \"\"\"\n    if len(x) == 1:\n        return x[0]\n    return x",
        "begin_line": 499,
        "end_line": 512,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0003869969040247678,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.utils.generic_utils.object_list_uid#515",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils",
        "signature": "keras.utils.generic_utils.object_list_uid(object_list)",
        "snippet": "def object_list_uid(object_list):\n    object_list = to_list(object_list)\n    return ', '.join([str(abs(id(x))) for x in object_list])",
        "begin_line": 515,
        "end_line": 517,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002613012803762738,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.utils.generic_utils.is_all_none#520",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils",
        "signature": "keras.utils.generic_utils.is_all_none(iterable_or_element)",
        "snippet": "def is_all_none(iterable_or_element):\n    iterable = to_list(iterable_or_element, allow_tuple=True)\n    for element in iterable:\n        if element is not None:\n            return False\n    return True",
        "begin_line": 520,
        "end_line": 525,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.utils.generic_utils.slice_arrays#528",
        "src_path": "keras/utils/generic_utils.py",
        "class_name": "keras.utils.generic_utils",
        "signature": "keras.utils.generic_utils.slice_arrays(arrays, start=None, stop=None)",
        "snippet": "def slice_arrays(arrays, start=None, stop=None):\n    \"\"\"Slices an array or list of arrays.\n\n    This takes an array-like, or a list of\n    array-likes, and outputs:\n        - arrays[start:stop] if `arrays` is an array-like\n        - [x[start:stop] for x in arrays] if `arrays` is a list\n\n    Can also work on list/array of indices: `_slice_arrays(x, indices)`\n\n    # Arguments\n        arrays: Single array or list of arrays.\n        start: can be an integer index (start index)\n            or a list/array of indices\n        stop: integer (stop index); should be None if\n            `start` was a list.\n\n    # Returns\n        A slice of the array(s).\n    \"\"\"\n    if arrays is None:\n        return [None]\n    elif isinstance(arrays, list):\n        if hasattr(start, '__len__'):\n            # hdf5 datasets only support list objects as indices\n            if hasattr(start, 'shape'):\n                start = start.tolist()\n            return [None if x is None else x[start] for x in arrays]\n        else:\n            return [None if x is None else x[start:stop] for x in arrays]\n    else:\n        if hasattr(start, '__len__'):\n            if hasattr(start, 'shape'):\n                start = start.tolist()\n            return arrays[start]\n        elif hasattr(start, '__getitem__'):\n            return arrays[start:stop]\n        else:\n            return [None]",
        "begin_line": 528,
        "end_line": 566,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0004764173415912339,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.training_arrays.fit_loop#22",
        "src_path": "keras/engine/training_arrays.py",
        "class_name": "keras.engine.training_arrays",
        "signature": "keras.engine.training_arrays.fit_loop(model, fit_function, fit_inputs, out_labels=None, batch_size=None, epochs=100, verbose=1, callbacks=None, val_function=None, val_inputs=None, shuffle=True, callback_metrics=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_freq=1)",
        "snippet": "def fit_loop(model, fit_function, fit_inputs,\n             out_labels=None,\n             batch_size=None,\n             epochs=100,\n             verbose=1,\n             callbacks=None,\n             val_function=None,\n             val_inputs=None,\n             shuffle=True,\n             callback_metrics=None,\n             initial_epoch=0,\n             steps_per_epoch=None,\n             validation_steps=None,\n             validation_freq=1):\n    \"\"\"Abstract fit function for `fit_function(fit_inputs)`.\n\n    Assumes that fit_function returns a list, labeled by out_labels.\n\n    # Arguments\n        model: Keras model instance.\n        fit_function: Keras function returning a list of tensors\n        fit_inputs: List of tensors to be fed to `fit_function`\n        out_labels: List of strings, display names of\n            the outputs of `fit_function`\n        batch_size: Integer batch size or None if unknown.\n        epochs: Number of times to iterate over the data\n        verbose: Verbosity mode, 0, 1 or 2\n        callbacks: List of callbacks to be called during training and validation\n            (if `val_function` and `val_inputs` are not `None`).\n        val_function: Keras function to call for validation\n        val_inputs: List of tensors to be fed to `val_function`\n        shuffle: Whether to shuffle the data at the beginning of each epoch\n        callback_metrics: List of strings, the display names of the metrics\n            passed to the callbacks. They should be the\n            concatenation of list the display names of the outputs of\n             `fit_function` and the list of display names\n             of the outputs of `fit_inputs`.\n        initial_epoch: Epoch at which to start training\n            (useful for resuming a previous training run)\n        steps_per_epoch: Total number of steps (batches of samples)\n            before declaring one epoch finished and starting the\n            next epoch. Ignored with the default value of `None`.\n        validation_steps: Number of steps to run validation for\n            (only if doing validation from data tensors).\n            Ignored with the default value of `None`.\n        validation_freq: Only relevant if validation data is provided. Integer\n            or list/tuple/set. If an integer, specifies how many training\n            epochs to run before a new validation run is performed, e.g.\n            validation_freq=2` runs validation every 2 epochs. If a list,\n            tuple, or set, specifies the epochs on which to run validation,\n            e.g. `validation_freq=[1, 2, 10]` runs validation at the end\n            of the 1st, 2nd, and 10th epochs.\n\n    # Returns\n        `History` object.\n    \"\"\"\n    do_validation = False\n    if val_function and val_inputs:\n        do_validation = True\n        if (verbose and fit_inputs and\n           hasattr(fit_inputs[0], 'shape') and hasattr(val_inputs[0], 'shape')):\n            print('Train on %d samples, validate on %d samples' %\n                  (fit_inputs[0].shape[0], val_inputs[0].shape[0]))\n    if validation_steps:\n        do_validation = True\n        if steps_per_epoch is None:\n            raise ValueError('Can only use `validation_steps` '\n                             'when doing step-wise '\n                             'training, i.e. `steps_per_epoch` '\n                             'must be set.')\n    elif do_validation:\n        if steps_per_epoch:\n            raise ValueError('Must specify `validation_steps` '\n                             'to perform validation '\n                             'when doing step-wise training.')\n\n    num_train_samples = check_num_samples(fit_inputs,\n                                          batch_size=batch_size,\n                                          steps=steps_per_epoch,\n                                          steps_name='steps_per_epoch')\n    if num_train_samples is not None:\n        index_array = np.arange(num_train_samples)\n\n    model.history = cbks.History()\n    _callbacks = [cbks.BaseLogger(\n        stateful_metrics=model.stateful_metric_names)]\n    if verbose:\n        if steps_per_epoch is not None:\n            count_mode = 'steps'\n        else:\n            count_mode = 'samples'\n        _callbacks.append(\n            cbks.ProgbarLogger(\n                count_mode,\n                stateful_metrics=model.stateful_metric_names))\n    _callbacks += (callbacks or []) + [model.history]\n    callbacks = cbks.CallbackList(_callbacks)\n    out_labels = out_labels or []\n\n    # it's possible to callback a different model than itself\n    # (used by Sequential models)\n    callback_model = model._get_callback_model()\n\n    callbacks.set_model(callback_model)\n    callbacks.set_params({\n        'batch_size': batch_size,\n        'epochs': epochs,\n        'steps': steps_per_epoch,\n        'samples': num_train_samples,\n        'verbose': verbose,\n        'do_validation': do_validation,\n        'metrics': callback_metrics or [],\n    })\n    callbacks._call_begin_hook('train')\n    callbacks.model.stop_training = False\n    for cbk in callbacks:\n        cbk.validation_data = val_inputs\n\n    # To prevent a slowdown,\n    # we find beforehand the arrays that need conversion.\n    feed = (model._feed_inputs +\n            model._feed_targets +\n            model._feed_sample_weights)\n    indices_for_conversion_to_dense = []\n    for i in range(len(feed)):\n        if issparse(fit_inputs[i]) and not K.is_sparse(feed[i]):\n            indices_for_conversion_to_dense.append(i)\n\n    for epoch in range(initial_epoch, epochs):\n        # Reset stateful metrics\n        for m in model.stateful_metric_functions:\n            m.reset_states()\n        callbacks.on_epoch_begin(epoch)\n        epoch_logs = {}\n        if steps_per_epoch is not None:\n            for step_index in range(steps_per_epoch):\n                batch_logs = {'batch': step_index, 'size': 1}\n                callbacks._call_batch_hook('train', 'begin', step_index, batch_logs)\n                outs = fit_function(fit_inputs)\n\n                outs = to_list(outs)\n                for l, o in zip(out_labels, outs):\n                    batch_logs[l] = o\n\n                callbacks._call_batch_hook('train', 'end', step_index, batch_logs)\n                if callback_model.stop_training:\n                    break\n\n            if do_validation and should_run_validation(validation_freq, epoch):\n                val_outs = test_loop(model, val_function, val_inputs,\n                                     steps=validation_steps,\n                                     callbacks=callbacks,\n                                     verbose=0)\n                val_outs = to_list(val_outs)\n                # Same labels assumed.\n                for l, o in zip(out_labels, val_outs):\n                    epoch_logs['val_' + l] = o\n        else:\n            if shuffle == 'batch':\n                index_array = batch_shuffle(index_array, batch_size)\n            elif shuffle:\n                np.random.shuffle(index_array)\n\n            batches = make_batches(num_train_samples, batch_size)\n            for batch_index, (batch_start, batch_end) in enumerate(batches):\n                batch_ids = index_array[batch_start:batch_end]\n                try:\n                    if isinstance(fit_inputs[-1], int):\n                        # Do not slice the training phase flag.\n                        ins_batch = slice_arrays(\n                            fit_inputs[:-1], batch_ids) + [fit_inputs[-1]]\n                    else:\n                        ins_batch = slice_arrays(fit_inputs, batch_ids)\n                except TypeError:\n                    raise TypeError('TypeError while preparing batch. '\n                                    'If using HDF5 input data, '\n                                    'pass shuffle=\"batch\".')\n                batch_logs = {'batch': batch_index, 'size': len(batch_ids)}\n                callbacks._call_batch_hook('train', 'begin', batch_index, batch_logs)\n                for i in indices_for_conversion_to_dense:\n                    ins_batch[i] = ins_batch[i].toarray()\n\n                outs = fit_function(ins_batch)\n                outs = to_list(outs)\n                for l, o in zip(out_labels, outs):\n                    batch_logs[l] = o\n\n                callbacks._call_batch_hook('train', 'end', batch_index, batch_logs)\n                if callbacks.model.stop_training:\n                    break\n\n            if batch_index == len(batches) - 1:  # Last batch.\n                if do_validation and should_run_validation(validation_freq, epoch):\n                    val_outs = test_loop(model, val_function, val_inputs,\n                                         batch_size=batch_size,\n                                         callbacks=callbacks,\n                                         verbose=0)\n                    val_outs = to_list(val_outs)\n                    # Same labels assumed.\n                    for l, o in zip(out_labels, val_outs):\n                        epoch_logs['val_' + l] = o\n\n        callbacks.on_epoch_end(epoch, epoch_logs)\n        if callbacks.model.stop_training:\n            break\n    callbacks._call_end_hook('train')\n    return model.history",
        "begin_line": 22,
        "end_line": 228,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.training_arrays.predict_loop#231",
        "src_path": "keras/engine/training_arrays.py",
        "class_name": "keras.engine.training_arrays",
        "signature": "keras.engine.training_arrays.predict_loop(model, f, ins, batch_size=32, verbose=0, steps=None, callbacks=None)",
        "snippet": "def predict_loop(model, f, ins,\n                 batch_size=32,\n                 verbose=0,\n                 steps=None,\n                 callbacks=None):\n    \"\"\"Abstract method to loop over some data in batches.\n\n    # Arguments\n        model: Keras model instance.\n        f: Keras function returning a list of tensors.\n        ins: list of tensors to be fed to `f`.\n        batch_size: integer batch size.\n        verbose: verbosity mode.\n        steps: Total number of steps (batches of samples)\n            before declaring `predict_loop` finished.\n            Ignored with the default value of `None`.\n        callbacks: List of callbacks or an instance of\n            `keras.callbacks.CallbackList` to be called during prediction.\n\n    # Returns\n        Array of predictions (if the model has a single output)\n        or list of arrays of predictions\n        (if the model has multiple outputs).\n    \"\"\"\n    num_samples = check_num_samples(ins,\n                                    batch_size=batch_size,\n                                    steps=steps,\n                                    steps_name='steps')\n\n    # Check if callbacks have not been already configured\n    if not isinstance(callbacks, cbks.CallbackList):\n        callbacks = cbks.CallbackList(callbacks)\n        callback_model = model._get_callback_model()\n        callbacks.set_model(callback_model)\n        callback_params = {\n            'batch_size': batch_size,\n            'steps': steps,\n            'samples': num_samples,\n            'verbose': verbose,\n        }\n        callbacks.set_params(callback_params)\n\n    if verbose == 1:\n        if steps is not None:\n            progbar = Progbar(target=steps)\n        else:\n            progbar = Progbar(target=num_samples)\n\n    indices_for_conversion_to_dense = []\n    for i in range(len(model._feed_inputs)):\n        if issparse(ins[i]) and not K.is_sparse(model._feed_inputs[i]):\n            indices_for_conversion_to_dense.append(i)\n\n    callbacks.model.stop_training = False\n    callbacks._call_begin_hook('predict')\n\n    if steps is not None:\n        # Step-based predictions.\n        # Since we do not know how many samples\n        # we will see, we cannot pre-allocate\n        # the returned Numpy arrays.\n        # Instead, we store one array per batch seen\n        # and concatenate them upon returning.\n        unconcatenated_outs = []\n        for step in range(steps):\n            batch_logs = {'batch': step, 'size': 1}\n            callbacks._call_batch_hook('predict', 'begin', step, batch_logs)\n            batch_outs = f(ins)\n            batch_outs = to_list(batch_outs)\n            if step == 0:\n                for batch_out in batch_outs:\n                    unconcatenated_outs.append([])\n            for i, batch_out in enumerate(batch_outs):\n                unconcatenated_outs[i].append(batch_out)\n\n            batch_logs['outputs'] = batch_outs\n            callbacks._call_batch_hook('predict', 'end', step, batch_logs)\n            if verbose == 1:\n                progbar.update(step + 1)\n        callbacks.on_predict_end()\n        if len(unconcatenated_outs) == 1:\n            return np.concatenate(unconcatenated_outs[0], axis=0)\n        return [np.concatenate(unconcatenated_outs[i], axis=0)\n                for i in range(len(unconcatenated_outs))]\n    else:\n        # Sample-based predictions.\n        outs = []\n        batches = make_batches(num_samples, batch_size)\n        index_array = np.arange(num_samples)\n        for batch_index, (batch_start, batch_end) in enumerate(batches):\n            batch_ids = index_array[batch_start:batch_end]\n            if ins and isinstance(ins[-1], int):\n                # Do not slice the training phase flag.\n                ins_batch = slice_arrays(ins[:-1], batch_ids) + [ins[-1]]\n            else:\n                ins_batch = slice_arrays(ins, batch_ids)\n            for i in indices_for_conversion_to_dense:\n                ins_batch[i] = ins_batch[i].toarray()\n\n            batch_logs = {'batch': batch_index, 'size': len(batch_ids)}\n            callbacks._call_batch_hook('predict', 'begin', batch_index, batch_logs)\n            print('ins_batch', ins_batch)\n            batch_outs = f(ins_batch)\n            batch_outs = to_list(batch_outs)\n            if batch_index == 0:\n                # Pre-allocate the results arrays.\n                for batch_out in batch_outs:\n                    shape = (num_samples,) + batch_out.shape[1:]\n                    outs.append(np.zeros(shape, dtype=batch_out.dtype))\n            for i, batch_out in enumerate(batch_outs):\n                outs[i][batch_start:batch_end] = batch_out\n\n            batch_logs['outputs'] = batch_outs\n            callbacks._call_batch_hook('predict', 'end', batch_index, batch_logs)\n            if verbose == 1:\n                progbar.update(batch_end)\n        callbacks._call_end_hook('predict')\n        return unpack_singleton(outs)",
        "begin_line": 231,
        "end_line": 348,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0004144218814753419,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.training_arrays.test_loop#351",
        "src_path": "keras/engine/training_arrays.py",
        "class_name": "keras.engine.training_arrays",
        "signature": "keras.engine.training_arrays.test_loop(model, f, ins, batch_size=None, verbose=0, steps=None, callbacks=None)",
        "snippet": "def test_loop(model, f, ins,\n              batch_size=None,\n              verbose=0,\n              steps=None,\n              callbacks=None):\n    \"\"\"Abstract method to loop over some data in batches.\n\n    # Arguments\n        model: Keras model instance.\n        f: Keras function returning a list of tensors.\n        ins: list of tensors to be fed to `f`.\n        batch_size: integer batch size or `None`.\n        verbose: verbosity mode.\n        steps: Total number of steps (batches of samples)\n            before declaring predictions finished.\n            Ignored with the default value of `None`.\n        callbacks: List of callbacks or an instance of\n            `keras.callbacks.CallbackList` to be called during evaluation.\n\n    # Returns\n        Scalar loss (if the model has a single output and no metrics)\n        or list of scalars (if the model has multiple outputs\n        and/or metrics). The attribute `model.metrics_names` will give you\n        the display labels for the scalar outputs.\n    \"\"\"\n\n    if hasattr(model, 'metrics'):\n        for m in model.stateful_metric_functions:\n            m.reset_states()\n        stateful_metric_indices = [\n            i for i, name in enumerate(model.metrics_names)\n            if str(name) in model.stateful_metric_names]\n    else:\n        stateful_metric_indices = []\n\n    num_samples = check_num_samples(ins,\n                                    batch_size=batch_size,\n                                    steps=steps,\n                                    steps_name='steps')\n\n    # Check if callbacks have not been already configured\n    if not isinstance(callbacks, cbks.CallbackList):\n        callbacks = cbks.CallbackList(callbacks)\n        callback_model = model._get_callback_model()\n        callbacks.set_model(callback_model)\n        callback_metrics = []\n        if hasattr(model, 'metrics_names'):\n            callback_metrics = list(model.metrics_names)\n        callback_params = {\n            'batch_size': batch_size,\n            'steps': steps,\n            'samples': num_samples,\n            'verbose': verbose,\n            'metrics': callback_metrics,\n        }\n        callbacks.set_params(callback_params)\n\n    outs = []\n    if verbose == 1:\n        if steps is not None:\n            progbar = Progbar(target=steps)\n        else:\n            progbar = Progbar(target=num_samples)\n\n    # To prevent a slowdown,\n    # we find beforehand the arrays that need conversion.\n    feed = (model._feed_inputs +\n            model._feed_targets +\n            model._feed_sample_weights)\n    indices_for_conversion_to_dense = []\n    for i in range(len(feed)):\n        if issparse(ins[i]) and not K.is_sparse(feed[i]):\n            indices_for_conversion_to_dense.append(i)\n\n    callbacks.model.stop_training = False\n    callbacks._call_begin_hook('test')\n\n    if steps is not None:\n        for step in range(steps):\n            batch_logs = {'batch': step, 'size': 1}\n            callbacks._call_batch_hook('test', 'begin', step, batch_logs)\n            batch_outs = f(ins)\n            if isinstance(batch_outs, list):\n                if step == 0:\n                    for _ in enumerate(batch_outs):\n                        outs.append(0.)\n                for i, batch_out in enumerate(batch_outs):\n                    if i in stateful_metric_indices:\n                        outs[i] = float(batch_out)\n                    else:\n                        outs[i] += batch_out\n            else:\n                if step == 0:\n                    outs.append(0.)\n                outs[0] += batch_outs\n\n            if hasattr(model, 'metrics_names'):\n                for l, o in zip(model.metrics_names, batch_outs):\n                    batch_logs[l] = o\n            callbacks._call_batch_hook('test', 'end', step, batch_logs)\n\n            if verbose == 1:\n                progbar.update(step + 1)\n        for i in range(len(outs)):\n            if i not in stateful_metric_indices:\n                outs[i] /= steps\n    else:\n        batches = make_batches(num_samples, batch_size)\n        index_array = np.arange(num_samples)\n        for batch_index, (batch_start, batch_end) in enumerate(batches):\n            batch_ids = index_array[batch_start:batch_end]\n            if isinstance(ins[-1], int):\n                # Do not slice the training phase flag.\n                ins_batch = slice_arrays(ins[:-1], batch_ids) + [ins[-1]]\n            else:\n                ins_batch = slice_arrays(ins, batch_ids)\n            for i in indices_for_conversion_to_dense:\n                ins_batch[i] = ins_batch[i].toarray()\n\n            batch_logs = {'batch': batch_index, 'size': len(batch_ids)}\n            callbacks._call_batch_hook('test', 'begin', batch_index, batch_logs)\n            batch_outs = f(ins_batch)\n            if isinstance(batch_outs, list):\n                if batch_index == 0:\n                    for batch_out in enumerate(batch_outs):\n                        outs.append(0.)\n                for i, batch_out in enumerate(batch_outs):\n                    if i in stateful_metric_indices:\n                        outs[i] = batch_out\n                    else:\n                        outs[i] += batch_out * len(batch_ids)\n            else:\n                if batch_index == 0:\n                    outs.append(0.)\n                outs[0] += batch_outs * len(batch_ids)\n\n            if hasattr(model, 'metrics_names'):\n                for l, o in zip(model.metrics_names, batch_outs):\n                    batch_logs[l] = o\n            callbacks._call_batch_hook('test', 'end', batch_index, batch_logs)\n\n            if verbose == 1:\n                progbar.update(batch_end)\n        for i in range(len(outs)):\n            if i not in stateful_metric_indices:\n                outs[i] /= num_samples\n    callbacks._call_end_hook('test')\n    return unpack_singleton(outs)",
        "begin_line": 351,
        "end_line": 498,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0006176652254478073,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.constraints.serialize#160",
        "src_path": "keras/constraints.py",
        "class_name": "keras.constraints",
        "signature": "keras.constraints.serialize(constraint)",
        "snippet": "def serialize(constraint):\n    return serialize_keras_object(constraint)",
        "begin_line": 160,
        "end_line": 161,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00037778617302606723,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.constraints.get#171",
        "src_path": "keras/constraints.py",
        "class_name": "keras.constraints",
        "signature": "keras.constraints.get(identifier)",
        "snippet": "def get(identifier):\n    if identifier is None:\n        return None\n    if isinstance(identifier, dict):\n        return deserialize(identifier)\n    elif isinstance(identifier, six.string_types):\n        config = {'class_name': str(identifier), 'config': {}}\n        return deserialize(config)\n    elif callable(identifier):\n        return identifier\n    else:\n        raise ValueError('Could not interpret constraint identifier: ' +\n                         str(identifier))",
        "begin_line": 171,
        "end_line": 183,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.000281610813855252,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.CallbackList.__init__#45",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.CallbackList",
        "signature": "keras.callbacks.callbacks.CallbackList.__init__(self, callbacks=None, queue_length=10)",
        "snippet": "    def __init__(self, callbacks=None, queue_length=10):\n        callbacks = callbacks or []\n        self.callbacks = [c for c in callbacks]\n        self.queue_length = queue_length\n        self.params = {}\n        self.model = None\n        self._reset_batch_timing()",
        "begin_line": 45,
        "end_line": 51,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00036913990402362494,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.CallbackList._reset_batch_timing#53",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.CallbackList",
        "signature": "keras.callbacks.callbacks.CallbackList._reset_batch_timing(self)",
        "snippet": "    def _reset_batch_timing(self):\n        self._delta_t_batch = 0.\n        self._delta_ts = defaultdict(lambda: deque([], maxlen=self.queue_length))",
        "begin_line": 53,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00036913990402362494,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.CallbackList.set_params#60",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.CallbackList",
        "signature": "keras.callbacks.callbacks.CallbackList.set_params(self, params)",
        "snippet": "    def set_params(self, params):\n        self.params = params\n        for callback in self.callbacks:\n            callback.set_params(params)",
        "begin_line": 60,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005083884087442806,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.CallbackList.set_model#65",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.CallbackList",
        "signature": "keras.callbacks.callbacks.CallbackList.set_model(self, model)",
        "snippet": "    def set_model(self, model):\n        self.model = model\n        for callback in self.callbacks:\n            callback.set_model(model)",
        "begin_line": 65,
        "end_line": 68,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005083884087442806,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.CallbackList._call_batch_hook#70",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.CallbackList",
        "signature": "keras.callbacks.callbacks.CallbackList._call_batch_hook(self, mode, hook, batch, logs=None)",
        "snippet": "    def _call_batch_hook(self, mode, hook, batch, logs=None):\n        \"\"\"Helper function for all batch_{begin | end} methods.\"\"\"\n        if not self.callbacks:\n            return\n        hook_name = 'on_{mode}_batch_{hook}'.format(mode=mode, hook=hook)\n        if hook == 'end':\n            if not hasattr(self, '_t_enter_batch'):\n                self._t_enter_batch = time.time()\n            # Batch is ending, calculate batch time\n            self._delta_t_batch = time.time() - self._t_enter_batch\n\n        logs = logs or {}\n        t_before_callbacks = time.time()\n        for callback in self.callbacks:\n            batch_hook = getattr(callback, hook_name)\n            batch_hook(batch, logs)\n        self._delta_ts[hook_name].append(time.time() - t_before_callbacks)\n\n        delta_t_median = np.median(self._delta_ts[hook_name])\n        if (self._delta_t_batch > 0. and\n           delta_t_median > 0.95 * self._delta_t_batch and\n           delta_t_median > 0.1):\n            warnings.warn(\n                'Method (%s) is slow compared '\n                'to the batch update (%f). Check your callbacks.'\n                % (hook_name, delta_t_median), RuntimeWarning)\n\n        if hook == 'begin':\n            self._t_enter_batch = time.time()",
        "begin_line": 70,
        "end_line": 98,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005083884087442806,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.CallbackList._call_begin_hook#100",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.CallbackList",
        "signature": "keras.callbacks.callbacks.CallbackList._call_begin_hook(self, mode)",
        "snippet": "    def _call_begin_hook(self, mode):\n        \"\"\"Helper function for on_{train|test|predict}_begin methods.\"\"\"\n        if mode == _TRAIN:\n            self.on_train_begin()\n        elif mode == _TEST:\n            self.on_test_begin()\n        else:\n            self.on_predict_begin()",
        "begin_line": 100,
        "end_line": 107,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0006176652254478073,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.CallbackList._call_end_hook#109",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.CallbackList",
        "signature": "keras.callbacks.callbacks.CallbackList._call_end_hook(self, mode)",
        "snippet": "    def _call_end_hook(self, mode):\n        \"\"\"Helper function for on_{train|test|predict}_end methods.\"\"\"\n        if mode == _TRAIN:\n            self.on_train_end()\n        elif mode == _TEST:\n            self.on_test_end()\n        else:\n            self.on_predict_end()",
        "begin_line": 109,
        "end_line": 116,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0006176652254478073,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.CallbackList.on_epoch_begin#124",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.CallbackList",
        "signature": "keras.callbacks.callbacks.CallbackList.on_epoch_begin(self, epoch, logs=None)",
        "snippet": "    def on_epoch_begin(self, epoch, logs=None):\n        \"\"\"Calls the `on_epoch_begin` methods of its callbacks.\n\n        This function should only be called during train mode.\n\n        # Arguments\n            epoch: integer, index of epoch.\n            logs: dict, Currently no data is passed to this argument for this method\n                but that may change in the future.\n        \"\"\"\n        logs = logs or {}\n        for callback in self.callbacks:\n            callback.on_epoch_begin(epoch, logs)\n        self._reset_batch_timing()",
        "begin_line": 124,
        "end_line": 137,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005083884087442806,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.CallbackList.on_epoch_end#139",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.CallbackList",
        "signature": "keras.callbacks.callbacks.CallbackList.on_epoch_end(self, epoch, logs=None)",
        "snippet": "    def on_epoch_end(self, epoch, logs=None):\n        \"\"\"Calls the `on_epoch_end` methods of its callbacks.\n\n        This function should only be called during train mode.\n\n        # Arguments\n            epoch: integer, index of epoch.\n            logs: dict, metric results for this training epoch, and for the\n                validation epoch if validation is performed. Validation result keys\n                are prefixed with `val_`.\n        \"\"\"\n        logs = logs or {}\n        for callback in self.callbacks:\n            callback.on_epoch_end(epoch, logs)",
        "begin_line": 139,
        "end_line": 152,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005083884087442806,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.CallbackList.on_train_begin#211",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.CallbackList",
        "signature": "keras.callbacks.callbacks.CallbackList.on_train_begin(self, logs=None)",
        "snippet": "    def on_train_begin(self, logs=None):\n        \"\"\"Calls the `on_train_begin` methods of its callbacks.\n\n        # Arguments\n            logs: dict, currently no data is passed to this argument for this method\n                but that may change in the future.\n        \"\"\"\n        for callback in self.callbacks:\n            callback.on_train_begin(logs)",
        "begin_line": 211,
        "end_line": 219,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005083884087442806,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.CallbackList.on_train_end#221",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.CallbackList",
        "signature": "keras.callbacks.callbacks.CallbackList.on_train_end(self, logs=None)",
        "snippet": "    def on_train_end(self, logs=None):\n        \"\"\"Calls the `on_train_end` methods of its callbacks.\n\n        # Arguments\n            logs: dict, currently no data is passed to this argument for this method\n                but that may change in the future.\n        \"\"\"\n        for callback in self.callbacks:\n            callback.on_train_end(logs)",
        "begin_line": 221,
        "end_line": 229,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005083884087442806,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.CallbackList.on_test_begin#231",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.CallbackList",
        "signature": "keras.callbacks.callbacks.CallbackList.on_test_begin(self, logs=None)",
        "snippet": "    def on_test_begin(self, logs=None):\n        \"\"\"Calls the `on_test_begin` methods of its callbacks.\n\n        # Arguments\n            logs: dict, currently no data is passed to this argument for this method\n                but that may change in the future.\n        \"\"\"\n        for callback in self.callbacks:\n            callback.on_test_begin(logs)",
        "begin_line": 231,
        "end_line": 239,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0006176652254478073,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.CallbackList.on_test_end#241",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.CallbackList",
        "signature": "keras.callbacks.callbacks.CallbackList.on_test_end(self, logs=None)",
        "snippet": "    def on_test_end(self, logs=None):\n        \"\"\"Calls the `on_test_end` methods of its callbacks.\n\n        # Arguments\n            logs: dict, currently no data is passed to this argument for this method\n                but that may change in the future.\n        \"\"\"\n        for callback in self.callbacks:\n            callback.on_test_end(logs)",
        "begin_line": 241,
        "end_line": 249,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0006176652254478073,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.CallbackList.on_predict_begin#251",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.CallbackList",
        "signature": "keras.callbacks.callbacks.CallbackList.on_predict_begin(self, logs=None)",
        "snippet": "    def on_predict_begin(self, logs=None):\n        \"\"\"Calls the `on_predict_begin` methods of its callbacks.\n\n        # Arguments\n            logs: dict, currently no data is passed to this argument for this method\n                but that may change in the future.\n        \"\"\"\n        for callback in self.callbacks:\n            callback.on_predict_begin(logs)",
        "begin_line": 251,
        "end_line": 259,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0004144218814753419,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.CallbackList.on_predict_end#261",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.CallbackList",
        "signature": "keras.callbacks.callbacks.CallbackList.on_predict_end(self, logs=None)",
        "snippet": "    def on_predict_end(self, logs=None):\n        \"\"\"Calls the `on_predict_end` methods of its callbacks.\n\n        # Arguments\n            logs: dict, currently no data is passed to this argument for this method\n                but that may change in the future.\n        \"\"\"\n        for callback in self.callbacks:\n            callback.on_predict_end(logs)",
        "begin_line": 261,
        "end_line": 269,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0004144218814753419,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.CallbackList.__iter__#271",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.CallbackList",
        "signature": "keras.callbacks.callbacks.CallbackList.__iter__(self)",
        "snippet": "    def __iter__(self):\n        return iter(self.callbacks)",
        "begin_line": 271,
        "end_line": 272,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005083884087442806,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.Callback.__init__#302",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.Callback",
        "signature": "keras.callbacks.callbacks.Callback.__init__(self)",
        "snippet": "    def __init__(self):\n        self.validation_data = None\n        self.model = None",
        "begin_line": 302,
        "end_line": 304,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005083884087442806,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.Callback.set_params#306",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.Callback",
        "signature": "keras.callbacks.callbacks.Callback.set_params(self, params)",
        "snippet": "    def set_params(self, params):\n        self.params = params",
        "begin_line": 306,
        "end_line": 307,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005083884087442806,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.Callback.set_model#309",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.Callback",
        "signature": "keras.callbacks.callbacks.Callback.set_model(self, model)",
        "snippet": "    def set_model(self, model):\n        self.model = model",
        "begin_line": 309,
        "end_line": 310,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005083884087442806,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.Callback.on_batch_begin#312",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.Callback",
        "signature": "keras.callbacks.callbacks.Callback.on_batch_begin(self, batch, logs=None)",
        "snippet": "    def on_batch_begin(self, batch, logs=None):\n        \"\"\"A backwards compatibility alias for `on_train_batch_begin`.\"\"\"",
        "begin_line": 312,
        "end_line": 313,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00044863167339614175,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.Callback.on_batch_end#315",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.Callback",
        "signature": "keras.callbacks.callbacks.Callback.on_batch_end(self, batch, logs=None)",
        "snippet": "    def on_batch_end(self, batch, logs=None):\n        \"\"\"A backwards compatibility alias for `on_train_batch_end`.\"\"\"",
        "begin_line": 315,
        "end_line": 316,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00044863167339614175,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.Callback.on_epoch_begin#318",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.Callback",
        "signature": "keras.callbacks.callbacks.Callback.on_epoch_begin(self, epoch, logs=None)",
        "snippet": "    def on_epoch_begin(self, epoch, logs=None):\n        \"\"\"Called at the start of an epoch.\n\n        Subclasses should override for any actions to run. This function should only\n        be called during train mode.\n\n        # Arguments\n            epoch: integer, index of epoch.\n            logs: dict, currently no data is passed to this argument for this method\n                but that may change in the future.\n        \"\"\"",
        "begin_line": 318,
        "end_line": 328,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00044863167339614175,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.Callback.on_train_batch_begin#343",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.Callback",
        "signature": "keras.callbacks.callbacks.Callback.on_train_batch_begin(self, batch, logs=None)",
        "snippet": "    def on_train_batch_begin(self, batch, logs=None):\n        \"\"\"Called at the beginning of a training batch in `fit` methods.\n\n        Subclasses should override for any actions to run.\n\n        # Arguments\n            batch: integer, index of batch within the current epoch.\n            logs: dict, has keys `batch` and `size` representing the current\n                batch number and the size of the batch.\n        \"\"\"\n        # For backwards compatibility\n        self.on_batch_begin(batch, logs=logs)",
        "begin_line": 343,
        "end_line": 354,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005083884087442806,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.Callback.on_train_batch_end#356",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.Callback",
        "signature": "keras.callbacks.callbacks.Callback.on_train_batch_end(self, batch, logs=None)",
        "snippet": "    def on_train_batch_end(self, batch, logs=None):\n        \"\"\"Called at the end of a training batch in `fit` methods.\n\n        Subclasses should override for any actions to run.\n\n        # Arguments\n            batch: integer, index of batch within the current epoch.\n            logs: dict, metric results for this batch.\n        \"\"\"\n        # For backwards compatibility\n        self.on_batch_end(batch, logs=logs)",
        "begin_line": 356,
        "end_line": 366,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005083884087442806,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.Callback.on_test_batch_begin#368",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.Callback",
        "signature": "keras.callbacks.callbacks.Callback.on_test_batch_begin(self, batch, logs=None)",
        "snippet": "    def on_test_batch_begin(self, batch, logs=None):\n        \"\"\"Called at the beginning of a batch in `evaluate` methods.\n\n        Also called at the beginning of a validation batch in the `fit` methods,\n        if validation data is provided.\n\n        Subclasses should override for any actions to run.\n\n        # Arguments\n            batch: integer, index of batch within the current epoch.\n            logs: dict, has keys `batch` and `size` representing the current\n                batch number and the size of the batch.\n        \"\"\"",
        "begin_line": 368,
        "end_line": 380,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0004764173415912339,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.Callback.on_test_batch_end#382",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.Callback",
        "signature": "keras.callbacks.callbacks.Callback.on_test_batch_end(self, batch, logs=None)",
        "snippet": "    def on_test_batch_end(self, batch, logs=None):\n        \"\"\"Called at the end of a batch in `evaluate` methods.\n\n        Also called at the end of a validation batch in the `fit` methods,\n        if validation data is provided.\n\n        Subclasses should override for any actions to run.\n\n        # Arguments\n            batch: integer, index of batch within the current epoch.\n            logs: dict, metric results for this batch.\n        \"\"\"",
        "begin_line": 382,
        "end_line": 393,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0004764173415912339,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.Callback.on_train_begin#416",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.Callback",
        "signature": "keras.callbacks.callbacks.Callback.on_train_begin(self, logs=None)",
        "snippet": "    def on_train_begin(self, logs=None):\n        \"\"\"Called at the beginning of training.\n\n        Subclasses should override for any actions to run.\n\n        # Arguments\n            logs: dict, currently no data is passed to this argument for this method\n                but that may change in the future.\n        \"\"\"",
        "begin_line": 416,
        "end_line": 424,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00044863167339614175,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.Callback.on_train_end#426",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.Callback",
        "signature": "keras.callbacks.callbacks.Callback.on_train_end(self, logs=None)",
        "snippet": "    def on_train_end(self, logs=None):\n        \"\"\"Called at the end of training.\n\n        Subclasses should override for any actions to run.\n\n        # Arguments\n            logs: dict, currently no data is passed to this argument for this method\n                but that may change in the future.\n        \"\"\"",
        "begin_line": 426,
        "end_line": 434,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00044863167339614175,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.Callback.on_test_begin#436",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.Callback",
        "signature": "keras.callbacks.callbacks.Callback.on_test_begin(self, logs=None)",
        "snippet": "    def on_test_begin(self, logs=None):\n        \"\"\"Called at the beginning of evaluation or validation.\n\n        Subclasses should override for any actions to run.\n\n        # Arguments\n            logs: dict, currently no data is passed to this argument for this method\n                but that may change in the future.\n        \"\"\"",
        "begin_line": 436,
        "end_line": 444,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0004764173415912339,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.Callback.on_test_end#446",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.Callback",
        "signature": "keras.callbacks.callbacks.Callback.on_test_end(self, logs=None)",
        "snippet": "    def on_test_end(self, logs=None):\n        \"\"\"Called at the end of evaluation or validation.\n\n        Subclasses should override for any actions to run.\n\n        # Arguments\n            logs: dict, currently no data is passed to this argument for this method\n                but that may change in the future.\n        \"\"\"",
        "begin_line": 446,
        "end_line": 454,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0004764173415912339,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.BaseLogger.__init__#489",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.BaseLogger",
        "signature": "keras.callbacks.callbacks.BaseLogger.__init__(self, stateful_metrics=None)",
        "snippet": "    def __init__(self, stateful_metrics=None):\n        if stateful_metrics:\n            self.stateful_metrics = set(stateful_metrics)\n        else:\n            self.stateful_metrics = set()",
        "begin_line": 489,
        "end_line": 493,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005083884087442806,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.BaseLogger.on_epoch_begin#495",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.BaseLogger",
        "signature": "keras.callbacks.callbacks.BaseLogger.on_epoch_begin(self, epoch, logs=None)",
        "snippet": "    def on_epoch_begin(self, epoch, logs=None):\n        self.seen = 0\n        self.totals = {}",
        "begin_line": 495,
        "end_line": 497,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005083884087442806,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.BaseLogger.on_batch_end#499",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.BaseLogger",
        "signature": "keras.callbacks.callbacks.BaseLogger.on_batch_end(self, batch, logs=None)",
        "snippet": "    def on_batch_end(self, batch, logs=None):\n        logs = logs or {}\n        batch_size = logs.get('size', 0)\n        self.seen += batch_size\n\n        for k, v in logs.items():\n            if k in self.stateful_metrics:\n                self.totals[k] = v\n            else:\n                if k in self.totals:\n                    self.totals[k] += v * batch_size\n                else:\n                    self.totals[k] = v * batch_size",
        "begin_line": 499,
        "end_line": 511,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005574136008918618,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.BaseLogger.on_epoch_end#513",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.BaseLogger",
        "signature": "keras.callbacks.callbacks.BaseLogger.on_epoch_end(self, epoch, logs=None)",
        "snippet": "    def on_epoch_end(self, epoch, logs=None):\n        if logs is not None:\n            for k in self.params['metrics']:\n                if k in self.totals:\n                    # Make value available to next callbacks.\n                    if k in self.stateful_metrics:\n                        logs[k] = self.totals[k]\n                    else:\n                        logs[k] = self.totals[k] / self.seen",
        "begin_line": 513,
        "end_line": 521,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005083884087442806,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.ProgbarLogger.__init__#553",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.ProgbarLogger",
        "signature": "keras.callbacks.callbacks.ProgbarLogger.__init__(self, count_mode='samples', stateful_metrics=None)",
        "snippet": "    def __init__(self, count_mode='samples',\n                 stateful_metrics=None):\n        super(ProgbarLogger, self).__init__()\n        if count_mode == 'samples':\n            self.use_steps = False\n        elif count_mode == 'steps':\n            self.use_steps = True\n        else:\n            raise ValueError('Unknown `count_mode`: ' + str(count_mode))\n        if stateful_metrics:\n            self.stateful_metrics = set(stateful_metrics)\n        else:\n            self.stateful_metrics = set()",
        "begin_line": 553,
        "end_line": 565,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.ProgbarLogger.on_train_begin#567",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.ProgbarLogger",
        "signature": "keras.callbacks.callbacks.ProgbarLogger.on_train_begin(self, logs=None)",
        "snippet": "    def on_train_begin(self, logs=None):\n        self.verbose = self.params['verbose']\n        self.epochs = self.params['epochs']",
        "begin_line": 567,
        "end_line": 569,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.ProgbarLogger.on_epoch_begin#571",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.ProgbarLogger",
        "signature": "keras.callbacks.callbacks.ProgbarLogger.on_epoch_begin(self, epoch, logs=None)",
        "snippet": "    def on_epoch_begin(self, epoch, logs=None):\n        if self.verbose:\n            print('Epoch %d/%d' % (epoch + 1, self.epochs))\n            if self.use_steps:\n                target = self.params['steps']\n            else:\n                target = self.params['samples']\n            self.target = target\n            self.progbar = Progbar(target=self.target,\n                                   verbose=self.verbose,\n                                   stateful_metrics=self.stateful_metrics)\n        self.seen = 0",
        "begin_line": 571,
        "end_line": 582,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.ProgbarLogger.on_batch_begin#584",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.ProgbarLogger",
        "signature": "keras.callbacks.callbacks.ProgbarLogger.on_batch_begin(self, batch, logs=None)",
        "snippet": "    def on_batch_begin(self, batch, logs=None):\n        if self.seen < self.target:\n            self.log_values = []",
        "begin_line": 584,
        "end_line": 586,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.ProgbarLogger.on_batch_end#588",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.ProgbarLogger",
        "signature": "keras.callbacks.callbacks.ProgbarLogger.on_batch_end(self, batch, logs=None)",
        "snippet": "    def on_batch_end(self, batch, logs=None):\n        logs = logs or {}\n        batch_size = logs.get('size', 0)\n        if self.use_steps:\n            self.seen += 1\n        else:\n            self.seen += batch_size\n\n        for k in self.params['metrics']:\n            if k in logs:\n                self.log_values.append((k, logs[k]))\n\n        # Skip progbar update for the last batch;\n        # will be handled by on_epoch_end.\n        if self.verbose and self.seen < self.target:\n            self.progbar.update(self.seen, self.log_values)",
        "begin_line": 588,
        "end_line": 603,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.ProgbarLogger.on_epoch_end#605",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.ProgbarLogger",
        "signature": "keras.callbacks.callbacks.ProgbarLogger.on_epoch_end(self, epoch, logs=None)",
        "snippet": "    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        for k in self.params['metrics']:\n            if k in logs:\n                self.log_values.append((k, logs[k]))\n        if self.verbose:\n            self.progbar.update(self.seen, self.log_values)",
        "begin_line": 605,
        "end_line": 611,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.History.on_train_begin#622",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.History",
        "signature": "keras.callbacks.callbacks.History.on_train_begin(self, logs=None)",
        "snippet": "    def on_train_begin(self, logs=None):\n        self.epoch = []\n        self.history = {}",
        "begin_line": 622,
        "end_line": 624,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005083884087442806,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.callbacks.callbacks.History.on_epoch_end#626",
        "src_path": "keras/callbacks/callbacks.py",
        "class_name": "keras.callbacks.callbacks.History",
        "signature": "keras.callbacks.callbacks.History.on_epoch_end(self, epoch, logs=None)",
        "snippet": "    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        self.epoch.append(epoch)\n        for k, v in logs.items():\n            self.history.setdefault(k, []).append(v)",
        "begin_line": 626,
        "end_line": 630,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005083884087442806,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.base_layer.Layer.__init__#94",
        "src_path": "keras/engine/base_layer.py",
        "class_name": "keras.engine.base_layer.Layer",
        "signature": "keras.engine.base_layer.Layer.__init__(self, **kwargs)",
        "snippet": "    def __init__(self, **kwargs):\n        self.input_spec = None\n        self.supports_masking = False\n        self.stateful = False\n\n        # These properties will be set upon call of self.build()\n        self._trainable_weights = []\n        self._non_trainable_weights = []\n        self._losses = []\n        self._updates = []\n        self._per_input_losses = {}\n        self._per_input_updates = {}\n        self._built = False\n\n        # These lists will be filled via successive calls\n        # to self._add_inbound_node().\n        self._inbound_nodes = []\n        self._outbound_nodes = []\n\n        # These properties should be set by the user via keyword arguments.\n        # note that 'dtype', 'input_shape' and 'batch_input_shape'\n        # are only applicable to input layers: do not pass these keywords\n        # to non-input layers.\n        allowed_kwargs = {'input_shape',\n                          'batch_input_shape',\n                          'batch_size',\n                          'dtype',\n                          'name',\n                          'trainable',\n                          'weights',\n                          'input_dtype',  # legacy\n                          }\n        for kwarg in kwargs:\n            if kwarg not in allowed_kwargs:\n                raise TypeError('Keyword argument not understood:', kwarg)\n        name = kwargs.get('name')\n        if not name:\n            prefix = self.__class__.__name__\n            name = _to_snake_case(prefix) + '_' + str(K.get_uid(prefix))\n        self.name = name\n\n        self.trainable = kwargs.get('trainable', True)\n        if 'input_shape' in kwargs or 'batch_input_shape' in kwargs:\n            # In this case we will later create an input layer\n            # to insert before the current layer\n            if 'batch_input_shape' in kwargs:\n                batch_input_shape = tuple(kwargs['batch_input_shape'])\n            elif 'input_shape' in kwargs:\n                if 'batch_size' in kwargs:\n                    batch_size = kwargs['batch_size']\n                else:\n                    batch_size = None\n                batch_input_shape = (\n                    batch_size,) + tuple(kwargs['input_shape'])\n            self.batch_input_shape = batch_input_shape\n\n            # Set dtype.\n            dtype = kwargs.get('dtype')\n            if dtype is None:\n                dtype = kwargs.get('input_dtype')\n            if dtype is None:\n                dtype = K.floatx()\n            self.dtype = dtype\n\n        if 'weights' in kwargs:\n            self._initial_weights = kwargs['weights']\n        else:\n            self._initial_weights = None",
        "begin_line": 94,
        "end_line": 161,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0004692632566870014,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.base_layer.Layer._node_key#164",
        "src_path": "keras/engine/base_layer.py",
        "class_name": "keras.engine.base_layer.Layer",
        "signature": "keras.engine.base_layer.Layer._node_key(layer, node_index)",
        "snippet": "    def _node_key(layer, node_index):\n        \"\"\"Converts a layer and its index to a unique (immutable type) name.\n\n        This function is used internally with `self._network_nodes`.\n\n        # Arguments\n            layer: The layer.\n            node_index: The layer's position (e.g. via enumerate) in a list of\n                nodes.\n\n        # Returns\n            The unique name.\n        \"\"\"\n        return layer.name + '_ib-' + str(node_index)",
        "begin_line": 164,
        "end_line": 177,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002961208172934557,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.base_layer.Layer.losses#180",
        "src_path": "keras/engine/base_layer.py",
        "class_name": "keras.engine.base_layer.Layer",
        "signature": "keras.engine.base_layer.Layer.losses(self)",
        "snippet": "    def losses(self):\n        return self._losses",
        "begin_line": 180,
        "end_line": 181,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00030731407498463427,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.base_layer.Layer.updates#184",
        "src_path": "keras/engine/base_layer.py",
        "class_name": "keras.engine.base_layer.Layer",
        "signature": "keras.engine.base_layer.Layer.updates(self)",
        "snippet": "    def updates(self):\n        if not self.trainable and not self.stateful:\n            return []\n        return self._updates",
        "begin_line": 184,
        "end_line": 187,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0004789272030651341,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.base_layer.Layer.built#190",
        "src_path": "keras/engine/base_layer.py",
        "class_name": "keras.engine.base_layer.Layer",
        "signature": "keras.engine.base_layer.Layer.built(self)",
        "snippet": "    def built(self):\n        return self._built",
        "begin_line": 190,
        "end_line": 191,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002613012803762738,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.base_layer.Layer.built#194",
        "src_path": "keras/engine/base_layer.py",
        "class_name": "keras.engine.base_layer.Layer",
        "signature": "keras.engine.base_layer.Layer.built(self, value)",
        "snippet": "    def built(self, value):\n        self._built = value",
        "begin_line": 194,
        "end_line": 195,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002613012803762738,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.base_layer.Layer.trainable_weights#198",
        "src_path": "keras/engine/base_layer.py",
        "class_name": "keras.engine.base_layer.Layer",
        "signature": "keras.engine.base_layer.Layer.trainable_weights(self)",
        "snippet": "    def trainable_weights(self):\n        trainable = getattr(self, 'trainable', True)\n        if trainable:\n            return self._trainable_weights\n        else:\n            return []",
        "begin_line": 198,
        "end_line": 203,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0004144218814753419,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.base_layer.Layer.non_trainable_weights#210",
        "src_path": "keras/engine/base_layer.py",
        "class_name": "keras.engine.base_layer.Layer",
        "signature": "keras.engine.base_layer.Layer.non_trainable_weights(self)",
        "snippet": "    def non_trainable_weights(self):\n        trainable = getattr(self, 'trainable', True)\n        if not trainable:\n            return self._trainable_weights + self._non_trainable_weights\n        else:\n            return self._non_trainable_weights",
        "begin_line": 210,
        "end_line": 215,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00044863167339614175,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.base_layer.Layer.add_weight#222",
        "src_path": "keras/engine/base_layer.py",
        "class_name": "keras.engine.base_layer.Layer",
        "signature": "keras.engine.base_layer.Layer.add_weight(self, name, shape, dtype=None, initializer=None, regularizer=None, trainable=True, constraint=None)",
        "snippet": "    def add_weight(self,\n                   name,\n                   shape,\n                   dtype=None,\n                   initializer=None,\n                   regularizer=None,\n                   trainable=True,\n                   constraint=None):\n        \"\"\"Adds a weight variable to the layer.\n\n        # Arguments\n            name: String, the name for the weight variable.\n            shape: The shape tuple of the weight.\n            dtype: The dtype of the weight.\n            initializer: An Initializer instance (callable).\n            regularizer: An optional Regularizer instance.\n            trainable: A boolean, whether the weight should\n                be trained via backprop or not (assuming\n                that the layer itself is also trainable).\n            constraint: An optional Constraint instance.\n\n        # Returns\n            The created weight variable.\n        \"\"\"\n        initializer = initializers.get(initializer)\n        if dtype is None:\n            dtype = K.floatx()\n        weight = K.variable(initializer(shape),\n                            dtype=dtype,\n                            name=name,\n                            constraint=constraint)\n        if regularizer is not None:\n            with K.name_scope('weight_regularizer'):\n                self.add_loss(regularizer(weight))\n        if trainable:\n            self._trainable_weights.append(weight)\n        else:\n            self._non_trainable_weights.append(weight)\n        return weight",
        "begin_line": 222,
        "end_line": 260,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.000281610813855252,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.base_layer.Layer.assert_input_compatibility#262",
        "src_path": "keras/engine/base_layer.py",
        "class_name": "keras.engine.base_layer.Layer",
        "signature": "keras.engine.base_layer.Layer.assert_input_compatibility(self, inputs)",
        "snippet": "    def assert_input_compatibility(self, inputs):\n        \"\"\"Checks compatibility between the layer and provided inputs.\n\n        This checks that the tensor(s) `input`\n        verify the input assumptions of the layer\n        (if any). If not, exceptions are raised.\n\n        # Arguments\n            inputs: input tensor or list of input tensors.\n\n        # Raises\n            ValueError: in case of mismatch between\n                the provided inputs and the expectations of the layer.\n        \"\"\"\n        inputs = to_list(inputs)\n        for x in inputs:\n            try:\n                K.is_keras_tensor(x)\n            except ValueError:\n                raise ValueError('Layer ' + self.name + ' was called with '\n                                 'an input that isn\\'t a symbolic tensor. '\n                                 'Received type: ' +\n                                 str(type(x)) + '. Full input: ' +\n                                 str(inputs) + '. All inputs to the layer '\n                                 'should be tensors.')\n\n        if not self.input_spec:\n            return\n        if not isinstance(self.input_spec, (list, tuple)):\n            input_spec = to_list(self.input_spec)\n        else:\n            input_spec = self.input_spec\n        if len(inputs) != len(input_spec):\n            raise ValueError('Layer ' + self.name + ' expects ' +\n                             str(len(input_spec)) + ' inputs, '\n                             'but it received ' + str(len(inputs)) +\n                             ' input tensors. Input received: ' +\n                             str(inputs))\n        for input_index, (x, spec) in enumerate(zip(inputs, input_spec)):\n            if spec is None:\n                continue\n\n            # Check ndim.\n            if spec.ndim is not None:\n                if K.ndim(x) != spec.ndim:\n                    raise ValueError('Input ' + str(input_index) +\n                                     ' is incompatible with layer ' +\n                                     self.name + ': expected ndim=' +\n                                     str(spec.ndim) + ', found ndim=' +\n                                     str(K.ndim(x)))\n            if spec.max_ndim is not None:\n                ndim = K.ndim(x)\n                if ndim is not None and ndim > spec.max_ndim:\n                    raise ValueError('Input ' + str(input_index) +\n                                     ' is incompatible with layer ' +\n                                     self.name + ': expected max_ndim=' +\n                                     str(spec.max_ndim) + ', found ndim=' +\n                                     str(K.ndim(x)))\n            if spec.min_ndim is not None:\n                ndim = K.ndim(x)\n                if ndim is not None and ndim < spec.min_ndim:\n                    raise ValueError('Input ' + str(input_index) +\n                                     ' is incompatible with layer ' +\n                                     self.name + ': expected min_ndim=' +\n                                     str(spec.min_ndim) + ', found ndim=' +\n                                     str(K.ndim(x)))\n            # Check dtype.\n            if spec.dtype is not None:\n                if K.dtype(x) != spec.dtype:\n                    raise ValueError('Input ' + str(input_index) +\n                                     ' is incompatible with layer ' +\n                                     self.name + ': expected dtype=' +\n                                     str(spec.dtype) + ', found dtype=' +\n                                     str(K.dtype(x)))\n            # Check specific shape axes.\n            if spec.axes:\n                try:\n                    x_shape = K.int_shape(x)\n                except TypeError:\n                    x_shape = None\n                if x_shape is not None:\n                    for axis, value in spec.axes.items():\n                        if (value is not None and\n                                x_shape[int(axis)] not in {value, None}):\n                            raise ValueError(\n                                'Input ' + str(input_index) +\n                                ' is incompatible with layer ' +\n                                self.name + ': expected axis ' +\n                                str(axis) + ' of input shape to have '\n                                'value ' + str(value) +\n                                ' but got shape ' + str(x_shape))\n            # Check shape.\n            if spec.shape is not None:\n                try:\n                    x_shape = K.int_shape(x)\n                except TypeError:\n                    x_shape = None\n                if x_shape is not None:\n                    for spec_dim, dim in zip(spec.shape, x_shape):\n                        if spec_dim is not None and dim is not None:\n                            if spec_dim != dim:\n                                raise ValueError(\n                                    'Input ' + str(input_index) +\n                                    ' is incompatible with layer ' +\n                                    self.name + ': expected shape=' +\n                                    str(spec.shape) + ', found shape=' +\n                                    str(x_shape))",
        "begin_line": 262,
        "end_line": 368,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.base_layer.Layer.call#370",
        "src_path": "keras/engine/base_layer.py",
        "class_name": "keras.engine.base_layer.Layer",
        "signature": "keras.engine.base_layer.Layer.call(self, inputs, **kwargs)",
        "snippet": "    def call(self, inputs, **kwargs):\n        \"\"\"This is where the layer's logic lives.\n\n        # Arguments\n            inputs: Input tensor, or list/tuple of input tensors.\n            **kwargs: Additional keyword arguments.\n\n        # Returns\n            A tensor or list/tuple of tensors.\n        \"\"\"\n        return inputs",
        "begin_line": 370,
        "end_line": 380,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.base_layer.Layer.__call__#383",
        "src_path": "keras/engine/base_layer.py",
        "class_name": "keras.engine.base_layer.Layer",
        "signature": "keras.engine.base_layer.Layer.__call__(self, inputs, **kwargs)",
        "snippet": "    def __call__(self, inputs, **kwargs):\n        \"\"\"Wrapper around self.call(), for handling internal references.\n\n        If a Keras tensor is passed:\n            - We call self._add_inbound_node().\n            - If necessary, we `build` the layer to match\n                the _keras_shape of the input(s).\n            - We update the _keras_shape of every input tensor with\n                its new shape (obtained via self.compute_output_shape).\n                This is done as part of _add_inbound_node().\n            - We update the _keras_history of the output tensor(s)\n                with the current layer.\n                This is done as part of _add_inbound_node().\n\n        # Arguments\n            inputs: Can be a tensor or list/tuple of tensors.\n            **kwargs: Additional keyword arguments to be passed to `call()`.\n\n        # Returns\n            Output of the layer's `call` method.\n\n        # Raises\n            ValueError: in case the layer is missing shape information\n                for its `build` call.\n        \"\"\"\n        if isinstance(inputs, list):\n            inputs = inputs[:]\n        with K.name_scope(self.name):\n            # Handle laying building (weight creating, input spec locking).\n            if not self.built:\n                # Raise exceptions in case the input is not compatible\n                # with the input_spec specified in the layer constructor.\n                self.assert_input_compatibility(inputs)\n\n                # Collect input shapes to build layer.\n                input_shapes = []\n                for x_elem in to_list(inputs):\n                    if hasattr(x_elem, '_keras_shape'):\n                        input_shapes.append(x_elem._keras_shape)\n                    elif hasattr(K, 'int_shape'):\n                        input_shapes.append(K.int_shape(x_elem))\n                    else:\n                        raise ValueError('You tried to call layer \"' +\n                                         self.name +\n                                         '\". This layer has no information'\n                                         ' about its expected input shape, '\n                                         'and thus cannot be built. '\n                                         'You can build it manually via: '\n                                         '`layer.build(batch_input_shape)`')\n                self.build(unpack_singleton(input_shapes))\n                self.built = True\n\n                # Load weights that were specified at layer instantiation.\n                if self._initial_weights is not None:\n                    self.set_weights(self._initial_weights)\n\n            # Raise exceptions in case the input is not compatible\n            # with the input_spec set at build time.\n            self.assert_input_compatibility(inputs)\n\n            # Handle mask propagation.\n            previous_mask = _collect_previous_mask(inputs)\n            user_kwargs = copy.copy(kwargs)\n            if not is_all_none(previous_mask):\n                # The previous layer generated a mask.\n                if has_arg(self.call, 'mask'):\n                    if 'mask' not in kwargs:\n                        # If mask is explicitly passed to __call__,\n                        # we should override the default mask.\n                        kwargs['mask'] = previous_mask\n            # Handle automatic shape inference (only useful for Theano).\n            input_shape = _collect_input_shape(inputs)\n\n            # Actually call the layer,\n            # collecting output(s), mask(s), and shape(s).\n            output = self.call(inputs, **kwargs)\n            output_mask = self.compute_mask(inputs, previous_mask)\n\n            # If the layer returns tensors from its inputs, unmodified,\n            # we copy them to avoid loss of tensor metadata.\n            output_ls = to_list(output)\n            inputs_ls = to_list(inputs)\n            output_ls_copy = []\n            for x in output_ls:\n                if x in inputs_ls:\n                    x = K.identity(x)\n                output_ls_copy.append(x)\n            output = unpack_singleton(output_ls_copy)\n\n            # Inferring the output shape is only relevant for Theano.\n            if all([s is not None\n                    for s in to_list(input_shape)]):\n                output_shape = self.compute_output_shape(input_shape)\n            else:\n                if isinstance(input_shape, list):\n                    output_shape = [None for _ in input_shape]\n                else:\n                    output_shape = None\n\n            if (not isinstance(output_mask, (list, tuple)) and\n                    len(output_ls) > 1):\n                # Augment the mask to match the length of the output.\n                output_mask = [output_mask] * len(output_ls)\n\n            # Add an inbound node to the layer, so that it keeps track\n            # of the call and of all new variables created during the call.\n            # This also updates the layer history of the output tensor(s).\n            # If the input tensor(s) had not previous Keras history,\n            # this does nothing.\n            self._add_inbound_node(input_tensors=inputs,\n                                   output_tensors=output,\n                                   input_masks=previous_mask,\n                                   output_masks=output_mask,\n                                   input_shapes=input_shape,\n                                   output_shapes=output_shape,\n                                   arguments=user_kwargs)\n\n            # Apply activity regularizer if any:\n            if (hasattr(self, 'activity_regularizer') and\n                    self.activity_regularizer is not None):\n                with K.name_scope('activity_regularizer'):\n                    regularization_losses = [\n                        self.activity_regularizer(x)\n                        for x in to_list(output)]\n                self.add_loss(regularization_losses,\n                              inputs=to_list(inputs))\n        return output",
        "begin_line": 383,
        "end_line": 509,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.base_layer.Layer._add_inbound_node#511",
        "src_path": "keras/engine/base_layer.py",
        "class_name": "keras.engine.base_layer.Layer",
        "signature": "keras.engine.base_layer.Layer._add_inbound_node(self, input_tensors, output_tensors, input_masks, output_masks, input_shapes, output_shapes, arguments=None)",
        "snippet": "    def _add_inbound_node(self, input_tensors, output_tensors,\n                          input_masks, output_masks,\n                          input_shapes, output_shapes, arguments=None):\n        \"\"\"Internal method to create an inbound node for the layer.\n\n        # Arguments\n            input_tensors: list of input tensors.\n            output_tensors: list of output tensors.\n            input_masks: list of input masks (a mask can be a tensor, or None).\n            output_masks: list of output masks\n                (a mask can be a tensor, or None).\n            input_shapes: list of input shape tuples.\n            output_shapes: list of output shape tuples.\n            arguments: dictionary of keyword arguments that were passed to the\n                `call` method of the layer at the call that created the node.\n        \"\"\"\n        input_tensors = to_list(input_tensors)\n        output_tensors = to_list(output_tensors)\n        input_masks = to_list(input_masks)\n        output_masks = to_list(output_masks)\n        input_shapes = to_list(input_shapes)\n        output_shapes = to_list(output_shapes)\n\n        # Collect input tensor(s) coordinates.\n        inbound_layers = []\n        node_indices = []\n        tensor_indices = []\n        for x in input_tensors:\n            if hasattr(x, '_keras_history'):\n                inbound_layer, node_index, tensor_index = x._keras_history\n                inbound_layers.append(inbound_layer)\n                node_indices.append(node_index)\n                tensor_indices.append(tensor_index)\n            else:\n                inbound_layers.append(None)\n                node_indices.append(None)\n                tensor_indices.append(None)\n\n        # Create node, add it to inbound nodes.\n        Node(\n            self,\n            inbound_layers=inbound_layers,\n            node_indices=node_indices,\n            tensor_indices=tensor_indices,\n            input_tensors=input_tensors,\n            output_tensors=output_tensors,\n            input_masks=input_masks,\n            output_masks=output_masks,\n            input_shapes=input_shapes,\n            output_shapes=output_shapes,\n            arguments=arguments\n        )\n\n        # Update tensor history, _keras_shape and _uses_learning_phase.\n        for i in range(len(output_tensors)):\n            output_tensors[i]._keras_shape = output_shapes[i]\n            uses_lp = any(\n                [getattr(x, '_uses_learning_phase', False)\n                 for x in input_tensors])\n            uses_lp = getattr(self, 'uses_learning_phase', False) or uses_lp\n            output_tensors[i]._uses_learning_phase = getattr(\n                output_tensors[i], '_uses_learning_phase', False) or uses_lp\n            output_tensors[i]._keras_history = (self,\n                                                len(self._inbound_nodes) - 1,\n                                                i)",
        "begin_line": 511,
        "end_line": 575,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002613012803762738,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.base_layer.Layer.compute_output_shape#577",
        "src_path": "keras/engine/base_layer.py",
        "class_name": "keras.engine.base_layer.Layer",
        "signature": "keras.engine.base_layer.Layer.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        \"\"\"Computes the output shape of the layer.\n\n        Assumes that the layer will be built\n        to match that input shape provided.\n\n        # Arguments\n            input_shape: Shape tuple (tuple of integers)\n                or list of shape tuples (one per output tensor of the layer).\n                Shape tuples can include None for free dimensions,\n                instead of an integer.\n\n        # Returns\n            An input shape tuple.\n        \"\"\"\n        return input_shape",
        "begin_line": 577,
        "end_line": 592,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.base_layer.Layer.compute_mask#594",
        "src_path": "keras/engine/base_layer.py",
        "class_name": "keras.engine.base_layer.Layer",
        "signature": "keras.engine.base_layer.Layer.compute_mask(self, inputs, mask=None)",
        "snippet": "    def compute_mask(self, inputs, mask=None):\n        \"\"\"Computes an output mask tensor.\n\n        # Arguments\n            inputs: Tensor or list of tensors.\n            mask: Tensor or list of tensors.\n\n        # Returns\n            None or a tensor (or list of tensors,\n                one per output tensor of the layer).\n        \"\"\"\n        if not self.supports_masking:\n            if mask is not None:\n                if isinstance(mask, list):\n                    if any(m is not None for m in mask):\n                        raise TypeError('Layer ' + self.name +\n                                        ' does not support masking, '\n                                        'but was passed an input_mask: ' +\n                                        str(mask))\n                else:\n                    raise TypeError('Layer ' + self.name +\n                                    ' does not support masking, '\n                                    'but was passed an input_mask: ' +\n                                    str(mask))\n            # masking not explicitly supported: return None as mask\n            return None\n        # if masking is explicitly supported, by default\n        # carry over the input mask\n        return mask",
        "begin_line": 594,
        "end_line": 622,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.base_layer.Layer.build#624",
        "src_path": "keras/engine/base_layer.py",
        "class_name": "keras.engine.base_layer.Layer",
        "signature": "keras.engine.base_layer.Layer.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        \"\"\"Creates the layer weights.\n\n        Must be implemented on all layers that have weights.\n\n        # Arguments\n            input_shape: Keras tensor (future input to layer)\n                or list/tuple of Keras tensors to reference\n                for weight shape computations.\n        \"\"\"\n        self.built = True",
        "begin_line": 624,
        "end_line": 634,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0004297378599054577,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.base_layer.Layer._get_node_attribute_at_index#636",
        "src_path": "keras/engine/base_layer.py",
        "class_name": "keras.engine.base_layer.Layer",
        "signature": "keras.engine.base_layer.Layer._get_node_attribute_at_index(self, node_index, attr, attr_name)",
        "snippet": "    def _get_node_attribute_at_index(self, node_index, attr, attr_name):\n        \"\"\"Retrieves an attribute (e.g. input_tensors) from a node.\n\n        This is used to implement the methods:\n            - get_input_shape_at\n            - get_output_shape_at\n            - get_input_at\n            etc...\n\n        # Arguments\n            node_index: Integer index of the node from which\n                to retrieve the attribute.\n            attr: Exact node attribute name.\n            attr_name: Human-readable attribute name, for error messages.\n\n        # Returns\n            The layer's attribute `attr` at the node of index `node_index`.\n\n        # Raises\n            RuntimeError: If the layer has no inbound nodes.\n            ValueError: If the index is does not match any node.\n        \"\"\"\n        if not self._inbound_nodes:\n            raise RuntimeError('The layer has never been called '\n                               'and thus has no defined ' + attr_name + '.')\n        if not len(self._inbound_nodes) > node_index:\n            raise ValueError('Asked to get ' + attr_name +\n                             ' at node ' + str(node_index) +\n                             ', but the layer has only ' +\n                             str(len(self._inbound_nodes)) + ' inbound nodes.')\n        values = getattr(self._inbound_nodes[node_index], attr)\n        return unpack_singleton(values)",
        "begin_line": 636,
        "end_line": 667,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002613012803762738,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.base_layer.Layer.input#770",
        "src_path": "keras/engine/base_layer.py",
        "class_name": "keras.engine.base_layer.Layer",
        "signature": "keras.engine.base_layer.Layer.input(self)",
        "snippet": "    def input(self):\n        \"\"\"Retrieves the input tensor(s) of a layer.\n\n        Only applicable if the layer has exactly one inbound node,\n        i.e. if it is connected to one incoming layer.\n\n        # Returns\n            Input tensor or list of input tensors.\n\n        # Raises\n            AttributeError: if the layer is connected to\n            more than one incoming layers.\n        \"\"\"\n        if len(self._inbound_nodes) > 1:\n            raise AttributeError('Layer ' + self.name +\n                                 ' has multiple inbound nodes, '\n                                 'hence the notion of \"layer input\" '\n                                 'is ill-defined. '\n                                 'Use `get_input_at(node_index)` instead.')\n        elif not self._inbound_nodes:\n            raise AttributeError('Layer ' + self.name +\n                                 ' is not connected, no input to return.')\n        return self._get_node_attribute_at_index(0, 'input_tensors',\n                                                 'input')",
        "begin_line": 770,
        "end_line": 793,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002613012803762738,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.base_layer.Layer.add_loss#935",
        "src_path": "keras/engine/base_layer.py",
        "class_name": "keras.engine.base_layer.Layer",
        "signature": "keras.engine.base_layer.Layer.add_loss(self, losses, inputs=None)",
        "snippet": "    def add_loss(self, losses, inputs=None):\n        \"\"\"Adds losses to the layer.\n\n        The loss may potentially be conditional on some inputs tensors,\n        for instance activity losses are conditional on the layer's inputs.\n\n        # Arguments\n            losses: loss tensor or list of loss tensors\n                to add to the layer.\n            inputs: input tensor or list of inputs tensors to mark\n                the losses as conditional on these inputs.\n                If None is passed, the loss is assumed unconditional\n                (e.g. L2 weight regularization, which only depends\n                on the layer's weights variables, not on any inputs tensors).\n        \"\"\"\n        if losses is None or losses == []:\n            return\n        # Update self.losses\n        losses = to_list(losses)\n        if hasattr(self, '_losses'):\n            self._losses += losses\n        # Update self._per_input_updates\n        if isinstance(inputs, list) and inputs == []:\n            inputs = None\n        if inputs is not None:\n            inputs_hash = object_list_uid(inputs)\n        else:\n            # Updates indexed by None are unconditional\n            # rather than input-dependent\n            inputs_hash = None\n        if inputs_hash not in self._per_input_losses:\n            self._per_input_losses[inputs_hash] = []\n        self._per_input_losses[inputs_hash] += losses",
        "begin_line": 935,
        "end_line": 967,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.base_layer.Layer.add_update#969",
        "src_path": "keras/engine/base_layer.py",
        "class_name": "keras.engine.base_layer.Layer",
        "signature": "keras.engine.base_layer.Layer.add_update(self, updates, inputs=None)",
        "snippet": "    def add_update(self, updates, inputs=None):\n        \"\"\"Adds updates to the layer.\n\n        The updates may potentially be conditional on some inputs tensors,\n        for instance batch norm updates are conditional on the layer's inputs.\n\n        # Arguments\n            updates: update op or list of update ops\n                to add to the layer.\n            inputs: input tensor or list of inputs tensors to mark\n                the updates as conditional on these inputs.\n                If None is passed, the updates are assumed unconditional.\n        \"\"\"\n        if updates is None or updates == []:\n            return\n        # Update self.updates\n        updates = to_list(updates)\n        if hasattr(self, '_updates'):\n            self._updates += updates\n        # Update self._per_input_updates\n        if isinstance(inputs, list) and inputs == []:\n            inputs = None\n        if inputs is not None:\n            inputs_hash = object_list_uid(inputs)\n        else:\n            # Updates indexed by None are unconditional\n            # rather than input-dependent\n            inputs_hash = None\n        if inputs_hash not in self._per_input_updates:\n            self._per_input_updates[inputs_hash] = []\n        self._per_input_updates[inputs_hash] += updates",
        "begin_line": 969,
        "end_line": 999,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.base_layer.Layer.get_updates_for#1001",
        "src_path": "keras/engine/base_layer.py",
        "class_name": "keras.engine.base_layer.Layer",
        "signature": "keras.engine.base_layer.Layer.get_updates_for(self, inputs)",
        "snippet": "    def get_updates_for(self, inputs):\n        if not self.trainable and not self.stateful:\n            return []\n        if inputs is not None:\n            inputs_hash = object_list_uid(inputs)\n        else:\n            inputs_hash = None\n        if inputs_hash in self._per_input_updates:\n            return self._per_input_updates[inputs_hash]\n        return []",
        "begin_line": 1001,
        "end_line": 1010,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0004764173415912339,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.base_layer.Layer.get_losses_for#1012",
        "src_path": "keras/engine/base_layer.py",
        "class_name": "keras.engine.base_layer.Layer",
        "signature": "keras.engine.base_layer.Layer.get_losses_for(self, inputs)",
        "snippet": "    def get_losses_for(self, inputs):\n        if inputs is not None:\n            inputs_hash = object_list_uid(inputs)\n        else:\n            inputs_hash = None\n        if inputs_hash in self._per_input_losses:\n            return self._per_input_losses[inputs_hash]\n        return []",
        "begin_line": 1012,
        "end_line": 1019,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00029859659599880563,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.base_layer.Layer.weights#1022",
        "src_path": "keras/engine/base_layer.py",
        "class_name": "keras.engine.base_layer.Layer",
        "signature": "keras.engine.base_layer.Layer.weights(self)",
        "snippet": "    def weights(self):\n        return self.trainable_weights + self.non_trainable_weights",
        "begin_line": 1022,
        "end_line": 1023,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00031655587211142766,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.base_layer.Layer.get_weights#1062",
        "src_path": "keras/engine/base_layer.py",
        "class_name": "keras.engine.base_layer.Layer",
        "signature": "keras.engine.base_layer.Layer.get_weights(self)",
        "snippet": "    def get_weights(self):\n        \"\"\"Returns the current weights of the layer.\n\n        # Returns\n            Weights values as a list of numpy arrays.\n        \"\"\"\n        params = self.weights\n        return K.batch_get_value(params)",
        "begin_line": 1062,
        "end_line": 1069,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.base_layer.Layer.get_config#1071",
        "src_path": "keras/engine/base_layer.py",
        "class_name": "keras.engine.base_layer.Layer",
        "signature": "keras.engine.base_layer.Layer.get_config(self)",
        "snippet": "    def get_config(self):\n        \"\"\"Returns the config of the layer.\n\n        A layer config is a Python dictionary (serializable)\n        containing the configuration of a layer.\n        The same layer can be reinstantiated later\n        (without its trained weights) from this configuration.\n\n        The config of a layer does not include connectivity\n        information, nor the layer class name. These are handled\n        by `Network` (one layer of abstraction above).\n\n        # Returns\n            Python dictionary.\n        \"\"\"\n        config = {'name': self.name,\n                  'trainable': self.trainable}\n        if hasattr(self, 'batch_input_shape'):\n            config['batch_input_shape'] = self.batch_input_shape\n        if hasattr(self, 'dtype'):\n            config['dtype'] = self.dtype\n        return config",
        "begin_line": 1071,
        "end_line": 1092,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0004692632566870014,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.base_layer.Layer.from_config#1095",
        "src_path": "keras/engine/base_layer.py",
        "class_name": "keras.engine.base_layer.Layer",
        "signature": "keras.engine.base_layer.Layer.from_config(cls, config)",
        "snippet": "    def from_config(cls, config):\n        \"\"\"Creates a layer from its config.\n\n        This method is the reverse of `get_config`,\n        capable of instantiating the same layer from the config\n        dictionary. It does not handle layer connectivity\n        (handled by Network), nor weights (handled by `set_weights`).\n\n        # Arguments\n            config: A Python dictionary, typically the\n                output of get_config.\n\n        # Returns\n            A layer instance.\n        \"\"\"\n        return cls(**config)",
        "begin_line": 1095,
        "end_line": 1110,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0003551136363636364,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.base_layer.InputSpec.__init__#1153",
        "src_path": "keras/engine/base_layer.py",
        "class_name": "keras.engine.base_layer.InputSpec",
        "signature": "keras.engine.base_layer.InputSpec.__init__(self, dtype=None, shape=None, ndim=None, max_ndim=None, min_ndim=None, axes=None)",
        "snippet": "    def __init__(self, dtype=None,\n                 shape=None,\n                 ndim=None,\n                 max_ndim=None,\n                 min_ndim=None,\n                 axes=None):\n        self.dtype = dtype\n        self.shape = shape\n        if shape is not None:\n            self.ndim = len(shape)\n        else:\n            self.ndim = ndim\n        self.max_ndim = max_ndim\n        self.min_ndim = min_ndim\n        self.axes = axes or {}",
        "begin_line": 1153,
        "end_line": 1167,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005083884087442806,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.base_layer.Node.__init__#1225",
        "src_path": "keras/engine/base_layer.py",
        "class_name": "keras.engine.base_layer.Node",
        "signature": "keras.engine.base_layer.Node.__init__(self, outbound_layer, inbound_layers, node_indices, tensor_indices, input_tensors, output_tensors, input_masks, output_masks, input_shapes, output_shapes, arguments=None)",
        "snippet": "    def __init__(self, outbound_layer,\n                 inbound_layers, node_indices, tensor_indices,\n                 input_tensors, output_tensors,\n                 input_masks, output_masks,\n                 input_shapes, output_shapes,\n                 arguments=None):\n        # Layer instance (NOT a list).\n        # this is the layer that takes a list of input tensors\n        # and turns them into a list of output tensors.\n        # the current node will be added to\n        # the inbound_nodes of outbound_layer.\n        self.outbound_layer = outbound_layer\n\n        # The following 3 properties describe where\n        # the input tensors come from: which layers,\n        # and for each layer, which node and which\n        # tensor output of each node.\n\n        # List of layer instances.\n        self.inbound_layers = inbound_layers\n        # List of integers, 1:1 mapping with inbound_layers.\n        self.node_indices = node_indices\n        # List of integers, 1:1 mapping with inbound_layers.\n        self.tensor_indices = tensor_indices\n\n        # Following 2 properties:\n        # tensor inputs and outputs of outbound_layer.\n\n        # List of tensors. 1:1 mapping with inbound_layers.\n        self.input_tensors = input_tensors\n        # List of tensors, created by outbound_layer.call().\n        self.output_tensors = output_tensors\n\n        # Following 2 properties: input and output masks.\n        # List of tensors, 1:1 mapping with input_tensor.\n        self.input_masks = input_masks\n        # List of tensors, created by outbound_layer.compute_mask().\n        self.output_masks = output_masks\n\n        # Following 2 properties: input and output shapes.\n\n        # List of shape tuples, shapes of input_tensors.\n        self.input_shapes = input_shapes\n        # List of shape tuples, shapes of output_tensors.\n        self.output_shapes = output_shapes\n\n        # Optional keyword arguments to layer's `call`.\n        self.arguments = arguments\n\n        # Add nodes to all layers involved.\n        for layer in inbound_layers:\n            if layer is not None:\n                layer._outbound_nodes.append(self)\n        outbound_layer._inbound_nodes.append(self)",
        "begin_line": 1225,
        "end_line": 1278,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002613012803762738,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.base_layer._collect_previous_mask#1297",
        "src_path": "keras/engine/base_layer.py",
        "class_name": "keras.engine.base_layer",
        "signature": "keras.engine.base_layer._collect_previous_mask(input_tensors)",
        "snippet": "def _collect_previous_mask(input_tensors):\n    \"\"\"Retrieves the output mask(s) of the previous node.\n\n    # Arguments\n        input_tensors: A tensor or list of tensors.\n\n    # Returns\n        A mask tensor or list of mask tensors.\n    \"\"\"\n    input_tensors = to_list(input_tensors)\n    masks = []\n    for x in input_tensors:\n        if hasattr(x, '_keras_history'):\n            inbound_layer, node_index, tensor_index = x._keras_history\n            node = inbound_layer._inbound_nodes[node_index]\n            mask = node.output_masks[tensor_index]\n            masks.append(mask)\n        else:\n            masks.append(None)\n    return unpack_singleton(masks)",
        "begin_line": 1297,
        "end_line": 1316,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002613012803762738,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.base_layer._to_snake_case#1319",
        "src_path": "keras/engine/base_layer.py",
        "class_name": "keras.engine.base_layer",
        "signature": "keras.engine.base_layer._to_snake_case(name)",
        "snippet": "def _to_snake_case(name):\n    intermediate = re.sub('(.)([A-Z][a-z0-9]+)', r'\\1_\\2', name)\n    insecure = re.sub('([a-z])([A-Z])', r'\\1_\\2', intermediate).lower()\n    # If the class is private the name starts with \"_\" which is not secure\n    # for creating scopes. We prefix the name with \"private\" in this case.\n    if insecure[0] != '_':\n        return insecure\n    return 'private' + insecure",
        "begin_line": 1319,
        "end_line": 1326,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002901073397156948,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.base_layer._collect_input_shape#1329",
        "src_path": "keras/engine/base_layer.py",
        "class_name": "keras.engine.base_layer",
        "signature": "keras.engine.base_layer._collect_input_shape(input_tensors)",
        "snippet": "def _collect_input_shape(input_tensors):\n    \"\"\"Collects the output shape(s) of a list of Keras tensors.\n\n    # Arguments\n        input_tensors: list of input tensors (or single input tensor).\n\n    # Returns\n        List of shape tuples (or single tuple), one tuple per input.\n    \"\"\"\n    input_tensors = to_list(input_tensors)\n    shapes = []\n    for x in input_tensors:\n        try:\n            shapes.append(K.int_shape(x))\n        except TypeError:\n            shapes.append(None)\n    return unpack_singleton(shapes)",
        "begin_line": 1329,
        "end_line": 1345,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002613012803762738,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.legacy.interfaces.legacy_support#26",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.legacy_support(func)",
        "snippet": "    def legacy_support(func):\n        @six.wraps(func)\n        def wrapper(*args, **kwargs):\n            if object_type == 'class':\n                object_name = args[0].__class__.__name__\n            else:\n                object_name = func.__name__\n            if preprocessor:\n                args, kwargs, converted = preprocessor(args, kwargs)\n            else:\n                converted = []\n            if check_positional_args:\n                if len(args) > len(allowed_positional_args) + 1:\n                    raise TypeError('`' + object_name +\n                                    '` can accept only ' +\n                                    str(len(allowed_positional_args)) +\n                                    ' positional arguments ' +\n                                    str(tuple(allowed_positional_args)) +\n                                    ', but you passed the following '\n                                    'positional arguments: ' +\n                                    str(list(args[1:])))\n            for key in value_conversions:\n                if key in kwargs:\n                    old_value = kwargs[key]\n                    if old_value in value_conversions[key]:\n                        kwargs[key] = value_conversions[key][old_value]\n            for old_name, new_name in conversions:\n                if old_name in kwargs:\n                    value = kwargs.pop(old_name)\n                    if new_name in kwargs:\n                        raise_duplicate_arg_error(old_name, new_name)\n                    kwargs[new_name] = value\n                    converted.append((new_name, old_name))\n            if converted:\n                signature = '`' + object_name + '('\n                for i, value in enumerate(args[1:]):\n                    if isinstance(value, six.string_types):\n                        signature += '\"' + value + '\"'\n                    else:\n                        if isinstance(value, np.ndarray):\n                            str_val = 'array'\n                        else:\n                            str_val = str(value)\n                        if len(str_val) > 10:\n                            str_val = str_val[:10] + '...'\n                        signature += str_val\n                    if i < len(args[1:]) - 1 or kwargs:\n                        signature += ', '\n                for i, (name, value) in enumerate(kwargs.items()):\n                    signature += name + '='\n                    if isinstance(value, six.string_types):\n                        signature += '\"' + value + '\"'\n                    else:\n                        if isinstance(value, np.ndarray):\n                            str_val = 'array'\n                        else:\n                            str_val = str(value)\n                        if len(str_val) > 10:\n                            str_val = str_val[:10] + '...'\n                        signature += str_val\n                    if i < len(kwargs) - 1:\n                        signature += ', '\n                signature += ')`'\n                warnings.warn('Update your `' + object_name + '` call to the ' +\n                              'Keras 2 API: ' + signature, stacklevel=2)\n            return func(*args, **kwargs)\n        wrapper._original_function = func\n        return wrapper",
        "begin_line": 26,
        "end_line": 93,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002613012803762738,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.legacy.interfaces.wrapper#28",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.wrapper(*args, **kwargs)",
        "snippet": "        def wrapper(*args, **kwargs):\n            if object_type == 'class':\n                object_name = args[0].__class__.__name__\n            else:\n                object_name = func.__name__\n            if preprocessor:\n                args, kwargs, converted = preprocessor(args, kwargs)\n            else:\n                converted = []\n            if check_positional_args:\n                if len(args) > len(allowed_positional_args) + 1:\n                    raise TypeError('`' + object_name +\n                                    '` can accept only ' +\n                                    str(len(allowed_positional_args)) +\n                                    ' positional arguments ' +\n                                    str(tuple(allowed_positional_args)) +\n                                    ', but you passed the following '\n                                    'positional arguments: ' +\n                                    str(list(args[1:])))\n            for key in value_conversions:\n                if key in kwargs:\n                    old_value = kwargs[key]\n                    if old_value in value_conversions[key]:\n                        kwargs[key] = value_conversions[key][old_value]\n            for old_name, new_name in conversions:\n                if old_name in kwargs:\n                    value = kwargs.pop(old_name)\n                    if new_name in kwargs:\n                        raise_duplicate_arg_error(old_name, new_name)\n                    kwargs[new_name] = value\n                    converted.append((new_name, old_name))\n            if converted:\n                signature = '`' + object_name + '('\n                for i, value in enumerate(args[1:]):\n                    if isinstance(value, six.string_types):\n                        signature += '\"' + value + '\"'\n                    else:\n                        if isinstance(value, np.ndarray):\n                            str_val = 'array'\n                        else:\n                            str_val = str(value)\n                        if len(str_val) > 10:\n                            str_val = str_val[:10] + '...'\n                        signature += str_val\n                    if i < len(args[1:]) - 1 or kwargs:\n                        signature += ', '\n                for i, (name, value) in enumerate(kwargs.items()):\n                    signature += name + '='\n                    if isinstance(value, six.string_types):\n                        signature += '\"' + value + '\"'\n                    else:\n                        if isinstance(value, np.ndarray):\n                            str_val = 'array'\n                        else:\n                            str_val = str(value)\n                        if len(str_val) > 10:\n                            str_val = str_val[:10] + '...'\n                        signature += str_val\n                    if i < len(kwargs) - 1:\n                        signature += ', '\n                signature += ')`'\n                warnings.warn('Update your `' + object_name + '` call to the ' +\n                              'Keras 2 API: ' + signature, stacklevel=2)\n            return func(*args, **kwargs)",
        "begin_line": 28,
        "end_line": 91,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0006756756756756757,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.legacy.interfaces.recurrent_args_preprocessor#157",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.recurrent_args_preprocessor(args, kwargs)",
        "snippet": "def recurrent_args_preprocessor(args, kwargs):\n    converted = []\n    if 'forget_bias_init' in kwargs:\n        if kwargs['forget_bias_init'] == 'one':\n            kwargs.pop('forget_bias_init')\n            kwargs['unit_forget_bias'] = True\n            converted.append(('forget_bias_init', 'unit_forget_bias'))\n        else:\n            kwargs.pop('forget_bias_init')\n            warnings.warn('The `forget_bias_init` argument '\n                          'has been ignored. Use `unit_forget_bias=True` '\n                          'instead to initialize with ones.', stacklevel=3)\n    if 'input_dim' in kwargs:\n        input_length = kwargs.pop('input_length', None)\n        input_dim = kwargs.pop('input_dim')\n        input_shape = (input_length, input_dim)\n        kwargs['input_shape'] = input_shape\n        converted.append(('input_dim', 'input_shape'))\n        warnings.warn('The `input_dim` and `input_length` arguments '\n                      'in recurrent layers are deprecated. '\n                      'Use `input_shape` instead.', stacklevel=3)\n    return args, kwargs, converted",
        "begin_line": 157,
        "end_line": 178,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.legacy.interfaces.conv2d_args_preprocessor#269",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.conv2d_args_preprocessor(args, kwargs)",
        "snippet": "def conv2d_args_preprocessor(args, kwargs):\n    converted = []\n    if len(args) > 4:\n        raise TypeError('Layer can receive at most 3 positional arguments.')\n    elif len(args) == 4:\n        if isinstance(args[2], int) and isinstance(args[3], int):\n            new_keywords = ['padding', 'strides', 'data_format']\n            for kwd in new_keywords:\n                if kwd in kwargs:\n                    raise ValueError(\n                        'It seems that you are using the Keras 2 '\n                        'and you are passing both `kernel_size` and `strides` '\n                        'as integer positional arguments. For safety reasons, '\n                        'this is disallowed. Pass `strides` '\n                        'as a keyword argument instead.')\n            kernel_size = (args[2], args[3])\n            args = [args[0], args[1], kernel_size]\n            converted.append(('kernel_size', 'nb_row/nb_col'))\n    elif len(args) == 3 and isinstance(args[2], int):\n        if 'nb_col' in kwargs:\n            kernel_size = (args[2], kwargs.pop('nb_col'))\n            args = [args[0], args[1], kernel_size]\n            converted.append(('kernel_size', 'nb_row/nb_col'))\n    elif len(args) == 2:\n        if 'nb_row' in kwargs and 'nb_col' in kwargs:\n            kernel_size = (kwargs.pop('nb_row'), kwargs.pop('nb_col'))\n            args = [args[0], args[1], kernel_size]\n            converted.append(('kernel_size', 'nb_row/nb_col'))\n    elif len(args) == 1:\n        if 'nb_row' in kwargs and 'nb_col' in kwargs:\n            kernel_size = (kwargs.pop('nb_row'), kwargs.pop('nb_col'))\n            kwargs['kernel_size'] = kernel_size\n            converted.append(('kernel_size', 'nb_row/nb_col'))\n    return args, kwargs, converted",
        "begin_line": 269,
        "end_line": 302,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.legacy.interfaces.add_weight_args_preprocessing#627",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.add_weight_args_preprocessing(args, kwargs)",
        "snippet": "def add_weight_args_preprocessing(args, kwargs):\n    if len(args) > 1:\n        if isinstance(args[1], (tuple, list)):\n            kwargs['shape'] = args[1]\n            args = (args[0],) + args[2:]\n            if len(args) > 1:\n                if isinstance(args[1], six.string_types):\n                    kwargs['name'] = args[1]\n                    args = (args[0],) + args[2:]\n    return args, kwargs, []",
        "begin_line": 627,
        "end_line": 636,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.000281610813855252,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.legacy.interfaces.get_updates_arg_preprocessing#644",
        "src_path": "keras/legacy/interfaces.py",
        "class_name": "keras.legacy.interfaces",
        "signature": "keras.legacy.interfaces.get_updates_arg_preprocessing(args, kwargs)",
        "snippet": "def get_updates_arg_preprocessing(args, kwargs):\n    # Old interface: (params, constraints, loss)\n    # New interface: (loss, params)\n    if len(args) > 4:\n        raise TypeError('`get_update` call received more arguments '\n                        'than expected.')\n    elif len(args) == 4:\n        # Assuming old interface.\n        opt, params, _, loss = args\n        kwargs['loss'] = loss\n        kwargs['params'] = params\n        return [opt], kwargs, []\n    elif len(args) == 3:\n        if isinstance(args[1], (list, tuple)):\n            assert isinstance(args[2], dict)\n            assert 'loss' in kwargs\n            opt, params, _ = args\n            kwargs['params'] = params\n            return [opt], kwargs, []\n    return args, kwargs, []",
        "begin_line": 644,
        "end_line": 663,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00034164673727365904,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.activations.softmax#14",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.softmax(x, axis=-1)",
        "snippet": "def softmax(x, axis=-1):\n    \"\"\"Softmax activation function.\n\n    # Arguments\n        x: Input tensor.\n        axis: Integer, axis along which the softmax normalization is applied.\n\n    # Returns\n        Tensor, output of softmax transformation.\n\n    # Raises\n        ValueError: In case `dim(x) == 1`.\n    \"\"\"\n    ndim = K.ndim(x)\n    if ndim == 2:\n        return K.softmax(x)\n    elif ndim > 2:\n        e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n        s = K.sum(e, axis=axis, keepdims=True)\n        return e / s\n    else:\n        raise ValueError('Cannot apply softmax to a tensor that is 1D. '\n                         'Received input: %s' % x)",
        "begin_line": 14,
        "end_line": 36,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.activations.relu#109",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.relu(x, alpha=0.0, max_value=None, threshold=0.0)",
        "snippet": "def relu(x, alpha=0., max_value=None, threshold=0.):\n    \"\"\"Rectified Linear Unit.\n\n    With default values, it returns element-wise `max(x, 0)`.\n\n    Otherwise, it follows:\n    `f(x) = max_value` for `x >= max_value`,\n    `f(x) = x` for `threshold <= x < max_value`,\n    `f(x) = alpha * (x - threshold)` otherwise.\n\n    # Arguments\n        x: Input tensor.\n        alpha: float. Slope of the negative part. Defaults to zero.\n        max_value: float. Saturation threshold.\n        threshold: float. Threshold value for thresholded activation.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return K.relu(x, alpha=alpha, max_value=max_value, threshold=threshold)",
        "begin_line": 109,
        "end_line": 128,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005574136008918618,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.activations.tanh#131",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.tanh(x)",
        "snippet": "def tanh(x):\n    \"\"\"Hyperbolic tangent activation function.\n    \"\"\"\n    return K.tanh(x)",
        "begin_line": 131,
        "end_line": 134,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.activations.hard_sigmoid#143",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.hard_sigmoid(x)",
        "snippet": "def hard_sigmoid(x):\n    \"\"\"Hard sigmoid activation function.\n\n    Faster to compute than sigmoid activation.\n\n    # Arguments\n        x: Input tensor.\n\n    # Returns\n        Hard sigmoid activation:\n\n        - `0` if `x < -2.5`\n        - `1` if `x > 2.5`\n        - `0.2 * x + 0.5` if `-2.5 <= x <= 2.5`.\n    \"\"\"\n    return K.hard_sigmoid(x)",
        "begin_line": 143,
        "end_line": 158,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.activations.linear#167",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.linear(x)",
        "snippet": "def linear(x):\n    \"\"\"Linear (i.e. identity) activation function.\n    \"\"\"\n    return x",
        "begin_line": 167,
        "end_line": 170,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002944640753828033,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.activations.serialize#173",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.serialize(activation)",
        "snippet": "def serialize(activation):\n    return activation.__name__",
        "begin_line": 173,
        "end_line": 174,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00037778617302606723,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.activations.deserialize#177",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.deserialize(name, custom_objects=None)",
        "snippet": "def deserialize(name, custom_objects=None):\n    return deserialize_keras_object(\n        name,\n        module_objects=globals(),\n        custom_objects=custom_objects,\n        printable_module_name='activation function')",
        "begin_line": 177,
        "end_line": 182,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00031496062992125983,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.activations.get#185",
        "src_path": "keras/activations.py",
        "class_name": "keras.activations",
        "signature": "keras.activations.get(identifier)",
        "snippet": "def get(identifier):\n    \"\"\"Get the `identifier` activation function.\n\n    # Arguments\n        identifier: None or str, name of the function.\n\n    # Returns\n        The activation function, `linear` if `identifier` is None.\n\n    # Raises\n        ValueError if unknown identifier\n    \"\"\"\n    if identifier is None:\n        return linear\n    if isinstance(identifier, six.string_types):\n        identifier = str(identifier)\n        return deserialize(identifier)\n    elif callable(identifier):\n        if isinstance(identifier, Layer):\n            warnings.warn(\n                'Do not pass a layer instance (such as {identifier}) as the '\n                'activation argument of another layer. Instead, advanced '\n                'activation layers should be used just like any other '\n                'layer in a model.'.format(\n                    identifier=identifier.__class__.__name__))\n        return identifier\n    else:\n        raise ValueError('Could not interpret '\n                         'activation function identifier:', identifier)",
        "begin_line": 185,
        "end_line": 213,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend._is_tf_1#42",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend._is_tf_1()",
        "snippet": "def _is_tf_1():\n    return tf.__version__.startswith('1.')",
        "begin_line": 42,
        "end_line": 43,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002965599051008304,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.is_symbolic#79",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.is_symbolic(x)",
        "snippet": "def is_symbolic(x):\n    return isinstance(x, tf.Tensor) and hasattr(x, 'op')",
        "begin_line": 79,
        "end_line": 80,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002901073397156948,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.eager#83",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.eager(func)",
        "snippet": "def eager(func):\n    \"\"\"Decorator used in TensorFlow 2.0 to exit the Keras graph.\n\n    # Arguments\n        func: Function to decorate.\n\n    # Returns\n        Decorated function.\n    \"\"\"\n    if _is_tf_1():\n        return func\n\n    global _SYMBOLIC_SCOPE\n\n    @functools.wraps(func)\n    def eager_fn_wrapper(*args, **kwargs):\n        prev_value = _SYMBOLIC_SCOPE.value\n        try:\n            _SYMBOLIC_SCOPE.value = False\n            with context.eager_mode():\n                out = func(*args, **kwargs)\n        finally:\n            _SYMBOLIC_SCOPE.value = prev_value\n        return out\n    return eager_fn_wrapper",
        "begin_line": 83,
        "end_line": 107,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.get_uid#110",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.get_uid(prefix='')",
        "snippet": "def get_uid(prefix=''):\n    \"\"\"Provides a unique UID given a string prefix.\n\n    # Arguments\n        prefix: string.\n\n    # Returns\n        An integer.\n\n    # Example\n    ```python\n        >>> keras.backend.get_uid('dense')\n        1\n        >>> keras.backend.get_uid('dense')\n        2\n    ```\n\n    \"\"\"\n    return tf_keras_backend.get_uid(prefix)",
        "begin_line": 110,
        "end_line": 128,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002613012803762738,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.epsilon#145",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.epsilon()",
        "snippet": "def epsilon():\n    \"\"\"Returns the value of the fuzz factor used in numeric expressions.\n\n    # Returns\n        A float.\n\n    # Example\n    ```python\n        >>> keras.backend.epsilon()\n        1e-07\n    ```\n    \"\"\"\n    return tf_keras_backend.epsilon()",
        "begin_line": 145,
        "end_line": 157,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00036913990402362494,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.floatx#184",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.floatx()",
        "snippet": "def floatx():\n    \"\"\"Returns the default float type, as a string.\n    (e.g. 'float16', 'float32', 'float64').\n\n    # Returns\n        String, the current default float type.\n\n    # Example\n    ```python\n        >>> keras.backend.floatx()\n        'float32'\n    ```\n    \"\"\"\n    return tf_keras_backend.floatx()",
        "begin_line": 184,
        "end_line": 197,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00024563989191844754,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.image_data_format#246",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.image_data_format()",
        "snippet": "def image_data_format():\n    \"\"\"Returns the default image data format convention.\n\n    # Returns\n        A string, either `'channels_first'` or `'channels_last'`\n\n    # Example\n    ```python\n        >>> keras.backend.image_data_format()\n        'channels_first'\n    ```\n    \"\"\"\n    return tf_keras_backend.image_data_format()",
        "begin_line": 246,
        "end_line": 258,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.normalize_data_format#280",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.normalize_data_format(value)",
        "snippet": "def normalize_data_format(value):\n    \"\"\"Checks that the value correspond to a valid data format.\n\n    # Arguments\n        value: String or None. `'channels_first'` or `'channels_last'`.\n\n    # Returns\n        A string, either `'channels_first'` or `'channels_last'`\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> K.normalize_data_format(None)\n        'channels_first'\n        >>> K.normalize_data_format('channels_last')\n        'channels_last'\n    ```\n\n    # Raises\n        ValueError: if `value` or the global `data_format` invalid.\n    \"\"\"\n    if value is None:\n        value = image_data_format()\n    data_format = value.lower()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('The `data_format` argument must be one of '\n                         '\"channels_first\", \"channels_last\". Received: ' +\n                         str(value))\n    return data_format",
        "begin_line": 280,
        "end_line": 308,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.learning_phase#312",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.learning_phase()",
        "snippet": "def learning_phase():\n    \"\"\"Returns the learning phase flag.\n\n    The learning phase flag is a bool tensor (0 = test, 1 = train)\n    to be passed as input to any Keras function\n    that uses a different behavior at train time and test time.\n\n    # Returns\n        Learning phase (scalar integer tensor or Python integer).\n    \"\"\"\n    lp = tf_keras_backend.learning_phase()\n    if _is_tf_1():\n        return lp\n    else:\n        if isinstance(lp, int):\n            return lp\n        if lp in _LEARNING_PHASE_CACHE:\n            return _LEARNING_PHASE_CACHE[lp]\n        with name_scope(''):\n            int_lp = tf.cast(lp, 'int32', name='learning_phase')\n        _LEARNING_PHASE_CACHE[lp] = int_lp\n        return int_lp",
        "begin_line": 312,
        "end_line": 333,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.get_session#349",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.get_session()",
        "snippet": "def get_session():\n    \"\"\"Returns the TF session to be used by the backend.\n\n    If a default TensorFlow session is available, we will return it.\n\n    Else, we will return the global Keras session.\n\n    If no global Keras session exists at this point:\n    we will create a new global session.\n\n    Note that you can manually set the global session\n    via `K.set_session(sess)`.\n\n    # Returns\n        A TensorFlow session.\n\n    # Raises\n        RuntimeError: if no session is available\n            (e.g. when using TensorFlow 2.0).\n    \"\"\"\n    if not _is_tf_1():\n        raise RuntimeError(\n            '`get_session` is not available '\n            'when using TensorFlow 2.0.')\n    if tf.executing_eagerly():\n        raise RuntimeError(\n            '`get_session` is not available when '\n            'TensorFlow is executing eagerly.')\n    return tf_keras_backend.get_session()",
        "begin_line": 349,
        "end_line": 377,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00030731407498463427,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.clear_session#401",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.clear_session()",
        "snippet": "def clear_session():\n    \"\"\"Destroys the current Keras graph and creates a new one.\n\n    Useful to avoid clutter from old models / layers.\n    \"\"\"\n    tf_keras_backend.clear_session()\n    global _LEARNING_PHASE_CACHE\n    _LEARNING_PHASE_CACHE = {}",
        "begin_line": 401,
        "end_line": 408,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00024563989191844754,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.v1_variable_initialization#411",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.v1_variable_initialization()",
        "snippet": "def v1_variable_initialization():\n    session = get_session()\n    with session.graph.as_default():\n        variables = tf.global_variables()\n        candidate_vars = []\n        for v in variables:\n            if not getattr(v, '_keras_initialized', False):\n                candidate_vars.append(v)\n        if candidate_vars:\n            # This step is expensive, so we only run it on variables\n            # not already marked as initialized.\n            is_initialized = session.run(\n                [tf.is_variable_initialized(v) for v in candidate_vars])\n            uninitialized_vars = []\n            for flag, v in zip(is_initialized, candidate_vars):\n                if not flag:\n                    uninitialized_vars.append(v)\n                v._keras_initialized = True\n            if uninitialized_vars:\n                session.run(tf.variables_initializer(uninitialized_vars))",
        "begin_line": 411,
        "end_line": 430,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00031969309462915604,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend._to_tensor#515",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend._to_tensor(x, dtype)",
        "snippet": "def _to_tensor(x, dtype):\n    \"\"\"Convert the input `x` to a tensor of type `dtype`.\n\n    # Arguments\n        x: An object to be converted (numpy array, list, tensors).\n        dtype: The destination type.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.convert_to_tensor(x, dtype=dtype)",
        "begin_line": 515,
        "end_line": 525,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00038955979742890534,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.is_sparse#528",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.is_sparse(tensor)",
        "snippet": "def is_sparse(tensor):\n    \"\"\"Returns whether a tensor is a sparse tensor.\n\n    # Arguments\n        tensor: A tensor instance.\n\n    # Returns\n        A boolean.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> a = K.placeholder((2, 2), sparse=False)\n        >>> print(K.is_sparse(a))\n        False\n        >>> b = K.placeholder((2, 2), sparse=True)\n        >>> print(K.is_sparse(b))\n        True\n    ```\n    \"\"\"\n    return isinstance(tensor, tf.SparseTensor)",
        "begin_line": 528,
        "end_line": 548,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002613012803762738,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.to_dense#552",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.to_dense(tensor)",
        "snippet": "def to_dense(tensor):\n    \"\"\"Converts a sparse tensor into a dense tensor and returns it.\n\n    # Arguments\n        tensor: A tensor instance (potentially sparse).\n\n    # Returns\n        A dense tensor.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> b = K.placeholder((2, 2), sparse=True)\n        >>> print(K.is_sparse(b))\n        True\n        >>> c = K.to_dense(b)\n        >>> print(K.is_sparse(c))\n        False\n    ```\n    \"\"\"\n    if is_sparse(tensor):\n        return tf.sparse.to_dense(tensor)\n    else:\n        return tensor",
        "begin_line": 552,
        "end_line": 575,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.variable#578",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.variable(value, dtype=None, name=None, constraint=None)",
        "snippet": "def variable(value, dtype=None, name=None, constraint=None):\n    \"\"\"Instantiates a variable and returns it.\n\n    # Arguments\n        value: Numpy array, initial value of the tensor.\n        dtype: Tensor type.\n        name: Optional name string for the tensor.\n        constraint: Optional projection function to be\n            applied to the variable after an optimizer update.\n\n    # Returns\n        A variable instance (with Keras metadata included).\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> val = np.array([[1, 2], [3, 4]])\n        >>> kvar = K.variable(value=val, dtype='float64', name='example_var')\n        >>> K.dtype(kvar)\n        'float64'\n        >>> print(kvar)\n        example_var\n        >>> K.eval(kvar)\n        array([[ 1.,  2.],\n               [ 3.,  4.]])\n    ```\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    v = tf_keras_backend.variable(\n        value, dtype=dtype, name=name, constraint=constraint)\n    if hasattr(value, 'tocoo'):\n        v._keras_shape = value.tocoo().shape\n    elif isinstance(value, np.ndarray):\n        v._keras_shape = value.shape\n    elif hasattr(value, 'shape'):\n        v._keras_shape = int_shape(value)\n    v._uses_learning_phase = False\n    return v",
        "begin_line": 578,
        "end_line": 616,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0006756756756756757,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.constant#619",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.constant(value, dtype=None, shape=None, name=None)",
        "snippet": "def constant(value, dtype=None, shape=None, name=None):\n    \"\"\"Creates a constant tensor.\n\n    # Arguments\n        value: A constant value (or list)\n        dtype: The type of the elements of the resulting tensor.\n        shape: Optional dimensions of resulting tensor.\n        name: Optional name for the tensor.\n\n    # Returns\n        A Constant Tensor.\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    with tf_ops.init_scope():\n        return tf.constant(value, dtype=dtype, shape=shape, name=name)",
        "begin_line": 619,
        "end_line": 634,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00028506271379703536,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.is_keras_tensor#637",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.is_keras_tensor(x)",
        "snippet": "def is_keras_tensor(x):\n    \"\"\"Returns whether `x` is a Keras tensor.\n\n    A \"Keras tensor\" is a tensor that was returned by a Keras layer,\n    (`Layer` class) or by `Input`.\n\n    # Arguments\n        x: A candidate tensor.\n\n    # Returns\n        A boolean: Whether the argument is a Keras tensor.\n\n    # Raises\n        ValueError: In case `x` is not a symbolic tensor.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> from keras.layers import Input, Dense\n        >>> np_var = numpy.array([1, 2])\n        >>> K.is_keras_tensor(np_var) # A numpy array is not a symbolic tensor.\n        ValueError\n        >>> k_var = tf.placeholder('float32', shape=(1,1))\n        >>> # A variable indirectly created outside of keras is not a Keras tensor.\n        >>> K.is_keras_tensor(k_var)\n        False\n        >>> keras_var = K.variable(np_var)\n        >>> # A variable created with the keras backend is not a Keras tensor.\n        >>> K.is_keras_tensor(keras_var)\n        False\n        >>> keras_placeholder = K.placeholder(shape=(2, 4, 5))\n        >>> # A placeholder is not a Keras tensor.\n        >>> K.is_keras_tensor(keras_placeholder)\n        False\n        >>> keras_input = Input([10])\n        >>> K.is_keras_tensor(keras_input) # An Input is a Keras tensor.\n        True\n        >>> keras_layer_output = Dense(10)(keras_input)\n        >>> # Any Keras layer output is a Keras tensor.\n        >>> K.is_keras_tensor(keras_layer_output)\n        True\n    ```\n    \"\"\"\n    if not is_tensor(x):\n        raise ValueError('Unexpectedly found an instance of type `' +\n                         str(type(x)) + '`. '\n                         'Expected a symbolic tensor instance.')\n    return hasattr(x, '_keras_history')",
        "begin_line": 637,
        "end_line": 684,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002613012803762738,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.is_tensor#687",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.is_tensor(x)",
        "snippet": "def is_tensor(x):\n    return isinstance(x, tf_ops._TensorLike) or tf_ops.is_dense_tensor_like(x)",
        "begin_line": 687,
        "end_line": 688,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002613012803762738,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.placeholder#692",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.placeholder(shape=None, ndim=None, dtype=None, sparse=False, name=None)",
        "snippet": "def placeholder(shape=None, ndim=None, dtype=None, sparse=False, name=None):\n    \"\"\"Instantiates a placeholder tensor and returns it.\n\n    # Arguments\n        shape: Shape of the placeholder\n            (integer tuple, may include `None` entries).\n        ndim: Number of axes of the tensor.\n            At least one of {`shape`, `ndim`} must be specified.\n            If both are specified, `shape` is used.\n        dtype: Placeholder type.\n        sparse: Boolean, whether the placeholder should have a sparse type.\n        name: Optional name string for the placeholder.\n\n    # Returns\n        Tensor instance (with Keras metadata included).\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> input_ph = K.placeholder(shape=(2, 4, 5))\n        >>> input_ph._keras_shape\n        (2, 4, 5)\n        >>> input_ph\n        <tf.Tensor 'Placeholder_4:0' shape=(2, 4, 5) dtype=float32>\n    ```\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    x = tf_keras_backend.placeholder(\n        shape=shape, ndim=ndim, dtype=dtype, sparse=sparse, name=name)\n    if shape is None:\n        if ndim is not None:\n            shape = tuple(None for _ in range(ndim))\n    x._keras_shape = shape\n    x._uses_learning_phase = False\n    return x",
        "begin_line": 692,
        "end_line": 727,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00030731407498463427,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.shape#746",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.shape(x)",
        "snippet": "def shape(x):\n    \"\"\"Returns the symbolic shape of a tensor or variable.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A symbolic shape (which is itself a tensor).\n\n    # Examples\n    ```python\n        # TensorFlow example\n        >>> from keras import backend as K\n        >>> tf_session = K.get_session()\n        >>> val = np.array([[1, 2], [3, 4]])\n        >>> kvar = K.variable(value=val)\n        >>> inputs = keras.backend.placeholder(shape=(2, 4, 5))\n        >>> K.shape(kvar)\n        <tf.Tensor 'Shape_8:0' shape=(2,) dtype=int32>\n        >>> K.shape(inputs)\n        <tf.Tensor 'Shape_9:0' shape=(3,) dtype=int32>\n        # To get integer shape (Instead, you can use K.int_shape(x))\n        >>> K.shape(kvar).eval(session=tf_session)\n        array([2, 2], dtype=int32)\n        >>> K.shape(inputs).eval(session=tf_session)\n        array([2, 4, 5], dtype=int32)\n    ```\n    \"\"\"\n    return tf.shape(x)",
        "begin_line": 746,
        "end_line": 774,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.int_shape#777",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.int_shape(x)",
        "snippet": "def int_shape(x):\n    \"\"\"Returns the shape of tensor or variable as a tuple of int or None entries.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tuple of integers (or None entries).\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> inputs = K.placeholder(shape=(2, 4, 5))\n        >>> K.int_shape(inputs)\n        (2, 4, 5)\n        >>> val = np.array([[1, 2], [3, 4]])\n        >>> kvar = K.variable(value=val)\n        >>> K.int_shape(kvar)\n        (2, 2)\n    ```\n\n    {{np_implementation}}\n    \"\"\"\n    if hasattr(x, '_keras_shape'):\n        return x._keras_shape\n    try:\n        if isinstance(x.shape, tuple):\n            return x.shape\n        return tuple(x.shape.as_list())\n    except ValueError:\n        return None",
        "begin_line": 777,
        "end_line": 807,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002613012803762738,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.ndim#810",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.ndim(x)",
        "snippet": "def ndim(x):\n    \"\"\"Returns the number of axes in a tensor, as an integer.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        Integer (scalar), number of axes.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> inputs = K.placeholder(shape=(2, 4, 5))\n        >>> val = np.array([[1, 2], [3, 4]])\n        >>> kvar = K.variable(value=val)\n        >>> K.ndim(inputs)\n        3\n        >>> K.ndim(kvar)\n        2\n    ```\n\n    {{np_implementation}}\n    \"\"\"\n    return x.shape.rank",
        "begin_line": 810,
        "end_line": 833,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002613012803762738,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.dtype#836",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.dtype(x)",
        "snippet": "def dtype(x):\n    \"\"\"Returns the dtype of a Keras tensor or variable, as a string.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        String, dtype of `x`.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> K.dtype(K.placeholder(shape=(2,4,5)))\n        'float32'\n        >>> K.dtype(K.placeholder(shape=(2,4,5), dtype='float32'))\n        'float32'\n        >>> K.dtype(K.placeholder(shape=(2,4,5), dtype='float64'))\n        'float64'\n        # Keras variable\n        >>> kvar = K.variable(np.array([[1, 2], [3, 4]]))\n        >>> K.dtype(kvar)\n        'float32_ref'\n        >>> kvar = K.variable(np.array([[1, 2], [3, 4]]), dtype='float32')\n        >>> K.dtype(kvar)\n        'float32_ref'\n    ```\n    {{np_implementation}}\n    \"\"\"\n    return x.dtype.base_dtype.name",
        "begin_line": 836,
        "end_line": 864,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00029859659599880563,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.eval#867",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.eval(x)",
        "snippet": "def eval(x):\n    \"\"\"Evaluates the value of a tensor.\n\n    # Arguments\n        x: A tensor.\n\n    # Returns\n        A Numpy array.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.variable(np.array([[1, 2], [3, 4]]), dtype='float32')\n        >>> K.eval(kvar)\n        array([[ 1.,  2.],\n               [ 3.,  4.]], dtype=float32)\n    ```\n    {{np_implementation}}\n    \"\"\"\n    if _is_tf_1():\n        return to_dense(x).eval(session=get_session())\n    if hasattr(x, 'numpy'):\n        with context.eager_mode():\n            return x.numpy()\n    eval_fn = function([], [x])\n    return eval_fn([])[0]",
        "begin_line": 867,
        "end_line": 892,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.zeros#895",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.zeros(shape, dtype=None, name=None)",
        "snippet": "def zeros(shape, dtype=None, name=None):\n    \"\"\"Instantiates an all-zeros variable and returns it.\n\n    # Arguments\n        shape: Tuple of integers, shape of returned Keras variable\n        dtype: String, data type of returned Keras variable\n        name: String, name of returned Keras variable\n\n    # Returns\n        A variable (including Keras metadata), filled with `0.0`.\n        Note that if `shape` was symbolic, we cannot return a variable,\n        and will return a dynamically-shaped tensor instead.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.zeros((3,4))\n        >>> K.eval(kvar)\n        array([[ 0.,  0.,  0.,  0.],\n               [ 0.,  0.,  0.,  0.],\n               [ 0.,  0.,  0.,  0.]], dtype=float32)\n    ```\n    {{np_implementation}}\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    with tf_ops.init_scope():\n        v = tf.zeros(shape=shape, dtype=dtype, name=name)\n        if py_all(v.shape.as_list()):\n            return variable(v, dtype=dtype, name=name)\n        return v",
        "begin_line": 895,
        "end_line": 925,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0004692632566870014,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.zeros_like#990",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.zeros_like(x, dtype=None, name=None)",
        "snippet": "def zeros_like(x, dtype=None, name=None):\n    \"\"\"Instantiates an all-zeros variable of the same shape as another tensor.\n\n    # Arguments\n        x: Keras variable or Keras tensor.\n        dtype: String, dtype of returned Keras variable.\n             None uses the dtype of x.\n        name: String, name for the variable to create.\n\n    # Returns\n        A Keras variable with the shape of x filled with zeros.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> kvar = K.variable(np.random.random((2,3)))\n        >>> kvar_zeros = K.zeros_like(kvar)\n        >>> K.eval(kvar_zeros)\n        array([[ 0.,  0.,  0.],\n               [ 0.,  0.,  0.]], dtype=float32)\n    ```\n    {{np_implementation}}\n    \"\"\"\n    return tf.zeros_like(x, dtype=dtype, name=name)",
        "begin_line": 990,
        "end_line": 1013,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.cast#1160",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.cast(x, dtype)",
        "snippet": "def cast(x, dtype):\n    \"\"\"Casts a tensor to a different dtype and returns it.\n\n    You can cast a Keras variable but it still returns a Keras tensor.\n\n    # Arguments\n        x: Keras tensor (or variable).\n        dtype: String, either (`'float16'`, `'float32'`, or `'float64'`).\n\n    # Returns\n        Keras tensor with dtype `dtype`.\n\n    # Example\n    ```python\n        >>> from keras import backend as K\n        >>> input = K.placeholder((2, 3), dtype='float32')\n        >>> input\n        <tf.Tensor 'Placeholder_2:0' shape=(2, 3) dtype=float32>\n        # It doesn't work in-place as below.\n        >>> K.cast(input, dtype='float16')\n        <tf.Tensor 'Cast_1:0' shape=(2, 3) dtype=float16>\n        >>> input\n        <tf.Tensor 'Placeholder_2:0' shape=(2, 3) dtype=float32>\n        # you need to assign it.\n        >>> input = K.cast(input, dtype='float16')\n        >>> input\n        <tf.Tensor 'Cast_2:0' shape=(2, 3) dtype=float16>\n    ```\n    \"\"\"\n    return tf.cast(x, dtype)",
        "begin_line": 1160,
        "end_line": 1189,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00029859659599880563,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.update#1196",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.update(x, new_x)",
        "snippet": "def update(x, new_x):\n    \"\"\"Update the value of `x` to `new_x`.\n\n    # Arguments\n        x: A `Variable`.\n        new_x: A tensor of same shape as `x`.\n\n    # Returns\n        The variable `x` updated.\n    \"\"\"\n    return tf_state_ops.assign(x, new_x)",
        "begin_line": 1196,
        "end_line": 1206,
        "comment": "",
        "is_bug": true,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00034164673727365904,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.update_add#1210",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.update_add(x, increment)",
        "snippet": "def update_add(x, increment):\n    \"\"\"Update the value of `x` by adding `increment`.\n\n    # Arguments\n        x: A `Variable`.\n        increment: A tensor of same shape as `x`.\n\n    # Returns\n        The variable `x` updated.\n    \"\"\"\n    return tf_state_ops.assign_add(x, increment)",
        "begin_line": 1210,
        "end_line": 1220,
        "comment": "",
        "is_bug": true,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00034164673727365904,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.dot#1259",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.dot(x, y)",
        "snippet": "def dot(x, y):\n    \"\"\"Multiplies 2 tensors (and/or variables) and returns a *tensor*.\n\n    When attempting to multiply a nD tensor\n    with a nD tensor, it reproduces the Theano behavior.\n    (e.g. `(2, 3) * (4, 3, 5) -> (2, 4, 5)`)\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A tensor, dot product of `x` and `y`.\n\n    # Examples\n    ```python\n        # dot product between tensors\n        >>> x = K.placeholder(shape=(2, 3))\n        >>> y = K.placeholder(shape=(3, 4))\n        >>> xy = K.dot(x, y)\n        >>> xy\n        <tf.Tensor 'MatMul_9:0' shape=(2, 4) dtype=float32>\n    ```\n\n    ```python\n        # dot product between tensors\n        >>> x = K.placeholder(shape=(32, 28, 3))\n        >>> y = K.placeholder(shape=(3, 4))\n        >>> xy = K.dot(x, y)\n        >>> xy\n        <tf.Tensor 'MatMul_9:0' shape=(32, 28, 4) dtype=float32>\n    ```\n\n    ```python\n        # Theano-like behavior example\n        >>> x = K.random_uniform_variable(shape=(2, 3), low=0, high=1)\n        >>> y = K.ones((4, 3, 5))\n        >>> xy = K.dot(x, y)\n        >>> K.int_shape(xy)\n        (2, 4, 5)\n    ```\n    {{np_implementation}}\n    \"\"\"\n    if ndim(x) is not None and (ndim(x) > 2 or ndim(y) > 2):\n        x_shape = []\n        for i, s in zip(int_shape(x), tf.unstack(tf.shape(x))):\n            if i is not None:\n                x_shape.append(i)\n            else:\n                x_shape.append(s)\n        x_shape = tuple(x_shape)\n        y_shape = []\n        for i, s in zip(int_shape(y), tf.unstack(tf.shape(y))):\n            if i is not None:\n                y_shape.append(i)\n            else:\n                y_shape.append(s)\n        y_shape = tuple(y_shape)\n        y_permute_dim = list(range(ndim(y)))\n        y_permute_dim = [y_permute_dim.pop(-2)] + y_permute_dim\n        xt = tf.reshape(x, [-1, x_shape[-1]])\n        yt = tf.reshape(tf.transpose(y, perm=y_permute_dim), [y_shape[-2], -1])\n        return tf.reshape(tf.matmul(xt, yt),\n                          x_shape[:-1] + y_shape[:-2] + y_shape[-1:])\n    if is_sparse(x):\n        out = tf.sparse.sparse_dense_matmul(x, y)\n    else:\n        out = tf.matmul(x, y)\n    return out",
        "begin_line": 1259,
        "end_line": 1327,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.000281610813855252,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.max#1588",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.max(x, axis=None, keepdims=False)",
        "snippet": "def max(x, axis=None, keepdims=False):\n    \"\"\"Maximum value in a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer or list of integers in [-rank(x), rank(x)),\n            the axes to find maximum values. If `None` (default), finds the\n            maximum over all dimensions.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with maximum values of `x`.\n\n    {{np_implementation}}\n    \"\"\"\n    return tf.reduce_max(x, axis, keepdims)",
        "begin_line": 1588,
        "end_line": 1606,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.sum#1630",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.sum(x, axis=None, keepdims=False)",
        "snippet": "def sum(x, axis=None, keepdims=False):\n    \"\"\"Sum of the values in a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer or list of integers in [-rank(x), rank(x)),\n            the axes to sum over. If `None` (default), sums over all\n            dimensions.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with sum of `x`.\n\n    {{np_implementation}}\n    \"\"\"\n    return tf.reduce_sum(x, axis, keepdims)",
        "begin_line": 1630,
        "end_line": 1648,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.prod#1651",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.prod(x, axis=None, keepdims=False)",
        "snippet": "def prod(x, axis=None, keepdims=False):\n    \"\"\"Multiplies the values in a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer or list of integers in [-rank(x), rank(x)),\n            the axes to compute the product. If `None` (default), computes\n            the product over all dimensions.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1. If `keepdims` is `True`,\n            the reduced dimension is retained with length 1.\n\n    # Returns\n        A tensor with the product of elements of `x`.\n\n    {{np_implementation}}\n    \"\"\"\n    return tf.reduce_prod(x, axis, keepdims)",
        "begin_line": 1651,
        "end_line": 1669,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.mean#1746",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.mean(x, axis=None, keepdims=False)",
        "snippet": "def mean(x, axis=None, keepdims=False):\n    \"\"\"Mean of a tensor, alongside the specified axis.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: An integer or list of integers in [-rank(x), rank(x)),\n            the axes to compute the mean. If `None` (default), computes\n            the mean over all dimensions.\n        keepdims: A boolean, whether to keep the dimensions or not.\n            If `keepdims` is `False`, the rank of the tensor is reduced\n            by 1 for each entry in `axis`. If `keepdims` is `True`,\n            the reduced dimensions are retained with length 1.\n\n    # Returns\n        A tensor with the mean of elements of `x`.\n    {{np_implementation}}\n    \"\"\"\n    if x.dtype.base_dtype == tf.bool:\n        x = tf.cast(x, floatx())\n    return tf.reduce_mean(x, axis, keepdims)",
        "begin_line": 1746,
        "end_line": 1765,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.any#1768",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.any(x, axis=None, keepdims=False)",
        "snippet": "def any(x, axis=None, keepdims=False):\n    \"\"\"Bitwise reduction (logical OR).\n\n    # Arguments\n        x: Tensor or variable.\n        axis: An integer or list of integers in [-rank(x), rank(x)),\n            the axes to compute the logical or. If `None` (default), computes\n            the logical or over all dimensions.\n        keepdims: whether the drop or broadcast the reduction axes.\n\n    # Returns\n        A uint8 tensor (0s and 1s).\n    {{np_implementation}}\n    \"\"\"\n    x = tf.cast(x, tf.bool)\n    return tf.reduce_any(x, axis, keepdims)",
        "begin_line": 1768,
        "end_line": 1783,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.argmax#1804",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.argmax(x, axis=-1)",
        "snippet": "def argmax(x, axis=-1):\n    \"\"\"Returns the index of the maximum value along an axis.\n\n    # Arguments\n        x: Tensor or variable.\n        axis: axis along which to perform the reduction.\n\n    # Returns\n        A tensor.\n    {{np_implementation}}\n    \"\"\"\n    return tf.argmax(x, axis)",
        "begin_line": 1804,
        "end_line": 1815,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00038955979742890534,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.square#1832",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.square(x)",
        "snippet": "def square(x):\n    \"\"\"Element-wise square.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.square(x)",
        "begin_line": 1832,
        "end_line": 1841,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00030731407498463427,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.abs#1844",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.abs(x)",
        "snippet": "def abs(x):\n    \"\"\"Element-wise absolute value.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.abs(x)",
        "begin_line": 1844,
        "end_line": 1853,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.sqrt#1856",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.sqrt(x)",
        "snippet": "def sqrt(x):\n    \"\"\"Element-wise square root.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    {{np_implementation}}\n    \"\"\"\n    zero = _to_tensor(0., x.dtype.base_dtype)\n    inf = _to_tensor(np.inf, x.dtype.base_dtype)\n    x = tf.clip_by_value(x, zero, inf)\n    return tf.sqrt(x)",
        "begin_line": 1856,
        "end_line": 1869,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00038955979742890534,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.exp#1872",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.exp(x)",
        "snippet": "def exp(x):\n    \"\"\"Element-wise exponential.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.exp(x)",
        "begin_line": 1872,
        "end_line": 1881,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.round#1920",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.round(x)",
        "snippet": "def round(x):\n    \"\"\"Element-wise rounding to the closest integer.\n\n    In case of tie, the rounding mode used is \"half to even\".\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.round(x)",
        "begin_line": 1920,
        "end_line": 1931,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.pow#1946",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.pow(x, a)",
        "snippet": "def pow(x, a):\n    \"\"\"Element-wise exponentiation.\n\n    # Arguments\n        x: Tensor or variable.\n        a: Python integer.\n\n    # Returns\n        A tensor.\n    {{np_implementation}}\n    \"\"\"\n    return tf.pow(x, a)",
        "begin_line": 1946,
        "end_line": 1957,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005574136008918618,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.equal#1983",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.equal(x, y)",
        "snippet": "def equal(x, y):\n    \"\"\"Element-wise equality between two tensors.\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n\n    {{np_implementation}}\n    \"\"\"\n    return tf.equal(x, y)",
        "begin_line": 1983,
        "end_line": 1995,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00038387715930902113,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.not_equal#1998",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.not_equal(x, y)",
        "snippet": "def not_equal(x, y):\n    \"\"\"Element-wise inequality between two tensors.\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A bool tensor.\n\n    {{np_implementation}}\n    \"\"\"\n    return tf.not_equal(x, y)",
        "begin_line": 1998,
        "end_line": 2010,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00029859659599880563,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.cos#2115",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.cos(x)",
        "snippet": "def cos(x):\n    \"\"\"Computes cos of x element-wise.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.cos(x)",
        "begin_line": 2115,
        "end_line": 2124,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.concatenate#2350",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.concatenate(tensors, axis=-1)",
        "snippet": "def concatenate(tensors, axis=-1):\n    \"\"\"Concatenates a list of tensors alongside the specified axis.\n\n    # Arguments\n        tensors: list of tensors to concatenate.\n        axis: concatenation axis.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if axis < 0:\n        rank = ndim(tensors[0])\n        if rank:\n            axis %= rank\n        else:\n            axis = 0\n    if py_all([is_sparse(x) for x in tensors]):\n        return tf.sparse.concat(axis, tensors)\n    else:\n        return tf.concat([to_dense(x) for x in tensors], axis)",
        "begin_line": 2350,
        "end_line": 2369,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.reshape#2372",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.reshape(x, shape)",
        "snippet": "def reshape(x, shape):\n    \"\"\"Reshapes a tensor to the specified shape.\n\n    # Arguments\n        x: Tensor or variable.\n        shape: Target shape tuple.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    return tf.reshape(x, shape)",
        "begin_line": 2372,
        "end_line": 2382,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0006176652254478073,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.repeat#2538",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.repeat(x, n)",
        "snippet": "def repeat(x, n):\n    \"\"\"Repeats a 2D tensor.\n\n    if `x` has shape (samples, dim) and `n` is `2`,\n    the output will have shape `(samples, 2, dim)`.\n\n    # Arguments\n        x: Tensor or variable.\n        n: Python integer, number of times to repeat.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    assert ndim(x) == 2\n    x = tf.expand_dims(x, 1)\n    pattern = tf.stack([1, n, 1])\n    return tf.tile(x, pattern)",
        "begin_line": 2538,
        "end_line": 2554,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.tile#2594",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.tile(x, n)",
        "snippet": "def tile(x, n):\n    \"\"\"Creates a tensor by tiling `x` by `n`.\n\n    # Arguments\n        x: A tensor or variable\n        n: A list of integer. The length must be the same as the number of\n            dimensions in `x`.\n\n    # Returns\n        A tiled tensor.\n    \"\"\"\n    if isinstance(n, int):\n        n = [n]\n    return tf.tile(x, n)",
        "begin_line": 2594,
        "end_line": 2607,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.batch_flatten#2622",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.batch_flatten(x)",
        "snippet": "def batch_flatten(x):\n    \"\"\"Turn a nD tensor into a 2D tensor with same 0th dimension.\n\n    In other words, it flattens each data samples of a batch.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    x = tf.reshape(x, tf.stack([-1, prod(shape(x)[1:])]))\n    return x",
        "begin_line": 2622,
        "end_line": 2634,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.expand_dims#2637",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.expand_dims(x, axis=-1)",
        "snippet": "def expand_dims(x, axis=-1):\n    \"\"\"Adds a 1-sized dimension at index \"axis\".\n\n    # Arguments\n        x: A tensor or variable.\n        axis: Position where to add a new axis.\n\n    # Returns\n        A tensor with expanded dimensions.\n    \"\"\"\n    return tf.expand_dims(x, axis)",
        "begin_line": 2637,
        "end_line": 2647,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.get_value#2823",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.get_value(x)",
        "snippet": "def get_value(x):\n    \"\"\"Returns the value of a variable.\n\n    # Arguments\n        x: input variable.\n\n    # Returns\n        A Numpy array.\n    \"\"\"\n    if _is_tf_1():\n        return x.eval(session=get_session())\n    else:\n        return x.numpy()",
        "begin_line": 2823,
        "end_line": 2835,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00040225261464199515,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.batch_get_value#2838",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.batch_get_value(ops)",
        "snippet": "def batch_get_value(ops):\n    \"\"\"Returns the value of more than one tensor variable.\n\n    # Arguments\n        ops: list of ops to run.\n\n    # Returns\n        A list of Numpy arrays.\n    \"\"\"\n    return tf_keras_backend.batch_get_value(ops)",
        "begin_line": 2838,
        "end_line": 2847,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00031655587211142766,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.batch_set_value#2861",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.batch_set_value(tuples)",
        "snippet": "def batch_set_value(tuples):\n    \"\"\"Sets the values of many tensor variables at once.\n\n    # Arguments\n        tuples: a list of tuples `(tensor, value)`.\n            `value` should be a Numpy array.\n    \"\"\"\n    tf_keras_backend.batch_set_value(tuples)",
        "begin_line": 2861,
        "end_line": 2868,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00031655587211142766,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.function#2908",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.function(inputs, outputs, updates=None, **kwargs)",
        "snippet": "def function(inputs, outputs, updates=None, **kwargs):\n    if _is_tf_1():\n        v1_variable_initialization()\n    return tf_keras_backend.function(inputs, outputs,\n                                     updates=updates,\n                                     **kwargs)",
        "begin_line": 2908,
        "end_line": 2913,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00031969309462915604,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.gradients#2917",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.gradients(loss, variables)",
        "snippet": "def gradients(loss, variables):\n    \"\"\"Returns the gradients of `loss` w.r.t. `variables`.\n\n    # Arguments\n        loss: Scalar tensor to minimize.\n        variables: List of variables.\n\n    # Returns\n        A gradients tensor.\n    \"\"\"\n    if _is_tf_1():\n        return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n    return tf.gradients(loss, variables)",
        "begin_line": 2917,
        "end_line": 2929,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00034164673727365904,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.rnn#2952",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.rnn(step_function, inputs, initial_states, go_backwards=False, mask=None, constants=None, unroll=False, input_length=None)",
        "snippet": "def rnn(step_function, inputs, initial_states,\n        go_backwards=False, mask=None, constants=None,\n        unroll=False, input_length=None):\n    \"\"\"Iterates over the time dimension of a tensor.\n\n    # Arguments\n        step_function:\n            Parameters:\n                inputs: Tensor with shape (samples, ...) (no time dimension),\n                    representing input for the batch of samples at a certain\n                    time step.\n                states: List of tensors.\n            Returns:\n                outputs: Tensor with shape (samples, ...) (no time dimension),\n                new_states: List of tensors, same length and shapes\n                    as 'states'.\n        inputs: Tensor of temporal data of shape (samples, time, ...)\n            (at least 3D).\n        initial_states: Tensor with shape (samples, ...) (no time dimension),\n            containing the initial values for the states used in\n            the step function.\n        go_backwards: Boolean. If True, do the iteration over the time\n            dimension in reverse order and return the reversed sequence.\n        mask: Binary tensor with shape (samples, time),\n            with a zero for every element that is masked.\n        constants: A list of constant values passed at each step.\n        unroll: Whether to unroll the RNN or to use a symbolic loop\n            (`while_loop` or `scan` depending on backend).\n        input_length: Static number of timesteps in the input.\n\n    # Returns\n        A tuple, `(last_output, outputs, new_states)`.\n\n        last_output: The latest output of the rnn, of shape `(samples, ...)`\n        outputs: Tensor with shape `(samples, time, ...)` where each\n            entry `outputs[s, t]` is the output of the step function\n            at time `t` for sample `s`.\n        new_states: List of tensors, latest states returned by\n            the step function, of shape `(samples, ...)`.\n\n    # Raises\n        ValueError: If input dimension is less than 3.\n        ValueError: If `unroll` is `True`\n            but input timestep is not a fixed number.\n        ValueError: If `mask` is provided (not `None`)\n            but states is not provided (`len(states)` == 0).\n\n    {{np_implementation}}\n    \"\"\"\n    last_output, outputs, new_states = tf_keras_backend.rnn(\n        step_function, inputs, initial_states,\n        go_backwards=go_backwards,\n        mask=mask,\n        constants=constants,\n        unroll=unroll,\n        input_length=input_length)\n    reachable = tf_utils.get_reachable_from_inputs([learning_phase()],\n                                                   targets=[last_output])\n    if last_output in reachable:\n        last_output._uses_learning_phase = True\n    return last_output, outputs, new_states",
        "begin_line": 2952,
        "end_line": 3012,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.relu#3147",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.relu(x, alpha=0.0, max_value=None, threshold=0.0)",
        "snippet": "def relu(x, alpha=0., max_value=None, threshold=0.):\n    \"\"\"Rectified linear unit.\n\n    With default values, it returns element-wise `max(x, 0)`.\n\n    Otherwise, it follows:\n    `f(x) = max_value` for `x >= max_value`,\n    `f(x) = x` for `threshold <= x < max_value`,\n    `f(x) = alpha * (x - threshold)` otherwise.\n\n    # Arguments\n        x: A tensor or variable.\n        alpha: A scalar, slope of negative section (default=`0.`).\n        max_value: float. Saturation threshold.\n        threshold: float. Threshold value for thresholded activation.\n\n    # Returns\n        A tensor.\n\n    {{np_implementation}}\n    \"\"\"\n\n    if alpha != 0.:\n        if max_value is None and threshold == 0.:\n            return tf.nn.leaky_relu(x, alpha=alpha)\n\n        if threshold != 0.:\n            negative_part = tf.nn.relu(-x + threshold)\n        else:\n            negative_part = tf.nn.relu(-x)\n\n    clip_max = max_value is not None\n\n    if threshold != 0:\n        # computes x for x > threshold else 0\n        x = x * tf.cast(tf.greater(x, threshold), floatx())\n    elif max_value == 6:\n        # if no threshold, then can use nn.relu6 native TF op for performance\n        x = tf.nn.relu6(x)\n        clip_max = False\n    else:\n        x = tf.nn.relu(x)\n\n    if clip_max:\n        max_value = _to_tensor(max_value, x.dtype.base_dtype)\n        zero = _to_tensor(0., x.dtype.base_dtype)\n        x = tf.clip_by_value(x, zero, max_value)\n\n    if alpha != 0:\n        alpha = _to_tensor(alpha, x.dtype.base_dtype)\n        x -= alpha * negative_part\n    return x",
        "begin_line": 3147,
        "end_line": 3198,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005574136008918618,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.softmax#3220",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.softmax(x, axis=-1)",
        "snippet": "def softmax(x, axis=-1):\n    \"\"\"Softmax of a tensor.\n\n    # Arguments\n        x: A tensor or variable.\n        axis: The dimension softmax would be performed on.\n            The default is -1 which indicates the last dimension.\n\n    # Returns\n        A tensor.\n\n    {{np_implementation}}\n    \"\"\"\n    return tf.nn.softmax(x, axis=axis)",
        "begin_line": 3220,
        "end_line": 3233,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005574136008918618,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.hard_sigmoid#3347",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.hard_sigmoid(x)",
        "snippet": "def hard_sigmoid(x):\n    \"\"\"Segment-wise linear approximation of sigmoid.\n\n    Faster than sigmoid.\n    Returns `0.` if `x < -2.5`, `1.` if `x > 2.5`.\n    In `-2.5 <= x <= 2.5`, returns `0.2 * x + 0.5`.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n\n    {{np_implementation}}\n    \"\"\"\n    return tf_keras_backend.hard_sigmoid(x)",
        "begin_line": 3347,
        "end_line": 3362,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.tanh#3365",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.tanh(x)",
        "snippet": "def tanh(x):\n    \"\"\"Element-wise tanh.\n\n    # Arguments\n        x: A tensor or variable.\n\n    # Returns\n        A tensor.\n\n    {{np_implementation}}\n    \"\"\"\n    return tf.nn.tanh(x)",
        "begin_line": 3365,
        "end_line": 3376,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend._preprocess_conv2d_input#3460",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend._preprocess_conv2d_input(x, data_format, force_transpose=False)",
        "snippet": "def _preprocess_conv2d_input(x, data_format, force_transpose=False):\n    \"\"\"Transpose and cast the input before the conv2d.\n\n    # Arguments\n        x: input tensor.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n        force_transpose: boolean, whether force to transpose input from NCHW to NHWC\n                        if the `data_format` is `\"channels_first\"`.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    # tensorflow doesn't support float64 for conv layer before 1.8.0\n    if (dtype(x) == 'float64' and\n            StrictVersion(tf.__version__.split('-')[0]) < StrictVersion('1.8.0')):\n        x = tf.cast(x, 'float32')\n    tf_data_format = 'NHWC'\n    if data_format == 'channels_first':\n        if not _has_nchw_support() or force_transpose:\n            x = tf.transpose(x, (0, 2, 3, 1))  # NCHW -> NHWC\n        else:\n            tf_data_format = 'NCHW'\n    return x, tf_data_format",
        "begin_line": 3460,
        "end_line": 3482,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend._preprocess_padding#3508",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend._preprocess_padding(padding)",
        "snippet": "def _preprocess_padding(padding):\n    \"\"\"Convert keras' padding to tensorflow's padding.\n\n    # Arguments\n        padding: string, `\"same\"` or `\"valid\"`.\n\n    # Returns\n        a string, `\"SAME\"` or `\"VALID\"`.\n\n    # Raises\n        ValueError: if `padding` is invalid.\n    \"\"\"\n    if padding == 'same':\n        padding = 'SAME'\n    elif padding == 'valid':\n        padding = 'VALID'\n    else:\n        raise ValueError('Invalid padding: ' + str(padding))\n    return padding",
        "begin_line": 3508,
        "end_line": 3526,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.conv2d#3582",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.conv2d(x, kernel, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1))",
        "snippet": "def conv2d(x, kernel, strides=(1, 1), padding='valid',\n           data_format=None, dilation_rate=(1, 1)):\n    \"\"\"2D convolution.\n\n    # Arguments\n        x: Tensor or variable.\n        kernel: kernel tensor.\n        strides: strides tuple.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n            Whether to use Theano or TensorFlow/CNTK data format\n            for inputs/kernels/outputs.\n        dilation_rate: tuple of 2 integers.\n\n    # Returns\n        A tensor, result of 2D convolution.\n\n    # Raises\n        ValueError: If `data_format` is neither\n            `\"channels_last\"` nor `\"channels_first\"`.\n    \"\"\"\n    data_format = normalize_data_format(data_format)\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n\n    padding = _preprocess_padding(padding)\n\n    # TF 2 arg conversion\n    kwargs = {}\n    if _is_tf_1():\n        kwargs['dilation_rate'] = dilation_rate\n    else:\n        kwargs['dilations'] = dilation_rate\n\n    x = tf.nn.convolution(\n        x, kernel,\n        strides=strides,\n        padding=padding,\n        data_format=tf_data_format,\n        **kwargs)\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x",
        "begin_line": 3582,
        "end_line": 3624,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.bias_add#4145",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.bias_add(x, bias, data_format=None)",
        "snippet": "def bias_add(x, bias, data_format=None):\n    \"\"\"Adds a bias vector to a tensor.\n\n    # Arguments\n        x: Tensor or variable.\n        bias: Bias tensor to add.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        Output tensor.\n\n    # Raises\n        ValueError: In one of the two cases below:\n                    1. invalid `data_format` argument.\n                    2. invalid bias shape.\n                       the bias should be either a vector or\n                       a tensor with ndim(x) - 1 dimension\n    {{np_implementation}}\n    \"\"\"\n    data_format = normalize_data_format(data_format)\n    bias_shape = int_shape(bias)\n    if len(bias_shape) != 1 and len(bias_shape) != ndim(x) - 1:\n        raise ValueError('Unexpected bias dimensions %d, '\n                         'expect to be 1 or %d dimensions'\n                         % (len(bias_shape), ndim(x)))\n    if ndim(x) == 5:\n        if len(bias_shape) == 1:\n            new_shape = (1, 1, 1, 1, bias_shape[0])\n        else:\n            new_shape = (1,) + bias_shape\n        new_shape = transpose_shape(new_shape, data_format,\n                                    spatial_axes=(1, 2, 3))\n        x = x + reshape(bias, new_shape)\n    elif ndim(x) == 4:\n        if data_format == 'channels_first':\n            if len(bias_shape) == 1:\n                if _has_nchw_support():\n                    x = tf.nn.bias_add(x, bias,\n                                       data_format='NCHW')\n                else:\n                    x = x + reshape(bias, (1, bias_shape[0], 1, 1))\n            else:\n                x = x + reshape(bias, (1, bias_shape[2]) + bias_shape[:2])\n        elif data_format == 'channels_last':\n            if len(bias_shape) == 1:\n                x = tf.nn.bias_add(x, bias,\n                                   data_format='NHWC')\n            else:\n                x = x + reshape(bias, (1,) + bias_shape)\n    elif ndim(x) == 3:\n        if len(bias_shape) == 1:\n            new_shape = (1, 1, bias_shape[0])\n        else:\n            new_shape = (1,) + bias_shape\n        new_shape = transpose_shape(new_shape, data_format,\n                                    spatial_axes=(1,))\n        x = x + reshape(bias, new_shape)\n    else:\n        x = tf.nn.bias_add(x, bias)\n    return x",
        "begin_line": 4145,
        "end_line": 4204,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.backend.tensorflow_backend.random_uniform#4237",
        "src_path": "keras/backend/tensorflow_backend.py",
        "class_name": "keras.backend.tensorflow_backend",
        "signature": "keras.backend.tensorflow_backend.random_uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None)",
        "snippet": "def random_uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None):\n    \"\"\"Returns a tensor with uniform distribution of values.\n\n    # Arguments\n        shape: A tuple of integers, the shape of tensor to create.\n        minval: A float, lower boundary of the uniform distribution\n            to draw samples.\n        maxval: A float, upper boundary of the uniform distribution\n            to draw samples.\n        dtype: String, dtype of returned tensor.\n        seed: Integer, random seed.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if dtype is None:\n        dtype = floatx()\n    if seed is None:\n        seed = np.random.randint(10e6)\n    if py_any(list(is_symbolic(x) for x in (shape, minval, maxval))):\n        with get_graph().as_default():\n            return tf_keras_backend.random_uniform(\n                shape, minval=minval, maxval=maxval, dtype=dtype, seed=seed)\n    with tf_ops.init_scope():\n        return tf_keras_backend.random_uniform(\n            shape, minval=minval, maxval=maxval, dtype=dtype, seed=seed)",
        "begin_line": 4237,
        "end_line": 4262,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002901073397156948,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.input_layer.InputLayer.__init__#34",
        "src_path": "keras/engine/input_layer.py",
        "class_name": "keras.engine.input_layer.InputLayer",
        "signature": "keras.engine.input_layer.InputLayer.__init__(self, input_shape=None, batch_size=None, batch_input_shape=None, dtype=None, input_tensor=None, sparse=False, name=None)",
        "snippet": "    def __init__(self, input_shape=None, batch_size=None,\n                 batch_input_shape=None,\n                 dtype=None, input_tensor=None, sparse=False, name=None):\n        if not name:\n            prefix = 'input'\n            name = prefix + '_' + str(K.get_uid(prefix))\n        super(InputLayer, self).__init__(dtype=dtype, name=name)\n\n        self.trainable = False\n        self.built = True\n        self.sparse = sparse\n        self.supports_masking = True\n\n        if input_shape and batch_input_shape:\n            raise ValueError('Only provide the input_shape OR '\n                             'batch_input_shape argument to '\n                             'InputLayer, not both at the same time.')\n        if input_tensor is not None and batch_input_shape is None:\n            # If input_tensor is set, and batch_input_shape is not set:\n            # Attempt automatic input shape inference.\n            try:\n                batch_input_shape = K.int_shape(input_tensor)\n            except TypeError:\n                if not input_shape and not batch_input_shape:\n                    raise ValueError('InputLayer was provided '\n                                     'an input_tensor argument, '\n                                     'but its input shape cannot be '\n                                     'automatically inferred. '\n                                     'You should pass an input_shape or '\n                                     'batch_input_shape argument.')\n        if not batch_input_shape:\n            if not input_shape:\n                raise ValueError('An Input layer should be passed either '\n                                 'a `batch_input_shape` or an `input_shape`.')\n            else:\n                batch_input_shape = (batch_size,) + tuple(input_shape)\n        else:\n            batch_input_shape = tuple(batch_input_shape)\n\n        if not dtype:\n            if input_tensor is None:\n                dtype = K.floatx()\n            else:\n                dtype = K.dtype(input_tensor)\n\n        self.batch_input_shape = batch_input_shape\n        self.dtype = dtype\n\n        if input_tensor is None:\n            self.is_placeholder = True\n            input_tensor = K.placeholder(shape=batch_input_shape,\n                                         dtype=dtype,\n                                         sparse=self.sparse,\n                                         name=self.name)\n        else:\n            self.is_placeholder = False\n            input_tensor._keras_shape = batch_input_shape\n        # Create an input node to add to self.outbound_node\n        # and set output_tensors' _keras_history.\n        input_tensor._uses_learning_phase = False\n        input_tensor._keras_history = (self, 0, 0)\n        Node(self,\n             inbound_layers=[],\n             node_indices=[],\n             tensor_indices=[],\n             input_tensors=[input_tensor],\n             output_tensors=[input_tensor],\n             input_masks=[None],\n             output_masks=[None],\n             input_shapes=[batch_input_shape],\n             output_shapes=[batch_input_shape])",
        "begin_line": 34,
        "end_line": 104,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0004233700254022015,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.input_layer.InputLayer.get_config#106",
        "src_path": "keras/engine/input_layer.py",
        "class_name": "keras.engine.input_layer.InputLayer",
        "signature": "keras.engine.input_layer.InputLayer.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'batch_input_shape': self.batch_input_shape,\n                  'dtype': self.dtype,\n                  'sparse': self.sparse,\n                  'name': self.name}\n        return config",
        "begin_line": 106,
        "end_line": 111,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00044863167339614175,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.input_layer.Input#114",
        "src_path": "keras/engine/input_layer.py",
        "class_name": "keras.engine.input_layer",
        "signature": "keras.engine.input_layer.Input(shape=None, batch_shape=None, name=None, dtype=None, sparse=False, tensor=None)",
        "snippet": "def Input(shape=None, batch_shape=None,\n          name=None, dtype=None, sparse=False,\n          tensor=None):\n    \"\"\"`Input()` is used to instantiate a Keras tensor.\n\n    A Keras tensor is a tensor object from the underlying backend\n    (Theano, TensorFlow or CNTK), which we augment with certain\n    attributes that allow us to build a Keras model\n    just by knowing the inputs and outputs of the model.\n\n    For instance, if a, b and c are Keras tensors,\n    it becomes possible to do:\n    `model = Model(input=[a, b], output=c)`\n\n    The added Keras attributes are:\n        `_keras_shape`: Integer shape tuple propagated\n            via Keras-side shape inference.\n        `_keras_history`: Last layer applied to the tensor.\n            the entire layer graph is retrievable from that layer,\n            recursively.\n\n    # Arguments\n        shape: A shape tuple (integer), not including the batch size.\n            For instance, `shape=(32,)` indicates that the expected input\n            will be batches of 32-dimensional vectors.\n        batch_shape: A shape tuple (integer), including the batch size.\n            For instance, `batch_shape=(10, 32)` indicates that\n            the expected input will be batches of 10 32-dimensional vectors.\n            `batch_shape=(None, 32)` indicates batches of an arbitrary number\n            of 32-dimensional vectors.\n        name: An optional name string for the layer.\n            Should be unique in a model (do not reuse the same name twice).\n            It will be autogenerated if it isn't provided.\n        dtype: The data type expected by the input, as a string\n            (`float32`, `float64`, `int32`...)\n        sparse: A boolean specifying whether the placeholder\n            to be created is sparse.\n        tensor: Optional existing tensor to wrap into the `Input` layer.\n            If set, the layer will not create a placeholder tensor.\n\n    # Returns\n        A tensor.\n\n    # Example\n\n    ```python\n    # this is a logistic regression in Keras\n    x = Input(shape=(32,))\n    y = Dense(16, activation='softmax')(x)\n    model = Model(x, y)\n    ```\n    \"\"\"\n    if not batch_shape and tensor is None:\n        assert shape is not None, ('Please provide to Input either a `shape`'\n                                   ' or a `batch_shape` argument. Note that '\n                                   '`shape` does not include the batch '\n                                   'dimension.')\n    if shape is not None and not batch_shape:\n        batch_shape = (None,) + tuple(shape)\n    if not dtype:\n        dtype = K.floatx()\n    input_layer = InputLayer(batch_input_shape=batch_shape,\n                             name=name, dtype=dtype,\n                             sparse=sparse,\n                             input_tensor=tensor)\n    # Return tensor including _keras_shape and _keras_history.\n    # Note that in this case train_output and test_output are the same pointer.\n    outputs = input_layer._inbound_nodes[0].output_tensors\n    return unpack_singleton(outputs)",
        "begin_line": 114,
        "end_line": 182,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00040225261464199515,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.regularizers.serialize#65",
        "src_path": "keras/regularizers.py",
        "class_name": "keras.regularizers",
        "signature": "keras.regularizers.serialize(regularizer)",
        "snippet": "def serialize(regularizer):\n    return serialize_keras_object(regularizer)",
        "begin_line": 65,
        "end_line": 66,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00037778617302606723,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.regularizers.get#76",
        "src_path": "keras/regularizers.py",
        "class_name": "keras.regularizers",
        "signature": "keras.regularizers.get(identifier)",
        "snippet": "def get(identifier):\n    if identifier is None:\n        return None\n    if isinstance(identifier, dict):\n        return deserialize(identifier)\n    elif isinstance(identifier, six.string_types):\n        config = {'class_name': str(identifier), 'config': {}}\n        return deserialize(config)\n    elif callable(identifier):\n        return identifier\n    else:\n        raise ValueError('Could not interpret regularizer identifier: ' +\n                         str(identifier))",
        "begin_line": 76,
        "end_line": 88,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.000281610813855252,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.core.Masking.__init__#58",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Masking",
        "signature": "keras.layers.core.Masking.__init__(self, mask_value=0.0, **kwargs)",
        "snippet": "    def __init__(self, mask_value=0., **kwargs):\n        super(Masking, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.mask_value = mask_value",
        "begin_line": 58,
        "end_line": 61,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.core.Masking.compute_mask#63",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Masking",
        "signature": "keras.layers.core.Masking.compute_mask(self, inputs, mask=None)",
        "snippet": "    def compute_mask(self, inputs, mask=None):\n        output_mask = K.any(K.not_equal(inputs, self.mask_value), axis=-1)\n        return output_mask",
        "begin_line": 63,
        "end_line": 65,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.core.Masking.call#67",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Masking",
        "signature": "keras.layers.core.Masking.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        boolean_mask = K.any(K.not_equal(inputs, self.mask_value),\n                             axis=-1, keepdims=True)\n        return inputs * K.cast(boolean_mask, K.dtype(inputs))",
        "begin_line": 67,
        "end_line": 70,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.core.Masking.compute_output_shape#77",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Masking",
        "signature": "keras.layers.core.Masking.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        return input_shape",
        "begin_line": 77,
        "end_line": 78,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.core.Activation.__init__#294",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Activation",
        "signature": "keras.layers.core.Activation.__init__(self, activation, **kwargs)",
        "snippet": "    def __init__(self, activation, **kwargs):\n        super(Activation, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.activation = activations.get(activation)",
        "begin_line": 294,
        "end_line": 297,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005083884087442806,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.core.Activation.call#299",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Activation",
        "signature": "keras.layers.core.Activation.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        return self.activation(inputs)",
        "begin_line": 299,
        "end_line": 300,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005083884087442806,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.core.Activation.compute_output_shape#307",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Activation",
        "signature": "keras.layers.core.Activation.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        return input_shape",
        "begin_line": 307,
        "end_line": 308,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005083884087442806,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.core.Flatten.__init__#492",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Flatten",
        "signature": "keras.layers.core.Flatten.__init__(self, data_format=None, **kwargs)",
        "snippet": "    def __init__(self, data_format=None, **kwargs):\n        super(Flatten, self).__init__(**kwargs)\n        self.input_spec = InputSpec(min_ndim=3)\n        self.data_format = K.normalize_data_format(data_format)",
        "begin_line": 492,
        "end_line": 495,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.core.Flatten.compute_output_shape#497",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Flatten",
        "signature": "keras.layers.core.Flatten.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if not all(input_shape[1:]):\n            raise ValueError('The shape of the input to \"Flatten\" '\n                             'is not fully defined '\n                             '(got ' + str(input_shape[1:]) + '. '\n                             'Make sure to pass a complete \"input_shape\" '\n                             'or \"batch_input_shape\" argument to the first '\n                             'layer in your model.')\n        return (input_shape[0], np.prod(input_shape[1:]))",
        "begin_line": 497,
        "end_line": 505,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.core.Flatten.call#507",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Flatten",
        "signature": "keras.layers.core.Flatten.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        if self.data_format == 'channels_first':\n            # Ensure works for any dim\n            permutation = [0]\n            permutation.extend([i for i in\n                                range(2, K.ndim(inputs))])\n            permutation.append(1)\n            inputs = K.permute_dimensions(inputs, permutation)\n\n        return K.batch_flatten(inputs)",
        "begin_line": 507,
        "end_line": 516,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.core.RepeatVector.__init__#549",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.RepeatVector",
        "signature": "keras.layers.core.RepeatVector.__init__(self, n, **kwargs)",
        "snippet": "    def __init__(self, n, **kwargs):\n        super(RepeatVector, self).__init__(**kwargs)\n        self.n = n\n        self.input_spec = InputSpec(ndim=2)",
        "begin_line": 549,
        "end_line": 552,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.core.RepeatVector.compute_output_shape#554",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.RepeatVector",
        "signature": "keras.layers.core.RepeatVector.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        return (input_shape[0], self.n, input_shape[1])",
        "begin_line": 554,
        "end_line": 555,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.core.RepeatVector.call#557",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.RepeatVector",
        "signature": "keras.layers.core.RepeatVector.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        return K.repeat(inputs, self.n)",
        "begin_line": 557,
        "end_line": 558,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.core.RepeatVector.get_config#560",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.RepeatVector",
        "signature": "keras.layers.core.RepeatVector.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {'n': self.n}\n        base_config = super(RepeatVector, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 560,
        "end_line": 563,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.core.Lambda.__init__#647",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Lambda",
        "signature": "keras.layers.core.Lambda.__init__(self, function, output_shape=None, mask=None, arguments=None, **kwargs)",
        "snippet": "    def __init__(self, function, output_shape=None,\n                 mask=None, arguments=None, **kwargs):\n        super(Lambda, self).__init__(**kwargs)\n        self.function = function\n        self._input_dtypes = None\n        self.arguments = arguments if arguments else {}\n        if mask is not None:\n            self.supports_masking = True\n        self.mask = mask\n\n        if output_shape is None:\n            self._output_shape = None\n        elif isinstance(output_shape, (tuple, list)):\n            self._output_shape = tuple(output_shape)\n        else:\n            if not callable(output_shape):\n                raise TypeError('In Lambda, `output_shape` '\n                                'must be a list, a tuple, or a function.')\n            self._output_shape = output_shape",
        "begin_line": 647,
        "end_line": 665,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.core.Lambda.compute_output_shape#667",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Lambda",
        "signature": "keras.layers.core.Lambda.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        if self._output_shape is None:\n            # With TensorFlow or CNTK, we can infer the output shape directly:\n            if K.backend() in ('tensorflow', 'cntk'):\n                if isinstance(input_shape, list):\n                    xs = [K.placeholder(shape=shape, dtype=dtype)\n                          for shape, dtype in zip(input_shape, self._input_dtypes)]\n                    x = self.call(xs)\n                else:\n                    x = K.placeholder(shape=input_shape, dtype=self._input_dtypes)\n                    x = self.call(x)\n                if isinstance(x, list):\n                    return [K.int_shape(x_elem) for x_elem in x]\n                else:\n                    return K.int_shape(x)\n            # Otherwise, we default to the input shape.\n            warnings.warn('`output_shape` argument not specified for layer {} '\n                          'and cannot be automatically inferred '\n                          'with the Theano backend. '\n                          'Defaulting to output shape `{}` '\n                          '(same as input shape). '\n                          'If the expected output shape is different, '\n                          'specify it via the `output_shape` argument.'\n                          .format(self.name, input_shape))\n            return input_shape\n        elif isinstance(self._output_shape, (tuple, list)):\n            if isinstance(input_shape, list):\n                num_samples = input_shape[0][0]\n            else:\n                num_samples = input_shape[0] if input_shape else None\n            return (num_samples,) + tuple(self._output_shape)\n        else:\n            shape = self._output_shape(input_shape)\n            if not isinstance(shape, (list, tuple)):\n                raise ValueError('`output_shape` function must return a tuple or '\n                                 'a list of tuples.')\n            if isinstance(shape, list):\n                if isinstance(shape[0], int) or shape[0] is None:\n                    shape = tuple(shape)\n            return shape",
        "begin_line": 667,
        "end_line": 706,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.core.Lambda.call#708",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Lambda",
        "signature": "keras.layers.core.Lambda.call(self, inputs, mask=None)",
        "snippet": "    def call(self, inputs, mask=None):\n        arguments = self.arguments\n        if has_arg(self.function, 'mask'):\n            arguments['mask'] = mask\n        if isinstance(inputs, list):\n            self._input_dtypes = [K.dtype(x) for x in inputs]\n        else:\n            self._input_dtypes = K.dtype(inputs)\n        return self.function(inputs, **arguments)",
        "begin_line": 708,
        "end_line": 716,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.core.Lambda.compute_mask#718",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Lambda",
        "signature": "keras.layers.core.Lambda.compute_mask(self, inputs, mask=None)",
        "snippet": "    def compute_mask(self, inputs, mask=None):\n        if callable(self.mask):\n            return self.mask(inputs, mask)\n        return self.mask",
        "begin_line": 718,
        "end_line": 721,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.core.Lambda.get_config#723",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Lambda",
        "signature": "keras.layers.core.Lambda.get_config(self)",
        "snippet": "    def get_config(self):\n        if isinstance(self.function, python_types.LambdaType):\n            function = func_dump(self.function)\n            function_type = 'lambda'\n        else:\n            function = self.function.__name__\n            function_type = 'function'\n\n        if isinstance(self._output_shape, python_types.LambdaType):\n            output_shape = func_dump(self._output_shape)\n            output_shape_type = 'lambda'\n        elif callable(self._output_shape):\n            output_shape = self._output_shape.__name__\n            output_shape_type = 'function'\n        else:\n            output_shape = self._output_shape\n            output_shape_type = 'raw'\n\n        config = {'function': function,\n                  'function_type': function_type,\n                  'output_shape': output_shape,\n                  'output_shape_type': output_shape_type,\n                  'arguments': self.arguments}\n        base_config = super(Lambda, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 723,
        "end_line": 747,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.core.Lambda.from_config#750",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Lambda",
        "signature": "keras.layers.core.Lambda.from_config(cls, config, custom_objects=None)",
        "snippet": "    def from_config(cls, config, custom_objects=None):\n        config = config.copy()\n        globs = globals()\n        if custom_objects:\n            globs = dict(list(globs.items()) + list(custom_objects.items()))\n        function_type = config.pop('function_type')\n        if function_type == 'function':\n            # Simple lookup in custom objects\n            function = deserialize_keras_object(\n                config['function'],\n                custom_objects=custom_objects,\n                printable_module_name='function in Lambda layer')\n        elif function_type == 'lambda':\n            # Unsafe deserialization from bytecode\n            function = func_load(config['function'], globs=globs)\n        else:\n            raise TypeError('Unknown function type:', function_type)\n\n        output_shape_type = config.pop('output_shape_type')\n        if output_shape_type == 'function':\n            # Simple lookup in custom objects\n            output_shape = deserialize_keras_object(\n                config['output_shape'],\n                custom_objects=custom_objects,\n                printable_module_name='output_shape function in Lambda layer')\n        elif output_shape_type == 'lambda':\n            # Unsafe deserialization from bytecode\n            output_shape = func_load(config['output_shape'], globs=globs)\n        else:\n            output_shape = config['output_shape']\n\n        # If arguments were numpy array, they have been saved as\n        # list. We need to recover the ndarray\n        if 'arguments' in config:\n            for key in config['arguments']:\n                if isinstance(config['arguments'][key], dict):\n                    arg_dict = config['arguments'][key]\n                    if 'type' in arg_dict and arg_dict['type'] == 'ndarray':\n                        # Overwrite the argument with its numpy translation\n                        config['arguments'][key] = np.array(arg_dict['value'])\n\n        config['function'] = function\n        config['output_shape'] = output_shape\n        return cls(**config)",
        "begin_line": 750,
        "end_line": 793,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.core.Dense.__init__#860",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Dense",
        "signature": "keras.layers.core.Dense.__init__(self, units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)",
        "snippet": "    def __init__(self, units,\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n        super(Dense, self).__init__(**kwargs)\n        self.units = units\n        self.activation = activations.get(activation)\n        self.use_bias = use_bias\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n        self.input_spec = InputSpec(min_ndim=2)\n        self.supports_masking = True",
        "begin_line": 860,
        "end_line": 885,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0007698229407236335,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.core.Dense.build#887",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Dense",
        "signature": "keras.layers.core.Dense.build(self, input_shape)",
        "snippet": "    def build(self, input_shape):\n        assert len(input_shape) >= 2\n        input_dim = input_shape[-1]\n\n        self.kernel = self.add_weight(shape=(input_dim, self.units),\n                                      initializer=self.kernel_initializer,\n                                      name='kernel',\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(self.units,),\n                                        initializer=self.bias_initializer,\n                                        name='bias',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        self.input_spec = InputSpec(min_ndim=2, axes={-1: input_dim})\n        self.built = True",
        "begin_line": 887,
        "end_line": 905,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002901073397156948,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.core.Dense.call#907",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Dense",
        "signature": "keras.layers.core.Dense.call(self, inputs)",
        "snippet": "    def call(self, inputs):\n        output = K.dot(inputs, self.kernel)\n        if self.use_bias:\n            output = K.bias_add(output, self.bias, data_format='channels_last')\n        if self.activation is not None:\n            output = self.activation(output)\n        return output",
        "begin_line": 907,
        "end_line": 913,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002901073397156948,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.core.Dense.compute_output_shape#915",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Dense",
        "signature": "keras.layers.core.Dense.compute_output_shape(self, input_shape)",
        "snippet": "    def compute_output_shape(self, input_shape):\n        assert input_shape and len(input_shape) >= 2\n        assert input_shape[-1]\n        output_shape = list(input_shape)\n        output_shape[-1] = self.units\n        return tuple(output_shape)",
        "begin_line": 915,
        "end_line": 920,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0002901073397156948,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.layers.core.Dense.get_config#922",
        "src_path": "keras/layers/core.py",
        "class_name": "keras.layers.core.Dense",
        "signature": "keras.layers.core.Dense.get_config(self)",
        "snippet": "    def get_config(self):\n        config = {\n            'units': self.units,\n            'activation': activations.serialize(self.activation),\n            'use_bias': self.use_bias,\n            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n            'bias_initializer': initializers.serialize(self.bias_initializer),\n            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n            'activity_regularizer':\n                regularizers.serialize(self.activity_regularizer),\n            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n            'bias_constraint': constraints.serialize(self.bias_constraint)\n        }\n        base_config = super(Dense, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
        "begin_line": 922,
        "end_line": 937,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0003869969040247678,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.saving._uniquify#37",
        "src_path": "keras/engine/saving.py",
        "class_name": "keras.engine.saving",
        "signature": "keras.engine.saving._uniquify(names)",
        "snippet": "def _uniquify(names):\n    \"\"\"Uniquify list of strings.\n\n    Custom layers and optimizers written by users\n    for TF 1.x might produce weights with same variable\n    names in TF 2. This method \"uniquifies\" a given list\n    of names.\n\n    e.g: `['a', 'b', 'b', 'c'] -> ['a', 'b', 'b_2', 'c']`\n\n    # Arguments\n        names: List of strings.\n\n    # Returns\n        List of unique strings.\n    \"\"\"\n    counts = {}\n    unique_names = []\n    for name in names:\n        if name in counts:\n            counts[name] += 1\n            name = name + '_' + str(counts[name])\n        else:\n            counts[name] = 1\n        unique_names.append(name)\n    return unique_names",
        "begin_line": 37,
        "end_line": 62,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00037778617302606723,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.saving._serialize_model#65",
        "src_path": "keras/engine/saving.py",
        "class_name": "keras.engine.saving",
        "signature": "keras.engine.saving._serialize_model(model, h5dict, include_optimizer=True)",
        "snippet": "def _serialize_model(model, h5dict, include_optimizer=True):\n    \"\"\"Model serialization logic.\n\n    This method is used for both writing to HDF5 file/group,\n    as well as pickling. This is achieved via a\n    `keras.utils.hdf5_utls.H5Dict` object, which can wrap HDF5\n    files, groups and dicts with a common API.\n\n    # Arguments\n        model: Keras model instance to be serialized.\n        h5dict: keras.utils.io_utils.HD5Dict instance.\n        include_optimizer: If True, serialize optimizer's state together.\n\n    \"\"\"\n    def get_json_type(obj):\n        \"\"\"Serialize any object to a JSON-serializable structure.\n\n        # Arguments\n            obj: the object to serialize\n\n        # Returns\n            JSON-serializable structure representing `obj`.\n\n        # Raises\n            TypeError: if `obj` cannot be serialized.\n        \"\"\"\n        # if obj is a serializable Keras class instance\n        # e.g. optimizer, layer\n        if hasattr(obj, 'get_config'):\n            return {'class_name': obj.__class__.__name__,\n                    'config': obj.get_config()}\n\n        # if obj is any numpy type\n        if type(obj).__module__ == np.__name__:\n            if isinstance(obj, np.ndarray):\n                return obj.tolist()\n            else:\n                return obj.item()\n\n        # misc functions (e.g. loss function)\n        if callable(obj):\n            return obj.__name__\n\n        # if obj is a python 'type'\n        if type(obj).__name__ == type.__name__:\n            return obj.__name__\n\n        raise TypeError('Not JSON Serializable: %s' % (obj,))\n\n    from .. import __version__ as keras_version\n\n    h5dict['keras_version'] = str(keras_version).encode('utf8')\n    h5dict['backend'] = K.backend().encode('utf8')\n\n    model_config = {}\n    model_config['class_name'] = model.__class__.__name__\n    model_config['config'] = model.get_config()\n    model_config = json.dumps(model_config, default=get_json_type)\n    model_config = model_config.encode('utf-8')\n    h5dict['model_config'] = model_config\n\n    model_weights_group = h5dict['model_weights']\n    model_layers = model.layers\n    model_weights_group['layer_names'] = [layer.name.encode('utf8')\n                                          for layer in model_layers]\n    model_weights_group['backend'] = K.backend().encode('utf8')\n    model_weights_group['keras_version'] = str(keras_version).encode('utf8')\n    for layer in model_layers:\n        layer_group = model_weights_group[layer.name]\n        symbolic_weights = layer.weights\n        weight_values = K.batch_get_value(symbolic_weights)\n        weight_names = []\n        for i, (w, val) in enumerate(zip(symbolic_weights, weight_values)):\n            if hasattr(w, 'name') and w.name:\n                name = str(w.name)\n            else:\n                name = 'param_' + str(i)\n            if name in weight_names:\n                idx = 2\n                unique_name = name + '_1'\n                while unique_name in weight_names:\n                    unique_name = name + '_' + str(idx)\n                    idx += 1\n                name = unique_name\n            weight_names.append(name.encode('utf8'))\n        weight_names = _uniquify(weight_names)\n        layer_group['weight_names'] = weight_names\n        for name, val in zip(weight_names, weight_values):\n            layer_group[name] = val\n    if include_optimizer and model.optimizer:\n        if isinstance(model.optimizer, optimizers.TFOptimizer):\n            warnings.warn(\n                'TensorFlow optimizers do not '\n                'make it possible to access '\n                'optimizer attributes or optimizer state '\n                'after instantiation. '\n                'As a result, we cannot save the optimizer '\n                'as part of the model save file.'\n                'You will have to compile your model again '\n                'after loading it. '\n                'Prefer using a Keras optimizer instead '\n                '(see keras.io/optimizers).')\n        else:\n            h5dict['training_config'] = json.dumps({\n                'optimizer_config': {\n                    'class_name': model.optimizer.__class__.__name__,\n                    'config': model.optimizer.get_config()\n                },\n                'loss': model.loss,\n                'metrics': model.metrics,\n                'weighted_metrics': model.weighted_metrics,\n                'sample_weight_mode': model.sample_weight_mode,\n                'loss_weights': model.loss_weights,\n            }, default=get_json_type).encode('utf8')\n            symbolic_weights = getattr(model.optimizer, 'weights')\n            if symbolic_weights:\n                optimizer_weights_group = h5dict['optimizer_weights']\n                weight_values = K.batch_get_value(symbolic_weights)\n                weight_names = []\n                for i, (w, val) in enumerate(zip(symbolic_weights,\n                                                 weight_values)):\n                    # Default values of symbolic_weights is /variable\n                    # for Theano and CNTK\n                    if K.backend() == 'theano' or K.backend() == 'cntk':\n                        if hasattr(w, 'name'):\n                            if w.name.split('/')[-1] == 'variable':\n                                name = str(w.name) + '_' + str(i)\n                            else:\n                                name = str(w.name)\n                        else:\n                            name = 'param_' + str(i)\n                    else:\n                        if hasattr(w, 'name') and w.name:\n                            name = str(w.name)\n                        else:\n                            name = 'param_' + str(i)\n                    if name in weight_names:\n                        idx = 2\n                        unique_name = name + '_1'\n                        while unique_name in weight_names:\n                            unique_name = name + '_' + str(idx)\n                            idx += 1\n                        name = unique_name\n                    weight_names.append(name.encode('utf8'))\n                weight_names = _uniquify(weight_names)\n                optimizer_weights_group['weight_names'] = weight_names\n                for name, val in zip(weight_names, weight_values):\n                    optimizer_weights_group[name] = val",
        "begin_line": 65,
        "end_line": 212,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0004297378599054577,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.saving.get_json_type#79",
        "src_path": "keras/engine/saving.py",
        "class_name": "keras.engine.saving",
        "signature": "keras.engine.saving.get_json_type(obj)",
        "snippet": "    def get_json_type(obj):\n        \"\"\"Serialize any object to a JSON-serializable structure.\n\n        # Arguments\n            obj: the object to serialize\n\n        # Returns\n            JSON-serializable structure representing `obj`.\n\n        # Raises\n            TypeError: if `obj` cannot be serialized.\n        \"\"\"\n        # if obj is a serializable Keras class instance\n        # e.g. optimizer, layer\n        if hasattr(obj, 'get_config'):\n            return {'class_name': obj.__class__.__name__,\n                    'config': obj.get_config()}\n\n        # if obj is any numpy type\n        if type(obj).__module__ == np.__name__:\n            if isinstance(obj, np.ndarray):\n                return obj.tolist()\n            else:\n                return obj.item()\n\n        # misc functions (e.g. loss function)\n        if callable(obj):\n            return obj.__name__\n\n        # if obj is a python 'type'\n        if type(obj).__name__ == type.__name__:\n            return obj.__name__\n\n        raise TypeError('Not JSON Serializable: %s' % (obj,))",
        "begin_line": 79,
        "end_line": 112,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.saving._deserialize_model#215",
        "src_path": "keras/engine/saving.py",
        "class_name": "keras.engine.saving",
        "signature": "keras.engine.saving._deserialize_model(h5dict, custom_objects=None, compile=True)",
        "snippet": "def _deserialize_model(h5dict, custom_objects=None, compile=True):\n    \"\"\"De-serializes a model serialized via _serialize_model\n\n    # Arguments\n        h5dict: `keras.utils.hdf5_utils.HFDict` instance.\n        custom_objects: Optional dictionary mapping names\n            (strings) to custom classes or functions to be\n            considered during deserialization.\n        compile: Boolean, whether to compile the model\n            after loading.\n\n    # Returns\n        A Keras model instance. If an optimizer was found\n        as part of the saved model, the model is already\n        compiled. Otherwise, the model is uncompiled and\n        a warning will be displayed. When `compile` is set\n        to False, the compilation is omitted without any\n        warning.\n    \"\"\"\n    if not custom_objects:\n        custom_objects = {}\n\n    def convert_custom_objects(obj):\n        \"\"\"Handles custom object lookup.\n\n        # Arguments\n            obj: object, dict, or list.\n\n        # Returns\n            The same structure, where occurrences\n                of a custom object name have been replaced\n                with the custom object.\n        \"\"\"\n        if isinstance(obj, list):\n            deserialized = []\n            for value in obj:\n                deserialized.append(convert_custom_objects(value))\n            return deserialized\n        if isinstance(obj, dict):\n            deserialized = {}\n            for key, value in obj.items():\n                deserialized[key] = convert_custom_objects(value)\n            return deserialized\n        if obj in custom_objects:\n            return custom_objects[obj]\n        return obj\n\n    model_config = h5dict['model_config']\n    if model_config is None:\n        raise ValueError('No model found in config.')\n    model_config = json.loads(model_config.decode('utf-8'))\n    model = model_from_config(model_config, custom_objects=custom_objects)\n    model_weights_group = h5dict['model_weights']\n\n    if 'keras_version' in model_weights_group:\n        original_keras_version = model_weights_group['keras_version'].decode('utf8')\n    else:\n        original_keras_version = '1'\n    if 'backend' in model_weights_group:\n        original_backend = model_weights_group['backend'].decode('utf8')\n    else:\n        original_backend = None\n\n    layer_names = model_weights_group['layer_names']\n\n    layers = model.layers\n\n    filtered_layers = []\n    for layer in layers:\n        weights = layer.weights\n        if weights:\n            filtered_layers.append(layer)\n\n    filtered_layer_names = []\n    for name in layer_names:\n        layer_weights = model_weights_group[name]\n        weight_names = layer_weights['weight_names']\n        if len(weight_names) > 0:\n            filtered_layer_names.append(name)\n\n    layer_names = filtered_layer_names\n    if len(layer_names) != len(filtered_layers):\n        raise ValueError('You are trying to load a weight file'\n                         ' containing {} layers into a model with {} layers'\n                         .format(len(layer_names), len(filtered_layers))\n                         )\n\n    # We batch weight value assignments in a single backend call\n    # which provides a speedup in TensorFlow.\n    weight_value_tuples = []\n    for k, name in enumerate(layer_names):\n        layer_weights = model_weights_group[name]\n        weight_names = layer_weights['weight_names']\n        weight_values = [layer_weights[weight_name] for weight_name in weight_names]\n        layer = filtered_layers[k]\n        symbolic_weights = layer.weights\n        weight_values = preprocess_weights_for_loading(layer,\n                                                       weight_values,\n                                                       original_keras_version,\n                                                       original_backend,\n                                                       reshape=False)\n        if len(weight_values) != len(symbolic_weights):\n            raise ValueError('Layer #' + str(k) +\n                             ' (named \"' + layer.name +\n                             '\" in the current model) was found to '\n                             'correspond to layer ' + name +\n                             ' in the save file. '\n                             'However the new layer ' + layer.name +\n                             ' expects ' + str(len(symbolic_weights)) +\n                             ' weights, but the saved weights have ' +\n                             str(len(weight_values)) +\n                             ' elements.')\n        weight_value_tuples += zip(symbolic_weights, weight_values)\n    K.batch_set_value(weight_value_tuples)\n\n    if compile:\n        training_config = h5dict.get('training_config')\n        if training_config is None:\n            warnings.warn('No training configuration found in save file: '\n                          'the model was *not* compiled. '\n                          'Compile it manually.')\n            return model\n        training_config = json.loads(training_config.decode('utf-8'))\n        optimizer_config = training_config['optimizer_config']\n        optimizer = optimizers.deserialize(optimizer_config,\n                                           custom_objects=custom_objects)\n\n        # Recover loss functions and metrics.\n        loss = convert_custom_objects(training_config['loss'])\n        metrics = convert_custom_objects(training_config['metrics'])\n        sample_weight_mode = training_config['sample_weight_mode']\n        loss_weights = training_config['loss_weights']\n\n        # Compile model.\n        model.compile(optimizer=optimizer,\n                      loss=loss,\n                      metrics=metrics,\n                      loss_weights=loss_weights,\n                      sample_weight_mode=sample_weight_mode)\n\n        # Set optimizer weights.\n        if 'optimizer_weights' in h5dict:\n            # Build train function (to get weight updates).\n            model._make_train_function()\n            optimizer_weights_group = h5dict['optimizer_weights']\n            optimizer_weight_names = [\n                n.decode('utf8') for n in\n                optimizer_weights_group['weight_names']]\n            optimizer_weight_values = [optimizer_weights_group[n] for n in\n                                       optimizer_weight_names]\n            try:\n                model.optimizer.set_weights(optimizer_weight_values)\n            except ValueError:\n                warnings.warn('Error in loading the saved optimizer '\n                              'state. As a result, your model is '\n                              'starting with a freshly initialized '\n                              'optimizer.')\n\n    return model",
        "begin_line": 215,
        "end_line": 373,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005083884087442806,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.saving.convert_custom_objects#237",
        "src_path": "keras/engine/saving.py",
        "class_name": "keras.engine.saving",
        "signature": "keras.engine.saving.convert_custom_objects(obj)",
        "snippet": "    def convert_custom_objects(obj):\n        \"\"\"Handles custom object lookup.\n\n        # Arguments\n            obj: object, dict, or list.\n\n        # Returns\n            The same structure, where occurrences\n                of a custom object name have been replaced\n                with the custom object.\n        \"\"\"\n        if isinstance(obj, list):\n            deserialized = []\n            for value in obj:\n                deserialized.append(convert_custom_objects(value))\n            return deserialized\n        if isinstance(obj, dict):\n            deserialized = {}\n            for key, value in obj.items():\n                deserialized[key] = convert_custom_objects(value)\n            return deserialized\n        if obj in custom_objects:\n            return custom_objects[obj]\n        return obj",
        "begin_line": 237,
        "end_line": 260,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.saving._gcs_copy#376",
        "src_path": "keras/engine/saving.py",
        "class_name": "keras.engine.saving",
        "signature": "keras.engine.saving._gcs_copy(source_filepath, target_filepath, overwrite=True)",
        "snippet": "def _gcs_copy(source_filepath, target_filepath, overwrite=True):\n    \"\"\"Copies a file to/from/within Google Cloud Storage (GCS).\n\n    # Arguments\n        source_filepath: String, path to the file on filesystem or object on GCS to\n            copy from.\n        target_filepath: String, path to the file on filesystem or object on GCS to\n            copy to.\n        overwrite: Whether we should overwrite an existing file/object at the target\n            location, or instead ask the user with a manual prompt.\n    \"\"\"\n    if tf_file_io is None:\n        raise ImportError('Google Cloud Storage file transfer requires TensorFlow.')\n    if not overwrite and tf_file_io.file_exists(target_filepath):\n        proceed = ask_to_proceed_with_overwrite(target_filepath)\n        if not proceed:\n            return\n    with tf_file_io.FileIO(source_filepath, mode='rb') as source_f:\n        with tf_file_io.FileIO(target_filepath, mode='wb') as target_f:\n            target_f.write(source_f.read())",
        "begin_line": 376,
        "end_line": 395,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.saving._is_gcs_location#398",
        "src_path": "keras/engine/saving.py",
        "class_name": "keras.engine.saving",
        "signature": "keras.engine.saving._is_gcs_location(filepath)",
        "snippet": "def _is_gcs_location(filepath):\n    \"\"\"Checks if `filepath` is referencing a google storage bucket.\n\n    # Arguments\n        filepath: The location to check.\n    \"\"\"\n    return isinstance(filepath, string_types) and filepath.startswith('gs://')",
        "begin_line": 398,
        "end_line": 404,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00037778617302606723,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.saving.allow_write_to_gcs#407",
        "src_path": "keras/engine/saving.py",
        "class_name": "keras.engine.saving",
        "signature": "keras.engine.saving.allow_write_to_gcs(save_function)",
        "snippet": "def allow_write_to_gcs(save_function):\n    \"\"\"Function decorator to support saving to Google Cloud Storage (GCS).\n\n    This decorator parses the `filepath` argument of the `save_function` and\n    transfers the file to GCS if `filepath` starts with \"gs://\".\n\n    Note: the file is temporarily writen to local filesystem before copied to GSC.\n\n    # Arguments\n        save_function: The function to wrap, with requirements:\n            - second positional argument should indicate the location to save to.\n            - third positional argument should be the `overwrite` option indicating\n            whether we should overwrite an existing file/object at the target\n            location, or instead ask the user with a manual prompt.\n    \"\"\"\n    @wraps(save_function)\n    def save_wrapper(obj, filepath, overwrite=True, *args, **kwargs):\n        if _is_gcs_location(filepath):\n            tmp_filepath = os.path.join(tempfile.gettempdir(),\n                                        os.path.basename(filepath))\n            save_function(obj, tmp_filepath, True, *args, **kwargs)\n            try:\n                _gcs_copy(tmp_filepath, filepath, overwrite)\n            finally:\n                os.remove(tmp_filepath)\n        else:\n            save_function(obj, filepath, overwrite, *args, **kwargs)\n\n    return save_wrapper",
        "begin_line": 407,
        "end_line": 435,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00037778617302606723,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.saving.save_wrapper#423",
        "src_path": "keras/engine/saving.py",
        "class_name": "keras.engine.saving",
        "signature": "keras.engine.saving.save_wrapper(obj, filepath, overwrite=True, *args, **kwargs)",
        "snippet": "    def save_wrapper(obj, filepath, overwrite=True, *args, **kwargs):\n        if _is_gcs_location(filepath):\n            tmp_filepath = os.path.join(tempfile.gettempdir(),\n                                        os.path.basename(filepath))\n            save_function(obj, tmp_filepath, True, *args, **kwargs)\n            try:\n                _gcs_copy(tmp_filepath, filepath, overwrite)\n            finally:\n                os.remove(tmp_filepath)\n        else:\n            save_function(obj, filepath, overwrite, *args, **kwargs)",
        "begin_line": 423,
        "end_line": 433,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.saving.extract_named_arg#451",
        "src_path": "keras/engine/saving.py",
        "class_name": "keras.engine.saving",
        "signature": "keras.engine.saving.extract_named_arg(f, name, args, kwargs)",
        "snippet": "    def extract_named_arg(f, name, args, kwargs):\n        if name in kwargs:\n            arg = kwargs.pop(name)\n            return arg, args, kwargs\n        argnames = inspect.getargspec(f)[0]\n        for i, (argname, arg) in enumerate(zip(argnames, args)):\n            if argname == name:\n                return arg, args[:i] + args[i + 1:], kwargs\n        else:\n            raise ValueError('function {} has no argument {}'.format(f, name))",
        "begin_line": 451,
        "end_line": 460,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00037778617302606723,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.saving.allow_read_from_gcs#438",
        "src_path": "keras/engine/saving.py",
        "class_name": "keras.engine.saving",
        "signature": "keras.engine.saving.allow_read_from_gcs(load_function)",
        "snippet": "def allow_read_from_gcs(load_function):\n    \"\"\"Function decorator to support loading from Google Cloud Storage (GCS).\n\n    This decorator parses the `filepath` argument of the `load_function` and\n    fetches the required object from GCS if `filepath` starts with \"gs://\".\n\n    Note: the file is temporarily copied to local filesystem from GCS before loaded.\n\n    # Arguments\n        load_function: The function to wrap, with requirements:\n            - should have one _named_ argument `filepath` indicating the location to\n            load from.\n    \"\"\"\n    def extract_named_arg(f, name, args, kwargs):\n        if name in kwargs:\n            arg = kwargs.pop(name)\n            return arg, args, kwargs\n        argnames = inspect.getargspec(f)[0]\n        for i, (argname, arg) in enumerate(zip(argnames, args)):\n            if argname == name:\n                return arg, args[:i] + args[i + 1:], kwargs\n        else:\n            raise ValueError('function {} has no argument {}'.format(f, name))\n\n    @wraps(load_function)\n    def load_wrapper(*args, **kwargs):\n        filepath, _args, _kwargs = extract_named_arg(\n            load_function, 'filepath', args, kwargs)\n        if _is_gcs_location(filepath):\n            tmp_filepath = os.path.join(tempfile.gettempdir(),\n                                        os.path.basename(filepath))\n            _gcs_copy(filepath, tmp_filepath)\n            _kwargs['filepath'] = tmp_filepath\n            try:\n                res = load_function(*_args, **_kwargs)\n            finally:\n                os.remove(tmp_filepath)\n            return res\n        return load_function(*args, **kwargs)\n\n    return load_wrapper",
        "begin_line": 438,
        "end_line": 478,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00037778617302606723,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.saving.load_wrapper#463",
        "src_path": "keras/engine/saving.py",
        "class_name": "keras.engine.saving",
        "signature": "keras.engine.saving.load_wrapper(*args, **kwargs)",
        "snippet": "    def load_wrapper(*args, **kwargs):\n        filepath, _args, _kwargs = extract_named_arg(\n            load_function, 'filepath', args, kwargs)\n        if _is_gcs_location(filepath):\n            tmp_filepath = os.path.join(tempfile.gettempdir(),\n                                        os.path.basename(filepath))\n            _gcs_copy(filepath, tmp_filepath)\n            _kwargs['filepath'] = tmp_filepath\n            try:\n                res = load_function(*_args, **_kwargs)\n            finally:\n                os.remove(tmp_filepath)\n            return res\n        return load_function(*args, **kwargs)",
        "begin_line": 463,
        "end_line": 476,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.saving.save_model#482",
        "src_path": "keras/engine/saving.py",
        "class_name": "keras.engine.saving",
        "signature": "keras.engine.saving.save_model(model, filepath, overwrite=True, include_optimizer=True)",
        "snippet": "def save_model(model, filepath, overwrite=True, include_optimizer=True):\n    \"\"\"Save a model to a HDF5 file.\n\n    Note: Please also see\n    [How can I install HDF5 or h5py to save my models in Keras?](\n        /getting-started/faq/\n        #how-can-i-install-HDF5-or-h5py-to-save-my-models-in-Keras)\n    in the FAQ for instructions on how to install `h5py`.\n\n    The saved model contains:\n        - the model's configuration (topology)\n        - the model's weights\n        - the model's optimizer's state (if any)\n\n    Thus the saved model can be reinstantiated in\n    the exact same state, without any of the code\n    used for model definition or training.\n\n    # Arguments\n        model: Keras model instance to be saved.\n        filepath: one of the following:\n            - string, path where to save the model, or\n            - h5py.File or h5py.Group object where to save the model\n        overwrite: Whether we should overwrite any existing\n            model at the target location, or instead\n            ask the user with a manual prompt.\n        include_optimizer: If True, save optimizer's state together.\n\n    # Raises\n        ImportError: if h5py is not available.\n    \"\"\"\n    if h5py is None:\n        raise ImportError('`save_model` requires h5py.')\n\n    if not isinstance(filepath, h5py.Group):\n        # If file exists and should not be overwritten.\n        if not overwrite and os.path.isfile(filepath):\n            proceed = ask_to_proceed_with_overwrite(filepath)\n            if not proceed:\n                return\n        opened_new_file = True\n    else:\n        opened_new_file = False\n\n    h5dict = H5Dict(filepath, mode='w')\n    try:\n        _serialize_model(model, h5dict, include_optimizer)\n    finally:\n        if opened_new_file:\n            h5dict.close()",
        "begin_line": 482,
        "end_line": 531,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.saving.load_model#535",
        "src_path": "keras/engine/saving.py",
        "class_name": "keras.engine.saving",
        "signature": "keras.engine.saving.load_model(filepath, custom_objects=None, compile=True)",
        "snippet": "def load_model(filepath, custom_objects=None, compile=True):\n    \"\"\"Loads a model saved via `save_model`.\n\n    # Arguments\n        filepath: one of the following:\n            - string, path to the saved model, or\n            - h5py.File or h5py.Group object from which to load the model\n        custom_objects: Optional dictionary mapping names\n            (strings) to custom classes or functions to be\n            considered during deserialization.\n        compile: Boolean, whether to compile the model\n            after loading.\n\n    # Returns\n        A Keras model instance. If an optimizer was found\n        as part of the saved model, the model is already\n        compiled. Otherwise, the model is uncompiled and\n        a warning will be displayed. When `compile` is set\n        to False, the compilation is omitted without any\n        warning.\n\n    # Raises\n        ImportError: if h5py is not available.\n        ValueError: In case of an invalid savefile.\n    \"\"\"\n    if h5py is None:\n        raise ImportError('`load_model` requires h5py.')\n    model = None\n    opened_new_file = not isinstance(filepath, h5py.Group)\n    h5dict = H5Dict(filepath, 'r')\n    try:\n        model = _deserialize_model(h5dict, custom_objects, compile)\n    finally:\n        if opened_new_file:\n            h5dict.close()\n    return model",
        "begin_line": 535,
        "end_line": 570,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0004144218814753419,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.saving.pickle_model#573",
        "src_path": "keras/engine/saving.py",
        "class_name": "keras.engine.saving",
        "signature": "keras.engine.saving.pickle_model(model)",
        "snippet": "def pickle_model(model):\n    d = {}\n    h5dict = H5Dict(d)\n    _serialize_model(model, h5dict)\n    return d",
        "begin_line": 573,
        "end_line": 577,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005574136008918618,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.saving.unpickle_model#580",
        "src_path": "keras/engine/saving.py",
        "class_name": "keras.engine.saving",
        "signature": "keras.engine.saving.unpickle_model(state)",
        "snippet": "def unpickle_model(state):\n    h5dict = H5Dict(state, mode='r')\n    return _deserialize_model(h5dict)",
        "begin_line": 580,
        "end_line": 582,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0005574136008918618,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.saving.model_from_config#585",
        "src_path": "keras/engine/saving.py",
        "class_name": "keras.engine.saving",
        "signature": "keras.engine.saving.model_from_config(config, custom_objects=None)",
        "snippet": "def model_from_config(config, custom_objects=None):\n    \"\"\"Instantiates a Keras model from its config.\n\n    # Arguments\n        config: Configuration dictionary.\n        custom_objects: Optional dictionary mapping names\n            (strings) to custom classes or functions to be\n            considered during deserialization.\n\n    # Returns\n        A Keras model instance (uncompiled).\n\n    # Raises\n        TypeError: if `config` is not a dictionary.\n    \"\"\"\n    if isinstance(config, list):\n        raise TypeError('`model_from_config` expects a dictionary, '\n                        'not a list. Maybe you meant to use '\n                        '`Sequential.from_config(config)`?')\n    from ..layers import deserialize\n    return deserialize(config, custom_objects=custom_objects)",
        "begin_line": 585,
        "end_line": 605,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0003551136363636364,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.saving.save_attributes_to_hdf5_group#642",
        "src_path": "keras/engine/saving.py",
        "class_name": "keras.engine.saving",
        "signature": "keras.engine.saving.save_attributes_to_hdf5_group(group, name, data)",
        "snippet": "def save_attributes_to_hdf5_group(group, name, data):\n    \"\"\"Saves attributes (data) of the specified name into the HDF5 group.\n\n    This method deals with an inherent problem of HDF5 file which is not\n    able to store data larger than HDF5_OBJECT_HEADER_LIMIT bytes.\n\n    # Arguments\n        group: A pointer to a HDF5 group.\n        name: A name of the attributes to save.\n        data: Attributes data to store.\n    \"\"\"\n    # Check that no item in `data` is larger than `HDF5_OBJECT_HEADER_LIMIT`\n    # because in that case even chunking the array would not make the saving\n    # possible.\n    bad_attributes = [x for x in data if len(x) > HDF5_OBJECT_HEADER_LIMIT]\n\n    # Expecting this to never be true.\n    if len(bad_attributes) > 0:\n        raise RuntimeError('The following attributes cannot be saved to HDF5 '\n                           'file because they are larger than %d bytes: %s'\n                           % (HDF5_OBJECT_HEADER_LIMIT,\n                              ', '.join([x for x in bad_attributes])))\n\n    data_npy = np.asarray(data)\n\n    num_chunks = 1\n    chunked_data = np.array_split(data_npy, num_chunks)\n\n    # This will never loop forever thanks to the test above.\n    while any(map(lambda x: x.nbytes > HDF5_OBJECT_HEADER_LIMIT, chunked_data)):\n        num_chunks += 1\n        chunked_data = np.array_split(data_npy, num_chunks)\n\n    if num_chunks > 1:\n        for chunk_id, chunk_data in enumerate(chunked_data):\n            group.attrs['%s%d' % (name, chunk_id)] = chunk_data\n    else:\n        group.attrs[name] = data",
        "begin_line": 642,
        "end_line": 679,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0006756756756756757,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.saving.load_attributes_from_hdf5_group#682",
        "src_path": "keras/engine/saving.py",
        "class_name": "keras.engine.saving",
        "signature": "keras.engine.saving.load_attributes_from_hdf5_group(group, name)",
        "snippet": "def load_attributes_from_hdf5_group(group, name):\n    \"\"\"Loads attributes of the specified name from the HDF5 group.\n\n    This method deals with an inherent problem\n    of HDF5 file which is not able to store\n    data larger than HDF5_OBJECT_HEADER_LIMIT bytes.\n\n    # Arguments\n        group: A pointer to a HDF5 group.\n        name: A name of the attributes to load.\n\n    # Returns\n        data: Attributes data.\n    \"\"\"\n    if name in group.attrs:\n        data = [n.decode('utf8') for n in group.attrs[name]]\n    else:\n        data = []\n        chunk_id = 0\n        while ('%s%d' % (name, chunk_id)) in group.attrs:\n            data.extend([n.decode('utf8')\n                         for n in group.attrs['%s%d' % (name, chunk_id)]])\n            chunk_id += 1\n    return data",
        "begin_line": 682,
        "end_line": 705,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0006756756756756757,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.saving.save_weights_to_hdf5_group#708",
        "src_path": "keras/engine/saving.py",
        "class_name": "keras.engine.saving",
        "signature": "keras.engine.saving.save_weights_to_hdf5_group(group, layers)",
        "snippet": "def save_weights_to_hdf5_group(group, layers):\n    \"\"\"Saves weights into the HDF5 group.\n\n    # Arguments\n        group: A pointer to a HDF5 group.\n        layers: Layers to load.\n    \"\"\"\n    from .. import __version__ as keras_version\n\n    save_attributes_to_hdf5_group(\n        group, 'layer_names', [layer.name.encode('utf8') for layer in layers])\n    group.attrs['backend'] = K.backend().encode('utf8')\n    group.attrs['keras_version'] = str(keras_version).encode('utf8')\n\n    for layer in layers:\n        g = group.create_group(layer.name)\n        symbolic_weights = layer.weights\n        weight_values = K.batch_get_value(symbolic_weights)\n        weight_names = []\n        for i, (w, val) in enumerate(zip(symbolic_weights, weight_values)):\n            if hasattr(w, 'name') and w.name:\n                name = str(w.name)\n            else:\n                name = 'param_' + str(i)\n            weight_names.append(name.encode('utf8'))\n        save_attributes_to_hdf5_group(g, 'weight_names', weight_names)\n        for name, val in zip(weight_names, weight_values):\n            param_dset = g.create_dataset(name, val.shape,\n                                          dtype=val.dtype)\n            if not val.shape:\n                # scalar\n                param_dset[()] = val\n            else:\n                param_dset[:] = val",
        "begin_line": 708,
        "end_line": 741,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0006756756756756757,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.saving.preprocess_weights_for_loading#744",
        "src_path": "keras/engine/saving.py",
        "class_name": "keras.engine.saving",
        "signature": "keras.engine.saving.preprocess_weights_for_loading(layer, weights, original_keras_version=None, original_backend=None, reshape=False)",
        "snippet": "def preprocess_weights_for_loading(layer, weights,\n                                   original_keras_version=None,\n                                   original_backend=None,\n                                   reshape=False):\n    \"\"\"Converts layers weights from Keras 1 format to Keras 2.\n\n    # Arguments\n        layer: Layer instance.\n        weights: List of weights values (Numpy arrays).\n        original_keras_version: Keras version for the weights, as a string.\n        original_backend: Keras backend the weights were trained with,\n            as a string.\n        reshape: Reshape weights to fit the layer when the correct number\n            of values are present but the shape does not match.\n\n    # Returns\n        A list of weights values (Numpy arrays).\n    \"\"\"\n    def convert_nested_bidirectional(weights):\n        \"\"\"Converts layers nested in `Bidirectional` wrapper.\n\n        # Arguments\n            weights: List of weights values (Numpy arrays).\n        # Returns\n            A list of weights values (Numpy arrays).\n        \"\"\"\n        num_weights_per_layer = len(weights) // 2\n        forward_weights = preprocess_weights_for_loading(\n            layer.forward_layer,\n            weights[:num_weights_per_layer],\n            original_keras_version,\n            original_backend)\n        backward_weights = preprocess_weights_for_loading(\n            layer.backward_layer,\n            weights[num_weights_per_layer:],\n            original_keras_version,\n            original_backend)\n        return forward_weights + backward_weights\n\n    def convert_nested_time_distributed(weights):\n        \"\"\"Converts layers nested in `TimeDistributed` wrapper.\n\n        # Arguments\n            weights: List of weights values (Numpy arrays).\n        # Returns\n            A list of weights values (Numpy arrays).\n        \"\"\"\n        return preprocess_weights_for_loading(\n            layer.layer, weights, original_keras_version, original_backend)\n\n    def convert_nested_model(weights):\n        \"\"\"Converts layers nested in `Model` or `Sequential`.\n\n        # Arguments\n            weights: List of weights values (Numpy arrays).\n        # Returns\n            A list of weights values (Numpy arrays).\n        \"\"\"\n        new_weights = []\n        # trainable weights\n        for sublayer in layer.layers:\n            num_weights = len(sublayer.trainable_weights)\n            if num_weights > 0:\n                new_weights.extend(preprocess_weights_for_loading(\n                    layer=sublayer,\n                    weights=weights[:num_weights],\n                    original_keras_version=original_keras_version,\n                    original_backend=original_backend))\n                weights = weights[num_weights:]\n\n        # non-trainable weights\n        for sublayer in layer.layers:\n            num_weights = len([l for l in sublayer.weights\n                               if l not in sublayer.trainable_weights])\n            if num_weights > 0:\n                new_weights.extend(preprocess_weights_for_loading(\n                    layer=sublayer,\n                    weights=weights[:num_weights],\n                    original_keras_version=original_keras_version,\n                    original_backend=original_backend))\n                weights = weights[num_weights:]\n        return new_weights\n\n    # Convert layers nested in Bidirectional/TimeDistributed/Model/Sequential.\n    # Both transformation should be ran for both Keras 1->2 conversion\n    # and for conversion of CuDNN layers.\n    if layer.__class__.__name__ == 'Bidirectional':\n        weights = convert_nested_bidirectional(weights)\n    if layer.__class__.__name__ == 'TimeDistributed':\n        weights = convert_nested_time_distributed(weights)\n    elif layer.__class__.__name__ in ['Model', 'Sequential']:\n        weights = convert_nested_model(weights)\n\n    if original_keras_version == '1':\n        if layer.__class__.__name__ == 'TimeDistributed':\n            weights = preprocess_weights_for_loading(layer.layer,\n                                                     weights,\n                                                     original_keras_version,\n                                                     original_backend)\n\n        if layer.__class__.__name__ == 'Conv1D':\n            shape = weights[0].shape\n            # Handle Keras 1.1 format\n            if shape[:2] != (layer.kernel_size[0], 1) or shape[3] != layer.filters:\n                # Legacy shape:\n                # (filters, input_dim, filter_length, 1)\n                assert (shape[0] == layer.filters and\n                        shape[2:] == (layer.kernel_size[0], 1))\n                weights[0] = np.transpose(weights[0], (2, 3, 1, 0))\n            weights[0] = weights[0][:, 0, :, :]\n\n        if layer.__class__.__name__ == 'Conv2D':\n            if layer.data_format == 'channels_first':\n                # old: (filters, stack_size, kernel_rows, kernel_cols)\n                # new: (kernel_rows, kernel_cols, stack_size, filters)\n                weights[0] = np.transpose(weights[0], (2, 3, 1, 0))\n\n        if layer.__class__.__name__ == 'Conv2DTranspose':\n            if layer.data_format == 'channels_last':\n                # old: (kernel_rows, kernel_cols, stack_size, filters)\n                # new: (kernel_rows, kernel_cols, filters, stack_size)\n                weights[0] = np.transpose(weights[0], (0, 1, 3, 2))\n            if layer.data_format == 'channels_first':\n                # old: (filters, stack_size, kernel_rows, kernel_cols)\n                # new: (kernel_rows, kernel_cols, filters, stack_size)\n                weights[0] = np.transpose(weights[0], (2, 3, 0, 1))\n\n        if layer.__class__.__name__ == 'Conv3D':\n            if layer.data_format == 'channels_first':\n                # old: (filters, stack_size, ...)\n                # new: (..., stack_size, filters)\n                weights[0] = np.transpose(weights[0], (2, 3, 4, 1, 0))\n\n        if layer.__class__.__name__ == 'GRU':\n            if len(weights) == 9:\n                kernel = np.concatenate([weights[0],\n                                         weights[3],\n                                         weights[6]], axis=-1)\n                recurrent_kernel = np.concatenate([weights[1],\n                                                   weights[4],\n                                                   weights[7]], axis=-1)\n                bias = np.concatenate([weights[2],\n                                       weights[5],\n                                       weights[8]], axis=-1)\n                weights = [kernel, recurrent_kernel, bias]\n\n        if layer.__class__.__name__ == 'LSTM':\n            if len(weights) == 12:\n                # old: i, c, f, o\n                # new: i, f, c, o\n                kernel = np.concatenate([weights[0],\n                                         weights[6],\n                                         weights[3],\n                                         weights[9]], axis=-1)\n                recurrent_kernel = np.concatenate([weights[1],\n                                                   weights[7],\n                                                   weights[4],\n                                                   weights[10]], axis=-1)\n                bias = np.concatenate([weights[2],\n                                       weights[8],\n                                       weights[5],\n                                       weights[11]], axis=-1)\n                weights = [kernel, recurrent_kernel, bias]\n\n        if layer.__class__.__name__ == 'ConvLSTM2D':\n            if len(weights) == 12:\n                kernel = np.concatenate([weights[0],\n                                         weights[6],\n                                         weights[3],\n                                         weights[9]], axis=-1)\n                recurrent_kernel = np.concatenate([weights[1],\n                                                   weights[7],\n                                                   weights[4],\n                                                   weights[10]], axis=-1)\n                bias = np.concatenate([weights[2],\n                                       weights[8],\n                                       weights[5],\n                                       weights[11]], axis=-1)\n                if layer.data_format == 'channels_first':\n                    # old: (filters, stack_size, kernel_rows, kernel_cols)\n                    # new: (kernel_rows, kernel_cols, stack_size, filters)\n                    kernel = np.transpose(kernel, (2, 3, 1, 0))\n                    recurrent_kernel = np.transpose(recurrent_kernel,\n                                                    (2, 3, 1, 0))\n                weights = [kernel, recurrent_kernel, bias]\n\n    conv_layers = ['Conv1D',\n                   'Conv2D',\n                   'Conv3D',\n                   'Conv2DTranspose',\n                   'ConvLSTM2D']\n    if layer.__class__.__name__ in conv_layers:\n        layer_weights_shape = K.int_shape(layer.weights[0])\n        if _need_convert_kernel(original_backend):\n            weights[0] = conv_utils.convert_kernel(weights[0])\n            if layer.__class__.__name__ == 'ConvLSTM2D':\n                weights[1] = conv_utils.convert_kernel(weights[1])\n        if reshape and layer_weights_shape != weights[0].shape:\n            if weights[0].size != np.prod(layer_weights_shape):\n                raise ValueError('Weights must be of equal size to ' +\n                                 'apply a reshape operation. ' +\n                                 'Layer ' + layer.name +\n                                 '\\'s weights have shape ' +\n                                 str(layer_weights_shape) + ' and size ' +\n                                 str(np.prod(layer_weights_shape)) + '. ' +\n                                 'The weights for loading have shape ' +\n                                 str(weights[0].shape) + ' and size ' +\n                                 str(weights[0].size) + '. ')\n            weights[0] = np.reshape(weights[0], layer_weights_shape)\n        elif layer_weights_shape != weights[0].shape:\n            weights[0] = np.transpose(weights[0], (3, 2, 0, 1))\n            if layer.__class__.__name__ == 'ConvLSTM2D':\n                weights[1] = np.transpose(weights[1], (3, 2, 0, 1))\n\n    # convert CuDNN layers\n    weights = _convert_rnn_weights(layer, weights)\n\n    return weights",
        "begin_line": 744,
        "end_line": 961,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.saving.convert_nested_bidirectional#762",
        "src_path": "keras/engine/saving.py",
        "class_name": "keras.engine.saving",
        "signature": "keras.engine.saving.convert_nested_bidirectional(weights)",
        "snippet": "    def convert_nested_bidirectional(weights):\n        \"\"\"Converts layers nested in `Bidirectional` wrapper.\n\n        # Arguments\n            weights: List of weights values (Numpy arrays).\n        # Returns\n            A list of weights values (Numpy arrays).\n        \"\"\"\n        num_weights_per_layer = len(weights) // 2\n        forward_weights = preprocess_weights_for_loading(\n            layer.forward_layer,\n            weights[:num_weights_per_layer],\n            original_keras_version,\n            original_backend)\n        backward_weights = preprocess_weights_for_loading(\n            layer.backward_layer,\n            weights[num_weights_per_layer:],\n            original_keras_version,\n            original_backend)\n        return forward_weights + backward_weights",
        "begin_line": 762,
        "end_line": 781,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00032948929159802305,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.saving.convert_nested_time_distributed#783",
        "src_path": "keras/engine/saving.py",
        "class_name": "keras.engine.saving",
        "signature": "keras.engine.saving.convert_nested_time_distributed(weights)",
        "snippet": "    def convert_nested_time_distributed(weights):\n        \"\"\"Converts layers nested in `TimeDistributed` wrapper.\n\n        # Arguments\n            weights: List of weights values (Numpy arrays).\n        # Returns\n            A list of weights values (Numpy arrays).\n        \"\"\"\n        return preprocess_weights_for_loading(\n            layer.layer, weights, original_keras_version, original_backend)",
        "begin_line": 783,
        "end_line": 792,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0011198208286674132,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.saving.convert_nested_model#794",
        "src_path": "keras/engine/saving.py",
        "class_name": "keras.engine.saving",
        "signature": "keras.engine.saving.convert_nested_model(weights)",
        "snippet": "    def convert_nested_model(weights):\n        \"\"\"Converts layers nested in `Model` or `Sequential`.\n\n        # Arguments\n            weights: List of weights values (Numpy arrays).\n        # Returns\n            A list of weights values (Numpy arrays).\n        \"\"\"\n        new_weights = []\n        # trainable weights\n        for sublayer in layer.layers:\n            num_weights = len(sublayer.trainable_weights)\n            if num_weights > 0:\n                new_weights.extend(preprocess_weights_for_loading(\n                    layer=sublayer,\n                    weights=weights[:num_weights],\n                    original_keras_version=original_keras_version,\n                    original_backend=original_backend))\n                weights = weights[num_weights:]\n\n        # non-trainable weights\n        for sublayer in layer.layers:\n            num_weights = len([l for l in sublayer.weights\n                               if l not in sublayer.trainable_weights])\n            if num_weights > 0:\n                new_weights.extend(preprocess_weights_for_loading(\n                    layer=sublayer,\n                    weights=weights[:num_weights],\n                    original_keras_version=original_keras_version,\n                    original_backend=original_backend))\n                weights = weights[num_weights:]\n        return new_weights",
        "begin_line": 794,
        "end_line": 825,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.saving._convert_rnn_weights#964",
        "src_path": "keras/engine/saving.py",
        "class_name": "keras.engine.saving",
        "signature": "keras.engine.saving._convert_rnn_weights(layer, weights)",
        "snippet": "def _convert_rnn_weights(layer, weights):\n    \"\"\"Converts weights for RNN layers between native and CuDNN format.\n\n    Input kernels for each gate are transposed and converted between Fortran\n    and C layout, recurrent kernels are transposed. For LSTM biases are summed/\n    split in half, for GRU biases are reshaped.\n\n    Weights can be converted in both directions between `LSTM` and`CuDNNSLTM`\n    and between `CuDNNGRU` and `GRU(reset_after=True)`. Default `GRU` is not\n    compatible with `CuDNNGRU`.\n\n    For missing biases in `LSTM`/`GRU` (`use_bias=False`),\n    no conversion is made.\n\n    # Arguments\n        layer: Target layer instance.\n        weights: List of source weights values (input kernels, recurrent\n            kernels, [biases]) (Numpy arrays).\n\n    # Returns\n        A list of converted weights values (Numpy arrays).\n\n    # Raises\n        ValueError: for incompatible GRU layer/weights or incompatible biases\n    \"\"\"\n\n    def transform_kernels(kernels, func, n_gates):\n        \"\"\"Transforms kernel for each gate separately using given function.\n\n        # Arguments\n            kernels: Stacked array of kernels for individual gates.\n            func: Function applied to kernel of each gate.\n            n_gates: Number of gates (4 for LSTM, 3 for GRU).\n        # Returns\n            Stacked array of transformed kernels.\n        \"\"\"\n        return np.hstack([func(k) for k in np.hsplit(kernels, n_gates)])\n\n    def transpose_input(from_cudnn):\n        \"\"\"Makes a function that transforms input kernels from/to CuDNN format.\n\n        It keeps the shape, but changes between the layout (Fortran/C). Eg.:\n\n        ```\n        Keras                 CuDNN\n        [[0, 1, 2],  <--->  [[0, 2, 4],\n         [3, 4, 5]]          [1, 3, 5]]\n        ```\n\n        It can be passed to `transform_kernels()`.\n\n        # Arguments\n            from_cudnn: `True` if source weights are in CuDNN format, `False`\n                if they're in plain Keras format.\n        # Returns\n            Function that converts input kernel to the other format.\n        \"\"\"\n        order = 'F' if from_cudnn else 'C'\n\n        def transform(kernel):\n            return kernel.T.reshape(kernel.shape, order=order)\n\n        return transform\n\n    target_class = layer.__class__.__name__\n\n    # convert the weights between CuDNNLSTM and LSTM\n    if target_class in ['LSTM', 'CuDNNLSTM'] and len(weights) == 3:\n        # determine if we're loading a CuDNNLSTM layer\n        # from the number of bias weights:\n        # CuDNNLSTM has (units * 8) weights; while LSTM has (units * 4)\n        # if there's no bias weight in the file, skip this conversion\n        units = weights[1].shape[0]\n        bias_shape = weights[2].shape\n        n_gates = 4\n\n        if bias_shape == (2 * units * n_gates,):\n            source = 'CuDNNLSTM'\n        elif bias_shape == (units * n_gates,):\n            source = 'LSTM'\n        else:\n            raise ValueError('Invalid bias shape: ' + str(bias_shape))\n\n        def convert_weights(weights, from_cudnn=True):\n            # transpose (and reshape) input and recurrent kernels\n            kernels = transform_kernels(weights[0],\n                                        transpose_input(from_cudnn),\n                                        n_gates)\n            recurrent_kernels = transform_kernels(weights[1], lambda k: k.T, n_gates)\n            if from_cudnn:\n                # merge input and recurrent biases into a single set\n                biases = np.sum(np.split(weights[2], 2, axis=0), axis=0)\n            else:\n                # Split single set of biases evenly to two sets. The way of\n                # splitting doesn't matter as long as the two sets sum is kept.\n                biases = np.tile(0.5 * weights[2], 2)\n            return [kernels, recurrent_kernels, biases]\n\n        if source != target_class:\n            weights = convert_weights(weights, from_cudnn=source == 'CuDNNLSTM')\n\n    # convert the weights between CuDNNGRU and GRU(reset_after=True)\n    if target_class in ['GRU', 'CuDNNGRU'] and len(weights) == 3:\n        # We can determine the source of the weights from the shape of the bias.\n        # If there is no bias we skip the conversion\n        # since CuDNNGRU always has biases.\n\n        units = weights[1].shape[0]\n        bias_shape = weights[2].shape\n        n_gates = 3\n\n        def convert_weights(weights, from_cudnn=True):\n            kernels = transform_kernels(weights[0],\n                                        transpose_input(from_cudnn),\n                                        n_gates)\n            recurrent_kernels = transform_kernels(weights[1], lambda k: k.T, n_gates)\n            biases = np.array(weights[2]).reshape((2, -1) if from_cudnn else -1)\n            return [kernels, recurrent_kernels, biases]\n\n        if bias_shape == (2 * units * n_gates,):\n            source = 'CuDNNGRU'\n        elif bias_shape == (2, units * n_gates):\n            source = 'GRU(reset_after=True)'\n        elif bias_shape == (units * n_gates,):\n            source = 'GRU(reset_after=False)'\n        else:\n            raise ValueError('Invalid bias shape: ' + str(bias_shape))\n\n        if target_class == 'CuDNNGRU':\n            target = 'CuDNNGRU'\n        elif layer.reset_after:\n            target = 'GRU(reset_after=True)'\n        else:\n            target = 'GRU(reset_after=False)'\n\n        # only convert between different types\n        if source != target:\n            types = (source, target)\n            if 'GRU(reset_after=False)' in types:\n                raise ValueError('%s is not compatible with %s' % types)\n            if source == 'CuDNNGRU':\n                weights = convert_weights(weights, from_cudnn=True)\n            elif source == 'GRU(reset_after=True)':\n                weights = convert_weights(weights, from_cudnn=False)\n\n    return weights",
        "begin_line": 964,
        "end_line": 1109,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.saving.transform_kernels#990",
        "src_path": "keras/engine/saving.py",
        "class_name": "keras.engine.saving",
        "signature": "keras.engine.saving.transform_kernels(kernels, func, n_gates)",
        "snippet": "    def transform_kernels(kernels, func, n_gates):\n        \"\"\"Transforms kernel for each gate separately using given function.\n\n        # Arguments\n            kernels: Stacked array of kernels for individual gates.\n            func: Function applied to kernel of each gate.\n            n_gates: Number of gates (4 for LSTM, 3 for GRU).\n        # Returns\n            Stacked array of transformed kernels.\n        \"\"\"\n        return np.hstack([func(k) for k in np.hsplit(kernels, n_gates)])",
        "begin_line": 990,
        "end_line": 1000,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00032948929159802305,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.saving.transpose_input#1002",
        "src_path": "keras/engine/saving.py",
        "class_name": "keras.engine.saving",
        "signature": "keras.engine.saving.transpose_input(from_cudnn)",
        "snippet": "    def transpose_input(from_cudnn):\n        \"\"\"Makes a function that transforms input kernels from/to CuDNN format.\n\n        It keeps the shape, but changes between the layout (Fortran/C). Eg.:\n\n        ```\n        Keras                 CuDNN\n        [[0, 1, 2],  <--->  [[0, 2, 4],\n         [3, 4, 5]]          [1, 3, 5]]\n        ```\n\n        It can be passed to `transform_kernels()`.\n\n        # Arguments\n            from_cudnn: `True` if source weights are in CuDNN format, `False`\n                if they're in plain Keras format.\n        # Returns\n            Function that converts input kernel to the other format.\n        \"\"\"\n        order = 'F' if from_cudnn else 'C'\n\n        def transform(kernel):\n            return kernel.T.reshape(kernel.shape, order=order)\n\n        return transform",
        "begin_line": 1002,
        "end_line": 1026,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.00032948929159802305,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.saving.convert_weights#1047",
        "src_path": "keras/engine/saving.py",
        "class_name": "keras.engine.saving",
        "signature": "keras.engine.saving.convert_weights(weights, from_cudnn=True)",
        "snippet": "        def convert_weights(weights, from_cudnn=True):\n            # transpose (and reshape) input and recurrent kernels\n            kernels = transform_kernels(weights[0],\n                                        transpose_input(from_cudnn),\n                                        n_gates)\n            recurrent_kernels = transform_kernels(weights[1], lambda k: k.T, n_gates)\n            if from_cudnn:\n                # merge input and recurrent biases into a single set\n                biases = np.sum(np.split(weights[2], 2, axis=0), axis=0)\n            else:\n                # Split single set of biases evenly to two sets. The way of\n                # splitting doesn't matter as long as the two sets sum is kept.\n                biases = np.tile(0.5 * weights[2], 2)\n            return [kernels, recurrent_kernels, biases]",
        "begin_line": 1047,
        "end_line": 1060,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.saving._need_convert_kernel#1112",
        "src_path": "keras/engine/saving.py",
        "class_name": "keras.engine.saving",
        "signature": "keras.engine.saving._need_convert_kernel(original_backend)",
        "snippet": "def _need_convert_kernel(original_backend):\n    \"\"\"Checks if conversion on kernel matrices is required during weight loading.\n\n    The convolution operation is implemented differently in different backends.\n    While TH implements convolution, TF and CNTK implement the correlation operation.\n    So the channel axis needs to be flipped when TF weights are loaded on a TH model,\n    or vice versa. However, there's no conversion required between TF and CNTK.\n\n    # Arguments\n        original_backend: Keras backend the weights were trained with, as a string.\n\n    # Returns\n        `True` if conversion on kernel matrices is required, otherwise `False`.\n    \"\"\"\n    if original_backend is None:\n        # backend information not available\n        return False\n    uses_correlation = {'tensorflow': True,\n                        'theano': False,\n                        'cntk': True}\n    if original_backend not in uses_correlation:\n        # By default, do not convert the kernels if the original backend is unknown\n        return False\n    if K.backend() in uses_correlation:\n        current_uses_correlation = uses_correlation[K.backend()]\n    else:\n        # Assume unknown backends use correlation\n        current_uses_correlation = True\n    return uses_correlation[original_backend] != current_uses_correlation",
        "begin_line": 1112,
        "end_line": 1140,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.saving.load_weights_from_hdf5_group#1143",
        "src_path": "keras/engine/saving.py",
        "class_name": "keras.engine.saving",
        "signature": "keras.engine.saving.load_weights_from_hdf5_group(f, layers, reshape=False)",
        "snippet": "def load_weights_from_hdf5_group(f, layers, reshape=False):\n    \"\"\"Implements topological (order-based) weight loading.\n\n    # Arguments\n        f: A pointer to a HDF5 group.\n        layers: a list of target layers.\n        reshape: Reshape weights to fit the layer when the correct number\n            of values are present but the shape does not match.\n\n    # Raises\n        ValueError: in case of mismatch between provided layers\n            and weights file.\n    \"\"\"\n    if 'keras_version' in f.attrs:\n        original_keras_version = f.attrs['keras_version'].decode('utf8')\n    else:\n        original_keras_version = '1'\n    if 'backend' in f.attrs:\n        original_backend = f.attrs['backend'].decode('utf8')\n    else:\n        original_backend = None\n\n    filtered_layers = []\n    for layer in layers:\n        weights = layer.weights\n        if weights:\n            filtered_layers.append(layer)\n\n    layer_names = load_attributes_from_hdf5_group(f, 'layer_names')\n    filtered_layer_names = []\n    for name in layer_names:\n        g = f[name]\n        weight_names = load_attributes_from_hdf5_group(g, 'weight_names')\n        if weight_names:\n            filtered_layer_names.append(name)\n    layer_names = filtered_layer_names\n    if len(layer_names) != len(filtered_layers):\n        raise ValueError('You are trying to load a weight file '\n                         'containing ' + str(len(layer_names)) +\n                         ' layers into a model with ' +\n                         str(len(filtered_layers)) + ' layers.')\n\n    # We batch weight value assignments in a single backend call\n    # which provides a speedup in TensorFlow.\n    weight_value_tuples = []\n    for k, name in enumerate(layer_names):\n        g = f[name]\n        weight_names = load_attributes_from_hdf5_group(g, 'weight_names')\n        weight_values = [np.asarray(g[weight_name]) for weight_name in weight_names]\n        layer = filtered_layers[k]\n        symbolic_weights = layer.weights\n        weight_values = preprocess_weights_for_loading(layer,\n                                                       weight_values,\n                                                       original_keras_version,\n                                                       original_backend,\n                                                       reshape=reshape)\n        if len(weight_values) != len(symbolic_weights):\n            raise ValueError('Layer #' + str(k) +\n                             ' (named \"' + layer.name +\n                             '\" in the current model) was found to '\n                             'correspond to layer ' + name +\n                             ' in the save file. '\n                             'However the new layer ' + layer.name +\n                             ' expects ' + str(len(symbolic_weights)) +\n                             ' weights, but the saved weights have ' +\n                             str(len(weight_values)) +\n                             ' elements.')\n        weight_value_tuples += zip(symbolic_weights, weight_values)\n    K.batch_set_value(weight_value_tuples)",
        "begin_line": 1143,
        "end_line": 1211,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.engine.saving.load_weights_from_hdf5_group_by_name#1214",
        "src_path": "keras/engine/saving.py",
        "class_name": "keras.engine.saving",
        "signature": "keras.engine.saving.load_weights_from_hdf5_group_by_name(f, layers, skip_mismatch=False, reshape=False)",
        "snippet": "def load_weights_from_hdf5_group_by_name(f, layers, skip_mismatch=False,\n                                         reshape=False):\n    \"\"\"Implements name-based weight loading.\n\n    (instead of topological weight loading).\n\n    Layers that have no matching name are skipped.\n\n    # Arguments\n        f: A pointer to a HDF5 group.\n        layers: A list of target layers.\n        skip_mismatch: Boolean, whether to skip loading of layers\n            where there is a mismatch in the number of weights,\n            or a mismatch in the shape of the weights.\n        reshape: Reshape weights to fit the layer when the correct number\n            of values are present but the shape does not match.\n\n    # Raises\n        ValueError: in case of mismatch between provided layers\n            and weights file and skip_mismatch=False.\n    \"\"\"\n    if 'keras_version' in f.attrs:\n        original_keras_version = f.attrs['keras_version'].decode('utf8')\n    else:\n        original_keras_version = '1'\n    if 'backend' in f.attrs:\n        original_backend = f.attrs['backend'].decode('utf8')\n    else:\n        original_backend = None\n\n    # New file format.\n    layer_names = load_attributes_from_hdf5_group(f, 'layer_names')\n\n    # Reverse index of layer name to list of layers with name.\n    index = {}\n    for layer in layers:\n        if layer.name:\n            index.setdefault(layer.name, []).append(layer)\n\n    # We batch weight value assignments in a single backend call\n    # which provides a speedup in TensorFlow.\n    weight_value_tuples = []\n    for k, name in enumerate(layer_names):\n        g = f[name]\n        weight_names = load_attributes_from_hdf5_group(g, 'weight_names')\n        weight_values = [np.asarray(g[weight_name]) for weight_name in weight_names]\n\n        for layer in index.get(name, []):\n            symbolic_weights = layer.weights\n            weight_values = preprocess_weights_for_loading(\n                layer,\n                weight_values,\n                original_keras_version,\n                original_backend,\n                reshape=reshape)\n            if len(weight_values) != len(symbolic_weights):\n                if skip_mismatch:\n                    warnings.warn('Skipping loading of weights for '\n                                  'layer {}'.format(layer.name) + ' due to mismatch '\n                                  'in number of weights ({} vs {}).'.format(\n                                      len(symbolic_weights), len(weight_values)))\n                    continue\n                else:\n                    raise ValueError('Layer #' + str(k) +\n                                     ' (named \"' + layer.name +\n                                     '\") expects ' +\n                                     str(len(symbolic_weights)) +\n                                     ' weight(s), but the saved weights' +\n                                     ' have ' + str(len(weight_values)) +\n                                     ' element(s).')\n            # Set values.\n            for i in range(len(weight_values)):\n                symbolic_shape = K.int_shape(symbolic_weights[i])\n                if symbolic_shape != weight_values[i].shape:\n                    if skip_mismatch:\n                        warnings.warn('Skipping loading of weights for '\n                                      'layer {}'.format(layer.name) + ' due to '\n                                      'mismatch in shape ({} vs {}).'.format(\n                                          symbolic_weights[i].shape,\n                                          weight_values[i].shape))\n                        continue\n                    else:\n                        raise ValueError('Layer #' + str(k) +\n                                         ' (named \"' + layer.name +\n                                         '\"), weight ' +\n                                         str(symbolic_weights[i]) +\n                                         ' has shape {}'.format(symbolic_shape) +\n                                         ', but the saved weight has shape ' +\n                                         str(weight_values[i].shape) + '.')\n                else:\n                    weight_value_tuples.append((symbolic_weights[i],\n                                                weight_values[i]))\n\n    K.batch_set_value(weight_value_tuples)",
        "begin_line": 1214,
        "end_line": 1307,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.utils.conv_utils.normalize_tuple#12",
        "src_path": "keras/utils/conv_utils.py",
        "class_name": "keras.utils.conv_utils",
        "signature": "keras.utils.conv_utils.normalize_tuple(value, n, name)",
        "snippet": "def normalize_tuple(value, n, name):\n    \"\"\"Transforms a single int or iterable of ints into an int tuple.\n\n    # Arguments\n        value: The value to validate and convert. Could be an int, or any iterable\n          of ints.\n        n: The size of the tuple to be returned.\n        name: The name of the argument being validated, e.g. `strides` or\n          `kernel_size`. This is only used to format error messages.\n\n    # Returns\n        A tuple of n integers.\n\n    # Raises\n        ValueError: If something else than an int/long or iterable thereof was\n        passed.\n    \"\"\"\n    if isinstance(value, int):\n        return (value,) * n\n    else:\n        try:\n            value_tuple = tuple(value)\n        except TypeError:\n            raise ValueError('The `' + name + '` argument must be a tuple of ' +\n                             str(n) + ' integers. Received: ' + str(value))\n        if len(value_tuple) != n:\n            raise ValueError('The `' + name + '` argument must be a tuple of ' +\n                             str(n) + ' integers. Received: ' + str(value))\n        for single_value in value_tuple:\n            try:\n                int(single_value)\n            except ValueError:\n                raise ValueError('The `' + name + '` argument must be a tuple of ' +\n                                 str(n) + ' integers. Received: ' + str(value) + ' '\n                                 'including element ' + str(single_value) + ' of '\n                                 'type ' + str(type(single_value)))\n    return value_tuple",
        "begin_line": 12,
        "end_line": 48,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.utils.conv_utils.normalize_padding#51",
        "src_path": "keras/utils/conv_utils.py",
        "class_name": "keras.utils.conv_utils",
        "signature": "keras.utils.conv_utils.normalize_padding(value)",
        "snippet": "def normalize_padding(value):\n    padding = value.lower()\n    allowed = {'valid', 'same', 'causal'}\n    if K.backend() == 'theano':\n        allowed.add('full')\n    if padding not in allowed:\n        raise ValueError('The `padding` argument must be one of \"valid\", \"same\" '\n                         '(or \"causal\" for Conv1D). Received: ' + str(padding))\n    return padding",
        "begin_line": 51,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    },
    {
        "name": "keras.utils.conv_utils.conv_output_length#85",
        "src_path": "keras/utils/conv_utils.py",
        "class_name": "keras.utils.conv_utils",
        "signature": "keras.utils.conv_utils.conv_output_length(input_length, filter_size, padding, stride, dilation=1)",
        "snippet": "def conv_output_length(input_length, filter_size,\n                       padding, stride, dilation=1):\n    \"\"\"Determines output length of a convolution given input length.\n\n    # Arguments\n        input_length: integer.\n        filter_size: integer.\n        padding: one of `\"same\"`, `\"valid\"`, `\"full\"`.\n        stride: integer.\n        dilation: dilation rate, integer.\n\n    # Returns\n        The output length (integer).\n    \"\"\"\n    if input_length is None:\n        return None\n    assert padding in {'same', 'valid', 'full', 'causal'}\n    dilated_filter_size = filter_size + (filter_size - 1) * (dilation - 1)\n    if padding == 'same':\n        output_length = input_length\n    elif padding == 'valid':\n        output_length = input_length - dilated_filter_size + 1\n    elif padding == 'causal':\n        output_length = input_length\n    elif padding == 'full':\n        output_length = input_length + dilated_filter_size - 1\n    return (output_length + stride - 1) // stride",
        "begin_line": 85,
        "end_line": 111,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00048567265662943174,
            "pseudo_dstar_susp": 0.00048567265662943174,
            "pseudo_tarantula_susp": 0.00048567265662943174,
            "pseudo_op2_susp": 0.0031446540880503146,
            "pseudo_barinel_susp": 0.00048567265662943174
        }
    }
]