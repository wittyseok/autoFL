coverage run -m pytest tests/keras/test_sequential_model.py::test_clone_functional_model_with_multi_outputs
============================= test session starts ==============================
platform linux -- Python 3.7.3, pytest-5.4.3, py-1.8.1, pluggy-0.13.1 -- /opt/conda/envs/ec1239e90de2b89d455019719a3688a0/bin/python
cachedir: .pytest_cache
rootdir: /home/user/BugsInPy/temp/projects/keras, inifile: pytest.ini
plugins: forked-1.1.3, flaky-3.6.1, xdist-1.32.0
gw0 I / gw1 I

[gw0] linux Python 3.7.3 cwd: /home/user/BugsInPy/temp/projects/keras

[gw1] linux Python 3.7.3 cwd: /home/user/BugsInPy/temp/projects/keras

[gw0] Python 3.7.3 (default, Mar 27 2019, 22:11:17)  -- [GCC 7.3.0]

[gw1] Python 3.7.3 (default, Mar 27 2019, 22:11:17)  -- [GCC 7.3.0]
gw0 [1] / gw1 [1]

scheduling tests via LoadScheduling

tests/keras/test_sequential_model.py::test_clone_functional_model_with_multi_outputs 
[gw0] [100%] FAILED tests/keras/test_sequential_model.py::test_clone_functional_model_with_multi_outputs 

=================================== FAILURES ===================================
________________ test_clone_functional_model_with_multi_outputs ________________
[gw0] linux -- Python 3.7.3 /opt/conda/envs/ec1239e90de2b89d455019719a3688a0/bin/python

    def test_clone_functional_model_with_multi_outputs():
        input_layer = keras.Input(shape=(4,))
    
        # Layer with single input and multiple outputs
        layer1 = keras.layers.Lambda(lambda x: [x + 1, x],
                                     lambda shapes: [shapes, shapes])
        x_a, x_b = layer1(input_layer)
    
        class SwapLayer(keras.layers.Layer):
            def call(self, inputs, **kwargs):
                return [inputs[1], inputs[0]]
    
            def compute_output_shape(self, input_shape):
                return [input_shape[1], input_shape[0]]
    
        # Layer with multiple inputs and outputs
        x_a, x_b = SwapLayer()([x_a, x_b])
        model = keras.Model(inputs=[input_layer], outputs=[x_a, x_b])
>       new_model = keras.models.clone_model(model)

tests/keras/test_sequential_model.py:360: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
keras/models.py:251: in clone_model
    return _clone_functional_model(model, input_tensors=input_tensors)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

model = <keras.engine.training.Model object at 0x7fc7070e7278>
input_tensors = [<tf.Tensor 'input_1_1:0' shape=(?, 4) dtype=float32>]

    def _clone_functional_model(model, input_tensors=None):
        """Clone a functional `Model` instance.
    
        Model cloning is similar to calling a model on new inputs,
        except that it creates new layers (and thus new weights) instead
        of sharing the weights of the existing layers.
    
        # Arguments
            model: Instance of `Model`.
            input_tensors: optional list of input tensors
                to build the model upon. If not provided,
                placeholders will be created.
    
        # Returns
            An instance of `Model` reproducing the behavior
            of the original model, on top of new inputs tensors,
            using newly instantiated weights.
    
        # Raises
            ValueError: in case of invalid `model` argument value.
        """
        if not isinstance(model, Model):
            raise ValueError('Expected `model` argument '
                             'to be a `Model` instance, got ', model)
        if isinstance(model, Sequential):
            raise ValueError('Expected `model` argument '
                             'to be a functional `Model` instance, '
                             'got a `Sequential` instance instead:', model)
    
        layer_map = {}  # Cache for created layers.
        tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}
        if input_tensors is None:
            # Create placeholders to build the model on top of.
            input_layers = []
            input_tensors = []
            for layer in model._input_layers:
                input_tensor = Input(batch_shape=layer.batch_input_shape,
                                     dtype=layer.dtype,
                                     sparse=layer.sparse,
                                     name=layer.name)
                input_tensors.append(input_tensor)
                # Cache newly created input layer.
                newly_created_input_layer = input_tensor._keras_history[0]
                layer_map[layer] = newly_created_input_layer
            for _original, _cloned in zip(model._input_layers, input_layers):
                layer_map[_original] = _cloned
        else:
            # Make sure that all input tensors come from a Keras layer.
            # If tensor comes from an input layer: cache the input layer.
            input_tensors = to_list(input_tensors)
            _input_tensors = []
            for i, x in enumerate(input_tensors):
                if not K.is_keras_tensor(x):
                    name = model._input_layers[i].name
                    input_tensor = Input(tensor=x,
                                         name='input_wrapper_for_' + name)
                    _input_tensors.append(input_tensor)
                    # Cache newly created input layer.
                    original_input_layer = x._keras_history[0]
                    newly_created_input_layer = input_tensor._keras_history[0]
                    layer_map[original_input_layer] = newly_created_input_layer
                else:
                    _input_tensors.append(x)
            input_tensors = _input_tensors
    
        for x, y in zip(model.inputs, input_tensors):
            tensor_map[x] = (y, None)  # tensor, mask
    
        # Iterated over every node in the reference model, in depth order.
        depth_keys = list(model._nodes_by_depth.keys())
        depth_keys.sort(reverse=True)
        for depth in depth_keys:
            nodes = model._nodes_by_depth[depth]
            for node in nodes:
                # Recover the corresponding layer.
                layer = node.outbound_layer
    
                # Get or create layer.
                if layer not in layer_map:
                    # Clone layer.
                    new_layer = layer.__class__.from_config(layer.get_config())
                    layer_map[layer] = new_layer
                    layer = new_layer
                else:
                    # Reuse previously cloned layer.
                    layer = layer_map[layer]
                    # Don't call InputLayer multiple times.
                    if isinstance(layer, InputLayer):
                        continue
    
                # Gather inputs to call the new layer.
                reference_input_tensors = node.input_tensors
                reference_output_tensors = node.output_tensors
    
                # If all previous input tensors are available in tensor_map,
                # then call node.inbound_layer on them.
                computed_data = []  # List of tuples (input, mask).
                for x in reference_input_tensors:
                    if x in tensor_map:
                        computed_data.append(tensor_map[x])
    
                if len(computed_data) == len(reference_input_tensors):
                    # Call layer.
                    if node.arguments:
                        kwargs = node.arguments
                    else:
                        kwargs = {}
                    if len(computed_data) == 1:
                        computed_tensor, computed_mask = computed_data[0]
                        if has_arg(layer.call, 'mask'):
                            if 'mask' not in kwargs:
                                kwargs['mask'] = computed_mask
                        output_tensors = to_list(
                            layer(computed_tensor, **kwargs))
                        output_masks = to_list(
                            layer.compute_mask(computed_tensor,
                                               computed_mask))
                        computed_tensors = [computed_tensor]
                        computed_masks = [computed_mask]
                    else:
                        computed_tensors = [x[0] for x in computed_data]
                        computed_masks = [x[1] for x in computed_data]
                        if has_arg(layer.call, 'mask'):
                            if 'mask' not in kwargs:
                                kwargs['mask'] = computed_masks
                        output_tensors = to_list(
                            layer(computed_tensors, **kwargs))
                        output_masks = to_list(
                            layer.compute_mask(computed_tensors,
                                               computed_masks))
                    # Update tensor_map.
                    for x, y, mask in zip(reference_output_tensors,
                                          output_tensors,
                                          output_masks):
                        tensor_map[x] = (y, mask)
    
        # Check that we did compute the model outputs,
        # then instantiate a new model from inputs and outputs.
        output_tensors = []
        for x in model.outputs:
>           assert x in tensor_map, 'Could not compute output ' + str(x)
E           AssertionError: Could not compute output Tensor("swap_layer_1/Identity:0", shape=(?, 4), dtype=float32)

keras/models.py:166: AssertionError
----------------------------- Captured stderr call -----------------------------
WARNING:tensorflow:From /home/user/BugsInPy/temp/projects/keras/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /home/user/BugsInPy/temp/projects/keras/keras/backend/tensorflow_backend.py:528: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

------------------------------ Captured log call -------------------------------
WARNING  tensorflow:module_wrapper.py:139 From /home/user/BugsInPy/temp/projects/keras/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING  tensorflow:module_wrapper.py:139 From /home/user/BugsInPy/temp/projects/keras/keras/backend/tensorflow_backend.py:528: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.
--------------------------- Captured stderr teardown ---------------------------
WARNING:tensorflow:From /home/user/BugsInPy/temp/projects/keras/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From /home/user/BugsInPy/temp/projects/keras/keras/backend/tensorflow_backend.py:99: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

---------------------------- Captured log teardown -----------------------------
WARNING  tensorflow:module_wrapper.py:139 From /home/user/BugsInPy/temp/projects/keras/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING  tensorflow:module_wrapper.py:139 From /home/user/BugsInPy/temp/projects/keras/keras/backend/tensorflow_backend.py:99: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.
=============================== warnings summary ===============================
/opt/conda/envs/ec1239e90de2b89d455019719a3688a0/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/learn_io/generator_io.py:26
  /opt/conda/envs/ec1239e90de2b89d455019719a3688a0/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/learn_io/generator_io.py:26: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working
    from collections import Container

-- Docs: https://docs.pytest.org/en/latest/warnings.html
========================== slowest 20 test durations ===========================
0.01s call     tests/keras/test_sequential_model.py::test_clone_functional_model_with_multi_outputs

(0.00 durations hidden.  Use -vv to show these durations.)
=========================== short test summary info ============================
FAILED tests/keras/test_sequential_model.py::test_clone_functional_model_with_multi_outputs
========================= 1 failed, 1 warning in 2.59s =========================
Using TensorFlow backend.
