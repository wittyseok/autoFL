[
    {
        "name": "pandas.core.dtypes.dtypes.Registry.find#78",
        "src_path": "pandas/core/dtypes/dtypes.py",
        "class_name": "pandas.core.dtypes.dtypes.Registry",
        "signature": "pandas.core.dtypes.dtypes.Registry.find(self, dtype: Union[Type[ExtensionDtype], str])",
        "snippet": "    def find(\n        self, dtype: Union[Type[ExtensionDtype], str]\n    ) -> Optional[Type[ExtensionDtype]]:\n        \"\"\"\n        Parameters\n        ----------\n        dtype : Type[ExtensionDtype] or str\n\n        Returns\n        -------\n        return the first matching dtype, otherwise return None\n        \"\"\"\n        if not isinstance(dtype, str):\n            dtype_type = dtype\n            if not isinstance(dtype, type):\n                dtype_type = type(dtype)\n            if issubclass(dtype_type, ExtensionDtype):\n                return dtype\n\n            return None\n\n        for dtype_type in self.dtypes:\n            try:\n                return dtype_type.construct_from_string(dtype)\n            except TypeError:\n                pass\n\n        return None",
        "begin_line": 78,
        "end_line": 105,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.dtypes.CategoricalDtype.construct_from_string#352",
        "src_path": "pandas/core/dtypes/dtypes.py",
        "class_name": "pandas.core.dtypes.dtypes.CategoricalDtype",
        "signature": "pandas.core.dtypes.dtypes.CategoricalDtype.construct_from_string(cls, string: str_type)",
        "snippet": "    def construct_from_string(cls, string: str_type) -> \"CategoricalDtype\":\n        \"\"\"\n        Construct a CategoricalDtype from a string.\n\n        Parameters\n        ----------\n        string : str\n            Must be the string \"category\" in order to be successfully constructed.\n\n        Returns\n        -------\n        CategoricalDtype\n            Instance of the dtype.\n\n        Raises\n        ------\n        TypeError\n            If a CategoricalDtype cannot be constructed from the input.\n        \"\"\"\n        if not isinstance(string, str):\n            raise TypeError(\n                f\"'construct_from_string' expects a string, got {type(string)}\"\n            )\n        if string != cls.name:\n            raise TypeError(f\"Cannot construct a 'CategoricalDtype' from '{string}'\")\n\n        # need ordered=None to ensure that operations specifying dtype=\"category\" don't\n        # override the ordered value for existing categoricals\n        return cls(ordered=None)",
        "begin_line": 352,
        "end_line": 380,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.dtypes.DatetimeTZDtype.construct_from_string#734",
        "src_path": "pandas/core/dtypes/dtypes.py",
        "class_name": "pandas.core.dtypes.dtypes.DatetimeTZDtype",
        "signature": "pandas.core.dtypes.dtypes.DatetimeTZDtype.construct_from_string(cls, string: str_type)",
        "snippet": "    def construct_from_string(cls, string: str_type):\n        \"\"\"\n        Construct a DatetimeTZDtype from a string.\n\n        Parameters\n        ----------\n        string : str\n            The string alias for this DatetimeTZDtype.\n            Should be formatted like ``datetime64[ns, <tz>]``,\n            where ``<tz>`` is the timezone name.\n\n        Examples\n        --------\n        >>> DatetimeTZDtype.construct_from_string('datetime64[ns, UTC]')\n        datetime64[ns, UTC]\n        \"\"\"\n        if not isinstance(string, str):\n            raise TypeError(\n                f\"'construct_from_string' expects a string, got {type(string)}\"\n            )\n\n        msg = f\"Cannot construct a 'DatetimeTZDtype' from '{string}'\"\n        match = cls._match.match(string)\n        if match:\n            d = match.groupdict()\n            try:\n                return cls(unit=d[\"unit\"], tz=d[\"tz\"])\n            except (KeyError, TypeError, ValueError) as err:\n                # KeyError if maybe_get_tz tries and fails to get a\n                #  pytz timezone (actually pytz.UnknownTimeZoneError).\n                # TypeError if we pass a nonsense tz;\n                # ValueError if we pass a unit other than \"ns\"\n                raise TypeError(msg) from err\n        raise TypeError(msg)",
        "begin_line": 734,
        "end_line": 767,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.dtypes.PeriodDtype.construct_from_string#887",
        "src_path": "pandas/core/dtypes/dtypes.py",
        "class_name": "pandas.core.dtypes.dtypes.PeriodDtype",
        "signature": "pandas.core.dtypes.dtypes.PeriodDtype.construct_from_string(cls, string)",
        "snippet": "    def construct_from_string(cls, string):\n        \"\"\"\n        Strict construction from a string, raise a TypeError if not\n        possible\n        \"\"\"\n        if (\n            isinstance(string, str)\n            and (string.startswith(\"period[\") or string.startswith(\"Period[\"))\n            or isinstance(string, ABCDateOffset)\n        ):\n            # do not parse string like U as period[U]\n            # avoid tuple to be regarded as freq\n            try:\n                return cls(freq=string)\n            except ValueError:\n                pass\n        if isinstance(string, str):\n            msg = f\"Cannot construct a 'PeriodDtype' from '{string}'\"\n        else:\n            msg = f\"'construct_from_string' expects a string, got {type(string)}\"\n        raise TypeError(msg)",
        "begin_line": 887,
        "end_line": 907,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.dtypes.PeriodDtype.is_dtype#937",
        "src_path": "pandas/core/dtypes/dtypes.py",
        "class_name": "pandas.core.dtypes.dtypes.PeriodDtype",
        "signature": "pandas.core.dtypes.dtypes.PeriodDtype.is_dtype(cls, dtype)",
        "snippet": "    def is_dtype(cls, dtype) -> bool:\n        \"\"\"\n        Return a boolean if we if the passed type is an actual dtype that we\n        can match (via string or type)\n        \"\"\"\n        if isinstance(dtype, str):\n            # PeriodDtype can be instantiated from freq string like \"U\",\n            # but doesn't regard freq str like \"U\" as dtype.\n            if dtype.startswith(\"period[\") or dtype.startswith(\"Period[\"):\n                try:\n                    if cls._parse_dtype_strict(dtype) is not None:\n                        return True\n                    else:\n                        return False\n                except ValueError:\n                    return False\n            else:\n                return False\n        return super().is_dtype(dtype)",
        "begin_line": 937,
        "end_line": 955,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.dtypes.IntervalDtype.construct_from_string#1091",
        "src_path": "pandas/core/dtypes/dtypes.py",
        "class_name": "pandas.core.dtypes.dtypes.IntervalDtype",
        "signature": "pandas.core.dtypes.dtypes.IntervalDtype.construct_from_string(cls, string)",
        "snippet": "    def construct_from_string(cls, string):\n        \"\"\"\n        attempt to construct this type from a string, raise a TypeError\n        if its not possible\n        \"\"\"\n        if not isinstance(string, str):\n            raise TypeError(\n                f\"'construct_from_string' expects a string, got {type(string)}\"\n            )\n\n        if string.lower() == \"interval\" or cls._match.search(string) is not None:\n            return cls(string)\n\n        msg = (\n            f\"Cannot construct a 'IntervalDtype' from '{string}'.\\n\\n\"\n            \"Incorrectly formatted string passed to constructor. \"\n            \"Valid formats include Interval or Interval[dtype] \"\n            \"where dtype is numeric, datetime, or timedelta\"\n        )\n        raise TypeError(msg)",
        "begin_line": 1091,
        "end_line": 1110,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.dtypes.IntervalDtype.is_dtype#1145",
        "src_path": "pandas/core/dtypes/dtypes.py",
        "class_name": "pandas.core.dtypes.dtypes.IntervalDtype",
        "signature": "pandas.core.dtypes.dtypes.IntervalDtype.is_dtype(cls, dtype)",
        "snippet": "    def is_dtype(cls, dtype) -> bool:\n        \"\"\"\n        Return a boolean if we if the passed type is an actual dtype that we\n        can match (via string or type)\n        \"\"\"\n        if isinstance(dtype, str):\n            if dtype.lower().startswith(\"interval\"):\n                try:\n                    if cls.construct_from_string(dtype) is not None:\n                        return True\n                    else:\n                        return False\n                except (ValueError, TypeError):\n                    return False\n            else:\n                return False\n        return super().is_dtype(dtype)",
        "begin_line": 1145,
        "end_line": 1161,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.indexes.numeric.NumericIndex._validate_dtype#82",
        "src_path": "pandas/core/indexes/numeric.py",
        "class_name": "pandas.core.indexes.numeric.NumericIndex",
        "signature": "pandas.core.indexes.numeric.NumericIndex._validate_dtype(cls, dtype: Dtype)",
        "snippet": "    def _validate_dtype(cls, dtype: Dtype) -> None:\n        if dtype is None:\n            return\n        validation_metadata = {\n            \"int64index\": (is_signed_integer_dtype, \"signed integer\"),\n            \"uint64index\": (is_unsigned_integer_dtype, \"unsigned integer\"),\n            \"float64index\": (is_float_dtype, \"float\"),\n            \"rangeindex\": (is_signed_integer_dtype, \"signed integer\"),\n        }\n\n        validation_func, expected = validation_metadata[cls._typ]\n        if not validation_func(dtype):\n            raise ValueError(\n                f\"Incorrect `dtype` passed: expected {expected}, received {dtype}\"\n            )",
        "begin_line": 82,
        "end_line": 96,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.indexes.numeric.NumericIndex.is_all_dates#159",
        "src_path": "pandas/core/indexes/numeric.py",
        "class_name": "pandas.core.indexes.numeric.NumericIndex",
        "signature": "pandas.core.indexes.numeric.NumericIndex.is_all_dates(self)",
        "snippet": "    def is_all_dates(self) -> bool:\n        \"\"\"\n        Checks that all the labels are datetime objects.\n        \"\"\"\n        return False",
        "begin_line": 159,
        "end_line": 163,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.arrays.base.ExtensionArray.ndim#411",
        "src_path": "pandas/core/arrays/base.py",
        "class_name": "pandas.core.arrays.base.ExtensionArray",
        "signature": "pandas.core.arrays.base.ExtensionArray.ndim(self)",
        "snippet": "    def ndim(self) -> int:\n        \"\"\"\n        Extension Arrays are only allowed to be 1-dimensional.\n        \"\"\"\n        return 1",
        "begin_line": 411,
        "end_line": 415,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.missing.isna#50",
        "src_path": "pandas/core/dtypes/missing.py",
        "class_name": "pandas.core.dtypes.missing",
        "signature": "pandas.core.dtypes.missing.isna(obj)",
        "snippet": "def isna(obj):\n    \"\"\"\n    Detect missing values for an array-like object.\n\n    This function takes a scalar or array-like object and indicates\n    whether values are missing (``NaN`` in numeric arrays, ``None`` or ``NaN``\n    in object arrays, ``NaT`` in datetimelike).\n\n    Parameters\n    ----------\n    obj : scalar or array-like\n        Object to check for null or missing values.\n\n    Returns\n    -------\n    bool or array-like of bool\n        For scalar input, returns a scalar boolean.\n        For array input, returns an array of boolean indicating whether each\n        corresponding element is missing.\n\n    See Also\n    --------\n    notna : Boolean inverse of pandas.isna.\n    Series.isna : Detect missing values in a Series.\n    DataFrame.isna : Detect missing values in a DataFrame.\n    Index.isna : Detect missing values in an Index.\n\n    Examples\n    --------\n    Scalar arguments (including strings) result in a scalar boolean.\n\n    >>> pd.isna('dog')\n    False\n\n    >>> pd.isna(pd.NA)\n    True\n\n    >>> pd.isna(np.nan)\n    True\n\n    ndarrays result in an ndarray of booleans.\n\n    >>> array = np.array([[1, np.nan, 3], [4, 5, np.nan]])\n    >>> array\n    array([[ 1., nan,  3.],\n           [ 4.,  5., nan]])\n    >>> pd.isna(array)\n    array([[False,  True, False],\n           [False, False,  True]])\n\n    For indexes, an ndarray of booleans is returned.\n\n    >>> index = pd.DatetimeIndex([\"2017-07-05\", \"2017-07-06\", None,\n    ...                           \"2017-07-08\"])\n    >>> index\n    DatetimeIndex(['2017-07-05', '2017-07-06', 'NaT', '2017-07-08'],\n                  dtype='datetime64[ns]', freq=None)\n    >>> pd.isna(index)\n    array([False, False,  True, False])\n\n    For Series and DataFrame, the same type is returned, containing booleans.\n\n    >>> df = pd.DataFrame([['ant', 'bee', 'cat'], ['dog', None, 'fly']])\n    >>> df\n         0     1    2\n    0  ant   bee  cat\n    1  dog  None  fly\n    >>> pd.isna(df)\n           0      1      2\n    0  False  False  False\n    1  False   True  False\n\n    >>> pd.isna(df[1])\n    0    False\n    1     True\n    Name: 1, dtype: bool\n    \"\"\"\n    return _isna(obj)",
        "begin_line": 50,
        "end_line": 127,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.missing._isna_new#133",
        "src_path": "pandas/core/dtypes/missing.py",
        "class_name": "pandas.core.dtypes.missing",
        "signature": "pandas.core.dtypes.missing._isna_new(obj)",
        "snippet": "def _isna_new(obj):\n\n    if is_scalar(obj):\n        return libmissing.checknull(obj)\n    # hack (for now) because MI registers as ndarray\n    elif isinstance(obj, ABCMultiIndex):\n        raise NotImplementedError(\"isna is not defined for MultiIndex\")\n    elif isinstance(obj, type):\n        return False\n    elif isinstance(\n        obj,\n        (\n            ABCSeries,\n            np.ndarray,\n            ABCIndexClass,\n            ABCExtensionArray,\n            ABCDatetimeArray,\n            ABCTimedeltaArray,\n        ),\n    ):\n        return _isna_ndarraylike(obj)\n    elif isinstance(obj, ABCGeneric):\n        return obj._constructor(obj._data.isna(func=isna))\n    elif isinstance(obj, list):\n        return _isna_ndarraylike(np.asarray(obj, dtype=object))\n    elif hasattr(obj, \"__array__\"):\n        return _isna_ndarraylike(np.asarray(obj))\n    else:\n        return obj is None",
        "begin_line": 133,
        "end_line": 161,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.missing._isna_ndarraylike#226",
        "src_path": "pandas/core/dtypes/missing.py",
        "class_name": "pandas.core.dtypes.missing",
        "signature": "pandas.core.dtypes.missing._isna_ndarraylike(obj)",
        "snippet": "def _isna_ndarraylike(obj):\n    is_extension = is_extension_array_dtype(obj)\n\n    if not is_extension:\n        # Avoid accessing `.values` on things like\n        # PeriodIndex, which may be expensive.\n        values = getattr(obj, \"values\", obj)\n    else:\n        values = obj\n\n    dtype = values.dtype\n\n    if is_extension:\n        if isinstance(obj, (ABCIndexClass, ABCSeries)):\n            values = obj._values\n        else:\n            values = obj\n        result = values.isna()\n    elif isinstance(obj, ABCDatetimeArray):\n        return obj.isna()\n    elif is_string_dtype(dtype):\n        # Working around NumPy ticket 1542\n        shape = values.shape\n\n        if is_string_like_dtype(dtype):\n            # object array of strings\n            result = np.zeros(values.shape, dtype=bool)\n        else:\n            # object array of non-strings\n            result = np.empty(shape, dtype=bool)\n            vec = libmissing.isnaobj(values.ravel())\n            result[...] = vec.reshape(shape)\n\n    elif needs_i8_conversion(dtype):\n        # this is the NaT pattern\n        result = values.view(\"i8\") == iNaT\n    else:\n        result = np.isnan(values)\n\n    # box\n    if isinstance(obj, ABCSeries):\n        result = obj._constructor(result, index=obj.index, name=obj.name, copy=False)\n\n    return result",
        "begin_line": 226,
        "end_line": 269,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.common.ensure_python_int#173",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.ensure_python_int(value: Union[int, np.integer])",
        "snippet": "def ensure_python_int(value: Union[int, np.integer]) -> int:\n    \"\"\"\n    Ensure that a value is a python int.\n\n    Parameters\n    ----------\n    value: int or numpy.integer\n\n    Returns\n    -------\n    int\n\n    Raises\n    ------\n    TypeError: if the value isn't an int or can't be converted to one.\n    \"\"\"\n    if not is_scalar(value):\n        raise TypeError(f\"Value needs to be a scalar value, was type {type(value)}\")\n    try:\n        new_value = int(value)\n        assert new_value == value\n    except (TypeError, ValueError, AssertionError) as err:\n        raise TypeError(f\"Wrong type {type(value)} for value {value}\") from err\n    return new_value",
        "begin_line": 173,
        "end_line": 196,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.common.classes#199",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.classes(*klasses)",
        "snippet": "def classes(*klasses) -> Callable:\n    \"\"\" evaluate if the tipo is a subclass of the klasses \"\"\"\n    return lambda tipo: issubclass(tipo, klasses)",
        "begin_line": 199,
        "end_line": 201,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.16666666666666666,
            "pseudo_dstar_susp": 0.16666666666666666,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.16666666666666666,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.common.classes_and_not_datetimelike#204",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.classes_and_not_datetimelike(*klasses)",
        "snippet": "def classes_and_not_datetimelike(*klasses) -> Callable:\n    \"\"\"\n    evaluate if the tipo is a subclass of the klasses\n    and not a datetimelike\n    \"\"\"\n    return lambda tipo: (\n        issubclass(tipo, klasses)\n        and not issubclass(tipo, (np.datetime64, np.timedelta64))\n    )",
        "begin_line": 204,
        "end_line": 212,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.16666666666666666,
            "pseudo_dstar_susp": 0.16666666666666666,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.16666666666666666,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_object_dtype#215",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_object_dtype(arr_or_dtype)",
        "snippet": "def is_object_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether an array-like or dtype is of the object dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like or dtype is of the object dtype.\n\n    Examples\n    --------\n    >>> is_object_dtype(object)\n    True\n    >>> is_object_dtype(int)\n    False\n    >>> is_object_dtype(np.array([], dtype=object))\n    True\n    >>> is_object_dtype(np.array([], dtype=int))\n    False\n    >>> is_object_dtype([1, 2, 3])\n    False\n    \"\"\"\n    return _is_dtype_type(arr_or_dtype, classes(np.object_))",
        "begin_line": 215,
        "end_line": 242,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_sparse#245",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_sparse(arr)",
        "snippet": "def is_sparse(arr) -> bool:\n    \"\"\"\n    Check whether an array-like is a 1-D pandas sparse array.\n\n    Check that the one-dimensional array-like is a pandas sparse array.\n    Returns True if it is a pandas sparse array, not another type of\n    sparse array.\n\n    Parameters\n    ----------\n    arr : array-like\n        Array-like to check.\n\n    Returns\n    -------\n    bool\n        Whether or not the array-like is a pandas sparse array.\n\n    Examples\n    --------\n    Returns `True` if the parameter is a 1-D pandas sparse array.\n\n    >>> is_sparse(pd.arrays.SparseArray([0, 0, 1, 0]))\n    True\n    >>> is_sparse(pd.Series(pd.arrays.SparseArray([0, 0, 1, 0])))\n    True\n\n    Returns `False` if the parameter is not sparse.\n\n    >>> is_sparse(np.array([0, 0, 1, 0]))\n    False\n    >>> is_sparse(pd.Series([0, 1, 0, 0]))\n    False\n\n    Returns `False` if the parameter is not a pandas sparse array.\n\n    >>> from scipy.sparse import bsr_matrix\n    >>> is_sparse(bsr_matrix([0, 1, 0, 0]))\n    False\n\n    Returns `False` if the parameter has more than one dimension.\n    \"\"\"\n    from pandas.core.arrays.sparse import SparseDtype\n\n    dtype = getattr(arr, \"dtype\", arr)\n    return isinstance(dtype, SparseDtype)",
        "begin_line": 245,
        "end_line": 290,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_categorical#331",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_categorical(arr)",
        "snippet": "def is_categorical(arr) -> bool:\n    \"\"\"\n    Check whether an array-like is a Categorical instance.\n\n    Parameters\n    ----------\n    arr : array-like\n        The array-like to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like is of a Categorical instance.\n\n    Examples\n    --------\n    >>> is_categorical([1, 2, 3])\n    False\n\n    Categoricals, Series Categoricals, and CategoricalIndex will return True.\n\n    >>> cat = pd.Categorical([1, 2, 3])\n    >>> is_categorical(cat)\n    True\n    >>> is_categorical(pd.Series(cat))\n    True\n    >>> is_categorical(pd.CategoricalIndex([1, 2, 3]))\n    True\n    \"\"\"\n    return isinstance(arr, ABCCategorical) or is_categorical_dtype(arr)",
        "begin_line": 331,
        "end_line": 360,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_datetime64_dtype#363",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_datetime64_dtype(arr_or_dtype)",
        "snippet": "def is_datetime64_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether an array-like or dtype is of the datetime64 dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like or dtype is of the datetime64 dtype.\n\n    Examples\n    --------\n    >>> is_datetime64_dtype(object)\n    False\n    >>> is_datetime64_dtype(np.datetime64)\n    True\n    >>> is_datetime64_dtype(np.array([], dtype=int))\n    False\n    >>> is_datetime64_dtype(np.array([], dtype=np.datetime64))\n    True\n    >>> is_datetime64_dtype([1, 2, 3])\n    False\n    \"\"\"\n    return _is_dtype_type(arr_or_dtype, classes(np.datetime64))",
        "begin_line": 363,
        "end_line": 390,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_datetime64tz_dtype#393",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_datetime64tz_dtype(arr_or_dtype)",
        "snippet": "def is_datetime64tz_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether an array-like or dtype is of a DatetimeTZDtype dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like or dtype is of a DatetimeTZDtype dtype.\n\n    Examples\n    --------\n    >>> is_datetime64tz_dtype(object)\n    False\n    >>> is_datetime64tz_dtype([1, 2, 3])\n    False\n    >>> is_datetime64tz_dtype(pd.DatetimeIndex([1, 2, 3]))  # tz-naive\n    False\n    >>> is_datetime64tz_dtype(pd.DatetimeIndex([1, 2, 3], tz=\"US/Eastern\"))\n    True\n\n    >>> dtype = DatetimeTZDtype(\"ns\", tz=\"US/Eastern\")\n    >>> s = pd.Series([], dtype=dtype)\n    >>> is_datetime64tz_dtype(dtype)\n    True\n    >>> is_datetime64tz_dtype(s)\n    True\n    \"\"\"\n    if arr_or_dtype is None:\n        return False\n    return DatetimeTZDtype.is_dtype(arr_or_dtype)",
        "begin_line": 393,
        "end_line": 427,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_timedelta64_dtype#430",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_timedelta64_dtype(arr_or_dtype)",
        "snippet": "def is_timedelta64_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether an array-like or dtype is of the timedelta64 dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like or dtype is of the timedelta64 dtype.\n\n    Examples\n    --------\n    >>> is_timedelta64_dtype(object)\n    False\n    >>> is_timedelta64_dtype(np.timedelta64)\n    True\n    >>> is_timedelta64_dtype([1, 2, 3])\n    False\n    >>> is_timedelta64_dtype(pd.Series([], dtype=\"timedelta64[ns]\"))\n    True\n    >>> is_timedelta64_dtype('0 days')\n    False\n    \"\"\"\n    return _is_dtype_type(arr_or_dtype, classes(np.timedelta64))",
        "begin_line": 430,
        "end_line": 457,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_period_dtype#460",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_period_dtype(arr_or_dtype)",
        "snippet": "def is_period_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether an array-like or dtype is of the Period dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like or dtype is of the Period dtype.\n\n    Examples\n    --------\n    >>> is_period_dtype(object)\n    False\n    >>> is_period_dtype(PeriodDtype(freq=\"D\"))\n    True\n    >>> is_period_dtype([1, 2, 3])\n    False\n    >>> is_period_dtype(pd.Period(\"2017-01-01\"))\n    False\n    >>> is_period_dtype(pd.PeriodIndex([], freq=\"A\"))\n    True\n    \"\"\"\n    # TODO: Consider making Period an instance of PeriodDtype\n    if arr_or_dtype is None:\n        return False\n    return PeriodDtype.is_dtype(arr_or_dtype)",
        "begin_line": 460,
        "end_line": 490,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_interval_dtype#493",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_interval_dtype(arr_or_dtype)",
        "snippet": "def is_interval_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether an array-like or dtype is of the Interval dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like or dtype is of the Interval dtype.\n\n    Examples\n    --------\n    >>> is_interval_dtype(object)\n    False\n    >>> is_interval_dtype(IntervalDtype())\n    True\n    >>> is_interval_dtype([1, 2, 3])\n    False\n    >>>\n    >>> interval = pd.Interval(1, 2, closed=\"right\")\n    >>> is_interval_dtype(interval)\n    False\n    >>> is_interval_dtype(pd.IntervalIndex([interval]))\n    True\n    \"\"\"\n    # TODO: Consider making Interval an instance of IntervalDtype\n    if arr_or_dtype is None:\n        return False\n    return IntervalDtype.is_dtype(arr_or_dtype)",
        "begin_line": 493,
        "end_line": 525,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_categorical_dtype#528",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_categorical_dtype(arr_or_dtype)",
        "snippet": "def is_categorical_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether an array-like or dtype is of the Categorical dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like or dtype is of the Categorical dtype.\n\n    Examples\n    --------\n    >>> is_categorical_dtype(object)\n    False\n    >>> is_categorical_dtype(CategoricalDtype())\n    True\n    >>> is_categorical_dtype([1, 2, 3])\n    False\n    >>> is_categorical_dtype(pd.Categorical([1, 2, 3]))\n    True\n    >>> is_categorical_dtype(pd.CategoricalIndex([1, 2, 3]))\n    True\n    \"\"\"\n    if arr_or_dtype is None:\n        return False\n    return CategoricalDtype.is_dtype(arr_or_dtype)",
        "begin_line": 528,
        "end_line": 557,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_string_dtype#560",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_string_dtype(arr_or_dtype)",
        "snippet": "def is_string_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether the provided array or dtype is of the string dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of the string dtype.\n\n    Examples\n    --------\n    >>> is_string_dtype(str)\n    True\n    >>> is_string_dtype(object)\n    True\n    >>> is_string_dtype(int)\n    False\n    >>>\n    >>> is_string_dtype(np.array(['a', 'b']))\n    True\n    >>> is_string_dtype(pd.Series([1, 2]))\n    False\n    \"\"\"\n    # TODO: gh-15585: consider making the checks stricter.\n    def condition(dtype) -> bool:\n        return dtype.kind in (\"O\", \"S\", \"U\") and not is_excluded_dtype(dtype)\n\n    def is_excluded_dtype(dtype) -> bool:\n        \"\"\"\n        These have kind = \"O\" but aren't string dtypes so need to be explicitly excluded\n        \"\"\"\n        is_excluded_checks = (is_period_dtype, is_interval_dtype)\n        return any(is_excluded(dtype) for is_excluded in is_excluded_checks)\n\n    return _is_dtype(arr_or_dtype, condition)",
        "begin_line": 560,
        "end_line": 599,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.common.condition#589",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.condition(dtype)",
        "snippet": "    def condition(dtype) -> bool:\n        return dtype.kind in (\"O\", \"S\", \"U\") and not is_excluded_dtype(dtype)",
        "begin_line": 589,
        "end_line": 590,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.16666666666666666,
            "pseudo_dstar_susp": 0.16666666666666666,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.16666666666666666,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_excluded_dtype#592",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_excluded_dtype(dtype)",
        "snippet": "    def is_excluded_dtype(dtype) -> bool:\n        \"\"\"\n        These have kind = \"O\" but aren't string dtypes so need to be explicitly excluded\n        \"\"\"\n        is_excluded_checks = (is_period_dtype, is_interval_dtype)\n        return any(is_excluded(dtype) for is_excluded in is_excluded_checks)",
        "begin_line": 592,
        "end_line": 597,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.16666666666666666,
            "pseudo_dstar_susp": 0.16666666666666666,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.16666666666666666,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_integer_dtype#690",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_integer_dtype(arr_or_dtype)",
        "snippet": "def is_integer_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether the provided array or dtype is of an integer dtype.\n\n    Unlike in `in_any_int_dtype`, timedelta64 instances will return False.\n\n    .. versionchanged:: 0.24.0\n\n       The nullable Integer dtypes (e.g. pandas.Int64Dtype) are also considered\n       as integer by this function.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of an integer dtype and\n        not an instance of timedelta64.\n\n    Examples\n    --------\n    >>> is_integer_dtype(str)\n    False\n    >>> is_integer_dtype(int)\n    True\n    >>> is_integer_dtype(float)\n    False\n    >>> is_integer_dtype(np.uint64)\n    True\n    >>> is_integer_dtype('int8')\n    True\n    >>> is_integer_dtype('Int8')\n    True\n    >>> is_integer_dtype(pd.Int8Dtype)\n    True\n    >>> is_integer_dtype(np.datetime64)\n    False\n    >>> is_integer_dtype(np.timedelta64)\n    False\n    >>> is_integer_dtype(np.array(['a', 'b']))\n    False\n    >>> is_integer_dtype(pd.Series([1, 2]))\n    True\n    >>> is_integer_dtype(np.array([], dtype=np.timedelta64))\n    False\n    >>> is_integer_dtype(pd.Index([1, 2.]))  # float\n    False\n    \"\"\"\n    return _is_dtype_type(arr_or_dtype, classes_and_not_datetimelike(np.integer))",
        "begin_line": 690,
        "end_line": 741,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_string_like_dtype#1272",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_string_like_dtype(arr_or_dtype)",
        "snippet": "def is_string_like_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check whether the provided array or dtype is of a string-like dtype.\n\n    Unlike `is_string_dtype`, the object dtype is excluded because it\n    is a mixed dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of the string dtype.\n\n    Examples\n    --------\n    >>> is_string_like_dtype(str)\n    True\n    >>> is_string_like_dtype(object)\n    False\n    >>> is_string_like_dtype(np.array(['a', 'b']))\n    True\n    >>> is_string_like_dtype(pd.Series([1, 2]))\n    False\n    \"\"\"\n    return _is_dtype(arr_or_dtype, lambda dtype: dtype.kind in (\"S\", \"U\"))",
        "begin_line": 1272,
        "end_line": 1300,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.16666666666666666,
            "pseudo_dstar_susp": 0.16666666666666666,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.16666666666666666,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.common.is_extension_array_dtype#1467",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.is_extension_array_dtype(arr_or_dtype)",
        "snippet": "def is_extension_array_dtype(arr_or_dtype) -> bool:\n    \"\"\"\n    Check if an object is a pandas extension array type.\n\n    See the :ref:`Use Guide <extending.extension-types>` for more.\n\n    Parameters\n    ----------\n    arr_or_dtype : object\n        For array-like input, the ``.dtype`` attribute will\n        be extracted.\n\n    Returns\n    -------\n    bool\n        Whether the `arr_or_dtype` is an extension array type.\n\n    Notes\n    -----\n    This checks whether an object implements the pandas extension\n    array interface. In pandas, this includes:\n\n    * Categorical\n    * Sparse\n    * Interval\n    * Period\n    * DatetimeArray\n    * TimedeltaArray\n\n    Third-party libraries may implement arrays or types satisfying\n    this interface as well.\n\n    Examples\n    --------\n    >>> from pandas.api.types import is_extension_array_dtype\n    >>> arr = pd.Categorical(['a', 'b'])\n    >>> is_extension_array_dtype(arr)\n    True\n    >>> is_extension_array_dtype(arr.dtype)\n    True\n\n    >>> arr = np.array(['a', 'b'])\n    >>> is_extension_array_dtype(arr.dtype)\n    False\n    \"\"\"\n    dtype = getattr(arr_or_dtype, \"dtype\", arr_or_dtype)\n    return isinstance(dtype, ExtensionDtype) or registry.find(dtype) is not None",
        "begin_line": 1467,
        "end_line": 1513,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.common._is_dtype#1548",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common._is_dtype(arr_or_dtype, condition)",
        "snippet": "def _is_dtype(arr_or_dtype, condition) -> bool:\n    \"\"\"\n    Return a boolean if the condition is satisfied for the arr_or_dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like, str, np.dtype, or ExtensionArrayType\n        The array-like or dtype object whose dtype we want to extract.\n    condition : callable[Union[np.dtype, ExtensionDtype]]\n\n    Returns\n    -------\n    bool\n\n    \"\"\"\n    if arr_or_dtype is None:\n        return False\n    try:\n        dtype = _get_dtype(arr_or_dtype)\n    except (TypeError, ValueError, UnicodeEncodeError):\n        return False\n    return condition(dtype)",
        "begin_line": 1548,
        "end_line": 1569,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.common._get_dtype#1572",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common._get_dtype(arr_or_dtype)",
        "snippet": "def _get_dtype(arr_or_dtype) -> DtypeObj:\n    \"\"\"\n    Get the dtype instance associated with an array\n    or dtype object.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype object whose dtype we want to extract.\n\n    Returns\n    -------\n    obj_dtype : The extract dtype instance from the\n                passed in array or dtype object.\n\n    Raises\n    ------\n    TypeError : The passed in object is None.\n    \"\"\"\n    if arr_or_dtype is None:\n        raise TypeError(\"Cannot deduce dtype from null object\")\n\n    # fastpath\n    elif isinstance(arr_or_dtype, np.dtype):\n        return arr_or_dtype\n    elif isinstance(arr_or_dtype, type):\n        return np.dtype(arr_or_dtype)\n\n    # if we have an array-like\n    elif hasattr(arr_or_dtype, \"dtype\"):\n        arr_or_dtype = arr_or_dtype.dtype\n\n    return pandas_dtype(arr_or_dtype)",
        "begin_line": 1572,
        "end_line": 1604,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.common._is_dtype_type#1607",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common._is_dtype_type(arr_or_dtype, condition)",
        "snippet": "def _is_dtype_type(arr_or_dtype, condition) -> bool:\n    \"\"\"\n    Return a boolean if the condition is satisfied for the arr_or_dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array-like or dtype object whose dtype we want to extract.\n    condition : callable[Union[np.dtype, ExtensionDtypeType]]\n\n    Returns\n    -------\n    bool : if the condition is satisfied for the arr_or_dtype\n    \"\"\"\n    if arr_or_dtype is None:\n        return condition(type(None))\n\n    # fastpath\n    if isinstance(arr_or_dtype, np.dtype):\n        return condition(arr_or_dtype.type)\n    elif isinstance(arr_or_dtype, type):\n        if issubclass(arr_or_dtype, ExtensionDtype):\n            arr_or_dtype = arr_or_dtype.type\n        return condition(np.dtype(arr_or_dtype).type)\n\n    # if we have an array-like\n    if hasattr(arr_or_dtype, \"dtype\"):\n        arr_or_dtype = arr_or_dtype.dtype\n\n    # we are not possibly a dtype\n    elif is_list_like(arr_or_dtype):\n        return condition(type(None))\n\n    try:\n        tipo = pandas_dtype(arr_or_dtype).type\n    except (TypeError, ValueError, UnicodeEncodeError):\n        if is_scalar(arr_or_dtype):\n            return condition(type(None))\n\n        return False\n\n    return condition(tipo)",
        "begin_line": 1607,
        "end_line": 1648,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.common.pandas_dtype#1740",
        "src_path": "pandas/core/dtypes/common.py",
        "class_name": "pandas.core.dtypes.common",
        "signature": "pandas.core.dtypes.common.pandas_dtype(dtype)",
        "snippet": "def pandas_dtype(dtype) -> DtypeObj:\n    \"\"\"\n    Convert input into a pandas only dtype object or a numpy dtype object.\n\n    Parameters\n    ----------\n    dtype : object to be converted\n\n    Returns\n    -------\n    np.dtype or a pandas dtype\n\n    Raises\n    ------\n    TypeError if not a dtype\n    \"\"\"\n    # short-circuit\n    if isinstance(dtype, np.ndarray):\n        return dtype.dtype\n    elif isinstance(dtype, (np.dtype, ExtensionDtype)):\n        return dtype\n\n    # registered extension types\n    result = registry.find(dtype)\n    if result is not None:\n        return result\n\n    # try a numpy dtype\n    # raise a consistent TypeError if failed\n    try:\n        npdtype = np.dtype(dtype)\n    except SyntaxError as err:\n        # np.dtype uses `eval` which can raise SyntaxError\n        raise TypeError(f\"data type '{dtype}' not understood\") from err\n\n    # Any invalid dtype (such as pd.Timestamp) should raise an error.\n    # np.dtype(invalid_type).kind = 0 for such objects. However, this will\n    # also catch some valid dtypes such as object, np.object_ and 'object'\n    # which we safeguard against by catching them earlier and returning\n    # np.dtype(valid_dtype) before this condition is evaluated.\n    if is_hashable(dtype) and dtype in [object, np.object_, \"object\", \"O\"]:\n        # check hashability to avoid errors/DeprecationWarning when we get\n        # here and `dtype` is an array\n        return npdtype\n    elif npdtype.kind == \"O\":\n        raise TypeError(f\"dtype '{dtype}' not understood\")\n\n    return npdtype",
        "begin_line": 1740,
        "end_line": 1787,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.construction.extract_array#338",
        "src_path": "pandas/core/construction.py",
        "class_name": "pandas.core.construction",
        "signature": "pandas.core.construction.extract_array(obj, extract_numpy: bool=False)",
        "snippet": "def extract_array(obj, extract_numpy: bool = False):\n    \"\"\"\n    Extract the ndarray or ExtensionArray from a Series or Index.\n\n    For all other types, `obj` is just returned as is.\n\n    Parameters\n    ----------\n    obj : object\n        For Series / Index, the underlying ExtensionArray is unboxed.\n        For Numpy-backed ExtensionArrays, the ndarray is extracted.\n\n    extract_numpy : bool, default False\n        Whether to extract the ndarray from a PandasArray\n\n    Returns\n    -------\n    arr : object\n\n    Examples\n    --------\n    >>> extract_array(pd.Series(['a', 'b', 'c'], dtype='category'))\n    [a, b, c]\n    Categories (3, object): [a, b, c]\n\n    Other objects like lists, arrays, and DataFrames are just passed through.\n\n    >>> extract_array([1, 2, 3])\n    [1, 2, 3]\n\n    For an ndarray-backed Series / Index a PandasArray is returned.\n\n    >>> extract_array(pd.Series([1, 2, 3]))\n    <PandasArray>\n    [1, 2, 3]\n    Length: 3, dtype: int64\n\n    To extract all the way down to the ndarray, pass ``extract_numpy=True``.\n\n    >>> extract_array(pd.Series([1, 2, 3]), extract_numpy=True)\n    array([1, 2, 3])\n    \"\"\"\n    if isinstance(obj, (ABCIndexClass, ABCSeries)):\n        obj = obj.array\n\n    if extract_numpy and isinstance(obj, ABCPandasArray):\n        obj = obj.to_numpy()\n\n    return obj",
        "begin_line": 338,
        "end_line": 386,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.construction.sanitize_array#389",
        "src_path": "pandas/core/construction.py",
        "class_name": "pandas.core.construction",
        "signature": "pandas.core.construction.sanitize_array(data, index, dtype=None, copy: bool=False, raise_cast_failure: bool=False)",
        "snippet": "def sanitize_array(\n    data, index, dtype=None, copy: bool = False, raise_cast_failure: bool = False\n):\n    \"\"\"\n    Sanitize input data to an ndarray, copy if specified, coerce to the\n    dtype if specified.\n    \"\"\"\n    if dtype is not None:\n        dtype = pandas_dtype(dtype)\n\n    if isinstance(data, ma.MaskedArray):\n        mask = ma.getmaskarray(data)\n        if mask.any():\n            data, fill_value = maybe_upcast(data, copy=True)\n            data.soften_mask()  # set hardmask False if it was True\n            data[mask] = fill_value\n        else:\n            data = data.copy()\n\n    # extract ndarray or ExtensionArray, ensure we have no PandasArray\n    data = extract_array(data, extract_numpy=True)\n\n    # GH#846\n    if isinstance(data, np.ndarray):\n\n        if dtype is not None and is_float_dtype(data.dtype) and is_integer_dtype(dtype):\n            # possibility of nan -> garbage\n            try:\n                subarr = _try_cast(data, dtype, copy, True)\n            except ValueError:\n                if copy:\n                    subarr = data.copy()\n                else:\n                    subarr = np.array(data, copy=False)\n        else:\n            # we will try to copy be-definition here\n            subarr = _try_cast(data, dtype, copy, raise_cast_failure)\n\n    elif isinstance(data, ABCExtensionArray):\n        # it is already ensured above this is not a PandasArray\n        subarr = data\n\n        if dtype is not None:\n            subarr = subarr.astype(dtype, copy=copy)\n        elif copy:\n            subarr = subarr.copy()\n        return subarr\n\n    elif isinstance(data, (list, tuple)) and len(data) > 0:\n        if dtype is not None:\n            subarr = _try_cast(data, dtype, copy, raise_cast_failure)\n        else:\n            subarr = maybe_convert_platform(data)\n\n        subarr = maybe_cast_to_datetime(subarr, dtype)\n\n    elif isinstance(data, range):\n        # GH#16804\n        arr = np.arange(data.start, data.stop, data.step, dtype=\"int64\")\n        subarr = _try_cast(arr, dtype, copy, raise_cast_failure)\n    else:\n        subarr = _try_cast(data, dtype, copy, raise_cast_failure)\n\n    # scalar like, GH\n    if getattr(subarr, \"ndim\", 0) == 0:\n        if isinstance(data, list):  # pragma: no cover\n            subarr = np.array(data, dtype=object)\n        elif index is not None:\n            value = data\n\n            # figure out the dtype from the value (upcast if necessary)\n            if dtype is None:\n                dtype, value = infer_dtype_from_scalar(value)\n            else:\n                # need to possibly convert the value here\n                value = maybe_cast_to_datetime(value, dtype)\n\n            subarr = construct_1d_arraylike_from_scalar(value, len(index), dtype)\n\n        else:\n            return subarr.item()\n\n    # the result that we want\n    elif subarr.ndim == 1:\n        if index is not None:\n\n            # a 1-element ndarray\n            if len(subarr) != len(index) and len(subarr) == 1:\n                subarr = construct_1d_arraylike_from_scalar(\n                    subarr[0], len(index), subarr.dtype\n                )\n\n    elif subarr.ndim > 1:\n        if isinstance(data, np.ndarray):\n            raise Exception(\"Data must be 1-dimensional\")\n        else:\n            subarr = com.asarray_tuplesafe(data, dtype=dtype)\n\n    if not (is_extension_array_dtype(subarr.dtype) or is_extension_array_dtype(dtype)):\n        # This is to prevent mixed-type Series getting all casted to\n        # NumPy string type, e.g. NaN --> '-1#IND'.\n        if issubclass(subarr.dtype.type, str):\n            # GH#16605\n            # If not empty convert the data to dtype\n            # GH#19853: If data is a scalar, subarr has already the result\n            if not lib.is_scalar(data):\n                if not np.all(isna(data)):\n                    data = np.array(data, dtype=dtype, copy=False)\n                subarr = np.array(data, dtype=object, copy=copy)\n\n        if is_object_dtype(subarr.dtype) and not is_object_dtype(dtype):\n            inferred = lib.infer_dtype(subarr, skipna=False)\n            if inferred in {\"interval\", \"period\"}:\n                subarr = array(subarr)\n\n    return subarr",
        "begin_line": 389,
        "end_line": 504,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.construction._try_cast#507",
        "src_path": "pandas/core/construction.py",
        "class_name": "pandas.core.construction",
        "signature": "pandas.core.construction._try_cast(arr, dtype: Optional[Union[np.dtype, 'ExtensionDtype']], copy: bool, raise_cast_failure: bool)",
        "snippet": "def _try_cast(\n    arr,\n    dtype: Optional[Union[np.dtype, \"ExtensionDtype\"]],\n    copy: bool,\n    raise_cast_failure: bool,\n):\n    \"\"\"\n    Convert input to numpy ndarray and optionally cast to a given dtype.\n\n    Parameters\n    ----------\n    arr : ndarray, list, tuple, iterator (catchall)\n        Excludes: ExtensionArray, Series, Index.\n    dtype : np.dtype, ExtensionDtype or None\n    copy : bool\n        If False, don't copy the data if not needed.\n    raise_cast_failure : bool\n        If True, and if a dtype is specified, raise errors during casting.\n        Otherwise an object array is returned.\n    \"\"\"\n    # perf shortcut as this is the most common case\n    if isinstance(arr, np.ndarray):\n        if maybe_castable(arr) and not copy and dtype is None:\n            return arr\n\n    try:\n        # GH#15832: Check if we are requesting a numeric dype and\n        # that we can convert the data to the requested dtype.\n        if is_integer_dtype(dtype):\n            subarr = maybe_cast_to_integer_array(arr, dtype)\n\n        subarr = maybe_cast_to_datetime(arr, dtype)\n        # Take care in creating object arrays (but iterators are not\n        # supported):\n        if is_object_dtype(dtype) and (\n            is_list_like(subarr)\n            and not (is_iterator(subarr) or isinstance(subarr, np.ndarray))\n        ):\n            subarr = construct_1d_object_array_from_listlike(subarr)\n        elif not is_extension_array_dtype(subarr):\n            subarr = construct_1d_ndarray_preserving_na(subarr, dtype, copy=copy)\n    except OutOfBoundsDatetime:\n        # in case of out of bound datetime64 -> always raise\n        raise\n    except (ValueError, TypeError):\n        if is_categorical_dtype(dtype):\n            # We *do* allow casting to categorical, since we know\n            # that Categorical is the only array type for 'category'.\n            dtype = cast(CategoricalDtype, dtype)\n            subarr = dtype.construct_array_type()(\n                arr, dtype.categories, ordered=dtype.ordered\n            )\n        elif is_extension_array_dtype(dtype):\n            # create an extension array from its dtype\n            dtype = cast(ExtensionDtype, dtype)\n            array_type = dtype.construct_array_type()._from_sequence\n            subarr = array_type(arr, dtype=dtype, copy=copy)\n        elif dtype is not None and raise_cast_failure:\n            raise\n        else:\n            subarr = np.array(arr, dtype=object, copy=copy)\n    return subarr",
        "begin_line": 507,
        "end_line": 568,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.construction.is_empty_data#571",
        "src_path": "pandas/core/construction.py",
        "class_name": "pandas.core.construction",
        "signature": "pandas.core.construction.is_empty_data(data: Any)",
        "snippet": "def is_empty_data(data: Any) -> bool:\n    \"\"\"\n    Utility to check if a Series is instantiated with empty data,\n    which does not contain dtype information.\n\n    Parameters\n    ----------\n    data : array-like, Iterable, dict, or scalar value\n        Contains data stored in Series.\n\n    Returns\n    -------\n    bool\n    \"\"\"\n    is_none = data is None\n    is_list_like_without_dtype = is_list_like(data) and not hasattr(data, \"dtype\")\n    is_simple_empty = is_list_like_without_dtype and not data\n    return is_none or is_simple_empty",
        "begin_line": 571,
        "end_line": 588,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.strings.str_repeat#726",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.str_repeat(arr, repeats)",
        "snippet": "def str_repeat(arr, repeats):\n    \"\"\"\n    Duplicate each string in the Series or Index.\n\n    Parameters\n    ----------\n    repeats : int or sequence of int\n        Same value for all (int) or different value per (sequence).\n\n    Returns\n    -------\n    Series or Index of object\n        Series or Index of repeated string objects specified by\n        input parameter repeats.\n\n    Examples\n    --------\n    >>> s = pd.Series(['a', 'b', 'c'])\n    >>> s\n    0    a\n    1    b\n    2    c\n    dtype: object\n\n    Single int repeats string in Series\n\n    >>> s.str.repeat(repeats=2)\n    0    aa\n    1    bb\n    2    cc\n    dtype: object\n\n    Sequence of int repeats corresponding string in Series\n\n    >>> s.str.repeat(repeats=[1, 2, 3])\n    0      a\n    1     bb\n    2    ccc\n    dtype: object\n    \"\"\"\n    if is_scalar(repeats):\n\n        def scalar_rep(x):\n            try:\n                return bytes.__mul__(x, repeats)\n            except TypeError:\n                return str.__mul__(x, repeats)\n\n        return _na_map(scalar_rep, arr, dtype=str)\n    else:\n\n        def rep(x, r):\n            try:\n                return bytes.__mul__(x, r)\n            except TypeError:\n                return str.__mul__(x, r)\n\n        repeats = np.asarray(repeats, dtype=object)\n        result = libops.vec_binop(np.asarray(arr), repeats, rep)\n        return result",
        "begin_line": 726,
        "end_line": 785,
        "comment": "",
        "is_bug": true,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.strings.rep#777",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.rep(x, r)",
        "snippet": "        def rep(x, r):\n            try:\n                return bytes.__mul__(x, r)\n            except TypeError:\n                return str.__mul__(x, r)",
        "begin_line": 777,
        "end_line": 781,
        "comment": "",
        "is_bug": true,
        "susp": {
            "pseudo_ochiai_susp": 0.16666666666666666,
            "pseudo_dstar_susp": 0.16666666666666666,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.16666666666666666,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.strings._forbid_nonstring_types#1933",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings._forbid_nonstring_types(func)",
        "snippet": "    def _forbid_nonstring_types(func):\n        func_name = func.__name__ if name is None else name\n\n        @wraps(func)\n        def wrapper(self, *args, **kwargs):\n            if self._inferred_dtype not in allowed_types:\n                msg = (\n                    f\"Cannot use .str.{func_name} with values of \"\n                    f\"inferred dtype '{self._inferred_dtype}'.\"\n                )\n                raise TypeError(msg)\n            return func(self, *args, **kwargs)\n\n        wrapper.__name__ = func_name\n        return wrapper",
        "begin_line": 1933,
        "end_line": 1947,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.strings.wrapper#1937",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings",
        "signature": "pandas.core.strings.wrapper(self, *args, **kwargs)",
        "snippet": "        def wrapper(self, *args, **kwargs):\n            if self._inferred_dtype not in allowed_types:\n                msg = (\n                    f\"Cannot use .str.{func_name} with values of \"\n                    f\"inferred dtype '{self._inferred_dtype}'.\"\n                )\n                raise TypeError(msg)\n            return func(self, *args, **kwargs)",
        "begin_line": 1937,
        "end_line": 1944,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.strings.StringMethods.__init__#2030",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods.__init__(self, data)",
        "snippet": "    def __init__(self, data):\n        self._inferred_dtype = self._validate(data)\n        self._is_categorical = is_categorical_dtype(data)\n        self._is_string = data.dtype.name == \"string\"\n\n        # .values.categories works for both Series/Index\n        self._parent = data.values.categories if self._is_categorical else data\n        # save orig to blow up categoricals to the right type\n        self._orig = data\n        self._freeze()",
        "begin_line": 2030,
        "end_line": 2039,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.strings.StringMethods._validate#2042",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods._validate(data)",
        "snippet": "    def _validate(data):\n        \"\"\"\n        Auxiliary function for StringMethods, infers and checks dtype of data.\n\n        This is a \"first line of defence\" at the creation of the StringMethods-\n        object (see _make_accessor), and just checks that the dtype is in the\n        *union* of the allowed types over all string methods below; this\n        restriction is then refined on a per-method basis using the decorator\n        @forbid_nonstring_types (more info in the corresponding docstring).\n\n        This really should exclude all series/index with any non-string values,\n        but that isn't practical for performance reasons until we have a str\n        dtype (GH 9343 / 13877)\n\n        Parameters\n        ----------\n        data : The content of the Series\n\n        Returns\n        -------\n        dtype : inferred dtype of data\n        \"\"\"\n        from pandas import StringDtype\n\n        if isinstance(data, ABCMultiIndex):\n            raise AttributeError(\n                \"Can only use .str accessor with Index, not MultiIndex\"\n            )\n\n        # see _libs/lib.pyx for list of inferred types\n        allowed_types = [\"string\", \"empty\", \"bytes\", \"mixed\", \"mixed-integer\"]\n\n        values = getattr(data, \"values\", data)  # Series / Index\n        values = getattr(values, \"categories\", values)  # categorical / normal\n\n        # explicitly allow StringDtype\n        if isinstance(values.dtype, StringDtype):\n            return \"string\"\n\n        try:\n            inferred_dtype = lib.infer_dtype(values, skipna=True)\n        except ValueError:\n            # GH#27571 mostly occurs with ExtensionArray\n            inferred_dtype = None\n\n        if inferred_dtype not in allowed_types:\n            raise AttributeError(\"Can only use .str accessor with string values!\")\n        return inferred_dtype",
        "begin_line": 2042,
        "end_line": 2089,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.strings.StringMethods.repeat#2773",
        "src_path": "pandas/core/strings.py",
        "class_name": "pandas.core.strings.StringMethods",
        "signature": "pandas.core.strings.StringMethods.repeat(self, repeats)",
        "snippet": "    def repeat(self, repeats):\n        result = str_repeat(self._parent, repeats)\n        return self._wrap_result(result)",
        "begin_line": 2773,
        "end_line": 2775,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager.__init__#1496",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager.__init__(self, block: Block, axis: Union[Index, List[Index]], do_integrity_check: bool=False, fastpath: bool=False)",
        "snippet": "    def __init__(\n        self,\n        block: Block,\n        axis: Union[Index, List[Index]],\n        do_integrity_check: bool = False,\n        fastpath: bool = False,\n    ):\n        if isinstance(axis, list):\n            if len(axis) != 1:\n                raise ValueError(\n                    \"cannot create SingleBlockManager with more than 1 axis\"\n                )\n            axis = axis[0]\n\n        # passed from constructor, single block, single axis\n        if fastpath:\n            self.axes = [axis]\n            if isinstance(block, list):\n\n                # empty block\n                if len(block) == 0:\n                    block = [np.array([])]\n                elif len(block) != 1:\n                    raise ValueError(\n                        \"Cannot create SingleBlockManager with more than 1 block\"\n                    )\n                block = block[0]\n        else:\n            self.axes = [ensure_index(axis)]\n\n            # create the block here\n            if isinstance(block, list):\n\n                # provide consolidation to the interleaved_dtype\n                if len(block) > 1:\n                    dtype = _interleaved_dtype(block)\n                    block = [b.astype(dtype) for b in block]\n                    block = _consolidate(block)\n\n                if len(block) != 1:\n                    raise ValueError(\n                        \"Cannot create SingleBlockManager with more than 1 block\"\n                    )\n                block = block[0]\n\n        if not isinstance(block, Block):\n            block = make_block(block, placement=slice(0, len(axis)), ndim=1)\n\n        self.blocks = tuple([block])",
        "begin_line": 1496,
        "end_line": 1544,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager._block#1550",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager._block(self)",
        "snippet": "    def _block(self) -> Block:\n        return self.blocks[0]",
        "begin_line": 1550,
        "end_line": 1551,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager.dtype#1578",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager.dtype(self)",
        "snippet": "    def dtype(self) -> DtypeObj:\n        return self._block.dtype",
        "begin_line": 1578,
        "end_line": 1579,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.internals.managers.SingleBlockManager.external_values#1591",
        "src_path": "pandas/core/internals/managers.py",
        "class_name": "pandas.core.internals.managers.SingleBlockManager",
        "signature": "pandas.core.internals.managers.SingleBlockManager.external_values(self)",
        "snippet": "    def external_values(self):\n        \"\"\"The array that Series.values returns\"\"\"\n        return self._block.external_values()",
        "begin_line": 1591,
        "end_line": 1593,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.arrays.numpy_.PandasDtype.__init__#47",
        "src_path": "pandas/core/arrays/numpy_.py",
        "class_name": "pandas.core.arrays.numpy_.PandasDtype",
        "signature": "pandas.core.arrays.numpy_.PandasDtype.__init__(self, dtype: object)",
        "snippet": "    def __init__(self, dtype: object):\n        self._dtype = np.dtype(dtype)",
        "begin_line": 47,
        "end_line": 48,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.arrays.numpy_.PandasArray.__init__#157",
        "src_path": "pandas/core/arrays/numpy_.py",
        "class_name": "pandas.core.arrays.numpy_.PandasArray",
        "signature": "pandas.core.arrays.numpy_.PandasArray.__init__(self, values: Union[np.ndarray, 'PandasArray'], copy: bool=False)",
        "snippet": "    def __init__(self, values: Union[np.ndarray, \"PandasArray\"], copy: bool = False):\n        if isinstance(values, type(self)):\n            values = values._ndarray\n        if not isinstance(values, np.ndarray):\n            raise ValueError(\n                f\"'values' must be a NumPy array, not {type(values).__name__}\"\n            )\n\n        if values.ndim != 1:\n            raise ValueError(\"PandasArray must be 1-dimensional.\")\n\n        if copy:\n            values = values.copy()\n\n        self._ndarray = values\n        self._dtype = PandasDtype(values.dtype)",
        "begin_line": 157,
        "end_line": 172,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.arrays.numpy_.PandasArray.dtype#196",
        "src_path": "pandas/core/arrays/numpy_.py",
        "class_name": "pandas.core.arrays.numpy_.PandasArray",
        "signature": "pandas.core.arrays.numpy_.PandasArray.dtype(self)",
        "snippet": "    def dtype(self) -> PandasDtype:\n        return self._dtype",
        "begin_line": 196,
        "end_line": 197,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.arrays.numpy_.PandasArray.__array__#202",
        "src_path": "pandas/core/arrays/numpy_.py",
        "class_name": "pandas.core.arrays.numpy_.PandasArray",
        "signature": "pandas.core.arrays.numpy_.PandasArray.__array__(self, dtype=None)",
        "snippet": "    def __array__(self, dtype=None) -> np.ndarray:\n        return np.asarray(self._ndarray, dtype=dtype)",
        "begin_line": 202,
        "end_line": 203,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.arrays.numpy_.PandasArray.__len__#273",
        "src_path": "pandas/core/arrays/numpy_.py",
        "class_name": "pandas.core.arrays.numpy_.PandasArray",
        "signature": "pandas.core.arrays.numpy_.PandasArray.__len__(self)",
        "snippet": "    def __len__(self) -> int:\n        return len(self._ndarray)",
        "begin_line": 273,
        "end_line": 274,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.base.NoNewAttributesMixin._freeze#112",
        "src_path": "pandas/core/base.py",
        "class_name": "pandas.core.base.NoNewAttributesMixin",
        "signature": "pandas.core.base.NoNewAttributesMixin._freeze(self)",
        "snippet": "    def _freeze(self):\n        \"\"\"\n        Prevents setting additional attributes.\n        \"\"\"\n        object.__setattr__(self, \"__frozen\", True)",
        "begin_line": 112,
        "end_line": 116,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.base.NoNewAttributesMixin.__setattr__#119",
        "src_path": "pandas/core/base.py",
        "class_name": "pandas.core.base.NoNewAttributesMixin",
        "signature": "pandas.core.base.NoNewAttributesMixin.__setattr__(self, key: str, value)",
        "snippet": "    def __setattr__(self, key: str, value):\n        # _cache is used by a decorator\n        # We need to check both 1.) cls.__dict__ and 2.) getattr(self, key)\n        # because\n        # 1.) getattr is false for attributes that raise errors\n        # 2.) cls.__dict__ doesn't traverse into base classes\n        if getattr(self, \"__frozen\", False) and not (\n            key == \"_cache\"\n            or key in type(self).__dict__\n            or getattr(self, key, None) is not None\n        ):\n            raise AttributeError(f\"You cannot add any new attribute '{key}'\")\n        object.__setattr__(self, key, value)",
        "begin_line": 119,
        "end_line": 131,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.common.all_none#177",
        "src_path": "pandas/core/common.py",
        "class_name": "pandas.core.common",
        "signature": "pandas.core.common.all_none(*args)",
        "snippet": "def all_none(*args) -> bool:\n    \"\"\"\n    Returns a boolean indicating if all arguments are None.\n    \"\"\"\n    return all(arg is None for arg in args)",
        "begin_line": 177,
        "end_line": 181,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.16666666666666666,
            "pseudo_dstar_susp": 0.16666666666666666,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.16666666666666666,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.common.maybe_iterable_to_list#269",
        "src_path": "pandas/core/common.py",
        "class_name": "pandas.core.common",
        "signature": "pandas.core.common.maybe_iterable_to_list(obj: Union[Iterable[T], T])",
        "snippet": "def maybe_iterable_to_list(obj: Union[Iterable[T], T]) -> Union[Collection[T], T]:\n    \"\"\"\n    If obj is Iterable but not list-like, consume into list.\n    \"\"\"\n    if isinstance(obj, abc.Iterable) and not isinstance(obj, abc.Sized):\n        return list(obj)\n    return obj",
        "begin_line": 269,
        "end_line": 275,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.accessor.CachedAccessor.__get__#183",
        "src_path": "pandas/core/accessor.py",
        "class_name": "pandas.core.accessor.CachedAccessor",
        "signature": "pandas.core.accessor.CachedAccessor.__get__(self, obj, cls)",
        "snippet": "    def __get__(self, obj, cls):\n        if obj is None:\n            # we're accessing the attribute of the class, i.e., Dataset.geo\n            return self._accessor\n        accessor_obj = self._accessor(obj)\n        # Replace the property with the accessor object. Inspired by:\n        # https://www.pydanny.com/cached-property.html\n        # We need to use object.__setattr__ because we overwrite __setattr__ on\n        # NDFrame\n        object.__setattr__(obj, self._name, accessor_obj)\n        return accessor_obj",
        "begin_line": 183,
        "end_line": 193,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.series.Series.__init__#199",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.__init__(self, data=None, index=None, dtype=None, name=None, copy=False, fastpath=False)",
        "snippet": "    def __init__(\n        self, data=None, index=None, dtype=None, name=None, copy=False, fastpath=False\n    ):\n\n        # we are called internally, so short-circuit\n        if fastpath:\n\n            # data is an ndarray, index is defined\n            if not isinstance(data, SingleBlockManager):\n                data = SingleBlockManager(data, index, fastpath=True)\n            if copy:\n                data = data.copy()\n            if index is None:\n                index = data.index\n\n        else:\n\n            name = ibase.maybe_extract_name(name, data, type(self))\n\n            if is_empty_data(data) and dtype is None:\n                # gh-17261\n                warnings.warn(\n                    \"The default dtype for empty Series will be 'object' instead \"\n                    \"of 'float64' in a future version. Specify a dtype explicitly \"\n                    \"to silence this warning.\",\n                    DeprecationWarning,\n                    stacklevel=2,\n                )\n                # uncomment the line below when removing the DeprecationWarning\n                # dtype = np.dtype(object)\n\n            if index is not None:\n                index = ensure_index(index)\n\n            if data is None:\n                data = {}\n            if dtype is not None:\n                dtype = self._validate_dtype(dtype)\n\n            if isinstance(data, MultiIndex):\n                raise NotImplementedError(\n                    \"initializing a Series from a MultiIndex is not supported\"\n                )\n            elif isinstance(data, Index):\n\n                if dtype is not None:\n                    # astype copies\n                    data = data.astype(dtype)\n                else:\n                    # need to copy to avoid aliasing issues\n                    data = data._values.copy()\n                    if isinstance(data, ABCDatetimeIndex) and data.tz is not None:\n                        # GH#24096 need copy to be deep for datetime64tz case\n                        # TODO: See if we can avoid these copies\n                        data = data._values.copy(deep=True)\n                copy = False\n\n            elif isinstance(data, np.ndarray):\n                if len(data.dtype):\n                    # GH#13296 we are dealing with a compound dtype, which\n                    #  should be treated as 2D\n                    raise ValueError(\n                        \"Cannot construct a Series from an ndarray with \"\n                        \"compound dtype.  Use DataFrame instead.\"\n                    )\n                pass\n            elif isinstance(data, ABCSeries):\n                if index is None:\n                    index = data.index\n                else:\n                    data = data.reindex(index, copy=copy)\n                data = data._data\n            elif is_dict_like(data):\n                data, index = self._init_dict(data, index, dtype)\n                dtype = None\n                copy = False\n            elif isinstance(data, SingleBlockManager):\n                if index is None:\n                    index = data.index\n                elif not data.index.equals(index) or copy:\n                    # GH#19275 SingleBlockManager input should only be called\n                    # internally\n                    raise AssertionError(\n                        \"Cannot pass both SingleBlockManager \"\n                        \"`data` argument and a different \"\n                        \"`index` argument. `copy` must be False.\"\n                    )\n\n            elif is_extension_array_dtype(data):\n                pass\n            elif isinstance(data, (set, frozenset)):\n                raise TypeError(f\"'{type(data).__name__}' type is unordered\")\n            else:\n                data = com.maybe_iterable_to_list(data)\n\n            if index is None:\n                if not is_list_like(data):\n                    data = [data]\n                index = ibase.default_index(len(data))\n            elif is_list_like(data):\n\n                # a scalar numpy array is list-like but doesn't\n                # have a proper length\n                try:\n                    if len(index) != len(data):\n                        raise ValueError(\n                            f\"Length of passed values is {len(data)}, \"\n                            f\"index implies {len(index)}.\"\n                        )\n                except TypeError:\n                    pass\n\n            # create/copy the manager\n            if isinstance(data, SingleBlockManager):\n                if dtype is not None:\n                    data = data.astype(dtype=dtype, errors=\"ignore\", copy=copy)\n                elif copy:\n                    data = data.copy()\n            else:\n                data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True)\n\n                data = SingleBlockManager(data, index, fastpath=True)\n\n        generic.NDFrame.__init__(self, data)\n        self.name = name\n        self._set_axis(0, index, fastpath=True)",
        "begin_line": 199,
        "end_line": 324,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.series.Series._set_axis#389",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series._set_axis(self, axis: int, labels, fastpath: bool=False)",
        "snippet": "    def _set_axis(self, axis: int, labels, fastpath: bool = False) -> None:\n        \"\"\"\n        Override generic, we want to set the _typ here.\n\n        This is called from the cython code when we set the `index` attribute\n        directly, e.g. `series.index = [1, 2, 3]`.\n        \"\"\"\n        if not fastpath:\n            labels = ensure_index(labels)\n\n        is_all_dates = labels.is_all_dates\n        if is_all_dates:\n            if not isinstance(labels, (DatetimeIndex, PeriodIndex, TimedeltaIndex)):\n                try:\n                    labels = DatetimeIndex(labels)\n                    # need to set here because we changed the index\n                    if fastpath:\n                        self._data.set_axis(axis, labels)\n                except (tslibs.OutOfBoundsDatetime, ValueError):\n                    # labels may exceeds datetime bounds,\n                    # or not be a DatetimeIndex\n                    pass\n\n        object.__setattr__(self, \"_index\", labels)\n        if not fastpath:\n            # The ensure_index call aabove ensures we have an Index object\n            self._data.set_axis(axis, labels)",
        "begin_line": 389,
        "end_line": 415,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.series.Series.dtype#423",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.dtype(self)",
        "snippet": "    def dtype(self) -> DtypeObj:\n        \"\"\"\n        Return the dtype object of the underlying data.\n        \"\"\"\n        return self._data.dtype",
        "begin_line": 423,
        "end_line": 427,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.series.Series.name#437",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.name(self)",
        "snippet": "    def name(self) -> Label:\n        return self._name",
        "begin_line": 437,
        "end_line": 438,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.series.Series.name#441",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.name(self, value: Label)",
        "snippet": "    def name(self, value: Label) -> None:\n        if not is_hashable(value):\n            raise TypeError(\"Series.name must be a hashable type\")\n        object.__setattr__(self, \"_name\", value)",
        "begin_line": 441,
        "end_line": 444,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.series.Series.values#447",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.values(self)",
        "snippet": "    def values(self):\n        \"\"\"\n        Return Series as ndarray or ndarray-like depending on the dtype.\n\n        .. warning::\n\n           We recommend using :attr:`Series.array` or\n           :meth:`Series.to_numpy`, depending on whether you need\n           a reference to the underlying data or a NumPy array.\n\n        Returns\n        -------\n        numpy.ndarray or ndarray-like\n\n        See Also\n        --------\n        Series.array : Reference to the underlying data.\n        Series.to_numpy : A NumPy array representing the underlying data.\n\n        Examples\n        --------\n        >>> pd.Series([1, 2, 3]).values\n        array([1, 2, 3])\n\n        >>> pd.Series(list('aabc')).values\n        array(['a', 'a', 'b', 'c'], dtype=object)\n\n        >>> pd.Series(list('aabc')).astype('category').values\n        [a, a, b, c]\n        Categories (3, object): [a, b, c]\n\n        Timezone aware datetime data is converted to UTC:\n\n        >>> pd.Series(pd.date_range('20130101', periods=3,\n        ...                         tz='US/Eastern')).values\n        array(['2013-01-01T05:00:00.000000000',\n               '2013-01-02T05:00:00.000000000',\n               '2013-01-03T05:00:00.000000000'], dtype='datetime64[ns]')\n        \"\"\"\n        return self._data.external_values()",
        "begin_line": 447,
        "end_line": 486,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.series.Series.array#528",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.array(self)",
        "snippet": "    def array(self) -> ExtensionArray:\n        return self._data._block.array_values()",
        "begin_line": 528,
        "end_line": 529,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.series.Series.__array__#713",
        "src_path": "pandas/core/series.py",
        "class_name": "pandas.core.series.Series",
        "signature": "pandas.core.series.Series.__array__(self, dtype=None)",
        "snippet": "    def __array__(self, dtype=None) -> np.ndarray:\n        \"\"\"\n        Return the values as a NumPy array.\n\n        Users should not call this directly. Rather, it is invoked by\n        :func:`numpy.array` and :func:`numpy.asarray`.\n\n        Parameters\n        ----------\n        dtype : str or numpy.dtype, optional\n            The dtype to use for the resulting NumPy array. By default,\n            the dtype is inferred from the data.\n\n        Returns\n        -------\n        numpy.ndarray\n            The values in the series converted to a :class:`numpy.ndarray`\n            with the specified `dtype`.\n\n        See Also\n        --------\n        array : Create a new array from data.\n        Series.array : Zero-copy view to the array backing the Series.\n        Series.to_numpy : Series method for similar behavior.\n\n        Examples\n        --------\n        >>> ser = pd.Series([1, 2, 3])\n        >>> np.asarray(ser)\n        array([1, 2, 3])\n\n        For timezone-aware data, the timezones may be retained with\n        ``dtype='object'``\n\n        >>> tzser = pd.Series(pd.date_range('2000', periods=2, tz=\"CET\"))\n        >>> np.asarray(tzser, dtype=\"object\")\n        array([Timestamp('2000-01-01 00:00:00+0100', tz='CET', freq='D'),\n               Timestamp('2000-01-02 00:00:00+0100', tz='CET', freq='D')],\n              dtype=object)\n\n        Or the values may be localized to UTC and the tzinfo discarded with\n        ``dtype='datetime64[ns]'``\n\n        >>> np.asarray(tzser, dtype=\"datetime64[ns]\")  # doctest: +ELLIPSIS\n        array(['1999-12-31T23:00:00.000000000', ...],\n              dtype='datetime64[ns]')\n        \"\"\"\n        return np.asarray(self.array, dtype)",
        "begin_line": 713,
        "end_line": 760,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.inference.is_dict_like#263",
        "src_path": "pandas/core/dtypes/inference.py",
        "class_name": "pandas.core.dtypes.inference",
        "signature": "pandas.core.dtypes.inference.is_dict_like(obj)",
        "snippet": "def is_dict_like(obj) -> bool:\n    \"\"\"\n    Check if the object is dict-like.\n\n    Parameters\n    ----------\n    obj : The object to check\n\n    Returns\n    -------\n    is_dict_like : bool\n        Whether `obj` has dict-like properties.\n\n    Examples\n    --------\n    >>> is_dict_like({1: 2})\n    True\n    >>> is_dict_like([1, 2, 3])\n    False\n    >>> is_dict_like(dict)\n    False\n    >>> is_dict_like(dict())\n    True\n    \"\"\"\n    dict_like_attrs = (\"__getitem__\", \"keys\", \"__contains__\")\n    return (\n        all(hasattr(obj, attr) for attr in dict_like_attrs)\n        # [GH 25196] exclude classes\n        and not isinstance(obj, type)\n    )",
        "begin_line": 263,
        "end_line": 292,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.16666666666666666,
            "pseudo_dstar_susp": 0.16666666666666666,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.16666666666666666,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.inference.is_hashable#322",
        "src_path": "pandas/core/dtypes/inference.py",
        "class_name": "pandas.core.dtypes.inference",
        "signature": "pandas.core.dtypes.inference.is_hashable(obj)",
        "snippet": "def is_hashable(obj) -> bool:\n    \"\"\"\n    Return True if hash(obj) will succeed, False otherwise.\n\n    Some types will pass a test against collections.abc.Hashable but fail when\n    they are actually hashed with hash().\n\n    Distinguish between these and other types by trying the call to hash() and\n    seeing if they raise TypeError.\n\n    Returns\n    -------\n    bool\n\n    Examples\n    --------\n    >>> import collections\n    >>> a = ([],)\n    >>> isinstance(a, collections.abc.Hashable)\n    True\n    >>> is_hashable(a)\n    False\n    \"\"\"\n    # Unfortunately, we can't use isinstance(obj, collections.abc.Hashable),\n    # which can be faster than calling hash. That is because numpy scalars\n    # fail this test.\n\n    # Reconsider this decision once this numpy bug is fixed:\n    # https://github.com/numpy/numpy/issues/5562\n\n    try:\n        hash(obj)\n    except TypeError:\n        return False\n    else:\n        return True",
        "begin_line": 322,
        "end_line": 357,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.indexes.base.Index._reset_identity#556",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index._reset_identity(self)",
        "snippet": "    def _reset_identity(self):\n        \"\"\"\n        Initializes or resets ``_id`` attribute with new object.\n        \"\"\"\n        self._id = _Identity()\n        return self",
        "begin_line": 556,
        "end_line": 561,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.indexes.base.Index.name#1150",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base.Index",
        "signature": "pandas.core.indexes.base.Index.name(self, value)",
        "snippet": "    def name(self, value):\n        if self._no_setting_name:\n            # Used in MultiIndex.levels to avoid silently ignoring name updates.\n            raise RuntimeError(\n                \"Cannot set name on a level of a MultiIndex. Use \"\n                \"'MultiIndex.set_names' instead.\"\n            )\n        maybe_extract_name(value, None, type(self))\n        self._name = value",
        "begin_line": 1150,
        "end_line": 1158,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.indexes.base.default_index#5553",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base",
        "signature": "pandas.core.indexes.base.default_index(n)",
        "snippet": "def default_index(n):\n    from pandas.core.indexes.range import RangeIndex\n\n    return RangeIndex(0, n, name=None)",
        "begin_line": 5553,
        "end_line": 5556,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.indexes.base.maybe_extract_name#5559",
        "src_path": "pandas/core/indexes/base.py",
        "class_name": "pandas.core.indexes.base",
        "signature": "pandas.core.indexes.base.maybe_extract_name(name, obj, cls)",
        "snippet": "def maybe_extract_name(name, obj, cls) -> Label:\n    \"\"\"\n    If no name is passed, then extract it from data, validating hashability.\n    \"\"\"\n    if name is None and isinstance(obj, (Index, ABCSeries)):\n        # Note we don't just check for \"name\" attribute since that would\n        #  pick up e.g. dtype.name\n        name = obj.name\n\n    # GH#29069\n    if not is_hashable(name):\n        raise TypeError(f\"{cls.__name__}.name must be a hashable type\")\n\n    return name",
        "begin_line": 5559,
        "end_line": 5572,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.generic.create_pandas_abc_type#6",
        "src_path": "pandas/core/dtypes/generic.py",
        "class_name": "pandas.core.dtypes.generic",
        "signature": "pandas.core.dtypes.generic.create_pandas_abc_type(name, attr, comp)",
        "snippet": "def create_pandas_abc_type(name, attr, comp):\n\n    # https://github.com/python/mypy/issues/1006\n    # error: 'classmethod' used with a non-method\n    @classmethod  # type: ignore\n    def _check(cls, inst) -> bool:\n        return getattr(inst, attr, \"_typ\") in comp\n\n    dct = dict(__instancecheck__=_check, __subclasscheck__=_check)\n    meta = type(\"ABCBase\", (type,), dct)\n    return meta(name, tuple(), dct)",
        "begin_line": 6,
        "end_line": 16,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.generic._check#11",
        "src_path": "pandas/core/dtypes/generic.py",
        "class_name": "pandas.core.dtypes.generic",
        "signature": "pandas.core.dtypes.generic._check(cls, inst)",
        "snippet": "    def _check(cls, inst) -> bool:\n        return getattr(inst, attr, \"_typ\") in comp",
        "begin_line": 11,
        "end_line": 12,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.indexes.range.RangeIndex.__new__#88",
        "src_path": "pandas/core/indexes/range.py",
        "class_name": "pandas.core.indexes.range.RangeIndex",
        "signature": "pandas.core.indexes.range.RangeIndex.__new__(cls, start=None, stop=None, step=None, dtype=None, copy=False, name=None)",
        "snippet": "    def __new__(\n        cls, start=None, stop=None, step=None, dtype=None, copy=False, name=None,\n    ):\n\n        cls._validate_dtype(dtype)\n        name = maybe_extract_name(name, start, cls)\n\n        # RangeIndex\n        if isinstance(start, RangeIndex):\n            start = start._range\n            return cls._simple_new(start, name=name)\n\n        # validate the arguments\n        if com.all_none(start, stop, step):\n            raise TypeError(\"RangeIndex(...) must be called with integers\")\n\n        start = ensure_python_int(start) if start is not None else 0\n\n        if stop is None:\n            start, stop = 0, start\n        else:\n            stop = ensure_python_int(stop)\n\n        step = ensure_python_int(step) if step is not None else 1\n        if step == 0:\n            raise ValueError(\"Step must not be zero\")\n\n        rng = range(start, stop, step)\n        return cls._simple_new(rng, name=name)",
        "begin_line": 88,
        "end_line": 116,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.indexes.range.RangeIndex._simple_new#137",
        "src_path": "pandas/core/indexes/range.py",
        "class_name": "pandas.core.indexes.range.RangeIndex",
        "signature": "pandas.core.indexes.range.RangeIndex._simple_new(cls, values: range, name: Label=None)",
        "snippet": "    def _simple_new(cls, values: range, name: Label = None) -> \"RangeIndex\":\n        result = object.__new__(cls)\n\n        assert isinstance(values, range)\n\n        result._range = values\n        result.name = name\n\n        result._reset_identity()\n        return result",
        "begin_line": 137,
        "end_line": 146,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.indexes.range.RangeIndex.__len__#677",
        "src_path": "pandas/core/indexes/range.py",
        "class_name": "pandas.core.indexes.range.RangeIndex",
        "signature": "pandas.core.indexes.range.RangeIndex.__len__(self)",
        "snippet": "    def __len__(self) -> int:\n        \"\"\"\n        return the length of the RangeIndex\n        \"\"\"\n        return len(self._range)",
        "begin_line": 677,
        "end_line": 681,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.__init__#117",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.__init__(self, values, placement, ndim=None)",
        "snippet": "    def __init__(self, values, placement, ndim=None):\n        self.ndim = self._check_ndim(values, ndim)\n        self.mgr_locs = placement\n        self.values = values\n\n        if self._validate_ndim and self.ndim and len(self.mgr_locs) != len(self.values):\n            raise ValueError(\n                f\"Wrong number of items passed {len(self.values)}, \"\n                f\"placement implies {len(self.mgr_locs)}\"\n            )",
        "begin_line": 117,
        "end_line": 126,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block._check_ndim#128",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block._check_ndim(self, values, ndim)",
        "snippet": "    def _check_ndim(self, values, ndim):\n        \"\"\"\n        ndim inference and validation.\n\n        Infers ndim from 'values' if not provided to __init__.\n        Validates that values.ndim and ndim are consistent if and only if\n        the class variable '_validate_ndim' is True.\n\n        Parameters\n        ----------\n        values : array-like\n        ndim : int or None\n\n        Returns\n        -------\n        ndim : int\n\n        Raises\n        ------\n        ValueError : the number of dimensions do not match\n        \"\"\"\n        if ndim is None:\n            ndim = values.ndim\n\n        if self._validate_ndim and values.ndim != ndim:\n            raise ValueError(\n                \"Wrong number of dimensions. \"\n                f\"values.ndim != ndim [{values.ndim} != {ndim}]\"\n            )\n        return ndim",
        "begin_line": 128,
        "end_line": 157,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.external_values#202",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.external_values(self)",
        "snippet": "    def external_values(self):\n        \"\"\"\n        The array that Series.values returns (public attribute).\n\n        This has some historical constraints, and is overridden in block\n        subclasses to return the correct array (e.g. period returns\n        object ndarray and datetimetz a datetime64[ns] ndarray instead of\n        proper extension array).\n        \"\"\"\n        return self.values",
        "begin_line": 202,
        "end_line": 211,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.mgr_locs#252",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.mgr_locs(self, new_mgr_locs)",
        "snippet": "    def mgr_locs(self, new_mgr_locs):\n        if not isinstance(new_mgr_locs, libinternals.BlockPlacement):\n            new_mgr_locs = libinternals.BlockPlacement(new_mgr_locs)\n\n        self._mgr_locs = new_mgr_locs",
        "begin_line": 252,
        "end_line": 256,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.internals.blocks.Block.dtype#333",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.Block",
        "signature": "pandas.core.internals.blocks.Block.dtype(self)",
        "snippet": "    def dtype(self):\n        return self.values.dtype",
        "begin_line": 333,
        "end_line": 334,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.internals.blocks.NonConsolidatableMixIn.__init__#1612",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.NonConsolidatableMixIn",
        "signature": "pandas.core.internals.blocks.NonConsolidatableMixIn.__init__(self, values, placement, ndim=None)",
        "snippet": "    def __init__(self, values, placement, ndim=None):\n        \"\"\"\n        Initialize a non-consolidatable block.\n\n        'ndim' may be inferred from 'placement'.\n\n        This will call continue to call __init__ for the other base\n        classes mixed in with this Mixin.\n        \"\"\"\n        # Placement must be converted to BlockPlacement so that we can check\n        # its length\n        if not isinstance(placement, libinternals.BlockPlacement):\n            placement = libinternals.BlockPlacement(placement)\n\n        # Maybe infer ndim from placement\n        if ndim is None:\n            if len(placement) != 1:\n                ndim = 1\n            else:\n                ndim = 2\n        super().__init__(values, placement, ndim=ndim)",
        "begin_line": 1612,
        "end_line": 1632,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.internals.blocks.ExtensionBlock.__init__#1744",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.ExtensionBlock",
        "signature": "pandas.core.internals.blocks.ExtensionBlock.__init__(self, values, placement, ndim=None)",
        "snippet": "    def __init__(self, values, placement, ndim=None):\n        values = self._maybe_coerce_values(values)\n        super().__init__(values, placement, ndim)",
        "begin_line": 1744,
        "end_line": 1746,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.internals.blocks.ExtensionBlock._maybe_coerce_values#1748",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.ExtensionBlock",
        "signature": "pandas.core.internals.blocks.ExtensionBlock._maybe_coerce_values(self, values)",
        "snippet": "    def _maybe_coerce_values(self, values):\n        \"\"\"\n        Unbox to an extension array.\n\n        This will unbox an ExtensionArray stored in an Index or Series.\n        ExtensionArrays pass through. No dtype coercion is done.\n\n        Parameters\n        ----------\n        values : Index, Series, ExtensionArray\n\n        Returns\n        -------\n        ExtensionArray\n        \"\"\"\n        return extract_array(values)",
        "begin_line": 1748,
        "end_line": 1763,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.internals.blocks.ExtensionBlock.array_values#1827",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks.ExtensionBlock",
        "signature": "pandas.core.internals.blocks.ExtensionBlock.array_values(self)",
        "snippet": "    def array_values(self) -> ExtensionArray:\n        return self.values",
        "begin_line": 1827,
        "end_line": 1828,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.internals.blocks.get_block_type#2998",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks",
        "signature": "pandas.core.internals.blocks.get_block_type(values, dtype=None)",
        "snippet": "def get_block_type(values, dtype=None):\n    \"\"\"\n    Find the appropriate Block subclass to use for the given values and dtype.\n\n    Parameters\n    ----------\n    values : ndarray-like\n    dtype : numpy or pandas dtype\n\n    Returns\n    -------\n    cls : class, subclass of Block\n    \"\"\"\n    dtype = dtype or values.dtype\n    vtype = dtype.type\n\n    if is_sparse(dtype):\n        # Need this first(ish) so that Sparse[datetime] is sparse\n        cls = ExtensionBlock\n    elif is_categorical(values):\n        cls = CategoricalBlock\n    elif issubclass(vtype, np.datetime64):\n        assert not is_datetime64tz_dtype(values)\n        cls = DatetimeBlock\n    elif is_datetime64tz_dtype(values):\n        cls = DatetimeTZBlock\n    elif is_interval_dtype(dtype) or is_period_dtype(dtype):\n        cls = ObjectValuesExtensionBlock\n    elif is_extension_array_dtype(values):\n        cls = ExtensionBlock\n    elif issubclass(vtype, np.floating):\n        cls = FloatBlock\n    elif issubclass(vtype, np.timedelta64):\n        assert issubclass(vtype, np.integer)\n        cls = TimeDeltaBlock\n    elif issubclass(vtype, np.complexfloating):\n        cls = ComplexBlock\n    elif issubclass(vtype, np.integer):\n        cls = IntBlock\n    elif dtype == np.bool_:\n        cls = BoolBlock\n    else:\n        cls = ObjectBlock\n    return cls",
        "begin_line": 2998,
        "end_line": 3041,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.internals.blocks.make_block#3044",
        "src_path": "pandas/core/internals/blocks.py",
        "class_name": "pandas.core.internals.blocks",
        "signature": "pandas.core.internals.blocks.make_block(values, placement, klass=None, ndim=None, dtype=None)",
        "snippet": "def make_block(values, placement, klass=None, ndim=None, dtype=None):\n    # Ensure that we don't allow PandasArray / PandasDtype in internals.\n    # For now, blocks should be backed by ndarrays when possible.\n    if isinstance(values, ABCPandasArray):\n        values = values.to_numpy()\n        if ndim and ndim > 1:\n            values = np.atleast_2d(values)\n\n    if isinstance(dtype, PandasDtype):\n        dtype = dtype.numpy_dtype\n\n    if klass is None:\n        dtype = dtype or values.dtype\n        klass = get_block_type(values, dtype)\n\n    elif klass is DatetimeTZBlock and not is_datetime64tz_dtype(values):\n        # TODO: This is no longer hit internally; does it need to be retained\n        #  for e.g. pyarrow?\n        values = DatetimeArray._simple_new(values, dtype=dtype)\n\n    return klass(values, ndim=ndim, placement=placement)",
        "begin_line": 3044,
        "end_line": 3064,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas._config.config._get_single_key#95",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._get_single_key(pat: str, silent: bool)",
        "snippet": "def _get_single_key(pat: str, silent: bool) -> str:\n    keys = _select_options(pat)\n    if len(keys) == 0:\n        if not silent:\n            _warn_if_deprecated(pat)\n        raise OptionError(f\"No such keys(s): {repr(pat)}\")\n    if len(keys) > 1:\n        raise OptionError(\"Pattern matched multiple keys\")\n    key = keys[0]\n\n    if not silent:\n        _warn_if_deprecated(key)\n\n    key = _translate_key(key)\n\n    return key",
        "begin_line": 95,
        "end_line": 110,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas._config.config._set_option#121",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._set_option(*args, **kwargs)",
        "snippet": "def _set_option(*args, **kwargs) -> None:\n    # must at least 1 arg deal with constraints later\n    nargs = len(args)\n    if not nargs or nargs % 2 != 0:\n        raise ValueError(\"Must provide an even number of non-keyword arguments\")\n\n    # default to false\n    silent = kwargs.pop(\"silent\", False)\n\n    if kwargs:\n        kwarg = list(kwargs.keys())[0]\n        raise TypeError(f'_set_option() got an unexpected keyword argument \"{kwarg}\"')\n\n    for k, v in zip(args[::2], args[1::2]):\n        key = _get_single_key(k, silent)\n\n        o = _get_registered_option(key)\n        if o and o.validator:\n            o.validator(v)\n\n        # walk the nested dict\n        root, k = _get_root(key)\n        root[k] = v\n\n        if o.cb:\n            if silent:\n                with warnings.catch_warnings(record=True):\n                    o.cb(key)\n            else:\n                o.cb(key)",
        "begin_line": 121,
        "end_line": 150,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas._config.config.CallableDynamicDoc.__call__#241",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config.CallableDynamicDoc",
        "signature": "pandas._config.config.CallableDynamicDoc.__call__(self, *args, **kwds)",
        "snippet": "    def __call__(self, *args, **kwds):\n        return self.__func__(*args, **kwds)",
        "begin_line": 241,
        "end_line": 242,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas._config.config._select_options#548",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._select_options(pat: str)",
        "snippet": "def _select_options(pat: str) -> List[str]:\n    \"\"\"\n    returns a list of keys matching `pat`\n\n    if pat==\"all\", returns all registered options\n    \"\"\"\n    # short-circuit for exact key\n    if pat in _registered_options:\n        return [pat]\n\n    # else look through all of them\n    keys = sorted(_registered_options.keys())\n    if pat == \"all\":  # reserved key\n        return keys\n\n    return [k for k in keys if re.search(pat, k, re.I)]",
        "begin_line": 548,
        "end_line": 563,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.16666666666666666,
            "pseudo_dstar_susp": 0.16666666666666666,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.16666666666666666,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas._config.config._get_root#566",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._get_root(key: str)",
        "snippet": "def _get_root(key: str) -> Tuple[Dict[str, Any], str]:\n    path = key.split(\".\")\n    cursor = _global_config\n    for p in path[:-1]:\n        cursor = cursor[p]\n    return cursor, path[-1]",
        "begin_line": 566,
        "end_line": 571,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas._config.config._get_deprecated_option#580",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._get_deprecated_option(key: str)",
        "snippet": "def _get_deprecated_option(key: str):\n    \"\"\"\n    Retrieves the metadata for a deprecated option, if `key` is deprecated.\n\n    Returns\n    -------\n    DeprecatedOption (namedtuple) if key is deprecated, None otherwise\n    \"\"\"\n    try:\n        d = _deprecated_options[key]\n    except KeyError:\n        return None\n    else:\n        return d",
        "begin_line": 580,
        "end_line": 593,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas._config.config._get_registered_option#596",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._get_registered_option(key: str)",
        "snippet": "def _get_registered_option(key: str):\n    \"\"\"\n    Retrieves the option metadata if `key` is a registered option.\n\n    Returns\n    -------\n    RegisteredOption (namedtuple) if key is deprecated, None otherwise\n    \"\"\"\n    return _registered_options.get(key)",
        "begin_line": 596,
        "end_line": 604,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas._config.config._translate_key#607",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._translate_key(key: str)",
        "snippet": "def _translate_key(key: str) -> str:\n    \"\"\"\n    if key id deprecated and a replacement key defined, will return the\n    replacement key, otherwise returns `key` as - is\n    \"\"\"\n    d = _get_deprecated_option(key)\n    if d:\n        return d.rkey or key\n    else:\n        return key",
        "begin_line": 607,
        "end_line": 616,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas._config.config._warn_if_deprecated#619",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config._warn_if_deprecated(key: str)",
        "snippet": "def _warn_if_deprecated(key: str) -> bool:\n    \"\"\"\n    Checks if `key` is a deprecated option and if so, prints a warning.\n\n    Returns\n    -------\n    bool - True if `key` is deprecated, False otherwise.\n    \"\"\"\n    d = _get_deprecated_option(key)\n    if d:\n        if d.msg:\n            print(d.msg)\n            warnings.warn(d.msg, FutureWarning)\n        else:\n            msg = f\"'{key}' is deprecated\"\n            if d.removal_ver:\n                msg += f\" and will be removed in {d.removal_ver}\"\n            if d.rkey:\n                msg += f\", please use '{d.rkey}' instead.\"\n            else:\n                msg += \", please refrain from using it.\"\n\n            warnings.warn(msg, FutureWarning)\n        return True\n    return False",
        "begin_line": 619,
        "end_line": 643,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas._config.config.inner#816",
        "src_path": "pandas/_config/config.py",
        "class_name": "pandas._config.config",
        "signature": "pandas._config.config.inner(x)",
        "snippet": "    def inner(x) -> None:\n        if x not in legal_values:\n\n            if not any(c(x) for c in callables):\n                uvals = [str(lval) for lval in legal_values]\n                pp_values = \"|\".join(uvals)\n                msg = f\"Value must be one of {pp_values}\"\n                if len(callables):\n                    msg += \" or a callable\"\n                raise ValueError(msg)",
        "begin_line": 816,
        "end_line": 825,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.__init__#198",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.__init__(self, data: BlockManager, copy: bool=False, attrs: Optional[Mapping[Optional[Hashable], Any]]=None)",
        "snippet": "    def __init__(\n        self,\n        data: BlockManager,\n        copy: bool = False,\n        attrs: Optional[Mapping[Optional[Hashable], Any]] = None,\n    ):\n        # copy kwarg is retained for mypy compat, is not used\n\n        object.__setattr__(self, \"_is_copy\", None)\n        object.__setattr__(self, \"_data\", data)\n        object.__setattr__(self, \"_item_cache\", {})\n        if attrs is None:\n            attrs = {}\n        else:\n            attrs = dict(attrs)\n        object.__setattr__(self, \"_attrs\", attrs)",
        "begin_line": 198,
        "end_line": 213,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.generic.NDFrame._validate_dtype#253",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame._validate_dtype(cls, dtype)",
        "snippet": "    def _validate_dtype(cls, dtype):\n        \"\"\" validate the passed dtype \"\"\"\n        if dtype is not None:\n            dtype = pandas_dtype(dtype)\n\n            # a compound dtype\n            if dtype.kind == \"V\":\n                raise NotImplementedError(\n                    \"compound dtypes are not implemented \"\n                    f\"in the {cls.__name__} constructor\"\n                )\n\n        return dtype",
        "begin_line": 253,
        "end_line": 265,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.__getattr__#5146",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.__getattr__(self, name: str)",
        "snippet": "    def __getattr__(self, name: str):\n        \"\"\"\n        After regular attribute access, try looking up the name\n        This allows simpler access to columns for interactive use.\n        \"\"\"\n        # Note: obj.x will always call obj.__getattribute__('x') prior to\n        # calling obj.__getattr__('x').\n\n        if (\n            name in self._internal_names_set\n            or name in self._metadata\n            or name in self._accessors\n        ):\n            return object.__getattribute__(self, name)\n        else:\n            if self._info_axis._can_hold_identifiers_and_holds_name(name):\n                return self[name]\n            return object.__getattribute__(self, name)",
        "begin_line": 5146,
        "end_line": 5163,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.generic.NDFrame.__setattr__#5165",
        "src_path": "pandas/core/generic.py",
        "class_name": "pandas.core.generic.NDFrame",
        "signature": "pandas.core.generic.NDFrame.__setattr__(self, name: str, value)",
        "snippet": "    def __setattr__(self, name: str, value) -> None:\n        \"\"\"\n        After regular attribute access, try setting the name\n        This allows simpler access to columns for interactive use.\n        \"\"\"\n        # first try regular attribute access via __getattribute__, so that\n        # e.g. ``obj.x`` and ``obj.x = 4`` will always reference/modify\n        # the same attribute.\n\n        try:\n            object.__getattribute__(self, name)\n            return object.__setattr__(self, name, value)\n        except AttributeError:\n            pass\n\n        # if this fails, go on to more involved attribute setting\n        # (note that this matches __getattr__, above).\n        if name in self._internal_names_set:\n            object.__setattr__(self, name, value)\n        elif name in self._metadata:\n            object.__setattr__(self, name, value)\n        else:\n            try:\n                existing = getattr(self, name)\n                if isinstance(existing, Index):\n                    object.__setattr__(self, name, value)\n                elif name in self._info_axis:\n                    self[name] = value\n                else:\n                    object.__setattr__(self, name, value)\n            except (AttributeError, TypeError):\n                if isinstance(self, ABCDataFrame) and (is_list_like(value)):\n                    warnings.warn(\n                        \"Pandas doesn't allow columns to be \"\n                        \"created via a new attribute name - see \"\n                        \"https://pandas.pydata.org/pandas-docs/\"\n                        \"stable/indexing.html#attribute-access\",\n                        stacklevel=2,\n                    )\n                object.__setattr__(self, name, value)",
        "begin_line": 5165,
        "end_line": 5204,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.arrays.string_.StringDtype.type#60",
        "src_path": "pandas/core/arrays/string_.py",
        "class_name": "pandas.core.arrays.string_.StringDtype",
        "signature": "pandas.core.arrays.string_.StringDtype.type(self)",
        "snippet": "    def type(self) -> Type[str]:\n        return str",
        "begin_line": 60,
        "end_line": 61,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.arrays.string_.StringDtype.construct_array_type#64",
        "src_path": "pandas/core/arrays/string_.py",
        "class_name": "pandas.core.arrays.string_.StringDtype",
        "signature": "pandas.core.arrays.string_.StringDtype.construct_array_type(cls)",
        "snippet": "    def construct_array_type(cls) -> Type[\"StringArray\"]:\n        \"\"\"\n        Return the array type associated with this dtype.\n\n        Returns\n        -------\n        type\n        \"\"\"\n        return StringArray",
        "begin_line": 64,
        "end_line": 72,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.arrays.string_.StringArray.__init__#173",
        "src_path": "pandas/core/arrays/string_.py",
        "class_name": "pandas.core.arrays.string_.StringArray",
        "signature": "pandas.core.arrays.string_.StringArray.__init__(self, values, copy=False)",
        "snippet": "    def __init__(self, values, copy=False):\n        values = extract_array(values)\n        skip_validation = isinstance(values, type(self))\n\n        super().__init__(values, copy=copy)\n        self._dtype = StringDtype()\n        if not skip_validation:\n            self._validate()",
        "begin_line": 173,
        "end_line": 180,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.arrays.string_.StringArray._validate#182",
        "src_path": "pandas/core/arrays/string_.py",
        "class_name": "pandas.core.arrays.string_.StringArray",
        "signature": "pandas.core.arrays.string_.StringArray._validate(self)",
        "snippet": "    def _validate(self):\n        \"\"\"Validate that we only store NA or strings.\"\"\"\n        if len(self._ndarray) and not lib.is_string_array(self._ndarray, skipna=True):\n            raise ValueError(\"StringArray requires a sequence of strings or pandas.NA\")\n        if self._ndarray.dtype != \"object\":\n            raise ValueError(\n                \"StringArray requires a sequence of strings or pandas.NA. Got \"\n                f\"'{self._ndarray.dtype}' dtype instead.\"\n            )",
        "begin_line": 182,
        "end_line": 190,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.arrays.string_.StringArray._from_sequence#193",
        "src_path": "pandas/core/arrays/string_.py",
        "class_name": "pandas.core.arrays.string_.StringArray",
        "signature": "pandas.core.arrays.string_.StringArray._from_sequence(cls, scalars, dtype=None, copy=False)",
        "snippet": "    def _from_sequence(cls, scalars, dtype=None, copy=False):\n        if dtype:\n            assert dtype == \"string\"\n\n        result = np.asarray(scalars, dtype=\"object\")\n        if copy and result is scalars:\n            result = result.copy()\n\n        # Standardize all missing-like values to NA\n        # TODO: it would be nice to do this in _validate / lib.is_string_array\n        # We are already doing a scan over the values there.\n        na_values = isna(result)\n        if na_values.any():\n            if result is scalars:\n                # force a copy now, if we haven't already\n                result = result.copy()\n            result[na_values] = StringDtype.na_value\n\n        return cls(result)",
        "begin_line": 193,
        "end_line": 211,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.arrays.sparse.dtype.SparseDtype.construct_from_string#186",
        "src_path": "pandas/core/arrays/sparse/dtype.py",
        "class_name": "pandas.core.arrays.sparse.dtype.SparseDtype",
        "signature": "pandas.core.arrays.sparse.dtype.SparseDtype.construct_from_string(cls, string: str)",
        "snippet": "    def construct_from_string(cls, string: str) -> \"SparseDtype\":\n        \"\"\"\n        Construct a SparseDtype from a string form.\n\n        Parameters\n        ----------\n        string : str\n            Can take the following forms.\n\n            string           dtype\n            ================ ============================\n            'int'            SparseDtype[np.int64, 0]\n            'Sparse'         SparseDtype[np.float64, nan]\n            'Sparse[int]'    SparseDtype[np.int64, 0]\n            'Sparse[int, 0]' SparseDtype[np.int64, 0]\n            ================ ============================\n\n            It is not possible to specify non-default fill values\n            with a string. An argument like ``'Sparse[int, 1]'``\n            will raise a ``TypeError`` because the default fill value\n            for integers is 0.\n\n        Returns\n        -------\n        SparseDtype\n        \"\"\"\n        if not isinstance(string, str):\n            raise TypeError(\n                f\"'construct_from_string' expects a string, got {type(string)}\"\n            )\n        msg = f\"Cannot construct a 'SparseDtype' from '{string}'\"\n        if string.startswith(\"Sparse\"):\n            try:\n                sub_type, has_fill_value = cls._parse_subtype(string)\n            except ValueError as err:\n                raise TypeError(msg) from err\n            else:\n                result = SparseDtype(sub_type)\n                msg = (\n                    f\"Cannot construct a 'SparseDtype' from '{string}'.\\n\\nIt \"\n                    \"looks like the fill_value in the string is not \"\n                    \"the default for the dtype. Non-default fill_values \"\n                    \"are not supported. Use the 'SparseDtype()' \"\n                    \"constructor instead.\"\n                )\n                if has_fill_value and str(result) != string:\n                    raise TypeError(msg)\n                return result\n        else:\n            raise TypeError(msg)",
        "begin_line": 186,
        "end_line": 235,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.base.ExtensionDtype.__eq__#94",
        "src_path": "pandas/core/dtypes/base.py",
        "class_name": "pandas.core.dtypes.base.ExtensionDtype",
        "signature": "pandas.core.dtypes.base.ExtensionDtype.__eq__(self, other: Any)",
        "snippet": "    def __eq__(self, other: Any) -> bool:\n        \"\"\"\n        Check whether 'other' is equal to self.\n\n        By default, 'other' is considered equal if either\n\n        * it's a string matching 'self.name'.\n        * it's an instance of this type and all of the\n          the attributes in ``self._metadata`` are equal between\n          `self` and `other`.\n\n        Parameters\n        ----------\n        other : Any\n\n        Returns\n        -------\n        bool\n        \"\"\"\n        if isinstance(other, str):\n            try:\n                other = self.construct_from_string(other)\n            except TypeError:\n                return False\n        if isinstance(other, type(self)):\n            return all(\n                getattr(self, attr) == getattr(other, attr) for attr in self._metadata\n            )\n        return False",
        "begin_line": 94,
        "end_line": 122,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.16666666666666666,
            "pseudo_dstar_susp": 0.16666666666666666,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.16666666666666666,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.base.ExtensionDtype.kind#154",
        "src_path": "pandas/core/dtypes/base.py",
        "class_name": "pandas.core.dtypes.base.ExtensionDtype",
        "signature": "pandas.core.dtypes.base.ExtensionDtype.kind(self)",
        "snippet": "    def kind(self) -> str:\n        \"\"\"\n        A character code (one of 'biufcmMOSUV'), default 'O'\n\n        This should match the NumPy dtype used when the array is\n        converted to an ndarray, which is probably 'O' for object if\n        the extension type cannot be represented as a built-in NumPy\n        type.\n\n        See Also\n        --------\n        numpy.dtype.kind\n        \"\"\"\n        return \"O\"",
        "begin_line": 154,
        "end_line": 167,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.base.ExtensionDtype.construct_from_string#200",
        "src_path": "pandas/core/dtypes/base.py",
        "class_name": "pandas.core.dtypes.base.ExtensionDtype",
        "signature": "pandas.core.dtypes.base.ExtensionDtype.construct_from_string(cls, string: str)",
        "snippet": "    def construct_from_string(cls, string: str):\n        r\"\"\"\n        Construct this type from a string.\n\n        This is useful mainly for data types that accept parameters.\n        For example, a period dtype accepts a frequency parameter that\n        can be set as ``period[H]`` (where H means hourly frequency).\n\n        By default, in the abstract class, just the name of the type is\n        expected. But subclasses can overwrite this method to accept\n        parameters.\n\n        Parameters\n        ----------\n        string : str\n            The name of the type, for example ``category``.\n\n        Returns\n        -------\n        ExtensionDtype\n            Instance of the dtype.\n\n        Raises\n        ------\n        TypeError\n            If a class cannot be constructed from this 'string'.\n\n        Examples\n        --------\n        For extension dtypes with arguments the following may be an\n        adequate implementation.\n\n        >>> @classmethod\n        ... def construct_from_string(cls, string):\n        ...     pattern = re.compile(r\"^my_type\\[(?P<arg_name>.+)\\]$\")\n        ...     match = pattern.match(string)\n        ...     if match:\n        ...         return cls(**match.groupdict())\n        ...     else:\n        ...         raise TypeError(\n        ...             f\"Cannot construct a '{cls.__name__}' from '{string}'\"\n        ...         )\n        \"\"\"\n        if not isinstance(string, str):\n            raise TypeError(\n                f\"'construct_from_string' expects a string, got {type(string)}\"\n            )\n        # error: Non-overlapping equality check (left operand type: \"str\", right\n        #  operand type: \"Callable[[ExtensionDtype], str]\")  [comparison-overlap]\n        assert isinstance(cls.name, str), (cls, type(cls.name))\n        if string != cls.name:\n            raise TypeError(f\"Cannot construct a '{cls.__name__}' from '{string}'\")\n        return cls()",
        "begin_line": 200,
        "end_line": 252,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.base.ExtensionDtype.is_dtype#255",
        "src_path": "pandas/core/dtypes/base.py",
        "class_name": "pandas.core.dtypes.base.ExtensionDtype",
        "signature": "pandas.core.dtypes.base.ExtensionDtype.is_dtype(cls, dtype: object)",
        "snippet": "    def is_dtype(cls, dtype: object) -> bool:\n        \"\"\"\n        Check if we match 'dtype'.\n\n        Parameters\n        ----------\n        dtype : object\n            The object to check.\n\n        Returns\n        -------\n        bool\n\n        Notes\n        -----\n        The default implementation is True if\n\n        1. ``cls.construct_from_string(dtype)`` is an instance\n           of ``cls``.\n        2. ``dtype`` is an object and is an instance of ``cls``\n        3. ``dtype`` has a ``dtype`` attribute, and any of the above\n           conditions is true for ``dtype.dtype``.\n        \"\"\"\n        dtype = getattr(dtype, \"dtype\", dtype)\n\n        if isinstance(dtype, (ABCSeries, ABCIndexClass, ABCDataFrame, np.dtype)):\n            # https://github.com/pandas-dev/pandas/issues/22960\n            # avoid passing data to `construct_from_string`. This could\n            # cause a FutureWarning from numpy about failing elementwise\n            # comparison from, e.g., comparing DataFrame == 'category'.\n            return False\n        elif dtype is None:\n            return False\n        elif isinstance(dtype, cls):\n            return True\n        if isinstance(dtype, str):\n            try:\n                return cls.construct_from_string(dtype) is not None\n            except TypeError:\n                return False\n        return False",
        "begin_line": 255,
        "end_line": 295,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.conftest.pytest_runtest_setup#50",
        "src_path": "pandas/conftest.py",
        "class_name": "pandas.conftest",
        "signature": "pandas.conftest.pytest_runtest_setup(item)",
        "snippet": "def pytest_runtest_setup(item):\n    if \"slow\" in item.keywords and item.config.getoption(\"--skip-slow\"):\n        pytest.skip(\"skipping due to --skip-slow\")\n\n    if \"slow\" not in item.keywords and item.config.getoption(\"--only-slow\"):\n        pytest.skip(\"skipping due to --only-slow\")\n\n    if \"network\" in item.keywords and item.config.getoption(\"--skip-network\"):\n        pytest.skip(\"skipping due to --skip-network\")\n\n    if \"db\" in item.keywords and item.config.getoption(\"--skip-db\"):\n        pytest.skip(\"skipping due to --skip-db\")\n\n    if \"high_memory\" in item.keywords and not item.config.getoption(\n        \"--run-high-memory\"\n    ):\n        pytest.skip(\"skipping high memory test since --run-high-memory was not set\")",
        "begin_line": 50,
        "end_line": 66,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.conftest.configure_tests#70",
        "src_path": "pandas/conftest.py",
        "class_name": "pandas.conftest",
        "signature": "pandas.conftest.configure_tests()",
        "snippet": "def configure_tests():\n    \"\"\"\n    Configure settings for all tests and test modules.\n    \"\"\"\n    pd.set_option(\"chained_assignment\", \"raise\")",
        "begin_line": 70,
        "end_line": 74,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.conftest.add_imports#78",
        "src_path": "pandas/conftest.py",
        "class_name": "pandas.conftest",
        "signature": "pandas.conftest.add_imports(doctest_namespace)",
        "snippet": "def add_imports(doctest_namespace):\n    \"\"\"\n    Make `np` and `pd` names available for doctests.\n    \"\"\"\n    doctest_namespace[\"np\"] = np\n    doctest_namespace[\"pd\"] = pd",
        "begin_line": 78,
        "end_line": 83,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.cast.maybe_cast_to_datetime#1217",
        "src_path": "pandas/core/dtypes/cast.py",
        "class_name": "pandas.core.dtypes.cast",
        "signature": "pandas.core.dtypes.cast.maybe_cast_to_datetime(value, dtype, errors: str='raise')",
        "snippet": "def maybe_cast_to_datetime(value, dtype, errors: str = \"raise\"):\n    \"\"\"\n    try to cast the array/value to a datetimelike dtype, converting float\n    nan to iNaT\n    \"\"\"\n    from pandas.core.tools.timedeltas import to_timedelta\n    from pandas.core.tools.datetimes import to_datetime\n\n    if dtype is not None:\n        if isinstance(dtype, str):\n            dtype = np.dtype(dtype)\n\n        is_datetime64 = is_datetime64_dtype(dtype)\n        is_datetime64tz = is_datetime64tz_dtype(dtype)\n        is_timedelta64 = is_timedelta64_dtype(dtype)\n\n        if is_datetime64 or is_datetime64tz or is_timedelta64:\n\n            # Force the dtype if needed.\n            msg = (\n                f\"The '{dtype.name}' dtype has no unit. \"\n                f\"Please pass in '{dtype.name}[ns]' instead.\"\n            )\n\n            if is_datetime64 and not is_dtype_equal(dtype, _NS_DTYPE):\n\n                # pandas supports dtype whose granularity is less than [ns]\n                # e.g., [ps], [fs], [as]\n                if dtype <= np.dtype(\"M8[ns]\"):\n                    if dtype.name == \"datetime64\":\n                        raise ValueError(msg)\n                    dtype = _NS_DTYPE\n                else:\n                    raise TypeError(f\"cannot convert datetimelike to dtype [{dtype}]\")\n            elif is_datetime64tz:\n\n                # our NaT doesn't support tz's\n                # this will coerce to DatetimeIndex with\n                # a matching dtype below\n                if is_scalar(value) and isna(value):\n                    value = [value]\n\n            elif is_timedelta64 and not is_dtype_equal(dtype, _TD_DTYPE):\n\n                # pandas supports dtype whose granularity is less than [ns]\n                # e.g., [ps], [fs], [as]\n                if dtype <= np.dtype(\"m8[ns]\"):\n                    if dtype.name == \"timedelta64\":\n                        raise ValueError(msg)\n                    dtype = _TD_DTYPE\n                else:\n                    raise TypeError(f\"cannot convert timedeltalike to dtype [{dtype}]\")\n\n            if is_scalar(value):\n                if value == iNaT or isna(value):\n                    value = iNaT\n            else:\n                value = np.array(value, copy=False)\n\n                # have a scalar array-like (e.g. NaT)\n                if value.ndim == 0:\n                    value = iNaT\n\n                # we have an array of datetime or timedeltas & nulls\n                elif np.prod(value.shape) or not is_dtype_equal(value.dtype, dtype):\n                    try:\n                        if is_datetime64:\n                            value = to_datetime(value, errors=errors)\n                            # GH 25843: Remove tz information since the dtype\n                            # didn't specify one\n                            if value.tz is not None:\n                                value = value.tz_localize(None)\n                            value = value._values\n                        elif is_datetime64tz:\n                            # The string check can be removed once issue #13712\n                            # is solved. String data that is passed with a\n                            # datetime64tz is assumed to be naive which should\n                            # be localized to the timezone.\n                            is_dt_string = is_string_dtype(value)\n                            value = to_datetime(value, errors=errors).array\n                            if is_dt_string:\n                                # Strings here are naive, so directly localize\n                                value = value.tz_localize(dtype.tz)\n                            else:\n                                # Numeric values are UTC at this point,\n                                # so localize and convert\n                                value = value.tz_localize(\"UTC\").tz_convert(dtype.tz)\n                        elif is_timedelta64:\n                            value = to_timedelta(value, errors=errors)._values\n                    except OutOfBoundsDatetime:\n                        raise\n                    except (AttributeError, ValueError, TypeError):\n                        pass\n\n        # coerce datetimelike to object\n        elif is_datetime64_dtype(value) and not is_datetime64_dtype(dtype):\n            if is_object_dtype(dtype):\n                if value.dtype != _NS_DTYPE:\n                    value = value.astype(_NS_DTYPE)\n                ints = np.asarray(value).view(\"i8\")\n                return tslib.ints_to_pydatetime(ints)\n\n            # we have a non-castable dtype that was passed\n            raise TypeError(f\"Cannot cast datetime64 to {dtype}\")\n\n    else:\n\n        is_array = isinstance(value, np.ndarray)\n\n        # catch a datetime/timedelta that is not of ns variety\n        # and no coercion specified\n        if is_array and value.dtype.kind in [\"M\", \"m\"]:\n            dtype = value.dtype\n\n            if dtype.kind == \"M\" and dtype != _NS_DTYPE:\n                value = tslibs.conversion.ensure_datetime64ns(value)\n\n            elif dtype.kind == \"m\" and dtype != _TD_DTYPE:\n                value = to_timedelta(value)\n\n        # only do this if we have an array and the dtype of the array is not\n        # setup already we are not an integer/object, so don't bother with this\n        # conversion\n        elif not (\n            is_array\n            and not (\n                issubclass(value.dtype.type, np.integer) or value.dtype == np.object_\n            )\n        ):\n            value = maybe_infer_to_datetimelike(value)\n\n    return value",
        "begin_line": 1217,
        "end_line": 1348,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    },
    {
        "name": "pandas.core.dtypes.cast.construct_1d_ndarray_preserving_na#1490",
        "src_path": "pandas/core/dtypes/cast.py",
        "class_name": "pandas.core.dtypes.cast",
        "signature": "pandas.core.dtypes.cast.construct_1d_ndarray_preserving_na(values, dtype=None, copy: bool=False)",
        "snippet": "def construct_1d_ndarray_preserving_na(values, dtype=None, copy: bool = False):\n    \"\"\"\n    Construct a new ndarray, coercing `values` to `dtype`, preserving NA.\n\n    Parameters\n    ----------\n    values : Sequence\n    dtype : numpy.dtype, optional\n    copy : bool, default False\n        Note that copies may still be made with ``copy=False`` if casting\n        is required.\n\n    Returns\n    -------\n    arr : ndarray[dtype]\n\n    Examples\n    --------\n    >>> np.array([1.0, 2.0, None], dtype='str')\n    array(['1.0', '2.0', 'None'], dtype='<U4')\n\n    >>> construct_1d_ndarray_preserving_na([1.0, 2.0, None], dtype=np.dtype('str'))\n    array(['1.0', '2.0', None], dtype=object)\n    \"\"\"\n    subarr = np.array(values, dtype=dtype, copy=copy)\n\n    if dtype is not None and dtype.kind in (\"U\", \"S\"):\n        # GH-21083\n        # We can't just return np.array(subarr, dtype='str') since\n        # NumPy will convert the non-string objects into strings\n        # Including NA values. Se we have to go\n        # string -> object -> update NA, which requires an\n        # additional pass over the data.\n        na_values = isna(values)\n        subarr2 = subarr.astype(object)\n        subarr2[na_values] = np.asarray(values, dtype=object)[na_values]\n        subarr = subarr2\n\n    return subarr",
        "begin_line": 1490,
        "end_line": 1528,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0035087719298245615,
            "pseudo_dstar_susp": 0.0035087719298245615,
            "pseudo_tarantula_susp": 0.0035714285714285713,
            "pseudo_op2_susp": 0.0035087719298245615,
            "pseudo_barinel_susp": 0.0035714285714285713
        }
    }
]