[
    {
        "name": "youtube_dl.extractor.firsttv.FirstTVIE._real_extract#29",
        "src_path": "youtube_dl/extractor/firsttv.py",
        "class_name": "youtube_dl.extractor.firsttv.FirstTVIE",
        "signature": "youtube_dl.extractor.firsttv.FirstTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id, 'Downloading page')\n\n        video_url = self._html_search_regex(\n            r'''(?s)jwplayer\\('flashvideoportal_1'\\)\\.setup\\({.*?'file': '([^']+)'.*?}\\);''', webpage, 'video URL')\n\n        title = self._html_search_regex(\n            r'<div class=\"tv_translation\">\\s*<h1><a href=\"[^\"]+\">([^<]*)</a>', webpage, 'title')\n        description = self._html_search_regex(\n            r'<div class=\"descr\">\\s*<div>&nbsp;</div>\\s*<p>([^<]*)</p></div>', webpage, 'description', fatal=False)\n\n        thumbnail = self._og_search_thumbnail(webpage)\n        duration = self._og_search_property('video:duration', webpage, 'video duration', fatal=False)\n\n        like_count = self._html_search_regex(r'title=\"\u041f\u043e\u043d\u0440\u0430\u0432\u0438\u043b\u043e\u0441\u044c\".*?/></label> \\[(\\d+)\\]',\n            webpage, 'like count', fatal=False)\n        dislike_count = self._html_search_regex(r'title=\"\u041d\u0435 \u043f\u043e\u043d\u0440\u0430\u0432\u0438\u043b\u043e\u0441\u044c\".*?/></label> \\[(\\d+)\\]',\n            webpage, 'dislike count', fatal=False)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'thumbnail': thumbnail,\n            'title': title,\n            'description': description,\n            'duration': int_or_none(duration),\n            'like_count': int_or_none(like_count),\n            'dislike_count': int_or_none(dislike_count),\n        }",
        "begin_line": 29,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.orf.ORFIE._real_extract#31",
        "src_path": "youtube_dl/extractor/orf.py",
        "class_name": "youtube_dl.extractor.orf.ORFIE",
        "signature": "youtube_dl.extractor.orf.ORFIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('id')\n        webpage = self._download_webpage(url, playlist_id)\n\n        data_json = self._search_regex(\n            r'initializeAdworx\\((.+?)\\);\\n', webpage, 'video info')\n        all_data = json.loads(data_json)\n\n        def get_segments(all_data):\n            for data in all_data:\n                if data['name'] == 'Tracker::EPISODE_DETAIL_PAGE_OVER_PROGRAM':\n                    return data['values']['segments']\n\n        sdata = get_segments(all_data)\n        if not sdata:\n            raise ExtractorError('Unable to extract segments')\n\n        def quality_to_int(s):\n            m = re.search('([0-9]+)', s)\n            if m is None:\n                return -1\n            return int(m.group(1))\n\n        entries = []\n        for sd in sdata:\n            video_id = sd['id']\n            formats = [{\n                'preference': -10 if fd['delivery'] == 'hls' else None,\n                'format_id': '%s-%s-%s' % (\n                    fd['delivery'], fd['quality'], fd['quality_string']),\n                'url': fd['src'],\n                'protocol': fd['protocol'],\n                'quality': quality_to_int(fd['quality']),\n            } for fd in sd['playlist_item_array']['sources']]\n\n            # Check for geoblocking.\n            # There is a property is_geoprotection, but that's always false\n            geo_str = sd.get('geoprotection_string')\n            if geo_str:\n                try:\n                    http_url = next(\n                        f['url']\n                        for f in formats\n                        if re.match(r'^https?://.*\\.mp4$', f['url']))\n                except StopIteration:\n                    pass\n                else:\n                    req = HEADRequest(http_url)\n                    self._request_webpage(\n                        req, video_id,\n                        note='Testing for geoblocking',\n                        errnote=((\n                            'This video seems to be blocked outside of %s. '\n                            'You may want to try the streaming-* formats.')\n                            % geo_str),\n                        fatal=False)\n\n            self._sort_formats(formats)\n\n            upload_date = unified_strdate(sd['created_date'])\n            entries.append({\n                '_type': 'video',\n                'id': video_id,\n                'title': sd['header'],\n                'formats': formats,\n                'description': sd.get('description'),\n                'duration': int(sd['duration_in_seconds']),\n                'upload_date': upload_date,\n                'thumbnail': sd.get('image_full_url'),\n            })\n\n        return {\n            '_type': 'playlist',\n            'entries': entries,\n            'id': playlist_id,\n        }",
        "begin_line": 31,
        "end_line": 107,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.yahoo.YahooIE._real_extract#40",
        "src_path": "youtube_dl/extractor/yahoo.py",
        "class_name": "youtube_dl.extractor.yahoo.YahooIE",
        "signature": "youtube_dl.extractor.yahoo.YahooIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n\n        items_json = self._search_regex(r'mediaItems: ({.*?})$',\n            webpage, 'items', flags=re.MULTILINE)\n        items = json.loads(items_json)\n        info = items['mediaItems']['query']['results']['mediaObj'][0]\n        # The 'meta' field is not always in the video webpage, we request it\n        # from another page\n        long_id = info['id']\n        return self._get_info(long_id, video_id)",
        "begin_line": 40,
        "end_line": 52,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.yahoo.YahooIE._get_info#54",
        "src_path": "youtube_dl/extractor/yahoo.py",
        "class_name": "youtube_dl.extractor.yahoo.YahooIE",
        "signature": "youtube_dl.extractor.yahoo.YahooIE._get_info(self, long_id, video_id)",
        "snippet": "    def _get_info(self, long_id, video_id):\n        query = ('SELECT * FROM yahoo.media.video.streams WHERE id=\"%s\"'\n                 ' AND plrs=\"86Gj0vCaSzV_Iuf6hNylf2\" AND region=\"US\"'\n                 ' AND protocol=\"http\"' % long_id)\n        data = compat_urllib_parse.urlencode({\n            'q': query,\n            'env': 'prod',\n            'format': 'json',\n        })\n        query_result_json = self._download_webpage(\n            'http://video.query.yahoo.com/v1/public/yql?' + data,\n            video_id, 'Downloading video info')\n        query_result = json.loads(query_result_json)\n        info = query_result['query']['results']['mediaObj'][0]\n        meta = info['meta']\n\n        formats = []\n        for s in info['streams']:\n            format_info = {\n                'width': int_or_none(s.get('width')),\n                'height': int_or_none(s.get('height')),\n                'tbr': int_or_none(s.get('bitrate')),\n            }\n\n            host = s['host']\n            path = s['path']\n            if host.startswith('rtmp'):\n                format_info.update({\n                    'url': host,\n                    'play_path': path,\n                    'ext': 'flv',\n                })\n            else:\n                format_url = compat_urlparse.urljoin(host, path)\n                format_info['url'] = format_url\n                \n            formats.append(format_info)\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': meta['title'],\n            'formats': formats,\n            'description': clean_html(meta['description']),\n            'thumbnail': meta['thumbnail'],\n        }",
        "begin_line": 54,
        "end_line": 100,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.yahoo.YahooNewsIE._real_extract#121",
        "src_path": "youtube_dl/extractor/yahoo.py",
        "class_name": "youtube_dl.extractor.yahoo.YahooNewsIE",
        "signature": "youtube_dl.extractor.yahoo.YahooNewsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        long_id = self._search_regex(r'contentId: \\'(.+?)\\',', webpage, 'long id')\n        return self._get_info(long_id, video_id)",
        "begin_line": 121,
        "end_line": 126,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.yahoo.YahooSearchIE._get_n_results#135",
        "src_path": "youtube_dl/extractor/yahoo.py",
        "class_name": "youtube_dl.extractor.yahoo.YahooSearchIE",
        "signature": "youtube_dl.extractor.yahoo.YahooSearchIE._get_n_results(self, query, n)",
        "snippet": "    def _get_n_results(self, query, n):\n        \"\"\"Get a specified number of results for a query\"\"\"\n\n        res = {\n            '_type': 'playlist',\n            'id': query,\n            'entries': []\n        }\n        for pagenum in itertools.count(0): \n            result_url = 'http://video.search.yahoo.com/search/?p=%s&fr=screen&o=js&gs=0&b=%d' % (compat_urllib_parse.quote_plus(query), pagenum * 30)\n            webpage = self._download_webpage(result_url, query,\n                                             note='Downloading results page '+str(pagenum+1))\n            info = json.loads(webpage)\n            m = info['m']\n            results = info['results']\n\n            for (i, r) in enumerate(results):\n                if (pagenum * 30) +i >= n:\n                    break\n                mobj = re.search(r'(?P<url>screen\\.yahoo\\.com/.*?-\\d*?\\.html)\"', r)\n                e = self.url_result('http://' + mobj.group('url'), 'Yahoo')\n                res['entries'].append(e)\n            if (pagenum * 30 +i >= n) or (m['last'] >= (m['total'] -1)):\n                break\n\n        return res",
        "begin_line": 135,
        "end_line": 160,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.cbs.CBSIE._real_extract#23",
        "src_path": "youtube_dl/extractor/cbs.py",
        "class_name": "youtube_dl.extractor.cbs.CBSIE",
        "signature": "youtube_dl.extractor.cbs.CBSIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        real_id = self._search_regex(\n            r\"video\\.settings\\.pid\\s*=\\s*'([^']+)';\",\n            webpage, u'real video ID')\n        return self.url_result(u'theplatform:%s' % real_id)",
        "begin_line": 23,
        "end_line": 30,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.veoh.VeohIE._real_extract#24",
        "src_path": "youtube_dl/extractor/veoh.py",
        "class_name": "youtube_dl.extractor.veoh.VeohIE",
        "signature": "youtube_dl.extractor.veoh.VeohIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        age_limit = 0\n        if 'class=\"adultwarning-container\"' in webpage:\n            self.report_age_confirmation()\n            age_limit = 18\n            request = compat_urllib_request.Request(url)\n            request.add_header('Cookie', 'confirmedAdult=true')\n            webpage = self._download_webpage(request, video_id)\n\n        m_youtube = re.search(r'http://www\\.youtube\\.com/v/(.*?)(\\&|\")', webpage)\n        if m_youtube is not None:\n            youtube_id = m_youtube.group(1)\n            self.to_screen('%s: detected Youtube video.' % video_id)\n            return self.url_result(youtube_id, 'Youtube')\n\n        self.report_extraction(video_id)\n        info = self._search_regex(r'videoDetailsJSON = \\'({.*?})\\';', webpage, 'info')\n        info = json.loads(info)\n        video_url = info.get('fullPreviewHashHighPath') or info.get('fullPreviewHashLowPath')\n\n        return {\n            'id': info['videoId'],\n            'title': info['title'],\n            'url': video_url,\n            'uploader': info['username'],\n            'thumbnail': info.get('highResImage') or info.get('medResImage'),\n            'description': info['description'],\n            'view_count': info['views'],\n            'age_limit': age_limit,\n        }",
        "begin_line": 24,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.slashdot.SlashdotIE._real_extract#19",
        "src_path": "youtube_dl/extractor/slashdot.py",
        "class_name": "youtube_dl.extractor.slashdot.SlashdotIE",
        "signature": "youtube_dl.extractor.slashdot.SlashdotIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        ooyala_url = self._search_regex(r'<script src=\"(.*?)\"', webpage, 'ooyala url')\n        return self.url_result(ooyala_url, 'Ooyala')",
        "begin_line": 19,
        "end_line": 24,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.faz.FazIE._real_extract#23",
        "src_path": "youtube_dl/extractor/faz.py",
        "class_name": "youtube_dl.extractor.faz.FazIE",
        "signature": "youtube_dl.extractor.faz.FazIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        self.to_screen(video_id)\n        webpage = self._download_webpage(url, video_id)\n        config_xml_url = self._search_regex(r'writeFLV\\(\\'(.+?)\\',', webpage,\n            u'config xml url')\n        config = self._download_xml(config_xml_url, video_id,\n            u'Downloading config xml')\n\n        encodings = config.find('ENCODINGS')\n        formats = []\n        for code in ['LOW', 'HIGH', 'HQ']:\n            encoding = encodings.find(code)\n            if encoding is None:\n                continue\n            encoding_url = encoding.find('FILENAME').text\n            formats.append({\n                'url': encoding_url,\n                'ext': determine_ext(encoding_url),\n                'format_id': code.lower(),\n            })\n\n        descr = self._html_search_regex(r'<p class=\"Content Copy\">(.*?)</p>', webpage, u'description')\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n            'formats': formats,\n            'description': descr,\n            'thumbnail': config.find('STILL/STILL_BIG').text,\n        }",
        "begin_line": 23,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.cnn.CNNIE._real_extract#39",
        "src_path": "youtube_dl/extractor/cnn.py",
        "class_name": "youtube_dl.extractor.cnn.CNNIE",
        "signature": "youtube_dl.extractor.cnn.CNNIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        path = mobj.group('path')\n        page_title = mobj.group('title')\n        info_url = 'http://cnn.com/video/data/3.0/%s/index.xml' % path\n        info = self._download_xml(info_url, page_title)\n\n        formats = []\n        rex = re.compile(r'''(?x)\n            (?P<width>[0-9]+)x(?P<height>[0-9]+)\n            (?:_(?P<bitrate>[0-9]+)k)?\n        ''')\n        for f in info.findall('files/file'):\n            video_url = 'http://ht.cdn.turner.com/cnn/big%s' % (f.text.strip())\n            fdct = {\n                'format_id': f.attrib['bitrate'],\n                'url': video_url,\n            }\n\n            mf = rex.match(f.attrib['bitrate'])\n            if mf:\n                fdct['width'] = int(mf.group('width'))\n                fdct['height'] = int(mf.group('height'))\n                fdct['tbr'] = int_or_none(mf.group('bitrate'))\n            else:\n                mf = rex.search(f.text)\n                if mf:\n                    fdct['width'] = int(mf.group('width'))\n                    fdct['height'] = int(mf.group('height'))\n                    fdct['tbr'] = int_or_none(mf.group('bitrate'))\n                else:\n                    mi = re.match(r'ios_(audio|[0-9]+)$', f.attrib['bitrate'])\n                    if mi:\n                        if mi.group(1) == 'audio':\n                            fdct['vcodec'] = 'none'\n                            fdct['ext'] = 'm4a'\n                        else:\n                            fdct['tbr'] = int(mi.group(1))\n\n            formats.append(fdct)\n\n        self._sort_formats(formats)\n\n        thumbnails = sorted([((int(t.attrib['height']),int(t.attrib['width'])), t.text) for t in info.findall('images/image')])\n        thumbs_dict = [{'resolution': res, 'url': t_url} for (res, t_url) in thumbnails]\n\n        metas_el = info.find('metas')\n        upload_date = (\n            metas_el.attrib.get('version') if metas_el is not None else None)\n\n        duration_el = info.find('length')\n        duration = parse_duration(duration_el.text)\n\n        return {\n            'id': info.attrib['id'],\n            'title': info.find('headline').text,\n            'formats': formats,\n            'thumbnail': thumbnails[-1][1],\n            'thumbnails': thumbs_dict,\n            'description': info.find('description').text,\n            'duration': duration,\n            'upload_date': upload_date,\n        }",
        "begin_line": 39,
        "end_line": 101,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.cnn.CNNBlogsIE._real_extract#119",
        "src_path": "youtube_dl/extractor/cnn.py",
        "class_name": "youtube_dl.extractor.cnn.CNNBlogsIE",
        "signature": "youtube_dl.extractor.cnn.CNNBlogsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        webpage = self._download_webpage(url, url_basename(url))\n        cnn_url = self._html_search_regex(r'data-url=\"(.+?)\"', webpage, 'cnn url')\n        return {\n            '_type': 'url',\n            'url': cnn_url,\n            'ie_key': CNNIE.ie_key(),\n        }",
        "begin_line": 119,
        "end_line": 126,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.howcast.HowcastIE._real_extract#21",
        "src_path": "youtube_dl/extractor/howcast.py",
        "class_name": "youtube_dl.extractor.howcast.HowcastIE",
        "signature": "youtube_dl.extractor.howcast.HowcastIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n\n        self.report_extraction(video_id)\n\n        video_url = self._search_regex(r'\\'?file\\'?: \"(http://mobile-media\\.howcast\\.com/[0-9]+\\.mp4)',\n            webpage, 'video URL')\n\n        video_description = self._html_search_regex(r'<meta content=(?:\"([^\"]+)\"|\\'([^\\']+)\\') name=\\'description\\'',\n            webpage, 'description', fatal=False)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': self._og_search_title(webpage),\n            'description': video_description,\n            'thumbnail': self._og_search_thumbnail(webpage),\n        }",
        "begin_line": 21,
        "end_line": 41,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.nowness.NownessIE._real_extract#26",
        "src_path": "youtube_dl/extractor/nowness.py",
        "class_name": "youtube_dl.extractor.nowness.NownessIE",
        "signature": "youtube_dl.extractor.nowness.NownessIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('slug')\n\n        webpage = self._download_webpage(url, video_id)\n        player_url = self._search_regex(\n            r'\"([^\"]+/content/issue-[0-9.]+.js)\"', webpage, 'player URL')\n        real_id = self._search_regex(\n            r'\\sdata-videoId=\"([0-9]+)\"', webpage, 'internal video ID')\n\n        player_code = self._download_webpage(\n            player_url, video_id,\n            note='Downloading player JavaScript',\n            errnote='Player download failed')\n        player_code = player_code.replace(\"'+d+'\", real_id)\n\n        bc_url = BrightcoveIE._extract_brightcove_url(player_code)\n        if bc_url is None:\n            raise ExtractorError('Could not find player definition')\n        return {\n            '_type': 'url',\n            'url': bc_url,\n            'ie_key': 'Brightcove',\n        }",
        "begin_line": 26,
        "end_line": 49,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.gamekings.GamekingsIE._real_extract#19",
        "src_path": "youtube_dl/extractor/gamekings.py",
        "class_name": "youtube_dl.extractor.gamekings.GamekingsIE",
        "signature": "youtube_dl.extractor.gamekings.GamekingsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n\n        mobj = re.match(self._VALID_URL, url)\n        name = mobj.group('name')\n        webpage = self._download_webpage(url, name)\n        video_url = self._og_search_video_url(webpage)\n\n        video = re.search(r'[0-9]+', video_url)\n        video_id = video.group(0)\n\n        # Todo: add medium format\n        video_url = video_url.replace(video_id, 'large/' + video_id)\n\n        return {\n            'id': video_id,\n            'ext': 'mp4',\n            'url': video_url,\n            'title': self._og_search_title(webpage),\n            'description': self._og_search_description(webpage),\n        }",
        "begin_line": 19,
        "end_line": 38,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.rutube.RutubeIE._real_extract#38",
        "src_path": "youtube_dl/extractor/rutube.py",
        "class_name": "youtube_dl.extractor.rutube.RutubeIE",
        "signature": "youtube_dl.extractor.rutube.RutubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        \n        api_response = self._download_webpage('http://rutube.ru/api/video/%s/?format=json' % video_id,\n                                              video_id, 'Downloading video JSON')\n        video = json.loads(api_response)\n        \n        api_response = self._download_webpage('http://rutube.ru/api/play/trackinfo/%s/?format=json' % video_id,\n                                              video_id, 'Downloading trackinfo JSON')\n        trackinfo = json.loads(api_response)\n        \n        # Some videos don't have the author field\n        author = trackinfo.get('author') or {}\n        m3u8_url = trackinfo['video_balancer'].get('m3u8')\n        if m3u8_url is None:\n            raise ExtractorError('Couldn\\'t find m3u8 manifest url')\n\n        return {\n            'id': video['id'],\n            'title': video['title'],\n            'description': video['description'],\n            'duration': video['duration'],\n            'view_count': video['hits'],\n            'url': m3u8_url,\n            'ext': 'mp4',\n            'thumbnail': video['thumbnail_url'],\n            'uploader': author.get('name'),\n            'uploader_id': compat_str(author['id']) if author else None,\n            'upload_date': unified_strdate(video['created_ts']),\n            'age_limit': 18 if video['is_adult'] else 0,\n        }",
        "begin_line": 38,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.rutube.RutubeChannelIE._extract_videos#79",
        "src_path": "youtube_dl/extractor/rutube.py",
        "class_name": "youtube_dl.extractor.rutube.RutubeChannelIE",
        "signature": "youtube_dl.extractor.rutube.RutubeChannelIE._extract_videos(self, channel_id, channel_title=None)",
        "snippet": "    def _extract_videos(self, channel_id, channel_title=None):\n        entries = []\n        for pagenum in itertools.count(1):\n            api_response = self._download_webpage(\n                self._PAGE_TEMPLATE % (channel_id, pagenum),\n                channel_id, 'Downloading page %s' % pagenum)\n            page = json.loads(api_response)\n            results = page['results']\n            if not results:\n                break\n            entries.extend(self.url_result(result['video_url'], 'Rutube') for result in results)\n            if not page['has_next']:\n                break\n        return self.playlist_result(entries, channel_id, channel_title)",
        "begin_line": 79,
        "end_line": 92,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.rutube.RutubeChannelIE._real_extract#94",
        "src_path": "youtube_dl/extractor/rutube.py",
        "class_name": "youtube_dl.extractor.rutube.RutubeChannelIE",
        "signature": "youtube_dl.extractor.rutube.RutubeChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        channel_id = mobj.group('id')\n        return self._extract_videos(channel_id)",
        "begin_line": 94,
        "end_line": 97,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.rutube.RutubeMovieIE._real_extract#108",
        "src_path": "youtube_dl/extractor/rutube.py",
        "class_name": "youtube_dl.extractor.rutube.RutubeMovieIE",
        "signature": "youtube_dl.extractor.rutube.RutubeMovieIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        movie_id = mobj.group('id')\n        api_response = self._download_webpage(\n            self._MOVIE_TEMPLATE % movie_id, movie_id,\n            'Downloading movie JSON')\n        movie = json.loads(api_response)\n        movie_name = movie['name']\n        return self._extract_videos(movie_id, movie_name)",
        "begin_line": 108,
        "end_line": 116,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.testurl.TestURLIE._real_extract#15",
        "src_path": "youtube_dl/extractor/testurl.py",
        "class_name": "youtube_dl.extractor.testurl.TestURLIE",
        "signature": "youtube_dl.extractor.testurl.TestURLIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        from ..extractor import gen_extractors\n\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        extractor_id = mobj.group('extractor')\n        all_extractors = gen_extractors()\n\n        rex = re.compile(extractor_id, flags=re.IGNORECASE)\n        matching_extractors = [\n            e for e in all_extractors if rex.search(e.IE_NAME)]\n\n        if len(matching_extractors) == 0:\n            raise ExtractorError(\n                'No extractors matching %r found' % extractor_id,\n                expected=True)\n        elif len(matching_extractors) > 1:\n            # Is it obvious which one to pick?\n            try:\n                extractor = next(\n                    ie for ie in matching_extractors\n                    if ie.IE_NAME.lower() == extractor_id.lower())\n            except StopIteration:\n                raise ExtractorError(\n                    ('Found multiple matching extractors: %s' %\n                        ' '.join(ie.IE_NAME for ie in matching_extractors)),\n                    expected=True)\n        else:\n            extractor = matching_extractors[0]\n\n        num_str = mobj.group('num')\n        num = int(num_str) if num_str else 0\n\n        testcases = []\n        t = getattr(extractor, '_TEST', None)\n        if t:\n            testcases.append(t)\n        testcases.extend(getattr(extractor, '_TESTS', []))\n\n        try:\n            tc = testcases[num]\n        except IndexError:\n            raise ExtractorError(\n                ('Test case %d not found, got only %d tests' %\n                    (num, len(testcases))),\n                expected=True)\n\n        self.to_screen('Test URL: %s' % tc['url'])\n\n        return {\n            '_type': 'url',\n            'url': tc['url'],\n            'id': video_id,\n        }",
        "begin_line": 15,
        "end_line": 68,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.livestream.LivestreamIE._extract_video_info#25",
        "src_path": "youtube_dl/extractor/livestream.py",
        "class_name": "youtube_dl.extractor.livestream.LivestreamIE",
        "signature": "youtube_dl.extractor.livestream.LivestreamIE._extract_video_info(self, video_data)",
        "snippet": "    def _extract_video_info(self, video_data):\n        video_url = video_data.get('progressive_url_hd') or video_data.get('progressive_url')\n        return {'id': video_data['id'],\n                'url': video_url,\n                'ext': 'mp4',\n                'title': video_data['caption'],\n                'thumbnail': video_data['thumbnail_url'],\n                'upload_date': video_data['updated_at'].replace('-','')[:8],\n                }",
        "begin_line": 25,
        "end_line": 33,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.livestream.LivestreamIE._real_extract#35",
        "src_path": "youtube_dl/extractor/livestream.py",
        "class_name": "youtube_dl.extractor.livestream.LivestreamIE",
        "signature": "youtube_dl.extractor.livestream.LivestreamIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        event_name = mobj.group('event_name')\n        webpage = self._download_webpage(url, video_id or event_name)\n\n        if video_id is None:\n            # This is an event page:\n            config_json = self._search_regex(r'window.config = ({.*?});',\n                webpage, u'window config')\n            info = json.loads(config_json)['event']\n            videos = [self._extract_video_info(video_data['data'])\n                for video_data in info['feed']['data'] if video_data['type'] == u'video']\n            return self.playlist_result(videos, info['id'], info['full_name'])\n        else:\n            og_video = self._og_search_video_url(webpage, name=u'player url')\n            query_str = compat_urllib_parse_urlparse(og_video).query\n            query = compat_urlparse.parse_qs(query_str)\n            api_url = query['play_url'][0].replace('.smil', '')\n            info = json.loads(self._download_webpage(api_url, video_id,\n                                                     u'Downloading video info'))\n            return self._extract_video_info(info)",
        "begin_line": 35,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.livestream.LivestreamOriginalIE._real_extract#76",
        "src_path": "youtube_dl/extractor/livestream.py",
        "class_name": "youtube_dl.extractor.livestream.LivestreamOriginalIE",
        "signature": "youtube_dl.extractor.livestream.LivestreamOriginalIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        user = mobj.group('user')\n        api_url = 'http://x{0}x.api.channel.livestream.com/2.0/clipdetails?extendedInfo=true&id={1}'.format(user, video_id)\n\n        info = self._download_xml(api_url, video_id)\n        item = info.find('channel').find('item')\n        ns = {'media': 'http://search.yahoo.com/mrss'}\n        thumbnail_url = item.find(xpath_with_ns('media:thumbnail', ns)).attrib['url']\n        # Remove the extension and number from the path (like 1.jpg)\n        path = self._search_regex(r'(user-files/.+)_.*?\\.jpg$', thumbnail_url, u'path')\n\n        return {\n            'id': video_id,\n            'title': item.find('title').text,\n            'url': 'rtmp://extondemand.livestream.com/ondemand',\n            'play_path': 'mp4:trans/dv15/mogulus-{0}.mp4'.format(path),\n            'ext': 'flv',\n            'thumbnail': thumbnail_url,\n        }",
        "begin_line": 76,
        "end_line": 96,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.generic.GenericIE.report_download_webpage#139",
        "src_path": "youtube_dl/extractor/generic.py",
        "class_name": "youtube_dl.extractor.generic.GenericIE",
        "signature": "youtube_dl.extractor.generic.GenericIE.report_download_webpage(self, video_id)",
        "snippet": "    def report_download_webpage(self, video_id):\n        \"\"\"Report webpage download.\"\"\"\n        if not self._downloader.params.get('test', False):\n            self._downloader.report_warning('Falling back on generic information extractor.')\n        super(GenericIE, self).report_download_webpage(video_id)",
        "begin_line": 139,
        "end_line": 143,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.generic.GenericIE.report_following_redirect#145",
        "src_path": "youtube_dl/extractor/generic.py",
        "class_name": "youtube_dl.extractor.generic.GenericIE",
        "signature": "youtube_dl.extractor.generic.GenericIE.report_following_redirect(self, new_url)",
        "snippet": "    def report_following_redirect(self, new_url):\n        \"\"\"Report information extraction.\"\"\"\n        self._downloader.to_screen('[redirect] Following redirect to %s' % new_url)",
        "begin_line": 145,
        "end_line": 147,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.generic.GenericIE._send_head#149",
        "src_path": "youtube_dl/extractor/generic.py",
        "class_name": "youtube_dl.extractor.generic.GenericIE",
        "signature": "youtube_dl.extractor.generic.GenericIE._send_head(self, url)",
        "snippet": "    def _send_head(self, url):\n        \"\"\"Check if it is a redirect, like url shorteners, in case return the new url.\"\"\"\n\n        class HEADRedirectHandler(compat_urllib_request.HTTPRedirectHandler):\n            \"\"\"\n            Subclass the HTTPRedirectHandler to make it use our\n            HEADRequest also on the redirected URL\n            \"\"\"\n            def redirect_request(self, req, fp, code, msg, headers, newurl):\n                if code in (301, 302, 303, 307):\n                    newurl = newurl.replace(' ', '%20')\n                    newheaders = dict((k,v) for k,v in req.headers.items()\n                                      if k.lower() not in (\"content-length\", \"content-type\"))\n                    return HEADRequest(newurl,\n                                       headers=newheaders,\n                                       origin_req_host=req.get_origin_req_host(),\n                                       unverifiable=True)\n                else:\n                    raise compat_urllib_error.HTTPError(req.get_full_url(), code, msg, headers, fp)\n\n        class HTTPMethodFallback(compat_urllib_request.BaseHandler):\n            \"\"\"\n            Fallback to GET if HEAD is not allowed (405 HTTP error)\n            \"\"\"\n            def http_error_405(self, req, fp, code, msg, headers):\n                fp.read()\n                fp.close()\n\n                newheaders = dict((k,v) for k,v in req.headers.items()\n                                  if k.lower() not in (\"content-length\", \"content-type\"))\n                return self.parent.open(compat_urllib_request.Request(req.get_full_url(),\n                                                 headers=newheaders,\n                                                 origin_req_host=req.get_origin_req_host(),\n                                                 unverifiable=True))\n\n        # Build our opener\n        opener = compat_urllib_request.OpenerDirector()\n        for handler in [compat_urllib_request.HTTPHandler, compat_urllib_request.HTTPDefaultErrorHandler,\n                        HTTPMethodFallback, HEADRedirectHandler,\n                        compat_urllib_request.HTTPErrorProcessor, compat_urllib_request.HTTPSHandler]:\n            opener.add_handler(handler())\n\n        response = opener.open(HEADRequest(url))\n        if response is None:\n            raise ExtractorError('Invalid URL protocol')\n        return response",
        "begin_line": 149,
        "end_line": 194,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.generic.GenericIE._extract_rss#196",
        "src_path": "youtube_dl/extractor/generic.py",
        "class_name": "youtube_dl.extractor.generic.GenericIE",
        "signature": "youtube_dl.extractor.generic.GenericIE._extract_rss(self, url, video_id, doc)",
        "snippet": "    def _extract_rss(self, url, video_id, doc):\n        playlist_title = doc.find('./channel/title').text\n        playlist_desc_el = doc.find('./channel/description')\n        playlist_desc = None if playlist_desc_el is None else playlist_desc_el.text\n\n        entries = [{\n            '_type': 'url',\n            'url': e.find('link').text,\n            'title': e.find('title').text,\n        } for e in doc.findall('./channel/item')]\n\n        return {\n            '_type': 'playlist',\n            'id': url,\n            'title': playlist_title,\n            'description': playlist_desc,\n            'entries': entries,\n        }",
        "begin_line": 196,
        "end_line": 213,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.generic.GenericIE._real_extract#215",
        "src_path": "youtube_dl/extractor/generic.py",
        "class_name": "youtube_dl.extractor.generic.GenericIE",
        "signature": "youtube_dl.extractor.generic.GenericIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        parsed_url = compat_urlparse.urlparse(url)\n        if not parsed_url.scheme:\n            default_search = self._downloader.params.get('default_search')\n            if default_search is None:\n                default_search = 'auto'\n\n            if default_search == 'auto':\n                if '/' in url:\n                    self._downloader.report_warning('The url doesn\\'t specify the protocol, trying with http')\n                    return self.url_result('http://' + url)\n                else:\n                    return self.url_result('ytsearch:' + url)\n            else:\n                assert ':' in default_search\n                return self.url_result(default_search + url)\n        video_id = os.path.splitext(url.rstrip('/').split('/')[-1])[0]\n\n        self.to_screen('%s: Requesting header' % video_id)\n\n        try:\n            response = self._send_head(url)\n\n            # Check for redirect\n            new_url = response.geturl()\n            if url != new_url:\n                self.report_following_redirect(new_url)\n                return self.url_result(new_url)\n\n            # Check for direct link to a video\n            content_type = response.headers.get('Content-Type', '')\n            m = re.match(r'^(?P<type>audio|video|application(?=/ogg$))/(?P<format_id>.+)$', content_type)\n            if m:\n                upload_date = response.headers.get('Last-Modified')\n                if upload_date:\n                    upload_date = unified_strdate(upload_date)\n                return {\n                    'id': video_id,\n                    'title': os.path.splitext(url_basename(url))[0],\n                    'formats': [{\n                        'format_id': m.group('format_id'),\n                        'url': url,\n                        'vcodec': 'none' if m.group('type') == 'audio' else None\n                    }],\n                    'upload_date': upload_date,\n                }\n\n        except compat_urllib_error.HTTPError:\n            # This may be a stupid server that doesn't like HEAD, our UA, or so\n            pass\n\n        try:\n            webpage = self._download_webpage(url, video_id)\n        except ValueError:\n            # since this is the last-resort InfoExtractor, if\n            # this error is thrown, it'll be thrown here\n            raise ExtractorError('Failed to download URL: %s' % url)\n\n        self.report_extraction(video_id)\n\n        # Is it an RSS feed?\n        try:\n            doc = xml.etree.ElementTree.fromstring(webpage.encode('utf-8'))\n            if doc.tag == 'rss':\n                return self._extract_rss(url, video_id, doc)\n        except compat_xml_parse_error:\n            pass\n\n        # it's tempting to parse this further, but you would\n        # have to take into account all the variations like\n        #   Video Title - Site Name\n        #   Site Name | Video Title\n        #   Video Title - Tagline | Site Name\n        # and so on and so forth; it's just not practical\n        video_title = self._html_search_regex(\n            r'(?s)<title>(.*?)</title>', webpage, 'video title',\n            default='video')\n\n        # video uploader is domain name\n        video_uploader = self._search_regex(\n            r'^(?:https?://)?([^/]*)/.*', url, 'video uploader')\n\n        # Look for BrightCove:\n        bc_urls = BrightcoveIE._extract_brightcove_urls(webpage)\n        if bc_urls:\n            self.to_screen('Brightcove video detected.')\n            entries = [{\n                '_type': 'url',\n                'url': smuggle_url(bc_url, {'Referer': url}),\n                'ie_key': 'Brightcove'\n            } for bc_url in bc_urls]\n\n            return {\n                '_type': 'playlist',\n                'title': video_title,\n                'id': video_id,\n                'entries': entries,\n            }\n\n        # Look for embedded (iframe) Vimeo player\n        mobj = re.search(\n            r'<iframe[^>]+?src=\"((?:https?:)?//player\\.vimeo\\.com/video/.+?)\"', webpage)\n        if mobj:\n            player_url = unescapeHTML(mobj.group(1))\n            surl = smuggle_url(player_url, {'Referer': url})\n            return self.url_result(surl, 'Vimeo')\n\n        # Look for embedded (swf embed) Vimeo player\n        mobj = re.search(\n            r'<embed[^>]+?src=\"(https?://(?:www\\.)?vimeo\\.com/moogaloop\\.swf.+?)\"', webpage)\n        if mobj:\n            return self.url_result(mobj.group(1), 'Vimeo')\n\n        # Look for embedded YouTube player\n        matches = re.findall(r'''(?x)\n            (?:<iframe[^>]+?src=|embedSWF\\(\\s*)\n            ([\"\\'])(?P<url>(?:https?:)?//(?:www\\.)?youtube\\.com/\n                (?:embed|v)/.+?)\n            \\1''', webpage)\n        if matches:\n            urlrs = [self.url_result(unescapeHTML(tuppl[1]), 'Youtube')\n                     for tuppl in matches]\n            return self.playlist_result(\n                urlrs, playlist_id=video_id, playlist_title=video_title)\n\n        # Look for embedded Dailymotion player\n        matches = re.findall(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//(?:www\\.)?dailymotion\\.com/embed/video/.+?)\\1', webpage)\n        if matches:\n            urlrs = [self.url_result(unescapeHTML(tuppl[1]), 'Dailymotion')\n                     for tuppl in matches]\n            return self.playlist_result(\n                urlrs, playlist_id=video_id, playlist_title=video_title)\n\n        # Look for embedded Wistia player\n        match = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//(?:fast\\.)?wistia\\.net/embed/iframe/.+?)\\1', webpage)\n        if match:\n            return {\n                '_type': 'url_transparent',\n                'url': unescapeHTML(match.group('url')),\n                'ie_key': 'Wistia',\n                'uploader': video_uploader,\n                'title': video_title,\n                'id': video_id,\n            }\n\n        # Look for embedded blip.tv player\n        mobj = re.search(r'<meta\\s[^>]*https?://api\\.blip\\.tv/\\w+/redirect/\\w+/(\\d+)', webpage)\n        if mobj:\n            return self.url_result('http://blip.tv/a/a-'+mobj.group(1), 'BlipTV')\n        mobj = re.search(r'<(?:iframe|embed|object)\\s[^>]*(https?://(?:\\w+\\.)?blip\\.tv/(?:play/|api\\.swf#)[a-zA-Z0-9]+)', webpage)\n        if mobj:\n            return self.url_result(mobj.group(1), 'BlipTV')\n\n        # Look for Bandcamp pages with custom domain\n        mobj = re.search(r'<meta property=\"og:url\"[^>]*?content=\"(.*?bandcamp\\.com.*?)\"', webpage)\n        if mobj is not None:\n            burl = unescapeHTML(mobj.group(1))\n            # Don't set the extractor because it can be a track url or an album\n            return self.url_result(burl)\n\n        # Look for embedded Vevo player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//(?:cache\\.)?vevo\\.com/.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'))\n\n        # Look for Ooyala videos\n        mobj = re.search(r'player.ooyala.com/[^\"?]+\\?[^\"]*?(?:embedCode|ec)=([^\"&]+)', webpage)\n        if mobj is not None:\n            return OoyalaIE._build_url_result(mobj.group(1))\n\n        # Look for Aparat videos\n        mobj = re.search(r'<iframe src=\"(http://www\\.aparat\\.com/video/[^\"]+)\"', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group(1), 'Aparat')\n\n        # Look for MPORA videos\n        mobj = re.search(r'<iframe .*?src=\"(http://mpora\\.(?:com|de)/videos/[^\"]+)\"', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group(1), 'Mpora')\n\n        # Look for embedded NovaMov player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>http://(?:(?:embed|www)\\.)?novamov\\.com/embed\\.php.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'NovaMov')\n\n        # Look for embedded NowVideo player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>http://(?:(?:embed|www)\\.)?nowvideo\\.(?:ch|sx|eu)/embed\\.php.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'NowVideo')\n\n        # Look for embedded Facebook player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>https://www\\.facebook\\.com/video/embed.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'Facebook')\n\n        # Look for embedded VK player\n        mobj = re.search(r'<iframe[^>]+?src=([\"\\'])(?P<url>https?://vk\\.com/video_ext\\.php.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'VK')\n\n        # Look for embedded Huffington Post player\n        mobj = re.search(\n            r'<iframe[^>]+?src=([\"\\'])(?P<url>https?://embed\\.live\\.huffingtonpost\\.com/.+?)\\1', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'), 'HuffPost')\n\n        # Look for embed.ly\n        mobj = re.search(r'class=[\"\\']embedly-card[\"\\'][^>]href=[\"\\'](?P<url>[^\"\\']+)', webpage)\n        if mobj is not None:\n            return self.url_result(mobj.group('url'))\n        mobj = re.search(r'class=[\"\\']embedly-embed[\"\\'][^>]src=[\"\\'][^\"\\']*url=(?P<url>[^&]+)', webpage)\n        if mobj is not None:\n            return self.url_result(compat_urllib_parse.unquote(mobj.group('url')))\n\n        # Start with something easy: JW Player in SWFObject\n        mobj = re.search(r'flashvars: [\\'\"](?:.*&)?file=(http[^\\'\"&]*)', webpage)\n        if mobj is None:\n            # Look for gorilla-vid style embedding\n            mobj = re.search(r'(?s)(?:jw_plugins|JWPlayerOptions).*?file\\s*:\\s*[\"\\'](.*?)[\"\\']', webpage)\n        if mobj is None:\n            # Broaden the search a little bit\n            mobj = re.search(r'[^A-Za-z0-9]?(?:file|source)=(http[^\\'\"&]*)', webpage)\n        if mobj is None:\n            # Broaden the search a little bit: JWPlayer JS loader\n            mobj = re.search(r'[^A-Za-z0-9]?file[\"\\']?:\\s*[\"\\'](http(?![^\\'\"]+\\.[0-9]+[\\'\"])[^\\'\"]+)[\"\\']', webpage)\n        if mobj is None:\n            # Try to find twitter cards info\n            mobj = re.search(r'<meta (?:property|name)=\"twitter:player:stream\" (?:content|value)=\"(.+?)\"', webpage)\n        if mobj is None:\n            # We look for Open Graph info:\n            # We have to match any number spaces between elements, some sites try to align them (eg.: statigr.am)\n            m_video_type = re.search(r'<meta.*?property=\"og:video:type\".*?content=\"video/(.*?)\"', webpage)\n            # We only look in og:video if the MIME type is a video, don't try if it's a Flash player:\n            if m_video_type is not None:\n                mobj = re.search(r'<meta.*?property=\"og:video\".*?content=\"(.*?)\"', webpage)\n        if mobj is None:\n            # HTML5 video\n            mobj = re.search(r'<video[^<]*(?:>.*?<source.*?)? src=\"([^\"]+)\"', webpage, flags=re.DOTALL)\n        if mobj is None:\n            mobj = re.search(\n                r'(?i)<meta\\s+(?=(?:[a-z-]+=\"[^\"]+\"\\s+)*http-equiv=\"refresh\")'\n                r'(?:[a-z-]+=\"[^\"]+\"\\s+)*?content=\"[0-9]{,2};url=\\'([^\\']+)\\'\"',\n                webpage)\n            if mobj:\n                new_url = mobj.group(1)\n                self.report_following_redirect(new_url)\n                return {\n                    '_type': 'url',\n                    'url': new_url,\n                }\n        if mobj is None:\n            raise ExtractorError('Unsupported URL: %s' % url)\n\n        # It's possible that one of the regexes\n        # matched, but returned an empty group:\n        if mobj.group(1) is None:\n            raise ExtractorError('Did not find a valid video URL at %s' % url)\n\n        video_url = mobj.group(1)\n        video_url = compat_urlparse.urljoin(url, video_url)\n        video_id = compat_urllib_parse.unquote(os.path.basename(video_url))\n\n        # Sometimes, jwplayer extraction will result in a YouTube URL\n        if YoutubeIE.suitable(video_url):\n            return self.url_result(video_url, 'Youtube')\n\n        # here's a fun little line of code for you:\n        video_id = os.path.splitext(video_id)[0]\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'uploader': video_uploader,\n            'title': video_title,\n        }",
        "begin_line": 215,
        "end_line": 495,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.escapist.EscapistIE._real_extract#27",
        "src_path": "youtube_dl/extractor/escapist.py",
        "class_name": "youtube_dl.extractor.escapist.EscapistIE",
        "signature": "youtube_dl.extractor.escapist.EscapistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        showName = mobj.group('showname')\n        video_id = mobj.group('id')\n\n        self.report_extraction(video_id)\n        webpage = self._download_webpage(url, video_id)\n\n        videoDesc = self._html_search_regex(\n            r'<meta name=\"description\" content=\"([^\"]*)\"',\n            webpage, 'description', fatal=False)\n\n        playerUrl = self._og_search_video_url(webpage, name=u'player URL')\n\n        title = self._html_search_regex(\n            r'<meta name=\"title\" content=\"([^\"]*)\"',\n            webpage, 'title').split(' : ')[-1]\n\n        configUrl = self._search_regex('config=(.*)$', playerUrl, 'config URL')\n        configUrl = compat_urllib_parse.unquote(configUrl)\n\n        formats = []\n\n        def _add_format(name, cfgurl, quality):\n            config = self._download_json(\n                cfgurl, video_id,\n                'Downloading ' + name + ' configuration',\n                'Unable to download ' + name + ' configuration',\n                transform_source=lambda s: s.replace(\"'\", '\"'))\n\n            playlist = config['playlist']\n            formats.append({\n                'url': playlist[1]['url'],\n                'format_id': name,\n                'quality': quality,\n            })\n\n        _add_format('normal', configUrl, quality=0)\n        hq_url = (configUrl +\n                  ('&hq=1' if '?' in configUrl else configUrl + '?hq=1'))\n        try:\n            _add_format('hq', hq_url, quality=1)\n        except ExtractorError:\n            pass  # That's fine, we'll just use normal quality\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'uploader': showName,\n            'title': title,\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'description': videoDesc,\n            'player_url': playerUrl,\n        }",
        "begin_line": 27,
        "end_line": 82,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionIE._real_extract#81",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionIE",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        # Extract id and simplified title from URL\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n\n        url = 'http://www.dailymotion.com/video/%s' % video_id\n\n        # Retrieve video webpage to extract further information\n        request = self._build_request(url)\n        webpage = self._download_webpage(request, video_id)\n\n        # Extract URL, uploader and title from webpage\n        self.report_extraction(video_id)\n\n        # It may just embed a vevo video:\n        m_vevo = re.search(\n            r'<link rel=\"video_src\" href=\"[^\"]*?vevo.com[^\"]*?videoId=(?P<id>[\\w]*)',\n            webpage)\n        if m_vevo is not None:\n            vevo_id = m_vevo.group('id')\n            self.to_screen(u'Vevo video detected: %s' % vevo_id)\n            return self.url_result(u'vevo:%s' % vevo_id, ie='Vevo')\n\n        age_limit = self._rta_search(webpage)\n\n        video_upload_date = None\n        mobj = re.search(r'<div class=\"[^\"]*uploaded_cont[^\"]*\" title=\"[^\"]*\">([0-9]{2})-([0-9]{2})-([0-9]{4})</div>', webpage)\n        if mobj is not None:\n            video_upload_date = mobj.group(3) + mobj.group(2) + mobj.group(1)\n\n        embed_url = 'http://www.dailymotion.com/embed/video/%s' % video_id\n        embed_page = self._download_webpage(embed_url, video_id,\n                                            u'Downloading embed page')\n        info = self._search_regex(r'var info = ({.*?}),$', embed_page,\n            'video info', flags=re.MULTILINE)\n        info = json.loads(info)\n        if info.get('error') is not None:\n            msg = 'Couldn\\'t get video, Dailymotion says: %s' % info['error']['title']\n            raise ExtractorError(msg, expected=True)\n\n        formats = []\n        for (key, format_id) in self._FORMATS:\n            video_url = info.get(key)\n            if video_url is not None:\n                m_size = re.search(r'H264-(\\d+)x(\\d+)', video_url)\n                if m_size is not None:\n                    width, height = map(int_or_none, (m_size.group(1), m_size.group(2)))\n                else:\n                    width, height = None, None\n                formats.append({\n                    'url': video_url,\n                    'ext': 'mp4',\n                    'format_id': format_id,\n                    'width': width,\n                    'height': height,\n                })\n        if not formats:\n            raise ExtractorError(u'Unable to extract video URL')\n\n        # subtitles\n        video_subtitles = self.extract_subtitles(video_id, webpage)\n        if self._downloader.params.get('listsubtitles', False):\n            self._list_available_subtitles(video_id, webpage)\n            return\n\n        view_count = self._search_regex(\n            r'video_views_count[^>]+>\\s+([\\d\\.,]+)', webpage, u'view count', fatal=False)\n        if view_count is not None:\n            view_count = str_to_int(view_count)\n\n        return {\n            'id':       video_id,\n            'formats': formats,\n            'uploader': info['owner_screenname'],\n            'upload_date':  video_upload_date,\n            'title':    self._og_search_title(webpage),\n            'subtitles':    video_subtitles,\n            'thumbnail': info['thumbnail_url'],\n            'age_limit': age_limit,\n            'view_count': view_count,\n        }",
        "begin_line": 81,
        "end_line": 162,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionIE._get_available_subtitles#164",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionIE",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionIE._get_available_subtitles(self, video_id, webpage)",
        "snippet": "    def _get_available_subtitles(self, video_id, webpage):\n        try:\n            sub_list = self._download_webpage(\n                'https://api.dailymotion.com/video/%s/subtitles?fields=id,language,url' % video_id,\n                video_id, note=False)\n        except ExtractorError as err:\n            self._downloader.report_warning(u'unable to download video subtitles: %s' % compat_str(err))\n            return {}\n        info = json.loads(sub_list)\n        if (info['total'] > 0):\n            sub_lang_list = dict((l['language'], l['url']) for l in info['list'])\n            return sub_lang_list\n        self._downloader.report_warning(u'video doesn\\'t have subtitles')\n        return {}",
        "begin_line": 164,
        "end_line": 177,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionPlaylistIE._extract_entries#186",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionPlaylistIE",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionPlaylistIE._extract_entries(self, id)",
        "snippet": "    def _extract_entries(self, id):\n        video_ids = []\n        for pagenum in itertools.count(1):\n            request = self._build_request(self._PAGE_TEMPLATE % (id, pagenum))\n            webpage = self._download_webpage(request,\n                                             id, u'Downloading page %s' % pagenum)\n\n            playlist_el = get_element_by_attribute(u'class', u'row video_list', webpage)\n            video_ids.extend(re.findall(r'data-id=\"(.+?)\"', playlist_el))\n\n            if re.search(self._MORE_PAGES_INDICATOR, webpage, re.DOTALL) is None:\n                break\n        return [self.url_result('http://www.dailymotion.com/video/%s' % video_id, 'Dailymotion')\n                   for video_id in orderedSet(video_ids)]",
        "begin_line": 186,
        "end_line": 199,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionPlaylistIE._real_extract#201",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionPlaylistIE",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionPlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('id')\n        webpage = self._download_webpage(url, playlist_id)\n\n        return {'_type': 'playlist',\n                'id': playlist_id,\n                'title': get_element_by_id(u'playlist_name', webpage),\n                'entries': self._extract_entries(playlist_id),\n                }",
        "begin_line": 201,
        "end_line": 210,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.dailymotion.DailymotionUserIE._real_extract#219",
        "src_path": "youtube_dl/extractor/dailymotion.py",
        "class_name": "youtube_dl.extractor.dailymotion.DailymotionUserIE",
        "signature": "youtube_dl.extractor.dailymotion.DailymotionUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        user = mobj.group('user')\n        webpage = self._download_webpage(url, user)\n        full_user = self._html_search_regex(\n            r'<a class=\"label\" href=\"/%s\".*?>(.*?)</' % re.escape(user),\n            webpage, u'user', flags=re.DOTALL)\n\n        return {\n            '_type': 'playlist',\n            'id': user,\n            'title': full_user,\n            'entries': self._extract_entries(user),\n        }",
        "begin_line": 219,
        "end_line": 232,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.videopremium.VideoPremiumIE._real_extract#21",
        "src_path": "youtube_dl/extractor/videopremium.py",
        "class_name": "youtube_dl.extractor.videopremium.VideoPremiumIE",
        "signature": "youtube_dl.extractor.videopremium.VideoPremiumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n        webpage_url = 'http://videopremium.tv/' + video_id\n        webpage = self._download_webpage(webpage_url, video_id)\n\n        if re.match(r\"^<html><head><script[^>]*>window.location\\s*=\", webpage):\n            # Download again, we need a cookie\n            webpage = self._download_webpage(\n                webpage_url, video_id,\n                note=u'Downloading webpage again (with cookie)')\n\n        video_title = self._html_search_regex(\n            r'<h2(?:.*?)>\\s*(.+?)\\s*<', webpage, u'video title')\n\n        return {\n            'id':          video_id,\n            'url':         \"rtmp://e%d.md.iplay.md/play\" % random.randint(1, 16),\n            'play_path':   \"mp4:%s.f4v\" % video_id,\n            'page_url':    \"http://videopremium.tv/\" + video_id,\n            'player_url':  \"http://videopremium.tv/uplayer/uppod.swf\",\n            'ext':         'f4v',\n            'title':       video_title,\n        }",
        "begin_line": 21,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.zdf.ZDFIE._real_extract#31",
        "src_path": "youtube_dl/extractor/zdf.py",
        "class_name": "youtube_dl.extractor.zdf.ZDFIE",
        "signature": "youtube_dl.extractor.zdf.ZDFIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('video_id')\n\n        xml_url = 'http://www.zdf.de/ZDFmediathek/xmlservice/web/beitragsDetails?ak=web&id=%s' % video_id\n        doc = self._download_xml(\n            xml_url, video_id,\n            note='Downloading video info',\n            errnote='Failed to download video info')\n\n        title = doc.find('.//information/title').text\n        description = doc.find('.//information/detail').text\n        duration = int(doc.find('.//details/lengthSec').text)\n        uploader_node = doc.find('.//details/originChannelTitle')\n        uploader = None if uploader_node is None else uploader_node.text\n        uploader_id_node = doc.find('.//details/originChannelId')\n        uploader_id = None if uploader_id_node is None else uploader_id_node.text\n        upload_date = unified_strdate(doc.find('.//details/airtime').text)\n\n        def xml_to_format(fnode):\n            video_url = fnode.find('url').text\n            is_available = 'http://www.metafilegenerator' not in video_url\n\n            format_id = fnode.attrib['basetype']\n            format_m = re.match(r'''(?x)\n                (?P<vcodec>[^_]+)_(?P<acodec>[^_]+)_(?P<container>[^_]+)_\n                (?P<proto>[^_]+)_(?P<index>[^_]+)_(?P<indexproto>[^_]+)\n            ''', format_id)\n\n            ext = format_m.group('container')\n            proto = format_m.group('proto').lower()\n\n            quality = fnode.find('./quality').text\n            abr = int(fnode.find('./audioBitrate').text) // 1000\n            vbr_node = fnode.find('./videoBitrate')\n            vbr = None if vbr_node is None else int(vbr_node.text) // 1000\n\n            width_node = fnode.find('./width')\n            width = None if width_node is None else int_or_none(width_node.text)\n            height_node = fnode.find('./height')\n            height = None if height_node is None else int_or_none(height_node.text)\n\n            format_note = ''\n            if not format_note:\n                format_note = None\n\n            return {\n                'format_id': format_id + '-' + quality,\n                'url': video_url,\n                'ext': ext,\n                'acodec': format_m.group('acodec'),\n                'vcodec': format_m.group('vcodec'),\n                'abr': abr,\n                'vbr': vbr,\n                'width': width,\n                'height': height,\n                'filesize': int_or_none(fnode.find('./filesize').text),\n                'format_note': format_note,\n                'protocol': proto,\n                '_available': is_available,\n            }\n\n        format_nodes = doc.findall('.//formitaeten/formitaet')\n        formats = list(filter(\n            lambda f: f['_available'],\n            map(xml_to_format, format_nodes)))\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'upload_date': upload_date,\n            'formats': formats,\n        }",
        "begin_line": 31,
        "end_line": 109,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.malemotion.MalemotionIE._real_extract#23",
        "src_path": "youtube_dl/extractor/malemotion.py",
        "class_name": "youtube_dl.extractor.malemotion.MalemotionIE",
        "signature": "youtube_dl.extractor.malemotion.MalemotionIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group(\"id\")\n\n        webpage = self._download_webpage(url, video_id)\n\n        self.report_extraction(video_id)\n\n        # Extract video URL\n        video_url = compat_urllib_parse.unquote(\n            self._search_regex(r'<source type=\"video/mp4\" src=\"(.+?)\"', webpage, 'video URL'))\n\n        # Extract title\n        video_title = self._html_search_regex(\n            r'<title>(.*?)</title', webpage, 'title')\n\n        # Extract video thumbnail\n        video_thumbnail = self._search_regex(\n            r'<video .+?poster=\"(.+?)\"', webpage, 'thumbnail', fatal=False)\n\n        formats = [{\n            'url': video_url,\n            'ext': 'mp4',\n            'format_id': 'mp4',\n            'preference': 1,\n        }]\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'uploader': None,\n            'upload_date': None,\n            'title': video_title,\n            'thumbnail': video_thumbnail,\n            'description': None,\n            'age_limit': 18,\n        }",
        "begin_line": 23,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.ebaumsworld.EbaumsWorldIE._real_extract#20",
        "src_path": "youtube_dl/extractor/ebaumsworld.py",
        "class_name": "youtube_dl.extractor.ebaumsworld.EbaumsWorldIE",
        "signature": "youtube_dl.extractor.ebaumsworld.EbaumsWorldIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        config = self._download_xml(\n            'http://www.ebaumsworld.com/video/player/%s' % video_id, video_id)\n        video_url = config.find('file').text\n\n        return {\n            'id': video_id,\n            'title': config.find('title').text,\n            'url': video_url,\n            'ext': determine_ext(video_url),\n            'description': config.find('description').text,\n            'thumbnail': config.find('image').text,\n            'uploader': config.find('username').text,\n        }",
        "begin_line": 20,
        "end_line": 35,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.ehow.EHowIE._real_extract#24",
        "src_path": "youtube_dl/extractor/ehow.py",
        "class_name": "youtube_dl.extractor.ehow.EHowIE",
        "signature": "youtube_dl.extractor.ehow.EHowIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        video_url = self._search_regex(r'(?:file|source)=(http[^\\'\"&]*)',\n            webpage, u'video URL')\n        final_url = compat_urllib_parse.unquote(video_url)        \n        uploader = self._search_regex(r'<meta name=\"uploader\" content=\"(.+?)\" />',\n            webpage, u'uploader')\n        title = self._og_search_title(webpage).replace(' | eHow', '')\n        ext = determine_ext(final_url)\n\n        return {\n            '_type':       'video',\n            'id':          video_id,\n            'url':         final_url,\n            'ext':         ext,\n            'title':       title,\n            'thumbnail':   self._og_search_thumbnail(webpage),\n            'description': self._og_search_description(webpage),\n            'uploader':    uploader,\n        }",
        "begin_line": 24,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.steam.SteamIE.suitable#43",
        "src_path": "youtube_dl/extractor/steam.py",
        "class_name": "youtube_dl.extractor.steam.SteamIE",
        "signature": "youtube_dl.extractor.steam.SteamIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        \"\"\"Receives a URL and returns True if suitable for this IE.\"\"\"\n        return re.match(cls._VALID_URL, url, re.VERBOSE) is not None",
        "begin_line": 43,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0001584786053882726,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.steam.SteamIE._real_extract#47",
        "src_path": "youtube_dl/extractor/steam.py",
        "class_name": "youtube_dl.extractor.steam.SteamIE",
        "signature": "youtube_dl.extractor.steam.SteamIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url, re.VERBOSE)\n        gameID = m.group('gameID')\n\n        videourl = self._VIDEO_PAGE_TEMPLATE % gameID\n        webpage = self._download_webpage(videourl, gameID)\n\n        if re.search('<h2>Please enter your birth date to continue:</h2>', webpage) is not None:\n            videourl = self._AGECHECK_TEMPLATE % gameID\n            self.report_age_confirmation()\n            webpage = self._download_webpage(videourl, gameID)\n\n        self.report_extraction(gameID)\n        game_title = self._html_search_regex(r'<h2 class=\"pageheader\">(.*?)</h2>',\n                                             webpage, 'game title')\n\n        urlRE = r\"'movie_(?P<videoID>\\d+)': \\{\\s*FILENAME: \\\"(?P<videoURL>[\\w:/\\.\\?=]+)\\\"(,\\s*MOVIE_NAME: \\\"(?P<videoName>[\\w:/\\.\\?=\\+-]+)\\\")?\\s*\\},\"\n        mweb = re.finditer(urlRE, webpage)\n        namesRE = r'<span class=\"title\">(?P<videoName>.+?)</span>'\n        titles = re.finditer(namesRE, webpage)\n        thumbsRE = r'<img class=\"movie_thumb\" src=\"(?P<thumbnail>.+?)\">'\n        thumbs = re.finditer(thumbsRE, webpage)\n        videos = []\n        for vid,vtitle,thumb in zip(mweb,titles,thumbs):\n            video_id = vid.group('videoID')\n            title = vtitle.group('videoName')\n            video_url = vid.group('videoURL')\n            video_thumb = thumb.group('thumbnail')\n            if not video_url:\n                raise ExtractorError(u'Cannot find video url for %s' % video_id)\n            info = {\n                'id':video_id,\n                'url':video_url,\n                'ext': 'flv',\n                'title': unescapeHTML(title),\n                'thumbnail': video_thumb\n                  }\n            videos.append(info)\n        return [self.playlist_result(videos, gameID, game_title)]",
        "begin_line": 47,
        "end_line": 85,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.auengine.AUEngineIE._real_extract#24",
        "src_path": "youtube_dl/extractor/auengine.py",
        "class_name": "youtube_dl.extractor.auengine.AUEngineIE",
        "signature": "youtube_dl.extractor.auengine.AUEngineIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group(1)\n        webpage = self._download_webpage(url, video_id)\n        title = self._html_search_regex(r'<title>(?P<title>.+?)</title>',\n                webpage, 'title')\n        title = title.strip()\n        links = re.findall(r'\\s(?:file|url):\\s*[\"\\']([^\\'\"]+)[\"\\']', webpage)\n        links = map(compat_urllib_parse.unquote, links)\n\n        thumbnail = None\n        video_url = None\n        for link in links:\n            if link.endswith('.png'):\n                thumbnail = link\n            elif '/videos/' in link:\n                video_url = link\n        if not video_url:\n            raise ExtractorError(u'Could not find video URL')\n        ext = '.' + determine_ext(video_url)\n        if ext == title[-len(ext):]:\n            title = title[:-len(ext)]\n\n        return {\n            'id':        video_id,\n            'url':       video_url,\n            'title':     title,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 24,
        "end_line": 52,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.savefrom.SaveFromIE._real_extract#30",
        "src_path": "youtube_dl/extractor/savefrom.py",
        "class_name": "youtube_dl.extractor.savefrom.SaveFromIE",
        "signature": "youtube_dl.extractor.savefrom.SaveFromIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = os.path.splitext(url.split('/')[-1])[0]\n        return {\n            '_type': 'url',\n            'id': video_id,\n            'url': mobj.group('url'),\n        }",
        "begin_line": 30,
        "end_line": 37,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.ooyala.OoyalaIE._extract_result#30",
        "src_path": "youtube_dl/extractor/ooyala.py",
        "class_name": "youtube_dl.extractor.ooyala.OoyalaIE",
        "signature": "youtube_dl.extractor.ooyala.OoyalaIE._extract_result(self, info, more_info)",
        "snippet": "    def _extract_result(self, info, more_info):\n        return {'id': info['embedCode'],\n                'ext': 'mp4',\n                'title': unescapeHTML(info['title']),\n                'url': info.get('ipad_url') or info['url'],\n                'description': unescapeHTML(more_info['description']),\n                'thumbnail': more_info['promo'],\n                }",
        "begin_line": 30,
        "end_line": 37,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.ooyala.OoyalaIE._real_extract#39",
        "src_path": "youtube_dl/extractor/ooyala.py",
        "class_name": "youtube_dl.extractor.ooyala.OoyalaIE",
        "signature": "youtube_dl.extractor.ooyala.OoyalaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        embedCode = mobj.group('id')\n        player_url = 'http://player.ooyala.com/player.js?embedCode=%s' % embedCode\n        player = self._download_webpage(player_url, embedCode)\n        mobile_url = self._search_regex(r'mobile_player_url=\"(.+?)&device=\"',\n                                        player, u'mobile player url')\n        mobile_player = self._download_webpage(mobile_url, embedCode)\n        videos_info = self._search_regex(\n            r'var streams=window.oo_testEnv\\?\\[\\]:eval\\(\"\\((\\[{.*?}\\])\\)\"\\);',\n            mobile_player, u'info').replace('\\\\\"','\"')\n        videos_more_info = self._search_regex(r'eval\\(\"\\(({.*?\\\\\"promo\\\\\".*?})\\)\"', mobile_player, u'more info').replace('\\\\\"','\"')\n        videos_info = json.loads(videos_info)\n        videos_more_info =json.loads(videos_more_info)\n\n        if videos_more_info.get('lineup'):\n            videos = [self._extract_result(info, more_info) for (info, more_info) in zip(videos_info, videos_more_info['lineup'])]\n            return {'_type': 'playlist',\n                    'id': embedCode,\n                    'title': unescapeHTML(videos_more_info['title']),\n                    'entries': videos,\n                    }\n        else:\n            return self._extract_result(videos_info[0], videos_more_info)",
        "begin_line": 39,
        "end_line": 62,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.condenast.CondeNastIE._extract_series#46",
        "src_path": "youtube_dl/extractor/condenast.py",
        "class_name": "youtube_dl.extractor.condenast.CondeNastIE",
        "signature": "youtube_dl.extractor.condenast.CondeNastIE._extract_series(self, url, webpage)",
        "snippet": "    def _extract_series(self, url, webpage):\n        title = self._html_search_regex(r'<div class=\"cne-series-info\">.*?<h1>(.+?)</h1>',\n                                        webpage, 'series title', flags=re.DOTALL)\n        url_object = compat_urllib_parse_urlparse(url)\n        base_url = '%s://%s' % (url_object.scheme, url_object.netloc)\n        m_paths = re.finditer(r'<p class=\"cne-thumb-title\">.*?<a href=\"(/watch/.+?)[\"\\?]',\n                              webpage, flags=re.DOTALL)\n        paths = orderedSet(m.group(1) for m in m_paths)\n        build_url = lambda path: compat_urlparse.urljoin(base_url, path)\n        entries = [self.url_result(build_url(path), 'CondeNast') for path in paths]\n        return self.playlist_result(entries, playlist_title=title)",
        "begin_line": 46,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.condenast.CondeNastIE._extract_video#58",
        "src_path": "youtube_dl/extractor/condenast.py",
        "class_name": "youtube_dl.extractor.condenast.CondeNastIE",
        "signature": "youtube_dl.extractor.condenast.CondeNastIE._extract_video(self, webpage)",
        "snippet": "    def _extract_video(self, webpage):\n        description = self._html_search_regex([r'<div class=\"cne-video-description\">(.+?)</div>',\n                                               r'<div class=\"video-post-content\">(.+?)</div>',\n                                               ],\n                                              webpage, 'description',\n                                              fatal=False, flags=re.DOTALL)\n        params = self._search_regex(r'var params = {(.+?)}[;,]', webpage,\n                                    'player params', flags=re.DOTALL)\n        video_id = self._search_regex(r'videoId: [\\'\"](.+?)[\\'\"]', params, 'video id')\n        player_id = self._search_regex(r'playerId: [\\'\"](.+?)[\\'\"]', params, 'player id')\n        target = self._search_regex(r'target: [\\'\"](.+?)[\\'\"]', params, 'target')\n        data = compat_urllib_parse.urlencode({'videoId': video_id,\n                                              'playerId': player_id,\n                                              'target': target,\n                                              })\n        base_info_url = self._search_regex(r'url = [\\'\"](.+?)[\\'\"][,;]',\n                                           webpage, 'base info url',\n                                           default='http://player.cnevids.com/player/loader.js?')\n        info_url = base_info_url + data\n        info_page = self._download_webpage(info_url, video_id,\n                                           'Downloading video info')\n        video_info = self._search_regex(r'var video = ({.+?});', info_page, 'video info')\n        video_info = json.loads(video_info)\n\n        formats = [{\n            'format_id': '%s-%s' % (fdata['type'].split('/')[-1], fdata['quality']),\n            'url': fdata['src'],\n            'ext': fdata['type'].split('/')[-1],\n            'quality': 1 if fdata['quality'] == 'high' else 0,\n        } for fdata in video_info['sources'][0]]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': video_info['title'],\n            'thumbnail': video_info['poster_frame'],\n            'description': description,\n        }",
        "begin_line": 58,
        "end_line": 96,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.condenast.CondeNastIE._real_extract#98",
        "src_path": "youtube_dl/extractor/condenast.py",
        "class_name": "youtube_dl.extractor.condenast.CondeNastIE",
        "signature": "youtube_dl.extractor.condenast.CondeNastIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        site = mobj.group('site')\n        url_type = mobj.group('type')\n        id = mobj.group('id')\n\n        self.to_screen(u'Extracting from %s with the Cond\u00e9 Nast extractor' % self._SITES[site])\n        webpage = self._download_webpage(url, id)\n\n        if url_type == 'series':\n            return self._extract_series(url, webpage)\n        else:\n            return self._extract_video(webpage)",
        "begin_line": 98,
        "end_line": 110,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.lynda.LyndaIE._real_initialize#38",
        "src_path": "youtube_dl/extractor/lynda.py",
        "class_name": "youtube_dl.extractor.lynda.LyndaIE",
        "signature": "youtube_dl.extractor.lynda.LyndaIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 38,
        "end_line": 39,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.lynda.LyndaIE._real_extract#41",
        "src_path": "youtube_dl/extractor/lynda.py",
        "class_name": "youtube_dl.extractor.lynda.LyndaIE",
        "signature": "youtube_dl.extractor.lynda.LyndaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group(1)\n\n        page = self._download_webpage('http://www.lynda.com/ajax/player?videoId=%s&type=video' % video_id,\n                                      video_id, 'Downloading video JSON')\n        video_json = json.loads(page)\n\n        if 'Status' in video_json:\n            raise ExtractorError('lynda returned error: %s' % video_json['Message'], expected=True)\n\n        if video_json['HasAccess'] is False:\n            raise ExtractorError('Video %s is only available for members. ' % video_id + self.ACCOUNT_CREDENTIALS_HINT, expected=True)\n\n        video_id = video_json['ID']\n        duration = video_json['DurationInSeconds']\n        title = video_json['Title']\n\n        formats = []\n\n        fmts = video_json.get('Formats')\n        if fmts:\n            formats.extend([\n                {\n                    'url': fmt['Url'],\n                    'ext': fmt['Extension'],\n                    'width': fmt['Width'],\n                    'height': fmt['Height'],\n                    'filesize': fmt['FileSize'],\n                    'format_id': str(fmt['Resolution'])\n                } for fmt in fmts])\n\n        prioritized_streams = video_json.get('PrioritizedStreams')\n        if prioritized_streams:\n            formats.extend([\n                {\n                    'url': video_url,\n                    'width': int_or_none(format_id),\n                    'format_id': format_id,\n                } for format_id, video_url in prioritized_streams['0'].items()\n            ])\n\n        self._sort_formats(formats)\n\n        if self._downloader.params.get('listsubtitles', False):\n            self._list_available_subtitles(video_id, page)\n            return\n\n        subtitles = self._fix_subtitles(self.extract_subtitles(video_id, page))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'duration': duration,\n            'subtitles': subtitles,\n            'formats': formats\n        }",
        "begin_line": 41,
        "end_line": 97,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.lynda.LyndaIE._login#99",
        "src_path": "youtube_dl/extractor/lynda.py",
        "class_name": "youtube_dl.extractor.lynda.LyndaIE",
        "signature": "youtube_dl.extractor.lynda.LyndaIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n\n        login_form = {\n            'username': username,\n            'password': password,\n            'remember': 'false',\n            'stayPut': 'false'\n        }        \n        request = compat_urllib_request.Request(self._LOGIN_URL, compat_urllib_parse.urlencode(login_form))\n        login_page = self._download_webpage(request, None, note='Logging in as %s' % username)\n\n        # Not (yet) logged in\n        m = re.search(r'loginResultJson = \\'(?P<json>[^\\']+)\\';', login_page)\n        if m is not None:\n            response = m.group('json')\n            response_json = json.loads(response)            \n            state = response_json['state']\n\n            if state == 'notlogged':\n                raise ExtractorError('Unable to login, incorrect username and/or password', expected=True)\n\n            # This is when we get popup:\n            # > You're already logged in to lynda.com on two devices.\n            # > If you log in here, we'll log you out of another device.\n            # So, we need to confirm this.\n            if state == 'conflicted':\n                confirm_form = {\n                    'username': '',\n                    'password': '',\n                    'resolve': 'true',\n                    'remember': 'false',\n                    'stayPut': 'false',\n                }\n                request = compat_urllib_request.Request(self._LOGIN_URL, compat_urllib_parse.urlencode(confirm_form))\n                login_page = self._download_webpage(request, None, note='Confirming log in and log out from another device')\n\n        if re.search(self._SUCCESSFUL_LOGIN_REGEX, login_page) is None:\n            raise ExtractorError('Unable to log in')",
        "begin_line": 99,
        "end_line": 139,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.lynda.LyndaIE._fix_subtitles#141",
        "src_path": "youtube_dl/extractor/lynda.py",
        "class_name": "youtube_dl.extractor.lynda.LyndaIE",
        "signature": "youtube_dl.extractor.lynda.LyndaIE._fix_subtitles(self, subtitles)",
        "snippet": "    def _fix_subtitles(self, subtitles):\n        if subtitles is None:\n            return subtitles  # subtitles not requested\n\n        fixed_subtitles = {}\n        for k, v in subtitles.items():\n            subs = json.loads(v)\n            if len(subs) == 0:\n                continue\n            srt = ''\n            for pos in range(0, len(subs) - 1):\n                seq_current = subs[pos]\n                m_current = re.match(self._TIMECODE_REGEX, seq_current['Timecode'])\n                if m_current is None:\n                    continue\n                seq_next = subs[pos + 1]\n                m_next = re.match(self._TIMECODE_REGEX, seq_next['Timecode'])\n                if m_next is None:\n                    continue\n                appear_time = m_current.group('timecode')\n                disappear_time = m_next.group('timecode')\n                text = seq_current['Caption']\n                srt += '%s\\r\\n%s --> %s\\r\\n%s' % (str(pos), appear_time, disappear_time, text)\n            if srt:\n                fixed_subtitles[k] = srt\n        return fixed_subtitles",
        "begin_line": 141,
        "end_line": 166,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.lynda.LyndaIE._get_available_subtitles#168",
        "src_path": "youtube_dl/extractor/lynda.py",
        "class_name": "youtube_dl.extractor.lynda.LyndaIE",
        "signature": "youtube_dl.extractor.lynda.LyndaIE._get_available_subtitles(self, video_id, webpage)",
        "snippet": "    def _get_available_subtitles(self, video_id, webpage):\n        url = 'http://www.lynda.com/ajax/player?videoId=%s&type=transcript' % video_id\n        sub = self._download_webpage(url, None, note=False)\n        sub_json = json.loads(sub)\n        return {'en': url} if len(sub_json) > 0 else {}",
        "begin_line": 168,
        "end_line": 172,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.lynda.LyndaCourseIE._real_extract#183",
        "src_path": "youtube_dl/extractor/lynda.py",
        "class_name": "youtube_dl.extractor.lynda.LyndaCourseIE",
        "signature": "youtube_dl.extractor.lynda.LyndaCourseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        course_path = mobj.group('coursepath')\n        course_id = mobj.group('courseid')\n        \n        page = self._download_webpage('http://www.lynda.com/ajax/player?courseId=%s&type=course' % course_id,\n                                      course_id, 'Downloading course JSON')\n        course_json = json.loads(page)\n\n        if 'Status' in course_json and course_json['Status'] == 'NotFound':\n            raise ExtractorError('Course %s does not exist' % course_id, expected=True)\n\n        unaccessible_videos = 0\n        videos = []\n        (username, _) = self._get_login_info()\n\n        # Might want to extract videos right here from video['Formats'] as it seems 'Formats' is not provided\n        # by single video API anymore\n\n        for chapter in course_json['Chapters']:\n            for video in chapter['Videos']:\n                if username is None and video['HasAccess'] is False:\n                    unaccessible_videos += 1\n                    continue\n                videos.append(video['ID'])\n\n        if unaccessible_videos > 0:\n            self._downloader.report_warning('%s videos are only available for members and will not be downloaded. '\n                                            % unaccessible_videos + LyndaIE.ACCOUNT_CREDENTIALS_HINT)\n\n        entries = [\n            self.url_result('http://www.lynda.com/%s/%s-4.html' %\n                            (course_path, video_id),\n                            'Lynda')\n            for video_id in videos]\n\n        course_title = course_json['Title']\n\n        return self.playlist_result(entries, course_id, course_title)",
        "begin_line": 183,
        "end_line": 221,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.extremetube.ExtremeTubeIE._real_extract#24",
        "src_path": "youtube_dl/extractor/extremetube.py",
        "class_name": "youtube_dl.extractor.extremetube.ExtremeTubeIE",
        "signature": "youtube_dl.extractor.extremetube.ExtremeTubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n        url = 'http://www.' + mobj.group('url')\n\n        req = compat_urllib_request.Request(url)\n        req.add_header('Cookie', 'age_verified=1')\n        webpage = self._download_webpage(req, video_id)\n\n        video_title = self._html_search_regex(r'<h1 [^>]*?title=\"([^\"]+)\"[^>]*>\\1<', webpage, u'title')\n        uploader = self._html_search_regex(r'>Posted by:(?=<)(?:\\s|<[^>]*>)*(.+?)\\|', webpage, u'uploader', fatal=False)\n        video_url = compat_urllib_parse.unquote(self._html_search_regex(r'video_url=(.+?)&amp;', webpage, u'video_url'))\n        path = compat_urllib_parse_urlparse(video_url).path\n        extension = os.path.splitext(path)[1][1:]\n        format = path.split('/')[5].split('_')[:2]\n        format = \"-\".join(format)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'uploader': uploader,\n            'url': video_url,\n            'ext': extension,\n            'format': format,\n            'format_id': format,\n            'age_limit': 18,\n        }",
        "begin_line": 24,
        "end_line": 50,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.criterion.CriterionIE._real_extract#20",
        "src_path": "youtube_dl/extractor/criterion.py",
        "class_name": "youtube_dl.extractor.criterion.CriterionIE",
        "signature": "youtube_dl.extractor.criterion.CriterionIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group(1)\n        webpage = self._download_webpage(url, video_id)\n\n        final_url = self._search_regex(r'so.addVariable\\(\"videoURL\", \"(.+?)\"\\)\\;',\n                                webpage, 'video url')\n        title = self._html_search_regex(r'<meta content=\"(.+?)\" property=\"og:title\" />',\n                                webpage, 'video title')\n        description = self._html_search_regex(r'<meta name=\"description\" content=\"(.+?)\" />',\n                                webpage, 'video description')\n        thumbnail = self._search_regex(r'so.addVariable\\(\"thumbnailURL\", \"(.+?)\"\\)\\;',\n                                webpage, 'thumbnail url')\n\n        return {'id': video_id,\n                'url' : final_url,\n                'title': title,\n                'ext': determine_ext(final_url),\n                'description': description,\n                'thumbnail': thumbnail,\n                }",
        "begin_line": 20,
        "end_line": 40,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.vbox7.Vbox7IE._real_extract#27",
        "src_path": "youtube_dl/extractor/vbox7.py",
        "class_name": "youtube_dl.extractor.vbox7.Vbox7IE",
        "signature": "youtube_dl.extractor.vbox7.Vbox7IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        redirect_page, urlh = self._download_webpage_handle(url, video_id)\n        new_location = self._search_regex(r'window\\.location = \\'(.*)\\';',\n            redirect_page, 'redirect location')\n        redirect_url = urlh.geturl() + new_location\n        webpage = self._download_webpage(redirect_url, video_id,\n            'Downloading redirect page')\n\n        title = self._html_search_regex(r'<title>(.*)</title>',\n            webpage, 'title').split('/')[0].strip()\n\n        info_url = \"http://vbox7.com/play/magare.do\"\n        data = compat_urllib_parse.urlencode({'as3': '1', 'vid': video_id})\n        info_request = compat_urllib_request.Request(info_url, data)\n        info_request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        info_response = self._download_webpage(info_request, video_id, 'Downloading info webpage')\n        if info_response is None:\n            raise ExtractorError('Unable to extract the media url')\n        (final_url, thumbnail_url) = map(lambda x: x.split('=')[1], info_response.split('&'))\n\n        return {\n            'id': video_id,\n            'url': final_url,\n            'ext': 'flv',\n            'title': title,\n            'thumbnail': thumbnail_url,\n        }",
        "begin_line": 27,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.__init__#132",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.__init__(self, downloader=None)",
        "snippet": "    def __init__(self, downloader=None):\n        \"\"\"Constructor. Receives an optional downloader.\"\"\"\n        self._ready = False\n        self.set_downloader(downloader)",
        "begin_line": 132,
        "end_line": 135,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.017241379310344827,
            "pseudo_dstar_susp": 0.018867924528301886,
            "pseudo_tarantula_susp": 0.017241379310344827,
            "pseudo_op2_susp": 0.018867924528301886,
            "pseudo_barinel_susp": 0.017241379310344827
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.suitable#138",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        \"\"\"Receives a URL and returns True if suitable for this IE.\"\"\"\n\n        # This does not use has/getattr intentionally - we want to know whether\n        # we have cached the regexp for *this* class, whereas getattr would also\n        # match the superclass\n        if '_VALID_URL_RE' not in cls.__dict__:\n            cls._VALID_URL_RE = re.compile(cls._VALID_URL)\n        return cls._VALID_URL_RE.match(url) is not None",
        "begin_line": 138,
        "end_line": 146,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.working#149",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.working(cls)",
        "snippet": "    def working(cls):\n        \"\"\"Getter method for _WORKING.\"\"\"\n        return cls._WORKING",
        "begin_line": 149,
        "end_line": 151,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.023255813953488372,
            "pseudo_dstar_susp": 0.023255813953488372,
            "pseudo_tarantula_susp": 0.019230769230769232,
            "pseudo_op2_susp": 0.023255813953488372,
            "pseudo_barinel_susp": 0.019230769230769232
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.initialize#153",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.initialize(self)",
        "snippet": "    def initialize(self):\n        \"\"\"Initializes an instance (authentication, etc).\"\"\"\n        if not self._ready:\n            self._real_initialize()\n            self._ready = True",
        "begin_line": 153,
        "end_line": 157,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.extract#159",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.extract(self, url)",
        "snippet": "    def extract(self, url):\n        \"\"\"Extracts URL information and returns it in list of dicts.\"\"\"\n        self.initialize()\n        return self._real_extract(url)",
        "begin_line": 159,
        "end_line": 162,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.set_downloader#164",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.set_downloader(self, downloader)",
        "snippet": "    def set_downloader(self, downloader):\n        \"\"\"Sets the downloader for this IE.\"\"\"\n        self._downloader = downloader",
        "begin_line": 164,
        "end_line": 166,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.017241379310344827,
            "pseudo_dstar_susp": 0.018867924528301886,
            "pseudo_tarantula_susp": 0.017241379310344827,
            "pseudo_op2_susp": 0.018867924528301886,
            "pseudo_barinel_susp": 0.017241379310344827
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._real_initialize#168",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        \"\"\"Real initialization process. Redefine in subclasses.\"\"\"\n        pass",
        "begin_line": 168,
        "end_line": 170,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._real_extract#172",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        \"\"\"Real extraction process. Redefine in subclasses.\"\"\"\n        pass",
        "begin_line": 172,
        "end_line": 174,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.IE_NAME#182",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.IE_NAME(self)",
        "snippet": "    def IE_NAME(self):\n        return type(self).__name__[:-2]",
        "begin_line": 182,
        "end_line": 183,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._request_webpage#185",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._request_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True)",
        "snippet": "    def _request_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True):\n        \"\"\" Returns the response handle \"\"\"\n        if note is None:\n            self.report_download_webpage(video_id)\n        elif note is not False:\n            if video_id is None:\n                self.to_screen(u'%s' % (note,))\n            else:\n                self.to_screen(u'%s: %s' % (video_id, note))\n        try:\n            return self._downloader.urlopen(url_or_request)\n        except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:\n            if errnote is False:\n                return False\n            if errnote is None:\n                errnote = u'Unable to download webpage'\n            errmsg = u'%s: %s' % (errnote, compat_str(err))\n            if fatal:\n                raise ExtractorError(errmsg, sys.exc_info()[2], cause=err)\n            else:\n                self._downloader.report_warning(errmsg)\n                return False",
        "begin_line": 185,
        "end_line": 206,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._download_webpage_handle#208",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._download_webpage_handle(self, url_or_request, video_id, note=None, errnote=None, fatal=True)",
        "snippet": "    def _download_webpage_handle(self, url_or_request, video_id, note=None, errnote=None, fatal=True):\n        \"\"\" Returns a tuple (page content as string, URL handle) \"\"\"\n\n        # Strip hashes from the URL (#1038)\n        if isinstance(url_or_request, (compat_str, str)):\n            url_or_request = url_or_request.partition('#')[0]\n\n        urlh = self._request_webpage(url_or_request, video_id, note, errnote, fatal)\n        if urlh is False:\n            assert not fatal\n            return False\n        content_type = urlh.headers.get('Content-Type', '')\n        webpage_bytes = urlh.read()\n        m = re.match(r'[a-zA-Z0-9_.-]+/[a-zA-Z0-9_.-]+\\s*;\\s*charset=(.+)', content_type)\n        if m:\n            encoding = m.group(1)\n        else:\n            m = re.search(br'<meta[^>]+charset=[\\'\"]?([^\\'\")]+)[ /\\'\">]',\n                          webpage_bytes[:1024])\n            if m:\n                encoding = m.group(1).decode('ascii')\n            elif webpage_bytes.startswith(b'\\xff\\xfe'):\n                encoding = 'utf-16'\n            else:\n                encoding = 'utf-8'\n        if self._downloader.params.get('dump_intermediate_pages', False):\n            try:\n                url = url_or_request.get_full_url()\n            except AttributeError:\n                url = url_or_request\n            self.to_screen(u'Dumping request to ' + url)\n            dump = base64.b64encode(webpage_bytes).decode('ascii')\n            self._downloader.to_screen(dump)\n        if self._downloader.params.get('write_pages', False):\n            try:\n                url = url_or_request.get_full_url()\n            except AttributeError:\n                url = url_or_request\n            if len(url) > 200:\n                h = u'___' + hashlib.md5(url.encode('utf-8')).hexdigest()\n                url = url[:200 - len(h)] + h\n            raw_filename = ('%s_%s.dump' % (video_id, url))\n            filename = sanitize_filename(raw_filename, restricted=True)\n            self.to_screen(u'Saving request to ' + filename)\n            with open(filename, 'wb') as outf:\n                outf.write(webpage_bytes)\n\n        content = webpage_bytes.decode(encoding, 'replace')\n        return (content, urlh)",
        "begin_line": 208,
        "end_line": 256,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._download_webpage#258",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._download_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True)",
        "snippet": "    def _download_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True):\n        \"\"\" Returns the data of the page as a string \"\"\"\n        res = self._download_webpage_handle(url_or_request, video_id, note, errnote, fatal)\n        if res is False:\n            return res\n        else:\n            content, _ = res\n            return content",
        "begin_line": 258,
        "end_line": 265,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._download_xml#267",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._download_xml(self, url_or_request, video_id, note=u'Downloading XML', errnote=u'Unable to download XML', transform_source=None)",
        "snippet": "    def _download_xml(self, url_or_request, video_id,\n                      note=u'Downloading XML', errnote=u'Unable to download XML',\n                      transform_source=None):\n        \"\"\"Return the xml as an xml.etree.ElementTree.Element\"\"\"\n        xml_string = self._download_webpage(url_or_request, video_id, note, errnote)\n        if transform_source:\n            xml_string = transform_source(xml_string)\n        return xml.etree.ElementTree.fromstring(xml_string.encode('utf-8'))",
        "begin_line": 267,
        "end_line": 274,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._download_json#276",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._download_json(self, url_or_request, video_id, note=u'Downloading JSON metadata', errnote=u'Unable to download JSON metadata', transform_source=None)",
        "snippet": "    def _download_json(self, url_or_request, video_id,\n                       note=u'Downloading JSON metadata',\n                       errnote=u'Unable to download JSON metadata',\n                       transform_source=None):\n        json_string = self._download_webpage(url_or_request, video_id, note, errnote)\n        if transform_source:\n            json_string = transform_source(json_string)\n        try:\n            return json.loads(json_string)\n        except ValueError as ve:\n            raise ExtractorError('Failed to download JSON', cause=ve)",
        "begin_line": 276,
        "end_line": 286,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.report_warning#288",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.report_warning(self, msg, video_id=None)",
        "snippet": "    def report_warning(self, msg, video_id=None):\n        idstr = u'' if video_id is None else u'%s: ' % video_id\n        self._downloader.report_warning(\n            u'[%s] %s%s' % (self.IE_NAME, idstr, msg))",
        "begin_line": 288,
        "end_line": 291,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.to_screen#293",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.to_screen(self, msg)",
        "snippet": "    def to_screen(self, msg):\n        \"\"\"Print msg to screen, prefixing it with '[ie_name]'\"\"\"\n        self._downloader.to_screen(u'[%s] %s' % (self.IE_NAME, msg))",
        "begin_line": 293,
        "end_line": 295,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.report_extraction#297",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.report_extraction(self, id_or_name)",
        "snippet": "    def report_extraction(self, id_or_name):\n        \"\"\"Report information extraction.\"\"\"\n        self.to_screen(u'%s: Extracting information' % id_or_name)",
        "begin_line": 297,
        "end_line": 299,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.report_download_webpage#301",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.report_download_webpage(self, video_id)",
        "snippet": "    def report_download_webpage(self, video_id):\n        \"\"\"Report webpage download.\"\"\"\n        self.to_screen(u'%s: Downloading webpage' % video_id)",
        "begin_line": 301,
        "end_line": 303,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.report_age_confirmation#305",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.report_age_confirmation(self)",
        "snippet": "    def report_age_confirmation(self):\n        \"\"\"Report attempt to confirm age.\"\"\"\n        self.to_screen(u'Confirming age')",
        "begin_line": 305,
        "end_line": 307,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.report_login#309",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.report_login(self)",
        "snippet": "    def report_login(self):\n        \"\"\"Report attempt to log in.\"\"\"\n        self.to_screen(u'Logging in')",
        "begin_line": 309,
        "end_line": 311,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.url_result#315",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.url_result(url, ie=None, video_id=None)",
        "snippet": "    def url_result(url, ie=None, video_id=None):\n        \"\"\"Returns a url that points to a page that should be processed\"\"\"\n        #TODO: ie should be the class used for getting the info\n        video_info = {'_type': 'url',\n                      'url': url,\n                      'ie_key': ie}\n        if video_id is not None:\n            video_info['id'] = video_id\n        return video_info",
        "begin_line": 315,
        "end_line": 323,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor.playlist_result#325",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor.playlist_result(entries, playlist_id=None, playlist_title=None)",
        "snippet": "    def playlist_result(entries, playlist_id=None, playlist_title=None):\n        \"\"\"Returns a playlist\"\"\"\n        video_info = {'_type': 'playlist',\n                      'entries': entries}\n        if playlist_id:\n            video_info['id'] = playlist_id\n        if playlist_title:\n            video_info['title'] = playlist_title\n        return video_info",
        "begin_line": 325,
        "end_line": 333,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._search_regex#335",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._search_regex(self, pattern, string, name, default=_NO_DEFAULT, fatal=True, flags=0)",
        "snippet": "    def _search_regex(self, pattern, string, name, default=_NO_DEFAULT, fatal=True, flags=0):\n        \"\"\"\n        Perform a regex search on the given string, using a single or a list of\n        patterns returning the first matching group.\n        In case of failure return a default value or raise a WARNING or a\n        RegexNotFoundError, depending on fatal, specifying the field name.\n        \"\"\"\n        if isinstance(pattern, (str, compat_str, compiled_regex_type)):\n            mobj = re.search(pattern, string, flags)\n        else:\n            for p in pattern:\n                mobj = re.search(p, string, flags)\n                if mobj: break\n\n        if os.name != 'nt' and sys.stderr.isatty():\n            _name = u'\\033[0;34m%s\\033[0m' % name\n        else:\n            _name = name\n\n        if mobj:\n            # return the first matching group\n            return next(g for g in mobj.groups() if g is not None)\n        elif default is not _NO_DEFAULT:\n            return default\n        elif fatal:\n            raise RegexNotFoundError(u'Unable to extract %s' % _name)\n        else:\n            self._downloader.report_warning(u'unable to extract %s; '\n                u'please report this issue on http://yt-dl.org/bug' % _name)\n            return None",
        "begin_line": 335,
        "end_line": 364,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._html_search_regex#366",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._html_search_regex(self, pattern, string, name, default=_NO_DEFAULT, fatal=True, flags=0)",
        "snippet": "    def _html_search_regex(self, pattern, string, name, default=_NO_DEFAULT, fatal=True, flags=0):\n        \"\"\"\n        Like _search_regex, but strips HTML tags and unescapes entities.\n        \"\"\"\n        res = self._search_regex(pattern, string, name, default, fatal, flags)\n        if res:\n            return clean_html(res).strip()\n        else:\n            return res",
        "begin_line": 366,
        "end_line": 374,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._get_login_info#376",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._get_login_info(self)",
        "snippet": "    def _get_login_info(self):\n        \"\"\"\n        Get the the login info as (username, password)\n        It will look in the netrc file using the _NETRC_MACHINE value\n        If there's no info available, return (None, None)\n        \"\"\"\n        if self._downloader is None:\n            return (None, None)\n\n        username = None\n        password = None\n        downloader_params = self._downloader.params\n\n        # Attempt to use provided username and password or .netrc data\n        if downloader_params.get('username', None) is not None:\n            username = downloader_params['username']\n            password = downloader_params['password']\n        elif downloader_params.get('usenetrc', False):\n            try:\n                info = netrc.netrc().authenticators(self._NETRC_MACHINE)\n                if info is not None:\n                    username = info[0]\n                    password = info[2]\n                else:\n                    raise netrc.NetrcParseError('No authenticators for %s' % self._NETRC_MACHINE)\n            except (IOError, netrc.NetrcParseError) as err:\n                self._downloader.report_warning(u'parsing .netrc: %s' % compat_str(err))\n        \n        return (username, password)",
        "begin_line": 376,
        "end_line": 404,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._og_search_property#417",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._og_search_property(self, prop, html, name=None, **kargs)",
        "snippet": "    def _og_search_property(self, prop, html, name=None, **kargs):\n        if name is None:\n            name = 'OpenGraph %s' % prop\n        escaped = self._search_regex(self._og_regexes(prop), html, name, flags=re.DOTALL, **kargs)\n        if escaped is None:\n            return None\n        return unescapeHTML(escaped)",
        "begin_line": 417,
        "end_line": 423,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._og_search_thumbnail#425",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._og_search_thumbnail(self, html, **kargs)",
        "snippet": "    def _og_search_thumbnail(self, html, **kargs):\n        return self._og_search_property('image', html, u'thumbnail url', fatal=False, **kargs)",
        "begin_line": 425,
        "end_line": 426,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._og_search_description#428",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._og_search_description(self, html, **kargs)",
        "snippet": "    def _og_search_description(self, html, **kargs):\n        return self._og_search_property('description', html, fatal=False, **kargs)",
        "begin_line": 428,
        "end_line": 429,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._og_search_title#431",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._og_search_title(self, html, **kargs)",
        "snippet": "    def _og_search_title(self, html, **kargs):\n        return self._og_search_property('title', html, **kargs)",
        "begin_line": 431,
        "end_line": 432,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._og_search_video_url#434",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._og_search_video_url(self, html, name='video url', secure=True, **kargs)",
        "snippet": "    def _og_search_video_url(self, html, name='video url', secure=True, **kargs):\n        regexes = self._og_regexes('video')\n        if secure: regexes = self._og_regexes('video:secure_url') + regexes\n        return self._html_search_regex(regexes, html, name, **kargs)",
        "begin_line": 434,
        "end_line": 437,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._html_search_meta#439",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._html_search_meta(self, name, html, display_name=None, fatal=False)",
        "snippet": "    def _html_search_meta(self, name, html, display_name=None, fatal=False):\n        if display_name is None:\n            display_name = name\n        return self._html_search_regex(\n            r'''(?ix)<meta\n                    (?=[^>]+(?:itemprop|name|property)=[\"\\']%s[\"\\'])\n                    [^>]+content=[\"\\']([^\"\\']+)[\"\\']''' % re.escape(name),\n            html, display_name, fatal=fatal)",
        "begin_line": 439,
        "end_line": 446,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._dc_search_uploader#448",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._dc_search_uploader(self, html)",
        "snippet": "    def _dc_search_uploader(self, html):\n        return self._html_search_meta('dc.creator', html, 'uploader')",
        "begin_line": 448,
        "end_line": 449,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._rta_search#451",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._rta_search(self, html)",
        "snippet": "    def _rta_search(self, html):\n        # See http://www.rtalabel.org/index.php?content=howtofaq#single\n        if re.search(r'(?ix)<meta\\s+name=\"rating\"\\s+'\n                     r'     content=\"RTA-5042-1996-1400-1577-RTA\"',\n                     html):\n            return 18\n        return 0",
        "begin_line": 451,
        "end_line": 457,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._media_rating_search#459",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._media_rating_search(self, html)",
        "snippet": "    def _media_rating_search(self, html):\n        # See http://www.tjg-designs.com/WP/metadata-code-examples-adding-metadata-to-your-web-pages/\n        rating = self._html_search_meta('rating', html)\n\n        if not rating:\n            return None\n\n        RATING_TABLE = {\n            'safe for kids': 0,\n            'general': 8,\n            '14 years': 14,\n            'mature': 17,\n            'restricted': 19,\n        }\n        return RATING_TABLE.get(rating.lower(), None)",
        "begin_line": 459,
        "end_line": 473,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._twitter_search_player#475",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._twitter_search_player(self, html)",
        "snippet": "    def _twitter_search_player(self, html):\n        return self._html_search_meta('twitter:player', html,\n            'twitter card player')",
        "begin_line": 475,
        "end_line": 477,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.InfoExtractor._sort_formats#479",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.InfoExtractor",
        "signature": "youtube_dl.extractor.common.InfoExtractor._sort_formats(self, formats)",
        "snippet": "    def _sort_formats(self, formats):\n        if not formats:\n            raise ExtractorError(u'No video formats found')\n\n        def _formats_key(f):\n            # TODO remove the following workaround\n            from ..utils import determine_ext\n            if not f.get('ext') and 'url' in f:\n                f['ext'] = determine_ext(f['url'])\n\n            preference = f.get('preference')\n            if preference is None:\n                proto = f.get('protocol')\n                if proto is None:\n                    proto = compat_urllib_parse_urlparse(f.get('url', '')).scheme\n\n                preference = 0 if proto in ['http', 'https'] else -0.1\n                if f.get('ext') in ['f4f', 'f4m']:  # Not yet supported\n                    preference -= 0.5\n\n            if f.get('vcodec') == 'none':  # audio only\n                if self._downloader.params.get('prefer_free_formats'):\n                    ORDER = [u'aac', u'mp3', u'm4a', u'webm', u'ogg', u'opus']\n                else:\n                    ORDER = [u'webm', u'opus', u'ogg', u'mp3', u'aac', u'm4a']\n                ext_preference = 0\n                try:\n                    audio_ext_preference = ORDER.index(f['ext'])\n                except ValueError:\n                    audio_ext_preference = -1\n            else:\n                if self._downloader.params.get('prefer_free_formats'):\n                    ORDER = [u'flv', u'mp4', u'webm']\n                else:\n                    ORDER = [u'webm', u'flv', u'mp4']\n                try:\n                    ext_preference = ORDER.index(f['ext'])\n                except ValueError:\n                    ext_preference = -1\n                audio_ext_preference = 0\n\n            return (\n                preference,\n                f.get('quality') if f.get('quality') is not None else -1,\n                f.get('height') if f.get('height') is not None else -1,\n                f.get('width') if f.get('width') is not None else -1,\n                ext_preference,\n                f.get('tbr') if f.get('tbr') is not None else -1,\n                f.get('vbr') if f.get('vbr') is not None else -1,\n                f.get('abr') if f.get('abr') is not None else -1,\n                audio_ext_preference,\n                f.get('filesize') if f.get('filesize') is not None else -1,\n                f.get('format_id'),\n            )\n        formats.sort(key=_formats_key)",
        "begin_line": 479,
        "end_line": 533,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.SearchInfoExtractor._make_valid_url#544",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.SearchInfoExtractor",
        "signature": "youtube_dl.extractor.common.SearchInfoExtractor._make_valid_url(cls)",
        "snippet": "    def _make_valid_url(cls):\n        return r'%s(?P<prefix>|[1-9][0-9]*|all):(?P<query>[\\s\\S]+)' % cls._SEARCH_KEY",
        "begin_line": 544,
        "end_line": 545,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0001584786053882726,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.SearchInfoExtractor.suitable#548",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.SearchInfoExtractor",
        "signature": "youtube_dl.extractor.common.SearchInfoExtractor.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return re.match(cls._make_valid_url(), url) is not None",
        "begin_line": 548,
        "end_line": 549,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0001584786053882726,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.SearchInfoExtractor._real_extract#551",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.SearchInfoExtractor",
        "signature": "youtube_dl.extractor.common.SearchInfoExtractor._real_extract(self, query)",
        "snippet": "    def _real_extract(self, query):\n        mobj = re.match(self._make_valid_url(), query)\n        if mobj is None:\n            raise ExtractorError(u'Invalid search query \"%s\"' % query)\n\n        prefix = mobj.group('prefix')\n        query = mobj.group('query')\n        if prefix == '':\n            return self._get_n_results(query, 1)\n        elif prefix == 'all':\n            return self._get_n_results(query, self._MAX_RESULTS)\n        else:\n            n = int(prefix)\n            if n <= 0:\n                raise ExtractorError(u'invalid download number %s for query \"%s\"' % (n, query))\n            elif n > self._MAX_RESULTS:\n                self._downloader.report_warning(u'%s returns max %i results (you requested %i)' % (self._SEARCH_KEY, self._MAX_RESULTS, n))\n                n = self._MAX_RESULTS\n            return self._get_n_results(query, n)",
        "begin_line": 551,
        "end_line": 569,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.common.SearchInfoExtractor._get_n_results#571",
        "src_path": "youtube_dl/extractor/common.py",
        "class_name": "youtube_dl.extractor.common.SearchInfoExtractor",
        "signature": "youtube_dl.extractor.common.SearchInfoExtractor._get_n_results(self, query, n)",
        "snippet": "    def _get_n_results(self, query, n):\n        \"\"\"Get a specified number of results for a query\"\"\"\n        raise NotImplementedError(\"This method must be implemented by subclasses\")",
        "begin_line": 571,
        "end_line": 573,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.iprima.IPrimaIE._real_extract#41",
        "src_path": "youtube_dl/extractor/iprima.py",
        "class_name": "youtube_dl.extractor.iprima.IPrimaIE",
        "signature": "youtube_dl.extractor.iprima.IPrimaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        player_url = (\n            'http://embed.livebox.cz/iprimaplay/player-embed-v2.js?__tok%s__=%s' %\n            (floor(random()*1073741824), floor(random()*1073741824))\n        )\n\n        req = compat_urllib_request.Request(player_url)\n        req.add_header('Referer', url)\n        playerpage = self._download_webpage(req, video_id)\n\n        base_url = ''.join(re.findall(r\"embed\\['stream'\\] = '(.+?)'.+'(\\?auth=)'.+'(.+?)';\", playerpage)[1])\n\n        zoneGEO = self._html_search_regex(r'\"zoneGEO\":(.+?),', webpage, 'zoneGEO')\n        if zoneGEO != '0':\n            base_url = base_url.replace('token', 'token_' + zoneGEO)\n\n        formats = []\n        for format_id in ['lq', 'hq', 'hd']:\n            filename = self._html_search_regex(\n                r'\"%s_id\":(.+?),' % format_id, webpage, 'filename')\n\n            if filename == 'null':\n                continue\n\n            real_id = self._search_regex(\n                r'Prima-(?:[0-9]{10}|WEB)-([0-9]+)[-_]',\n                filename, 'real video id')\n\n            if format_id == 'lq':\n                quality = 0\n            elif format_id == 'hq':\n                quality = 1\n            elif format_id == 'hd':\n                quality = 2\n                filename = 'hq/' + filename\n\n            formats.append({\n                'format_id': format_id,\n                'url': base_url,\n                'quality': quality,\n                'play_path': 'mp4:' + filename.replace('\"', '')[:-4],\n                'rtmp_live': True,\n                'ext': 'flv',\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': real_id,\n            'title': self._og_search_title(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'formats': formats,\n            'description': self._og_search_description(webpage),\n        }",
        "begin_line": 41,
        "end_line": 99,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.tumblr.TumblrIE._real_extract#22",
        "src_path": "youtube_dl/extractor/tumblr.py",
        "class_name": "youtube_dl.extractor.tumblr.TumblrIE",
        "signature": "youtube_dl.extractor.tumblr.TumblrIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m_url = re.match(self._VALID_URL, url)\n        video_id = m_url.group('id')\n        blog = m_url.group('blog_name')\n\n        url = 'http://%s.tumblr.com/post/%s/' % (blog, video_id)\n        webpage = self._download_webpage(url, video_id)\n\n        re_video = r'src=\\\\x22(?P<video_url>http://%s\\.tumblr\\.com/video_file/%s/(.*?))\\\\x22 type=\\\\x22video/(?P<ext>.*?)\\\\x22' % (blog, video_id)\n        video = re.search(re_video, webpage)\n        if video is None:\n            raise ExtractorError('Unable to extract video')\n        video_url = video.group('video_url')\n        ext = video.group('ext')\n\n        video_thumbnail = self._search_regex(\n            r'posters.*?\\[\\\\x22(.*?)\\\\x22',\n            webpage, 'thumbnail', fatal=False)  # We pick the first poster\n        if video_thumbnail:\n            video_thumbnail = video_thumbnail.replace('\\\\\\\\/', '/')\n\n        # The only place where you can get a title, it's not complete,\n        # but searching in other places doesn't work for all videos\n        video_title = self._html_search_regex(r'<title>(?P<title>.*?)(?: \\| Tumblr)?</title>',\n            webpage, 'title', flags=re.DOTALL)\n\n        return [{'id': video_id,\n                 'url': video_url,\n                 'title': video_title,\n                 'thumbnail': video_thumbnail,\n                 'ext': ext\n                 }]",
        "begin_line": 22,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.mixcloud.MixcloudIE.check_urls#30",
        "src_path": "youtube_dl/extractor/mixcloud.py",
        "class_name": "youtube_dl.extractor.mixcloud.MixcloudIE",
        "signature": "youtube_dl.extractor.mixcloud.MixcloudIE.check_urls(self, url_list)",
        "snippet": "    def check_urls(self, url_list):\n        \"\"\"Returns 1st active url from list\"\"\"\n        for url in url_list:\n            try:\n                # We only want to know if the request succeed\n                # don't download the whole file\n                self._request_webpage(url, None, False)\n                return url\n            except ExtractorError:\n                url = None\n\n        return None",
        "begin_line": 30,
        "end_line": 41,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.mixcloud.MixcloudIE._get_url#43",
        "src_path": "youtube_dl/extractor/mixcloud.py",
        "class_name": "youtube_dl.extractor.mixcloud.MixcloudIE",
        "signature": "youtube_dl.extractor.mixcloud.MixcloudIE._get_url(self, template_url)",
        "snippet": "    def _get_url(self, template_url):\n        return self.check_urls(template_url % i for i in range(30))",
        "begin_line": 43,
        "end_line": 44,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.mixcloud.MixcloudIE._real_extract#46",
        "src_path": "youtube_dl/extractor/mixcloud.py",
        "class_name": "youtube_dl.extractor.mixcloud.MixcloudIE",
        "signature": "youtube_dl.extractor.mixcloud.MixcloudIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        uploader = mobj.group(1)\n        cloudcast_name = mobj.group(2)\n        track_id = compat_urllib_parse.unquote('-'.join((uploader, cloudcast_name)))\n\n        webpage = self._download_webpage(url, track_id)\n\n        api_url = 'http://api.mixcloud.com/%s/%s/' % (uploader, cloudcast_name)\n        info = self._download_json(\n            api_url, track_id, 'Downloading cloudcast info')\n\n        preview_url = self._search_regex(\n            r'\\s(?:data-preview-url|m-preview)=\"(.+?)\"', webpage, 'preview url')\n        song_url = preview_url.replace('/previews/', '/c/originals/')\n        template_url = re.sub(r'(stream\\d*)', 'stream%d', song_url)\n        final_song_url = self._get_url(template_url)\n        if final_song_url is None:\n            self.to_screen('Trying with m4a extension')\n            template_url = template_url.replace('.mp3', '.m4a').replace('originals/', 'm4a/64/')\n            final_song_url = self._get_url(template_url)\n        if final_song_url is None:\n            raise ExtractorError(u'Unable to extract track url')\n\n        return {\n            'id': track_id,\n            'title': info['name'],\n            'url': final_song_url,\n            'description': info.get('description'),\n            'thumbnail': info['pictures'].get('extra_large'),\n            'uploader': info['user']['name'],\n            'uploader_id': info['user']['username'],\n            'upload_date': unified_strdate(info['created_time']),\n            'view_count': info['play_count'],\n        }",
        "begin_line": 46,
        "end_line": 80,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.normalboots.NormalbootsIE._real_extract#28",
        "src_path": "youtube_dl/extractor/normalboots.py",
        "class_name": "youtube_dl.extractor.normalboots.NormalbootsIE",
        "signature": "youtube_dl.extractor.normalboots.NormalbootsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n\n        webpage = self._download_webpage(url, video_id)\n        video_uploader = self._html_search_regex(r'Posted\\sby\\s<a\\shref=\"[A-Za-z0-9/]*\">(?P<uploader>[A-Za-z]*)\\s</a>',\n            webpage, 'uploader')\n        raw_upload_date = self._html_search_regex('<span style=\"text-transform:uppercase; font-size:inherit;\">[A-Za-z]+, (?P<date>.*)</span>',\n            webpage, 'date')\n        video_upload_date = unified_strdate(raw_upload_date)\n\n        player_url = self._html_search_regex(r'<iframe\\swidth=\"[0-9]+\"\\sheight=\"[0-9]+\"\\ssrc=\"(?P<url>[\\S]+)\"', webpage, 'url')\n        player_page = self._download_webpage(player_url, video_id)\n        video_url = self._html_search_regex(r\"file:\\s'(?P<file>[^']+\\.mp4)'\", player_page, 'file')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': self._og_search_title(webpage),\n            'description': self._og_search_description(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'uploader': video_uploader,\n            'upload_date': video_upload_date,\n        }",
        "begin_line": 28,
        "end_line": 51,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youjizz.YouJizzIE._real_extract#23",
        "src_path": "youtube_dl/extractor/youjizz.py",
        "class_name": "youtube_dl.extractor.youjizz.YouJizzIE",
        "signature": "youtube_dl.extractor.youjizz.YouJizzIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('videoid')\n\n        # Get webpage content\n        webpage = self._download_webpage(url, video_id)\n\n        age_limit = self._rta_search(webpage)\n\n        # Get the video title\n        video_title = self._html_search_regex(r'<title>(?P<title>.*)</title>',\n            webpage, 'title').strip()\n\n        # Get the embed page\n        result = re.search(r'https?://www.youjizz.com/videos/embed/(?P<videoid>[0-9]+)', webpage)\n        if result is None:\n            raise ExtractorError('ERROR: unable to extract embed page')\n\n        embed_page_url = result.group(0).strip()\n        video_id = result.group('videoid')\n\n        webpage = self._download_webpage(embed_page_url, video_id)\n\n        # Get the video URL\n        m_playlist = re.search(r'so.addVariable\\(\"playlist\", ?\"(?P<playlist>.+?)\"\\);', webpage)\n        if m_playlist is not None:\n            playlist_url = m_playlist.group('playlist')\n            playlist_page = self._download_webpage(playlist_url, video_id,\n                                                   'Downloading playlist page')\n            m_levels = list(re.finditer(r'<level bitrate=\"(\\d+?)\" file=\"(.*?)\"', playlist_page))\n            if len(m_levels) == 0:\n                raise ExtractorError('Unable to extract video url')\n            videos = [(int(m.group(1)), m.group(2)) for m in m_levels]\n            (_, video_url) = sorted(videos)[0]\n            video_url = video_url.replace('%252F', '%2F')\n        else:\n            video_url = self._search_regex(r'so.addVariable\\(\"file\",encodeURIComponent\\(\"(?P<source>[^\"]+)\"\\)\\);',\n                                           webpage, 'video URL')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': video_title,\n            'ext': 'flv',\n            'format': 'flv',\n            'player_url': embed_page_url,\n            'age_limit': age_limit,\n        }",
        "begin_line": 23,
        "end_line": 71,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.keezmovies.KeezMoviesIE._real_extract#26",
        "src_path": "youtube_dl/extractor/keezmovies.py",
        "class_name": "youtube_dl.extractor.keezmovies.KeezMoviesIE",
        "signature": "youtube_dl.extractor.keezmovies.KeezMoviesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n        url = 'http://www.' + mobj.group('url')\n\n        req = compat_urllib_request.Request(url)\n        req.add_header('Cookie', 'age_verified=1')\n        webpage = self._download_webpage(req, video_id)\n\n        # embedded video\n        mobj = re.search(r'href=\"([^\"]+)\"></iframe>', webpage)\n        if mobj:\n            embedded_url = mobj.group(1)\n            return self.url_result(embedded_url)\n\n        video_title = self._html_search_regex(r'<h1 [^>]*>([^<]+)', webpage, u'title')\n        video_url = compat_urllib_parse.unquote(self._html_search_regex(r'video_url=(.+?)&amp;', webpage, u'video_url'))\n        if webpage.find('encrypted=true')!=-1:\n            password = self._html_search_regex(r'video_title=(.+?)&amp;', webpage, u'password')\n            video_url = aes_decrypt_text(video_url, password, 32).decode('utf-8')\n        path = compat_urllib_parse_urlparse(video_url).path\n        extension = os.path.splitext(path)[1][1:]\n        format = path.split('/')[4].split('_')[:2]\n        format = \"-\".join(format)\n\n        age_limit = self._rta_search(webpage)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'url': video_url,\n            'ext': extension,\n            'format': format,\n            'format_id': format,\n            'age_limit': age_limit,\n        }",
        "begin_line": 26,
        "end_line": 61,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.pornotube.PornotubeIE._real_extract#24",
        "src_path": "youtube_dl/extractor/pornotube.py",
        "class_name": "youtube_dl.extractor.pornotube.PornotubeIE",
        "signature": "youtube_dl.extractor.pornotube.PornotubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('videoid')\n        video_title = mobj.group('title')\n\n        # Get webpage content\n        webpage = self._download_webpage(url, video_id)\n\n        # Get the video URL\n        VIDEO_URL_RE = r'url: \"(?P<url>http://video[0-9].pornotube.com/.+\\.flv)\",'\n        video_url = self._search_regex(VIDEO_URL_RE, webpage, u'video url')\n        video_url = compat_urllib_parse.unquote(video_url)\n\n        #Get the uploaded date\n        VIDEO_UPLOADED_RE = r'<div class=\"video_added_by\">Added (?P<date>[0-9\\/]+) by'\n        upload_date = self._html_search_regex(VIDEO_UPLOADED_RE, webpage, u'upload date', fatal=False)\n        if upload_date: upload_date = unified_strdate(upload_date)\n        age_limit = self._rta_search(webpage)\n\n        info = {'id': video_id,\n                'url': video_url,\n                'uploader': None,\n                'upload_date': upload_date,\n                'title': video_title,\n                'ext': 'flv',\n                'format': 'flv',\n                'age_limit': age_limit}\n\n        return [info]",
        "begin_line": 24,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.depositfiles.DepositFilesIE._real_extract#22",
        "src_path": "youtube_dl/extractor/depositfiles.py",
        "class_name": "youtube_dl.extractor.depositfiles.DepositFilesIE",
        "signature": "youtube_dl.extractor.depositfiles.DepositFilesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        file_id = url.split('/')[-1]\n        # Rebuild url in english locale\n        url = 'http://depositfiles.com/en/files/' + file_id\n\n        # Retrieve file webpage with 'Free download' button pressed\n        free_download_indication = {'gateway_result' : '1'}\n        request = compat_urllib_request.Request(url, compat_urllib_parse.urlencode(free_download_indication))\n        try:\n            self.report_download_webpage(file_id)\n            webpage = compat_urllib_request.urlopen(request).read()\n        except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:\n            raise ExtractorError(u'Unable to retrieve file webpage: %s' % compat_str(err))\n\n        # Search for the real file URL\n        mobj = re.search(r'<form action=\"(http://fileshare.+?)\"', webpage)\n        if (mobj is None) or (mobj.group(1) is None):\n            # Try to figure out reason of the error.\n            mobj = re.search(r'<strong>(Attention.*?)</strong>', webpage, re.DOTALL)\n            if (mobj is not None) and (mobj.group(1) is not None):\n                restriction_message = re.sub('\\s+', ' ', mobj.group(1)).strip()\n                raise ExtractorError(u'%s' % restriction_message)\n            else:\n                raise ExtractorError(u'Unable to extract download URL from: %s' % url)\n\n        file_url = mobj.group(1)\n        file_extension = os.path.splitext(file_url)[1][1:]\n\n        # Search for file title\n        file_title = self._search_regex(r'<b title=\"(.*?)\">', webpage, u'title')\n\n        return [{\n            'id':       file_id.decode('utf-8'),\n            'url':      file_url.decode('utf-8'),\n            'uploader': None,\n            'upload_date':  None,\n            'title':    file_title,\n            'ext':      file_extension.decode('utf-8'),\n        }]",
        "begin_line": 22,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.wimp.WimpIE._real_extract#21",
        "src_path": "youtube_dl/extractor/wimp.py",
        "class_name": "youtube_dl.extractor.wimp.WimpIE",
        "signature": "youtube_dl.extractor.wimp.WimpIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group(1)\n        webpage = self._download_webpage(url, video_id)\n        video_url = self._search_regex(\n            r's1\\.addVariable\\(\"file\",\\s*\"([^\"]+)\"\\);', webpage, 'video URL')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': self._og_search_title(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'description': self._og_search_description(webpage),\n        }",
        "begin_line": 21,
        "end_line": 34,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.flickr.FlickrIE._real_extract#26",
        "src_path": "youtube_dl/extractor/flickr.py",
        "class_name": "youtube_dl.extractor.flickr.FlickrIE",
        "signature": "youtube_dl.extractor.flickr.FlickrIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n        video_uploader_id = mobj.group('uploader_id')\n        webpage_url = 'http://www.flickr.com/photos/' + video_uploader_id + '/' + video_id\n        webpage = self._download_webpage(webpage_url, video_id)\n\n        secret = self._search_regex(r\"photo_secret: '(\\w+)'\", webpage, 'secret')\n\n        first_url = 'https://secure.flickr.com/apps/video/video_mtl_xml.gne?v=x&photo_id=' + video_id + '&secret=' + secret + '&bitrate=700&target=_self'\n        first_xml = self._download_webpage(first_url, video_id, 'Downloading first data webpage')\n\n        node_id = self._html_search_regex(r'<Item id=\"id\">(\\d+-\\d+)</Item>',\n            first_xml, 'node_id')\n\n        second_url = 'https://secure.flickr.com/video_playlist.gne?node_id=' + node_id + '&tech=flash&mode=playlist&bitrate=700&secret=' + secret + '&rd=video.yahoo.com&noad=1'\n        second_xml = self._download_webpage(second_url, video_id, 'Downloading second data webpage')\n\n        self.report_extraction(video_id)\n\n        mobj = re.search(r'<STREAM APP=\"(.+?)\" FULLPATH=\"(.+?)\"', second_xml)\n        if mobj is None:\n            raise ExtractorError('Unable to extract video url')\n        video_url = mobj.group(1) + unescapeHTML(mobj.group(2))\n\n        return [{\n            'id':          video_id,\n            'url':         video_url,\n            'ext':         'mp4',\n            'title':       self._og_search_title(webpage),\n            'description': self._og_search_description(webpage),\n            'thumbnail':   self._og_search_thumbnail(webpage),\n            'uploader_id': video_uploader_id,\n        }]",
        "begin_line": 26,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.internetvideoarchive.InternetVideoArchiveIE._real_extract#38",
        "src_path": "youtube_dl/extractor/internetvideoarchive.py",
        "class_name": "youtube_dl.extractor.internetvideoarchive.InternetVideoArchiveIE",
        "signature": "youtube_dl.extractor.internetvideoarchive.InternetVideoArchiveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        query = compat_urlparse.urlparse(url).query\n        query_dic = compat_urlparse.parse_qs(query)\n        video_id = query_dic['publishedid'][0]\n        url = self._build_url(query)\n\n        flashconfiguration = self._download_xml(url, video_id,\n            u'Downloading flash configuration')\n        file_url = flashconfiguration.find('file').text\n        file_url = file_url.replace('/playlist.aspx', '/mrssplaylist.aspx')\n        # Replace some of the parameters in the query to get the best quality\n        # and http links (no m3u8 manifests)\n        file_url = re.sub(r'(?<=\\?)(.+)$',\n            lambda m: self._clean_query(m.group()),\n            file_url)\n        info = self._download_xml(file_url, video_id,\n            u'Downloading video info')\n        item = info.find('channel/item')\n\n        def _bp(p):\n            return xpath_with_ns(p,\n                {'media': 'http://search.yahoo.com/mrss/',\n                'jwplayer': 'http://developer.longtailvideo.com/trac/wiki/FlashFormats'})\n        formats = []\n        for content in item.findall(_bp('media:group/media:content')):\n            attr = content.attrib\n            f_url = attr['url']\n            width = int(attr['width'])\n            bitrate = int(attr['bitrate'])\n            format_id = '%d-%dk' % (width, bitrate)\n            formats.append({\n                'format_id': format_id,\n                'url': f_url,\n                'width': width,\n                'tbr': bitrate,\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': item.find('title').text,\n            'formats': formats,\n            'thumbnail': item.find(_bp('media:thumbnail')).attrib['url'],\n            'description': item.find('description').text,\n            'duration': int(attr['duration']),\n        }",
        "begin_line": 38,
        "end_line": 84,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.tutv.TutvIE._real_extract#22",
        "src_path": "youtube_dl/extractor/tutv.py",
        "class_name": "youtube_dl.extractor.tutv.TutvIE",
        "signature": "youtube_dl.extractor.tutv.TutvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        internal_id = self._search_regex(r'codVideo=([0-9]+)', webpage, 'internal video ID')\n\n        data_url = 'http://tu.tv/flvurl.php?codVideo=' + str(internal_id)\n        data_content = self._download_webpage(data_url, video_id, note='Downloading video info')\n        data = compat_parse_qs(data_content)\n        video_url = base64.b64decode(data['kpt'][0]).decode('utf-8')\n\n        return {\n            'id': internal_id,\n            'url': video_url,\n            'title': self._og_search_title(webpage),\n        }",
        "begin_line": 22,
        "end_line": 38,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.myspace.MySpaceIE._real_extract#47",
        "src_path": "youtube_dl/extractor/myspace.py",
        "class_name": "youtube_dl.extractor.myspace.MySpaceIE",
        "signature": "youtube_dl.extractor.myspace.MySpaceIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n\n        if mobj.group('mediatype').startswith('music/song'):\n            # songs don't store any useful info in the 'context' variable\n            def search_data(name):\n                return self._search_regex(r'data-%s=\"(.*?)\"' % name, webpage,\n                    name)\n            streamUrl = search_data('stream-url')\n            info = {\n                'id': video_id,\n                'title': self._og_search_title(webpage),\n                'uploader_id': search_data('artist-username'),\n                'thumbnail': self._og_search_thumbnail(webpage),\n            }\n        else:\n            context = json.loads(self._search_regex(r'context = ({.*?});', webpage,\n                u'context'))\n            video = context['video']\n            streamUrl = video['streamUrl']\n            info = {\n                'id': compat_str(video['mediaId']),\n                'title': video['title'],\n                'description': video['description'],\n                'thumbnail': video['imageUrl'],\n                'uploader': video['artistName'],\n                'uploader_id': video['artistUsername'],\n            }\n\n        rtmp_url, play_path = streamUrl.split(';', 1)\n        info.update({\n            'url': rtmp_url,\n            'play_path': play_path,\n            'ext': 'flv',\n        })\n        return info",
        "begin_line": 47,
        "end_line": 84,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.keek.KeekIE._real_extract#21",
        "src_path": "youtube_dl/extractor/keek.py",
        "class_name": "youtube_dl.extractor.keek.KeekIE",
        "signature": "youtube_dl.extractor.keek.KeekIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('videoID')\n\n        video_url = 'http://cdn.keek.com/keek/video/%s' % video_id\n        thumbnail = 'http://cdn.keek.com/keek/thumbnail/%s/w100/h75' % video_id\n        webpage = self._download_webpage(url, video_id)\n\n        uploader = self._html_search_regex(\n            r'<div class=\"user-name-and-bio\">[\\S\\s]+?<h2>(?P<uploader>.+?)</h2>',\n            webpage, 'uploader', fatal=False)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'ext': 'mp4',\n            'title': self._og_search_title(webpage),\n            'thumbnail': thumbnail,\n            'uploader': uploader\n        }",
        "begin_line": 21,
        "end_line": 40,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.huffpost.HuffPostIE._real_extract#34",
        "src_path": "youtube_dl/extractor/huffpost.py",
        "class_name": "youtube_dl.extractor.huffpost.HuffPostIE",
        "signature": "youtube_dl.extractor.huffpost.HuffPostIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        api_url = 'http://embed.live.huffingtonpost.com/api/segments/%s.json' % video_id\n        data = self._download_json(api_url, video_id)['data']\n\n        video_title = data['title']\n        duration = parse_duration(data['running_time'])\n        upload_date = unified_strdate(data['schedule']['starts_at'])\n        description = data.get('description')\n\n        thumbnails = []\n        for url in data['images'].values():\n            m = re.match('.*-([0-9]+x[0-9]+)\\.', url)\n            if not m:\n                continue\n            thumbnails.append({\n                'url': url,\n                'resolution': m.group(1),\n            })\n\n        formats = [{\n            'format': key,\n            'format_id': key.replace('/', '.'),\n            'ext': 'mp4',\n            'url': url,\n            'vcodec': 'none' if key.startswith('audio/') else None,\n        } for key, url in data['sources']['live'].items()]\n        if data.get('fivemin_id'):\n            fid = data['fivemin_id']\n            fcat = str(int(fid) // 100 + 1)\n            furl = 'http://avideos.5min.com/2/' + fcat[-3:] + '/' + fcat + '/' + fid + '.mp4'\n            formats.append({\n                'format': 'fivemin',\n                'url': furl,\n                'preference': 1,\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'description': description,\n            'formats': formats,\n            'duration': duration,\n            'upload_date': upload_date,\n            'thumbnails': thumbnails,\n        }",
        "begin_line": 34,
        "end_line": 82,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.niconico.NiconicoIE._real_initialize#46",
        "src_path": "youtube_dl/extractor/niconico.py",
        "class_name": "youtube_dl.extractor.niconico.NiconicoIE",
        "signature": "youtube_dl.extractor.niconico.NiconicoIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 46,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.niconico.NiconicoIE._login#49",
        "src_path": "youtube_dl/extractor/niconico.py",
        "class_name": "youtube_dl.extractor.niconico.NiconicoIE",
        "signature": "youtube_dl.extractor.niconico.NiconicoIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        # No authentication to be performed\n        if username is None:\n            if self._LOGIN_REQUIRED:\n                raise ExtractorError(u'No login info available, needed for using %s.' % self.IE_NAME, expected=True)\n            return False\n\n        # Log in\n        login_form_strs = {\n            u'mail': username,\n            u'password': password,\n        }\n        # Convert to UTF-8 *before* urlencode because Python 2.x's urlencode\n        # chokes on unicode\n        login_form = dict((k.encode('utf-8'), v.encode('utf-8')) for k,v in login_form_strs.items())\n        login_data = compat_urllib_parse.urlencode(login_form).encode('utf-8')\n        request = compat_urllib_request.Request(\n            u'https://secure.nicovideo.jp/secure/login', login_data)\n        login_results = self._download_webpage(\n            request, u'', note=u'Logging in', errnote=u'Unable to log in')\n        if re.search(r'(?i)<h1 class=\"mb8p4\">Log in error</h1>', login_results) is not None:\n            self._downloader.report_warning(u'unable to log in: bad username or password')\n            return False\n        return True",
        "begin_line": 49,
        "end_line": 73,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.niconico.NiconicoIE._real_extract#75",
        "src_path": "youtube_dl/extractor/niconico.py",
        "class_name": "youtube_dl.extractor.niconico.NiconicoIE",
        "signature": "youtube_dl.extractor.niconico.NiconicoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group(1)\n\n        # Get video webpage. We are not actually interested in it, but need\n        # the cookies in order to be able to download the info webpage\n        self._download_webpage('http://www.nicovideo.jp/watch/' + video_id, video_id)\n\n        video_info = self._download_xml(\n            'http://ext.nicovideo.jp/api/getthumbinfo/' + video_id, video_id,\n            note=u'Downloading video info page')\n\n        # Get flv info\n        flv_info_webpage = self._download_webpage(\n            u'http://flapi.nicovideo.jp/api/getflv?v=' + video_id,\n            video_id, u'Downloading flv info')\n        video_real_url = compat_urlparse.parse_qs(flv_info_webpage)['url'][0]\n\n        # Start extracting information\n        video_title = video_info.find('.//title').text\n        video_extension = video_info.find('.//movie_type').text\n        video_format = video_extension.upper()\n        video_thumbnail = video_info.find('.//thumbnail_url').text\n        video_description = video_info.find('.//description').text\n        video_uploader_id = video_info.find('.//user_id').text\n        video_upload_date = unified_strdate(video_info.find('.//first_retrieve').text.split('+')[0])\n        video_view_count = video_info.find('.//view_counter').text\n        video_webpage_url = video_info.find('.//watch_url').text\n\n        # uploader\n        video_uploader = video_uploader_id\n        url = 'http://seiga.nicovideo.jp/api/user/info?id=' + video_uploader_id\n        try:\n            user_info = self._download_xml(\n                url, video_id, note=u'Downloading user information')\n            video_uploader = user_info.find('.//nickname').text\n        except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:\n            self._downloader.report_warning(u'Unable to download user info webpage: %s' % compat_str(err))\n\n        return {\n            'id':          video_id,\n            'url':         video_real_url,\n            'title':       video_title,\n            'ext':         video_extension,\n            'format':      video_format,\n            'thumbnail':   video_thumbnail,\n            'description': video_description,\n            'uploader':    video_uploader,\n            'upload_date': video_upload_date,\n            'uploader_id': video_uploader_id,\n            'view_count':  video_view_count,\n            'webpage_url': video_webpage_url,\n        }",
        "begin_line": 75,
        "end_line": 127,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.bliptv.BlipTVIE._real_extract#47",
        "src_path": "youtube_dl/extractor/bliptv.py",
        "class_name": "youtube_dl.extractor.bliptv.BlipTVIE",
        "signature": "youtube_dl.extractor.bliptv.BlipTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        presumptive_id = mobj.group('presumptive_id')\n\n        # See https://github.com/rg3/youtube-dl/issues/857\n        embed_mobj = re.match(r'https?://(?:\\w+\\.)?blip\\.tv/(?:play/|api\\.swf#)([a-zA-Z0-9]+)', url)\n        if embed_mobj:\n            info_url = 'http://blip.tv/play/%s.x?p=1' % embed_mobj.group(1)\n            info_page = self._download_webpage(info_url, embed_mobj.group(1))\n            video_id = self._search_regex(\n                r'data-episode-id=\"([0-9]+)', info_page, 'video_id')\n            return self.url_result('http://blip.tv/a/a-' + video_id, 'BlipTV')\n        \n        cchar = '&' if '?' in url else '?'\n        json_url = url + cchar + 'skin=json&version=2&no_wrap=1'\n        request = compat_urllib_request.Request(json_url)\n        request.add_header('User-Agent', 'iTunes/10.6.1')\n\n        json_data = self._download_json(request, video_id=presumptive_id)\n\n        if 'Post' in json_data:\n            data = json_data['Post']\n        else:\n            data = json_data\n\n        video_id = compat_str(data['item_id'])\n        upload_date = datetime.datetime.strptime(data['datestamp'], '%m-%d-%y %H:%M%p').strftime('%Y%m%d')\n        subtitles = {}\n        formats = []\n        if 'additionalMedia' in data:\n            for f in data['additionalMedia']:\n                if f.get('file_type_srt') == 1:\n                    LANGS = {\n                        'english': 'en',\n                    }\n                    lang = f['role'].rpartition('-')[-1].strip().lower()\n                    langcode = LANGS.get(lang, lang)\n                    subtitles[langcode] = f['url']\n                    continue\n                if not int(f['media_width']):  # filter m3u8\n                    continue\n                formats.append({\n                    'url': f['url'],\n                    'format_id': f['role'],\n                    'width': int(f['media_width']),\n                    'height': int(f['media_height']),\n                })\n        else:\n            formats.append({\n                'url': data['media']['url'],\n                'width': int(data['media']['width']),\n                'height': int(data['media']['height']),\n            })\n        self._sort_formats(formats)\n\n        # subtitles\n        video_subtitles = self.extract_subtitles(video_id, subtitles)\n        if self._downloader.params.get('listsubtitles', False):\n            self._list_available_subtitles(video_id, subtitles)\n            return\n\n        return {\n            'id': video_id,\n            'uploader': data['display_name'],\n            'upload_date': upload_date,\n            'title': data['title'],\n            'thumbnail': data['thumbnailUrl'],\n            'description': data['description'],\n            'user_agent': 'iTunes/10.6.1',\n            'formats': formats,\n            'subtitles': video_subtitles,\n        }",
        "begin_line": 47,
        "end_line": 118,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.bliptv.BlipTVIE._download_subtitle_url#120",
        "src_path": "youtube_dl/extractor/bliptv.py",
        "class_name": "youtube_dl.extractor.bliptv.BlipTVIE",
        "signature": "youtube_dl.extractor.bliptv.BlipTVIE._download_subtitle_url(self, sub_lang, url)",
        "snippet": "    def _download_subtitle_url(self, sub_lang, url):\n        # For some weird reason, blip.tv serves a video instead of subtitles\n        # when we request with a common UA\n        req = compat_urllib_request.Request(url)\n        req.add_header('Youtubedl-user-agent', 'youtube-dl')\n        return self._download_webpage(req, None, note=False)",
        "begin_line": 120,
        "end_line": 125,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.bliptv.BlipTVUserIE._real_extract#133",
        "src_path": "youtube_dl/extractor/bliptv.py",
        "class_name": "youtube_dl.extractor.bliptv.BlipTVUserIE",
        "signature": "youtube_dl.extractor.bliptv.BlipTVUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        username = mobj.group(1)\n\n        page_base = 'http://m.blip.tv/pr/show_get_full_episode_list?users_id=%s&lite=0&esi=1'\n\n        page = self._download_webpage(url, username, 'Downloading user page')\n        mobj = re.search(r'data-users-id=\"([^\"]+)\"', page)\n        page_base = page_base % mobj.group(1)\n\n        # Download video ids using BlipTV Ajax calls. Result size per\n        # query is limited (currently to 12 videos) so we need to query\n        # page by page until there are no video ids - it means we got\n        # all of them.\n\n        video_ids = []\n        pagenum = 1\n\n        while True:\n            url = page_base + \"&page=\" + str(pagenum)\n            page = self._download_webpage(\n                url, username, 'Downloading video ids from page %d' % pagenum)\n\n            # Extract video identifiers\n            ids_in_page = []\n\n            for mobj in re.finditer(r'href=\"/([^\"]+)\"', page):\n                if mobj.group(1) not in ids_in_page:\n                    ids_in_page.append(unescapeHTML(mobj.group(1)))\n\n            video_ids.extend(ids_in_page)\n\n            # A little optimization - if current page is not\n            # \"full\", ie. does not contain PAGE_SIZE video ids then\n            # we can assume that this page is the last one - there\n            # are no more ids on further pages - no need to query\n            # again.\n\n            if len(ids_in_page) < self._PAGE_SIZE:\n                break\n\n            pagenum += 1\n\n        urls = ['http://blip.tv/%s' % video_id for video_id in video_ids]\n        url_entries = [self.url_result(vurl, 'BlipTV') for vurl in urls]\n        return [self.playlist_result(url_entries, playlist_title=username)]",
        "begin_line": 133,
        "end_line": 178,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveIE._real_extract#154",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url, smuggled_data = unsmuggle_url(url, {})\n\n        # Change the 'videoId' and others field to '@videoPlayer'\n        url = re.sub(r'(?<=[?&])(videoI(d|D)|bctid)', '%40videoPlayer', url)\n        # Change bckey (used by bcove.me urls) to playerKey\n        url = re.sub(r'(?<=[?&])bckey', 'playerKey', url)\n        mobj = re.match(self._VALID_URL, url)\n        query_str = mobj.group('query')\n        query = compat_urlparse.parse_qs(query_str)\n\n        videoPlayer = query.get('@videoPlayer')\n        if videoPlayer:\n            # We set the original url as the default 'Referer' header\n            referer = smuggled_data.get('Referer', url)\n            return self._get_video_info(\n                videoPlayer[0], query_str, query, referer=referer)\n        else:\n            player_key = query['playerKey']\n            return self._get_playlist_info(player_key[0])",
        "begin_line": 154,
        "end_line": 173,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveIE._get_video_info#175",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveIE._get_video_info(self, video_id, query_str, query, referer=None)",
        "snippet": "    def _get_video_info(self, video_id, query_str, query, referer=None):\n        request_url = self._FEDERATED_URL_TEMPLATE % query_str\n        req = compat_urllib_request.Request(request_url)\n        linkBase = query.get('linkBaseURL')\n        if linkBase is not None:\n            referer = linkBase[0]\n        if referer is not None:\n            req.add_header('Referer', referer)\n        webpage = self._download_webpage(req, video_id)\n\n        self.report_extraction(video_id)\n        info = self._search_regex(r'var experienceJSON = ({.*?});', webpage, 'json')\n        info = json.loads(info)['data']\n        video_info = info['programmedContent']['videoPlayer']['mediaDTO']\n        video_info['_youtubedl_adServerURL'] = info.get('adServerURL')\n\n        return self._extract_video_info(video_info)",
        "begin_line": 175,
        "end_line": 191,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveIE._get_playlist_info#193",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveIE._get_playlist_info(self, player_key)",
        "snippet": "    def _get_playlist_info(self, player_key):\n        info_url = 'http://c.brightcove.com/services/json/experience/runtime/?command=get_programming_for_experience&playerKey=%s' % player_key\n        playlist_info = self._download_webpage(\n            info_url, player_key, 'Downloading playlist information')\n\n        json_data = json.loads(playlist_info)\n        if 'videoList' not in json_data:\n            raise ExtractorError('Empty playlist')\n        playlist_info = json_data['videoList']\n        videos = [self._extract_video_info(video_info) for video_info in playlist_info['mediaCollectionDTO']['videoDTOs']]\n\n        return self.playlist_result(videos, playlist_id=playlist_info['id'],\n                                    playlist_title=playlist_info['mediaCollectionDTO']['displayName'])",
        "begin_line": 193,
        "end_line": 205,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.brightcove.BrightcoveIE._extract_video_info#207",
        "src_path": "youtube_dl/extractor/brightcove.py",
        "class_name": "youtube_dl.extractor.brightcove.BrightcoveIE",
        "signature": "youtube_dl.extractor.brightcove.BrightcoveIE._extract_video_info(self, video_info)",
        "snippet": "    def _extract_video_info(self, video_info):\n        info = {\n            'id': compat_str(video_info['id']),\n            'title': video_info['displayName'].strip(),\n            'description': video_info.get('shortDescription'),\n            'thumbnail': video_info.get('videoStillURL') or video_info.get('thumbnailURL'),\n            'uploader': video_info.get('publisherName'),\n        }\n\n        renditions = video_info.get('renditions')\n        if renditions:\n            renditions = sorted(renditions, key=lambda r: r['size'])\n            info['formats'] = [{\n                'url': rend['defaultURL'],\n                'height': rend.get('frameHeight'),\n                'width': rend.get('frameWidth'),\n            } for rend in renditions]\n        elif video_info.get('FLVFullLengthURL') is not None:\n            info.update({\n                'url': video_info['FLVFullLengthURL'],\n            })\n\n        if self._downloader.params.get('include_ads', False):\n            adServerURL = video_info.get('_youtubedl_adServerURL')\n            if adServerURL:\n                ad_info = {\n                    '_type': 'url',\n                    'url': adServerURL,\n                }\n                if 'url' in info:\n                    return {\n                        '_type': 'playlist',\n                        'title': info['title'],\n                        'entries': [ad_info, info],\n                    }\n                else:\n                    return ad_info\n\n        if 'url' not in info and not info.get('formats'):\n            raise ExtractorError('Unable to extract video url for %s' % info['id'])\n        return info",
        "begin_line": 207,
        "end_line": 247,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.kontrtube.KontrTubeIE._real_extract#27",
        "src_path": "youtube_dl/extractor/kontrtube.py",
        "class_name": "youtube_dl.extractor.kontrtube.KontrTubeIE",
        "signature": "youtube_dl.extractor.kontrtube.KontrTubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id, 'Downloading page')\n\n        video_url = self._html_search_regex(r\"video_url: '(.+?)/?',\", webpage, 'video URL')\n        thumbnail = self._html_search_regex(r\"preview_url: '(.+?)/?',\", webpage, 'video thumbnail', fatal=False)\n        title = self._html_search_regex(r'<title>(.+?) - \u0422\u0440\u0443\u0431\u0430 \u0437\u043e\u0432\u0451\u0442 - \u0418\u043d\u0442\u0435\u0440\u0435\u0441\u043d\u044b\u0439 \u0432\u0438\u0434\u0435\u043e\u0445\u043e\u0441\u0442\u0438\u043d\u0433</title>', webpage,\n            'video title')\n        description = self._html_search_meta('description', webpage, 'video description')\n\n        mobj = re.search(r'<div class=\"col_2\">\u0414\u043b\u0438\u0442\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u044c: <span>(?P<minutes>\\d+)\u043c:(?P<seconds>\\d+)\u0441</span></div>',\n            webpage)\n        duration = int(mobj.group('minutes')) * 60 + int(mobj.group('seconds')) if mobj else None\n\n        view_count = self._html_search_regex(r'<div class=\"col_2\">\u041f\u0440\u043e\u0441\u043c\u043e\u0442\u0440\u043e\u0432: <span>(\\d+)</span></div>', webpage,\n            'view count', fatal=False)\n        view_count = int(view_count) if view_count is not None else None\n\n        comment_count = None\n        comment_str = self._html_search_regex(r'\u041a\u043e\u043c\u043c\u0435\u043d\u0442\u0430\u0440\u0438\u0438: <span>([^<]+)</span>', webpage, 'comment count',\n            fatal=False)\n        if comment_str.startswith('\u043a\u043e\u043c\u043c\u0435\u043d\u0442\u0430\u0440\u0438\u0435\u0432 \u043d\u0435\u0442'):\n            comment_count = 0\n        else:\n            mobj = re.search(r'\\d+ \u0438\u0437 (?P<total>\\d+) \u043a\u043e\u043c\u043c\u0435\u043d\u0442\u0430\u0440\u0438\u0435\u0432', comment_str)\n            if mobj:\n                comment_count = int(mobj.group('total'))\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'thumbnail': thumbnail,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'view_count': view_count,\n            'comment_count': comment_count,\n        }",
        "begin_line": 27,
        "end_line": 66,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.vine.VineIE._real_extract#26",
        "src_path": "youtube_dl/extractor/vine.py",
        "class_name": "youtube_dl.extractor.vine.VineIE",
        "signature": "youtube_dl.extractor.vine.VineIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage('https://vine.co/v/' + video_id, video_id)\n\n        data = json.loads(self._html_search_regex(\n            r'window\\.POST_DATA = { %s: ({.+?}) }' % video_id, webpage, 'vine data'))\n\n        formats = [\n            {\n                'url': data['videoLowURL'],\n                'ext': 'mp4',\n                'format_id': 'low',\n            },\n            {\n                'url': data['videoUrl'],\n                'ext': 'mp4',\n                'format_id': 'standard',\n            }\n        ]\n\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n            'description': data['description'],\n            'thumbnail': data['thumbnailUrl'],\n            'upload_date': unified_strdate(data['created']),\n            'uploader': data['username'],\n            'uploader_id': data['userIdStr'],\n            'like_count': data['likes']['count'],\n            'comment_count': data['comments']['count'],\n            'repost_count': data['reposts']['count'],\n            'formats': formats,\n        }",
        "begin_line": 26,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.mooshare.MooshareIE._real_extract#45",
        "src_path": "youtube_dl/extractor/mooshare.py",
        "class_name": "youtube_dl.extractor.mooshare.MooshareIE",
        "signature": "youtube_dl.extractor.mooshare.MooshareIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        page = self._download_webpage(url, video_id, 'Downloading page')\n\n        if re.search(r'>Video Not Found or Deleted<', page) is not None:\n            raise ExtractorError(u'Video %s does not exist' % video_id, expected=True)\n\n        hash_key = self._html_search_regex(r'<input type=\"hidden\" name=\"hash\" value=\"([^\"]+)\">', page, 'hash')\n        title = self._html_search_regex(r'(?m)<div class=\"blockTitle\">\\s*<h2>Watch ([^<]+)</h2>', page, 'title')\n\n        download_form = {\n            'op': 'download1',\n            'id': video_id,\n            'hash': hash_key,\n        }\n\n        request = compat_urllib_request.Request(\n            'http://mooshare.biz/%s' % video_id, compat_urllib_parse.urlencode(download_form))\n        request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n\n        self.to_screen('%s: Waiting for timeout' % video_id)\n        time.sleep(5)\n\n        video_page = self._download_webpage(request, video_id, 'Downloading video page')\n\n        thumbnail = self._html_search_regex(r'image:\\s*\"([^\"]+)\",', video_page, 'thumbnail', fatal=False)\n        duration_str = self._html_search_regex(r'duration:\\s*\"(\\d+)\",', video_page, 'duration', fatal=False)\n        duration = int(duration_str) if duration_str is not None else None\n\n        formats = []\n\n        # SD video\n        mobj = re.search(r'(?m)file:\\s*\"(?P<url>[^\"]+)\",\\s*provider:', video_page)\n        if mobj is not None:\n            formats.append({\n                'url': mobj.group('url'),\n                'format_id': 'sd',\n                'format': 'SD',\n            })\n\n        # HD video\n        mobj = re.search(r'\\'hd-2\\': { file: \\'(?P<url>[^\\']+)\\' },', video_page)\n        if mobj is not None:\n            formats.append({\n                'url': mobj.group('url'),\n                'format_id': 'hd',\n                'format': 'HD',\n            })\n\n        # rtmp video\n        mobj = re.search(r'(?m)file: \"(?P<playpath>[^\"]+)\",\\s*streamer: \"(?P<rtmpurl>rtmp://[^\"]+)\",', video_page)\n        if mobj is not None:\n            formats.append({\n                'url': mobj.group('rtmpurl'),\n                'play_path': mobj.group('playpath'),\n                'rtmp_live': False,\n                'ext': 'mp4',\n                'format_id': 'rtmp',\n                'format': 'HD',\n            })\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 45,
        "end_line": 114,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.naver.NaverIE._real_extract#24",
        "src_path": "youtube_dl/extractor/naver.py",
        "class_name": "youtube_dl.extractor.naver.NaverIE",
        "signature": "youtube_dl.extractor.naver.NaverIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group(1)\n        webpage = self._download_webpage(url, video_id)\n        m_id = re.search(r'var rmcPlayer = new nhn.rmcnmv.RMCVideoPlayer\\(\"(.+?)\", \"(.+?)\"',\n            webpage)\n        if m_id is None:\n            raise ExtractorError(u'couldn\\'t extract vid and key')\n        vid = m_id.group(1)\n        key = m_id.group(2)\n        query = compat_urllib_parse.urlencode({'vid': vid, 'inKey': key,})\n        query_urls = compat_urllib_parse.urlencode({\n            'masterVid': vid,\n            'protocol': 'p2p',\n            'inKey': key,\n        })\n        info = self._download_xml(\n            'http://serviceapi.rmcnmv.naver.com/flash/videoInfo.nhn?' + query,\n            video_id, u'Downloading video info')\n        urls = self._download_xml(\n            'http://serviceapi.rmcnmv.naver.com/flash/playableEncodingOption.nhn?' + query_urls,\n            video_id, u'Downloading video formats info')\n\n        formats = []\n        for format_el in urls.findall('EncodingOptions/EncodingOption'):\n            domain = format_el.find('Domain').text\n            if domain.startswith('rtmp'):\n                continue\n            formats.append({\n                'url': domain + format_el.find('uri').text,\n                'ext': 'mp4',\n                'width': int(format_el.find('width').text),\n                'height': int(format_el.find('height').text),\n            })\n\n        return {\n            'id': video_id,\n            'title': info.find('Subject').text,\n            'formats': formats,\n            'description': self._og_search_description(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'upload_date': info.find('WriteDate').text.replace('.', ''),\n            'view_count': int(info.find('PlayCount').text),\n        }",
        "begin_line": 24,
        "end_line": 67,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.m6.M6IE._real_extract#25",
        "src_path": "youtube_dl/extractor/m6.py",
        "class_name": "youtube_dl.extractor.m6.M6IE",
        "signature": "youtube_dl.extractor.m6.M6IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        rss = self._download_xml('http://ws.m6.fr/v1/video/info/m6/bonus/%s' % video_id, video_id,\n            'Downloading video RSS')\n\n        title = rss.find('./channel/item/title').text\n        description = rss.find('./channel/item/description').text\n        thumbnail = rss.find('./channel/item/visuel_clip_big').text\n        duration = int(rss.find('./channel/item/duration').text)\n        view_count = int(rss.find('./channel/item/nombre_vues').text)\n\n        formats = []\n        for format_id in ['lq', 'sd', 'hq', 'hd']:\n            video_url = rss.find('./channel/item/url_video_%s' % format_id)\n            if video_url is None:\n                continue\n            formats.append({\n                'url': video_url.text,\n                'format_id': format_id,\n            })\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'view_count': view_count,\n            'formats': formats,\n        }",
        "begin_line": 25,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.blinkx.BlinkxIE._real_extract#35",
        "src_path": "youtube_dl/extractor/blinkx.py",
        "class_name": "youtube_dl.extractor.blinkx.BlinkxIE",
        "signature": "youtube_dl.extractor.blinkx.BlinkxIE._real_extract(self, rl)",
        "snippet": "    def _real_extract(self, rl):\n        m = re.match(self._VALID_URL, rl)\n        video_id = m.group('id')\n        display_id = video_id[:8]\n\n        api_url = (u'https://apib4.blinkx.com/api.php?action=play_video&' +\n                   'video=%s' % video_id)\n        data_json = self._download_webpage(api_url, display_id)\n        data = json.loads(data_json)['api']['results'][0]\n        dt = datetime.datetime.fromtimestamp(data['pubdate_epoch'])\n        pload_date = dt.strftime('%Y%m%d')\n\n        duration = None\n        thumbnails = []\n        formats = []\n        for m in data['media']:\n            if m['type'] == 'jpg':\n                thumbnails.append({\n                    'url': m['link'],\n                    'width': int(m['w']),\n                    'height': int(m['h']),\n                })\n            elif m['type'] == 'original':\n                duration = m['d']\n            elif m['type'] == 'youtube':\n                yt_id = m['link']\n                self.to_screen(u'Youtube video detected: %s' % yt_id)\n                return self.url_result(yt_id, 'Youtube', video_id=yt_id)\n            elif m['type'] in ('flv', 'mp4'):\n                vcodec = remove_start(m['vcodec'], 'ff')\n                acodec = remove_start(m['acodec'], 'ff')\n                tbr = (int(m['vbr']) + int(m['abr'])) // 1000\n                format_id = (u'%s-%sk-%s' %\n                             (vcodec,\n                              tbr,\n                              m['w']))\n                formats.append({\n                    'format_id': format_id,\n                    'url': m['link'],\n                    'vcodec': vcodec,\n                    'acodec': acodec,\n                    'abr': int(m['abr']) // 1000,\n                    'vbr': int(m['vbr']) // 1000,\n                    'tbr': tbr,\n                    'width': int(m['w']),\n                    'height': int(m['h']),\n                })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': display_id,\n            'fullid': video_id,\n            'title': data['title'],\n            'formats': formats,\n            'uploader': data['channel_name'],\n            'upload_date': pload_date,\n            'description': data.get('description'),\n            'thumbnails': thumbnails,\n            'duration': duration,\n        }",
        "begin_line": 35,
        "end_line": 95,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.ina.InaIE._real_extract#21",
        "src_path": "youtube_dl/extractor/ina.py",
        "class_name": "youtube_dl.extractor.ina.InaIE",
        "signature": "youtube_dl.extractor.ina.InaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n        mrss_url = 'http://player.ina.fr/notices/%s.mrss' % video_id\n        info_doc = self._download_xml(mrss_url, video_id)\n\n        self.report_extraction(video_id)\n\n        video_url = info_doc.find('.//{http://search.yahoo.com/mrss/}player').attrib['url']\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': info_doc.find('.//title').text,\n        }",
        "begin_line": 21,
        "end_line": 36,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.__init__#25",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.__init__(self, downloader=None)",
        "snippet": "    def __init__(self,downloader=None):\n        PostProcessor.__init__(self, downloader)\n        self._exes = self.detect_executables()",
        "begin_line": 25,
        "end_line": 27,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor._get_executable#34",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor._get_executable(self)",
        "snippet": "    def _get_executable(self):\n        if self._downloader.params.get('prefer_ffmpeg', False):\n            return self._exes['ffmpeg'] or self._exes['avconv']\n        else:\n            return self._exes['avconv'] or self._exes['ffmpeg']",
        "begin_line": 34,
        "end_line": 38,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor._uses_avconv#40",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor._uses_avconv(self)",
        "snippet": "    def _uses_avconv(self):\n        return self._get_executable() == self._exes['avconv']",
        "begin_line": 40,
        "end_line": 41,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.run_ffmpeg_multiple_files#43",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.run_ffmpeg_multiple_files(self, input_paths, out_path, opts)",
        "snippet": "    def run_ffmpeg_multiple_files(self, input_paths, out_path, opts):\n        if not self._get_executable():\n            raise FFmpegPostProcessorError(u'ffmpeg or avconv not found. Please install one.')\n\n        files_cmd = []\n        for path in input_paths:\n            files_cmd.extend(['-i', encodeFilename(path, True)])\n        cmd = ([self._get_executable(), '-y'] + files_cmd\n               + opts +\n               [encodeFilename(self._ffmpeg_filename_argument(out_path), True)])\n\n        if self._downloader.params.get('verbose', False):\n            self._downloader.to_screen(u'[debug] ffmpeg command line: %s' % shell_quote(cmd))\n        p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        stdout,stderr = p.communicate()\n        if p.returncode != 0:\n            stderr = stderr.decode('utf-8', 'replace')\n            msg = stderr.strip().split('\\n')[-1]\n            raise FFmpegPostProcessorError(msg)",
        "begin_line": 43,
        "end_line": 61,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.run_ffmpeg#63",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor.run_ffmpeg(self, path, out_path, opts)",
        "snippet": "    def run_ffmpeg(self, path, out_path, opts):\n        self.run_ffmpeg_multiple_files([path], out_path, opts)",
        "begin_line": 63,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor._ffmpeg_filename_argument#66",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessor._ffmpeg_filename_argument(self, fn)",
        "snippet": "    def _ffmpeg_filename_argument(self, fn):\n        # ffmpeg broke --, see https://ffmpeg.org/trac/ffmpeg/ticket/2127 for details\n        if fn.startswith(u'-'):\n            return u'./' + fn\n        return fn",
        "begin_line": 66,
        "end_line": 70,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.__init__#74",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.__init__(self, downloader=None, preferredcodec=None, preferredquality=None, nopostoverwrites=False)",
        "snippet": "    def __init__(self, downloader=None, preferredcodec=None, preferredquality=None, nopostoverwrites=False):\n        FFmpegPostProcessor.__init__(self, downloader)\n        if preferredcodec is None:\n            preferredcodec = 'best'\n        self._preferredcodec = preferredcodec\n        self._preferredquality = preferredquality\n        self._nopostoverwrites = nopostoverwrites",
        "begin_line": 74,
        "end_line": 80,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.get_audio_codec#82",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.get_audio_codec(self, path)",
        "snippet": "    def get_audio_codec(self, path):\n        if not self._exes['ffprobe'] and not self._exes['avprobe']:\n            raise PostProcessingError(u'ffprobe or avprobe not found. Please install one.')\n        try:\n            cmd = [\n                self._exes['avprobe'] or self._exes['ffprobe'],\n                '-show_streams',\n                encodeFilename(self._ffmpeg_filename_argument(path), True)]\n            handle = subprocess.Popen(cmd, stderr=compat_subprocess_get_DEVNULL(), stdout=subprocess.PIPE)\n            output = handle.communicate()[0]\n            if handle.wait() != 0:\n                return None\n        except (IOError, OSError):\n            return None\n        audio_codec = None\n        for line in output.decode('ascii', 'ignore').split('\\n'):\n            if line.startswith('codec_name='):\n                audio_codec = line.split('=')[1].strip()\n            elif line.strip() == 'codec_type=audio' and audio_codec is not None:\n                return audio_codec\n        return None",
        "begin_line": 82,
        "end_line": 102,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.run_ffmpeg#104",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.run_ffmpeg(self, path, out_path, codec, more_opts)",
        "snippet": "    def run_ffmpeg(self, path, out_path, codec, more_opts):\n        if codec is None:\n            acodec_opts = []\n        else:\n            acodec_opts = ['-acodec', codec]\n        opts = ['-vn'] + acodec_opts + more_opts\n        try:\n            FFmpegPostProcessor.run_ffmpeg(self, path, out_path, opts)\n        except FFmpegPostProcessorError as err:\n            raise AudioConversionError(err.msg)",
        "begin_line": 104,
        "end_line": 113,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.run#115",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegExtractAudioPP.run(self, information)",
        "snippet": "    def run(self, information):\n        path = information['filepath']\n\n        filecodec = self.get_audio_codec(path)\n        if filecodec is None:\n            raise PostProcessingError(u'WARNING: unable to obtain file audio codec with ffprobe')\n\n        uses_avconv = self._uses_avconv()\n        more_opts = []\n        if self._preferredcodec == 'best' or self._preferredcodec == filecodec or (self._preferredcodec == 'm4a' and filecodec == 'aac'):\n            if filecodec == 'aac' and self._preferredcodec in ['m4a', 'best']:\n                # Lossless, but in another container\n                acodec = 'copy'\n                extension = 'm4a'\n                more_opts = ['-bsf:a' if uses_avconv else '-absf', 'aac_adtstoasc']\n            elif filecodec in ['aac', 'mp3', 'vorbis', 'opus']:\n                # Lossless if possible\n                acodec = 'copy'\n                extension = filecodec\n                if filecodec == 'aac':\n                    more_opts = ['-f', 'adts']\n                if filecodec == 'vorbis':\n                    extension = 'ogg'\n            else:\n                # MP3 otherwise.\n                acodec = 'libmp3lame'\n                extension = 'mp3'\n                more_opts = []\n                if self._preferredquality is not None:\n                    if int(self._preferredquality) < 10:\n                        more_opts += ['-q:a' if uses_avconv else '-aq', self._preferredquality]\n                    else:\n                        more_opts += ['-b:a' if uses_avconv else '-ab', self._preferredquality + 'k']\n        else:\n            # We convert the audio (lossy)\n            acodec = {'mp3': 'libmp3lame', 'aac': 'aac', 'm4a': 'aac', 'opus': 'opus', 'vorbis': 'libvorbis', 'wav': None}[self._preferredcodec]\n            extension = self._preferredcodec\n            more_opts = []\n            if self._preferredquality is not None:\n                # The opus codec doesn't support the -aq option\n                if int(self._preferredquality) < 10 and extension != 'opus':\n                    more_opts += ['-q:a' if uses_avconv else '-aq', self._preferredquality]\n                else:\n                    more_opts += ['-b:a' if uses_avconv else '-ab', self._preferredquality + 'k']\n            if self._preferredcodec == 'aac':\n                more_opts += ['-f', 'adts']\n            if self._preferredcodec == 'm4a':\n                more_opts += ['-bsf:a' if uses_avconv else '-absf', 'aac_adtstoasc']\n            if self._preferredcodec == 'vorbis':\n                extension = 'ogg'\n            if self._preferredcodec == 'wav':\n                extension = 'wav'\n                more_opts += ['-f', 'wav']\n\n        prefix, sep, ext = path.rpartition(u'.') # not os.path.splitext, since the latter does not work on unicode in all setups\n        new_path = prefix + sep + extension\n\n        # If we download foo.mp3 and convert it to... foo.mp3, then don't delete foo.mp3, silly.\n        if new_path == path:\n            self._nopostoverwrites = True\n\n        try:\n            if self._nopostoverwrites and os.path.exists(encodeFilename(new_path)):\n                self._downloader.to_screen(u'[youtube] Post-process file %s exists, skipping' % new_path)\n            else:\n                self._downloader.to_screen(u'[' + self._get_executable() + '] Destination: ' + new_path)\n                self.run_ffmpeg(path, new_path, acodec, more_opts)\n        except:\n            etype,e,tb = sys.exc_info()\n            if isinstance(e, AudioConversionError):\n                msg = u'audio conversion failed: ' + e.msg\n            else:\n                msg = u'error running ' + self._get_executable()\n            raise PostProcessingError(msg)\n\n        # Try to update the date time for extracted audio file.\n        if information.get('filetime') is not None:\n            try:\n                os.utime(encodeFilename(new_path), (time.time(), information['filetime']))\n            except:\n                self._downloader.report_warning(u'Cannot update utime of audio file')\n\n        information['filepath'] = new_path\n        return self._nopostoverwrites,information",
        "begin_line": 115,
        "end_line": 198,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegVideoConvertor.__init__#202",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegVideoConvertor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegVideoConvertor.__init__(self, downloader=None, preferedformat=None)",
        "snippet": "    def __init__(self, downloader=None,preferedformat=None):\n        super(FFmpegVideoConvertor, self).__init__(downloader)\n        self._preferedformat=preferedformat",
        "begin_line": 202,
        "end_line": 204,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegVideoConvertor.run#206",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegVideoConvertor",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegVideoConvertor.run(self, information)",
        "snippet": "    def run(self, information):\n        path = information['filepath']\n        prefix, sep, ext = path.rpartition(u'.')\n        outpath = prefix + sep + self._preferedformat\n        if information['ext'] == self._preferedformat:\n            self._downloader.to_screen(u'[ffmpeg] Not converting video file %s - already is in target format %s' % (path, self._preferedformat))\n            return True,information\n        self._downloader.to_screen(u'['+'ffmpeg'+'] Converting video from %s to %s, Destination: ' % (information['ext'], self._preferedformat) +outpath)\n        self.run_ffmpeg(path, outpath, [])\n        information['filepath'] = outpath\n        information['format'] = self._preferedformat\n        information['ext'] = self._preferedformat\n        return False,information",
        "begin_line": 206,
        "end_line": 218,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegEmbedSubtitlePP.__init__#410",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegEmbedSubtitlePP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegEmbedSubtitlePP.__init__(self, downloader=None, subtitlesformat='srt')",
        "snippet": "    def __init__(self, downloader=None, subtitlesformat='srt'):\n        super(FFmpegEmbedSubtitlePP, self).__init__(downloader)\n        self._subformat = subtitlesformat",
        "begin_line": 410,
        "end_line": 412,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegEmbedSubtitlePP.run#419",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegEmbedSubtitlePP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegEmbedSubtitlePP.run(self, information)",
        "snippet": "    def run(self, information):\n        if information['ext'] != u'mp4':\n            self._downloader.to_screen(u'[ffmpeg] Subtitles can only be embedded in mp4 files')\n            return True, information\n        if not information.get('subtitles'):\n            self._downloader.to_screen(u'[ffmpeg] There aren\\'t any subtitles to embed') \n            return True, information\n\n        sub_langs = [key for key in information['subtitles']]\n        filename = information['filepath']\n        input_files = [filename] + [subtitles_filename(filename, lang, self._subformat) for lang in sub_langs]\n\n        opts = ['-map', '0:0', '-map', '0:1', '-c:v', 'copy', '-c:a', 'copy']\n        for (i, lang) in enumerate(sub_langs):\n            opts.extend(['-map', '%d:0' % (i+1), '-c:s:%d' % i, 'mov_text'])\n            lang_code = self._conver_lang_code(lang)\n            if lang_code is not None:\n                opts.extend(['-metadata:s:s:%d' % i, 'language=%s' % lang_code])\n        opts.extend(['-f', 'mp4'])\n\n        temp_filename = filename + u'.temp'\n        self._downloader.to_screen(u'[ffmpeg] Embedding subtitles in \\'%s\\'' % filename)\n        self.run_ffmpeg_multiple_files(input_files, temp_filename, opts)\n        os.remove(encodeFilename(filename))\n        os.rename(encodeFilename(temp_filename), encodeFilename(filename))\n\n        return True, information",
        "begin_line": 419,
        "end_line": 445,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegMetadataPP.run#449",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegMetadataPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegMetadataPP.run(self, info)",
        "snippet": "    def run(self, info):\n        metadata = {}\n        if info.get('title') is not None:\n            metadata['title'] = info['title']\n        if info.get('upload_date') is not None:\n            metadata['date'] = info['upload_date']\n        if info.get('uploader') is not None:\n            metadata['artist'] = info['uploader']\n        elif info.get('uploader_id') is not None:\n            metadata['artist'] = info['uploader_id']\n\n        if not metadata:\n            self._downloader.to_screen(u'[ffmpeg] There isn\\'t any metadata to add')\n            return True, info\n\n        filename = info['filepath']\n        temp_filename = prepend_extension(filename, 'temp')\n\n        options = ['-c', 'copy']\n        for (name, value) in metadata.items():\n            options.extend(['-metadata', '%s=%s' % (name, value)])\n\n        self._downloader.to_screen(u'[ffmpeg] Adding metadata to \\'%s\\'' % filename)\n        self.run_ffmpeg(filename, temp_filename, options)\n        os.remove(encodeFilename(filename))\n        os.rename(encodeFilename(temp_filename), encodeFilename(filename))\n        return True, info",
        "begin_line": 449,
        "end_line": 475,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.postprocessor.ffmpeg.FFmpegMergerPP.run#479",
        "src_path": "youtube_dl/postprocessor/ffmpeg.py",
        "class_name": "youtube_dl.postprocessor.ffmpeg.FFmpegMergerPP",
        "signature": "youtube_dl.postprocessor.ffmpeg.FFmpegMergerPP.run(self, info)",
        "snippet": "    def run(self, info):\n        filename = info['filepath']\n        args = ['-c', 'copy']\n        self._downloader.to_screen(u'[ffmpeg] Merging formats into \"%s\"' % filename)\n        self.run_ffmpeg_multiple_files(info['__files_to_merge'], filename, args)\n        return True, info",
        "begin_line": 479,
        "end_line": 484,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.xhamster.XHamsterIE._real_extract#47",
        "src_path": "youtube_dl/extractor/xhamster.py",
        "class_name": "youtube_dl.extractor.xhamster.XHamsterIE",
        "signature": "youtube_dl.extractor.xhamster.XHamsterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self,url):\n        def extract_video_url(webpage):\n            mp4 = re.search(r'<video\\s+.*?file=\"([^\"]+)\".*?>', webpage)\n            if mp4 is None:\n                raise ExtractorError('Unable to extract media URL')\n            else:\n                return mp4.group(1)\n\n        def is_hd(webpage):\n            return '<div class=\\'icon iconHD\\'' in webpage\n\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n        seo = mobj.group('seo')\n        mrss_url = 'http://xhamster.com/movies/%s/%s.html' % (video_id, seo)\n        webpage = self._download_webpage(mrss_url, video_id)\n\n        title = self._html_search_regex(r'<title>(?P<title>.+?) - xHamster\\.com</title>', webpage, 'title')\n\n        # Only a few videos have an description\n        mobj = re.search(r'<span>Description: </span>([^<]+)', webpage)\n        description = mobj.group(1) if mobj else None\n\n        upload_date = self._html_search_regex(r'hint=\\'(\\d{4}-\\d{2}-\\d{2}) \\d{2}:\\d{2}:\\d{2} [A-Z]{3,4}\\'',\n            webpage, 'upload date', fatal=False)\n        if upload_date:\n            upload_date = unified_strdate(upload_date)\n\n        uploader_id = self._html_search_regex(r'<a href=\\'/user/[^>]+>(?P<uploader_id>[^<]+)',\n            webpage, 'uploader id', default='anonymous')\n\n        thumbnail = self._html_search_regex(r'<video\\s+.*?poster=\"([^\"]+)\".*?>', webpage, 'thumbnail', fatal=False)\n\n        duration = parse_duration(self._html_search_regex(r'<span>Runtime:</span> (\\d+:\\d+)</div>',\n            webpage, 'duration', fatal=False))\n\n        view_count = self._html_search_regex(r'<span>Views:</span> ([^<]+)</div>', webpage, 'view count', fatal=False)\n        if view_count:\n            view_count = str_to_int(view_count)\n\n        mobj = re.search(r\"hint='(?P<likecount>\\d+) Likes / (?P<dislikecount>\\d+) Dislikes'\", webpage)\n        (like_count, dislike_count) = (mobj.group('likecount'), mobj.group('dislikecount')) if mobj else (None, None)\n\n        mobj = re.search(r'</label>Comments \\((?P<commentcount>\\d+)\\)</div>', webpage)\n        comment_count = mobj.group('commentcount') if mobj else 0\n\n        age_limit = self._rta_search(webpage)\n\n        hd = is_hd(webpage)\n\n        video_url = extract_video_url(webpage)\n        formats = [{\n            'url': video_url,\n            'format_id': 'hd' if hd else 'sd',\n            'preference': 1,\n        }]\n\n        if not hd:\n            mrss_url = self._search_regex(r'<link rel=\"canonical\" href=\"([^\"]+)', webpage, 'mrss_url')\n            webpage = self._download_webpage(mrss_url + '?hd', video_id, note='Downloading HD webpage')\n            if is_hd(webpage):\n                video_url = extract_video_url(webpage)\n                formats.append({\n                    'url': video_url,\n                    'format_id': 'hd',\n                    'preference': 2,\n                })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'upload_date': upload_date,\n            'uploader_id': uploader_id,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'view_count': view_count,\n            'like_count': int_or_none(like_count),\n            'dislike_count': int_or_none(dislike_count),\n            'comment_count': int_or_none(comment_count),\n            'age_limit': age_limit,\n            'formats': formats,\n        }",
        "begin_line": 47,
        "end_line": 132,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.techtalks.TechTalksIE._real_extract#35",
        "src_path": "youtube_dl/extractor/techtalks.py",
        "class_name": "youtube_dl.extractor.techtalks.TechTalksIE",
        "signature": "youtube_dl.extractor.techtalks.TechTalksIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        talk_id = mobj.group('id')\n        webpage = self._download_webpage(url, talk_id)\n        rtmp_url = self._search_regex(r'netConnectionUrl: \\'(.*?)\\'', webpage,\n            u'rtmp url')\n        play_path = self._search_regex(r'href=\\'(.*?)\\' [^>]*id=\"flowplayer_presenter\"',\n            webpage, u'presenter play path')\n        title = clean_html(get_element_by_attribute('class', 'title', webpage))\n        video_info = {\n                'id': talk_id,\n                'title': title,\n                'url': rtmp_url,\n                'play_path': play_path,\n                'ext': 'flv',\n            }\n        m_slides = re.search(r'<a class=\"slides\" href=\\'(.*?)\\'', webpage)\n        if m_slides is None:\n            return video_info\n        else:\n            return [\n                video_info,\n                # The slides video\n                {\n                    'id': talk_id + '-slides',\n                    'title': title,\n                    'url': rtmp_url,\n                    'play_path': m_slides.group(1),\n                    'ext': 'flv',\n                },\n            ]",
        "begin_line": 35,
        "end_line": 65,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.ivi.IviIE._extract_description#55",
        "src_path": "youtube_dl/extractor/ivi.py",
        "class_name": "youtube_dl.extractor.ivi.IviIE",
        "signature": "youtube_dl.extractor.ivi.IviIE._extract_description(self, html)",
        "snippet": "    def _extract_description(self, html):\n        m = re.search(r'<meta name=\"description\" content=\"(?P<description>[^\"]+)\"/>', html)\n        return m.group('description') if m is not None else None",
        "begin_line": 55,
        "end_line": 57,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.ivi.IviIE._extract_comment_count#59",
        "src_path": "youtube_dl/extractor/ivi.py",
        "class_name": "youtube_dl.extractor.ivi.IviIE",
        "signature": "youtube_dl.extractor.ivi.IviIE._extract_comment_count(self, html)",
        "snippet": "    def _extract_comment_count(self, html):\n        m = re.search('(?s)<a href=\"#\" id=\"view-comments\" class=\"action-button dim gradient\">\\s*\u041a\u043e\u043c\u043c\u0435\u043d\u0442\u0430\u0440\u0438\u0438:\\s*(?P<commentcount>\\d+)\\s*</a>', html)\n        return int(m.group('commentcount')) if m is not None else 0",
        "begin_line": 59,
        "end_line": 61,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.ivi.IviIE._real_extract#63",
        "src_path": "youtube_dl/extractor/ivi.py",
        "class_name": "youtube_dl.extractor.ivi.IviIE",
        "signature": "youtube_dl.extractor.ivi.IviIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n\n        api_url = 'http://api.digitalaccess.ru/api/json/'\n\n        data = {'method': 'da.content.get',\n                'params': [video_id, {'site': 's183',\n                                      'referrer': 'http://www.ivi.ru/watch/%s' % video_id,\n                                      'contentid': video_id\n                                      }\n                           ]\n                }\n\n        request = compat_urllib_request.Request(api_url, json.dumps(data))\n\n        video_json_page = self._download_webpage(request, video_id, 'Downloading video JSON')\n        video_json = json.loads(video_json_page)\n\n        if 'error' in video_json:\n            error = video_json['error']\n            if error['origin'] == 'NoRedisValidData':\n                raise ExtractorError('Video %s does not exist' % video_id, expected=True)\n            raise ExtractorError('Unable to download video %s: %s' % (video_id, error['message']), expected=True)\n\n        result = video_json['result']\n\n        formats = [{\n            'url': x['url'],\n            'format_id': x['content_format'],\n            'preference': self._known_formats.index(x['content_format']),\n        } for x in result['files'] if x['content_format'] in self._known_formats]\n\n        self._sort_formats(formats)\n\n        if not formats:\n            raise ExtractorError('No media links available for %s' % video_id)\n\n        duration = result['duration']\n        compilation = result['compilation']\n        title = result['title']\n\n        title = '%s - %s' % (compilation, title) if compilation is not None else title  \n\n        previews = result['preview']\n        previews.sort(key=lambda fmt: self._known_thumbnails.index(fmt['content_format']))\n        thumbnail = previews[-1]['url'] if len(previews) > 0 else None\n\n        video_page = self._download_webpage(url, video_id, 'Downloading video page')\n        description = self._extract_description(video_page)\n        comment_count = self._extract_comment_count(video_page)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'description': description,\n            'duration': duration,\n            'comment_count': comment_count,\n            'formats': formats,\n        }",
        "begin_line": 63,
        "end_line": 123,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.ivi.IviCompilationIE._extract_entries#131",
        "src_path": "youtube_dl/extractor/ivi.py",
        "class_name": "youtube_dl.extractor.ivi.IviCompilationIE",
        "signature": "youtube_dl.extractor.ivi.IviCompilationIE._extract_entries(self, html, compilation_id)",
        "snippet": "    def _extract_entries(self, html, compilation_id):\n        return [self.url_result('http://www.ivi.ru/watch/%s/%s' % (compilation_id, serie), 'Ivi')\n                for serie in re.findall(r'<strong><a href=\"/watch/%s/(\\d+)\">(?:[^<]+)</a></strong>' % compilation_id, html)]",
        "begin_line": 131,
        "end_line": 133,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.ivi.IviCompilationIE._real_extract#135",
        "src_path": "youtube_dl/extractor/ivi.py",
        "class_name": "youtube_dl.extractor.ivi.IviCompilationIE",
        "signature": "youtube_dl.extractor.ivi.IviCompilationIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        compilation_id = mobj.group('compilationid')\n        season_id = mobj.group('seasonid')\n\n        if season_id is not None: # Season link\n            season_page = self._download_webpage(url, compilation_id, 'Downloading season %s web page' % season_id)\n            playlist_id = '%s/season%s' % (compilation_id, season_id)\n            playlist_title = self._html_search_meta('title', season_page, 'title')\n            entries = self._extract_entries(season_page, compilation_id)\n        else: # Compilation link            \n            compilation_page = self._download_webpage(url, compilation_id, 'Downloading compilation web page')\n            playlist_id = compilation_id\n            playlist_title = self._html_search_meta('title', compilation_page, 'title')\n            seasons = re.findall(r'<a href=\"/watch/%s/season(\\d+)\">[^<]+</a>' % compilation_id, compilation_page)\n            if len(seasons) == 0: # No seasons in this compilation\n                entries = self._extract_entries(compilation_page, compilation_id)\n            else:\n                entries = []\n                for season_id in seasons:\n                    season_page = self._download_webpage(\n                        'http://www.ivi.ru/watch/%s/season%s' % (compilation_id, season_id),\n                        compilation_id, 'Downloading season %s web page' % season_id)\n                    entries.extend(self._extract_entries(season_page, compilation_id))\n\n        return self.playlist_result(entries, playlist_id, playlist_title)",
        "begin_line": 135,
        "end_line": 160,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.pyvideo.PyvideoIE._real_extract#33",
        "src_path": "youtube_dl/extractor/pyvideo.py",
        "class_name": "youtube_dl.extractor.pyvideo.PyvideoIE",
        "signature": "youtube_dl.extractor.pyvideo.PyvideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        m_youtube = re.search(r'(https?://www\\.youtube\\.com/watch\\?v=.*)', webpage)\n\n        if m_youtube is not None:\n            return self.url_result(m_youtube.group(1), 'Youtube')\n\n        title = self._html_search_regex(r'<div class=\"section\">.*?<h3>([^>]+?)</h3>',\n            webpage, u'title', flags=re.DOTALL)\n        video_url = self._search_regex([r'<source src=\"(.*?)\"',\n            r'<dt>Download</dt>.*?<a href=\"(.+?)\"'],\n            webpage, u'video url', flags=re.DOTALL)\n        return {\n            'id': video_id,\n            'title': os.path.splitext(title)[0],\n            'url': video_url,\n        }",
        "begin_line": 33,
        "end_line": 51,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.franceinter.FranceInterIE._real_extract#20",
        "src_path": "youtube_dl/extractor/franceinter.py",
        "class_name": "youtube_dl.extractor.franceinter.FranceInterIE",
        "signature": "youtube_dl.extractor.franceinter.FranceInterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        title = self._html_search_regex(\n            r'<span class=\"roll_overflow\">(.*?)</span></h1>', webpage, 'title')\n        path = self._search_regex(\n            r'&urlAOD=(.*?)&startTime', webpage, 'video url')\n        video_url = 'http://www.franceinter.fr/' + path\n\n        return {\n            'id': video_id,\n            'formats': [{\n                'url': video_url,\n                'vcodec': 'none',\n            }],\n            'title': title,\n        }",
        "begin_line": 20,
        "end_line": 38,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.myspass.MySpassIE._real_extract#24",
        "src_path": "youtube_dl/extractor/myspass.py",
        "class_name": "youtube_dl.extractor.myspass.MySpassIE",
        "signature": "youtube_dl.extractor.myspass.MySpassIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        META_DATA_URL_TEMPLATE = 'http://www.myspass.de/myspass/includes/apps/video/getvideometadataxml.php?id=%s'\n\n        # video id is the last path element of the URL\n        # usually there is a trailing slash, so also try the second but last\n        url_path = compat_urllib_parse_urlparse(url).path\n        url_parent_path, video_id = os.path.split(url_path)\n        if not video_id:\n            _, video_id = os.path.split(url_parent_path)\n\n        # get metadata\n        metadata_url = META_DATA_URL_TEMPLATE % video_id\n        metadata = self._download_xml(metadata_url, video_id)\n\n        # extract values from metadata\n        url_flv_el = metadata.find('url_flv')\n        if url_flv_el is None:\n            raise ExtractorError('Unable to extract download url')\n        video_url = url_flv_el.text\n        title_el = metadata.find('title')\n        if title_el is None:\n            raise ExtractorError('Unable to extract title')\n        title = title_el.text\n        format_id_el = metadata.find('format_id')\n        if format_id_el is None:\n            format = 'mp4'\n        else:\n            format = format_id_el.text\n        description_el = metadata.find('description')\n        if description_el is not None:\n            description = description_el.text\n        else:\n            description = None\n        imagePreview_el = metadata.find('imagePreview')\n        if imagePreview_el is not None:\n            thumbnail = imagePreview_el.text\n        else:\n            thumbnail = None\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'format': format,\n            'thumbnail': thumbnail,\n            'description': description,\n        }",
        "begin_line": 24,
        "end_line": 70,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.nba.NBAIE._real_extract#20",
        "src_path": "youtube_dl/extractor/nba.py",
        "class_name": "youtube_dl.extractor.nba.NBAIE",
        "signature": "youtube_dl.extractor.nba.NBAIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group(1)\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = 'http://ht-mobile.cdn.turner.com/nba/big' + video_id + '_nba_1280x720.mp4'\n\n        shortened_video_id = video_id.rpartition('/')[2]\n        title = self._og_search_title(webpage, default=shortened_video_id).replace('NBA.com: ', '')\n\n        description = self._html_search_regex(r'<meta name=\"description\" (?:content|value)=\"(.*?)\" />', webpage, 'description', fatal=False)\n\n        return {\n            'id': shortened_video_id,\n            'url': video_url,\n            'ext': 'mp4',\n            'title': title,\n            'description': description,\n        }",
        "begin_line": 20,
        "end_line": 39,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.sztvhu.SztvHuIE._real_extract#22",
        "src_path": "youtube_dl/extractor/sztvhu.py",
        "class_name": "youtube_dl.extractor.sztvhu.SztvHuIE",
        "signature": "youtube_dl.extractor.sztvhu.SztvHuIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        video_file = self._search_regex(\n            r'file: \"...:(.*?)\",', webpage, 'video file')\n        title = self._html_search_regex(\n            r'<meta name=\"title\" content=\"([^\"]*?) - [^-]*? - [^-]*?\"',\n            webpage, 'video title')\n        description = self._html_search_regex(\n            r'<meta name=\"description\" content=\"([^\"]*)\"/>',\n            webpage, 'video description', fatal=False)\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        video_url = 'http://media.sztv.hu/vod/' + video_file\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'ext': determine_ext(video_url),\n            'description': description,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 22,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.compat_ord#183",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.compat_ord(c)",
        "snippet": "def compat_ord(c):\n    if type(c) is int: return c\n    else: return ord(c)",
        "begin_line": 183,
        "end_line": 185,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.preferredencoding#198",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.preferredencoding()",
        "snippet": "def preferredencoding():\n    \"\"\"Get preferred encoding.\n\n    Returns the best encoding scheme for the system, based on\n    locale.getpreferredencoding() and some further tweaks.\n    \"\"\"\n    try:\n        pref = locale.getpreferredencoding()\n        u'TEST'.encode(pref)\n    except:\n        pref = 'UTF-8'\n\n    return pref",
        "begin_line": 198,
        "end_line": 210,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.compat_print#216",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.compat_print(s)",
        "snippet": "    def compat_print(s):\n        assert type(s) == type(u'')\n        print(s)",
        "begin_line": 216,
        "end_line": 218,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.write_json_file#227",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.write_json_file(obj, fn)",
        "snippet": "    def write_json_file(obj, fn):\n        with open(fn, 'w', encoding='utf-8') as f:\n            json.dump(obj, f)",
        "begin_line": 227,
        "end_line": 229,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.find_xpath_attr#232",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.find_xpath_attr(node, xpath, key, val)",
        "snippet": "    def find_xpath_attr(node, xpath, key, val):\n        \"\"\" Find the xpath xpath[@key=val] \"\"\"\n        assert re.match(r'^[a-zA-Z]+$', key)\n        assert re.match(r'^[a-zA-Z0-9@\\s:._]*$', val)\n        expr = xpath + u\"[@%s='%s']\" % (key, val)\n        return node.find(expr)",
        "begin_line": 232,
        "end_line": 237,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.006711409395973154,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.xpath_with_ns#247",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.xpath_with_ns(path, ns_map)",
        "snippet": "def xpath_with_ns(path, ns_map):\n    components = [c.split(':') for c in path.split('/')]\n    replaced = []\n    for c in components:\n        if len(c) == 1:\n            replaced.append(c[0])\n        else:\n            ns, tag = c\n            replaced.append('{%s}%s' % (ns_map[ns], tag))\n    return '/'.join(replaced)",
        "begin_line": 247,
        "end_line": 256,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.006711409395973154,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.htmlentity_transform#258",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.htmlentity_transform(matchobj)",
        "snippet": "def htmlentity_transform(matchobj):\n    \"\"\"Transforms an HTML entity to a character.\n\n    This function receives a match object and is intended to be used with\n    the re.sub() function.\n    \"\"\"\n    entity = matchobj.group(1)\n\n    # Known non-numeric HTML entity\n    if entity in compat_html_entities.name2codepoint:\n        return compat_chr(compat_html_entities.name2codepoint[entity])\n\n    mobj = re.match(u'(?u)#(x?\\\\d+)', entity)\n    if mobj is not None:\n        numstr = mobj.group(1)\n        if numstr.startswith(u'x'):\n            base = 16\n            numstr = u'0%s' % numstr\n        else:\n            base = 10\n        return compat_chr(int(numstr, base))\n\n    # Unknown entity in name, return its literal representation\n    return (u'&%s;' % entity)",
        "begin_line": 258,
        "end_line": 281,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.BaseHTMLParser.__init#285",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.BaseHTMLParser",
        "signature": "youtube_dl.utils.BaseHTMLParser.__init(self)",
        "snippet": "    def __init(self):\n        compat_html_parser.HTMLParser.__init__(self)\n        self.html = None",
        "begin_line": 285,
        "end_line": 287,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.BaseHTMLParser.loads#289",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.BaseHTMLParser",
        "signature": "youtube_dl.utils.BaseHTMLParser.loads(self, html)",
        "snippet": "    def loads(self, html):\n        self.html = html\n        self.feed(html)\n        self.close()",
        "begin_line": 289,
        "end_line": 292,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.006711409395973154,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.AttrParser.__init__#296",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.AttrParser",
        "signature": "youtube_dl.utils.AttrParser.__init__(self, attribute, value)",
        "snippet": "    def __init__(self, attribute, value):\n        self.attribute = attribute\n        self.value = value\n        self.result = None\n        self.started = False\n        self.depth = {}\n        self.watch_startpos = False\n        self.error_count = 0\n        BaseHTMLParser.__init__(self)",
        "begin_line": 296,
        "end_line": 304,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.AttrParser.error#306",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.AttrParser",
        "signature": "youtube_dl.utils.AttrParser.error(self, message)",
        "snippet": "    def error(self, message):\n        if self.error_count > 10 or self.started:\n            raise compat_html_parser.HTMLParseError(message, self.getpos())\n        self.rawdata = '\\n'.join(self.html.split('\\n')[self.getpos()[0]:]) # skip one line\n        self.error_count += 1\n        self.goahead(1)",
        "begin_line": 306,
        "end_line": 311,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.AttrParser.handle_starttag#313",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.AttrParser",
        "signature": "youtube_dl.utils.AttrParser.handle_starttag(self, tag, attrs)",
        "snippet": "    def handle_starttag(self, tag, attrs):\n        attrs = dict(attrs)\n        if self.started:\n            self.find_startpos(None)\n        if self.attribute in attrs and attrs[self.attribute] == self.value:\n            self.result = [tag]\n            self.started = True\n            self.watch_startpos = True\n        if self.started:\n            if not tag in self.depth: self.depth[tag] = 0\n            self.depth[tag] += 1",
        "begin_line": 313,
        "end_line": 323,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.AttrParser.handle_endtag#325",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.AttrParser",
        "signature": "youtube_dl.utils.AttrParser.handle_endtag(self, tag)",
        "snippet": "    def handle_endtag(self, tag):\n        if self.started:\n            if tag in self.depth: self.depth[tag] -= 1\n            if self.depth[self.result[0]] == 0:\n                self.started = False\n                self.result.append(self.getpos())",
        "begin_line": 325,
        "end_line": 330,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.AttrParser.find_startpos#332",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.AttrParser",
        "signature": "youtube_dl.utils.AttrParser.find_startpos(self, x)",
        "snippet": "    def find_startpos(self, x):\n        \"\"\"Needed to put the start position of the result (self.result[1])\n        after the opening tag with the requested id\"\"\"\n        if self.watch_startpos:\n            self.watch_startpos = False\n            self.result.append(self.getpos())",
        "begin_line": 332,
        "end_line": 337,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.AttrParser.get_result#341",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.AttrParser",
        "signature": "youtube_dl.utils.AttrParser.get_result(self)",
        "snippet": "    def get_result(self):\n        if self.result is None:\n            return None\n        if len(self.result) != 3:\n            return None\n        lines = self.html.split('\\n')\n        lines = lines[self.result[1][0]-1:self.result[2][0]]\n        lines[0] = lines[0][self.result[1][1]:]\n        if len(lines) == 1:\n            lines[-1] = lines[-1][:self.result[2][1]-self.result[1][1]]\n        lines[-1] = lines[-1][:self.result[2][1]]\n        return '\\n'.join(lines).strip()",
        "begin_line": 341,
        "end_line": 352,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.get_element_by_id#360",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.get_element_by_id(id, html)",
        "snippet": "def get_element_by_id(id, html):\n    \"\"\"Return the content of the tag with the specified ID in the passed HTML document\"\"\"\n    return get_element_by_attribute(\"id\", id, html)",
        "begin_line": 360,
        "end_line": 362,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.get_element_by_attribute#364",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.get_element_by_attribute(attribute, value, html)",
        "snippet": "def get_element_by_attribute(attribute, value, html):\n    \"\"\"Return the content of the tag with the specified attribute in the passed HTML document\"\"\"\n    parser = AttrParser(attribute, value)\n    try:\n        parser.loads(html)\n    except compat_html_parser.HTMLParseError:\n        pass\n    return parser.get_result()",
        "begin_line": 364,
        "end_line": 371,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.MetaParser.__init__#378",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.MetaParser",
        "signature": "youtube_dl.utils.MetaParser.__init__(self, name)",
        "snippet": "    def __init__(self, name):\n        BaseHTMLParser.__init__(self)\n        self.name = name\n        self.content = None\n        self.result = None",
        "begin_line": 378,
        "end_line": 382,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.006711409395973154,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.MetaParser.handle_starttag#384",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.MetaParser",
        "signature": "youtube_dl.utils.MetaParser.handle_starttag(self, tag, attrs)",
        "snippet": "    def handle_starttag(self, tag, attrs):\n        if tag != 'meta':\n            return\n        attrs = dict(attrs)\n        if attrs.get('name') == self.name:\n            self.result = attrs.get('content')",
        "begin_line": 384,
        "end_line": 389,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.006711409395973154,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.MetaParser.get_result#391",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.MetaParser",
        "signature": "youtube_dl.utils.MetaParser.get_result(self)",
        "snippet": "    def get_result(self):\n        return self.result",
        "begin_line": 391,
        "end_line": 392,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.006711409395973154,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.get_meta_content#394",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.get_meta_content(name, html)",
        "snippet": "def get_meta_content(name, html):\n    \"\"\"\n    Return the content attribute from the meta tag with the given name attribute.\n    \"\"\"\n    parser = MetaParser(name)\n    try:\n        parser.loads(html)\n    except compat_html_parser.HTMLParseError:\n        pass\n    return parser.get_result()",
        "begin_line": 394,
        "end_line": 403,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.006711409395973154,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.clean_html#406",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.clean_html(html)",
        "snippet": "def clean_html(html):\n    \"\"\"Clean an HTML snippet into a readable string\"\"\"\n    # Newline vs <br />\n    html = html.replace('\\n', ' ')\n    html = re.sub(r'\\s*<\\s*br\\s*/?\\s*>\\s*', '\\n', html)\n    html = re.sub(r'<\\s*/\\s*p\\s*>\\s*<\\s*p[^>]*>', '\\n', html)\n    # Strip html tags\n    html = re.sub('<.*?>', '', html)\n    # Replace html entities\n    html = unescapeHTML(html)\n    return html.strip()",
        "begin_line": 406,
        "end_line": 416,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.sanitize_open#419",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.sanitize_open(filename, open_mode)",
        "snippet": "def sanitize_open(filename, open_mode):\n    \"\"\"Try to open the given filename, and slightly tweak it if this fails.\n\n    Attempts to open the given filename. If this fails, it tries to change\n    the filename slightly, step by step, until it's either able to open it\n    or it fails and raises a final exception, like the standard open()\n    function.\n\n    It returns the tuple (stream, definitive_file_name).\n    \"\"\"\n    try:\n        if filename == u'-':\n            if sys.platform == 'win32':\n                import msvcrt\n                msvcrt.setmode(sys.stdout.fileno(), os.O_BINARY)\n            return (sys.stdout.buffer if hasattr(sys.stdout, 'buffer') else sys.stdout, filename)\n        stream = open(encodeFilename(filename), open_mode)\n        return (stream, filename)\n    except (IOError, OSError) as err:\n        if err.errno in (errno.EACCES,):\n            raise\n\n        # In case of error, try to remove win32 forbidden chars\n        alt_filename = os.path.join(\n                        re.sub(u'[/<>:\"\\\\|\\\\\\\\?\\\\*]', u'#', path_part)\n                        for path_part in os.path.split(filename)\n                       )\n        if alt_filename == filename:\n            raise\n        else:\n            # An exception here should be caught in the caller\n            stream = open(encodeFilename(filename), open_mode)\n            return (stream, alt_filename)",
        "begin_line": 419,
        "end_line": 451,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.timeconvert#454",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.timeconvert(timestr)",
        "snippet": "def timeconvert(timestr):\n    \"\"\"Convert RFC 2822 defined time string into system timestamp\"\"\"\n    timestamp = None\n    timetuple = email.utils.parsedate_tz(timestr)\n    if timetuple is not None:\n        timestamp = email.utils.mktime_tz(timetuple)\n    return timestamp",
        "begin_line": 454,
        "end_line": 460,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.006711409395973154,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.sanitize_filename#462",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.sanitize_filename(s, restricted=False, is_id=False)",
        "snippet": "def sanitize_filename(s, restricted=False, is_id=False):\n    \"\"\"Sanitizes a string so it could be used as part of a filename.\n    If restricted is set, use a stricter subset of allowed characters.\n    Set is_id if this is not an arbitrary string, but an ID that should be kept if possible\n    \"\"\"\n    def replace_insane(char):\n        if char == '?' or ord(char) < 32 or ord(char) == 127:\n            return ''\n        elif char == '\"':\n            return '' if restricted else '\\''\n        elif char == ':':\n            return '_-' if restricted else ' -'\n        elif char in '\\\\/|*<>':\n            return '_'\n        if restricted and (char in '!&\\'()[]{}$;`^,#' or char.isspace()):\n            return '_'\n        if restricted and ord(char) > 127:\n            return '_'\n        return char\n\n    result = u''.join(map(replace_insane, s))\n    if not is_id:\n        while '__' in result:\n            result = result.replace('__', '_')\n        result = result.strip('_')\n        # Common case of \"Foreign band name - English song title\"\n        if restricted and result.startswith('-_'):\n            result = result[2:]\n        if not result:\n            result = '_'\n    return result",
        "begin_line": 462,
        "end_line": 492,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.006711409395973154,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.replace_insane#467",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.replace_insane(char)",
        "snippet": "    def replace_insane(char):\n        if char == '?' or ord(char) < 32 or ord(char) == 127:\n            return ''\n        elif char == '\"':\n            return '' if restricted else '\\''\n        elif char == ':':\n            return '_-' if restricted else ' -'\n        elif char in '\\\\/|*<>':\n            return '_'\n        if restricted and (char in '!&\\'()[]{}$;`^,#' or char.isspace()):\n            return '_'\n        if restricted and ord(char) > 127:\n            return '_'\n        return char",
        "begin_line": 467,
        "end_line": 480,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.006711409395973154,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.orderedSet#494",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.orderedSet(iterable)",
        "snippet": "def orderedSet(iterable):\n    \"\"\" Remove all duplicates from the input iterable \"\"\"\n    res = []\n    for el in iterable:\n        if el not in res:\n            res.append(el)\n    return res",
        "begin_line": 494,
        "end_line": 500,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.006711409395973154,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.unescapeHTML#502",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.unescapeHTML(s)",
        "snippet": "def unescapeHTML(s):\n    \"\"\"\n    @param s a string\n    \"\"\"\n    assert type(s) == type(u'')\n\n    result = re.sub(u'(?u)&(.+?);', htmlentity_transform, s)\n    return result",
        "begin_line": 502,
        "end_line": 509,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.006711409395973154,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.encodeFilename#512",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.encodeFilename(s, for_subprocess=False)",
        "snippet": "def encodeFilename(s, for_subprocess=False):\n    \"\"\"\n    @param s The name of the file\n    \"\"\"\n\n    assert type(s) == compat_str\n\n    # Python 3 has a Unicode API\n    if sys.version_info >= (3, 0):\n        return s\n\n    if sys.platform == 'win32' and sys.getwindowsversion()[0] >= 5:\n        # Pass u'' directly to use Unicode APIs on Windows 2000 and up\n        # (Detecting Windows NT 4 is tricky because 'major >= 4' would\n        # match Windows 9x series as well. Besides, NT 4 is obsolete.)\n        if not for_subprocess:\n            return s\n        else:\n            # For subprocess calls, encode with locale encoding\n            # Refer to http://stackoverflow.com/a/9951851/35070\n            encoding = preferredencoding()\n    else:\n        encoding = sys.getfilesystemencoding()\n    if encoding is None:\n        encoding = 'utf-8'\n    return s.encode(encoding, 'ignore')",
        "begin_line": 512,
        "end_line": 537,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.006711409395973154,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.decodeOption#540",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.decodeOption(optval)",
        "snippet": "def decodeOption(optval):\n    if optval is None:\n        return optval\n    if isinstance(optval, bytes):\n        optval = optval.decode(preferredencoding())\n\n    assert isinstance(optval, compat_str)\n    return optval",
        "begin_line": 540,
        "end_line": 547,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.formatSeconds#549",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.formatSeconds(secs)",
        "snippet": "def formatSeconds(secs):\n    if secs > 3600:\n        return '%d:%02d:%02d' % (secs // 3600, (secs % 3600) // 60, secs % 60)\n    elif secs > 60:\n        return '%d:%02d' % (secs // 60, secs % 60)\n    else:\n        return '%d' % secs",
        "begin_line": 549,
        "end_line": 555,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.make_HTTPS_handler#558",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.make_HTTPS_handler(opts_no_check_certificate, **kwargs)",
        "snippet": "def make_HTTPS_handler(opts_no_check_certificate, **kwargs):\n    if sys.version_info < (3, 2):\n        import httplib\n\n        class HTTPSConnectionV3(httplib.HTTPSConnection):\n            def __init__(self, *args, **kwargs):\n                httplib.HTTPSConnection.__init__(self, *args, **kwargs)\n\n            def connect(self):\n                sock = socket.create_connection((self.host, self.port), self.timeout)\n                if getattr(self, '_tunnel_host', False):\n                    self.sock = sock\n                    self._tunnel()\n                try:\n                    self.sock = ssl.wrap_socket(sock, self.key_file, self.cert_file, ssl_version=ssl.PROTOCOL_SSLv3)\n                except ssl.SSLError:\n                    self.sock = ssl.wrap_socket(sock, self.key_file, self.cert_file, ssl_version=ssl.PROTOCOL_SSLv23)\n\n        class HTTPSHandlerV3(compat_urllib_request.HTTPSHandler):\n            def https_open(self, req):\n                return self.do_open(HTTPSConnectionV3, req)\n        return HTTPSHandlerV3(**kwargs)\n    else:\n        context = ssl.SSLContext(ssl.PROTOCOL_SSLv3)\n        context.verify_mode = (ssl.CERT_NONE\n                               if opts_no_check_certificate\n                               else ssl.CERT_REQUIRED)\n        context.set_default_verify_paths()\n        try:\n            context.load_default_certs()\n        except AttributeError:\n            pass  # Python < 3.4\n        return compat_urllib_request.HTTPSHandler(context=context, **kwargs)",
        "begin_line": 558,
        "end_line": 590,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0625,
            "pseudo_dstar_susp": 0.0625,
            "pseudo_tarantula_susp": 0.041666666666666664,
            "pseudo_op2_susp": 0.0625,
            "pseudo_barinel_susp": 0.041666666666666664
        }
    },
    {
        "name": "youtube_dl.utils.ExtractorError.__init__#594",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.ExtractorError",
        "signature": "youtube_dl.utils.ExtractorError.__init__(self, msg, tb=None, expected=False, cause=None)",
        "snippet": "    def __init__(self, msg, tb=None, expected=False, cause=None):\n        \"\"\" tb, if given, is the original traceback (so that it can be printed out).\n        If expected is set, this is a normal error message and most likely not a bug in youtube-dl.\n        \"\"\"\n\n        if sys.exc_info()[0] in (compat_urllib_error.URLError, socket.timeout, UnavailableVideoError):\n            expected = True\n        if not expected:\n            msg = msg + u'; please report this issue on https://yt-dl.org/bug . Be sure to call youtube-dl with the --verbose flag and include its complete output. Make sure you are using the latest version; type  youtube-dl -U  to update.'\n        super(ExtractorError, self).__init__(msg)\n\n        self.traceback = tb\n        self.exc_info = sys.exc_info()  # preserve original exception\n        self.cause = cause",
        "begin_line": 594,
        "end_line": 607,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.ExtractorError.format_traceback#609",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.ExtractorError",
        "signature": "youtube_dl.utils.ExtractorError.format_traceback(self)",
        "snippet": "    def format_traceback(self):\n        if self.traceback is None:\n            return None\n        return u''.join(traceback.format_tb(self.traceback))",
        "begin_line": 609,
        "end_line": 612,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.DownloadError.__init__#627",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.DownloadError",
        "signature": "youtube_dl.utils.DownloadError.__init__(self, msg, exc_info=None)",
        "snippet": "    def __init__(self, msg, exc_info=None):\n        \"\"\" exc_info, if given, is the original exception that caused the trouble (as returned by sys.exc_info()). \"\"\"\n        super(DownloadError, self).__init__(msg)\n        self.exc_info = exc_info",
        "begin_line": 627,
        "end_line": 630,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.PostProcessingError.__init__#648",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.PostProcessingError",
        "signature": "youtube_dl.utils.PostProcessingError.__init__(self, msg)",
        "snippet": "    def __init__(self, msg):\n        self.msg = msg",
        "begin_line": 648,
        "end_line": 649,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.ContentTooShortError.__init__#676",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.ContentTooShortError",
        "signature": "youtube_dl.utils.ContentTooShortError.__init__(self, downloaded, expected)",
        "snippet": "    def __init__(self, downloaded, expected):\n        self.downloaded = downloaded\n        self.expected = expected",
        "begin_line": 676,
        "end_line": 678,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.YoutubeDLHandler.http_request#713",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.YoutubeDLHandler",
        "signature": "youtube_dl.utils.YoutubeDLHandler.http_request(self, req)",
        "snippet": "    def http_request(self, req):\n        for h,v in std_headers.items():\n            if h in req.headers:\n                del req.headers[h]\n            req.add_header(h, v)\n        if 'Youtubedl-no-compression' in req.headers:\n            if 'Accept-encoding' in req.headers:\n                del req.headers['Accept-encoding']\n            del req.headers['Youtubedl-no-compression']\n        if 'Youtubedl-user-agent' in req.headers:\n            if 'User-agent' in req.headers:\n                del req.headers['User-agent']\n            req.headers['User-agent'] = req.headers['Youtubedl-user-agent']\n            del req.headers['Youtubedl-user-agent']\n        return req",
        "begin_line": 713,
        "end_line": 727,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.YoutubeDLHandler.http_response#729",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.YoutubeDLHandler",
        "signature": "youtube_dl.utils.YoutubeDLHandler.http_response(self, req, resp)",
        "snippet": "    def http_response(self, req, resp):\n        old_resp = resp\n        # gzip\n        if resp.headers.get('Content-encoding', '') == 'gzip':\n            content = resp.read()\n            gz = gzip.GzipFile(fileobj=io.BytesIO(content), mode='rb')\n            try:\n                uncompressed = io.BytesIO(gz.read())\n            except IOError as original_ioerror:\n                # There may be junk add the end of the file\n                # See http://stackoverflow.com/q/4928560/35070 for details\n                for i in range(1, 1024):\n                    try:\n                        gz = gzip.GzipFile(fileobj=io.BytesIO(content[:-i]), mode='rb')\n                        uncompressed = io.BytesIO(gz.read())\n                    except IOError:\n                        continue\n                    break\n                else:\n                    raise original_ioerror\n            resp = self.addinfourl_wrapper(uncompressed, old_resp.headers, old_resp.url, old_resp.code)\n            resp.msg = old_resp.msg\n        # deflate\n        if resp.headers.get('Content-encoding', '') == 'deflate':\n            gz = io.BytesIO(self.deflate(resp.read()))\n            resp = self.addinfourl_wrapper(gz, old_resp.headers, old_resp.url, old_resp.code)\n            resp.msg = old_resp.msg\n        return resp",
        "begin_line": 729,
        "end_line": 756,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.unified_strdate#762",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.unified_strdate(date_str)",
        "snippet": "def unified_strdate(date_str):\n    \"\"\"Return a string with the date in the format YYYYMMDD\"\"\"\n    upload_date = None\n    #Replace commas\n    date_str = date_str.replace(',', ' ')\n    # %z (UTC offset) is only supported in python>=3.2\n    date_str = re.sub(r' ?(\\+|-)[0-9]{2}:?[0-9]{2}$', '', date_str)\n    format_expressions = [\n        '%d %B %Y',\n        '%d %b %Y',\n        '%B %d %Y',\n        '%b %d %Y',\n        '%Y-%m-%d',\n        '%d.%m.%Y',\n        '%d/%m/%Y',\n        '%Y/%m/%d %H:%M:%S',\n        '%Y-%m-%d %H:%M:%S',\n        '%d.%m.%Y %H:%M',\n        '%Y-%m-%dT%H:%M:%SZ',\n        '%Y-%m-%dT%H:%M:%S.%fZ',\n        '%Y-%m-%dT%H:%M:%S.%f0Z',\n        '%Y-%m-%dT%H:%M:%S',\n        '%Y-%m-%dT%H:%M:%S.%f',\n        '%Y-%m-%dT%H:%M',\n    ]\n    for expression in format_expressions:\n        try:\n            upload_date = datetime.datetime.strptime(date_str, expression).strftime('%Y%m%d')\n        except ValueError:\n            pass\n    if upload_date is None:\n        timetuple = email.utils.parsedate_tz(date_str)\n        if timetuple:\n            upload_date = datetime.datetime(*timetuple[:6]).strftime('%Y%m%d')\n    return upload_date",
        "begin_line": 762,
        "end_line": 796,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.006711409395973154,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.determine_ext#798",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.determine_ext(url, default_ext=u'unknown_video')",
        "snippet": "def determine_ext(url, default_ext=u'unknown_video'):\n    guess = url.partition(u'?')[0].rpartition(u'.')[2]\n    if re.match(r'^[A-Za-z0-9]+$', guess):\n        return guess\n    else:\n        return default_ext",
        "begin_line": 798,
        "end_line": 803,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.subtitles_filename#805",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.subtitles_filename(filename, sub_lang, sub_format)",
        "snippet": "def subtitles_filename(filename, sub_lang, sub_format):\n    return filename.rsplit('.', 1)[0] + u'.' + sub_lang + u'.' + sub_format",
        "begin_line": 805,
        "end_line": 806,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.date_from_str#808",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.date_from_str(date_str)",
        "snippet": "def date_from_str(date_str):\n    \"\"\"\n    Return a datetime object from a string in the format YYYYMMDD or\n    (now|today)[+-][0-9](day|week|month|year)(s)?\"\"\"\n    today = datetime.date.today()\n    if date_str == 'now'or date_str == 'today':\n        return today\n    match = re.match('(now|today)(?P<sign>[+-])(?P<time>\\d+)(?P<unit>day|week|month|year)(s)?', date_str)\n    if match is not None:\n        sign = match.group('sign')\n        time = int(match.group('time'))\n        if sign == '-':\n            time = -time\n        unit = match.group('unit')\n        #A bad aproximation?\n        if unit == 'month':\n            unit = 'day'\n            time *= 30\n        elif unit == 'year':\n            unit = 'day'\n            time *= 365\n        unit += 's'\n        delta = datetime.timedelta(**{unit: time})\n        return today + delta\n    return datetime.datetime.strptime(date_str, \"%Y%m%d\").date()",
        "begin_line": 808,
        "end_line": 832,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.006711409395973154,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.hyphenate_date#834",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.hyphenate_date(date_str)",
        "snippet": "def hyphenate_date(date_str):\n    \"\"\"\n    Convert a date in 'YYYYMMDD' format to 'YYYY-MM-DD' format\"\"\"\n    match = re.match(r'^(\\d\\d\\d\\d)(\\d\\d)(\\d\\d)$', date_str)\n    if match is not None:\n        return '-'.join(match.groups())\n    else:\n        return date_str",
        "begin_line": 834,
        "end_line": 841,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.DateRange.__init__#845",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.DateRange",
        "signature": "youtube_dl.utils.DateRange.__init__(self, start=None, end=None)",
        "snippet": "    def __init__(self, start=None, end=None):\n        \"\"\"start and end must be strings in the format accepted by date\"\"\"\n        if start is not None:\n            self.start = date_from_str(start)\n        else:\n            self.start = datetime.datetime.min.date()\n        if end is not None:\n            self.end = date_from_str(end)\n        else:\n            self.end = datetime.datetime.max.date()\n        if self.start > self.end:\n            raise ValueError('Date range: \"%s\" , the start date must be before the end date' % self)",
        "begin_line": 845,
        "end_line": 856,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.006711409395973154,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.DateRange.__contains__#861",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.DateRange",
        "signature": "youtube_dl.utils.DateRange.__contains__(self, date)",
        "snippet": "    def __contains__(self, date):\n        \"\"\"Check if the date is in the range\"\"\"\n        if not isinstance(date, datetime.date):\n            date = date_from_str(date)\n        return self.start <= date <= self.end",
        "begin_line": 861,
        "end_line": 865,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.006711409395973154,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.DateRange.__str__#866",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.DateRange",
        "signature": "youtube_dl.utils.DateRange.__str__(self)",
        "snippet": "    def __str__(self):\n        return '%s - %s' % ( self.start.isoformat(), self.end.isoformat())",
        "begin_line": 866,
        "end_line": 867,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.platform_name#870",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.platform_name()",
        "snippet": "def platform_name():\n    \"\"\" Returns the platform name as a compat_str \"\"\"\n    res = platform.platform()\n    if isinstance(res, bytes):\n        res = res.decode(preferredencoding())\n\n    assert isinstance(res, compat_str)\n    return res",
        "begin_line": 870,
        "end_line": 877,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.write_string#880",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.write_string(s, out=None)",
        "snippet": "def write_string(s, out=None):\n    if out is None:\n        out = sys.stderr\n    assert type(s) == compat_str\n\n    if ('b' in getattr(out, 'mode', '') or\n            sys.version_info[0] < 3):  # Python 2 lies about mode of sys.stderr\n        s = s.encode(preferredencoding(), 'ignore')\n    try:\n        out.write(s)\n    except UnicodeEncodeError:\n        # In Windows shells, this can fail even when the codec is just charmap!?\n        # See https://wiki.python.org/moin/PrintFails#Issue\n        if sys.platform == 'win32' and hasattr(out, 'encoding'):\n            s = s.encode(out.encoding, 'ignore').decode(out.encoding)\n            out.write(s)\n        else:\n            raise\n\n    out.flush()",
        "begin_line": 880,
        "end_line": 899,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.bytes_to_intlist#902",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.bytes_to_intlist(bs)",
        "snippet": "def bytes_to_intlist(bs):\n    if not bs:\n        return []\n    if isinstance(bs[0], int):  # Python 3\n        return list(bs)\n    else:\n        return [ord(c) for c in bs]",
        "begin_line": 902,
        "end_line": 908,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.intlist_to_bytes#911",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.intlist_to_bytes(xs)",
        "snippet": "def intlist_to_bytes(xs):\n    if not xs:\n        return b''\n    if isinstance(chr(0), bytes):  # Python 2\n        return ''.join([chr(x) for x in xs])\n    else:\n        return bytes(xs)",
        "begin_line": 911,
        "end_line": 917,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.get_cachedir#920",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.get_cachedir(params={})",
        "snippet": "def get_cachedir(params={}):\n    cache_root = os.environ.get('XDG_CACHE_HOME',\n                                os.path.expanduser('~/.cache'))\n    return params.get('cachedir', os.path.join(cache_root, 'youtube-dl'))",
        "begin_line": 920,
        "end_line": 923,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.002369668246445498,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils._lock_file#984",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils._lock_file(f, exclusive)",
        "snippet": "    def _lock_file(f, exclusive):\n        fcntl.lockf(f, fcntl.LOCK_EX if exclusive else fcntl.LOCK_SH)",
        "begin_line": 984,
        "end_line": 985,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils._unlock_file#987",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils._unlock_file(f)",
        "snippet": "    def _unlock_file(f):\n        fcntl.lockf(f, fcntl.LOCK_UN)",
        "begin_line": 987,
        "end_line": 988,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.locked_file.__init__#992",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.locked_file",
        "signature": "youtube_dl.utils.locked_file.__init__(self, filename, mode, encoding=None)",
        "snippet": "    def __init__(self, filename, mode, encoding=None):\n        assert mode in ['r', 'a', 'w']\n        self.f = io.open(filename, mode, encoding=encoding)\n        self.mode = mode",
        "begin_line": 992,
        "end_line": 995,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.locked_file.__enter__#997",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.locked_file",
        "signature": "youtube_dl.utils.locked_file.__enter__(self)",
        "snippet": "    def __enter__(self):\n        exclusive = self.mode != 'r'\n        try:\n            _lock_file(self.f, exclusive)\n        except IOError:\n            self.f.close()\n            raise\n        return self",
        "begin_line": 997,
        "end_line": 1004,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.locked_file.__exit__#1006",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.locked_file",
        "signature": "youtube_dl.utils.locked_file.__exit__(self, etype, value, traceback)",
        "snippet": "    def __exit__(self, etype, value, traceback):\n        try:\n            _unlock_file(self.f)\n        finally:\n            self.f.close()",
        "begin_line": 1006,
        "end_line": 1010,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.locked_file.__iter__#1012",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.locked_file",
        "signature": "youtube_dl.utils.locked_file.__iter__(self)",
        "snippet": "    def __iter__(self):\n        return iter(self.f)",
        "begin_line": 1012,
        "end_line": 1013,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.locked_file.write#1015",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.locked_file",
        "signature": "youtube_dl.utils.locked_file.write(self, *args)",
        "snippet": "    def write(self, *args):\n        return self.f.write(*args)",
        "begin_line": 1015,
        "end_line": 1016,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.locked_file.read#1018",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.locked_file",
        "signature": "youtube_dl.utils.locked_file.read(self, *args)",
        "snippet": "    def read(self, *args):\n        return self.f.read(*args)",
        "begin_line": 1018,
        "end_line": 1019,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.shell_quote#1022",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.shell_quote(args)",
        "snippet": "def shell_quote(args):\n    quoted_args = []\n    encoding = sys.getfilesystemencoding()\n    if encoding is None:\n        encoding = 'utf-8'\n    for a in args:\n        if isinstance(a, bytes):\n            # We may get a filename encoded with 'encodeFilename'\n            a = a.decode(encoding)\n        quoted_args.append(pipes.quote(a))\n    return u' '.join(quoted_args)",
        "begin_line": 1022,
        "end_line": 1032,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.006711409395973154,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.takewhile_inclusive#1035",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.takewhile_inclusive(pred, seq)",
        "snippet": "def takewhile_inclusive(pred, seq):\n    \"\"\" Like itertools.takewhile, but include the latest evaluated element\n        (the first element so that Not pred(e)) \"\"\"\n    for e in seq:\n        yield e\n        if not pred(e):\n            return",
        "begin_line": 1035,
        "end_line": 1041,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.smuggle_url#1044",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.smuggle_url(url, data)",
        "snippet": "def smuggle_url(url, data):\n    \"\"\" Pass additional data in a URL for internal use. \"\"\"\n\n    sdata = compat_urllib_parse.urlencode(\n        {u'__youtubedl_smuggle': json.dumps(data)})\n    return url + u'#' + sdata",
        "begin_line": 1044,
        "end_line": 1049,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.006711409395973154,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.unsmuggle_url#1052",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.unsmuggle_url(smug_url, default=None)",
        "snippet": "def unsmuggle_url(smug_url, default=None):\n    if not '#__youtubedl_smuggle' in smug_url:\n        return smug_url, default\n    url, _, sdata = smug_url.rpartition(u'#')\n    jsond = compat_parse_qs(sdata)[u'__youtubedl_smuggle'][0]\n    data = json.loads(jsond)\n    return url, data",
        "begin_line": 1052,
        "end_line": 1058,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.006711409395973154,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.format_bytes#1061",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.format_bytes(bytes)",
        "snippet": "def format_bytes(bytes):\n    if bytes is None:\n        return u'N/A'\n    if type(bytes) is str:\n        bytes = float(bytes)\n    if bytes == 0.0:\n        exponent = 0\n    else:\n        exponent = int(math.log(bytes, 1024.0))\n    suffix = [u'B', u'KiB', u'MiB', u'GiB', u'TiB', u'PiB', u'EiB', u'ZiB', u'YiB'][exponent]\n    converted = float(bytes) / float(1024 ** exponent)\n    return u'%.2f%s' % (converted, suffix)",
        "begin_line": 1061,
        "end_line": 1072,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.str_to_int#1075",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.str_to_int(int_str)",
        "snippet": "def str_to_int(int_str):\n    int_str = re.sub(r'[,\\.]', u'', int_str)\n    return int(int_str)",
        "begin_line": 1075,
        "end_line": 1077,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.006711409395973154,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.get_term_width#1080",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.get_term_width()",
        "snippet": "def get_term_width():\n    columns = os.environ.get('COLUMNS', None)\n    if columns:\n        return int(columns)\n\n    try:\n        sp = subprocess.Popen(\n            ['stty', 'size'],\n            stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        out, err = sp.communicate()\n        return int(out.split()[1])\n    except:\n        pass\n    return None",
        "begin_line": 1080,
        "end_line": 1093,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.002369668246445498,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.month_by_name#1096",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.month_by_name(name)",
        "snippet": "def month_by_name(name):\n    \"\"\" Return the number of a month by (locale-independently) English name \"\"\"\n\n    ENGLISH_NAMES = [\n        u'January', u'February', u'March', u'April', u'May', u'June',\n        u'July', u'August', u'September', u'October', u'November', u'December']\n    try:\n        return ENGLISH_NAMES.index(name) + 1\n    except ValueError:\n        return None",
        "begin_line": 1096,
        "end_line": 1105,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.fix_xml_ampersands#1108",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.fix_xml_ampersands(xml_str)",
        "snippet": "def fix_xml_ampersands(xml_str):\n    \"\"\"Replace all the '&' by '&amp;' in XML\"\"\"\n    return re.sub(\n        r'&(?!amp;|lt;|gt;|apos;|quot;|#x[0-9a-fA-F]{,4};|#[0-9]{,4};)',\n        u'&amp;',\n        xml_str)",
        "begin_line": 1108,
        "end_line": 1113,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.006711409395973154,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.setproctitle#1116",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.setproctitle(title)",
        "snippet": "def setproctitle(title):\n    assert isinstance(title, compat_str)\n    try:\n        libc = ctypes.cdll.LoadLibrary(\"libc.so.6\")\n    except OSError:\n        return\n    title = title\n    buf = ctypes.create_string_buffer(len(title) + 1)\n    buf.value = title.encode('utf-8')\n    try:\n        libc.prctl(15, ctypes.byref(buf), 0, 0, 0)\n    except AttributeError:\n        return  # Strange libc, just skip this",
        "begin_line": 1116,
        "end_line": 1128,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.002369668246445498,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.remove_start#1131",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.remove_start(s, start)",
        "snippet": "def remove_start(s, start):\n    if s.startswith(start):\n        return s[len(start):]\n    return s",
        "begin_line": 1131,
        "end_line": 1134,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.url_basename#1137",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.url_basename(url)",
        "snippet": "def url_basename(url):\n    path = compat_urlparse.urlparse(url).path\n    return path.strip(u'/').split(u'/')[-1]",
        "begin_line": 1137,
        "end_line": 1139,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.006711409395973154,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.HEADRequest.get_method#1143",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.HEADRequest",
        "signature": "youtube_dl.utils.HEADRequest.get_method(self)",
        "snippet": "    def get_method(self):\n        return \"HEAD\"",
        "begin_line": 1143,
        "end_line": 1144,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.int_or_none#1147",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.int_or_none(v, scale=1)",
        "snippet": "def int_or_none(v, scale=1):\n    return v if v is None else (int(v) // scale)",
        "begin_line": 1147,
        "end_line": 1148,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.parse_duration#1151",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.parse_duration(s)",
        "snippet": "def parse_duration(s):\n    if s is None:\n        return None\n\n    m = re.match(\n        r'(?:(?:(?P<hours>[0-9]+)[:h])?(?P<mins>[0-9]+)[:m])?(?P<secs>[0-9]+)s?$', s)\n    if not m:\n        return None\n    res = int(m.group('secs'))\n    if m.group('mins'):\n        res += int(m.group('mins')) * 60\n        if m.group('hours'):\n            res += int(m.group('hours')) * 60 * 60\n    return res",
        "begin_line": 1151,
        "end_line": 1164,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.006711409395973154,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.prepend_extension#1167",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.prepend_extension(filename, ext)",
        "snippet": "def prepend_extension(filename, ext):\n    name, real_ext = os.path.splitext(filename) \n    return u'{0}.{1}{2}'.format(name, ext, real_ext)",
        "begin_line": 1167,
        "end_line": 1169,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.check_executable#1172",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.check_executable(exe, args=[])",
        "snippet": "def check_executable(exe, args=[]):\n    \"\"\" Checks if the given binary is installed somewhere in PATH, and returns its name.\n    args can be a list of arguments for a short output (like -version) \"\"\"\n    try:\n        subprocess.Popen([exe] + args, stdout=subprocess.PIPE, stderr=subprocess.PIPE).communicate()\n    except OSError:\n        return False\n    return exe",
        "begin_line": 1172,
        "end_line": 1179,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.PagedList.__init__#1183",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.PagedList",
        "signature": "youtube_dl.utils.PagedList.__init__(self, pagefunc, pagesize)",
        "snippet": "    def __init__(self, pagefunc, pagesize):\n        self._pagefunc = pagefunc\n        self._pagesize = pagesize",
        "begin_line": 1183,
        "end_line": 1185,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.006711409395973154,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.PagedList.__len__#1187",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.PagedList",
        "signature": "youtube_dl.utils.PagedList.__len__(self)",
        "snippet": "    def __len__(self):\n        # This is only useful for tests\n        return len(self.getslice())",
        "begin_line": 1187,
        "end_line": 1189,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.PagedList.getslice#1191",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils.PagedList",
        "signature": "youtube_dl.utils.PagedList.getslice(self, start=0, end=None)",
        "snippet": "    def getslice(self, start=0, end=None):\n        res = []\n        for pagenum in itertools.count(start // self._pagesize):\n            firstid = pagenum * self._pagesize\n            nextfirstid = pagenum * self._pagesize + self._pagesize\n            if start >= nextfirstid:\n                continue\n\n            page_results = list(self._pagefunc(pagenum))\n\n            startv = (\n                start % self._pagesize\n                if firstid <= start < nextfirstid\n                else 0)\n\n            endv = (\n                ((end - 1) % self._pagesize) + 1\n                if (end is not None and firstid <= end <= nextfirstid)\n                else None)\n\n            if startv != 0 or endv is not None:\n                page_results = page_results[startv:endv]\n            res.extend(page_results)\n\n            # A little optimization - if current page is not \"full\", ie. does\n            # not contain page_size videos then we can assume that this page\n            # is the last one - there are no more ids on further pages -\n            # i.e. no need to query again.\n            if len(page_results) + startv < self._pagesize:\n                break\n\n            # If we got the whole page, but the next page is not interesting,\n            # break out early as well\n            if end == nextfirstid:\n                break\n        return res",
        "begin_line": 1191,
        "end_line": 1226,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.006711409395973154,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.uppercase_escape#1229",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.uppercase_escape(s)",
        "snippet": "def uppercase_escape(s):\n    return re.sub(\n        r'\\\\U([0-9a-fA-F]{8})',\n        lambda m: compat_chr(int(m.group(1), base=16)), s)",
        "begin_line": 1229,
        "end_line": 1232,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.read_batch_urls#1252",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.read_batch_urls(batch_fd)",
        "snippet": "def read_batch_urls(batch_fd):\n    def fixup(url):\n        if not isinstance(url, compat_str):\n            url = url.decode('utf-8', 'replace')\n        BOM_UTF8 = u'\\xef\\xbb\\xbf'\n        if url.startswith(BOM_UTF8):\n            url = url[len(BOM_UTF8):]\n        url = url.strip()\n        if url.startswith(('#', ';', ']')):\n            return False\n        return url\n\n    with contextlib.closing(batch_fd) as fd:\n        return [url for url in map(fixup, fd) if url]",
        "begin_line": 1252,
        "end_line": 1265,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.006711409395973154,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.utils.fixup#1253",
        "src_path": "youtube_dl/utils.py",
        "class_name": "youtube_dl.utils",
        "signature": "youtube_dl.utils.fixup(url)",
        "snippet": "    def fixup(url):\n        if not isinstance(url, compat_str):\n            url = url.decode('utf-8', 'replace')\n        BOM_UTF8 = u'\\xef\\xbb\\xbf'\n        if url.startswith(BOM_UTF8):\n            url = url[len(BOM_UTF8):]\n        url = url.strip()\n        if url.startswith(('#', ';', ']')):\n            return False\n        return url",
        "begin_line": 1253,
        "end_line": 1262,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.006711409395973154,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.eighttracks.EightTracksIE._real_extract#86",
        "src_path": "youtube_dl/extractor/eighttracks.py",
        "class_name": "youtube_dl.extractor.eighttracks.EightTracksIE",
        "signature": "youtube_dl.extractor.eighttracks.EightTracksIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        if mobj is None:\n            raise ExtractorError(u'Invalid URL: %s' % url)\n        playlist_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, playlist_id)\n\n        json_like = self._search_regex(r\"PAGE.mix = (.*?);\\n\", webpage, u'trax information', flags=re.DOTALL)\n        data = json.loads(json_like)\n\n        session = str(random.randint(0, 1000000000))\n        mix_id = data['id']\n        track_count = data['tracks_count']\n        first_url = 'http://8tracks.com/sets/%s/play?player=sm&mix_id=%s&format=jsonh' % (session, mix_id)\n        next_url = first_url\n        res = []\n        for i in range(track_count):\n            api_json = self._download_webpage(next_url, playlist_id,\n                note=u'Downloading song information %s/%s' % (str(i+1), track_count),\n                errnote=u'Failed to download song information')\n            api_data = json.loads(api_json)\n            track_data = api_data[u'set']['track']\n            info = {\n                'id': track_data['id'],\n                'url': track_data['track_file_stream_url'],\n                'title': track_data['performer'] + u' - ' + track_data['name'],\n                'raw_title': track_data['name'],\n                'uploader_id': data['user']['login'],\n                'ext': 'm4a',\n            }\n            res.append(info)\n            next_url = 'http://8tracks.com/sets/%s/next?player=sm&mix_id=%s&format=jsonh&track_id=%s' % (session, mix_id, track_data['id'])\n        return res",
        "begin_line": 86,
        "end_line": 119,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.redtube.RedTubeIE._real_extract#22",
        "src_path": "youtube_dl/extractor/redtube.py",
        "class_name": "youtube_dl.extractor.redtube.RedTubeIE",
        "signature": "youtube_dl.extractor.redtube.RedTubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n        video_extension = 'mp4'\n        webpage = self._download_webpage(url, video_id)\n\n        self.report_extraction(video_id)\n\n        video_url = self._html_search_regex(\n            r'<source src=\"(.+?)\" type=\"video/mp4\">', webpage, u'video URL')\n\n        video_title = self._html_search_regex(\n            r'<h1 class=\"videoTitle[^\"]*\">(.+?)</h1>',\n            webpage, u'title')\n\n        video_thumbnail = self._html_search_regex(\n            r'playerInnerHTML.+?<img\\s+src=\"(.+?)\"',\n            webpage, u'thumbnail', fatal=False)\n\n        # No self-labeling, but they describe themselves as\n        # \"Home of Videos Porno\"\n        age_limit = 18\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'ext': video_extension,\n            'title': video_title,\n            'thumbnail': video_thumbnail,\n            'age_limit': age_limit,\n        }",
        "begin_line": 22,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.mofosex.MofosexIE._real_extract#23",
        "src_path": "youtube_dl/extractor/mofosex.py",
        "class_name": "youtube_dl.extractor.mofosex.MofosexIE",
        "signature": "youtube_dl.extractor.mofosex.MofosexIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n        url = 'http://www.' + mobj.group('url')\n\n        req = compat_urllib_request.Request(url)\n        req.add_header('Cookie', 'age_verified=1')\n        webpage = self._download_webpage(req, video_id)\n\n        video_title = self._html_search_regex(r'<h1>(.+?)<', webpage, u'title')\n        video_url = compat_urllib_parse.unquote(self._html_search_regex(r'flashvars.video_url = \\'([^\\']+)', webpage, u'video_url'))\n        path = compat_urllib_parse_urlparse(video_url).path\n        extension = os.path.splitext(path)[1][1:]\n        format = path.split('/')[5].split('_')[:2]\n        format = \"-\".join(format)\n\n        age_limit = self._rta_search(webpage)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'url': video_url,\n            'ext': extension,\n            'format': format,\n            'format_id': format,\n            'age_limit': age_limit,\n        }",
        "begin_line": 23,
        "end_line": 49,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.pornhd.PornHdIE._real_extract#21",
        "src_path": "youtube_dl/extractor/pornhd.py",
        "class_name": "youtube_dl.extractor.pornhd.PornHdIE",
        "signature": "youtube_dl.extractor.pornhd.PornHdIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('video_id')\n        video_title = mobj.group('video_title')\n\n        webpage = self._download_webpage(url, video_id)\n\n        next_url = self._html_search_regex(\n            r'&hd=(http.+?)&', webpage, 'video URL')\n        next_url = compat_urllib_parse.unquote(next_url)\n\n        video_url = self._download_webpage(\n            next_url, video_id, note='Retrieving video URL',\n            errnote='Could not retrieve video URL')\n        age_limit = 18\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'ext': 'flv',\n            'title': video_title,\n            'age_limit': age_limit,\n        }",
        "begin_line": 21,
        "end_line": 44,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.ted.TEDIE._extract_info#44",
        "src_path": "youtube_dl/extractor/ted.py",
        "class_name": "youtube_dl.extractor.ted.TEDIE",
        "signature": "youtube_dl.extractor.ted.TEDIE._extract_info(self, webpage)",
        "snippet": "    def _extract_info(self, webpage):\n        info_json = self._search_regex(r'q\\(\"\\w+.init\",({.+})\\)</script>',\n            webpage, 'info json')\n        return json.loads(info_json)",
        "begin_line": 44,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.ted.TEDIE._real_extract#49",
        "src_path": "youtube_dl/extractor/ted.py",
        "class_name": "youtube_dl.extractor.ted.TEDIE",
        "signature": "youtube_dl.extractor.ted.TEDIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url, re.VERBOSE)\n        name = m.group('name')\n        if m.group('type_talk'):\n            return self._talk_info(url, name)\n        else:\n            return self._playlist_videos_info(url, name)",
        "begin_line": 49,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.ted.TEDIE._playlist_videos_info#57",
        "src_path": "youtube_dl/extractor/ted.py",
        "class_name": "youtube_dl.extractor.ted.TEDIE",
        "signature": "youtube_dl.extractor.ted.TEDIE._playlist_videos_info(self, url, name)",
        "snippet": "    def _playlist_videos_info(self, url, name):\n        '''Returns the videos of the playlist'''\n\n        webpage = self._download_webpage(url, name,\n            'Downloading playlist webpage')\n        info = self._extract_info(webpage)\n        playlist_info = info['playlist']\n\n        playlist_entries = [\n            self.url_result(u'http://www.ted.com/talks/' + talk['slug'], self.ie_key())\n            for talk in info['talks']\n        ]\n        return self.playlist_result(\n            playlist_entries,\n            playlist_id=compat_str(playlist_info['id']),\n            playlist_title=playlist_info['title'])",
        "begin_line": 57,
        "end_line": 72,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.ted.TEDIE._talk_info#74",
        "src_path": "youtube_dl/extractor/ted.py",
        "class_name": "youtube_dl.extractor.ted.TEDIE",
        "signature": "youtube_dl.extractor.ted.TEDIE._talk_info(self, url, video_name)",
        "snippet": "    def _talk_info(self, url, video_name):\n        webpage = self._download_webpage(url, video_name)\n        self.report_extraction(video_name)\n\n        talk_info = self._extract_info(webpage)['talks'][0]\n\n        formats = [{\n            'ext': 'mp4',\n            'url': format_url,\n            'format_id': format_id,\n            'format': format_id,\n            'preference': self._FORMATS_PREFERENCE.get(format_id, -1),\n        } for (format_id, format_url) in talk_info['nativeDownloads'].items()]\n        self._sort_formats(formats)\n\n        video_id = compat_str(talk_info['id'])\n        # subtitles\n        video_subtitles = self.extract_subtitles(video_id, talk_info)\n        if self._downloader.params.get('listsubtitles', False):\n            self._list_available_subtitles(video_id, talk_info)\n            return\n\n        return {\n            'id': video_id,\n            'title': talk_info['title'],\n            'uploader': talk_info['speaker'],\n            'thumbnail': talk_info['thumb'],\n            'description': self._og_search_description(webpage),\n            'subtitles': video_subtitles,\n            'formats': formats,\n        }",
        "begin_line": 74,
        "end_line": 104,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.ted.TEDIE._get_available_subtitles#106",
        "src_path": "youtube_dl/extractor/ted.py",
        "class_name": "youtube_dl.extractor.ted.TEDIE",
        "signature": "youtube_dl.extractor.ted.TEDIE._get_available_subtitles(self, video_id, talk_info)",
        "snippet": "    def _get_available_subtitles(self, video_id, talk_info):\n        languages = [lang['languageCode'] for lang in talk_info.get('languages', [])]\n        if languages:\n            sub_lang_list = {}\n            for l in languages:\n                url = 'http://www.ted.com/talks/subtitles/id/%s/lang/%s/format/srt' % (video_id, l)\n                sub_lang_list[l] = url\n            return sub_lang_list\n        else:\n            self._downloader.report_warning(u'video doesn\\'t have subtitles')\n            return {}",
        "begin_line": 106,
        "end_line": 116,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.newgrounds.NewgroundsIE._real_extract#22",
        "src_path": "youtube_dl/extractor/newgrounds.py",
        "class_name": "youtube_dl.extractor.newgrounds.NewgroundsIE",
        "signature": "youtube_dl.extractor.newgrounds.NewgroundsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        music_id = mobj.group('id')\n        webpage = self._download_webpage(url, music_id)\n        \n        title = self._html_search_regex(\n            r',\"name\":\"([^\"]+)\",', webpage, 'music title')\n        uploader = self._html_search_regex(\n            r',\"artist\":\"([^\"]+)\",', webpage, 'music uploader')\n        \n        music_url_json_string = self._html_search_regex(\n            r'({\"url\":\"[^\"]+\"),', webpage, 'music url') + '}'\n        music_url_json = json.loads(music_url_json_string)\n        music_url = music_url_json['url']\n\n        return {\n            'id': music_id,\n            'title': title,\n            'url': music_url,\n            'uploader': uploader,\n        }",
        "begin_line": 22,
        "end_line": 42,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.pbs.PBSIE._real_extract#32",
        "src_path": "youtube_dl/extractor/pbs.py",
        "class_name": "youtube_dl.extractor.pbs.PBSIE",
        "signature": "youtube_dl.extractor.pbs.PBSIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        presumptive_id = mobj.group('presumptive_id')\n        display_id = presumptive_id\n        if presumptive_id:\n            webpage = self._download_webpage(url, display_id)\n            url = self._search_regex(\n                r'<iframe\\s+id=[\"\\']partnerPlayer[\"\\'].*?\\s+src=[\"\\'](.*?)[\"\\']>',\n                webpage, 'player URL')\n            mobj = re.match(self._VALID_URL, url)\n\n        player_id = mobj.group('player_id')\n        if not display_id:\n            display_id = player_id\n        if player_id:\n            player_page = self._download_webpage(\n                url, display_id, note='Downloading player page',\n                errnote='Could not download player page')\n            video_id = self._search_regex(\n                r'<div\\s+id=\"video_([0-9]+)\"', player_page, 'video ID')\n        else:\n            video_id = mobj.group('id')\n            display_id = video_id\n\n        info_url = 'http://video.pbs.org/videoInfo/%s?format=json' % video_id\n        info = self._download_json(info_url, display_id)\n\n        return {\n            'id': video_id,\n            'title': info['title'],\n            'url': info['alternate_encoding']['url'],\n            'ext': 'mp4',\n            'description': info['program'].get('description'),\n            'thumbnail': info.get('image_url'),\n            'duration': info.get('duration'),\n        }",
        "begin_line": 32,
        "end_line": 68,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.addanime.AddAnimeIE._real_extract#28",
        "src_path": "youtube_dl/extractor/addanime.py",
        "class_name": "youtube_dl.extractor.addanime.AddAnimeIE",
        "signature": "youtube_dl.extractor.addanime.AddAnimeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        try:\n            mobj = re.match(self._VALID_URL, url)\n            video_id = mobj.group('video_id')\n            webpage = self._download_webpage(url, video_id)\n        except ExtractorError as ee:\n            if not isinstance(ee.cause, compat_HTTPError) or \\\n               ee.cause.code != 503:\n                raise\n\n            redir_webpage = ee.cause.read().decode('utf-8')\n            action = self._search_regex(\n                r'<form id=\"challenge-form\" action=\"([^\"]+)\"',\n                redir_webpage, u'Redirect form')\n            vc = self._search_regex(\n                r'<input type=\"hidden\" name=\"jschl_vc\" value=\"([^\"]+)\"/>',\n                redir_webpage, u'redirect vc value')\n            av = re.search(\n                r'a\\.value = ([0-9]+)[+]([0-9]+)[*]([0-9]+);',\n                redir_webpage)\n            if av is None:\n                raise ExtractorError(u'Cannot find redirect math task')\n            av_res = int(av.group(1)) + int(av.group(2)) * int(av.group(3))\n\n            parsed_url = compat_urllib_parse_urlparse(url)\n            av_val = av_res + len(parsed_url.netloc)\n            confirm_url = (\n                parsed_url.scheme + u'://' + parsed_url.netloc +\n                action + '?' +\n                compat_urllib_parse.urlencode({\n                    'jschl_vc': vc, 'jschl_answer': compat_str(av_val)}))\n            self._download_webpage(\n                confirm_url, video_id,\n                note=u'Confirming after redirect')\n            webpage = self._download_webpage(url, video_id)\n\n        formats = []\n        for format_id in ('normal', 'hq'):\n            rex = r\"var %s_video_file = '(.*?)';\" % re.escape(format_id)\n            video_url = self._search_regex(rex, webpage, u'video file URLx',\n                                           fatal=False)\n            if not video_url:\n                continue\n            formats.append({\n                'format_id': format_id,\n                'url': video_url,\n            })\n        if not formats:\n            raise ExtractorError(u'Cannot find any video format!')\n        video_title = self._og_search_title(webpage)\n        video_description = self._og_search_description(webpage)\n\n        return {\n            '_type': 'video',\n            'id':  video_id,\n            'formats': formats,\n            'title': video_title,\n            'description': video_description\n        }",
        "begin_line": 28,
        "end_line": 86,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.chilloutzone.ChilloutzoneIE._real_extract#52",
        "src_path": "youtube_dl/extractor/chilloutzone.py",
        "class_name": "youtube_dl.extractor.chilloutzone.ChilloutzoneIE",
        "signature": "youtube_dl.extractor.chilloutzone.ChilloutzoneIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        base64_video_info = self._html_search_regex(\n            r'var cozVidData = \"(.+?)\";', webpage, 'video data')\n        decoded_video_info = base64.b64decode(base64_video_info).decode(\"utf-8\")\n        video_info_dict = json.loads(decoded_video_info)\n\n        # get video information from dict\n        video_url = video_info_dict['mediaUrl']\n        description = clean_html(video_info_dict.get('description'))\n        title = video_info_dict['title']\n        native_platform = video_info_dict['nativePlatform']\n        native_video_id = video_info_dict['nativeVideoId']\n        source_priority = video_info_dict['sourcePriority']\n\n        # If nativePlatform is None a fallback mechanism is used (i.e. youtube embed)\n        if native_platform is None:\n            youtube_url = self._html_search_regex(\n                r'<iframe.* src=\"((?:https?:)?//(?:[^.]+\\.)?youtube\\.com/.+?)\"',\n                webpage, 'fallback video URL', default=None)\n            if youtube_url is not None:\n                return self.url_result(youtube_url, ie='Youtube')\n\n        # Non Fallback: Decide to use native source (e.g. youtube or vimeo) or\n        # the own CDN\n        if source_priority == 'native':\n            if native_platform == 'youtube':\n                return self.url_result(native_video_id, ie='Youtube')\n            if native_platform == 'vimeo':\n                return self.url_result(\n                    'http://vimeo.com/' + native_video_id, ie='Vimeo')\n\n        if not video_url:\n            raise ExtractorError('No video found')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'ext': 'mp4',\n            'title': title,\n            'description': description,\n        }",
        "begin_line": 52,
        "end_line": 97,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.viddler.ViddlerIE._real_extract#20",
        "src_path": "youtube_dl/extractor/viddler.py",
        "class_name": "youtube_dl.extractor.viddler.ViddlerIE",
        "signature": "youtube_dl.extractor.viddler.ViddlerIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        embed_url = mobj.group('domain') + u'/embed/' + video_id\n        webpage = self._download_webpage(embed_url, video_id)\n\n        video_sources_code = self._search_regex(\n            r\"(?ms)sources\\s*:\\s*(\\{.*?\\})\", webpage, u'video URLs')\n        video_sources = json.loads(video_sources_code.replace(\"'\", '\"'))\n\n        formats = [{\n            'url': video_url,\n            'format': format_id,\n        } for video_url, format_id in video_sources.items()]\n\n        title = self._html_search_regex(\n            r\"title\\s*:\\s*'([^']*)'\", webpage, u'title')\n        uploader = self._html_search_regex(\n            r\"authorName\\s*:\\s*'([^']*)'\", webpage, u'uploader', fatal=False)\n        duration_s = self._html_search_regex(\n            r\"duration\\s*:\\s*([0-9.]*)\", webpage, u'duration', fatal=False)\n        duration = float(duration_s) if duration_s else None\n        thumbnail = self._html_search_regex(\n            r\"thumbnail\\s*:\\s*'([^']*)'\",\n            webpage, u'thumbnail', fatal=False)\n\n        return {\n            '_type': 'video',\n            'id': video_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 20,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.ard.ARDIE._real_extract#28",
        "src_path": "youtube_dl/extractor/ard.py",
        "class_name": "youtube_dl.extractor.ard.ARDIE",
        "signature": "youtube_dl.extractor.ard.ARDIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        # determine video id from url\n        m = re.match(self._VALID_URL, url)\n\n        numid = re.search(r'documentId=([0-9]+)', url)\n        if numid:\n            video_id = numid.group(1)\n        else:\n            video_id = m.group('video_id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(\n            r'<h1(?:\\s+class=\"boxTopHeadline\")?>(.*?)</h1>', webpage, 'title')\n        description = self._html_search_meta(\n            'dcterms.abstract', webpage, 'description')\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        streams = [\n            mo.groupdict()\n            for mo in re.finditer(\n                r'mediaCollection\\.addMediaStream\\((?P<media_type>\\d+), (?P<quality>\\d+), \"(?P<rtmp_url>[^\"]*)\", \"(?P<video_url>[^\"]*)\", \"[^\"]*\"\\)', webpage)]\n        if not streams:\n            if '\"fsk\"' in webpage:\n                raise ExtractorError('This video is only available after 20:00')\n\n        formats = []\n        for s in streams:\n            format = {\n                'quality': int(s['quality']),\n            }\n            if s.get('rtmp_url'):\n                format['protocol'] = 'rtmp'\n                format['url'] = s['rtmp_url']\n                format['playpath'] = s['video_url']\n            else:\n                format['url'] = s['video_url']\n\n            quality_name = self._search_regex(\n                r'[,.]([a-zA-Z0-9_-]+),?\\.mp4', format['url'],\n                'quality name', default='NA')\n            format['format_id'] = '%s-%s-%s-%s' % (\n                determine_ext(format['url']), quality_name, s['media_type'],\n                s['quality'])\n\n            formats.append(format)\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'formats': formats,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 28,
        "end_line": 83,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.spankwire.SpankwireIE._real_extract#34",
        "src_path": "youtube_dl/extractor/spankwire.py",
        "class_name": "youtube_dl.extractor.spankwire.SpankwireIE",
        "signature": "youtube_dl.extractor.spankwire.SpankwireIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n        url = 'http://www.' + mobj.group('url')\n\n        req = compat_urllib_request.Request(url)\n        req.add_header('Cookie', 'age_verified=1')\n        webpage = self._download_webpage(req, video_id)\n\n        title = self._html_search_regex(r'<h1>([^<]+)', webpage, 'title')\n        description = self._html_search_regex(\n            r'<div\\s+id=\"descriptionContent\">([^<]+)<', webpage, 'description', fatal=False)\n        thumbnail = self._html_search_regex(\n            r'flashvars\\.image_url = \"([^\"]+)', webpage, 'thumbnail', fatal=False)\n\n        uploader = self._html_search_regex(\n            r'by:\\s*<a [^>]*>(.+?)</a>', webpage, 'uploader', fatal=False)\n        uploader_id = self._html_search_regex(\n            r'by:\\s*<a href=\"/Profile\\.aspx\\?.*?UserId=(\\d+).*?\"', webpage, 'uploader id', fatal=False)\n        upload_date = self._html_search_regex(r'</a> on (.+?) at \\d+:\\d+', webpage, 'upload date', fatal=False)\n        if upload_date:\n            upload_date = unified_strdate(upload_date)\n        \n        view_count = self._html_search_regex(\n            r'<div id=\"viewsCounter\"><span>([^<]+)</span> views</div>', webpage, 'view count', fatal=False)\n        if view_count:\n            view_count = str_to_int(view_count)\n        comment_count = int_or_none(self._html_search_regex(\n            r'<span id=\"spCommentCount\">\\s*(\\d+)</span> Comments</div>', webpage, 'comment count', fatal=False))\n\n        video_urls = list(map(compat_urllib_parse.unquote , re.findall(r'flashvars\\.quality_[0-9]{3}p = \"([^\"]+)', webpage)))\n        if webpage.find('flashvars\\.encrypted = \"true\"') != -1:\n            password = self._html_search_regex(r'flashvars\\.video_title = \"([^\"]+)', webpage, 'password').replace('+', ' ')\n            video_urls = list(map(lambda s: aes_decrypt_text(s, password, 32).decode('utf-8'), video_urls))\n\n        formats = []\n        for video_url in video_urls:\n            path = compat_urllib_parse_urlparse(video_url).path\n            format = path.split('/')[4].split('_')[:2]\n            resolution, bitrate_str = format\n            format = \"-\".join(format)\n            height = int(resolution.rstrip('Pp'))\n            tbr = int(bitrate_str.rstrip('Kk'))\n            formats.append({\n                'url': video_url,\n                'resolution': resolution,\n                'format': format,\n                'tbr': tbr,\n                'height': height,\n                'format_id': format,\n            })\n        self._sort_formats(formats)\n\n        age_limit = self._rta_search(webpage)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'upload_date': upload_date,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'formats': formats,\n            'age_limit': age_limit,\n        }",
        "begin_line": 34,
        "end_line": 101,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.prosiebensat1.ProSiebenSat1IE._real_extract#184",
        "src_path": "youtube_dl/extractor/prosiebensat1.py",
        "class_name": "youtube_dl.extractor.prosiebensat1.ProSiebenSat1IE",
        "signature": "youtube_dl.extractor.prosiebensat1.ProSiebenSat1IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        page = self._download_webpage(url, video_id, 'Downloading page')\n\n        def extract(patterns, name, page, fatal=False):\n            for pattern in patterns:\n                mobj = re.search(pattern, page)\n                if mobj:\n                    return clean_html(mobj.group(1))\n            if fatal:\n                raise RegexNotFoundError(u'Unable to extract %s' % name)\n            return None\n\n        clip_id = extract(self._CLIPID_REGEXES, 'clip id', page, fatal=True)\n\n        access_token = 'testclient'\n        client_name = 'kolibri-1.2.5'\n        client_location = url\n\n        videos_api_url = 'http://vas.sim-technik.de/vas/live/v2/videos?%s' % compat_urllib_parse.urlencode({\n            'access_token': access_token,\n            'client_location': client_location,\n            'client_name': client_name,\n            'ids': clip_id,\n        })\n\n        videos = self._download_json(videos_api_url, clip_id, 'Downloading videos JSON')\n\n        duration = float(videos[0]['duration'])\n        source_ids = [source['id'] for source in videos[0]['sources']]\n        source_ids_str = ','.join(map(str, source_ids))\n\n        g = '01!8d8F_)r9]4s[qeuXfP%'\n\n        client_id = g[:2] + sha1(''.join([clip_id, g, access_token, client_location, g, client_name])\n                                 .encode('utf-8')).hexdigest()\n\n        sources_api_url = 'http://vas.sim-technik.de/vas/live/v2/videos/%s/sources?%s' % (clip_id, compat_urllib_parse.urlencode({\n            'access_token': access_token,\n            'client_id': client_id,\n            'client_location': client_location,\n            'client_name': client_name,\n        }))\n\n        sources = self._download_json(sources_api_url, clip_id, 'Downloading sources JSON')\n        server_id = sources['server_id']\n\n        client_id = g[:2] + sha1(''.join([g, clip_id, access_token, server_id,\n                                          client_location, source_ids_str, g, client_name])\n                                 .encode('utf-8')).hexdigest()\n\n        url_api_url = 'http://vas.sim-technik.de/vas/live/v2/videos/%s/sources/url?%s' % (clip_id, compat_urllib_parse.urlencode({\n            'access_token': access_token,\n            'client_id': client_id,\n            'client_location': client_location,\n            'client_name': client_name,\n            'server_id': server_id,\n            'source_ids': source_ids_str,\n        }))\n\n        urls = self._download_json(url_api_url, clip_id, 'Downloading urls JSON')\n\n        title = extract(self._TITLE_REGEXES, 'title', page, fatal=True)\n        description = extract(self._DESCRIPTION_REGEXES, 'description', page)\n        thumbnail = self._og_search_thumbnail(page)\n\n        upload_date = extract(self._UPLOAD_DATE_REGEXES, 'upload date', page)\n        if upload_date:\n            upload_date = unified_strdate(upload_date)\n\n        formats = []\n\n        urls_sources = urls['sources']\n        if isinstance(urls_sources, dict):\n            urls_sources = urls_sources.values()\n\n        def fix_bitrate(bitrate):\n            return bitrate / 1000 if bitrate % 1000 == 0 else bitrate\n\n        for source in urls_sources:\n            protocol = source['protocol']\n            if protocol == 'rtmp' or protocol == 'rtmpe':\n                mobj = re.search(r'^(?P<url>rtmpe?://[^/]+/(?P<app>[^/]+))/(?P<playpath>.+)$', source['url'])\n                if not mobj:\n                    continue\n                formats.append({\n                    'url': mobj.group('url'),\n                    'app': mobj.group('app'),\n                    'play_path': mobj.group('playpath'),\n                    'player_url': 'http://livepassdl.conviva.com/hf/ver/2.79.0.17083/LivePassModuleMain.swf',\n                    'page_url': 'http://www.prosieben.de',\n                    'vbr': fix_bitrate(source['bitrate']),\n                    'ext': 'mp4',\n                    'format_id': '%s_%s' % (source['cdn'], source['bitrate']),\n                })\n            else:\n                formats.append({\n                    'url': source['url'],\n                    'vbr': fix_bitrate(source['bitrate']),\n                })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': clip_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 184,
        "end_line": 297,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.tvp.TvpIE._real_extract#22",
        "src_path": "youtube_dl/extractor/tvp.py",
        "class_name": "youtube_dl.extractor.tvp.TvpIE",
        "signature": "youtube_dl.extractor.tvp.TvpIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        json_url = 'http://www.tvp.pl/pub/stat/videofileinfo?video_id=%s' % video_id\n        json_params = self._download_webpage(\n            json_url, video_id, u\"Downloading video metadata\")\n\n        params = json.loads(json_params)\n        self.report_extraction(video_id)\n        video_url = params['video_url']\n\n        title = self._og_search_title(webpage, fatal=True)\n        return {\n            'id': video_id,\n            'title': title,\n            'ext': 'wmv',\n            'url': video_url,\n            'description': self._og_search_description(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n        }",
        "begin_line": 22,
        "end_line": 42,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.cspan.CSpanIE._real_extract#27",
        "src_path": "youtube_dl/extractor/cspan.py",
        "class_name": "youtube_dl.extractor.cspan.CSpanIE",
        "signature": "youtube_dl.extractor.cspan.CSpanIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        page_id = mobj.group('id')\n        webpage = self._download_webpage(url, page_id)\n        video_id = self._search_regex(r'data-progid=\\'(\\d+)\\'>', webpage, 'video id')\n\n        description = self._html_search_regex(\n            [\n                # The full description\n                r'<div class=\\'expandable\\'>(.*?)<a href=\\'#\\'',\n                # If the description is small enough the other div is not\n                # present, otherwise this is a stripped version\n                r'<p class=\\'initial\\'>(.*?)</p>'\n            ],\n            webpage, 'description', flags=re.DOTALL)\n\n        info_url = 'http://c-spanvideo.org/videoLibrary/assets/player/ajax-player.php?os=android&html5=program&id=' + video_id\n        data = self._download_json(info_url, video_id)\n\n        url = unescapeHTML(data['video']['files'][0]['path']['#text'])\n\n        doc = self._download_xml('http://www.c-span.org/common/services/flashXml.php?programid=' + video_id,\n            video_id)\n\n        def find_string(s):\n            return find_xpath_attr(doc, './/string', 'name', s).text\n\n        return {\n            'id': video_id,\n            'title': find_string('title'),\n            'url': url,\n            'description': description,\n            'thumbnail': find_string('poster'),\n        }",
        "begin_line": 27,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.rbmaradio.RBMARadioIE._real_extract#29",
        "src_path": "youtube_dl/extractor/rbmaradio.py",
        "class_name": "youtube_dl.extractor.rbmaradio.RBMARadioIE",
        "signature": "youtube_dl.extractor.rbmaradio.RBMARadioIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('videoID')\n\n        webpage = self._download_webpage(url, video_id)\n\n        json_data = self._search_regex(r'window\\.gon.*?gon\\.show=(.+?);$',\n            webpage, 'json data', flags=re.MULTILINE)\n\n        try:\n            data = json.loads(json_data)\n        except ValueError as e:\n            raise ExtractorError('Invalid JSON: ' + str(e))\n\n        video_url = data['akamai_url'] + '&cbr=256'\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': data['title'],\n            'description': data.get('teaser_text'),\n            'location': data.get('country_of_origin'),\n            'uploader': data.get('host', {}).get('name'),\n            'uploader_id': data.get('host', {}).get('slug'),\n            'thumbnail': data.get('image', {}).get('large_url_2x'),\n            'duration': data.get('duration'),\n        }",
        "begin_line": 29,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._restore_bytes#57",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._restore_bytes(self, formatted_size)",
        "snippet": "    def _restore_bytes(self, formatted_size):\n        if not formatted_size:\n            return 0\n        m = re.match(r'^(?P<size>\\d+(?:\\.\\d+)?)\\s+(?P<units>[a-zA-Z]+)', formatted_size)\n        if not m:\n            return 0\n        units = m.group('units')\n        try:\n            exponent = ['B', 'KB', 'MB', 'GB', 'TB', 'PB', 'EB', 'ZB', 'YB'].index(units.upper())\n        except ValueError:\n            return 0\n        size = float(m.group('size'))\n        return int(size * (1024 ** exponent))",
        "begin_line": 57,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._formats_from_html#71",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._formats_from_html(self, html)",
        "snippet": "    def _formats_from_html(self, html):\n        FORMAT_REGEX = r'''\n            (?x)\n            <a\\s+href=\"(?P<url>[^\"]+)\">(?P<quality>[^<]+)</a>\\s*\n            <span\\s+class=\"usage\">\\((?P<note>[^\\)]+)\\)</span>\\s*\n            (?:<div\\s+class=\"popup\\s+rounded\">\\s*\n            <h3>File\\s+size</h3>\\s*(?P<filesize>.*?)\\s*\n            </div>)?                                                # File size part may be missing\n        '''\n        # Extract known formats\n        formats = [{\n            'url': x.group('url'),\n            'format_id': x.group('quality'),\n            'format_note': x.group('note'),\n            'format': '%s (%s)' % (x.group('quality'), x.group('note')),\n            'filesize': self._restore_bytes(x.group('filesize')), # File size is approximate\n            'preference': self._known_formats.index(x.group('quality')),\n            'vcodec': 'none' if x.group('note') == 'Audio only' else None,\n        } for x in list(re.finditer(FORMAT_REGEX, html)) if x.group('quality') in self._known_formats]\n\n        self._sort_formats(formats)\n\n        return formats",
        "begin_line": 71,
        "end_line": 93,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_title#95",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_title(self, html)",
        "snippet": "    def _extract_title(self, html):\n        title = self._html_search_meta('title', html, 'title')\n        if title is None:           \n            title = self._og_search_title(html)\n            TITLE_SUFFIX = ' (Channel 9)'\n            if title is not None and title.endswith(TITLE_SUFFIX):\n                title = title[:-len(TITLE_SUFFIX)]\n        return title",
        "begin_line": 95,
        "end_line": 102,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_description#104",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_description(self, html)",
        "snippet": "    def _extract_description(self, html):\n        DESCRIPTION_REGEX = r'''(?sx)\n            <div\\s+class=\"entry-content\">\\s*\n            <div\\s+id=\"entry-body\">\\s*\n            (?P<description>.+?)\\s*\n            </div>\\s*\n            </div>\n        '''\n        m = re.search(DESCRIPTION_REGEX, html)\n        if m is not None:\n            return m.group('description')\n        return self._html_search_meta('description', html, 'description')",
        "begin_line": 104,
        "end_line": 115,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_duration#117",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_duration(self, html)",
        "snippet": "    def _extract_duration(self, html):\n        m = re.search(r'data-video_duration=\"(?P<hours>\\d{2}):(?P<minutes>\\d{2}):(?P<seconds>\\d{2})\"', html)\n        return ((int(m.group('hours')) * 60 * 60) + (int(m.group('minutes')) * 60) + int(m.group('seconds'))) if m else None",
        "begin_line": 117,
        "end_line": 119,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_slides#121",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_slides(self, html)",
        "snippet": "    def _extract_slides(self, html):\n        m = re.search(r'<a href=\"(?P<slidesurl>[^\"]+)\" class=\"slides\">Slides</a>', html)\n        return m.group('slidesurl') if m is not None else None",
        "begin_line": 121,
        "end_line": 123,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_zip#125",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_zip(self, html)",
        "snippet": "    def _extract_zip(self, html):\n        m = re.search(r'<a href=\"(?P<zipurl>[^\"]+)\" class=\"zip\">Zip</a>', html)\n        return m.group('zipurl') if m is not None else None",
        "begin_line": 125,
        "end_line": 127,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_avg_rating#129",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_avg_rating(self, html)",
        "snippet": "    def _extract_avg_rating(self, html):\n        m = re.search(r'<p class=\"avg-rating\">Avg Rating: <span>(?P<avgrating>[^<]+)</span></p>', html)\n        return float(m.group('avgrating')) if m is not None else 0",
        "begin_line": 129,
        "end_line": 131,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_rating_count#133",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_rating_count(self, html)",
        "snippet": "    def _extract_rating_count(self, html):\n        m = re.search(r'<div class=\"rating-count\">\\((?P<ratingcount>[^<]+)\\)</div>', html)\n        return int(self._fix_count(m.group('ratingcount'))) if m is not None else 0",
        "begin_line": 133,
        "end_line": 135,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_view_count#137",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_view_count(self, html)",
        "snippet": "    def _extract_view_count(self, html):\n        m = re.search(r'<li class=\"views\">\\s*<span class=\"count\">(?P<viewcount>[^<]+)</span> Views\\s*</li>', html)\n        return int(self._fix_count(m.group('viewcount'))) if m is not None else 0",
        "begin_line": 137,
        "end_line": 139,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_comment_count#141",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_comment_count(self, html)",
        "snippet": "    def _extract_comment_count(self, html):\n        m = re.search(r'<li class=\"comments\">\\s*<a href=\"#comments\">\\s*<span class=\"count\">(?P<commentcount>[^<]+)</span> Comments\\s*</a>\\s*</li>', html)\n        return int(self._fix_count(m.group('commentcount'))) if m is not None else 0",
        "begin_line": 141,
        "end_line": 143,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._fix_count#145",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._fix_count(self, count)",
        "snippet": "    def _fix_count(self, count):\n        return int(str(count).replace(',', '')) if count is not None else None",
        "begin_line": 145,
        "end_line": 146,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_authors#148",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_authors(self, html)",
        "snippet": "    def _extract_authors(self, html):\n        m = re.search(r'(?s)<li class=\"author\">(.*?)</li>', html)\n        if m is None:\n            return None\n        return re.findall(r'<a href=\"/Niners/[^\"]+\">([^<]+)</a>', m.group(1))",
        "begin_line": 148,
        "end_line": 152,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_session_code#154",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_session_code(self, html)",
        "snippet": "    def _extract_session_code(self, html):\n        m = re.search(r'<li class=\"code\">\\s*(?P<code>.+?)\\s*</li>', html)\n        return m.group('code') if m is not None else None",
        "begin_line": 154,
        "end_line": 156,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_session_day#158",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_session_day(self, html)",
        "snippet": "    def _extract_session_day(self, html):\n        m = re.search(r'<li class=\"day\">\\s*<a href=\"/Events/[^\"]+\">(?P<day>[^<]+)</a>\\s*</li>', html)\n        return m.group('day') if m is not None else None",
        "begin_line": 158,
        "end_line": 160,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_session_room#162",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_session_room(self, html)",
        "snippet": "    def _extract_session_room(self, html):\n        m = re.search(r'<li class=\"room\">\\s*(?P<room>.+?)\\s*</li>', html)\n        return m.group('room') if m is not None else None",
        "begin_line": 162,
        "end_line": 164,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_session_speakers#166",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_session_speakers(self, html)",
        "snippet": "    def _extract_session_speakers(self, html):\n        return re.findall(r'<a href=\"/Events/Speakers/[^\"]+\">([^<]+)</a>', html)",
        "begin_line": 166,
        "end_line": 167,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_content#169",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_content(self, html, content_path)",
        "snippet": "    def _extract_content(self, html, content_path):\n        # Look for downloadable content        \n        formats = self._formats_from_html(html)\n        slides = self._extract_slides(html)\n        zip_ = self._extract_zip(html)\n\n        # Nothing to download\n        if len(formats) == 0 and slides is None and zip_ is None:\n            self._downloader.report_warning('None of recording, slides or zip are available for %s' % content_path)\n            return\n\n        # Extract meta\n        title = self._extract_title(html)\n        description = self._extract_description(html)\n        thumbnail = self._og_search_thumbnail(html)\n        duration = self._extract_duration(html)\n        avg_rating = self._extract_avg_rating(html)\n        rating_count = self._extract_rating_count(html)\n        view_count = self._extract_view_count(html)\n        comment_count = self._extract_comment_count(html)\n\n        common = {'_type': 'video',\n                  'id': content_path,\n                  'description': description,\n                  'thumbnail': thumbnail,\n                  'duration': duration,\n                  'avg_rating': avg_rating,\n                  'rating_count': rating_count,\n                  'view_count': view_count,\n                  'comment_count': comment_count,\n                }\n\n        result = []\n\n        if slides is not None:\n            d = common.copy()\n            d.update({ 'title': title + '-Slides', 'url': slides })\n            result.append(d)\n\n        if zip_ is not None:\n            d = common.copy()\n            d.update({ 'title': title + '-Zip', 'url': zip_ })\n            result.append(d)\n\n        if len(formats) > 0:\n            d = common.copy()\n            d.update({ 'title': title, 'formats': formats })\n            result.append(d)\n\n        return result",
        "begin_line": 169,
        "end_line": 218,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_entry_item#220",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_entry_item(self, html, content_path)",
        "snippet": "    def _extract_entry_item(self, html, content_path):\n        contents = self._extract_content(html, content_path)\n        if contents is None:\n            return contents\n\n        authors = self._extract_authors(html)\n\n        for content in contents:\n            content['authors'] = authors\n\n        return contents",
        "begin_line": 220,
        "end_line": 230,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_session#232",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_session(self, html, content_path)",
        "snippet": "    def _extract_session(self, html, content_path):\n        contents = self._extract_content(html, content_path)\n        if contents is None:\n            return contents\n\n        session_meta = {'session_code': self._extract_session_code(html),\n                        'session_day': self._extract_session_day(html),\n                        'session_room': self._extract_session_room(html),\n                        'session_speakers': self._extract_session_speakers(html),\n                        }\n\n        for content in contents:\n            content.update(session_meta)\n\n        return contents",
        "begin_line": 232,
        "end_line": 246,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._extract_list#248",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._extract_list(self, content_path)",
        "snippet": "    def _extract_list(self, content_path):\n        rss = self._download_xml(self._RSS_URL % content_path, content_path, 'Downloading RSS')\n        entries = [self.url_result(session_url.text, 'Channel9')\n                   for session_url in rss.findall('./channel/item/link')]\n        title_text = rss.find('./channel/title').text\n        return self.playlist_result(entries, content_path, title_text)",
        "begin_line": 248,
        "end_line": 253,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.channel9.Channel9IE._real_extract#255",
        "src_path": "youtube_dl/extractor/channel9.py",
        "class_name": "youtube_dl.extractor.channel9.Channel9IE",
        "signature": "youtube_dl.extractor.channel9.Channel9IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        content_path = mobj.group('contentpath')\n\n        webpage = self._download_webpage(url, content_path, 'Downloading web page')\n\n        page_type_m = re.search(r'<meta name=\"Search.PageType\" content=\"(?P<pagetype>[^\"]+)\"/>', webpage)\n        if page_type_m is None:\n            raise ExtractorError('Search.PageType not found, don\\'t know how to process this page', expected=True)\n\n        page_type = page_type_m.group('pagetype')\n        if page_type == 'List':         # List page, may contain list of 'item'-like objects\n            return self._extract_list(content_path)\n        elif page_type == 'Entry.Item': # Any 'item'-like page, may contain downloadable content\n            return self._extract_entry_item(webpage, content_path)\n        elif page_type == 'Session':    # Event session page, may contain downloadable content\n            return self._extract_session(webpage, content_path)\n        else:\n            raise ExtractorError('Unexpected Search.PageType %s' % page_type, expected=True)",
        "begin_line": 255,
        "end_line": 273,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._decrypt_subtitles#54",
        "src_path": "youtube_dl/extractor/crunchyroll.py",
        "class_name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE",
        "signature": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._decrypt_subtitles(self, data, iv, id)",
        "snippet": "    def _decrypt_subtitles(self, data, iv, id):\n        data = bytes_to_intlist(data)\n        iv = bytes_to_intlist(iv)\n        id = int(id)\n\n        def obfuscate_key_aux(count, modulo, start):\n            output = list(start)\n            for _ in range(count):\n                output.append(output[-1] + output[-2])\n            # cut off start values\n            output = output[2:]\n            output = list(map(lambda x: x % modulo + 33, output))\n            return output\n\n        def obfuscate_key(key):\n            num1 = int(floor(pow(2, 25) * sqrt(6.9)))\n            num2 = (num1 ^ key) << 5\n            num3 = key ^ num1\n            num4 = num3 ^ (num3 >> 3) ^ num2\n            prefix = intlist_to_bytes(obfuscate_key_aux(20, 97, (1, 2)))\n            shaHash = bytes_to_intlist(sha1(prefix + str(num4).encode('ascii')).digest())\n            # Extend 160 Bit hash to 256 Bit\n            return shaHash + [0] * 12\n\n        key = obfuscate_key(id)\n        class Counter:\n            __value = iv\n            def next_value(self):\n                temp = self.__value\n                self.__value = inc(self.__value)\n                return temp\n        decrypted_data = intlist_to_bytes(aes_cbc_decrypt(data, key, iv))\n        return zlib.decompress(decrypted_data)",
        "begin_line": 54,
        "end_line": 86,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._convert_subtitles_to_srt#88",
        "src_path": "youtube_dl/extractor/crunchyroll.py",
        "class_name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE",
        "signature": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._convert_subtitles_to_srt(self, subtitles)",
        "snippet": "    def _convert_subtitles_to_srt(self, subtitles):\n        output = ''\n        for i, (start, end, text) in enumerate(re.findall(r'<event [^>]*?start=\"([^\"]+)\" [^>]*?end=\"([^\"]+)\" [^>]*?text=\"([^\"]+)\"[^>]*?>', subtitles), 1):\n            start = start.replace('.', ',')\n            end = end.replace('.', ',')\n            text = clean_html(text)\n            text = text.replace('\\\\N', '\\n')\n            if not text:\n                continue\n            output += '%d\\n%s --> %s\\n%s\\n\\n' % (i, start, end, text)\n        return output",
        "begin_line": 88,
        "end_line": 98,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._real_extract#100",
        "src_path": "youtube_dl/extractor/crunchyroll.py",
        "class_name": "youtube_dl.extractor.crunchyroll.CrunchyrollIE",
        "signature": "youtube_dl.extractor.crunchyroll.CrunchyrollIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self,url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('video_id')\n\n        if mobj.group('prefix') == 'm':\n            mobile_webpage = self._download_webpage(url, video_id, 'Downloading mobile webpage')\n            webpage_url = self._search_regex(r'<link rel=\"canonical\" href=\"([^\"]+)\" />', mobile_webpage, 'webpage_url')\n        else:\n            webpage_url = 'http://www.' + mobj.group('url')\n\n        webpage = self._download_webpage(webpage_url, video_id, 'Downloading webpage')\n        note_m = self._html_search_regex(r'<div class=\"showmedia-trailer-notice\">(.+?)</div>', webpage, 'trailer-notice', default='')\n        if note_m:\n            raise ExtractorError(note_m)\n\n        mobj = re.search(r'Page\\.messaging_box_controller\\.addItems\\(\\[(?P<msg>{.+?})\\]\\)', webpage)\n        if mobj:\n            msg = json.loads(mobj.group('msg'))\n            if msg.get('type') == 'error':\n                raise ExtractorError('crunchyroll returned error: %s' % msg['message_body'], expected=True)\n\n        video_title = self._html_search_regex(r'<h1[^>]*>(.+?)</h1>', webpage, 'video_title', flags=re.DOTALL)\n        video_title = re.sub(r' {2,}', ' ', video_title)\n        video_description = self._html_search_regex(r'\"description\":\"([^\"]+)', webpage, 'video_description', default='')\n        if not video_description:\n            video_description = None\n        video_upload_date = self._html_search_regex(r'<div>Availability for free users:(.+?)</div>', webpage, 'video_upload_date', fatal=False, flags=re.DOTALL)\n        if video_upload_date:\n            video_upload_date = unified_strdate(video_upload_date)\n        video_uploader = self._html_search_regex(r'<div>\\s*Publisher:(.+?)</div>', webpage, 'video_uploader', fatal=False, flags=re.DOTALL)\n\n        playerdata_url = compat_urllib_parse.unquote(self._html_search_regex(r'\"config_url\":\"([^\"]+)', webpage, 'playerdata_url'))\n        playerdata_req = compat_urllib_request.Request(playerdata_url)\n        playerdata_req.data = compat_urllib_parse.urlencode({'current_page': webpage_url})\n        playerdata_req.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        playerdata = self._download_webpage(playerdata_req, video_id, note='Downloading media info')\n\n        stream_id = self._search_regex(r'<media_id>([^<]+)', playerdata, 'stream_id')\n        video_thumbnail = self._search_regex(r'<episode_image_url>([^<]+)', playerdata, 'thumbnail', fatal=False)\n\n        formats = []\n        for fmt in re.findall(r'\\?p([0-9]{3,4})=1', webpage):\n            stream_quality, stream_format = self._FORMAT_IDS[fmt]\n            video_format = fmt+'p'\n            streamdata_req = compat_urllib_request.Request('http://www.crunchyroll.com/xml/')\n            # urlencode doesn't work!\n            streamdata_req.data = 'req=RpcApiVideoEncode%5FGetStreamInfo&video%5Fencode%5Fquality='+stream_quality+'&media%5Fid='+stream_id+'&video%5Fformat='+stream_format\n            streamdata_req.add_header('Content-Type', 'application/x-www-form-urlencoded')\n            streamdata_req.add_header('Content-Length', str(len(streamdata_req.data)))\n            streamdata = self._download_webpage(streamdata_req, video_id, note='Downloading media info for '+video_format)\n            video_url = self._search_regex(r'<host>([^<]+)', streamdata, 'video_url')\n            video_play_path = self._search_regex(r'<file>([^<]+)', streamdata, 'video_play_path')\n            formats.append({\n                'url': video_url,\n                'play_path':   video_play_path,\n                'ext': 'flv',\n                'format': video_format,\n                'format_id': video_format,\n            })\n\n        subtitles = {}\n        for sub_id, sub_name in re.findall(r'\\?ssid=([0-9]+)\" title=\"([^\"]+)', webpage):\n            sub_page = self._download_webpage('http://www.crunchyroll.com/xml/?req=RpcApiSubtitle_GetXml&subtitle_script_id='+sub_id,\\\n                                              video_id, note='Downloading subtitles for '+sub_name)\n            id = self._search_regex(r'id=\\'([0-9]+)', sub_page, 'subtitle_id', fatal=False)\n            iv = self._search_regex(r'<iv>([^<]+)', sub_page, 'subtitle_iv', fatal=False)\n            data = self._search_regex(r'<data>([^<]+)', sub_page, 'subtitle_data', fatal=False)\n            if not id or not iv or not data:\n                continue\n            id = int(id)\n            iv = base64.b64decode(iv)\n            data = base64.b64decode(data)\n\n            subtitle = self._decrypt_subtitles(data, iv, id).decode('utf-8')\n            lang_code = self._search_regex(r'lang_code=[\"\\']([^\"\\']+)', subtitle, 'subtitle_lang_code', fatal=False)\n            if not lang_code:\n                continue\n            subtitles[lang_code] = self._convert_subtitles_to_srt(subtitle)\n\n        return {\n            'id':          video_id,\n            'title':       video_title,\n            'description': video_description,\n            'thumbnail':   video_thumbnail,\n            'uploader':    video_uploader,\n            'upload_date': video_upload_date,\n            'subtitles':   subtitles,\n            'formats':     formats,\n        }",
        "begin_line": 100,
        "end_line": 188,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.weibo.WeiboIE._real_extract#32",
        "src_path": "youtube_dl/extractor/weibo.py",
        "class_name": "youtube_dl.extractor.weibo.WeiboIE",
        "signature": "youtube_dl.extractor.weibo.WeiboIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url, flags=re.VERBOSE)\n        video_id = mobj.group('id')\n        info_url = 'http://video.weibo.com/?s=v&a=play_list&format=json&mix_video_id=t_%s' % video_id\n        info_page = self._download_webpage(info_url, video_id)\n        info = json.loads(info_page)\n\n        videos_urls = map(lambda v: v['play_page_url'], info['result']['data'])\n        #Prefer sina video since they have thumbnails\n        videos_urls = sorted(videos_urls, key=lambda u: u'video.sina.com' in u)\n        player_url = videos_urls[-1]\n        m_sina = re.match(r'https?://video.sina.com.cn/v/b/(\\d+)-\\d+.html', player_url)\n        if m_sina is not None:\n            self.to_screen('Sina video detected')\n            sina_id = m_sina.group(1)\n            player_url = 'http://you.video.sina.com.cn/swf/quotePlayer.swf?vid=%s' % sina_id\n        return self.url_result(player_url)",
        "begin_line": 32,
        "end_line": 48,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.vesti.VestiIE._real_extract#134",
        "src_path": "youtube_dl/extractor/vesti.py",
        "class_name": "youtube_dl.extractor.vesti.VestiIE",
        "signature": "youtube_dl.extractor.vesti.VestiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        page = self._download_webpage(url, video_id, 'Downloading page')\n\n        mobj = re.search(\n            r'<meta property=\"og:video\" content=\"http://www\\.vesti\\.ru/i/flvplayer_videoHost\\.swf\\?vid=(?P<id>\\d+)',\n            page)\n        if mobj:\n            video_id = mobj.group('id')\n            page = self._download_webpage('http://www.vesti.ru/only_video.html?vid=%s' % video_id, video_id,\n                'Downloading video page')\n\n        mobj = re.search(\n            r'<meta property=\"og:video\" content=\"http://player\\.rutv\\.ru/flash2v/container\\.swf\\?id=(?P<id>\\d+)', page)\n        if mobj:\n            video_type = 'video'\n            video_id = mobj.group('id')\n        else:\n            mobj = re.search(\n                r'<iframe.+?src=\"http://player\\.rutv\\.ru/iframe/(?P<type>[^/]+)/id/(?P<id>\\d+)[^\"]*\".*?></iframe>',\n                page)\n\n            if not mobj:\n                raise ExtractorError('No media found', expected=True)\n\n            video_type = mobj.group('type')\n            video_id = mobj.group('id')\n\n        json_data = self._download_json(\n            'http://player.rutv.ru/iframe/%splay/id/%s' % ('live-' if video_type == 'live' else '', video_id),\n            video_id, 'Downloading JSON')\n\n        if json_data['errors']:\n            raise ExtractorError('vesti returned error: %s' % json_data['errors'], expected=True)\n\n        playlist = json_data['data']['playlist']\n        medialist = playlist['medialist']\n        media = medialist[0]\n\n        if media['errors']:\n            raise ExtractorError('vesti returned error: %s' % media['errors'], expected=True)\n\n        view_count = playlist.get('count_views')\n        priority_transport = playlist['priority_transport']\n\n        thumbnail = media['picture']\n        width = int_or_none(media['width'])\n        height = int_or_none(media['height'])\n        description = media['anons']\n        title = media['title']\n        duration = int_or_none(media.get('duration'))\n\n        formats = []\n\n        for transport, links in media['sources'].items():\n            for quality, url in links.items():\n                if transport == 'rtmp':\n                    mobj = re.search(r'^(?P<url>rtmp://[^/]+/(?P<app>.+))/(?P<playpath>.+)$', url)\n                    if not mobj:\n                        continue\n                    fmt = {\n                        'url': mobj.group('url'),\n                        'play_path': mobj.group('playpath'),\n                        'app': mobj.group('app'),\n                        'page_url': 'http://player.rutv.ru',\n                        'player_url': 'http://player.rutv.ru/flash2v/osmf.swf?i=22',\n                        'rtmp_live': True,\n                        'ext': 'flv',\n                        'vbr': int(quality),\n                    }\n                elif transport == 'm3u8':\n                    fmt = {\n                        'url': url,\n                        'ext': 'mp4',\n                    }\n                else:\n                    fmt = {\n                        'url': url\n                    }\n                fmt.update({\n                    'width': width,\n                    'height': height,\n                    'format_id': '%s-%s' % (transport, quality),\n                    'preference': -1 if priority_transport == transport else -2,\n                })\n                formats.append(fmt)\n\n        if not formats:\n            raise ExtractorError('No media links available for %s' % video_id)\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'view_count': view_count,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 134,
        "end_line": 236,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.hark.HarkIE._real_extract#22",
        "src_path": "youtube_dl/extractor/hark.py",
        "class_name": "youtube_dl.extractor.hark.HarkIE",
        "signature": "youtube_dl.extractor.hark.HarkIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group(1)\n        json_url = \"http://www.hark.com/clips/%s.json\" %(video_id)\n        info_json = self._download_webpage(json_url, video_id)\n        info = json.loads(info_json)\n        final_url = info['url']\n\n        return {'id': video_id,\n                'url' : final_url,\n                'title': info['name'],\n                'ext': determine_ext(final_url),\n                'description': info['description'],\n                'thumbnail': info['image_original'],\n                'duration': info['duration'],\n                }",
        "begin_line": 22,
        "end_line": 37,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.videodetective.VideoDetectiveIE._real_extract#23",
        "src_path": "youtube_dl/extractor/videodetective.py",
        "class_name": "youtube_dl.extractor.videodetective.VideoDetectiveIE",
        "signature": "youtube_dl.extractor.videodetective.VideoDetectiveIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        og_video = self._og_search_video_url(webpage)\n        query = compat_urlparse.urlparse(og_video).query\n        return self.url_result(InternetVideoArchiveIE._build_url(query),\n            ie=InternetVideoArchiveIE.ie_key())",
        "begin_line": 23,
        "end_line": 30,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.nhl.NHLBaseInfoExtractor._extract_video#18",
        "src_path": "youtube_dl/extractor/nhl.py",
        "class_name": "youtube_dl.extractor.nhl.NHLBaseInfoExtractor",
        "signature": "youtube_dl.extractor.nhl.NHLBaseInfoExtractor._extract_video(self, info)",
        "snippet": "    def _extract_video(self, info):\n        video_id = info['id']\n        self.report_extraction(video_id)\n\n        initial_video_url = info['publishPoint']\n        data = compat_urllib_parse.urlencode({\n            'type': 'fvod',\n            'path': initial_video_url.replace('.mp4', '_sd.mp4'),\n        })\n        path_url = 'http://video.nhl.com/videocenter/servlets/encryptvideopath?' + data\n        path_doc = self._download_xml(path_url, video_id,\n            u'Downloading final video url')\n        video_url = path_doc.find('path').text\n\n        join = compat_urlparse.urljoin\n        return {\n            'id': video_id,\n            'title': info['name'],\n            'url': video_url,\n            'ext': determine_ext(video_url),\n            'description': info['description'],\n            'duration': int(info['duration']),\n            'thumbnail': join(join(video_url, '/u/'), info['bigImage']),\n            'upload_date': unified_strdate(info['releaseDate'].split('.')[0]),\n        }",
        "begin_line": 18,
        "end_line": 42,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.nhl.NHLIE._real_extract#60",
        "src_path": "youtube_dl/extractor/nhl.py",
        "class_name": "youtube_dl.extractor.nhl.NHLIE",
        "signature": "youtube_dl.extractor.nhl.NHLIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        json_url = 'http://video.nhl.com/videocenter/servlets/playlist?ids=%s&format=json' % video_id\n        info_json = self._download_webpage(json_url, video_id,\n            u'Downloading info json')\n        info_json = self._fix_json(info_json)\n        info = json.loads(info_json)[0]\n        return self._extract_video(info)",
        "begin_line": 60,
        "end_line": 68,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.nhl.NHLVideocenterIE.suitable#77",
        "src_path": "youtube_dl/extractor/nhl.py",
        "class_name": "youtube_dl.extractor.nhl.NHLVideocenterIE",
        "signature": "youtube_dl.extractor.nhl.NHLVideocenterIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        if NHLIE.suitable(url):\n            return False\n        return super(NHLVideocenterIE, cls).suitable(url)",
        "begin_line": 77,
        "end_line": 80,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.006711409395973154,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.nhl.NHLVideocenterIE._real_extract#82",
        "src_path": "youtube_dl/extractor/nhl.py",
        "class_name": "youtube_dl.extractor.nhl.NHLVideocenterIE",
        "signature": "youtube_dl.extractor.nhl.NHLVideocenterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        team = mobj.group('team')\n        webpage = self._download_webpage(url, team)\n        cat_id = self._search_regex(\n            [r'var defaultCatId = \"(.+?)\";',\n             r'{statusIndex:0,index:0,.*?id:(.*?),'],\n            webpage, u'category id')\n        playlist_title = self._html_search_regex(\n            r'tab0\"[^>]*?>(.*?)</td>',\n            webpage, u'playlist title', flags=re.DOTALL).lower().capitalize()\n\n        data = compat_urllib_parse.urlencode({\n            'cid': cat_id,\n            # This is the default value\n            'count': 12,\n            'ptrs': 3,\n            'format': 'json',\n        })\n        path = '/videocenter/servlets/browse?' + data\n        request_url = compat_urlparse.urljoin(url, path)\n        response = self._download_webpage(request_url, playlist_title)\n        response = self._fix_json(response)\n        if not response.strip():\n            self._downloader.report_warning(u'Got an empty reponse, trying '\n                                            u'adding the \"newvideos\" parameter')\n            response = self._download_webpage(request_url + '&newvideos=true',\n                playlist_title)\n            response = self._fix_json(response)\n        videos = json.loads(response)\n\n        return {\n            '_type': 'playlist',\n            'title': playlist_title,\n            'id': cat_id,\n            'entries': [self._extract_video(i) for i in videos],\n        }",
        "begin_line": 82,
        "end_line": 118,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.mailru.MailRuIE._real_extract#29",
        "src_path": "youtube_dl/extractor/mailru.py",
        "class_name": "youtube_dl.extractor.mailru.MailRuIE",
        "signature": "youtube_dl.extractor.mailru.MailRuIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        video_data = self._download_json(\n            'http://videoapi.my.mail.ru/videos/%s.json?new=1' % video_id, video_id, 'Downloading video JSON')\n\n        author = video_data['author']\n        uploader = author['name']\n        uploader_id = author['id']\n\n        movie = video_data['movie']\n        content_id = str(movie['contentId'])\n        title = movie['title']\n        thumbnail = movie['poster']\n        duration = movie['duration']\n\n        upload_date = datetime.datetime.fromtimestamp(video_data['timestamp']).strftime('%Y%m%d')\n        view_count = video_data['views_count']\n\n        formats = [\n            {\n                'url': video['url'],\n                'format_id': video['name'],\n            } for video in video_data['videos']\n        ]\n\n        return {\n            'id': content_id,\n            'title': title,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'duration': duration,\n            'view_count': view_count,\n            'formats': formats,\n        }",
        "begin_line": 29,
        "end_line": 66,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.fktv.FKTVIE._real_extract#26",
        "src_path": "youtube_dl/extractor/fktv.py",
        "class_name": "youtube_dl.extractor.fktv.FKTVIE",
        "signature": "youtube_dl.extractor.fktv.FKTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        episode = int(mobj.group('ep'))\n\n        server = random.randint(2, 4)\n        video_thumbnail = 'http://fernsehkritik.tv/images/magazin/folge%d.jpg' % episode\n        start_webpage = self._download_webpage('http://fernsehkritik.tv/folge-%d/Start' % episode,\n            episode)\n        playlist = self._search_regex(r'playlist = (\\[.*?\\]);', start_webpage,\n            u'playlist', flags=re.DOTALL)\n        files = json.loads(re.sub('{[^{}]*?}', '{}', playlist))\n        # TODO: return a single multipart video\n        videos = []\n        for i, _ in enumerate(files, 1):\n            video_id = '%04d%d' % (episode, i)\n            video_url = 'http://dl%d.fernsehkritik.tv/fernsehkritik%d%s.flv' % (server, episode, '' if i == 1 else '-%d' % i)\n            videos.append({\n                'id': video_id,\n                'url': video_url,\n                'ext': determine_ext(video_url),\n                'title': clean_html(get_element_by_id('eptitle', start_webpage)),\n                'description': clean_html(get_element_by_id('contentlist', start_webpage)),\n                'thumbnail': video_thumbnail\n            })\n        return videos",
        "begin_line": 26,
        "end_line": 50,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.fktv.FKTVPosteckeIE._real_extract#65",
        "src_path": "youtube_dl/extractor/fktv.py",
        "class_name": "youtube_dl.extractor.fktv.FKTVPosteckeIE",
        "signature": "youtube_dl.extractor.fktv.FKTVPosteckeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        episode = int(mobj.group('ep'))\n\n        server = random.randint(2, 4)\n        video_id = '%04d' % episode\n        video_url = 'http://dl%d.fernsehkritik.tv/postecke/postecke%d.flv' % (server, episode)\n        video_title = 'Postecke %d' % episode\n        return {\n            'id':       video_id,\n            'url':      video_url,\n            'ext':      determine_ext(video_url),\n            'title':    video_title,\n        }",
        "begin_line": 65,
        "end_line": 78,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.hypem.HypemIE._real_extract#27",
        "src_path": "youtube_dl/extractor/hypem.py",
        "class_name": "youtube_dl.extractor.hypem.HypemIE",
        "signature": "youtube_dl.extractor.hypem.HypemIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        if mobj is None:\n            raise ExtractorError(u'Invalid URL: %s' % url)\n        track_id = mobj.group(1)\n\n        data = {'ax': 1, 'ts': time.time()}\n        data_encoded = compat_urllib_parse.urlencode(data)\n        complete_url = url + \"?\" + data_encoded\n        request = compat_urllib_request.Request(complete_url)\n        response, urlh = self._download_webpage_handle(request, track_id, u'Downloading webpage with the url')\n        cookie = urlh.headers.get('Set-Cookie', '')\n\n        self.report_extraction(track_id)\n\n        html_tracks = self._html_search_regex(r'<script type=\"application/json\" id=\"displayList-data\">(.*?)</script>',\n            response, u'tracks', flags=re.MULTILINE|re.DOTALL).strip()\n        try:\n            track_list = json.loads(html_tracks)\n            track = track_list[u'tracks'][0]\n        except ValueError:\n            raise ExtractorError(u'Hypemachine contained invalid JSON.')\n\n        key = track[u\"key\"]\n        track_id = track[u\"id\"]\n        artist = track[u\"artist\"]\n        title = track[u\"song\"]\n\n        serve_url = \"http://hypem.com/serve/source/%s/%s\" % (compat_str(track_id), compat_str(key))\n        request = compat_urllib_request.Request(serve_url, \"\" , {'Content-Type': 'application/json'})\n        request.add_header('cookie', cookie)\n        song_data_json = self._download_webpage(request, track_id, u'Downloading metadata')\n        try:\n            song_data = json.loads(song_data_json)\n        except ValueError:\n            raise ExtractorError(u'Hypemachine contained invalid JSON.')\n        final_url = song_data[u\"url\"]\n\n        return [{\n            'id':       track_id,\n            'url':      final_url,\n            'ext':      \"mp3\",\n            'title':    title,\n            'artist':   artist,\n        }]",
        "begin_line": 27,
        "end_line": 71,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.nbc.NBCIE._real_extract#23",
        "src_path": "youtube_dl/extractor/nbc.py",
        "class_name": "youtube_dl.extractor.nbc.NBCIE",
        "signature": "youtube_dl.extractor.nbc.NBCIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        theplatform_url = self._search_regex('class=\"video-player video-player-full\" data-mpx-url=\"(.*?)\"', webpage, 'theplatform url')\n        if theplatform_url.startswith('//'):\n            theplatform_url = 'http:' + theplatform_url\n        return self.url_result(theplatform_url)",
        "begin_line": 23,
        "end_line": 30,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.nbc.NBCNewsIE._real_extract#47",
        "src_path": "youtube_dl/extractor/nbc.py",
        "class_name": "youtube_dl.extractor.nbc.NBCNewsIE",
        "signature": "youtube_dl.extractor.nbc.NBCNewsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        all_info = self._download_xml('http://www.nbcnews.com/id/%s/displaymode/1219' % video_id, video_id)\n        info = all_info.find('video')\n\n        return {\n            'id': video_id,\n            'title': info.find('headline').text,\n            'ext': 'flv',\n            'url': find_xpath_attr(info, 'media', 'type', 'flashVideo').text,\n            'description': compat_str(info.find('caption').text),\n            'thumbnail': find_xpath_attr(info, 'media', 'type', 'thumbnail').text,\n        }",
        "begin_line": 47,
        "end_line": 60,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.streamcz.StreamCZIE._real_extract#27",
        "src_path": "youtube_dl/extractor/streamcz.py",
        "class_name": "youtube_dl.extractor.streamcz.StreamCZIE",
        "signature": "youtube_dl.extractor.streamcz.StreamCZIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n\n        webpage = self._download_webpage(url, video_id)\n\n        data = self._html_search_regex(r'Stream\\.Data\\.Episode\\((.+?)\\);', webpage, 'stream data')\n\n        jsonData = json.loads(data)\n\n        formats = []\n        for video in jsonData['instances']:\n            for video_format in video['instances']:\n                format_id = video_format['quality']\n\n                if format_id == '240p':\n                    quality = 0\n                elif format_id == '360p':\n                    quality = 1\n                elif format_id == '480p':\n                    quality = 2\n                elif format_id == '720p':\n                    quality = 3\n\n                formats.append({\n                    'format_id': '%s-%s' % (video_format['type'].split('/')[1], format_id),\n                    'url': video_format['source'],\n                    'quality': quality,\n                })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': str(jsonData['id']),\n            'title': self._og_search_title(webpage),\n            'thumbnail': jsonData['episode_image_original_url'].replace('//', 'http://'),\n            'formats': formats,\n            'description': self._og_search_description(webpage),\n            'duration': int_or_none(jsonData['duration']),\n            'view_count': int_or_none(jsonData['stats_total']),\n        }",
        "begin_line": 27,
        "end_line": 67,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.br.BRIE._real_extract#28",
        "src_path": "youtube_dl/extractor/br.py",
        "class_name": "youtube_dl.extractor.br.BRIE",
        "signature": "youtube_dl.extractor.br.BRIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('id')\n        page = self._download_webpage(url, display_id)\n        xml_url = self._search_regex(\n            r\"return BRavFramework\\.register\\(BRavFramework\\('avPlayer_(?:[a-f0-9-]{36})'\\)\\.setup\\({dataURL:'(/mediathek/video/[a-z0-9/~_.-]+)'}\\)\\);\", page, \"XMLURL\")\n        xml = self._download_xml(self._BASE_URL + xml_url, None)\n\n        videos = [{\n            \"id\": xml_video.get(\"externalId\"),\n            \"title\": xml_video.find(\"title\").text,\n            \"formats\": self._extract_formats(xml_video.find(\"assets\")),\n            \"thumbnails\": self._extract_thumbnails(xml_video.find(\"teaserImage/variants\")),\n            \"description\": \" \".join(xml_video.find(\"shareTitle\").text.splitlines()),\n            \"uploader\": xml_video.find(\"author\").text,\n            \"upload_date\": \"\".join(reversed(xml_video.find(\"broadcastDate\").text.split(\".\"))),\n            \"webpage_url\": xml_video.find(\"permalink\").text,\n        } for xml_video in xml.findall(\"video\")]\n\n        if len(videos) > 1:\n            self._downloader.report_warning(\n                'found multiple videos; please '\n                'report this with the video URL to http://yt-dl.org/bug')\n        if not videos:\n            raise ExtractorError('No video entries found')\n        return videos[0]",
        "begin_line": 28,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.br.BRIE._extract_formats#55",
        "src_path": "youtube_dl/extractor/br.py",
        "class_name": "youtube_dl.extractor.br.BRIE",
        "signature": "youtube_dl.extractor.br.BRIE._extract_formats(self, assets)",
        "snippet": "    def _extract_formats(self, assets):\n        formats = [{\n            \"url\": asset.find(\"downloadUrl\").text,\n            \"ext\": asset.find(\"mediaType\").text,\n            \"format_id\": asset.get(\"type\"),\n            \"width\": int(asset.find(\"frameWidth\").text),\n            \"height\": int(asset.find(\"frameHeight\").text),\n            \"tbr\": int(asset.find(\"bitrateVideo\").text),\n            \"abr\": int(asset.find(\"bitrateAudio\").text),\n            \"vcodec\": asset.find(\"codecVideo\").text,\n            \"container\": asset.find(\"mediaType\").text,\n            \"filesize\": int(asset.find(\"size\").text),\n        } for asset in assets.findall(\"asset\")\n            if asset.find(\"downloadUrl\") is not None]\n\n        self._sort_formats(formats)\n        return formats",
        "begin_line": 55,
        "end_line": 71,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.br.BRIE._extract_thumbnails#73",
        "src_path": "youtube_dl/extractor/br.py",
        "class_name": "youtube_dl.extractor.br.BRIE",
        "signature": "youtube_dl.extractor.br.BRIE._extract_thumbnails(self, variants)",
        "snippet": "    def _extract_thumbnails(self, variants):\n        thumbnails = [{\n            \"url\": self._BASE_URL + variant.find(\"url\").text,\n            \"width\": int(variant.find(\"width\").text),\n            \"height\": int(variant.find(\"height\").text),\n        } for variant in variants.findall(\"variant\")]\n        thumbnails.sort(key=lambda x: x[\"width\"] * x[\"height\"], reverse=True)\n        return thumbnails",
        "begin_line": 73,
        "end_line": 80,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTvIE.suitable#30",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTvIE",
        "signature": "youtube_dl.extractor.arte.ArteTvIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return any(re.match(regex, url) for regex in (cls._VIDEOS_URL, cls._LIVEWEB_URL))",
        "begin_line": 30,
        "end_line": 31,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.00015790304752881732,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTvIE._real_extract#61",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTvIE",
        "signature": "youtube_dl.extractor.arte.ArteTvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VIDEOS_URL, url)\n        if mobj is not None:\n            id = mobj.group('id')\n            lang = mobj.group('lang')\n            return self._extract_video(url, id, lang)\n\n        mobj = re.match(self._LIVEWEB_URL, url)\n        if mobj is not None:\n            name = mobj.group('name')\n            lang = mobj.group('lang')\n            return self._extract_liveweb(url, name, lang)\n\n        if re.search(self._LIVE_URL, url) is not None:\n            raise ExtractorError(u'Arte live streams are not yet supported, sorry')",
        "begin_line": 61,
        "end_line": 75,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTvIE._extract_video#79",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTvIE",
        "signature": "youtube_dl.extractor.arte.ArteTvIE._extract_video(self, url, video_id, lang)",
        "snippet": "    def _extract_video(self, url, video_id, lang):\n        \"\"\"Extract from videos.arte.tv\"\"\"\n        ref_xml_url = url.replace('/videos/', '/do_delegate/videos/')\n        ref_xml_url = ref_xml_url.replace('.html', ',view,asPlayerXml.xml')\n        ref_xml_doc = self._download_xml(ref_xml_url, video_id, note=u'Downloading metadata')\n        config_node = find_xpath_attr(ref_xml_doc, './/video', 'lang', lang)\n        config_xml_url = config_node.attrib['ref']\n        config_xml = self._download_webpage(config_xml_url, video_id, note=u'Downloading configuration')\n\n        video_urls = list(re.finditer(r'<url quality=\"(?P<quality>.*?)\">(?P<url>.*?)</url>', config_xml))\n        def _key(m):\n            quality = m.group('quality')\n            if quality == 'hd':\n                return 2\n            else:\n                return 1\n        # We pick the best quality\n        video_urls = sorted(video_urls, key=_key)\n        video_url = list(video_urls)[-1].group('url')\n        \n        title = self._html_search_regex(r'<name>(.*?)</name>', config_xml, 'title')\n        thumbnail = self._html_search_regex(r'<firstThumbnailUrl>(.*?)</firstThumbnailUrl>',\n                                            config_xml, 'thumbnail')\n        return {'id': video_id,\n                'title': title,\n                'thumbnail': thumbnail,\n                'url': video_url,\n                'ext': 'flv',\n                }",
        "begin_line": 79,
        "end_line": 107,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTvIE._extract_liveweb#109",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTvIE",
        "signature": "youtube_dl.extractor.arte.ArteTvIE._extract_liveweb(self, url, name, lang)",
        "snippet": "    def _extract_liveweb(self, url, name, lang):\n        \"\"\"Extract form http://liveweb.arte.tv/\"\"\"\n        webpage = self._download_webpage(url, name)\n        video_id = self._search_regex(r'eventId=(\\d+?)(\"|&)', webpage, 'event id')\n        config_doc = self._download_xml('http://download.liveweb.arte.tv/o21/liveweb/events/event-%s.xml' % video_id,\n                                            video_id, 'Downloading information')\n        event_doc = config_doc.find('event')\n        url_node = event_doc.find('video').find('urlHd')\n        if url_node is None:\n            url_node = event_doc.find('urlSd')\n\n        return {'id': video_id,\n                'title': event_doc.find('name%s' % lang.capitalize()).text,\n                'url': url_node.text.replace('MP4', 'mp4'),\n                'ext': 'flv',\n                'thumbnail': self._og_search_thumbnail(webpage),\n                }",
        "begin_line": 109,
        "end_line": 125,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTVPlus7IE._real_extract#141",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTVPlus7IE",
        "signature": "youtube_dl.extractor.arte.ArteTVPlus7IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id, lang = self._extract_url_info(url)\n        webpage = self._download_webpage(url, video_id)\n        return self._extract_from_webpage(webpage, video_id, lang)",
        "begin_line": 141,
        "end_line": 144,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTVPlus7IE._extract_from_webpage#146",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTVPlus7IE",
        "signature": "youtube_dl.extractor.arte.ArteTVPlus7IE._extract_from_webpage(self, webpage, video_id, lang)",
        "snippet": "    def _extract_from_webpage(self, webpage, video_id, lang):\n        json_url = self._html_search_regex(r'arte_vp_url=\"(.*?)\"', webpage, 'json url')\n        return self._extract_from_json_url(json_url, video_id, lang)",
        "begin_line": 146,
        "end_line": 148,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTVPlus7IE._extract_from_json_url#150",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTVPlus7IE",
        "signature": "youtube_dl.extractor.arte.ArteTVPlus7IE._extract_from_json_url(self, json_url, video_id, lang)",
        "snippet": "    def _extract_from_json_url(self, json_url, video_id, lang):\n        json_info = self._download_webpage(json_url, video_id, 'Downloading info json')\n        self.report_extraction(video_id)\n        info = json.loads(json_info)\n        player_info = info['videoJsonPlayer']\n\n        info_dict = {\n            'id': player_info['VID'],\n            'title': player_info['VTI'],\n            'description': player_info.get('VDE'),\n            'upload_date': unified_strdate(player_info.get('VDA', '').split(' ')[0]),\n            'thumbnail': player_info.get('programImage') or player_info.get('VTU', {}).get('IUR'),\n        }\n\n        all_formats = player_info['VSR'].values()\n        # Some formats use the m3u8 protocol\n        all_formats = list(filter(lambda f: f.get('videoFormat') != 'M3U8', all_formats))\n        def _match_lang(f):\n            if f.get('versionCode') is None:\n                return True\n            # Return true if that format is in the language of the url\n            if lang == 'fr':\n                l = 'F'\n            elif lang == 'de':\n                l = 'A'\n            regexes = [r'VO?%s' % l, r'VO?.-ST%s' % l]\n            return any(re.match(r, f['versionCode']) for r in regexes)\n        # Some formats may not be in the same language as the url\n        formats = filter(_match_lang, all_formats)\n        formats = list(formats) # in python3 filter returns an iterator\n        if not formats:\n            # Some videos are only available in the 'Originalversion'\n            # they aren't tagged as being in French or German\n            if all(f['versionCode'] == 'VO' for f in all_formats):\n                formats = all_formats\n            else:\n                raise ExtractorError(u'The formats list is empty')\n\n        if re.match(r'[A-Z]Q', formats[0]['quality']) is not None:\n            def sort_key(f):\n                return ['HQ', 'MQ', 'EQ', 'SQ'].index(f['quality'])\n        else:\n            def sort_key(f):\n                return (\n                    # Sort first by quality\n                    int(f.get('height',-1)),\n                    int(f.get('bitrate',-1)),\n                    # The original version with subtitles has lower relevance\n                    re.match(r'VO-ST(F|A)', f.get('versionCode', '')) is None,\n                    # The version with sourds/mal subtitles has also lower relevance\n                    re.match(r'VO?(F|A)-STM\\1', f.get('versionCode', '')) is None,\n                )\n        formats = sorted(formats, key=sort_key)\n        def _format(format_info):\n            quality = ''\n            height = format_info.get('height')\n            if height is not None:\n                quality = compat_str(height)\n            bitrate = format_info.get('bitrate')\n            if bitrate is not None:\n                quality += '-%d' % bitrate\n            if format_info.get('versionCode') is not None:\n                format_id = '%s-%s' % (quality, format_info['versionCode'])\n            else:\n                format_id = quality\n            info = {\n                'format_id': format_id,\n                'format_note': format_info.get('versionLibelle'),\n                'width': format_info.get('width'),\n                'height': height,\n            }\n            if format_info['mediaType'] == 'rtmp':\n                info['url'] = format_info['streamer']\n                info['play_path'] = 'mp4:' + format_info['url']\n                info['ext'] = 'flv'\n            else:\n                info['url'] = format_info['url']\n                info['ext'] = determine_ext(info['url'])\n            return info\n        info_dict['formats'] = [_format(f) for f in formats]\n\n        return info_dict",
        "begin_line": 150,
        "end_line": 231,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTVFutureIE._real_extract#260",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTVFutureIE",
        "signature": "youtube_dl.extractor.arte.ArteTVFutureIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        anchor_id, lang = self._extract_url_info(url)\n        webpage = self._download_webpage(url, anchor_id)\n        row = get_element_by_id(anchor_id, webpage)\n        return self._extract_from_webpage(row, anchor_id, lang)",
        "begin_line": 260,
        "end_line": 264,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.arte.ArteTVDDCIE._real_extract#271",
        "src_path": "youtube_dl/extractor/arte.py",
        "class_name": "youtube_dl.extractor.arte.ArteTVDDCIE",
        "signature": "youtube_dl.extractor.arte.ArteTVDDCIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id, lang = self._extract_url_info(url)\n        if lang == 'folge':\n            lang = 'de'\n        elif lang == 'emission':\n            lang = 'fr'\n        webpage = self._download_webpage(url, video_id)\n        scriptElement = get_element_by_attribute('class', 'visu_video_block', webpage)\n        script_url = self._html_search_regex(r'src=\"(.*?)\"', scriptElement, 'script url')\n        javascriptPlayerGenerator = self._download_webpage(script_url, video_id, 'Download javascript player generator')\n        json_url = self._search_regex(r\"json_url=(.*)&rendering_place.*\", javascriptPlayerGenerator, 'json url')\n        return self._extract_from_json_url(json_url, video_id, lang)",
        "begin_line": 271,
        "end_line": 282,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.funnyordie.FunnyOrDieIE._real_extract#23",
        "src_path": "youtube_dl/extractor/funnyordie.py",
        "class_name": "youtube_dl.extractor.funnyordie.FunnyOrDieIE",
        "signature": "youtube_dl.extractor.funnyordie.FunnyOrDieIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = self._search_regex(\n            [r'type=\"video/mp4\" src=\"(.*?)\"', r'src=\"([^>]*?)\" type=\\'video/mp4\\''],\n            webpage, 'video URL', flags=re.DOTALL)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'ext': 'mp4',\n            'title': self._og_search_title(webpage),\n            'description': self._og_search_description(webpage),\n        }",
        "begin_line": 23,
        "end_line": 39,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.ro220.Ro220IE._real_extract#25",
        "src_path": "youtube_dl/extractor/ro220.py",
        "class_name": "youtube_dl.extractor.ro220.Ro220IE",
        "signature": "youtube_dl.extractor.ro220.Ro220IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('video_id')\n\n        webpage = self._download_webpage(url, video_id)\n        flashVars_str = self._search_regex(\n            r'<param name=\"flashVars\" value=\"([^\"]+)\"',\n            webpage, 'flashVars')\n        flashVars = compat_parse_qs(flashVars_str)\n\n        return {\n            '_type': 'video',\n            'id': video_id,\n            'ext': 'mp4',\n            'url': flashVars['videoURL'][0],\n            'title': flashVars['title'][0],\n            'description': clean_html(flashVars['desc'][0]),\n            'thumbnail': flashVars['preview'][0],\n        }",
        "begin_line": 25,
        "end_line": 43,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.academicearth.AcademicEarthCourseIE._real_extract#11",
        "src_path": "youtube_dl/extractor/academicearth.py",
        "class_name": "youtube_dl.extractor.academicearth.AcademicEarthCourseIE",
        "signature": "youtube_dl.extractor.academicearth.AcademicEarthCourseIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        playlist_id = m.group('id')\n\n        webpage = self._download_webpage(url, playlist_id)\n        title = self._html_search_regex(\n            r'<h1 class=\"playlist-name\"[^>]*?>(.*?)</h1>', webpage, u'title')\n        description = self._html_search_regex(\n            r'<p class=\"excerpt\"[^>]*?>(.*?)</p>',\n            webpage, u'description', fatal=False)\n        urls = re.findall(\n            r'<li class=\"lecture-preview\">\\s*?<a target=\"_blank\" href=\"([^\"]+)\">',\n            webpage)\n        entries = [self.url_result(u) for u in urls]\n\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'title': title,\n            'description': description,\n            'entries': entries,\n        }",
        "begin_line": 11,
        "end_line": 32,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.appletrailers.AppleTrailersIE._real_extract#63",
        "src_path": "youtube_dl/extractor/appletrailers.py",
        "class_name": "youtube_dl.extractor.appletrailers.AppleTrailersIE",
        "signature": "youtube_dl.extractor.appletrailers.AppleTrailersIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        movie = mobj.group('movie')\n        uploader_id = mobj.group('company')\n\n        playlist_url = compat_urlparse.urljoin(url, u'includes/playlists/itunes.inc')\n        def fix_html(s):\n            s = re.sub(r'(?s)<script[^<]*?>.*?</script>', u'', s)\n            s = re.sub(r'<img ([^<]*?)>', r'<img \\1/>', s)\n            # The ' in the onClick attributes are not escaped, it couldn't be parsed\n            # like: http://trailers.apple.com/trailers/wb/gravity/\n            def _clean_json(m):\n                return u'iTunes.playURL(%s);' % m.group(1).replace('\\'', '&#39;')\n            s = re.sub(self._JSON_RE, _clean_json, s)\n            s = u'<html>' + s + u'</html>'\n            return s\n        doc = self._download_xml(playlist_url, movie, transform_source=fix_html)\n\n        playlist = []\n        for li in doc.findall('./div/ul/li'):\n            on_click = li.find('.//a').attrib['onClick']\n            trailer_info_json = self._search_regex(self._JSON_RE,\n                on_click, u'trailer info')\n            trailer_info = json.loads(trailer_info_json)\n            title = trailer_info['title']\n            video_id = movie + '-' + re.sub(r'[^a-zA-Z0-9]', '', title).lower()\n            thumbnail = li.find('.//img').attrib['src']\n            upload_date = trailer_info['posted'].replace('-', '')\n\n            runtime = trailer_info['runtime']\n            m = re.search(r'(?P<minutes>[0-9]+):(?P<seconds>[0-9]{1,2})', runtime)\n            duration = None\n            if m:\n                duration = 60 * int(m.group('minutes')) + int(m.group('seconds'))\n\n            first_url = trailer_info['url']\n            trailer_id = first_url.split('/')[-1].rpartition('_')[0].lower()\n            settings_json_url = compat_urlparse.urljoin(url, 'includes/settings/%s.json' % trailer_id)\n            settings_json = self._download_webpage(settings_json_url, trailer_id, u'Downloading settings json')\n            settings = json.loads(settings_json)\n\n            formats = []\n            for format in settings['metadata']['sizes']:\n                # The src is a file pointing to the real video file\n                format_url = re.sub(r'_(\\d*p.mov)', r'_h\\1', format['src'])\n                formats.append({\n                    'url': format_url,\n                    'ext': determine_ext(format_url),\n                    'format': format['type'],\n                    'width': format['width'],\n                    'height': int(format['height']),\n                })\n\n            self._sort_formats(formats)\n\n            playlist.append({\n                '_type': 'video',\n                'id': video_id,\n                'title': title,\n                'formats': formats,\n                'title': title,\n                'duration': duration,\n                'thumbnail': thumbnail,\n                'upload_date': upload_date,\n                'uploader_id': uploader_id,\n                'user_agent': 'QuickTime compatible (youtube-dl)',\n            })\n\n        return {\n            '_type': 'playlist',\n            'id': movie,\n            'entries': playlist,\n        }",
        "begin_line": 63,
        "end_line": 135,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.khanacademy.KhanAcademyIE._real_extract#28",
        "src_path": "youtube_dl/extractor/khanacademy.py",
        "class_name": "youtube_dl.extractor.khanacademy.KhanAcademyIE",
        "signature": "youtube_dl.extractor.khanacademy.KhanAcademyIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('id')\n\n        if m.group('key') == 'video':\n            data = self._download_json(\n                'http://api.khanacademy.org/api/v1/videos/' + video_id,\n                video_id, 'Downloading video info')\n\n            upload_date = unified_strdate(data['date_added'])\n            uploader = ', '.join(data['author_names'])\n            return {\n                '_type': 'url_transparent',\n                'url': data['url'],\n                'id': video_id,\n                'title': data['title'],\n                'thumbnail': data['image_url'],\n                'duration': data['duration'],\n                'description': data['description'],\n                'uploader': uploader,\n                'upload_date': upload_date,\n            }\n        else:\n            # topic\n            data = self._download_json(\n                'http://api.khanacademy.org/api/v1/topic/' + video_id,\n                video_id, 'Downloading topic info')\n\n            entries = [\n                {\n                    '_type': 'url',\n                    'url': c['url'],\n                    'id': c['id'],\n                    'title': c['title'],\n                }\n                for c in data['children'] if c['kind'] in ('Video', 'Topic')]\n\n            return {\n                '_type': 'playlist',\n                'id': video_id,\n                'title': data['title'],\n                'description': data['description'],\n                'entries': entries,\n            }",
        "begin_line": 28,
        "end_line": 71,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.postprocessor.common.PostProcessor.__init__#23",
        "src_path": "youtube_dl/postprocessor/common.py",
        "class_name": "youtube_dl.postprocessor.common.PostProcessor",
        "signature": "youtube_dl.postprocessor.common.PostProcessor.__init__(self, downloader=None)",
        "snippet": "    def __init__(self, downloader=None):\n        self._downloader = downloader",
        "begin_line": 23,
        "end_line": 24,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.postprocessor.common.PostProcessor.set_downloader#26",
        "src_path": "youtube_dl/postprocessor/common.py",
        "class_name": "youtube_dl.postprocessor.common.PostProcessor",
        "signature": "youtube_dl.postprocessor.common.PostProcessor.set_downloader(self, downloader)",
        "snippet": "    def set_downloader(self, downloader):\n        \"\"\"Sets the downloader for this PP.\"\"\"\n        self._downloader = downloader",
        "begin_line": 26,
        "end_line": 28,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.postprocessor.common.PostProcessor.run#30",
        "src_path": "youtube_dl/postprocessor/common.py",
        "class_name": "youtube_dl.postprocessor.common.PostProcessor",
        "signature": "youtube_dl.postprocessor.common.PostProcessor.run(self, information)",
        "snippet": "    def run(self, information):\n        \"\"\"Run the PostProcessor.\n\n        The \"information\" argument is a dictionary like the ones\n        composed by InfoExtractors. The only difference is that this\n        one has an extra field called \"filepath\" that points to the\n        downloaded file.\n\n        This method returns a tuple, the first element of which describes\n        whether the original file should be kept (i.e. not deleted - None for\n        no preference), and the second of which is the updated information.\n\n        In addition, this method may raise a PostProcessingError\n        exception if post processing fails.\n        \"\"\"\n        return None, information  # by default, keep file and do nothing",
        "begin_line": 30,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.francetv.FranceTVBaseInfoExtractor._extract_video#15",
        "src_path": "youtube_dl/extractor/francetv.py",
        "class_name": "youtube_dl.extractor.francetv.FranceTVBaseInfoExtractor",
        "signature": "youtube_dl.extractor.francetv.FranceTVBaseInfoExtractor._extract_video(self, video_id)",
        "snippet": "    def _extract_video(self, video_id):\n        info = self._download_xml(\n            'http://www.francetvinfo.fr/appftv/webservices/video/'\n            'getInfosOeuvre.php?id-diffusion='\n            + video_id, video_id, 'Downloading XML config')\n\n        manifest_url = info.find('videos/video/url').text\n        video_url = manifest_url.replace('manifest.f4m', 'index_2_av.m3u8')\n        video_url = video_url.replace('/z/', '/i/')\n        thumbnail_path = info.find('image').text\n\n        return {'id': video_id,\n                'ext': 'flv' if video_url.startswith('rtmp') else 'mp4',\n                'url': video_url,\n                'title': info.find('titre').text,\n                'thumbnail': compat_urlparse.urljoin('http://pluzz.francetv.fr', thumbnail_path),\n                'description': info.find('synopsis').text,\n                }",
        "begin_line": 15,
        "end_line": 32,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.francetv.PluzzIE._real_extract#41",
        "src_path": "youtube_dl/extractor/francetv.py",
        "class_name": "youtube_dl.extractor.francetv.PluzzIE",
        "signature": "youtube_dl.extractor.francetv.PluzzIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        title = re.match(self._VALID_URL, url).group(1)\n        webpage = self._download_webpage(url, title)\n        video_id = self._search_regex(\n            r'data-diffusion=\"(\\d+)\"', webpage, 'ID')\n        return self._extract_video(video_id)",
        "begin_line": 41,
        "end_line": 46,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.francetv.FranceTvInfoIE._real_extract#64",
        "src_path": "youtube_dl/extractor/francetv.py",
        "class_name": "youtube_dl.extractor.francetv.FranceTvInfoIE",
        "signature": "youtube_dl.extractor.francetv.FranceTvInfoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        page_title = mobj.group('title')\n        webpage = self._download_webpage(url, page_title)\n        video_id = self._search_regex(r'id-video=(\\d+?)[@\"]', webpage, 'video id')\n        return self._extract_video(video_id)",
        "begin_line": 64,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.francetv.FranceTVIE._real_extract#154",
        "src_path": "youtube_dl/extractor/francetv.py",
        "class_name": "youtube_dl.extractor.francetv.FranceTVIE",
        "signature": "youtube_dl.extractor.francetv.FranceTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        if mobj.group('key'):\n            webpage = self._download_webpage(url, mobj.group('key'))\n            id_res = [\n                (r'''(?x)<div\\s+class=\"video-player\">\\s*\n                    <a\\s+href=\"http://videos.francetv.fr/video/([0-9]+)\"\\s+\n                    class=\"francetv-video-player\">'''),\n                (r'<a id=\"player_direct\" href=\"http://info\\.francetelevisions'\n                 '\\.fr/\\?id-video=([^\"/&]+)'),\n                (r'<a class=\"video\" id=\"ftv_player_(.+?)\"'),\n            ]\n            video_id = self._html_search_regex(id_res, webpage, 'video ID')\n        else:\n            video_id = mobj.group('id')\n        return self._extract_video(video_id)",
        "begin_line": 154,
        "end_line": 169,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.francetv.GenerationQuoiIE._real_extract#190",
        "src_path": "youtube_dl/extractor/francetv.py",
        "class_name": "youtube_dl.extractor.francetv.GenerationQuoiIE",
        "signature": "youtube_dl.extractor.francetv.GenerationQuoiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        name = mobj.group('name')\n        info_url = compat_urlparse.urljoin(url, '/medias/video/%s.json' % name)\n        info_json = self._download_webpage(info_url, name)\n        info = json.loads(info_json)\n        return self.url_result('http://www.dailymotion.com/video/%s' % info['id'],\n            ie='Dailymotion')",
        "begin_line": 190,
        "end_line": 197,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.francetv.CultureboxIE._real_extract#218",
        "src_path": "youtube_dl/extractor/francetv.py",
        "class_name": "youtube_dl.extractor.francetv.CultureboxIE",
        "signature": "youtube_dl.extractor.francetv.CultureboxIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        name = mobj.group('name')\n        webpage = self._download_webpage(url, name)\n        video_id = self._search_regex(r'\"http://videos\\.francetv\\.fr/video/(.*?)\"', webpage, 'video id')\n        return self._extract_video(video_id)",
        "begin_line": 218,
        "end_line": 223,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.space.SpaceIE._real_extract#24",
        "src_path": "youtube_dl/extractor/space.py",
        "class_name": "youtube_dl.extractor.space.SpaceIE",
        "signature": "youtube_dl.extractor.space.SpaceIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        title = mobj.group('title')\n        webpage = self._download_webpage(url, title)\n        try:\n            # Some videos require the playerKey field, which isn't define in\n            # the BrightcoveExperience object\n            brightcove_url = self._og_search_video_url(webpage)\n        except RegexNotFoundError:\n            # Other videos works fine with the info from the object\n            brightcove_url = BrightcoveIE._extract_brightcove_url(webpage)\n        if brightcove_url is None:\n            raise ExtractorError(u'The webpage does not contain a video', expected=True)\n        return self.url_result(brightcove_url, BrightcoveIE.ie_key())",
        "begin_line": 24,
        "end_line": 37,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.c56.C56IE._real_extract#22",
        "src_path": "youtube_dl/extractor/c56.py",
        "class_name": "youtube_dl.extractor.c56.C56IE",
        "signature": "youtube_dl.extractor.c56.C56IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url, flags=re.VERBOSE)\n        text_id = mobj.group('textid')\n        info_page = self._download_webpage('http://vxml.56.com/json/%s/' % text_id,\n                                           text_id, 'Downloading video info')\n        info = json.loads(info_page)['info']\n        formats = [{\n            'format_id': f['type'],\n            'filesize': int(f['filesize']),\n            'url': f['url']\n        } for f in info['rfiles']]\n        self._sort_formats(formats)\n\n        return {\n            'id': info['vid'],\n            'title': info['Subject'],\n            'formats': formats,\n            'thumbnail': info.get('bimg') or info.get('img'),\n        }",
        "begin_line": 22,
        "end_line": 40,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.tinypic.TinyPicIE._real_extract#24",
        "src_path": "youtube_dl/extractor/tinypic.py",
        "class_name": "youtube_dl.extractor.tinypic.TinyPicIE",
        "signature": "youtube_dl.extractor.tinypic.TinyPicIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id, 'Downloading page')\n        \n        mobj = re.search(r'(?m)fo\\.addVariable\\(\"file\",\\s\"(?P<fileid>[\\da-z]+)\"\\);\\n'\n            '\\s+fo\\.addVariable\\(\"s\",\\s\"(?P<serverid>\\d+)\"\\);', webpage)\n        if mobj is None:\n            raise ExtractorError('Video %s does not exist' % video_id, expected=True)\n\n        file_id = mobj.group('fileid')\n        server_id = mobj.group('serverid')\n\n        KEYWORDS_SUFFIX = ', Video, images, photos, videos, myspace, ebay, video hosting, photo hosting'\n        keywords = self._html_search_meta('keywords', webpage, 'title')\n        title = keywords[:-len(KEYWORDS_SUFFIX)] if keywords.endswith(KEYWORDS_SUFFIX) else ''\n\n        video_url = 'http://v%s.tinypic.com/%s.flv' % (server_id, file_id)\n        thumbnail = 'http://v%s.tinypic.com/%s_th.jpg' % (server_id, file_id)\n\n        return {\n            'id': file_id,\n            'url': video_url,\n            'thumbnail': thumbnail,\n            'title': title\n        }",
        "begin_line": 24,
        "end_line": 50,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.pornhub.PornHubIE._real_extract#30",
        "src_path": "youtube_dl/extractor/pornhub.py",
        "class_name": "youtube_dl.extractor.pornhub.PornHubIE",
        "signature": "youtube_dl.extractor.pornhub.PornHubIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n        url = 'http://www.' + mobj.group('url')\n\n        req = compat_urllib_request.Request(url)\n        req.add_header('Cookie', 'age_verified=1')\n        webpage = self._download_webpage(req, video_id)\n\n        video_title = self._html_search_regex(r'<h1 [^>]+>([^<]+)', webpage, 'title')\n        video_uploader = self._html_search_regex(r'<b>From: </b>(?:\\s|<[^>]*>)*(.+?)<', webpage, 'uploader', fatal=False)\n        thumbnail = self._html_search_regex(r'\"image_url\":\"([^\"]+)', webpage, 'thumbnail', fatal=False)\n        if thumbnail:\n            thumbnail = compat_urllib_parse.unquote(thumbnail)\n\n        video_urls = list(map(compat_urllib_parse.unquote , re.findall(r'\"quality_[0-9]{3}p\":\"([^\"]+)', webpage)))\n        if webpage.find('\"encrypted\":true') != -1:\n            password = self._html_search_regex(r'\"video_title\":\"([^\"]+)', webpage, 'password').replace('+', ' ')\n            video_urls = list(map(lambda s: aes_decrypt_text(s, password, 32).decode('utf-8'), video_urls))\n\n        formats = []\n        for video_url in video_urls:\n            path = compat_urllib_parse_urlparse(video_url).path\n            extension = os.path.splitext(path)[1][1:]\n            format = path.split('/')[5].split('_')[:2]\n            format = \"-\".join(format)\n\n            m = re.match(r'^(?P<height>[0-9]+)P-(?P<tbr>[0-9]+)K$', format)\n            if m is None:\n                height = None\n                tbr = None\n            else:\n                height = int(m.group('height'))\n                tbr = int(m.group('tbr'))\n\n            formats.append({\n                'url': video_url,\n                'ext': extension,\n                'format': format,\n                'format_id': format,\n                'tbr': tbr,\n                'height': height,\n            })\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'uploader': video_uploader,\n            'title': video_title,\n            'thumbnail': thumbnail,\n            'formats': formats,\n            'age_limit': 18,\n        }",
        "begin_line": 30,
        "end_line": 82,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudIE.suitable#97",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return re.match(cls._VALID_URL, url, flags=re.VERBOSE) is not None",
        "begin_line": 97,
        "end_line": 98,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0001584786053882726,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudIE.report_resolve#100",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudIE.report_resolve(self, video_id)",
        "snippet": "    def report_resolve(self, video_id):\n        \"\"\"Report information extraction.\"\"\"\n        self.to_screen(u'%s: Resolving id' % video_id)",
        "begin_line": 100,
        "end_line": 102,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudIE._extract_info_dict#108",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudIE._extract_info_dict(self, info, full_title=None, quiet=False, secret_token=None)",
        "snippet": "    def _extract_info_dict(self, info, full_title=None, quiet=False, secret_token=None):\n        track_id = compat_str(info['id'])\n        name = full_title or track_id\n        if quiet:\n            self.report_extraction(name)\n\n        thumbnail = info['artwork_url']\n        if thumbnail is not None:\n            thumbnail = thumbnail.replace('-large', '-t500x500')\n        ext = 'mp3'\n        result = {\n            'id': track_id,\n            'uploader': info['user']['username'],\n            'upload_date': unified_strdate(info['created_at']),\n            'title': info['title'],\n            'description': info['description'],\n            'thumbnail': thumbnail,\n        }\n        if info.get('downloadable', False):\n            # We can build a direct link to the song\n            format_url = (\n                'https://api.soundcloud.com/tracks/{0}/download?client_id={1}'.format(\n                    track_id, self._CLIENT_ID))\n            result['formats'] = [{\n                'format_id': 'download',\n                'ext': info.get('original_format', 'mp3'),\n                'url': format_url,\n                'vcodec': 'none',\n            }]\n        else:\n            # We have to retrieve the url\n            streams_url = ('http://api.soundcloud.com/i1/tracks/{0}/streams?'\n                'client_id={1}&secret_token={2}'.format(track_id, self._IPHONE_CLIENT_ID, secret_token))\n            stream_json = self._download_webpage(\n                streams_url,\n                track_id, 'Downloading track url')\n\n            formats = []\n            format_dict = json.loads(stream_json)\n            for key, stream_url in format_dict.items():\n                if key.startswith(u'http'):\n                    formats.append({\n                        'format_id': key,\n                        'ext': ext,\n                        'url': stream_url,\n                        'vcodec': 'none',\n                    })\n                elif key.startswith(u'rtmp'):\n                    # The url doesn't have an rtmp app, we have to extract the playpath\n                    url, path = stream_url.split('mp3:', 1)\n                    formats.append({\n                        'format_id': key,\n                        'url': url,\n                        'play_path': 'mp3:' + path,\n                        'ext': ext,\n                        'vcodec': 'none',\n                    })\n\n            if not formats:\n                # We fallback to the stream_url in the original info, this\n                # cannot be always used, sometimes it can give an HTTP 404 error\n                formats.append({\n                    'format_id': 'fallback',\n                    'url': info['stream_url'] + '?client_id=' + self._CLIENT_ID,\n                    'ext': ext,\n                    'vcodec': 'none',\n                })\n\n            for f in formats:\n                if f['format_id'].startswith('http'):\n                    f['protocol'] = 'http'\n                if f['format_id'].startswith('rtmp'):\n                    f['protocol'] = 'rtmp'\n\n            self._sort_formats(formats)\n            result['formats'] = formats\n\n        return result",
        "begin_line": 108,
        "end_line": 185,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudIE._real_extract#187",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url, flags=re.VERBOSE)\n        if mobj is None:\n            raise ExtractorError(u'Invalid URL: %s' % url)\n\n        track_id = mobj.group('track_id')\n        token = None\n        if track_id is not None:\n            info_json_url = 'http://api.soundcloud.com/tracks/' + track_id + '.json?client_id=' + self._CLIENT_ID\n            full_title = track_id\n        elif mobj.group('player'):\n            query = compat_urlparse.parse_qs(compat_urlparse.urlparse(url).query)\n            return self.url_result(query['url'][0], ie='Soundcloud')\n        else:\n            # extract uploader (which is in the url)\n            uploader = mobj.group('uploader')\n            # extract simple title (uploader + slug of song title)\n            slug_title =  mobj.group('title')\n            token = mobj.group('token')\n            full_title = resolve_title = '%s/%s' % (uploader, slug_title)\n            if token:\n                resolve_title += '/%s' % token\n    \n            self.report_resolve(full_title)\n    \n            url = 'http://soundcloud.com/%s' % resolve_title\n            info_json_url = self._resolv_url(url)\n        info_json = self._download_webpage(info_json_url, full_title, 'Downloading info JSON')\n\n        info = json.loads(info_json)\n        return self._extract_info_dict(info, full_title, secret_token=token)",
        "begin_line": 187,
        "end_line": 217,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudSetIE._real_extract#225",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudSetIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudSetIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        if mobj is None:\n            raise ExtractorError(u'Invalid URL: %s' % url)\n\n        # extract uploader (which is in the url)\n        uploader = mobj.group(1)\n        # extract simple title (uploader + slug of song title)\n        slug_title =  mobj.group(2)\n        full_title = '%s/sets/%s' % (uploader, slug_title)\n\n        self.report_resolve(full_title)\n\n        url = 'http://soundcloud.com/%s/sets/%s' % (uploader, slug_title)\n        resolv_url = self._resolv_url(url)\n        info_json = self._download_webpage(resolv_url, full_title)\n\n        info = json.loads(info_json)\n        if 'errors' in info:\n            for err in info['errors']:\n                self._downloader.report_error(u'unable to download video webpage: %s' % compat_str(err['error_message']))\n            return\n\n        self.report_extraction(full_title)\n        return {'_type': 'playlist',\n                'entries': [self._extract_info_dict(track) for track in info['tracks']],\n                'id': info['id'],\n                'title': info['title'],\n                }",
        "begin_line": 225,
        "end_line": 253,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.soundcloud.SoundcloudUserIE._real_extract#263",
        "src_path": "youtube_dl/extractor/soundcloud.py",
        "class_name": "youtube_dl.extractor.soundcloud.SoundcloudUserIE",
        "signature": "youtube_dl.extractor.soundcloud.SoundcloudUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        uploader = mobj.group('user')\n\n        url = 'http://soundcloud.com/%s/' % uploader\n        resolv_url = self._resolv_url(url)\n        user_json = self._download_webpage(resolv_url, uploader,\n            'Downloading user info')\n        user = json.loads(user_json)\n\n        tracks = []\n        for i in itertools.count():\n            data = compat_urllib_parse.urlencode({'offset': i*50,\n                                                  'client_id': self._CLIENT_ID,\n                                                  })\n            tracks_url = 'http://api.soundcloud.com/users/%s/tracks.json?' % user['id'] + data\n            response = self._download_webpage(tracks_url, uploader, \n                'Downloading tracks page %s' % (i+1))\n            new_tracks = json.loads(response)\n            tracks.extend(self._extract_info_dict(track, quiet=True) for track in new_tracks)\n            if len(new_tracks) < 50:\n                break\n\n        return {\n            '_type': 'playlist',\n            'id': compat_str(user['id']),\n            'title': user['username'],\n            'entries': tracks,\n        }",
        "begin_line": 263,
        "end_line": 291,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.roxwel.RoxwelIE._real_extract#23",
        "src_path": "youtube_dl/extractor/roxwel.py",
        "class_name": "youtube_dl.extractor.roxwel.RoxwelIE",
        "signature": "youtube_dl.extractor.roxwel.RoxwelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        filename = mobj.group('filename')\n        info_url = 'http://www.roxwel.com/api/videos/%s' % filename\n        info_page = self._download_webpage(info_url, filename,\n                                           u'Downloading video info')\n\n        self.report_extraction(filename)\n        info = json.loads(info_page)\n        rtmp_rates = sorted([int(r.replace('flv_', '')) for r in info['media_rates'] if r.startswith('flv_')])\n        best_rate = rtmp_rates[-1]\n        url_page_url = 'http://roxwel.com/pl_one_time.php?filename=%s&quality=%s' % (filename, best_rate)\n        rtmp_url = self._download_webpage(url_page_url, filename, u'Downloading video url')\n        ext = determine_ext(rtmp_url)\n        if ext == 'f4v':\n            rtmp_url = rtmp_url.replace(filename, 'mp4:%s' % filename)\n\n        return {'id': filename,\n                'title': info['title'],\n                'url': rtmp_url,\n                'ext': 'flv',\n                'description': info['description'],\n                'thumbnail': info.get('player_image_url') or info.get('image_url_large'),\n                'uploader': info['artist'],\n                'uploader_id': info['artistname'],\n                'upload_date': unified_strdate(info['dbdate']),\n                }",
        "begin_line": 23,
        "end_line": 49,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.xvideos.XVideosIE._real_extract#23",
        "src_path": "youtube_dl/extractor/xvideos.py",
        "class_name": "youtube_dl.extractor.xvideos.XVideosIE",
        "signature": "youtube_dl.extractor.xvideos.XVideosIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group(1)\n\n        webpage = self._download_webpage(url, video_id)\n\n        self.report_extraction(video_id)\n\n        # Extract video URL\n        video_url = compat_urllib_parse.unquote(\n            self._search_regex(r'flv_url=(.+?)&', webpage, 'video URL'))\n\n        # Extract title\n        video_title = self._html_search_regex(\n            r'<title>(.*?)\\s+-\\s+XVID', webpage, 'title')\n\n        # Extract video thumbnail\n        video_thumbnail = self._search_regex(\n            r'url_bigthumb=(.+?)&amp', webpage, 'thumbnail', fatal=False)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'uploader': None,\n            'upload_date': None,\n            'title': video_title,\n            'ext': 'flv',\n            'thumbnail': video_thumbnail,\n            'description': None,\n            'age_limit': 18,\n        }",
        "begin_line": 23,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.mdr.MDRIE._real_extract#14",
        "src_path": "youtube_dl/extractor/mdr.py",
        "class_name": "youtube_dl.extractor.mdr.MDRIE",
        "signature": "youtube_dl.extractor.mdr.MDRIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('video_id')\n        domain = m.group('domain')\n\n        # determine title and media streams from webpage\n        html = self._download_webpage(url, video_id)\n\n        title = self._html_search_regex(r'<h2>(.*?)</h2>', html, u'title')\n        xmlurl = self._search_regex(\n            r'(/mediathek/(?:.+)/(?:video|audio)[0-9]+-avCustom.xml)', html, u'XML URL')\n\n        doc = self._download_xml(domain + xmlurl, video_id)\n        formats = []\n        for a in doc.findall('./assets/asset'):\n            url_el = a.find('.//progressiveDownloadUrl')\n            if url_el is None:\n                continue\n            abr = int(a.find('bitrateAudio').text) // 1000\n            media_type = a.find('mediaType').text\n            format = {\n                'abr': abr,\n                'filesize': int(a.find('fileSize').text),\n                'url': url_el.text,\n            }\n\n            vbr_el = a.find('bitrateVideo')\n            if vbr_el is None:\n                format.update({\n                    'vcodec': 'none',\n                    'format_id': u'%s-%d' % (media_type, abr),\n                })\n            else:\n                vbr = int(vbr_el.text) // 1000\n                format.update({\n                    'vbr': vbr,\n                    'width': int(a.find('frameWidth').text),\n                    'height': int(a.find('frameHeight').text),\n                    'format_id': u'%s-%d' % (media_type, vbr),\n                })\n            formats.append(format)\n        if not formats:\n            raise ExtractorError(u'Could not find any valid formats')\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n        }",
        "begin_line": 14,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.tvigle.TvigleIE._real_extract#44",
        "src_path": "youtube_dl/extractor/tvigle.py",
        "class_name": "youtube_dl.extractor.tvigle.TvigleIE",
        "signature": "youtube_dl.extractor.tvigle.TvigleIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        video_data = self._download_xml(\n            'http://www.tvigle.ru/xml/single.php?obj=%s' % video_id, video_id, 'Downloading video XML')\n\n        video = video_data.find('./video')\n\n        title = video.get('name')\n        description = video.get('anons')\n        if description:\n            description = clean_html(description)\n        thumbnail = video_data.get('img')\n        upload_date = unified_strdate(video.get('date'))\n        like_count = int_or_none(video.get('vtp'))\n\n        formats = []\n        for num, (format_id, format_note) in enumerate([['low_file', 'SQ'], ['file', 'HQ'], ['hd', 'HD 720']]):\n            video_url = video.get(format_id)\n            if not video_url:\n                continue\n            formats.append({\n                'url': video_url,\n                'format_id': format_id,\n                'format_note': format_note,\n                'quality': num,\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n            'like_count': like_count,\n            'age_limit': 18,\n            'formats': formats,\n        }",
        "begin_line": 44,
        "end_line": 84,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.gamespot.GameSpotIE._real_extract#27",
        "src_path": "youtube_dl/extractor/gamespot.py",
        "class_name": "youtube_dl.extractor.gamespot.GameSpotIE",
        "signature": "youtube_dl.extractor.gamespot.GameSpotIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        page_id = mobj.group('page_id')\n        webpage = self._download_webpage(url, page_id)\n        data_video_json = self._search_regex(r'data-video=[\"\\'](.*?)[\"\\']', webpage, 'data video')\n        data_video = json.loads(unescapeHTML(data_video_json))\n\n        # Transform the manifest url to a link to the mp4 files\n        # they are used in mobile devices.\n        f4m_url = data_video['videoStreams']['f4m_stream']\n        f4m_path = compat_urlparse.urlparse(f4m_url).path\n        QUALITIES_RE = r'((,\\d+)+,?)'\n        qualities = self._search_regex(QUALITIES_RE, f4m_path, 'qualities').strip(',').split(',')\n        http_path = f4m_path[1:].split('/', 1)[1]\n        http_template = re.sub(QUALITIES_RE, r'%s', http_path)\n        http_template = http_template.replace('.csmil/manifest.f4m', '')\n        http_template = compat_urlparse.urljoin('http://video.gamespotcdn.com/', http_template)\n        formats = []\n        for q in qualities:\n            formats.append({\n                'url': http_template % q,\n                'ext': 'mp4',\n                'format_id': q,\n            })\n\n        return {\n            'id': data_video['guid'],\n            'title': compat_urllib_parse.unquote(data_video['title']),\n            'formats': formats,\n            'description': get_meta_content('description', webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n        }",
        "begin_line": 27,
        "end_line": 58,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.sohu.SohuIE._real_extract#23",
        "src_path": "youtube_dl/extractor/sohu.py",
        "class_name": "youtube_dl.extractor.sohu.SohuIE",
        "signature": "youtube_dl.extractor.sohu.SohuIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n\n        def _fetch_data(vid_id, mytv=False):\n            if mytv:\n                base_data_url = 'http://my.tv.sohu.com/play/videonew.do?vid='\n            else:\n                base_data_url = u'http://hot.vrs.sohu.com/vrs_flash.action?vid='\n            data_url = base_data_url + str(vid_id)\n            data_json = self._download_webpage(\n                data_url, video_id,\n                note=u'Downloading JSON data for ' + str(vid_id))\n            return json.loads(data_json)\n\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        mytv = mobj.group('mytv') is not None\n\n        webpage = self._download_webpage(url, video_id)\n        raw_title = self._html_search_regex(r'(?s)<title>(.+?)</title>',\n                                            webpage, u'video title')\n        title = raw_title.partition('-')[0].strip()\n\n        vid = self._html_search_regex(r'var vid ?= ?[\"\\'](\\d+)[\"\\']', webpage,\n                                      u'video path')\n        data = _fetch_data(vid, mytv)\n\n        QUALITIES = ('ori', 'super', 'high', 'nor')\n        vid_ids = [data['data'][q + 'Vid']\n                   for q in QUALITIES\n                   if data['data'][q + 'Vid'] != 0]\n        if not vid_ids:\n            raise ExtractorError(u'No formats available for this video')\n\n        # For now, we just pick the highest available quality\n        vid_id = vid_ids[-1]\n\n        format_data = data if vid == vid_id else _fetch_data(vid_id, mytv)\n        part_count = format_data['data']['totalBlocks']\n        allot = format_data['allot']\n        prot = format_data['prot']\n        clipsURL = format_data['data']['clipsURL']\n        su = format_data['data']['su']\n\n        playlist = []\n        for i in range(part_count):\n            part_url = ('http://%s/?prot=%s&file=%s&new=%s' %\n                        (allot, prot, clipsURL[i], su[i]))\n            part_str = self._download_webpage(\n                part_url, video_id,\n                note=u'Downloading part %d of %d' % (i+1, part_count))\n\n            part_info = part_str.split('|')\n            video_url = '%s%s?key=%s' % (part_info[0], su[i], part_info[3])\n\n            video_info = {\n                'id': '%s_part%02d' % (video_id, i + 1),\n                'title': title,\n                'url': video_url,\n                'ext': 'mp4',\n            }\n            playlist.append(video_info)\n\n        if len(playlist) == 1:\n            info = playlist[0]\n            info['id'] = video_id\n        else:\n            info = {\n                '_type': 'playlist',\n                'entries': playlist,\n                'id': video_id,\n            }\n\n        return info",
        "begin_line": 23,
        "end_line": 95,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.ceskatelevize.CeskaTelevizeIE._real_extract#59",
        "src_path": "youtube_dl/extractor/ceskatelevize.py",
        "class_name": "youtube_dl.extractor.ceskatelevize.CeskaTelevizeIE",
        "signature": "youtube_dl.extractor.ceskatelevize.CeskaTelevizeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url = url.replace('/porady/', '/ivysilani/').replace('/video/', '')\n\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        NOT_AVAILABLE_STRING = 'This content is not available at your territory due to limited copyright.'\n        if '%s</p>' % NOT_AVAILABLE_STRING in webpage:\n            raise ExtractorError(NOT_AVAILABLE_STRING, expected=True)\n\n        typ = self._html_search_regex(r'getPlaylistUrl\\(\\[\\{\"type\":\"(.+?)\",\"id\":\".+?\"\\}\\],', webpage, 'type')\n        episode_id = self._html_search_regex(r'getPlaylistUrl\\(\\[\\{\"type\":\".+?\",\"id\":\"(.+?)\"\\}\\],', webpage, 'episode_id')\n\n        data = {\n            'playlist[0][type]': typ,\n            'playlist[0][id]': episode_id,\n            'requestUrl': compat_urllib_parse_urlparse(url).path,\n            'requestSource': 'iVysilani',\n        }\n\n        req = compat_urllib_request.Request('http://www.ceskatelevize.cz/ivysilani/ajax/get-playlist-url',\n                                            data=compat_urllib_parse.urlencode(data))\n\n        req.add_header('Content-type', 'application/x-www-form-urlencoded')\n        req.add_header('x-addr', '127.0.0.1')\n        req.add_header('X-Requested-With', 'XMLHttpRequest')\n        req.add_header('Referer', url)\n\n        playlistpage = self._download_json(req, video_id)\n\n        req = compat_urllib_request.Request(compat_urllib_parse.unquote(playlistpage['url']))\n        req.add_header('Referer', url)\n\n        playlist = self._download_xml(req, video_id)\n        \n        formats = []\n        for i in playlist.find('smilRoot/body'):\n            if 'AD' not in i.attrib['id']:\n                base_url = i.attrib['base']\n                parsedurl = compat_urllib_parse_urlparse(base_url)\n                duration = i.attrib['duration']\n\n                for video in i.findall('video'):\n                    if video.attrib['label'] != 'AD':\n                        format_id = video.attrib['label']\n                        play_path = video.attrib['src']\n                        vbr = int(video.attrib['system-bitrate'])\n\n                        formats.append({\n                            'format_id': format_id,\n                            'url': base_url,\n                            'vbr': vbr,\n                            'play_path': play_path,\n                            'app': parsedurl.path[1:] + '?' + parsedurl.query,\n                            'rtmp_live': True,\n                            'ext': 'flv',\n                        })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': episode_id,\n            'title': self._html_search_regex(r'<title>(.+?) \u2014 iVys\u00edl\u00e1n\u00ed \u2014 \u010cesk\u00e1 televize</title>', webpage, 'title'),\n            'duration': float(duration),\n            'formats': formats,\n        }",
        "begin_line": 59,
        "end_line": 126,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.instagram.InstagramIE._real_extract#22",
        "src_path": "youtube_dl/extractor/instagram.py",
        "class_name": "youtube_dl.extractor.instagram.InstagramIE",
        "signature": "youtube_dl.extractor.instagram.InstagramIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        uploader_id = self._search_regex(r'\"owner\":{\"username\":\"(.+?)\"',\n            webpage, 'uploader id', fatal=False)\n        desc = self._search_regex(r'\"caption\":\"(.*?)\"', webpage, 'description',\n            fatal=False)\n\n        return {\n            'id': video_id,\n            'url': self._og_search_video_url(webpage, secure=False),\n            'ext': 'mp4',\n            'title': 'Video by %s' % uploader_id,\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'uploader_id': uploader_id,\n            'description': desc,\n        }",
        "begin_line": 22,
        "end_line": 39,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.viki.VikiIE._real_extract#29",
        "src_path": "youtube_dl/extractor/viki.py",
        "class_name": "youtube_dl.extractor.viki.VikiIE",
        "signature": "youtube_dl.extractor.viki.VikiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group(1)\n\n        webpage = self._download_webpage(url, video_id)\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n\n        uploader_m = re.search(\n            r'<strong>Broadcast Network: </strong>\\s*([^<]*)<', webpage)\n        if uploader_m is None:\n            uploader = None\n        else:\n            uploader = uploader_m.group(1).strip()\n\n        rating_str = self._html_search_regex(\n            r'<strong>Rating: </strong>\\s*([^<]*)<', webpage,\n            u'rating information', default='').strip()\n        RATINGS = {\n            'G': 0,\n            'PG': 10,\n            'PG-13': 13,\n            'R': 16,\n            'NC': 18,\n        }\n        age_limit = RATINGS.get(rating_str)\n\n        info_url = 'http://www.viki.com/player5_fragment/%s?action=show&controller=videos' % video_id\n        info_webpage = self._download_webpage(\n            info_url, video_id, note=u'Downloading info page')\n        if re.match(r'\\s*<div\\s+class=\"video-error', info_webpage):\n            raise ExtractorError(\n                u'Video %s is blocked from your location.' % video_id,\n                expected=True)\n        video_url = self._html_search_regex(\n            r'<source[^>]+src=\"([^\"]+)\"', info_webpage, u'video URL')\n\n        upload_date_str = self._html_search_regex(\n            r'\"created_at\":\"([^\"]+)\"', info_webpage, u'upload date')\n        upload_date = (\n            unified_strdate(upload_date_str)\n            if upload_date_str is not None\n            else None\n        )\n\n        # subtitles\n        video_subtitles = self.extract_subtitles(video_id, info_webpage)\n        if self._downloader.params.get('listsubtitles', False):\n            self._list_available_subtitles(video_id, info_webpage)\n            return\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'description': description,\n            'thumbnail': thumbnail,\n            'age_limit': age_limit,\n            'uploader': uploader,\n            'subtitles': video_subtitles,\n            'upload_date': upload_date,\n        }",
        "begin_line": 29,
        "end_line": 91,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.viki.VikiIE._get_available_subtitles#93",
        "src_path": "youtube_dl/extractor/viki.py",
        "class_name": "youtube_dl.extractor.viki.VikiIE",
        "signature": "youtube_dl.extractor.viki.VikiIE._get_available_subtitles(self, video_id, info_webpage)",
        "snippet": "    def _get_available_subtitles(self, video_id, info_webpage):\n        res = {}\n        for sturl_html in re.findall(r'<track src=\"([^\"]+)\"/>', info_webpage):\n            sturl = unescapeHTML(sturl_html)\n            m = re.search(r'/(?P<lang>[a-z]+)\\.vtt', sturl)\n            if not m:\n                continue\n            res[m.group('lang')] = sturl\n        return res",
        "begin_line": 93,
        "end_line": 101,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.vice.ViceIE._real_extract#23",
        "src_path": "youtube_dl/extractor/vice.py",
        "class_name": "youtube_dl.extractor.vice.ViceIE",
        "signature": "youtube_dl.extractor.vice.ViceIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        name = mobj.group('name')\n        webpage = self._download_webpage(url, name)\n        try:\n            ooyala_url = self._og_search_video_url(webpage)\n        except ExtractorError:\n            try:\n                embed_code = self._search_regex(\n                    r'OO.Player.create\\(\\'ooyalaplayer\\', \\'(.+?)\\'', webpage,\n                    u'ooyala embed code')\n                ooyala_url = OoyalaIE._url_for_embed_code(embed_code)\n            except ExtractorError:\n                raise ExtractorError(u'The page doesn\\'t contain a video', expected=True)\n        return self.url_result(ooyala_url, ie='Ooyala')",
        "begin_line": 23,
        "end_line": 37,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.update.rsa_verify#16",
        "src_path": "youtube_dl/update.py",
        "class_name": "youtube_dl.update",
        "signature": "youtube_dl.update.rsa_verify(message, signature, key)",
        "snippet": "def rsa_verify(message, signature, key):\n    from struct import pack\n    from hashlib import sha256\n    from sys import version_info\n    def b(x):\n        if version_info[0] == 2: return x\n        else: return x.encode('latin1')\n    assert(type(message) == type(b('')))\n    block_size = 0\n    n = key[0]\n    while n:\n        block_size += 1\n        n >>= 8\n    signature = pow(int(signature, 16), key[1], key[0])\n    raw_bytes = []\n    while signature:\n        raw_bytes.insert(0, pack(\"B\", signature & 0xFF))\n        signature >>= 8\n    signature = (block_size - len(raw_bytes)) * b('\\x00') + b('').join(raw_bytes)\n    if signature[0:2] != b('\\x00\\x01'): return False\n    signature = signature[2:]\n    if not b('\\x00') in signature: return False\n    signature = signature[signature.index(b('\\x00'))+1:]\n    if not signature.startswith(b('\\x30\\x31\\x30\\x0D\\x06\\x09\\x60\\x86\\x48\\x01\\x65\\x03\\x04\\x02\\x01\\x05\\x00\\x04\\x20')): return False\n    signature = signature[19:]\n    if signature != sha256(message).digest(): return False\n    return True",
        "begin_line": 16,
        "end_line": 42,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.update.update_self#45",
        "src_path": "youtube_dl/update.py",
        "class_name": "youtube_dl.update",
        "signature": "youtube_dl.update.update_self(to_screen, verbose)",
        "snippet": "def update_self(to_screen, verbose):\n    \"\"\"Update the program file with the latest version from the repository\"\"\"\n\n    UPDATE_URL = \"http://rg3.github.io/youtube-dl/update/\"\n    VERSION_URL = UPDATE_URL + 'LATEST_VERSION'\n    JSON_URL = UPDATE_URL + 'versions.json'\n    UPDATES_RSA_KEY = (0x9d60ee4d8f805312fdb15a62f87b95bd66177b91df176765d13514a0f1754bcd2057295c5b6f1d35daa6742c3ffc9a82d3e118861c207995a8031e151d863c9927e304576bc80692bc8e094896fcf11b66f3e29e04e3a71e9a11558558acea1840aec37fc396fb6b65dc81a1c4144e03bd1c011de62e3f1357b327d08426fe93, 65537)\n\n    if not isinstance(globals().get('__loader__'), zipimporter) and not hasattr(sys, \"frozen\"):\n        to_screen(u'It looks like you installed youtube-dl with a package manager, pip, setup.py or a tarball. Please use that to update.')\n        return\n\n    # Check if there is a new version\n    try:\n        newversion = compat_urllib_request.urlopen(VERSION_URL).read().decode('utf-8').strip()\n    except:\n        if verbose: to_screen(compat_str(traceback.format_exc()))\n        to_screen(u'ERROR: can\\'t find the current version. Please try again later.')\n        return\n    if newversion == __version__:\n        to_screen(u'youtube-dl is up-to-date (' + __version__ + ')')\n        return\n\n    # Download and check versions info\n    try:\n        versions_info = compat_urllib_request.urlopen(JSON_URL).read().decode('utf-8')\n        versions_info = json.loads(versions_info)\n    except:\n        if verbose: to_screen(compat_str(traceback.format_exc()))\n        to_screen(u'ERROR: can\\'t obtain versions info. Please try again later.')\n        return\n    if not 'signature' in versions_info:\n        to_screen(u'ERROR: the versions file is not signed or corrupted. Aborting.')\n        return\n    signature = versions_info['signature']\n    del versions_info['signature']\n    if not rsa_verify(json.dumps(versions_info, sort_keys=True).encode('utf-8'), signature, UPDATES_RSA_KEY):\n        to_screen(u'ERROR: the versions file signature is invalid. Aborting.')\n        return\n\n    version_id = versions_info['latest']\n\n    def version_tuple(version_str):\n        return tuple(map(int, version_str.split('.')))\n    if version_tuple(__version__) >= version_tuple(version_id):\n        to_screen(u'youtube-dl is up to date (%s)' % __version__)\n        return\n\n    to_screen(u'Updating to version ' + version_id + ' ...')\n    version = versions_info['versions'][version_id]\n\n    print_notes(to_screen, versions_info['versions'])\n\n    filename = sys.argv[0]\n    # Py2EXE: Filename could be different\n    if hasattr(sys, \"frozen\") and not os.path.isfile(filename):\n        if os.path.isfile(filename + u'.exe'):\n            filename += u'.exe'\n\n    if not os.access(filename, os.W_OK):\n        to_screen(u'ERROR: no write permissions on %s' % filename)\n        return\n\n    # Py2EXE\n    if hasattr(sys, \"frozen\"):\n        exe = os.path.abspath(filename)\n        directory = os.path.dirname(exe)\n        if not os.access(directory, os.W_OK):\n            to_screen(u'ERROR: no write permissions on %s' % directory)\n            return\n\n        try:\n            urlh = compat_urllib_request.urlopen(version['exe'][0])\n            newcontent = urlh.read()\n            urlh.close()\n        except (IOError, OSError):\n            if verbose: to_screen(compat_str(traceback.format_exc()))\n            to_screen(u'ERROR: unable to download latest version')\n            return\n\n        newcontent_hash = hashlib.sha256(newcontent).hexdigest()\n        if newcontent_hash != version['exe'][1]:\n            to_screen(u'ERROR: the downloaded file hash does not match. Aborting.')\n            return\n\n        try:\n            with open(exe + '.new', 'wb') as outf:\n                outf.write(newcontent)\n        except (IOError, OSError):\n            if verbose: to_screen(compat_str(traceback.format_exc()))\n            to_screen(u'ERROR: unable to write the new version')\n            return\n\n        try:\n            bat = os.path.join(directory, 'youtube-dl-updater.bat')\n            with io.open(bat, 'w') as batfile:\n                batfile.write(u\"\"\"\n@echo off\necho Waiting for file handle to be closed ...\nping 127.0.0.1 -n 5 -w 1000 > NUL\nmove /Y \"%s.new\" \"%s\" > NUL\necho Updated youtube-dl to version %s.\nstart /b \"\" cmd /c del \"%%~f0\"&exit /b\"\n                \\n\"\"\" % (exe, exe, version_id))\n\n            subprocess.Popen([bat])  # Continues to run in the background\n            return  # Do not show premature success messages\n        except (IOError, OSError):\n            if verbose: to_screen(compat_str(traceback.format_exc()))\n            to_screen(u'ERROR: unable to overwrite current version')\n            return\n\n    # Zip unix package\n    elif isinstance(globals().get('__loader__'), zipimporter):\n        try:\n            urlh = compat_urllib_request.urlopen(version['bin'][0])\n            newcontent = urlh.read()\n            urlh.close()\n        except (IOError, OSError):\n            if verbose: to_screen(compat_str(traceback.format_exc()))\n            to_screen(u'ERROR: unable to download latest version')\n            return\n\n        newcontent_hash = hashlib.sha256(newcontent).hexdigest()\n        if newcontent_hash != version['bin'][1]:\n            to_screen(u'ERROR: the downloaded file hash does not match. Aborting.')\n            return\n\n        try:\n            with open(filename, 'wb') as outf:\n                outf.write(newcontent)\n        except (IOError, OSError):\n            if verbose: to_screen(compat_str(traceback.format_exc()))\n            to_screen(u'ERROR: unable to overwrite current version')\n            return\n\n    to_screen(u'Updated youtube-dl. Restart youtube-dl to use the new version.')",
        "begin_line": 45,
        "end_line": 181,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.update.get_notes#183",
        "src_path": "youtube_dl/update.py",
        "class_name": "youtube_dl.update",
        "signature": "youtube_dl.update.get_notes(versions, fromVersion)",
        "snippet": "def get_notes(versions, fromVersion):\n    notes = []\n    for v,vdata in sorted(versions.items()):\n        if v > fromVersion:\n            notes.extend(vdata.get('notes', []))\n    return notes",
        "begin_line": 183,
        "end_line": 188,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.update.print_notes#190",
        "src_path": "youtube_dl/update.py",
        "class_name": "youtube_dl.update",
        "signature": "youtube_dl.update.print_notes(to_screen, versions, fromVersion=__version__)",
        "snippet": "def print_notes(to_screen, versions, fromVersion=__version__):\n    notes = get_notes(versions, fromVersion)\n    if notes:\n        to_screen(u'PLEASE NOTE:')\n        for note in notes:\n            to_screen(note)",
        "begin_line": 190,
        "end_line": 195,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.clipfish.ClipfishIE._real_extract#24",
        "src_path": "youtube_dl/extractor/clipfish.py",
        "class_name": "youtube_dl.extractor.clipfish.ClipfishIE",
        "signature": "youtube_dl.extractor.clipfish.ClipfishIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group(1)\n\n        info_url = ('http://www.clipfish.de/devxml/videoinfo/%s?ts=%d' %\n                    (video_id, int(time.time())))\n        doc = self._download_xml(\n            info_url, video_id, note=u'Downloading info page')\n        title = doc.find('title').text\n        video_url = doc.find('filename').text\n        if video_url is None:\n            xml_bytes = xml.etree.ElementTree.tostring(doc)\n            raise ExtractorError(u'Cannot find video URL in document %r' %\n                                 xml_bytes)\n        thumbnail = doc.find('imageurl').text\n        duration_str = doc.find('duration').text\n        m = re.match(\n            r'^(?P<hours>[0-9]+):(?P<minutes>[0-9]{2}):(?P<seconds>[0-9]{2}):(?P<ms>[0-9]*)$',\n            duration_str)\n        if m:\n            duration = (\n                (int(m.group('hours')) * 60 * 60) +\n                (int(m.group('minutes')) * 60) +\n                (int(m.group('seconds')))\n            )\n        else:\n            duration = None\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'thumbnail': thumbnail,\n            'duration': duration,\n        }",
        "begin_line": 24,
        "end_line": 58,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.exfm.ExfmIE._real_extract#41",
        "src_path": "youtube_dl/extractor/exfm.py",
        "class_name": "youtube_dl.extractor.exfm.ExfmIE",
        "signature": "youtube_dl.extractor.exfm.ExfmIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        song_id = mobj.group('id')\n        info_url = \"http://ex.fm/api/v3/song/%s\" % song_id\n        info = self._download_json(info_url, song_id)['song']\n        song_url = info['url']\n        if re.match(self._SOUNDCLOUD_URL, song_url) is not None:\n            self.to_screen('Soundcloud song detected')\n            return self.url_result(song_url.replace('/stream', ''), 'Soundcloud')\n        return {\n            'id': song_id,\n            'url': song_url,\n            'ext': 'mp3',\n            'title': info['title'],\n            'thumbnail': info['image']['large'],\n            'uploader': info['artist'],\n            'view_count': info['loved_count'],\n        }",
        "begin_line": 41,
        "end_line": 58,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.vk.VKIE._login#72",
        "src_path": "youtube_dl/extractor/vk.py",
        "class_name": "youtube_dl.extractor.vk.VKIE",
        "signature": "youtube_dl.extractor.vk.VKIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n\n        login_form = {\n            'act': 'login',\n            'role': 'al_frame',\n            'expire': '1',\n            'email': username,\n            'pass': password,\n        }\n\n        request = compat_urllib_request.Request('https://login.vk.com/?act=login',\n            compat_urllib_parse.urlencode(login_form).encode('utf-8'))\n        login_page = self._download_webpage(request, None, note='Logging in as %s' % username)\n\n        if re.search(r'onLoginFailed', login_page):\n            raise ExtractorError('Unable to login, incorrect username and/or password', expected=True)",
        "begin_line": 72,
        "end_line": 90,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.vk.VKIE._real_initialize#92",
        "src_path": "youtube_dl/extractor/vk.py",
        "class_name": "youtube_dl.extractor.vk.VKIE",
        "signature": "youtube_dl.extractor.vk.VKIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 92,
        "end_line": 93,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.vk.VKIE._real_extract#95",
        "src_path": "youtube_dl/extractor/vk.py",
        "class_name": "youtube_dl.extractor.vk.VKIE",
        "signature": "youtube_dl.extractor.vk.VKIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n\n        if not video_id:\n            video_id = '%s_%s' % (mobj.group('oid'), mobj.group('id'))\n\n        info_url = 'http://vk.com/al_video.php?act=show&al=1&video=%s' % video_id\n        info_page = self._download_webpage(info_url, video_id)\n\n        if re.search(r'<!>Please log in or <', info_page):\n            raise ExtractorError('This video is only available for registered users, '\n                'use --username and --password options to provide account credentials.', expected=True)\n\n        m_yt = re.search(r'src=\"(http://www.youtube.com/.*?)\"', info_page)\n        if m_yt is not None:\n            self.to_screen(u'Youtube video detected')\n            return self.url_result(m_yt.group(1), 'Youtube')\n        data_json = self._search_regex(r'var vars = ({.*?});', info_page, 'vars')\n        data = json.loads(data_json)\n\n        formats = [{\n            'format_id': k,\n            'url': v,\n            'width': int(k[len('url'):]),\n        } for k, v in data.items()\n            if k.startswith('url')]\n        self._sort_formats(formats)\n\n        return {\n            'id': compat_str(data['vid']),\n            'formats': formats,\n            'title': unescapeHTML(data['md_title']),\n            'thumbnail': data.get('jpg'),\n            'uploader': data.get('md_author'),\n            'duration': data.get('duration')\n        }",
        "begin_line": 95,
        "end_line": 131,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.freesound.FreesoundIE._real_extract#22",
        "src_path": "youtube_dl/extractor/freesound.py",
        "class_name": "youtube_dl.extractor.freesound.FreesoundIE",
        "signature": "youtube_dl.extractor.freesound.FreesoundIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        music_id = mobj.group('id')\n        webpage = self._download_webpage(url, music_id)\n        title = self._html_search_regex(\n            r'<div id=\"single_sample_header\">.*?<a href=\"#\">(.+?)</a>',\n            webpage, 'music title', flags=re.DOTALL)\n        description = self._html_search_regex(\n            r'<div id=\"sound_description\">(.*?)</div>', webpage, 'description',\n            fatal=False, flags=re.DOTALL)\n\n        return {\n            'id': music_id,\n            'title': title,\n            'url': self._og_search_property('audio', webpage, 'music url'),\n            'uploader': self._og_search_property('audio:artist', webpage, 'music uploader'),\n            'description': description,\n        }",
        "begin_line": 22,
        "end_line": 39,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.jpopsukitv.JpopsukiIE._real_extract#32",
        "src_path": "youtube_dl/extractor/jpopsukitv.py",
        "class_name": "youtube_dl.extractor.jpopsukitv.JpopsukiIE",
        "signature": "youtube_dl.extractor.jpopsukitv.JpopsukiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = 'http://www.jpopsuki.tv' + self._html_search_regex(\n            r'<source src=\"(.*?)\" type', webpage, 'video url')\n\n        video_title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n        uploader = self._html_search_regex(\n            r'<li>from: <a href=\"/user/view/user/(.*?)/uid/',\n            webpage, 'video uploader', fatal=False)\n        uploader_id = self._html_search_regex(\n            r'<li>from: <a href=\"/user/view/user/\\S*?/uid/(\\d*)',\n            webpage, 'video uploader_id', fatal=False)\n        upload_date = self._html_search_regex(\n            r'<li>uploaded: (.*?)</li>', webpage, 'video upload_date',\n            fatal=False)\n        if upload_date is not None:\n            upload_date = unified_strdate(upload_date)\n        view_count_str = self._html_search_regex(\n            r'<li>Hits: ([0-9]+?)</li>', webpage, 'video view_count',\n            fatal=False)\n        comment_count_str = self._html_search_regex(\n            r'<h2>([0-9]+?) comments</h2>', webpage, 'video comment_count',\n            fatal=False)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': video_title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'upload_date': upload_date,\n            'view_count': int_or_none(view_count_str),\n            'comment_count': int_or_none(comment_count_str),\n        }",
        "begin_line": 32,
        "end_line": 73,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.__init__#46",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.__init__(self, ydl, params)",
        "snippet": "    def __init__(self, ydl, params):\n        \"\"\"Create a FileDownloader object with the given options.\"\"\"\n        self.ydl = ydl\n        self._progress_hooks = []\n        self.params = params",
        "begin_line": 46,
        "end_line": 50,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.to_screen#127",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.to_screen(self, *args, **kargs)",
        "snippet": "    def to_screen(self, *args, **kargs):\n        self.ydl.to_screen(*args, **kargs)",
        "begin_line": 127,
        "end_line": 128,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.to_stderr#130",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.to_stderr(self, message)",
        "snippet": "    def to_stderr(self, message):\n        self.ydl.to_screen(message)",
        "begin_line": 130,
        "end_line": 131,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.to_console_title#133",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.to_console_title(self, message)",
        "snippet": "    def to_console_title(self, message):\n        self.ydl.to_console_title(message)",
        "begin_line": 133,
        "end_line": 134,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.trouble#136",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.trouble(self, *args, **kargs)",
        "snippet": "    def trouble(self, *args, **kargs):\n        self.ydl.trouble(*args, **kargs)",
        "begin_line": 136,
        "end_line": 137,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_warning#139",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_warning(self, *args, **kargs)",
        "snippet": "    def report_warning(self, *args, **kargs):\n        self.ydl.report_warning(*args, **kargs)",
        "begin_line": 139,
        "end_line": 140,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_error#142",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_error(self, *args, **kargs)",
        "snippet": "    def report_error(self, *args, **kargs):\n        self.ydl.report_error(*args, **kargs)",
        "begin_line": 142,
        "end_line": 143,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.slow_down#145",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.slow_down(self, start_time, byte_counter)",
        "snippet": "    def slow_down(self, start_time, byte_counter):\n        \"\"\"Sleep if the download speed is over the rate limit.\"\"\"\n        rate_limit = self.params.get('ratelimit', None)\n        if rate_limit is None or byte_counter == 0:\n            return\n        now = time.time()\n        elapsed = now - start_time\n        if elapsed <= 0.0:\n            return\n        speed = float(byte_counter) / elapsed\n        if speed > rate_limit:\n            time.sleep((byte_counter - rate_limit * (now - start_time)) / rate_limit)",
        "begin_line": 145,
        "end_line": 156,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.temp_name#158",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.temp_name(self, filename)",
        "snippet": "    def temp_name(self, filename):\n        \"\"\"Returns a temporary filename for the given filename.\"\"\"\n        if self.params.get('nopart', False) or filename == u'-' or \\\n                (os.path.exists(encodeFilename(filename)) and not os.path.isfile(encodeFilename(filename))):\n            return filename\n        return filename + u'.part'",
        "begin_line": 158,
        "end_line": 163,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.undo_temp_name#165",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.undo_temp_name(self, filename)",
        "snippet": "    def undo_temp_name(self, filename):\n        if filename.endswith(u'.part'):\n            return filename[:-len(u'.part')]\n        return filename",
        "begin_line": 165,
        "end_line": 168,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.try_rename#170",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.try_rename(self, old_filename, new_filename)",
        "snippet": "    def try_rename(self, old_filename, new_filename):\n        try:\n            if old_filename == new_filename:\n                return\n            os.rename(encodeFilename(old_filename), encodeFilename(new_filename))\n        except (IOError, OSError) as err:\n            self.report_error(u'unable to rename file: %s' % str(err))",
        "begin_line": 170,
        "end_line": 176,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.try_utime#178",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.try_utime(self, filename, last_modified_hdr)",
        "snippet": "    def try_utime(self, filename, last_modified_hdr):\n        \"\"\"Try to set the last-modified time of the given file.\"\"\"\n        if last_modified_hdr is None:\n            return\n        if not os.path.isfile(encodeFilename(filename)):\n            return\n        timestr = last_modified_hdr\n        if timestr is None:\n            return\n        filetime = timeconvert(timestr)\n        if filetime is None:\n            return filetime\n        # Ignore obviously invalid dates\n        if filetime == 0:\n            return\n        try:\n            os.utime(filename, (time.time(), filetime))\n        except:\n            pass\n        return filetime",
        "begin_line": 178,
        "end_line": 197,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_destination#199",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_destination(self, filename)",
        "snippet": "    def report_destination(self, filename):\n        \"\"\"Report destination filename.\"\"\"\n        self.to_screen(u'[download] Destination: ' + filename)",
        "begin_line": 199,
        "end_line": 201,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader._report_progress_status#203",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader._report_progress_status(self, msg, is_last_line=False)",
        "snippet": "    def _report_progress_status(self, msg, is_last_line=False):\n        fullmsg = u'[download] ' + msg\n        if self.params.get('progress_with_newline', False):\n            self.to_screen(fullmsg)\n        else:\n            if os.name == 'nt':\n                prev_len = getattr(self, '_report_progress_prev_line_length',\n                                   0)\n                if prev_len > len(fullmsg):\n                    fullmsg += u' ' * (prev_len - len(fullmsg))\n                self._report_progress_prev_line_length = len(fullmsg)\n                clear_line = u'\\r'\n            else:\n                clear_line = (u'\\r\\x1b[K' if sys.stderr.isatty() else u'\\r')\n            self.to_screen(clear_line + fullmsg, skip_eol=not is_last_line)\n        self.to_console_title(u'youtube-dl ' + msg)",
        "begin_line": 203,
        "end_line": 218,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_progress#220",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_progress(self, percent, data_len_str, speed, eta)",
        "snippet": "    def report_progress(self, percent, data_len_str, speed, eta):\n        \"\"\"Report download progress.\"\"\"\n        if self.params.get('noprogress', False):\n            return\n        if eta is not None:\n            eta_str = self.format_eta(eta)\n        else:\n            eta_str = 'Unknown ETA'\n        if percent is not None:\n            percent_str = self.format_percent(percent)\n        else:\n            percent_str = 'Unknown %'\n        speed_str = self.format_speed(speed)\n\n        msg = (u'%s of %s at %s ETA %s' %\n               (percent_str, data_len_str, speed_str, eta_str))\n        self._report_progress_status(msg)",
        "begin_line": 220,
        "end_line": 236,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_progress_live_stream#238",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_progress_live_stream(self, downloaded_data_len, speed, elapsed)",
        "snippet": "    def report_progress_live_stream(self, downloaded_data_len, speed, elapsed):\n        if self.params.get('noprogress', False):\n            return\n        downloaded_str = format_bytes(downloaded_data_len)\n        speed_str = self.format_speed(speed)\n        elapsed_str = FileDownloader.format_seconds(elapsed)\n        msg = u'%s at %s (%s)' % (downloaded_str, speed_str, elapsed_str)\n        self._report_progress_status(msg)",
        "begin_line": 238,
        "end_line": 245,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_finish#247",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_finish(self, data_len_str, tot_time)",
        "snippet": "    def report_finish(self, data_len_str, tot_time):\n        \"\"\"Report download finished.\"\"\"\n        if self.params.get('noprogress', False):\n            self.to_screen(u'[download] Download completed')\n        else:\n            self._report_progress_status(\n                (u'100%% of %s in %s' %\n                 (data_len_str, self.format_seconds(tot_time))),\n                is_last_line=True)",
        "begin_line": 247,
        "end_line": 255,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_resuming_byte#257",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_resuming_byte(self, resume_len)",
        "snippet": "    def report_resuming_byte(self, resume_len):\n        \"\"\"Report attempt to resume at given byte.\"\"\"\n        self.to_screen(u'[download] Resuming download at byte %s' % resume_len)",
        "begin_line": 257,
        "end_line": 259,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_retry#261",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_retry(self, count, retries)",
        "snippet": "    def report_retry(self, count, retries):\n        \"\"\"Report retry in case of HTTP error 5xx\"\"\"\n        self.to_screen(u'[download] Got server HTTP error. Retrying (attempt %d of %d)...' % (count, retries))",
        "begin_line": 261,
        "end_line": 263,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_file_already_downloaded#265",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_file_already_downloaded(self, file_name)",
        "snippet": "    def report_file_already_downloaded(self, file_name):\n        \"\"\"Report file has already been fully downloaded.\"\"\"\n        try:\n            self.to_screen(u'[download] %s has already been downloaded' % file_name)\n        except UnicodeEncodeError:\n            self.to_screen(u'[download] The file has already been downloaded')",
        "begin_line": 265,
        "end_line": 270,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.report_unable_to_resume#272",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.report_unable_to_resume(self)",
        "snippet": "    def report_unable_to_resume(self):\n        \"\"\"Report it was impossible to resume download.\"\"\"\n        self.to_screen(u'[download] Unable to resume')",
        "begin_line": 272,
        "end_line": 274,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.download#276",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.download(self, filename, info_dict)",
        "snippet": "    def download(self, filename, info_dict):\n        \"\"\"Download to a filename using the info from info_dict\n        Return True on success and False otherwise\n        \"\"\"\n        # Check file already present\n        if self.params.get('continuedl', False) and os.path.isfile(encodeFilename(filename)) and not self.params.get('nopart', False):\n            self.report_file_already_downloaded(filename)\n            self._hook_progress({\n                'filename': filename,\n                'status': 'finished',\n                'total_bytes': os.path.getsize(encodeFilename(filename)),\n            })\n            return True\n\n        return self.real_download(filename, info_dict)",
        "begin_line": 276,
        "end_line": 290,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.real_download#292",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.real_download(self, filename, info_dict)",
        "snippet": "    def real_download(self, filename, info_dict):\n        \"\"\"Real download process. Redefine in subclasses.\"\"\"\n        raise NotImplementedError(u'This method must be implemented by sublcasses')",
        "begin_line": 292,
        "end_line": 294,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader._hook_progress#296",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader._hook_progress(self, status)",
        "snippet": "    def _hook_progress(self, status):\n        for ph in self._progress_hooks:\n            ph(status)",
        "begin_line": 296,
        "end_line": 298,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.common.FileDownloader.add_progress_hook#300",
        "src_path": "youtube_dl/downloader/common.py",
        "class_name": "youtube_dl.downloader.common.FileDownloader",
        "signature": "youtube_dl.downloader.common.FileDownloader.add_progress_hook(self, ph)",
        "snippet": "    def add_progress_hook(self, ph):\n        \"\"\" ph gets called on download progress, with a dictionary with the entries\n        * filename: The final filename\n        * status: One of \"downloading\" and \"finished\"\n\n        It can also have some of the following entries:\n\n        * downloaded_bytes: Bytes on disks\n        * total_bytes: Total bytes, None if unknown\n        * tmpfilename: The filename we're currently writing to\n        * eta: The estimated time in seconds, None if unknown\n        * speed: The download speed in bytes/second, None if unknown\n\n        Hooks are guaranteed to be called at least once (with status \"finished\")\n        if the download is successful.\n        \"\"\"\n        self._progress_hooks.append(ph)",
        "begin_line": 300,
        "end_line": 316,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.dropbox.DropboxIE._real_extract#22",
        "src_path": "youtube_dl/extractor/dropbox.py",
        "class_name": "youtube_dl.extractor.dropbox.DropboxIE",
        "signature": "youtube_dl.extractor.dropbox.DropboxIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        title = os.path.splitext(mobj.group('title'))[0]\n        video_url = url + '?dl=1'\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n        }",
        "begin_line": 22,
        "end_line": 32,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.toutv.TouTvIE._real_extract#35",
        "src_path": "youtube_dl/extractor/toutv.py",
        "class_name": "youtube_dl.extractor.toutv.TouTvIE",
        "signature": "youtube_dl.extractor.toutv.TouTvIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n\n        mediaId = self._search_regex(\n            r'\"idMedia\":\\s*\"([^\"]+)\"', webpage, 'media ID')\n\n        streams_url = 'http://release.theplatform.com/content.select?pid=' + mediaId\n        streams_doc = self._download_xml(\n            streams_url, video_id, note='Downloading stream list')\n\n        video_url = next(n.text\n                         for n in streams_doc.findall('.//choice/url')\n                         if '//ad.doubleclick' not in n.text)\n        if video_url.endswith('/Unavailable.flv'):\n            raise ExtractorError(\n                'Access to this video is blocked from outside of Canada',\n                expected=True)\n\n        duration_str = self._html_search_meta(\n            'video:duration', webpage, 'duration')\n        duration = int(duration_str) if duration_str else None\n        upload_date_str = self._html_search_meta(\n            'video:release_date', webpage, 'upload date')\n        upload_date = unified_strdate(upload_date_str) if upload_date_str else None\n\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n            'url': video_url,\n            'description': self._og_search_description(webpage),\n            'uploader': self._dc_search_uploader(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'age_limit': self._media_rating_search(webpage),\n            'duration': duration,\n            'upload_date': upload_date,\n            'ext': 'mp4',\n        }",
        "begin_line": 35,
        "end_line": 73,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.novamov.NovaMovIE._real_extract#37",
        "src_path": "youtube_dl/extractor/novamov.py",
        "class_name": "youtube_dl.extractor.novamov.NovaMovIE",
        "signature": "youtube_dl.extractor.novamov.NovaMovIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n\n        page = self._download_webpage(\n            'http://%s/video/%s' % (self._HOST, video_id), video_id, 'Downloading video page')\n\n        if re.search(self._FILE_DELETED_REGEX, page) is not None:\n            raise ExtractorError(u'Video %s does not exist' % video_id, expected=True)\n\n        filekey = self._search_regex(self._FILEKEY_REGEX, page, 'filekey')\n\n        title = self._html_search_regex(self._TITLE_REGEX, page, 'title', fatal=False)\n\n        description = self._html_search_regex(self._DESCRIPTION_REGEX, page, 'description', default='', fatal=False)\n\n        api_response = self._download_webpage(\n            'http://%s/api/player.api.php?key=%s&file=%s' % (self._HOST, filekey, video_id), video_id,\n            'Downloading video api response')\n\n        response = compat_urlparse.parse_qs(api_response)\n\n        if 'error_msg' in response:\n            raise ExtractorError('%s returned error: %s' % (self.IE_NAME, response['error_msg'][0]), expected=True)\n\n        video_url = response['url'][0]\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': description\n        }",
        "begin_line": 37,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.justintv.JustinTVIE.report_download_page#40",
        "src_path": "youtube_dl/extractor/justintv.py",
        "class_name": "youtube_dl.extractor.justintv.JustinTVIE",
        "signature": "youtube_dl.extractor.justintv.JustinTVIE.report_download_page(self, channel, offset)",
        "snippet": "    def report_download_page(self, channel, offset):\n        \"\"\"Report attempt to download a single page of videos.\"\"\"\n        self.to_screen(u'%s: Downloading video information from %d to %d' %\n                (channel, offset, offset + self._JUSTIN_PAGE_LIMIT))",
        "begin_line": 40,
        "end_line": 43,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.justintv.JustinTVIE._parse_page#46",
        "src_path": "youtube_dl/extractor/justintv.py",
        "class_name": "youtube_dl.extractor.justintv.JustinTVIE",
        "signature": "youtube_dl.extractor.justintv.JustinTVIE._parse_page(self, url, video_id)",
        "snippet": "    def _parse_page(self, url, video_id):\n        info_json = self._download_webpage(url, video_id,\n                                           u'Downloading video info JSON',\n                                           u'unable to download video info JSON')\n\n        response = json.loads(info_json)\n        if type(response) != list:\n            error_text = response.get('error', 'unknown error')\n            raise ExtractorError(u'Justin.tv API: %s' % error_text)\n        info = []\n        for clip in response:\n            video_url = clip['video_file_url']\n            if video_url:\n                video_extension = os.path.splitext(video_url)[1][1:]\n                video_date = re.sub('-', '', clip['start_time'][:10])\n                video_uploader_id = clip.get('user_id', clip.get('channel_id'))\n                video_id = clip['id']\n                video_title = clip.get('title', video_id)\n                info.append({\n                    'id': video_id,\n                    'url': video_url,\n                    'title': video_title,\n                    'uploader': clip.get('channel_name', video_uploader_id),\n                    'uploader_id': video_uploader_id,\n                    'upload_date': video_date,\n                    'ext': video_extension,\n                })\n        return (len(response), info)",
        "begin_line": 46,
        "end_line": 73,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.justintv.JustinTVIE._real_extract#75",
        "src_path": "youtube_dl/extractor/justintv.py",
        "class_name": "youtube_dl.extractor.justintv.JustinTVIE",
        "signature": "youtube_dl.extractor.justintv.JustinTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        if mobj is None:\n            raise ExtractorError(u'invalid URL: %s' % url)\n\n        api_base = 'http://api.justin.tv'\n        paged = False\n        if mobj.group('channelid'):\n            paged = True\n            video_id = mobj.group('channelid')\n            api = api_base + '/channel/archives/%s.json' % video_id\n        elif mobj.group('chapterid'):\n            chapter_id = mobj.group('chapterid')\n\n            webpage = self._download_webpage(url, chapter_id)\n            m = re.search(r'PP\\.archive_id = \"([0-9]+)\";', webpage)\n            if not m:\n                raise ExtractorError(u'Cannot find archive of a chapter')\n            archive_id = m.group(1)\n\n            api = api_base + '/broadcast/by_chapter/%s.xml' % chapter_id\n            doc = self._download_xml(api, chapter_id,\n                                             note=u'Downloading chapter information',\n                                             errnote=u'Chapter information download failed')\n            for a in doc.findall('.//archive'):\n                if archive_id == a.find('./id').text:\n                    break\n            else:\n                raise ExtractorError(u'Could not find chapter in chapter information')\n\n            video_url = a.find('./video_file_url').text\n            video_ext = video_url.rpartition('.')[2] or u'flv'\n\n            chapter_api_url = u'https://api.twitch.tv/kraken/videos/c' + chapter_id\n            chapter_info_json = self._download_webpage(chapter_api_url, u'c' + chapter_id,\n                                   note='Downloading chapter metadata',\n                                   errnote='Download of chapter metadata failed')\n            chapter_info = json.loads(chapter_info_json)\n\n            bracket_start = int(doc.find('.//bracket_start').text)\n            bracket_end = int(doc.find('.//bracket_end').text)\n\n            # TODO determine start (and probably fix up file)\n            #  youtube-dl -v http://www.twitch.tv/firmbelief/c/1757457\n            #video_url += u'?start=' + TODO:start_timestamp\n            # bracket_start is 13290, but we want 51670615\n            self._downloader.report_warning(u'Chapter detected, but we can just download the whole file. '\n                                            u'Chapter starts at %s and ends at %s' % (formatSeconds(bracket_start), formatSeconds(bracket_end)))\n\n            info = {\n                'id': u'c' + chapter_id,\n                'url': video_url,\n                'ext': video_ext,\n                'title': chapter_info['title'],\n                'thumbnail': chapter_info['preview'],\n                'description': chapter_info['description'],\n                'uploader': chapter_info['channel']['display_name'],\n                'uploader_id': chapter_info['channel']['name'],\n            }\n            return [info]\n        else:\n            video_id = mobj.group('videoid')\n            api = api_base + '/broadcast/by_archive/%s.json' % video_id\n\n        self.report_extraction(video_id)\n\n        info = []\n        offset = 0\n        limit = self._JUSTIN_PAGE_LIMIT\n        while True:\n            if paged:\n                self.report_download_page(video_id, offset)\n            page_url = api + ('?offset=%d&limit=%d' % (offset, limit))\n            page_count, page_info = self._parse_page(page_url, video_id)\n            info.extend(page_info)\n            if not paged or page_count != limit:\n                break\n            offset += limit\n        return info",
        "begin_line": 75,
        "end_line": 153,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.wat.WatIE.download_video_info#27",
        "src_path": "youtube_dl/extractor/wat.py",
        "class_name": "youtube_dl.extractor.wat.WatIE",
        "signature": "youtube_dl.extractor.wat.WatIE.download_video_info(self, real_id)",
        "snippet": "    def download_video_info(self, real_id):\n        # 'contentv4' is used in the website, but it also returns the related\n        # videos, we don't need them\n        info = self._download_webpage('http://www.wat.tv/interface/contentv3/' + real_id, real_id, 'Downloading video info')\n        info = json.loads(info)\n        return info['media']",
        "begin_line": 27,
        "end_line": 32,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.wat.WatIE._real_extract#35",
        "src_path": "youtube_dl/extractor/wat.py",
        "class_name": "youtube_dl.extractor.wat.WatIE",
        "signature": "youtube_dl.extractor.wat.WatIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        def real_id_for_chapter(chapter):\n            return chapter['tc_start'].split('-')[0]\n        mobj = re.match(self._VALID_URL, url)\n        short_id = mobj.group('shortID')\n        webpage = self._download_webpage(url, short_id)\n        real_id = self._search_regex(r'xtpage = \".*-(.*?)\";', webpage, 'real id')\n\n        video_info = self.download_video_info(real_id)\n        chapters = video_info['chapters']\n        first_chapter = chapters[0]\n\n        if real_id_for_chapter(first_chapter) != real_id:\n            self.to_screen('Multipart video detected')\n            chapter_urls = []\n            for chapter in chapters:\n                chapter_id = real_id_for_chapter(chapter)\n                # Yes, when we this chapter is processed by WatIE,\n                # it will download the info again\n                chapter_info = self.download_video_info(chapter_id)\n                chapter_urls.append(chapter_info['url'])\n            entries = [self.url_result(chapter_url) for chapter_url in chapter_urls]\n            return self.playlist_result(entries, real_id, video_info['title'])\n\n        # Otherwise we can continue and extract just one part, we have to use\n        # the short id for getting the video url\n        info = {'id': real_id,\n                'url': 'http://wat.tv/get/android5/%s.mp4' % real_id,\n                'ext': 'mp4',\n                'title': first_chapter['title'],\n                'thumbnail': first_chapter['preview'],\n                'description': first_chapter['description'],\n                'view_count': video_info['views'],\n                }\n        if 'date_diffusion' in first_chapter:\n            info['upload_date'] = unified_strdate(first_chapter['date_diffusion'])\n\n        return info",
        "begin_line": 35,
        "end_line": 72,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youku.YoukuIE._gen_sid#28",
        "src_path": "youtube_dl/extractor/youku.py",
        "class_name": "youtube_dl.extractor.youku.YoukuIE",
        "signature": "youtube_dl.extractor.youku.YoukuIE._gen_sid(self)",
        "snippet": "    def _gen_sid(self):\n        nowTime = int(time.time() * 1000)\n        random1 = random.randint(1000,1998)\n        random2 = random.randint(1000,9999)\n\n        return \"%d%d%d\" %(nowTime,random1,random2)",
        "begin_line": 28,
        "end_line": 33,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youku.YoukuIE._get_file_ID_mix_string#35",
        "src_path": "youtube_dl/extractor/youku.py",
        "class_name": "youtube_dl.extractor.youku.YoukuIE",
        "signature": "youtube_dl.extractor.youku.YoukuIE._get_file_ID_mix_string(self, seed)",
        "snippet": "    def _get_file_ID_mix_string(self, seed):\n        mixed = []\n        source = list(\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ/\\:._-1234567890\")\n        seed = float(seed)\n        for i in range(len(source)):\n            seed  =  (seed * 211 + 30031) % 65536\n            index  =  math.floor(seed / 65536 * len(source))\n            mixed.append(source[int(index)])\n            source.remove(source[int(index)])\n        #return ''.join(mixed)\n        return mixed",
        "begin_line": 35,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youku.YoukuIE._get_file_id#47",
        "src_path": "youtube_dl/extractor/youku.py",
        "class_name": "youtube_dl.extractor.youku.YoukuIE",
        "signature": "youtube_dl.extractor.youku.YoukuIE._get_file_id(self, fileId, seed)",
        "snippet": "    def _get_file_id(self, fileId, seed):\n        mixed = self._get_file_ID_mix_string(seed)\n        ids = fileId.split('*')\n        realId = []\n        for ch in ids:\n            if ch:\n                realId.append(mixed[int(ch)])\n        return ''.join(realId)",
        "begin_line": 47,
        "end_line": 54,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youku.YoukuIE._real_extract#56",
        "src_path": "youtube_dl/extractor/youku.py",
        "class_name": "youtube_dl.extractor.youku.YoukuIE",
        "signature": "youtube_dl.extractor.youku.YoukuIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        if mobj is None:\n            raise ExtractorError(u'Invalid URL: %s' % url)\n        video_id = mobj.group('ID')\n\n        info_url = 'http://v.youku.com/player/getPlayList/VideoIDS/' + video_id\n\n        jsondata = self._download_webpage(info_url, video_id)\n\n        self.report_extraction(video_id)\n        try:\n            config = json.loads(jsondata)\n            error_code = config['data'][0].get('error_code')\n            if error_code:\n                # -8 means blocked outside China.\n                error = config['data'][0].get('error')  # Chinese and English, separated by newline.\n                raise ExtractorError(error or u'Server reported error %i' % error_code,\n                    expected=True)\n\n            video_title =  config['data'][0]['title']\n            seed = config['data'][0]['seed']\n\n            format = self._downloader.params.get('format', None)\n            supported_format = list(config['data'][0]['streamfileids'].keys())\n\n            if format is None or format == 'best':\n                if 'hd2' in supported_format:\n                    format = 'hd2'\n                else:\n                    format = 'flv'\n                ext = u'flv'\n            elif format == 'worst':\n                format = 'mp4'\n                ext = u'mp4'\n            else:\n                format = 'flv'\n                ext = u'flv'\n\n\n            fileid = config['data'][0]['streamfileids'][format]\n            keys = [s['k'] for s in config['data'][0]['segs'][format]]\n            # segs is usually a dictionary, but an empty *list* if an error occured.\n        except (UnicodeDecodeError, ValueError, KeyError):\n            raise ExtractorError(u'Unable to extract info section')\n\n        files_info=[]\n        sid = self._gen_sid()\n        fileid = self._get_file_id(fileid, seed)\n\n        #column 8,9 of fileid represent the segment number\n        #fileid[7:9] should be changed\n        for index, key in enumerate(keys):\n\n            temp_fileid = '%s%02X%s' % (fileid[0:8], index, fileid[10:])\n            download_url = 'http://f.youku.com/player/getFlvPath/sid/%s_%02X/st/flv/fileid/%s?k=%s' % (sid, index, temp_fileid, key)\n\n            info = {\n                'id': '%s_part%02d' % (video_id, index),\n                'url': download_url,\n                'uploader': None,\n                'upload_date': None,\n                'title': video_title,\n                'ext': ext,\n            }\n            files_info.append(info)\n\n        return files_info",
        "begin_line": 56,
        "end_line": 123,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.aes.aes_ctr_decrypt#10",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.aes_ctr_decrypt(data, key, counter)",
        "snippet": "def aes_ctr_decrypt(data, key, counter):\n    \"\"\"\n    Decrypt with aes in counter mode\n    \n    @param {int[]} data        cipher\n    @param {int[]} key         16/24/32-Byte cipher key\n    @param {instance} counter  Instance whose next_value function (@returns {int[]}  16-Byte block)\n                               returns the next counter block\n    @returns {int[]}           decrypted data\n    \"\"\"\n    expanded_key = key_expansion(key)\n    block_count = int(ceil(float(len(data)) / BLOCK_SIZE_BYTES))\n    \n    decrypted_data=[]\n    for i in range(block_count):\n        counter_block = counter.next_value()\n        block = data[i*BLOCK_SIZE_BYTES : (i+1)*BLOCK_SIZE_BYTES]\n        block += [0]*(BLOCK_SIZE_BYTES - len(block))\n        \n        cipher_counter_block = aes_encrypt(counter_block, expanded_key)\n        decrypted_data += xor(block, cipher_counter_block)\n    decrypted_data = decrypted_data[:len(data)]\n    \n    return decrypted_data",
        "begin_line": 10,
        "end_line": 33,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.aes.aes_cbc_decrypt#35",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.aes_cbc_decrypt(data, key, iv)",
        "snippet": "def aes_cbc_decrypt(data, key, iv):\n    \"\"\"\n    Decrypt with aes in CBC mode\n    \n    @param {int[]} data        cipher\n    @param {int[]} key         16/24/32-Byte cipher key\n    @param {int[]} iv          16-Byte IV\n    @returns {int[]}           decrypted data\n    \"\"\"\n    expanded_key = key_expansion(key)\n    block_count = int(ceil(float(len(data)) / BLOCK_SIZE_BYTES))\n    \n    decrypted_data=[]\n    previous_cipher_block = iv\n    for i in range(block_count):\n        block = data[i*BLOCK_SIZE_BYTES : (i+1)*BLOCK_SIZE_BYTES]\n        block += [0]*(BLOCK_SIZE_BYTES - len(block))\n        \n        decrypted_block = aes_decrypt(block, expanded_key)\n        decrypted_data += xor(decrypted_block, previous_cipher_block)\n        previous_cipher_block = block\n    decrypted_data = decrypted_data[:len(data)]\n    \n    return decrypted_data",
        "begin_line": 35,
        "end_line": 58,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.aes.key_expansion#60",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.key_expansion(data)",
        "snippet": "def key_expansion(data):\n    \"\"\"\n    Generate key schedule\n    \n    @param {int[]} data  16/24/32-Byte cipher key\n    @returns {int[]}     176/208/240-Byte expanded key \n    \"\"\"\n    data = data[:] # copy\n    rcon_iteration = 1\n    key_size_bytes = len(data)\n    expanded_key_size_bytes = (key_size_bytes // 4 + 7) * BLOCK_SIZE_BYTES\n    \n    while len(data) < expanded_key_size_bytes:\n        temp = data[-4:]\n        temp = key_schedule_core(temp, rcon_iteration)\n        rcon_iteration += 1\n        data += xor(temp, data[-key_size_bytes : 4-key_size_bytes])\n        \n        for _ in range(3):\n            temp = data[-4:]\n            data += xor(temp, data[-key_size_bytes : 4-key_size_bytes])\n        \n        if key_size_bytes == 32:\n            temp = data[-4:]\n            temp = sub_bytes(temp)\n            data += xor(temp, data[-key_size_bytes : 4-key_size_bytes])\n        \n        for _ in range(3 if key_size_bytes == 32  else 2 if key_size_bytes == 24 else 0):\n            temp = data[-4:]\n            data += xor(temp, data[-key_size_bytes : 4-key_size_bytes])\n    data = data[:expanded_key_size_bytes]\n    \n    return data",
        "begin_line": 60,
        "end_line": 92,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.aes.aes_encrypt#94",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.aes_encrypt(data, expanded_key)",
        "snippet": "def aes_encrypt(data, expanded_key):\n    \"\"\"\n    Encrypt one block with aes\n    \n    @param {int[]} data          16-Byte state\n    @param {int[]} expanded_key  176/208/240-Byte expanded key \n    @returns {int[]}             16-Byte cipher\n    \"\"\"\n    rounds = len(expanded_key) // BLOCK_SIZE_BYTES - 1\n\n    data = xor(data, expanded_key[:BLOCK_SIZE_BYTES])\n    for i in range(1, rounds+1):\n        data = sub_bytes(data)\n        data = shift_rows(data)\n        if i != rounds:\n            data = mix_columns(data)\n        data = xor(data, expanded_key[i*BLOCK_SIZE_BYTES : (i+1)*BLOCK_SIZE_BYTES])\n\n    return data",
        "begin_line": 94,
        "end_line": 112,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.aes.aes_decrypt#114",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.aes_decrypt(data, expanded_key)",
        "snippet": "def aes_decrypt(data, expanded_key):\n    \"\"\"\n    Decrypt one block with aes\n    \n    @param {int[]} data          16-Byte cipher\n    @param {int[]} expanded_key  176/208/240-Byte expanded key\n    @returns {int[]}             16-Byte state\n    \"\"\"\n    rounds = len(expanded_key) // BLOCK_SIZE_BYTES - 1\n    \n    for i in range(rounds, 0, -1):\n        data = xor(data, expanded_key[i*BLOCK_SIZE_BYTES : (i+1)*BLOCK_SIZE_BYTES])\n        if i != rounds:\n            data = mix_columns_inv(data)\n        data = shift_rows_inv(data)\n        data = sub_bytes_inv(data)\n    data = xor(data, expanded_key[:BLOCK_SIZE_BYTES])\n    \n    return data",
        "begin_line": 114,
        "end_line": 132,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.aes.aes_decrypt_text#134",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.aes_decrypt_text(data, password, key_size_bytes)",
        "snippet": "def aes_decrypt_text(data, password, key_size_bytes):\n    \"\"\"\n    Decrypt text\n    - The first 8 Bytes of decoded 'data' are the 8 high Bytes of the counter\n    - The cipher key is retrieved by encrypting the first 16 Byte of 'password'\n      with the first 'key_size_bytes' Bytes from 'password' (if necessary filled with 0's)\n    - Mode of operation is 'counter'\n    \n    @param {str} data                    Base64 encoded string\n    @param {str,unicode} password        Password (will be encoded with utf-8)\n    @param {int} key_size_bytes          Possible values: 16 for 128-Bit, 24 for 192-Bit or 32 for 256-Bit\n    @returns {str}                       Decrypted data\n    \"\"\"\n    NONCE_LENGTH_BYTES = 8\n    \n    data = bytes_to_intlist(base64.b64decode(data))\n    password = bytes_to_intlist(password.encode('utf-8'))\n    \n    key = password[:key_size_bytes] + [0]*(key_size_bytes - len(password))\n    key = aes_encrypt(key[:BLOCK_SIZE_BYTES], key_expansion(key)) * (key_size_bytes // BLOCK_SIZE_BYTES)\n    \n    nonce = data[:NONCE_LENGTH_BYTES]\n    cipher = data[NONCE_LENGTH_BYTES:]\n    \n    class Counter:\n        __value = nonce + [0]*(BLOCK_SIZE_BYTES - NONCE_LENGTH_BYTES)\n        def next_value(self):\n            temp = self.__value\n            self.__value = inc(self.__value)\n            return temp\n    \n    decrypted_data = aes_ctr_decrypt(cipher, key, Counter())\n    plaintext = intlist_to_bytes(decrypted_data)\n    \n    return plaintext",
        "begin_line": 134,
        "end_line": 168,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.aes.sub_bytes#244",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.sub_bytes(data)",
        "snippet": "def sub_bytes(data):\n    return [SBOX[x] for x in data]",
        "begin_line": 244,
        "end_line": 245,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.aes.sub_bytes_inv#247",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.sub_bytes_inv(data)",
        "snippet": "def sub_bytes_inv(data):\n    return [SBOX_INV[x] for x in data]",
        "begin_line": 247,
        "end_line": 248,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.aes.rotate#250",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.rotate(data)",
        "snippet": "def rotate(data):\n    return data[1:] + [data[0]]",
        "begin_line": 250,
        "end_line": 251,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.aes.key_schedule_core#253",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.key_schedule_core(data, rcon_iteration)",
        "snippet": "def key_schedule_core(data, rcon_iteration):\n    data = rotate(data)\n    data = sub_bytes(data)\n    data[0] = data[0] ^ RCON[rcon_iteration]\n    \n    return data",
        "begin_line": 253,
        "end_line": 258,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.aes.xor#260",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.xor(data1, data2)",
        "snippet": "def xor(data1, data2):\n    return [x^y for x, y in zip(data1, data2)]",
        "begin_line": 260,
        "end_line": 261,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.aes.rijndael_mul#263",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.rijndael_mul(a, b)",
        "snippet": "def rijndael_mul(a, b):\n    if(a==0 or b==0):\n        return 0\n    return RIJNDAEL_EXP_TABLE[(RIJNDAEL_LOG_TABLE[a] + RIJNDAEL_LOG_TABLE[b]) % 0xFF]",
        "begin_line": 263,
        "end_line": 266,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.aes.mix_column#268",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.mix_column(data, matrix)",
        "snippet": "def mix_column(data, matrix):\n    data_mixed = []\n    for row in range(4):\n        mixed = 0\n        for column in range(4):\n            # xor is (+) and (-)\n            mixed ^= rijndael_mul(data[column], matrix[row][column])\n        data_mixed.append(mixed)\n    return data_mixed",
        "begin_line": 268,
        "end_line": 276,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.aes.mix_columns#278",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.mix_columns(data, matrix=MIX_COLUMN_MATRIX)",
        "snippet": "def mix_columns(data, matrix=MIX_COLUMN_MATRIX):\n    data_mixed = []\n    for i in range(4):\n        column = data[i*4 : (i+1)*4]\n        data_mixed += mix_column(column, matrix)\n    return data_mixed",
        "begin_line": 278,
        "end_line": 283,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.aes.mix_columns_inv#285",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.mix_columns_inv(data)",
        "snippet": "def mix_columns_inv(data):\n    return mix_columns(data, MIX_COLUMN_MATRIX_INV)",
        "begin_line": 285,
        "end_line": 286,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.aes.shift_rows#288",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.shift_rows(data)",
        "snippet": "def shift_rows(data):\n    data_shifted = []\n    for column in range(4):\n        for row in range(4):\n            data_shifted.append( data[((column + row) & 0b11) * 4 + row] )\n    return data_shifted",
        "begin_line": 288,
        "end_line": 293,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.aes.shift_rows_inv#295",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.shift_rows_inv(data)",
        "snippet": "def shift_rows_inv(data):\n    data_shifted = []\n    for column in range(4):\n        for row in range(4):\n            data_shifted.append( data[((column - row) & 0b11) * 4 + row] )\n    return data_shifted",
        "begin_line": 295,
        "end_line": 300,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.aes.inc#302",
        "src_path": "youtube_dl/aes.py",
        "class_name": "youtube_dl.aes",
        "signature": "youtube_dl.aes.inc(data)",
        "snippet": "def inc(data):\n    data = data[:] # copy\n    for i in range(len(data)-1,-1,-1):\n        if data[i] == 255:\n            data[i] = 0\n        else:\n            data[i] = data[i] + 1\n            break\n    return data",
        "begin_line": 302,
        "end_line": 310,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.cinemassacre.CinemassacreIE._real_extract#35",
        "src_path": "youtube_dl/extractor/cinemassacre.py",
        "class_name": "youtube_dl.extractor.cinemassacre.CinemassacreIE",
        "signature": "youtube_dl.extractor.cinemassacre.CinemassacreIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        webpage = self._download_webpage(url, None)  # Don't know video id yet\n        video_date = mobj.group('date_Y') + mobj.group('date_m') + mobj.group('date_d')\n        mobj = re.search(r'src=\"(?P<embed_url>http://player\\.screenwavemedia\\.com/play/[a-zA-Z]+\\.php\\?id=(?:Cinemassacre-)?(?P<video_id>.+?))\"', webpage)\n        if not mobj:\n            raise ExtractorError('Can\\'t extract embed url and video id')\n        playerdata_url = mobj.group('embed_url')\n        video_id = mobj.group('video_id')\n\n        video_title = self._html_search_regex(r'<title>(?P<title>.+?)\\|',\n            webpage, 'title')\n        video_description = self._html_search_regex(r'<div class=\"entry-content\">(?P<description>.+?)</div>',\n            webpage, 'description', flags=re.DOTALL, fatal=False)\n        if len(video_description) == 0:\n            video_description = None\n\n        playerdata = self._download_webpage(playerdata_url, video_id)\n\n        sd_url = self._html_search_regex(r'file: \\'(?P<sd_file>[^\\']+)\\', label: \\'SD\\'', playerdata, 'sd_file')\n        hd_url = self._html_search_regex(r'file: \\'(?P<hd_file>[^\\']+)\\', label: \\'HD\\'', playerdata, 'hd_file')\n        video_thumbnail = self._html_search_regex(r'image: \\'(?P<thumbnail>[^\\']+)\\'', playerdata, 'thumbnail', fatal=False)\n\n        formats = [\n            {\n                'url': sd_url,\n                'ext': 'mp4',\n                'format': 'sd',\n                'format_id': 'sd',\n            },\n            {\n                'url': hd_url,\n                'ext': 'mp4',\n                'format': 'hd',\n                'format_id': 'hd',\n            },\n        ]\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'formats': formats,\n            'description': video_description,\n            'upload_date': video_date,\n            'thumbnail': video_thumbnail,\n        }",
        "begin_line": 35,
        "end_line": 81,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.ndr.NDRIE._real_extract#42",
        "src_path": "youtube_dl/extractor/ndr.py",
        "class_name": "youtube_dl.extractor.ndr.NDRIE",
        "signature": "youtube_dl.extractor.ndr.NDRIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        page = self._download_webpage(url, video_id, 'Downloading page')\n\n        title = self._og_search_title(page)\n        description = self._og_search_description(page)\n\n        mobj = re.search(\n            r'<div class=\"duration\"><span class=\"min\">(?P<minutes>\\d+)</span>:<span class=\"sec\">(?P<seconds>\\d+)</span></div>',\n            page)\n        duration = int(mobj.group('minutes')) * 60 + int(mobj.group('seconds')) if mobj else None\n\n        formats = []\n\n        mp3_url = re.search(r'''{src:'(?P<audio>[^']+)', type:\"audio/mp3\"},''', page)\n        if mp3_url:\n            formats.append({\n                'url': mp3_url.group('audio'),\n                'format_id': 'mp3',\n            })\n\n        thumbnail = None\n\n        video_url = re.search(r'''3: {src:'(?P<video>.+?)\\.hi\\.mp4', type:\"video/mp4\"},''', page)\n        if video_url:\n            thumbnail = self._html_search_regex(r'(?m)title: \"NDR PLAYER\",\\s*poster: \"([^\"]+)\",',\n                page, 'thumbnail', fatal=False)\n            if thumbnail:\n                thumbnail = 'http://www.ndr.de' + thumbnail\n            for format_id in ['lo', 'hi', 'hq']:\n                formats.append({\n                    'url': '%s.%s.mp4' % (video_url.group('video'), format_id),\n                    'format_id': format_id,\n                })\n\n        if not formats:\n            raise ExtractorError('No media links available for %s' % video_id)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 42,
        "end_line": 89,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.comedycentral.ComedyCentralShowsIE.suitable#83",
        "src_path": "youtube_dl/extractor/comedycentral.py",
        "class_name": "youtube_dl.extractor.comedycentral.ComedyCentralShowsIE",
        "signature": "youtube_dl.extractor.comedycentral.ComedyCentralShowsIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        \"\"\"Receives a URL and returns True if suitable for this IE.\"\"\"\n        return re.match(cls._VALID_URL, url, re.VERBOSE) is not None",
        "begin_line": 83,
        "end_line": 85,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0001584786053882726,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.comedycentral.ComedyCentralShowsIE._real_extract#95",
        "src_path": "youtube_dl/extractor/comedycentral.py",
        "class_name": "youtube_dl.extractor.comedycentral.ComedyCentralShowsIE",
        "signature": "youtube_dl.extractor.comedycentral.ComedyCentralShowsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url, re.VERBOSE)\n        if mobj is None:\n            raise ExtractorError('Invalid URL: %s' % url)\n\n        if mobj.group('shortname'):\n            if mobj.group('shortname') in ('tds', 'thedailyshow'):\n                url = 'http://www.thedailyshow.com/full-episodes/'\n            else:\n                url = 'http://www.colbertnation.com/full-episodes/'\n            mobj = re.match(self._VALID_URL, url, re.VERBOSE)\n            assert mobj is not None\n\n        if mobj.group('clip'):\n            if mobj.group('showname') == 'thedailyshow':\n                epTitle = mobj.group('tdstitle')\n            else:\n                epTitle = mobj.group('cntitle')\n            dlNewest = False\n        elif mobj.group('interview'):\n            epTitle = mobj.group('interview_title')\n            dlNewest = False\n        else:\n            dlNewest = not mobj.group('episode')\n            if dlNewest:\n                epTitle = mobj.group('showname')\n            else:\n                epTitle = mobj.group('episode')\n\n        self.report_extraction(epTitle)\n        webpage,htmlHandle = self._download_webpage_handle(url, epTitle)\n        if dlNewest:\n            url = htmlHandle.geturl()\n            mobj = re.match(self._VALID_URL, url, re.VERBOSE)\n            if mobj is None:\n                raise ExtractorError('Invalid redirected URL: ' + url)\n            if mobj.group('episode') == '':\n                raise ExtractorError('Redirected URL is still not specific: ' + url)\n            epTitle = mobj.group('episode')\n\n        mMovieParams = re.findall('(?:<param name=\"movie\" value=\"|var url = \")(http://media.mtvnservices.com/([^\"]*(?:episode|video).*?:.*?))\"', webpage)\n\n        if len(mMovieParams) == 0:\n            # The Colbert Report embeds the information in a without\n            # a URL prefix; so extract the alternate reference\n            # and then add the URL prefix manually.\n\n            altMovieParams = re.findall('data-mgid=\"([^\"]*(?:episode|video).*?:.*?)\"', webpage)\n            if len(altMovieParams) == 0:\n                raise ExtractorError('unable to find Flash URL in webpage ' + url)\n            else:\n                mMovieParams = [(\"http://media.mtvnservices.com/\" + altMovieParams[0], altMovieParams[0])]\n\n        uri = mMovieParams[0][1]\n        indexUrl = 'http://shadow.comedycentral.com/feeds/video_player/mrss/?' + compat_urllib_parse.urlencode({'uri': uri})\n        idoc = self._download_xml(indexUrl, epTitle,\n                                          'Downloading show index',\n                                          'unable to download episode index')\n\n        results = []\n\n        itemEls = idoc.findall('.//item')\n        for partNum,itemEl in enumerate(itemEls):\n            mediaId = itemEl.findall('./guid')[0].text\n            shortMediaId = mediaId.split(':')[-1]\n            showId = mediaId.split(':')[-2].replace('.com', '')\n            officialTitle = itemEl.findall('./title')[0].text\n            officialDate = unified_strdate(itemEl.findall('./pubDate')[0].text)\n\n            configUrl = ('http://www.comedycentral.com/global/feeds/entertainment/media/mediaGenEntertainment.jhtml?' +\n                        compat_urllib_parse.urlencode({'uri': mediaId}))\n            cdoc = self._download_xml(configUrl, epTitle,\n                                               'Downloading configuration for %s' % shortMediaId)\n\n            turls = []\n            for rendition in cdoc.findall('.//rendition'):\n                finfo = (rendition.attrib['bitrate'], rendition.findall('./src')[0].text)\n                turls.append(finfo)\n\n            if len(turls) == 0:\n                self._downloader.report_error('unable to download ' + mediaId + ': No videos found')\n                continue\n\n            formats = []\n            for format, rtmp_video_url in turls:\n                w, h = self._video_dimensions.get(format, (None, None))\n                formats.append({\n                    'url': self._transform_rtmp_url(rtmp_video_url),\n                    'ext': self._video_extensions.get(format, 'mp4'),\n                    'format_id': format,\n                    'height': h,\n                    'width': w,\n                })\n\n            effTitle = showId + '-' + epTitle + ' part ' + compat_str(partNum+1)\n            results.append({\n                'id': shortMediaId,\n                'formats': formats,\n                'uploader': showId,\n                'upload_date': officialDate,\n                'title': effTitle,\n                'thumbnail': None,\n                'description': compat_str(officialTitle),\n            })\n\n        return results",
        "begin_line": 95,
        "end_line": 200,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.rtmp.RtmpFD.real_download#17",
        "src_path": "youtube_dl/downloader/rtmp.py",
        "class_name": "youtube_dl.downloader.rtmp.RtmpFD",
        "signature": "youtube_dl.downloader.rtmp.RtmpFD.real_download(self, filename, info_dict)",
        "snippet": "    def real_download(self, filename, info_dict):\n        def run_rtmpdump(args):\n            start = time.time()\n            resume_percent = None\n            resume_downloaded_data_len = None\n            proc = subprocess.Popen(args, stderr=subprocess.PIPE)\n            cursor_in_new_line = True\n            proc_stderr_closed = False\n            while not proc_stderr_closed:\n                # read line from stderr\n                line = ''\n                while True:\n                    char = proc.stderr.read(1)\n                    if not char:\n                        proc_stderr_closed = True\n                        break\n                    if char in [b'\\r', b'\\n']:\n                        break\n                    line += char.decode('ascii', 'replace')\n                if not line:\n                    # proc_stderr_closed is True\n                    continue\n                mobj = re.search(r'([0-9]+\\.[0-9]{3}) kB / [0-9]+\\.[0-9]{2} sec \\(([0-9]{1,2}\\.[0-9])%\\)', line)\n                if mobj:\n                    downloaded_data_len = int(float(mobj.group(1))*1024)\n                    percent = float(mobj.group(2))\n                    if not resume_percent:\n                        resume_percent = percent\n                        resume_downloaded_data_len = downloaded_data_len\n                    eta = self.calc_eta(start, time.time(), 100-resume_percent, percent-resume_percent)\n                    speed = self.calc_speed(start, time.time(), downloaded_data_len-resume_downloaded_data_len)\n                    data_len = None\n                    if percent > 0:\n                        data_len = int(downloaded_data_len * 100 / percent)\n                    data_len_str = '~' + format_bytes(data_len)\n                    self.report_progress(percent, data_len_str, speed, eta)\n                    cursor_in_new_line = False\n                    self._hook_progress({\n                        'downloaded_bytes': downloaded_data_len,\n                        'total_bytes': data_len,\n                        'tmpfilename': tmpfilename,\n                        'filename': filename,\n                        'status': 'downloading',\n                        'eta': eta,\n                        'speed': speed,\n                    })\n                else:\n                    # no percent for live streams\n                    mobj = re.search(r'([0-9]+\\.[0-9]{3}) kB / [0-9]+\\.[0-9]{2} sec', line)\n                    if mobj:\n                        downloaded_data_len = int(float(mobj.group(1))*1024)\n                        time_now = time.time()\n                        speed = self.calc_speed(start, time_now, downloaded_data_len)\n                        self.report_progress_live_stream(downloaded_data_len, speed, time_now - start)\n                        cursor_in_new_line = False\n                        self._hook_progress({\n                            'downloaded_bytes': downloaded_data_len,\n                            'tmpfilename': tmpfilename,\n                            'filename': filename,\n                            'status': 'downloading',\n                            'speed': speed,\n                        })\n                    elif self.params.get('verbose', False):\n                        if not cursor_in_new_line:\n                            self.to_screen('')\n                        cursor_in_new_line = True\n                        self.to_screen('[rtmpdump] '+line)\n            proc.wait()\n            if not cursor_in_new_line:\n                self.to_screen('')\n            return proc.returncode\n\n        url = info_dict['url']\n        player_url = info_dict.get('player_url', None)\n        page_url = info_dict.get('page_url', None)\n        app = info_dict.get('app', None)\n        play_path = info_dict.get('play_path', None)\n        tc_url = info_dict.get('tc_url', None)\n        flash_version = info_dict.get('flash_version', None)\n        live = info_dict.get('rtmp_live', False)\n        conn = info_dict.get('rtmp_conn', None)\n\n        self.report_destination(filename)\n        tmpfilename = self.temp_name(filename)\n        test = self.params.get('test', False)\n\n        # Check for rtmpdump first\n        try:\n            subprocess.call(['rtmpdump', '-h'], stdout=(open(os.path.devnull, 'w')), stderr=subprocess.STDOUT)\n        except (OSError, IOError):\n            self.report_error('RTMP download detected but \"rtmpdump\" could not be run')\n            return False\n\n        # Download using rtmpdump. rtmpdump returns exit code 2 when\n        # the connection was interrumpted and resuming appears to be\n        # possible. This is part of rtmpdump's normal usage, AFAIK.\n        basic_args = ['rtmpdump', '--verbose', '-r', url, '-o', tmpfilename]\n        if player_url is not None:\n            basic_args += ['--swfVfy', player_url]\n        if page_url is not None:\n            basic_args += ['--pageUrl', page_url]\n        if app is not None:\n            basic_args += ['--app', app]\n        if play_path is not None:\n            basic_args += ['--playpath', play_path]\n        if tc_url is not None:\n            basic_args += ['--tcUrl', url]\n        if test:\n            basic_args += ['--stop', '1']\n        if flash_version is not None:\n            basic_args += ['--flashVer', flash_version]\n        if live:\n            basic_args += ['--live']\n        if conn:\n            basic_args += ['--conn', conn]\n        args = basic_args + [[], ['--resume', '--skip', '1']][not live and self.params.get('continuedl', False)]\n\n        if sys.platform == 'win32' and sys.version_info < (3, 0):\n            # Windows subprocess module does not actually support Unicode\n            # on Python 2.x\n            # See http://stackoverflow.com/a/9951851/35070\n            subprocess_encoding = sys.getfilesystemencoding()\n            args = [a.encode(subprocess_encoding, 'ignore') for a in args]\n        else:\n            subprocess_encoding = None\n\n        if self.params.get('verbose', False):\n            if subprocess_encoding:\n                str_args = [\n                    a.decode(subprocess_encoding) if isinstance(a, bytes) else a\n                    for a in args]\n            else:\n                str_args = args\n            try:\n                import pipes\n                shell_quote = lambda args: ' '.join(map(pipes.quote, str_args))\n            except ImportError:\n                shell_quote = repr\n            self.to_screen('[debug] rtmpdump command line: ' + shell_quote(str_args))\n\n        RD_SUCCESS = 0\n        RD_FAILED = 1\n        RD_INCOMPLETE = 2\n        RD_NO_CONNECT = 3\n\n        retval = run_rtmpdump(args)\n\n        if retval == RD_NO_CONNECT:\n            self.report_error('[rtmpdump] Could not connect to RTMP server.')\n            return False\n\n        while (retval == RD_INCOMPLETE or retval == RD_FAILED) and not test and not live:\n            prevsize = os.path.getsize(encodeFilename(tmpfilename))\n            self.to_screen('[rtmpdump] %s bytes' % prevsize)\n            time.sleep(5.0) # This seems to be needed\n            retval = run_rtmpdump(basic_args + ['-e'] + [[], ['-k', '1']][retval == RD_FAILED])\n            cursize = os.path.getsize(encodeFilename(tmpfilename))\n            if prevsize == cursize and retval == RD_FAILED:\n                break\n             # Some rtmp streams seem abort after ~ 99.8%. Don't complain for those\n            if prevsize == cursize and retval == RD_INCOMPLETE and cursize > 1024:\n                self.to_screen('[rtmpdump] Could not download the whole video. This can happen for some advertisements.')\n                retval = RD_SUCCESS\n                break\n        if retval == RD_SUCCESS or (test and retval == RD_INCOMPLETE):\n            fsize = os.path.getsize(encodeFilename(tmpfilename))\n            self.to_screen('[rtmpdump] %s bytes' % fsize)\n            self.try_rename(tmpfilename, filename)\n            self._hook_progress({\n                'downloaded_bytes': fsize,\n                'total_bytes': fsize,\n                'filename': filename,\n                'status': 'finished',\n            })\n            return True\n        else:\n            self.to_stderr('\\n')\n            self.report_error('rtmpdump exited with code %d' % retval)\n            return False",
        "begin_line": 17,
        "end_line": 195,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.traileraddict.TrailerAddictIE._real_extract#22",
        "src_path": "youtube_dl/extractor/traileraddict.py",
        "class_name": "youtube_dl.extractor.traileraddict.TrailerAddictIE",
        "signature": "youtube_dl.extractor.traileraddict.TrailerAddictIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        name = mobj.group('movie') + '/' + mobj.group('trailer_name')\n        webpage = self._download_webpage(url, name)\n\n        title = self._search_regex(r'<title>(.+?)</title>',\n                webpage, 'video title').replace(' - Trailer Addict','')\n        view_count_str = self._search_regex(\n            r'<span class=\"views_n\">([0-9,.]+)</span>',\n            webpage, 'view count', fatal=False)\n        view_count = (\n            None if view_count_str is None\n            else int(view_count_str.replace(',', '')))\n        video_id = self._search_regex(\n            r'<param\\s+name=\"movie\"\\s+value=\"/emb/([0-9]+)\"\\s*/>',\n            webpage, 'video id')\n\n        # Presence of (no)watchplus function indicates HD quality is available\n        if re.search(r'function (no)?watchplus()', webpage):\n            fvar = \"fvarhd\"\n        else:\n            fvar = \"fvar\"\n\n        info_url = \"http://www.traileraddict.com/%s.php?tid=%s\" % (fvar, str(video_id))\n        info_webpage = self._download_webpage(info_url, video_id , \"Downloading the info webpage\")\n\n        final_url = self._search_regex(r'&fileurl=(.+)',\n                info_webpage, 'Download url').replace('%3F','?')\n        thumbnail_url = self._search_regex(r'&image=(.+?)&',\n                info_webpage, 'thumbnail url')\n\n        description = self._html_search_regex(\n            r'(?s)<div class=\"synopsis\">.*?<div class=\"movie_label_info\"[^>]*>(.*?)</div>',\n            webpage, 'description', fatal=False)\n\n        return {\n            'id': video_id,\n            'url': final_url,\n            'title': title,\n            'thumbnail': thumbnail_url,\n            'description': description,\n            'view_count': view_count,\n        }",
        "begin_line": 22,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.archiveorg.ArchiveOrgIE._real_extract#28",
        "src_path": "youtube_dl/extractor/archiveorg.py",
        "class_name": "youtube_dl.extractor.archiveorg.ArchiveOrgIE",
        "signature": "youtube_dl.extractor.archiveorg.ArchiveOrgIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        json_url = url + ('?' if '?' in url else '&') + 'output=json'\n        json_data = self._download_webpage(json_url, video_id)\n        data = json.loads(json_data)\n\n        title = data['metadata']['title'][0]\n        description = data['metadata']['description'][0]\n        uploader = data['metadata']['creator'][0]\n        upload_date = unified_strdate(data['metadata']['date'][0])\n\n        formats = [\n            {\n                'format': fdata['format'],\n                'url': 'http://' + data['server'] + data['dir'] + fn,\n                'file_size': int(fdata['size']),\n            }\n            for fn, fdata in data['files'].items()\n            if 'Video' in fdata['format']]\n\n        self._sort_formats(formats)\n\n        return {\n            '_type': 'video',\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'description': description,\n            'uploader': uploader,\n            'upload_date': upload_date,\n            'thumbnail': data.get('misc', {}).get('image'),\n        }",
        "begin_line": 28,
        "end_line": 61,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.metacafe.MetacafeIE.report_disclaimer#86",
        "src_path": "youtube_dl/extractor/metacafe.py",
        "class_name": "youtube_dl.extractor.metacafe.MetacafeIE",
        "signature": "youtube_dl.extractor.metacafe.MetacafeIE.report_disclaimer(self)",
        "snippet": "    def report_disclaimer(self):\n        \"\"\"Report disclaimer retrieval.\"\"\"\n        self.to_screen(u'Retrieving disclaimer')",
        "begin_line": 86,
        "end_line": 88,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.metacafe.MetacafeIE._real_initialize#90",
        "src_path": "youtube_dl/extractor/metacafe.py",
        "class_name": "youtube_dl.extractor.metacafe.MetacafeIE",
        "signature": "youtube_dl.extractor.metacafe.MetacafeIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        # Retrieve disclaimer\n        self.report_disclaimer()\n        self._download_webpage(self._DISCLAIMER, None, False, u'Unable to retrieve disclaimer')\n\n        # Confirm age\n        disclaimer_form = {\n            'filters': '0',\n            'submit': \"Continue - I'm over 18\",\n            }\n        request = compat_urllib_request.Request(self._FILTER_POST, compat_urllib_parse.urlencode(disclaimer_form))\n        request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        self.report_age_confirmation()\n        self._download_webpage(request, None, False, u'Unable to confirm age')",
        "begin_line": 90,
        "end_line": 103,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.metacafe.MetacafeIE._real_extract#105",
        "src_path": "youtube_dl/extractor/metacafe.py",
        "class_name": "youtube_dl.extractor.metacafe.MetacafeIE",
        "signature": "youtube_dl.extractor.metacafe.MetacafeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        # Extract id and simplified title from URL\n        mobj = re.match(self._VALID_URL, url)\n        if mobj is None:\n            raise ExtractorError(u'Invalid URL: %s' % url)\n\n        video_id = mobj.group(1)\n\n        # the video may come from an external site\n        m_external = re.match('^(\\w{2})-(.*)$', video_id)\n        if m_external is not None:\n            prefix, ext_id = m_external.groups()\n            # Check if video comes from YouTube\n            if prefix == 'yt':\n                return self.url_result('http://www.youtube.com/watch?v=%s' % ext_id, 'Youtube')\n            # CBS videos use theplatform.com\n            if prefix == 'cb':\n                return self.url_result('theplatform:%s' % ext_id, 'ThePlatform')\n\n        # Retrieve video webpage to extract further information\n        req = compat_urllib_request.Request('http://www.metacafe.com/watch/%s/' % video_id)\n\n        # AnyClip videos require the flashversion cookie so that we get the link\n        # to the mp4 file\n        mobj_an = re.match(r'^an-(.*?)$', video_id)\n        if mobj_an:\n            req.headers['Cookie'] = 'flashVersion=0;'\n        webpage = self._download_webpage(req, video_id)\n\n        # Extract URL, uploader and title from webpage\n        self.report_extraction(video_id)\n        mobj = re.search(r'(?m)&mediaURL=([^&]+)', webpage)\n        if mobj is not None:\n            mediaURL = compat_urllib_parse.unquote(mobj.group(1))\n            video_ext = mediaURL[-3:]\n\n            # Extract gdaKey if available\n            mobj = re.search(r'(?m)&gdaKey=(.*?)&', webpage)\n            if mobj is None:\n                video_url = mediaURL\n            else:\n                gdaKey = mobj.group(1)\n                video_url = '%s?__gda__=%s' % (mediaURL, gdaKey)\n        else:\n            mobj = re.search(r'<video src=\"([^\"]+)\"', webpage)\n            if mobj:\n                video_url = mobj.group(1)\n                video_ext = 'mp4'\n            else:\n                mobj = re.search(r' name=\"flashvars\" value=\"(.*?)\"', webpage)\n                if mobj is None:\n                    raise ExtractorError(u'Unable to extract media URL')\n                vardict = compat_parse_qs(mobj.group(1))\n                if 'mediaData' not in vardict:\n                    raise ExtractorError(u'Unable to extract media URL')\n                mobj = re.search(r'\"mediaURL\":\"(?P<mediaURL>http.*?)\",(.*?)\"key\":\"(?P<key>.*?)\"', vardict['mediaData'][0])\n                if mobj is None:\n                    raise ExtractorError(u'Unable to extract media URL')\n                mediaURL = mobj.group('mediaURL').replace('\\\\/', '/')\n                video_url = '%s?__gda__=%s' % (mediaURL, mobj.group('key'))\n                video_ext = determine_ext(video_url)\n\n        video_title = self._html_search_regex(r'(?im)<title>(.*) - Video</title>', webpage, u'title')\n        description = self._og_search_description(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n        video_uploader = self._html_search_regex(\n                r'submitter=(.*?);|googletag\\.pubads\\(\\)\\.setTargeting\\(\"(?:channel|submiter)\",\"([^\"]+)\"\\);',\n                webpage, u'uploader nickname', fatal=False)\n\n        if re.search(r'\"contentRating\":\"restricted\"', webpage) is not None:\n            age_limit = 18\n        else:\n            age_limit = 0\n\n        return {\n            '_type':    'video',\n            'id':       video_id,\n            'url':      video_url,\n            'description': description,\n            'uploader': video_uploader,\n            'upload_date':  None,\n            'title':    video_title,\n            'thumbnail':thumbnail,\n            'ext':      video_ext,\n            'age_limit': age_limit,\n        }",
        "begin_line": 105,
        "end_line": 190,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.canal13cl.Canal13clIE._real_extract#23",
        "src_path": "youtube_dl/extractor/canal13cl.py",
        "class_name": "youtube_dl.extractor.canal13cl.Canal13clIE",
        "signature": "youtube_dl.extractor.canal13cl.Canal13clIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        title = self._html_search_meta(\n            'twitter:title', webpage, 'title', fatal=True)\n        description = self._html_search_meta(\n            'twitter:description', webpage, 'description')\n        url = self._html_search_regex(\n            r'articuloVideo = \\\"(.*?)\\\"', webpage, 'url')\n        real_id = self._search_regex(\n            r'[^0-9]([0-9]{7,})[^0-9]', url, 'id', default=display_id)\n        thumbnail = self._html_search_regex(\n            r'articuloImagen = \\\"(.*?)\\\"', webpage, 'thumbnail')\n\n        return {\n            'id': real_id,\n            'display_id': display_id,\n            'url': url,\n            'title': title,\n            'description': description,\n            'ext': 'mp4',\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 23,
        "end_line": 48,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.discovery.DiscoveryIE._real_extract#25",
        "src_path": "youtube_dl/extractor/discovery.py",
        "class_name": "youtube_dl.extractor.discovery.DiscoveryIE",
        "signature": "youtube_dl.extractor.discovery.DiscoveryIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n\n        video_list_json = self._search_regex(r'var videoListJSON = ({.*?});',\n            webpage, 'video list', flags=re.DOTALL)\n        video_list = json.loads(video_list_json)\n        info = video_list['clips'][0]\n        formats = []\n        for f in info['mp4']:\n            formats.append(\n                {'url': f['src'], r'ext': r'mp4', 'tbr': int(f['bitrate'][:-1])})\n\n        return {\n            'id': info['contentId'],\n            'title': video_list['name'],\n            'formats': formats,\n            'description': info['videoCaption'],\n            'thumbnail': info.get('videoStillURL') or info.get('thumbnailURL'),\n            'duration': info['duration'],\n        }",
        "begin_line": 25,
        "end_line": 46,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoIE._login#104",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoIE._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n        self.report_login()\n        login_url = 'https://vimeo.com/log_in'\n        webpage = self._download_webpage(login_url, None, False)\n        token = self._search_regex(r'xsrft: \\'(.*?)\\'', webpage, 'login token')\n        data = compat_urllib_parse.urlencode({'email': username,\n                                              'password': password,\n                                              'action': 'login',\n                                              'service': 'vimeo',\n                                              'token': token,\n                                              })\n        login_request = compat_urllib_request.Request(login_url, data)\n        login_request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        login_request.add_header('Cookie', 'xsrft=%s' % token)\n        self._download_webpage(login_request, None, False, 'Wrong login info')",
        "begin_line": 104,
        "end_line": 121,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoIE._verify_video_password#123",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoIE._verify_video_password(self, url, video_id, webpage)",
        "snippet": "    def _verify_video_password(self, url, video_id, webpage):\n        password = self._downloader.params.get('videopassword', None)\n        if password is None:\n            raise ExtractorError('This video is protected by a password, use the --video-password option')\n        token = self._search_regex(r'xsrft: \\'(.*?)\\'', webpage, 'login token')\n        data = compat_urllib_parse.urlencode({'password': password,\n                                              'token': token})\n        # I didn't manage to use the password with https\n        if url.startswith('https'):\n            pass_url = url.replace('https','http')\n        else:\n            pass_url = url\n        password_request = compat_urllib_request.Request(pass_url+'/password', data)\n        password_request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        password_request.add_header('Cookie', 'xsrft=%s' % token)\n        self._download_webpage(password_request, video_id,\n                               'Verifying the password',\n                               'Wrong password')",
        "begin_line": 123,
        "end_line": 140,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoIE._verify_player_video_password#142",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoIE._verify_player_video_password(self, url, video_id)",
        "snippet": "    def _verify_player_video_password(self, url, video_id):\n        password = self._downloader.params.get('videopassword', None)\n        if password is None:\n            raise ExtractorError('This video is protected by a password, use the --video-password option')\n        data = compat_urllib_parse.urlencode({'password': password})\n        pass_url = url + '/check-password'\n        password_request = compat_urllib_request.Request(pass_url, data)\n        password_request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        return self._download_json(\n            password_request, video_id,\n            'Verifying the password',\n            'Wrong password')",
        "begin_line": 142,
        "end_line": 153,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoIE._real_initialize#155",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 155,
        "end_line": 156,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoIE._real_extract#158",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        url, data = unsmuggle_url(url)\n        headers = std_headers\n        if data is not None:\n            headers = headers.copy()\n            headers.update(data)\n\n        # Extract ID from URL\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        if mobj.group('pro') or mobj.group('player'):\n            url = 'http://player.vimeo.com/video/' + video_id\n        else:\n            url = 'https://vimeo.com/' + video_id\n\n        # Retrieve video webpage to extract further information\n        request = compat_urllib_request.Request(url, None, headers)\n        webpage = self._download_webpage(request, video_id)\n\n        # Now we begin extracting as much information as we can from what we\n        # retrieved. First we extract the information common to all extractors,\n        # and latter we extract those that are Vimeo specific.\n        self.report_extraction(video_id)\n\n        # Extract the config JSON\n        try:\n            try:\n                config_url = self._html_search_regex(\n                    r' data-config-url=\"(.+?)\"', webpage, 'config URL')\n                config_json = self._download_webpage(config_url, video_id)\n                config = json.loads(config_json)\n            except RegexNotFoundError:\n                # For pro videos or player.vimeo.com urls\n                # We try to find out to which variable is assigned the config dic\n                m_variable_name = re.search('(\\w)\\.video\\.id', webpage)\n                if m_variable_name is not None:\n                    config_re = r'%s=({.+?});' % re.escape(m_variable_name.group(1))\n                else:\n                    config_re = [r' = {config:({.+?}),assets:', r'(?:[abc])=({.+?});']\n                config = self._search_regex(config_re, webpage, 'info section',\n                    flags=re.DOTALL)\n                config = json.loads(config)\n        except Exception as e:\n            if re.search('The creator of this video has not given you permission to embed it on this domain.', webpage):\n                raise ExtractorError('The author has restricted the access to this video, try with the \"--referer\" option')\n\n            if re.search('<form[^>]+?id=\"pw_form\"', webpage) is not None:\n                self._verify_video_password(url, video_id, webpage)\n                return self._real_extract(url)\n            else:\n                raise ExtractorError('Unable to extract info section',\n                                     cause=e)\n        else:\n            if config.get('view') == 4:\n                config = self._verify_player_video_password(url, video_id)\n\n        # Extract title\n        video_title = config[\"video\"][\"title\"]\n\n        # Extract uploader and uploader_id\n        video_uploader = config[\"video\"][\"owner\"][\"name\"]\n        video_uploader_id = config[\"video\"][\"owner\"][\"url\"].split('/')[-1] if config[\"video\"][\"owner\"][\"url\"] else None\n\n        # Extract video thumbnail\n        video_thumbnail = config[\"video\"].get(\"thumbnail\")\n        if video_thumbnail is None:\n            video_thumbs = config[\"video\"].get(\"thumbs\")\n            if video_thumbs and isinstance(video_thumbs, dict):\n                _, video_thumbnail = sorted((int(width), t_url) for (width, t_url) in video_thumbs.items())[-1]\n\n        # Extract video description\n        video_description = None\n        try:\n            video_description = get_element_by_attribute(\"itemprop\", \"description\", webpage)\n            if video_description: video_description = clean_html(video_description)\n        except AssertionError as err:\n            # On some pages like (http://player.vimeo.com/video/54469442) the\n            # html tags are not closed, python 2.6 cannot handle it\n            if err.args[0] == 'we should not get here!':\n                pass\n            else:\n                raise\n\n        # Extract upload date\n        video_upload_date = None\n        mobj = re.search(r'<meta itemprop=\"dateCreated\" content=\"(\\d{4})-(\\d{2})-(\\d{2})T', webpage)\n        if mobj is not None:\n            video_upload_date = mobj.group(1) + mobj.group(2) + mobj.group(3)\n\n        try:\n            view_count = int(self._search_regex(r'UserPlays:(\\d+)', webpage, 'view count'))\n            like_count = int(self._search_regex(r'UserLikes:(\\d+)', webpage, 'like count'))\n            comment_count = int(self._search_regex(r'UserComments:(\\d+)', webpage, 'comment count'))\n        except RegexNotFoundError:\n            # This info is only available in vimeo.com/{id} urls\n            view_count = None\n            like_count = None\n            comment_count = None\n\n        # Vimeo specific: extract request signature and timestamp\n        sig = config['request']['signature']\n        timestamp = config['request']['timestamp']\n\n        # Vimeo specific: extract video codec and quality information\n        # First consider quality, then codecs, then take everything\n        codecs = [('vp6', 'flv'), ('vp8', 'flv'), ('h264', 'mp4')]\n        files = {'hd': [], 'sd': [], 'other': []}\n        config_files = config[\"video\"].get(\"files\") or config[\"request\"].get(\"files\")\n        for codec_name, codec_extension in codecs:\n            for quality in config_files.get(codec_name, []):\n                format_id = '-'.join((codec_name, quality)).lower()\n                key = quality if quality in files else 'other'\n                video_url = None\n                if isinstance(config_files[codec_name], dict):\n                    file_info = config_files[codec_name][quality]\n                    video_url = file_info.get('url')\n                else:\n                    file_info = {}\n                if video_url is None:\n                    video_url = \"http://player.vimeo.com/play_redirect?clip_id=%s&sig=%s&time=%s&quality=%s&codecs=%s&type=moogaloop_local&embed_location=\" \\\n                        %(video_id, sig, timestamp, quality, codec_name.upper())\n\n                files[key].append({\n                    'ext': codec_extension,\n                    'url': video_url,\n                    'format_id': format_id,\n                    'width': file_info.get('width'),\n                    'height': file_info.get('height'),\n                })\n        formats = []\n        for key in ('other', 'sd', 'hd'):\n            formats += files[key]\n        if len(formats) == 0:\n            raise ExtractorError('No known codec found')\n\n        subtitles = {}\n        text_tracks = config['request'].get('text_tracks')\n        if text_tracks:\n            for tt in text_tracks:\n                subtitles[tt['lang']] = 'http://vimeo.com' + tt['url']\n\n        video_subtitles = self.extract_subtitles(video_id, subtitles)\n        if self._downloader.params.get('listsubtitles', False):\n            self._list_available_subtitles(video_id, subtitles)\n            return\n\n        return {\n            'id': video_id,\n            'uploader': video_uploader,\n            'uploader_id': video_uploader_id,\n            'upload_date': video_upload_date,\n            'title': video_title,\n            'thumbnail': video_thumbnail,\n            'description': video_description,\n            'formats': formats,\n            'webpage_url': url,\n            'view_count': view_count,\n            'like_count': like_count,\n            'comment_count': comment_count,\n            'subtitles': video_subtitles,\n        }",
        "begin_line": 158,
        "end_line": 318,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoChannelIE._page_url#327",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoChannelIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoChannelIE._page_url(self, base_url, pagenum)",
        "snippet": "    def _page_url(self, base_url, pagenum):\n        return '%s/videos/page:%d/' % (base_url, pagenum)",
        "begin_line": 327,
        "end_line": 328,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoChannelIE._extract_list_title#330",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoChannelIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoChannelIE._extract_list_title(self, webpage)",
        "snippet": "    def _extract_list_title(self, webpage):\n        return self._html_search_regex(self._TITLE_RE, webpage, 'list title')",
        "begin_line": 330,
        "end_line": 331,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoChannelIE._extract_videos#333",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoChannelIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoChannelIE._extract_videos(self, list_id, base_url)",
        "snippet": "    def _extract_videos(self, list_id, base_url):\n        video_ids = []\n        for pagenum in itertools.count(1):\n            webpage = self._download_webpage(\n                self._page_url(base_url, pagenum) ,list_id,\n                'Downloading page %s' % pagenum)\n            video_ids.extend(re.findall(r'id=\"clip_(\\d+?)\"', webpage))\n            if re.search(self._MORE_PAGES_INDICATOR, webpage, re.DOTALL) is None:\n                break\n\n        entries = [self.url_result('http://vimeo.com/%s' % video_id, 'Vimeo')\n                   for video_id in video_ids]\n        return {'_type': 'playlist',\n                'id': list_id,\n                'title': self._extract_list_title(webpage),\n                'entries': entries,\n                }",
        "begin_line": 333,
        "end_line": 349,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoChannelIE._real_extract#351",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoChannelIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        channel_id =  mobj.group('id')\n        return self._extract_videos(channel_id, 'http://vimeo.com/channels/%s' % channel_id)",
        "begin_line": 351,
        "end_line": 354,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoUserIE.suitable#363",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoUserIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoUserIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        if VimeoChannelIE.suitable(url) or VimeoIE.suitable(url) or VimeoAlbumIE.suitable(url) or VimeoGroupsIE.suitable(url):\n            return False\n        return super(VimeoUserIE, cls).suitable(url)",
        "begin_line": 363,
        "end_line": 366,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.002369668246445498,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoUserIE._real_extract#368",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoUserIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        name = mobj.group('name')\n        return self._extract_videos(name, 'http://vimeo.com/%s' % name)",
        "begin_line": 368,
        "end_line": 371,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoAlbumIE._page_url#379",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoAlbumIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoAlbumIE._page_url(self, base_url, pagenum)",
        "snippet": "    def _page_url(self, base_url, pagenum):\n        return '%s/page:%d/' % (base_url, pagenum)",
        "begin_line": 379,
        "end_line": 380,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoAlbumIE._real_extract#382",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoAlbumIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoAlbumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        album_id = mobj.group('id')\n        return self._extract_videos(album_id, 'http://vimeo.com/album/%s' % album_id)",
        "begin_line": 382,
        "end_line": 385,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoGroupsIE._extract_list_title#392",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoGroupsIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoGroupsIE._extract_list_title(self, webpage)",
        "snippet": "    def _extract_list_title(self, webpage):\n        return self._og_search_title(webpage)",
        "begin_line": 392,
        "end_line": 393,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoGroupsIE._real_extract#395",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoGroupsIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoGroupsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        name = mobj.group('name')\n        return self._extract_videos(name, 'http://vimeo.com/groups/%s' % name)",
        "begin_line": 395,
        "end_line": 398,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.vimeo.VimeoReviewIE._real_extract#415",
        "src_path": "youtube_dl/extractor/vimeo.py",
        "class_name": "youtube_dl.extractor.vimeo.VimeoReviewIE",
        "signature": "youtube_dl.extractor.vimeo.VimeoReviewIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        player_url = 'https://player.vimeo.com/player/' + video_id\n        return self.url_result(player_url, 'Vimeo', video_id)",
        "begin_line": 415,
        "end_line": 419,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.__init__#176",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.__init__(self, params=None)",
        "snippet": "    def __init__(self, params=None):\n        \"\"\"Create a FileDownloader object with the given options.\"\"\"\n        if params is None:\n            params = {}\n        self._ies = []\n        self._ies_instances = {}\n        self._pps = []\n        self._progress_hooks = []\n        self._download_retcode = 0\n        self._num_downloads = 0\n        self._screen_file = [sys.stdout, sys.stderr][params.get('logtostderr', False)]\n        self._err_file = sys.stderr\n        self.params = params\n\n        if params.get('bidi_workaround', False):\n            try:\n                import pty\n                master, slave = pty.openpty()\n                width = get_term_width()\n                if width is None:\n                    width_args = []\n                else:\n                    width_args = ['-w', str(width)]\n                sp_kwargs = dict(\n                    stdin=subprocess.PIPE,\n                    stdout=slave,\n                    stderr=self._err_file)\n                try:\n                    self._output_process = subprocess.Popen(\n                        ['bidiv'] + width_args, **sp_kwargs\n                    )\n                except OSError:\n                    self._output_process = subprocess.Popen(\n                        ['fribidi', '-c', 'UTF-8'] + width_args, **sp_kwargs)\n                self._output_channel = os.fdopen(master, 'rb')\n            except OSError as ose:\n                if ose.errno == 2:\n                    self.report_warning('Could not find fribidi executable, ignoring --bidi-workaround . Make sure that  fribidi  is an executable file in one of the directories in your $PATH.')\n                else:\n                    raise\n\n        if (sys.version_info >= (3,) and sys.platform != 'win32' and\n                sys.getfilesystemencoding() in ['ascii', 'ANSI_X3.4-1968']\n                and not params['restrictfilenames']):\n            # On Python 3, the Unicode filesystem API will throw errors (#1474)\n            self.report_warning(\n                'Assuming --restrict-filenames since file system encoding '\n                'cannot encode all charactes. '\n                'Set the LC_ALL environment variable to fix this.')\n            self.params['restrictfilenames'] = True\n\n        if '%(stitle)s' in self.params.get('outtmpl', ''):\n            self.report_warning('%(stitle)s is deprecated. Use the %(title)s and the --restrict-filenames flag(which also secures %(uploader)s et al) instead.')\n\n        self._setup_opener()",
        "begin_line": 176,
        "end_line": 230,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0625,
            "pseudo_dstar_susp": 0.0625,
            "pseudo_tarantula_susp": 0.041666666666666664,
            "pseudo_op2_susp": 0.0625,
            "pseudo_barinel_susp": 0.041666666666666664
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.add_info_extractor#232",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.add_info_extractor(self, ie)",
        "snippet": "    def add_info_extractor(self, ie):\n        \"\"\"Add an InfoExtractor object to the end of the list.\"\"\"\n        self._ies.append(ie)\n        self._ies_instances[ie.ie_key()] = ie\n        ie.set_downloader(self)",
        "begin_line": 232,
        "end_line": 236,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.get_info_extractor#238",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.get_info_extractor(self, ie_key)",
        "snippet": "    def get_info_extractor(self, ie_key):\n        \"\"\"\n        Get an instance of an IE with name ie_key, it will try to get one from\n        the _ies list, if there's no instance it will create a new one and add\n        it to the extractor list.\n        \"\"\"\n        ie = self._ies_instances.get(ie_key)\n        if ie is None:\n            ie = get_info_extractor(ie_key)()\n            self.add_info_extractor(ie)\n        return ie",
        "begin_line": 238,
        "end_line": 248,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.add_default_info_extractors#250",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.add_default_info_extractors(self)",
        "snippet": "    def add_default_info_extractors(self):\n        \"\"\"\n        Add the InfoExtractors returned by gen_extractors to the end of the list\n        \"\"\"\n        for ie in gen_extractors():\n            self.add_info_extractor(ie)",
        "begin_line": 250,
        "end_line": 255,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.add_post_processor#257",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.add_post_processor(self, pp)",
        "snippet": "    def add_post_processor(self, pp):\n        \"\"\"Add a PostProcessor object to the end of the chain.\"\"\"\n        self._pps.append(pp)\n        pp.set_downloader(self)",
        "begin_line": 257,
        "end_line": 260,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.add_progress_hook#262",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.add_progress_hook(self, ph)",
        "snippet": "    def add_progress_hook(self, ph):\n        \"\"\"Add the progress hook (currently only for the file downloader)\"\"\"\n        self._progress_hooks.append(ph)",
        "begin_line": 262,
        "end_line": 264,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._bidi_workaround#266",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._bidi_workaround(self, message)",
        "snippet": "    def _bidi_workaround(self, message):\n        if not hasattr(self, '_output_channel'):\n            return message\n\n        assert hasattr(self, '_output_process')\n        assert type(message) == type('')\n        line_count = message.count('\\n') + 1\n        self._output_process.stdin.write((message + '\\n').encode('utf-8'))\n        self._output_process.stdin.flush()\n        res = ''.join(self._output_channel.readline().decode('utf-8')\n                       for _ in range(line_count))\n        return res[:-len('\\n')]",
        "begin_line": 266,
        "end_line": 277,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.to_screen#279",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.to_screen(self, message, skip_eol=False)",
        "snippet": "    def to_screen(self, message, skip_eol=False):\n        \"\"\"Print message to stdout if not in quiet mode.\"\"\"\n        return self.to_stdout(message, skip_eol, check_quiet=True)",
        "begin_line": 279,
        "end_line": 281,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.to_stdout#283",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.to_stdout(self, message, skip_eol=False, check_quiet=False)",
        "snippet": "    def to_stdout(self, message, skip_eol=False, check_quiet=False):\n        \"\"\"Print message to stdout if not in quiet mode.\"\"\"\n        if self.params.get('logger'):\n            self.params['logger'].debug(message)\n        elif not check_quiet or not self.params.get('quiet', False):\n            message = self._bidi_workaround(message)\n            terminator = ['\\n', ''][skip_eol]\n            output = message + terminator\n\n            write_string(output, self._screen_file)",
        "begin_line": 283,
        "end_line": 292,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.to_stderr#294",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.to_stderr(self, message)",
        "snippet": "    def to_stderr(self, message):\n        \"\"\"Print message to stderr.\"\"\"\n        assert type(message) == type('')\n        if self.params.get('logger'):\n            self.params['logger'].error(message)\n        else:\n            message = self._bidi_workaround(message)\n            output = message + '\\n'\n            write_string(output, self._err_file)",
        "begin_line": 294,
        "end_line": 302,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.to_console_title#304",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.to_console_title(self, message)",
        "snippet": "    def to_console_title(self, message):\n        if not self.params.get('consoletitle', False):\n            return\n        if os.name == 'nt' and ctypes.windll.kernel32.GetConsoleWindow():\n            # c_wchar_p() might not be necessary if `message` is\n            # already of type unicode()\n            ctypes.windll.kernel32.SetConsoleTitleW(ctypes.c_wchar_p(message))\n        elif 'TERM' in os.environ:\n            write_string('\\033]0;%s\\007' % message, self._screen_file)",
        "begin_line": 304,
        "end_line": 312,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.save_console_title#314",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.save_console_title(self)",
        "snippet": "    def save_console_title(self):\n        if not self.params.get('consoletitle', False):\n            return\n        if 'TERM' in os.environ:\n            # Save the title on stack\n            write_string('\\033[22;0t', self._screen_file)",
        "begin_line": 314,
        "end_line": 319,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.restore_console_title#321",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.restore_console_title(self)",
        "snippet": "    def restore_console_title(self):\n        if not self.params.get('consoletitle', False):\n            return\n        if 'TERM' in os.environ:\n            # Restore the title from stack\n            write_string('\\033[23;0t', self._screen_file)",
        "begin_line": 321,
        "end_line": 326,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.__enter__#328",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.__enter__(self)",
        "snippet": "    def __enter__(self):\n        self.save_console_title()\n        return self",
        "begin_line": 328,
        "end_line": 330,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.__exit__#332",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.__exit__(self, *args)",
        "snippet": "    def __exit__(self, *args):\n        self.restore_console_title()\n\n        if self.params.get('cookiefile') is not None:\n            self.cookiejar.save()",
        "begin_line": 332,
        "end_line": 336,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.trouble#338",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.trouble(self, message=None, tb=None)",
        "snippet": "    def trouble(self, message=None, tb=None):\n        \"\"\"Determine action to take when a download problem appears.\n\n        Depending on if the downloader has been configured to ignore\n        download errors or not, this method may throw an exception or\n        not when errors are found, after printing the message.\n\n        tb, if given, is additional traceback information.\n        \"\"\"\n        if message is not None:\n            self.to_stderr(message)\n        if self.params.get('verbose'):\n            if tb is None:\n                if sys.exc_info()[0]:  # if .trouble has been called from an except block\n                    tb = ''\n                    if hasattr(sys.exc_info()[1], 'exc_info') and sys.exc_info()[1].exc_info[0]:\n                        tb += ''.join(traceback.format_exception(*sys.exc_info()[1].exc_info))\n                    tb += compat_str(traceback.format_exc())\n                else:\n                    tb_data = traceback.format_list(traceback.extract_stack())\n                    tb = ''.join(tb_data)\n            self.to_stderr(tb)\n        if not self.params.get('ignoreerrors', False):\n            if sys.exc_info()[0] and hasattr(sys.exc_info()[1], 'exc_info') and sys.exc_info()[1].exc_info[0]:\n                exc_info = sys.exc_info()[1].exc_info\n            else:\n                exc_info = sys.exc_info()\n            raise DownloadError(message, exc_info)\n        self._download_retcode = 1",
        "begin_line": 338,
        "end_line": 366,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.report_warning#368",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.report_warning(self, message)",
        "snippet": "    def report_warning(self, message):\n        '''\n        Print the message to stderr, it will be prefixed with 'WARNING:'\n        If stderr is a tty file the 'WARNING:' will be colored\n        '''\n        if self._err_file.isatty() and os.name != 'nt':\n            _msg_header = '\\033[0;33mWARNING:\\033[0m'\n        else:\n            _msg_header = 'WARNING:'\n        warning_message = '%s %s' % (_msg_header, message)\n        self.to_stderr(warning_message)",
        "begin_line": 368,
        "end_line": 378,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.report_error#380",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.report_error(self, message, tb=None)",
        "snippet": "    def report_error(self, message, tb=None):\n        '''\n        Do the same as trouble, but prefixes the message with 'ERROR:', colored\n        in red if stderr is a tty file.\n        '''\n        if self._err_file.isatty() and os.name != 'nt':\n            _msg_header = '\\033[0;31mERROR:\\033[0m'\n        else:\n            _msg_header = 'ERROR:'\n        error_message = '%s %s' % (_msg_header, message)\n        self.trouble(error_message, tb)",
        "begin_line": 380,
        "end_line": 390,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.report_file_already_downloaded#392",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.report_file_already_downloaded(self, file_name)",
        "snippet": "    def report_file_already_downloaded(self, file_name):\n        \"\"\"Report file has already been fully downloaded.\"\"\"\n        try:\n            self.to_screen('[download] %s has already been downloaded' % file_name)\n        except UnicodeEncodeError:\n            self.to_screen('[download] The file has already been downloaded')",
        "begin_line": 392,
        "end_line": 397,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.prepare_filename#399",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.prepare_filename(self, info_dict)",
        "snippet": "    def prepare_filename(self, info_dict):\n        \"\"\"Generate the output filename.\"\"\"\n        try:\n            template_dict = dict(info_dict)\n\n            template_dict['epoch'] = int(time.time())\n            autonumber_size = self.params.get('autonumber_size')\n            if autonumber_size is None:\n                autonumber_size = 5\n            autonumber_templ = '%0' + str(autonumber_size) + 'd'\n            template_dict['autonumber'] = autonumber_templ % self._num_downloads\n            if template_dict.get('playlist_index') is not None:\n                template_dict['playlist_index'] = '%05d' % template_dict['playlist_index']\n            if template_dict.get('resolution') is None:\n                if template_dict.get('width') and template_dict.get('height'):\n                    template_dict['resolution'] = '%dx%d' % (template_dict['width'], template_dict['height'])\n                elif template_dict.get('height'):\n                    res = '%sp' % template_dict['height']\n                elif template_dict.get('width'):\n                    res = '?x%d' % template_dict['width']\n\n            sanitize = lambda k, v: sanitize_filename(\n                compat_str(v),\n                restricted=self.params.get('restrictfilenames'),\n                is_id=(k == 'id'))\n            template_dict = dict((k, sanitize(k, v))\n                                 for k, v in template_dict.items()\n                                 if v is not None)\n            template_dict = collections.defaultdict(lambda: 'NA', template_dict)\n\n            tmpl = os.path.expanduser(self.params['outtmpl'])\n            filename = tmpl % template_dict\n            return filename\n        except ValueError as err:\n            self.report_error('Error in output template: ' + str(err) + ' (encoding: ' + repr(preferredencoding()) + ')')\n            return None",
        "begin_line": 399,
        "end_line": 434,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._match_entry#436",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._match_entry(self, info_dict)",
        "snippet": "    def _match_entry(self, info_dict):\n        \"\"\" Returns None iff the file should be downloaded \"\"\"\n\n        video_title = info_dict.get('title', info_dict.get('id', 'video'))\n        if 'title' in info_dict:\n            # This can happen when we're just evaluating the playlist\n            title = info_dict['title']\n            matchtitle = self.params.get('matchtitle', False)\n            if matchtitle:\n                if not re.search(matchtitle, title, re.IGNORECASE):\n                    return '\"' + title + '\" title did not match pattern \"' + matchtitle + '\"'\n            rejecttitle = self.params.get('rejecttitle', False)\n            if rejecttitle:\n                if re.search(rejecttitle, title, re.IGNORECASE):\n                    return '\"' + title + '\" title matched reject pattern \"' + rejecttitle + '\"'\n        date = info_dict.get('upload_date', None)\n        if date is not None:\n            dateRange = self.params.get('daterange', DateRange())\n            if date not in dateRange:\n                return '%s upload date is not in range %s' % (date_from_str(date).isoformat(), dateRange)\n        view_count = info_dict.get('view_count', None)\n        if view_count is not None:\n            min_views = self.params.get('min_views')\n            if min_views is not None and view_count < min_views:\n                return 'Skipping %s, because it has not reached minimum view count (%d/%d)' % (video_title, view_count, min_views)\n            max_views = self.params.get('max_views')\n            if max_views is not None and view_count > max_views:\n                return 'Skipping %s, because it has exceeded the maximum view count (%d/%d)' % (video_title, view_count, max_views)\n        age_limit = self.params.get('age_limit')\n        if age_limit is not None:\n            if age_limit < info_dict.get('age_limit', 0):\n                return 'Skipping \"' + title + '\" because it is age restricted'\n        if self.in_download_archive(info_dict):\n            return '%s has already been recorded in archive' % video_title\n        return None",
        "begin_line": 436,
        "end_line": 470,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.add_extra_info#473",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.add_extra_info(info_dict, extra_info)",
        "snippet": "    def add_extra_info(info_dict, extra_info):\n        '''Set the keys from extra_info in info dict if they are missing'''\n        for key, value in extra_info.items():\n            info_dict.setdefault(key, value)",
        "begin_line": 473,
        "end_line": 476,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.006711409395973154,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.extract_info#478",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.extract_info(self, url, download=True, ie_key=None, extra_info={}, process=True)",
        "snippet": "    def extract_info(self, url, download=True, ie_key=None, extra_info={},\n                     process=True):\n        '''\n        Returns a list with a dictionary for each video we find.\n        If 'download', also downloads the videos.\n        extra_info is a dict containing the extra values to add to each result\n         '''\n\n        if ie_key:\n            ies = [self.get_info_extractor(ie_key)]\n        else:\n            ies = self._ies\n\n        for ie in ies:\n            if not ie.suitable(url):\n                continue\n\n            if not ie.working():\n                self.report_warning('The program functionality for this site has been marked as broken, '\n                                    'and will probably not work.')\n\n            try:\n                ie_result = ie.extract(url)\n                if ie_result is None: # Finished already (backwards compatibility; listformats and friends should be moved here)\n                    break\n                if isinstance(ie_result, list):\n                    # Backwards compatibility: old IE result format\n                    ie_result = {\n                        '_type': 'compat_list',\n                        'entries': ie_result,\n                    }\n                self.add_extra_info(ie_result,\n                    {\n                        'extractor': ie.IE_NAME,\n                        'webpage_url': url,\n                        'webpage_url_basename': url_basename(url),\n                        'extractor_key': ie.ie_key(),\n                    })\n                if process:\n                    return self.process_ie_result(ie_result, download, extra_info)\n                else:\n                    return ie_result\n            except ExtractorError as de: # An error we somewhat expected\n                self.report_error(compat_str(de), de.format_traceback())\n                break\n            except MaxDownloadsReached:\n                raise\n            except Exception as e:\n                if self.params.get('ignoreerrors', False):\n                    self.report_error(compat_str(e), tb=compat_str(traceback.format_exc()))\n                    break\n                else:\n                    raise\n        else:\n            self.report_error('no suitable InfoExtractor: %s' % url)",
        "begin_line": 478,
        "end_line": 532,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.process_ie_result#534",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.process_ie_result(self, ie_result, download=True, extra_info={})",
        "snippet": "    def process_ie_result(self, ie_result, download=True, extra_info={}):\n        \"\"\"\n        Take the result of the ie(may be modified) and resolve all unresolved\n        references (URLs, playlist items).\n\n        It will also download the videos if 'download'.\n        Returns the resolved ie_result.\n        \"\"\"\n\n        result_type = ie_result.get('_type', 'video') # If not given we suppose it's a video, support the default old system\n        if result_type == 'video':\n            self.add_extra_info(ie_result, extra_info)\n            return self.process_video_result(ie_result, download=download)\n        elif result_type == 'url':\n            # We have to add extra_info to the results because it may be\n            # contained in a playlist\n            return self.extract_info(ie_result['url'],\n                                     download,\n                                     ie_key=ie_result.get('ie_key'),\n                                     extra_info=extra_info)\n        elif result_type == 'url_transparent':\n            # Use the information from the embedding page\n            info = self.extract_info(\n                ie_result['url'], ie_key=ie_result.get('ie_key'),\n                extra_info=extra_info, download=False, process=False)\n\n            def make_result(embedded_info):\n                new_result = ie_result.copy()\n                for f in ('_type', 'url', 'ext', 'player_url', 'formats',\n                          'entries', 'ie_key', 'duration',\n                          'subtitles', 'annotations', 'format',\n                          'thumbnail', 'thumbnails'):\n                    if f in new_result:\n                        del new_result[f]\n                    if f in embedded_info:\n                        new_result[f] = embedded_info[f]\n                return new_result\n            new_result = make_result(info)\n\n            assert new_result.get('_type') != 'url_transparent'\n            if new_result.get('_type') == 'compat_list':\n                new_result['entries'] = [\n                    make_result(e) for e in new_result['entries']]\n\n            return self.process_ie_result(\n                new_result, download=download, extra_info=extra_info)\n        elif result_type == 'playlist':\n            # We process each entry in the playlist\n            playlist = ie_result.get('title', None) or ie_result.get('id', None)\n            self.to_screen('[download] Downloading playlist: %s' % playlist)\n\n            playlist_results = []\n\n            playliststart = self.params.get('playliststart', 1) - 1\n            playlistend = self.params.get('playlistend', None)\n            # For backwards compatibility, interpret -1 as whole list\n            if playlistend == -1:\n                playlistend = None\n\n            if isinstance(ie_result['entries'], list):\n                n_all_entries = len(ie_result['entries'])\n                entries = ie_result['entries'][playliststart:playlistend]\n                n_entries = len(entries)\n                self.to_screen(\n                    \"[%s] playlist %s: Collected %d video ids (downloading %d of them)\" %\n                    (ie_result['extractor'], playlist, n_all_entries, n_entries))\n            else:\n                assert isinstance(ie_result['entries'], PagedList)\n                entries = ie_result['entries'].getslice(\n                    playliststart, playlistend)\n                n_entries = len(entries)\n                self.to_screen(\n                    \"[%s] playlist %s: Downloading %d videos\" %\n                    (ie_result['extractor'], playlist, n_entries))\n\n            for i, entry in enumerate(entries, 1):\n                self.to_screen('[download] Downloading video #%s of %s' % (i, n_entries))\n                extra = {\n                    'playlist': playlist,\n                    'playlist_index': i + playliststart,\n                    'extractor': ie_result['extractor'],\n                    'webpage_url': ie_result['webpage_url'],\n                    'webpage_url_basename': url_basename(ie_result['webpage_url']),\n                    'extractor_key': ie_result['extractor_key'],\n                }\n\n                reason = self._match_entry(entry)\n                if reason is not None:\n                    self.to_screen('[download] ' + reason)\n                    continue\n\n                entry_result = self.process_ie_result(entry,\n                                                      download=download,\n                                                      extra_info=extra)\n                playlist_results.append(entry_result)\n            ie_result['entries'] = playlist_results\n            return ie_result\n        elif result_type == 'compat_list':\n            def _fixup(r):\n                self.add_extra_info(r,\n                    {\n                        'extractor': ie_result['extractor'],\n                        'webpage_url': ie_result['webpage_url'],\n                        'webpage_url_basename': url_basename(ie_result['webpage_url']),\n                        'extractor_key': ie_result['extractor_key'],\n                    })\n                return r\n            ie_result['entries'] = [\n                self.process_ie_result(_fixup(r), download, extra_info)\n                for r in ie_result['entries']\n            ]\n            return ie_result\n        else:\n            raise Exception('Invalid result type: %s' % result_type)",
        "begin_line": 534,
        "end_line": 647,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.select_format#649",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.select_format(self, format_spec, available_formats)",
        "snippet": "    def select_format(self, format_spec, available_formats):\n        if format_spec == 'best' or format_spec is None:\n            return available_formats[-1]\n        elif format_spec == 'worst':\n            return available_formats[0]\n        elif format_spec == 'bestaudio':\n            audio_formats = [\n                f for f in available_formats\n                if f.get('vcodec') == 'none']\n            if audio_formats:\n                return audio_formats[-1]\n        elif format_spec == 'worstaudio':\n            audio_formats = [\n                f for f in available_formats\n                if f.get('vcodec') == 'none']\n            if audio_formats:\n                return audio_formats[0]\n        else:\n            extensions = ['mp4', 'flv', 'webm', '3gp']\n            if format_spec in extensions:\n                filter_f = lambda f: f['ext'] == format_spec\n            else:\n                filter_f = lambda f: f['format_id'] == format_spec\n            matches = list(filter(filter_f, available_formats))\n            if matches:\n                return matches[-1]\n        return None",
        "begin_line": 649,
        "end_line": 675,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.process_video_result#677",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.process_video_result(self, info_dict, download=True)",
        "snippet": "    def process_video_result(self, info_dict, download=True):\n        assert info_dict.get('_type', 'video') == 'video'\n\n        if 'playlist' not in info_dict:\n            # It isn't part of a playlist\n            info_dict['playlist'] = None\n            info_dict['playlist_index'] = None\n\n        if 'display_id' not in info_dict and 'id' in info_dict:\n            info_dict['display_id'] = info_dict['id']\n\n        # This extractors handle format selection themselves\n        if info_dict['extractor'] in ['Youku']:\n            if download:\n                self.process_info(info_dict)\n            return info_dict\n\n        # We now pick which formats have to be downloaded\n        if info_dict.get('formats') is None:\n            # There's only one format available\n            formats = [info_dict]\n        else:\n            formats = info_dict['formats']\n\n        # We check that all the formats have the format and format_id fields\n        for (i, format) in enumerate(formats):\n            if format.get('format_id') is None:\n                format['format_id'] = compat_str(i)\n            if format.get('format') is None:\n                format['format'] = '{id} - {res}{note}'.format(\n                    id=format['format_id'],\n                    res=self.format_resolution(format),\n                    note=' ({0})'.format(format['format_note']) if format.get('format_note') is not None else '',\n                )\n            # Automatically determine file extension if missing\n            if 'ext' not in format:\n                format['ext'] = determine_ext(format['url'])\n\n        format_limit = self.params.get('format_limit', None)\n        if format_limit:\n            formats = list(takewhile_inclusive(\n                lambda f: f['format_id'] != format_limit, formats\n            ))\n\n        # TODO Central sorting goes here\n\n        if formats[0] is not info_dict:\n            # only set the 'formats' fields if the original info_dict list them\n            # otherwise we end up with a circular reference, the first (and unique)\n            # element in the 'formats' field in info_dict is info_dict itself,\n            # wich can't be exported to json\n            info_dict['formats'] = formats\n        if self.params.get('listformats', None):\n            self.list_formats(info_dict)\n            return\n\n        req_format = self.params.get('format')\n        if req_format is None:\n            req_format = 'best'\n        formats_to_download = []\n        # The -1 is for supporting YoutubeIE\n        if req_format in ('-1', 'all'):\n            formats_to_download = formats\n        else:\n            # We can accept formats requested in the format: 34/5/best, we pick\n            # the first that is available, starting from left\n            req_formats = req_format.split('/')\n            for rf in req_formats:\n                if re.match(r'.+?\\+.+?', rf) is not None:\n                    # Two formats have been requested like '137+139'\n                    format_1, format_2 = rf.split('+')\n                    formats_info = (self.select_format(format_1, formats),\n                        self.select_format(format_2, formats))\n                    if all(formats_info):\n                        selected_format = {\n                            'requested_formats': formats_info,\n                            'format': rf,\n                            'ext': formats_info[0]['ext'],\n                        }\n                    else:\n                        selected_format = None\n                else:\n                    selected_format = self.select_format(rf, formats)\n                if selected_format is not None:\n                    formats_to_download = [selected_format]\n                    break\n        if not formats_to_download:\n            raise ExtractorError('requested format not available',\n                                 expected=True)\n\n        if download:\n            if len(formats_to_download) > 1:\n                self.to_screen('[info] %s: downloading video in %s formats' % (info_dict['id'], len(formats_to_download)))\n            for format in formats_to_download:\n                new_info = dict(info_dict)\n                new_info.update(format)\n                self.process_info(new_info)\n        # We update the info dict with the best quality format (backwards compatibility)\n        info_dict.update(formats_to_download[-1])\n        return info_dict",
        "begin_line": 677,
        "end_line": 776,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.process_info#778",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.process_info(self, info_dict)",
        "snippet": "    def process_info(self, info_dict):\n        \"\"\"Process a single resolved IE result.\"\"\"\n\n        assert info_dict.get('_type', 'video') == 'video'\n\n        max_downloads = self.params.get('max_downloads')\n        if max_downloads is not None:\n            if self._num_downloads >= int(max_downloads):\n                raise MaxDownloadsReached()\n\n        info_dict['fulltitle'] = info_dict['title']\n        if len(info_dict['title']) > 200:\n            info_dict['title'] = info_dict['title'][:197] + '...'\n\n        # Keep for backwards compatibility\n        info_dict['stitle'] = info_dict['title']\n\n        if not 'format' in info_dict:\n            info_dict['format'] = info_dict['ext']\n\n        reason = self._match_entry(info_dict)\n        if reason is not None:\n            self.to_screen('[download] ' + reason)\n            return\n\n        self._num_downloads += 1\n\n        filename = self.prepare_filename(info_dict)\n\n        # Forced printings\n        if self.params.get('forcetitle', False):\n            self.to_stdout(info_dict['fulltitle'])\n        if self.params.get('forceid', False):\n            self.to_stdout(info_dict['id'])\n        if self.params.get('forceurl', False):\n            # For RTMP URLs, also include the playpath\n            self.to_stdout(info_dict['url'] + info_dict.get('play_path', ''))\n        if self.params.get('forcethumbnail', False) and info_dict.get('thumbnail') is not None:\n            self.to_stdout(info_dict['thumbnail'])\n        if self.params.get('forcedescription', False) and info_dict.get('description') is not None:\n            self.to_stdout(info_dict['description'])\n        if self.params.get('forcefilename', False) and filename is not None:\n            self.to_stdout(filename)\n        if self.params.get('forceduration', False) and info_dict.get('duration') is not None:\n            self.to_stdout(formatSeconds(info_dict['duration']))\n        if self.params.get('forceformat', False):\n            self.to_stdout(info_dict['format'])\n        if self.params.get('forcejson', False):\n            info_dict['_filename'] = filename\n            self.to_stdout(json.dumps(info_dict))\n\n        # Do nothing else if in simulate mode\n        if self.params.get('simulate', False):\n            return\n\n        if filename is None:\n            return\n\n        try:\n            dn = os.path.dirname(encodeFilename(filename))\n            if dn != '' and not os.path.exists(dn):\n                os.makedirs(dn)\n        except (OSError, IOError) as err:\n            self.report_error('unable to create directory ' + compat_str(err))\n            return\n\n        if self.params.get('writedescription', False):\n            descfn = filename + '.description'\n            if self.params.get('nooverwrites', False) and os.path.exists(encodeFilename(descfn)):\n                self.to_screen('[info] Video description is already present')\n            else:\n                try:\n                    self.to_screen('[info] Writing video description to: ' + descfn)\n                    with io.open(encodeFilename(descfn), 'w', encoding='utf-8') as descfile:\n                        descfile.write(info_dict['description'])\n                except (KeyError, TypeError):\n                    self.report_warning('There\\'s no description to write.')\n                except (OSError, IOError):\n                    self.report_error('Cannot write description file ' + descfn)\n                    return\n\n        if self.params.get('writeannotations', False):\n            annofn = filename + '.annotations.xml'\n            if self.params.get('nooverwrites', False) and os.path.exists(encodeFilename(annofn)):\n                self.to_screen('[info] Video annotations are already present')\n            else:\n                try:\n                    self.to_screen('[info] Writing video annotations to: ' + annofn)\n                    with io.open(encodeFilename(annofn), 'w', encoding='utf-8') as annofile:\n                        annofile.write(info_dict['annotations'])\n                except (KeyError, TypeError):\n                    self.report_warning('There are no annotations to write.')\n                except (OSError, IOError):\n                    self.report_error('Cannot write annotations file: ' + annofn)\n                    return\n\n        subtitles_are_requested = any([self.params.get('writesubtitles', False),\n                                       self.params.get('writeautomaticsub')])\n\n        if subtitles_are_requested and 'subtitles' in info_dict and info_dict['subtitles']:\n            # subtitles download errors are already managed as troubles in relevant IE\n            # that way it will silently go on when used with unsupporting IE\n            subtitles = info_dict['subtitles']\n            sub_format = self.params.get('subtitlesformat', 'srt')\n            for sub_lang in subtitles.keys():\n                sub = subtitles[sub_lang]\n                if sub is None:\n                    continue\n                try:\n                    sub_filename = subtitles_filename(filename, sub_lang, sub_format)\n                    if self.params.get('nooverwrites', False) and os.path.exists(encodeFilename(sub_filename)):\n                        self.to_screen('[info] Video subtitle %s.%s is already_present' % (sub_lang, sub_format))\n                    else:\n                        self.to_screen('[info] Writing video subtitles to: ' + sub_filename)\n                        with io.open(encodeFilename(sub_filename), 'w', encoding='utf-8') as subfile:\n                                subfile.write(sub)\n                except (OSError, IOError):\n                    self.report_error('Cannot write subtitles file ' + descfn)\n                    return\n\n        if self.params.get('writeinfojson', False):\n            infofn = os.path.splitext(filename)[0] + '.info.json'\n            if self.params.get('nooverwrites', False) and os.path.exists(encodeFilename(infofn)):\n                self.to_screen('[info] Video description metadata is already present')\n            else:\n                self.to_screen('[info] Writing video description metadata as JSON to: ' + infofn)\n                try:\n                    write_json_file(info_dict, encodeFilename(infofn))\n                except (OSError, IOError):\n                    self.report_error('Cannot write metadata to JSON file ' + infofn)\n                    return\n\n        if self.params.get('writethumbnail', False):\n            if info_dict.get('thumbnail') is not None:\n                thumb_format = determine_ext(info_dict['thumbnail'], 'jpg')\n                thumb_filename = os.path.splitext(filename)[0] + '.' + thumb_format\n                if self.params.get('nooverwrites', False) and os.path.exists(encodeFilename(thumb_filename)):\n                    self.to_screen('[%s] %s: Thumbnail is already present' %\n                                   (info_dict['extractor'], info_dict['id']))\n                else:\n                    self.to_screen('[%s] %s: Downloading thumbnail ...' %\n                                   (info_dict['extractor'], info_dict['id']))\n                    try:\n                        uf = compat_urllib_request.urlopen(info_dict['thumbnail'])\n                        with open(thumb_filename, 'wb') as thumbf:\n                            shutil.copyfileobj(uf, thumbf)\n                        self.to_screen('[%s] %s: Writing thumbnail to: %s' %\n                            (info_dict['extractor'], info_dict['id'], thumb_filename))\n                    except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:\n                        self.report_warning('Unable to download thumbnail \"%s\": %s' %\n                            (info_dict['thumbnail'], compat_str(err)))\n\n        if not self.params.get('skip_download', False):\n            if self.params.get('nooverwrites', False) and os.path.exists(encodeFilename(filename)):\n                success = True\n            else:\n                try:\n                    def dl(name, info):\n                        fd = get_suitable_downloader(info)(self, self.params)\n                        for ph in self._progress_hooks:\n                            fd.add_progress_hook(ph)\n                        return fd.download(name, info)\n                    if info_dict.get('requested_formats') is not None:\n                        downloaded = []\n                        success = True\n                        merger = FFmpegMergerPP(self)\n                        if not merger._get_executable():\n                            postprocessors = []\n                            self.report_warning('You have requested multiple '\n                                'formats but ffmpeg or avconv are not installed.'\n                                ' The formats won\\'t be merged')\n                        else:\n                            postprocessors = [merger]\n                        for f in info_dict['requested_formats']:\n                            new_info = dict(info_dict)\n                            new_info.update(f)\n                            fname = self.prepare_filename(new_info)\n                            fname = prepend_extension(fname, 'f%s' % f['format_id'])\n                            downloaded.append(fname)\n                            partial_success = dl(fname, new_info)\n                            success = success and partial_success\n                        info_dict['__postprocessors'] = postprocessors\n                        info_dict['__files_to_merge'] = downloaded\n                    else:\n                        # Just a single file\n                        success = dl(filename, info_dict)\n                except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:\n                    self.report_error('unable to download video data: %s' % str(err))\n                    return\n                except (OSError, IOError) as err:\n                    raise UnavailableVideoError(err)\n                except (ContentTooShortError, ) as err:\n                    self.report_error('content too short (expected %s bytes and served %s)' % (err.expected, err.downloaded))\n                    return\n\n            if success:\n                try:\n                    self.post_process(filename, info_dict)\n                except (PostProcessingError) as err:\n                    self.report_error('postprocessing: %s' % str(err))\n                    return\n\n        self.record_download_archive(info_dict)",
        "begin_line": 778,
        "end_line": 980,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.download#982",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.download(self, url_list)",
        "snippet": "    def download(self, url_list):\n        \"\"\"Download a given list of URLs.\"\"\"\n        if (len(url_list) > 1 and\n                '%' not in self.params['outtmpl']\n                and self.params.get('max_downloads') != 1):\n            raise SameFileError(self.params['outtmpl'])\n\n        for url in url_list:\n            try:\n                #It also downloads the videos\n                self.extract_info(url)\n            except UnavailableVideoError:\n                self.report_error('unable to download video')\n            except MaxDownloadsReached:\n                self.to_screen('[info] Maximum number of downloaded files reached.')\n                raise\n\n        return self._download_retcode",
        "begin_line": 982,
        "end_line": 999,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.download_with_info_file#1001",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.download_with_info_file(self, info_filename)",
        "snippet": "    def download_with_info_file(self, info_filename):\n        with io.open(info_filename, 'r', encoding='utf-8') as f:\n            info = json.load(f)\n        try:\n            self.process_ie_result(info, download=True)\n        except DownloadError:\n            webpage_url = info.get('webpage_url')\n            if webpage_url is not None:\n                self.report_warning('The info failed to download, trying with \"%s\"' % webpage_url)\n                return self.download([webpage_url])\n            else:\n                raise\n        return self._download_retcode",
        "begin_line": 1001,
        "end_line": 1013,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.post_process#1015",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.post_process(self, filename, ie_info)",
        "snippet": "    def post_process(self, filename, ie_info):\n        \"\"\"Run all the postprocessors on the given file.\"\"\"\n        info = dict(ie_info)\n        info['filepath'] = filename\n        keep_video = None\n        pps_chain = []\n        if ie_info.get('__postprocessors') is not None:\n            pps_chain.extend(ie_info['__postprocessors'])\n        pps_chain.extend(self._pps)\n        for pp in pps_chain:\n            try:\n                keep_video_wish, new_info = pp.run(info)\n                if keep_video_wish is not None:\n                    if keep_video_wish:\n                        keep_video = keep_video_wish\n                    elif keep_video is None:\n                        # No clear decision yet, let IE decide\n                        keep_video = keep_video_wish\n            except PostProcessingError as e:\n                self.report_error(e.msg)\n        if keep_video is False and not self.params.get('keepvideo', False):\n            try:\n                self.to_screen('Deleting original file %s (pass -k to keep)' % filename)\n                os.remove(encodeFilename(filename))\n            except (IOError, OSError):\n                self.report_warning('Unable to remove downloaded video file')",
        "begin_line": 1015,
        "end_line": 1040,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._make_archive_id#1042",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._make_archive_id(self, info_dict)",
        "snippet": "    def _make_archive_id(self, info_dict):\n        # Future-proof against any change in case\n        # and backwards compatibility with prior versions\n        extractor = info_dict.get('extractor_key')\n        if extractor is None:\n            if 'id' in info_dict:\n                extractor = info_dict.get('ie_key')  # key in a playlist\n        if extractor is None:\n            return None  # Incomplete video information\n        return extractor.lower() + ' ' + info_dict['id']",
        "begin_line": 1042,
        "end_line": 1051,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.in_download_archive#1053",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.in_download_archive(self, info_dict)",
        "snippet": "    def in_download_archive(self, info_dict):\n        fn = self.params.get('download_archive')\n        if fn is None:\n            return False\n\n        vid_id = self._make_archive_id(info_dict)\n        if vid_id is None:\n            return False  # Incomplete video information\n\n        try:\n            with locked_file(fn, 'r', encoding='utf-8') as archive_file:\n                for line in archive_file:\n                    if line.strip() == vid_id:\n                        return True\n        except IOError as ioe:\n            if ioe.errno != errno.ENOENT:\n                raise\n        return False",
        "begin_line": 1053,
        "end_line": 1070,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.record_download_archive#1072",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.record_download_archive(self, info_dict)",
        "snippet": "    def record_download_archive(self, info_dict):\n        fn = self.params.get('download_archive')\n        if fn is None:\n            return\n        vid_id = self._make_archive_id(info_dict)\n        assert vid_id\n        with locked_file(fn, 'a', encoding='utf-8') as archive_file:\n            archive_file.write(vid_id + '\\n')",
        "begin_line": 1072,
        "end_line": 1079,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.format_resolution#1082",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.format_resolution(format, default='unknown')",
        "snippet": "    def format_resolution(format, default='unknown'):\n        if format.get('vcodec') == 'none':\n            return 'audio only'\n        if format.get('resolution') is not None:\n            return format['resolution']\n        if format.get('height') is not None:\n            if format.get('width') is not None:\n                res = '%sx%s' % (format['width'], format['height'])\n            else:\n                res = '%sp' % format['height']\n        elif format.get('width') is not None:\n            res = '?x%d' % format['width']\n        else:\n            res = default\n        return res",
        "begin_line": 1082,
        "end_line": 1096,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.list_formats#1098",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.list_formats(self, info_dict)",
        "snippet": "    def list_formats(self, info_dict):\n        def format_note(fdict):\n            res = ''\n            if fdict.get('ext') in ['f4f', 'f4m']:\n                res += '(unsupported) '\n            if fdict.get('format_note') is not None:\n                res += fdict['format_note'] + ' '\n            if fdict.get('tbr') is not None:\n                res += '%4dk ' % fdict['tbr']\n            if fdict.get('container') is not None:\n                if res:\n                    res += ', '\n                res += '%s container' % fdict['container']\n            if (fdict.get('vcodec') is not None and\n                    fdict.get('vcodec') != 'none'):\n                if res:\n                    res += ', '\n                res += fdict['vcodec']\n                if fdict.get('vbr') is not None:\n                    res += '@'\n            elif fdict.get('vbr') is not None and fdict.get('abr') is not None:\n                res += 'video@'\n            if fdict.get('vbr') is not None:\n                res += '%4dk' % fdict['vbr']\n            if fdict.get('acodec') is not None:\n                if res:\n                    res += ', '\n                if fdict['acodec'] == 'none':\n                    res += 'video only'\n                else:\n                    res += '%-5s' % fdict['acodec']\n            elif fdict.get('abr') is not None:\n                if res:\n                    res += ', '\n                res += 'audio'\n            if fdict.get('abr') is not None:\n                res += '@%3dk' % fdict['abr']\n            if fdict.get('asr') is not None:\n                res += ' (%5dHz)' % fdict['asr']\n            if fdict.get('filesize') is not None:\n                if res:\n                    res += ', '\n                res += format_bytes(fdict['filesize'])\n            return res\n\n        def line(format, idlen=20):\n            return (('%-' + compat_str(idlen + 1) + 's%-10s%-12s%s') % (\n                format['format_id'],\n                format['ext'],\n                self.format_resolution(format),\n                format_note(format),\n            ))\n\n        formats = info_dict.get('formats', [info_dict])\n        idlen = max(len('format code'),\n                    max(len(f['format_id']) for f in formats))\n        formats_s = [line(f, idlen) for f in formats]\n        if len(formats) > 1:\n            formats_s[0] += (' ' if format_note(formats[0]) else '') + '(worst)'\n            formats_s[-1] += (' ' if format_note(formats[-1]) else '') + '(best)'\n\n        header_line = line({\n            'format_id': 'format code', 'ext': 'extension',\n            'resolution': 'resolution', 'format_note': 'note'}, idlen=idlen)\n        self.to_screen('[info] Available formats for %s:\\n%s\\n%s' %\n                       (info_dict['id'], header_line, '\\n'.join(formats_s)))",
        "begin_line": 1098,
        "end_line": 1163,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.urlopen#1165",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.urlopen(self, req)",
        "snippet": "    def urlopen(self, req):\n        \"\"\" Start an HTTP download \"\"\"\n        return self._opener.open(req)",
        "begin_line": 1165,
        "end_line": 1167,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL.print_debug_header#1169",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL.print_debug_header(self)",
        "snippet": "    def print_debug_header(self):\n        if not self.params.get('verbose'):\n            return\n        write_string('[debug] youtube-dl version ' + __version__ + '\\n')\n        try:\n            sp = subprocess.Popen(\n                ['git', 'rev-parse', '--short', 'HEAD'],\n                stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n                cwd=os.path.dirname(os.path.abspath(__file__)))\n            out, err = sp.communicate()\n            out = out.decode().strip()\n            if re.match('[0-9a-f]+', out):\n                write_string('[debug] Git HEAD: ' + out + '\\n')\n        except:\n            try:\n                sys.exc_clear()\n            except:\n                pass\n        write_string('[debug] Python version %s - %s' %\n                     (platform.python_version(), platform_name()) + '\\n')\n\n        proxy_map = {}\n        for handler in self._opener.handlers:\n            if hasattr(handler, 'proxies'):\n                proxy_map.update(handler.proxies)\n        write_string('[debug] Proxy map: ' + compat_str(proxy_map) + '\\n')",
        "begin_line": 1169,
        "end_line": 1194,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.YoutubeDL.YoutubeDL._setup_opener#1196",
        "src_path": "youtube_dl/YoutubeDL.py",
        "class_name": "youtube_dl.YoutubeDL.YoutubeDL",
        "signature": "youtube_dl.YoutubeDL.YoutubeDL._setup_opener(self)",
        "snippet": "    def _setup_opener(self):\n        timeout_val = self.params.get('socket_timeout')\n        timeout = 600 if timeout_val is None else float(timeout_val)\n\n        opts_cookiefile = self.params.get('cookiefile')\n        opts_proxy = self.params.get('proxy')\n\n        if opts_cookiefile is None:\n            self.cookiejar = compat_cookiejar.CookieJar()\n        else:\n            self.cookiejar = compat_cookiejar.MozillaCookieJar(\n                opts_cookiefile)\n            if os.access(opts_cookiefile, os.R_OK):\n                self.cookiejar.load()\n\n        cookie_processor = compat_urllib_request.HTTPCookieProcessor(\n            self.cookiejar)\n        if opts_proxy is not None:\n            if opts_proxy == '':\n                proxies = {}\n            else:\n                proxies = {'http': opts_proxy, 'https': opts_proxy}\n        else:\n            proxies = compat_urllib_request.getproxies()\n            # Set HTTPS proxy to HTTP one if given (https://github.com/rg3/youtube-dl/issues/805)\n            if 'http' in proxies and 'https' not in proxies:\n                proxies['https'] = proxies['http']\n        proxy_handler = compat_urllib_request.ProxyHandler(proxies)\n\n        debuglevel = 1 if self.params.get('debug_printtraffic') else 0\n        https_handler = make_HTTPS_handler(\n            self.params.get('nocheckcertificate', False), debuglevel=debuglevel)\n        ydlh = YoutubeDLHandler(debuglevel=debuglevel)\n        opener = compat_urllib_request.build_opener(\n            https_handler, proxy_handler, cookie_processor, ydlh)\n        # Delete the default user-agent header, which would otherwise apply in\n        # cases where our custom HTTP handler doesn't come into play\n        # (See https://github.com/rg3/youtube-dl/issues/1309 for details)\n        opener.addheaders = []\n        self._opener = opener\n\n        # TODO remove this global modification\n        compat_urllib_request.install_opener(opener)\n        socket.setdefaulttimeout(timeout)",
        "begin_line": 1196,
        "end_line": 1239,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.0625,
            "pseudo_dstar_susp": 0.0625,
            "pseudo_tarantula_susp": 0.041666666666666664,
            "pseudo_op2_susp": 0.0625,
            "pseudo_barinel_susp": 0.041666666666666664
        }
    },
    {
        "name": "youtube_dl.extractor.mtv._media_xml_tag#16",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv",
        "signature": "youtube_dl.extractor.mtv._media_xml_tag(tag)",
        "snippet": "def _media_xml_tag(tag):\n    return '{http://search.yahoo.com/mrss/}%s' % tag",
        "begin_line": 16,
        "end_line": 17,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_thumbnail_url#34",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_thumbnail_url(self, uri, itemdoc)",
        "snippet": "    def _get_thumbnail_url(self, uri, itemdoc):\n        search_path = '%s/%s' % (_media_xml_tag('group'), _media_xml_tag('thumbnail'))\n        thumb_node = itemdoc.find(search_path)\n        if thumb_node is None:\n            return None\n        else:\n            return thumb_node.attrib['url']",
        "begin_line": 34,
        "end_line": 40,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._extract_video_formats#42",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._extract_video_formats(self, mdoc)",
        "snippet": "    def _extract_video_formats(self, mdoc):\n        if re.match(r'.*/error_country_block\\.swf$', mdoc.find('.//src').text) is not None:\n            raise ExtractorError('This video is not available from your country.', expected=True)\n\n        formats = []\n        for rendition in mdoc.findall('.//rendition'):\n            try:\n                _, _, ext = rendition.attrib['type'].partition('/')\n                rtmp_video_url = rendition.find('./src').text\n                formats.append({'ext': ext,\n                                'url': self._transform_rtmp_url(rtmp_video_url),\n                                'format_id': rendition.get('bitrate'),\n                                'width': int(rendition.get('width')),\n                                'height': int(rendition.get('height')),\n                                })\n            except (KeyError, TypeError):\n                raise ExtractorError('Invalid rendition field.')\n        return formats",
        "begin_line": 42,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_video_info#61",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_video_info(self, itemdoc)",
        "snippet": "    def _get_video_info(self, itemdoc):\n        uri = itemdoc.find('guid').text\n        video_id = self._id_from_uri(uri)\n        self.report_extraction(video_id)\n        mediagen_url = itemdoc.find('%s/%s' % (_media_xml_tag('group'), _media_xml_tag('content'))).attrib['url']\n        # Remove the templates, like &device={device}\n        mediagen_url = re.sub(r'&[^=]*?={.*?}(?=(&|$))', '', mediagen_url)\n        if 'acceptMethods' not in mediagen_url:\n            mediagen_url += '&acceptMethods=fms'\n\n        mediagen_doc = self._download_xml(mediagen_url, video_id,\n            'Downloading video urls')\n\n        description_node = itemdoc.find('description')\n        if description_node is not None:\n            description = description_node.text.strip()\n        else:\n            description = None\n\n        title_el = None\n        if title_el is None:\n            title_el = find_xpath_attr(\n                itemdoc, './/{http://search.yahoo.com/mrss/}category',\n                'scheme', 'urn:mtvn:video_title')\n        if title_el is None:\n            title_el = itemdoc.find('.//{http://search.yahoo.com/mrss/}title')\n        if title_el is None:\n            title_el = itemdoc.find('.//title')\n            if title_el.text is None:\n                title_el = None\n\n        title = title_el.text\n        if title is None:\n            raise ExtractorError('Could not find video title')\n        title = title.strip()\n\n        return {\n            'title': title,\n            'formats': self._extract_video_formats(mediagen_doc),\n            'id': video_id,\n            'thumbnail': self._get_thumbnail_url(uri, itemdoc),\n            'description': description,\n        }",
        "begin_line": 61,
        "end_line": 103,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_videos_info#105",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._get_videos_info(self, uri)",
        "snippet": "    def _get_videos_info(self, uri):\n        video_id = self._id_from_uri(uri)\n        data = compat_urllib_parse.urlencode({'uri': uri})\n\n        idoc = self._download_xml(\n            self._FEED_URL + '?' + data, video_id,\n            'Downloading info', transform_source=fix_xml_ampersands)\n        return [self._get_video_info(item) for item in idoc.findall('.//item')]",
        "begin_line": 105,
        "end_line": 112,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._real_extract#114",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor",
        "signature": "youtube_dl.extractor.mtv.MTVServicesInfoExtractor._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        title = url_basename(url)\n        webpage = self._download_webpage(url, title)\n        try:\n            # the url can be http://media.mtvnservices.com/fb/{mgid}.swf\n            # or http://media.mtvnservices.com/{mgid}\n            og_url = self._og_search_video_url(webpage)\n            mgid = url_basename(og_url)\n            if mgid.endswith('.swf'):\n                mgid = mgid[:-4]\n        except RegexNotFoundError:\n            mgid = self._search_regex(\n                [r'data-mgid=\"(.*?)\"', r'swfobject.embedSWF\\(\".*?(mgid:.*?)\"'],\n                webpage, u'mgid')\n        return self._get_videos_info(mgid)",
        "begin_line": 114,
        "end_line": 128,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVIE._get_thumbnail_url#162",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVIE",
        "signature": "youtube_dl.extractor.mtv.MTVIE._get_thumbnail_url(self, uri, itemdoc)",
        "snippet": "    def _get_thumbnail_url(self, uri, itemdoc):\n        return 'http://mtv.mtvnimages.com/uri/' + uri",
        "begin_line": 162,
        "end_line": 163,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.mtv.MTVIE._real_extract#165",
        "src_path": "youtube_dl/extractor/mtv.py",
        "class_name": "youtube_dl.extractor.mtv.MTVIE",
        "signature": "youtube_dl.extractor.mtv.MTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n        uri = mobj.groupdict().get('mgid')\n        if uri is None:\n            webpage = self._download_webpage(url, video_id)\n    \n            # Some videos come from Vevo.com\n            m_vevo = re.search(r'isVevoVideo = true;.*?vevoVideoId = \"(.*?)\";',\n                               webpage, re.DOTALL)\n            if m_vevo:\n                vevo_id = m_vevo.group(1);\n                self.to_screen('Vevo video detected: %s' % vevo_id)\n                return self.url_result('vevo:%s' % vevo_id, ie='Vevo')\n    \n            uri = self._html_search_regex(r'/uri/(.*?)\\?', webpage, 'uri')\n        return self._get_videos_info(uri)",
        "begin_line": 165,
        "end_line": 181,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.__init__.get_suitable_downloader#15",
        "src_path": "youtube_dl/downloader/__init__.py",
        "class_name": "youtube_dl.downloader.__init__",
        "signature": "youtube_dl.downloader.__init__.get_suitable_downloader(info_dict)",
        "snippet": "def get_suitable_downloader(info_dict):\n    \"\"\"Get the downloader class that can handle the info dict.\"\"\"\n    url = info_dict['url']\n    protocol = info_dict.get('protocol')\n\n    if url.startswith('rtmp'):\n        return RtmpFD\n    if (protocol == 'm3u8') or (protocol is None and determine_ext(url) == 'm3u8'):\n        return HlsFD\n    if url.startswith('mms') or url.startswith('rtsp'):\n        return MplayerFD\n    if determine_ext(url) == 'f4m':\n        return F4mFD\n    else:\n        return HttpFD",
        "begin_line": 15,
        "end_line": 29,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.facebook.FacebookIE.report_login#43",
        "src_path": "youtube_dl/extractor/facebook.py",
        "class_name": "youtube_dl.extractor.facebook.FacebookIE",
        "signature": "youtube_dl.extractor.facebook.FacebookIE.report_login(self)",
        "snippet": "    def report_login(self):\n        \"\"\"Report attempt to log in.\"\"\"\n        self.to_screen('Logging in')",
        "begin_line": 43,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.facebook.FacebookIE._login#47",
        "src_path": "youtube_dl/extractor/facebook.py",
        "class_name": "youtube_dl.extractor.facebook.FacebookIE",
        "signature": "youtube_dl.extractor.facebook.FacebookIE._login(self)",
        "snippet": "    def _login(self):\n        (useremail, password) = self._get_login_info()\n        if useremail is None:\n            return\n\n        login_page_req = compat_urllib_request.Request(self._LOGIN_URL)\n        login_page_req.add_header('Cookie', 'locale=en_US')\n        self.report_login()\n        login_page = self._download_webpage(login_page_req, None, note=False,\n            errnote='Unable to download login page')\n        lsd = self._search_regex(\n            r'<input type=\"hidden\" name=\"lsd\" value=\"([^\"]*)\"',\n            login_page, 'lsd')\n        lgnrnd = self._search_regex(r'name=\"lgnrnd\" value=\"([^\"]*?)\"', login_page, 'lgnrnd')\n\n        login_form = {\n            'email': useremail,\n            'pass': password,\n            'lsd': lsd,\n            'lgnrnd': lgnrnd,\n            'next': 'http://facebook.com/home.php',\n            'default_persistent': '0',\n            'legacy_return': '1',\n            'timezone': '-60',\n            'trynum': '1',\n            }\n        request = compat_urllib_request.Request(self._LOGIN_URL, compat_urllib_parse.urlencode(login_form))\n        request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        try:\n            login_results = compat_urllib_request.urlopen(request).read()\n            if re.search(r'<form(.*)name=\"login\"(.*)</form>', login_results) is not None:\n                self._downloader.report_warning('unable to log in: bad username/password, or exceded login rate limit (~3/min). Check credentials or wait.')\n                return\n\n            check_form = {\n                'fb_dtsg': self._search_regex(r'\"fb_dtsg\":\"(.*?)\"', login_results, 'fb_dtsg'),\n                'nh': self._search_regex(r'name=\"nh\" value=\"(\\w*?)\"', login_results, 'nh'),\n                'name_action_selected': 'dont_save',\n                'submit[Continue]': self._search_regex(r'<input value=\"(.*?)\" name=\"submit\\[Continue\\]\"', login_results, 'continue'),\n            }\n            check_req = compat_urllib_request.Request(self._CHECKPOINT_URL, compat_urllib_parse.urlencode(check_form))\n            check_req.add_header('Content-Type', 'application/x-www-form-urlencoded')\n            check_response = compat_urllib_request.urlopen(check_req).read()\n            if re.search(r'id=\"checkpointSubmitButton\"', check_response) is not None:\n                self._downloader.report_warning('Unable to confirm login, you have to login in your brower and authorize the login.')\n        except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:\n            self._downloader.report_warning('unable to log in: %s' % compat_str(err))\n            return",
        "begin_line": 47,
        "end_line": 94,
        "comment": "",
        "is_bug": true,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.facebook.FacebookIE._real_initialize#96",
        "src_path": "youtube_dl/extractor/facebook.py",
        "class_name": "youtube_dl.extractor.facebook.FacebookIE",
        "signature": "youtube_dl.extractor.facebook.FacebookIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 96,
        "end_line": 97,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.facebook.FacebookIE._real_extract#99",
        "src_path": "youtube_dl/extractor/facebook.py",
        "class_name": "youtube_dl.extractor.facebook.FacebookIE",
        "signature": "youtube_dl.extractor.facebook.FacebookIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        if mobj is None:\n            raise ExtractorError('Invalid URL: %s' % url)\n        video_id = mobj.group('id')\n\n        url = 'https://www.facebook.com/video/video.php?v=%s' % video_id\n        webpage = self._download_webpage(url, video_id)\n\n        BEFORE = '{swf.addParam(param[0], param[1]);});\\n'\n        AFTER = '.forEach(function(variable) {swf.addVariable(variable[0], variable[1]);});'\n        m = re.search(re.escape(BEFORE) + '(.*?)' + re.escape(AFTER), webpage)\n        if not m:\n            m_msg = re.search(r'class=\"[^\"]*uiInterstitialContent[^\"]*\"><div>(.*?)</div>', webpage)\n            if m_msg is not None:\n                raise ExtractorError(\n                    'The video is not available, Facebook said: \"%s\"' % m_msg.group(1),\n                    expected=True)\n            else:\n                raise ExtractorError('Cannot parse data')\n        data = dict(json.loads(m.group(1)))\n        params_raw = compat_urllib_parse.unquote(data['params'])\n        params = json.loads(params_raw)\n        video_data = params['video_data'][0]\n        video_url = video_data.get('hd_src')\n        if not video_url:\n            video_url = video_data['sd_src']\n        if not video_url:\n            raise ExtractorError('Cannot find video URL')\n        video_duration = int(video_data['video_duration'])\n        thumbnail = video_data['thumbnail_src']\n\n        video_title = self._html_search_regex(\n            r'<h2 class=\"uiHeaderTitle\">([^<]*)</h2>', webpage, 'title')\n\n        info = {\n            'id': video_id,\n            'title': video_title,\n            'url': video_url,\n            'ext': 'mp4',\n            'duration': video_duration,\n            'thumbnail': thumbnail,\n        }\n        return [info]",
        "begin_line": 99,
        "end_line": 142,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.slideshare.SlideshareIE._real_extract#26",
        "src_path": "youtube_dl/extractor/slideshare.py",
        "class_name": "youtube_dl.extractor.slideshare.SlideshareIE",
        "signature": "youtube_dl.extractor.slideshare.SlideshareIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        page_title = mobj.group('title')\n        webpage = self._download_webpage(url, page_title)\n        slideshare_obj = self._search_regex(\n            r'var slideshare_object =  ({.*?}); var user_info =',\n            webpage, 'slideshare object')\n        info = json.loads(slideshare_obj)\n        if info['slideshow']['type'] != 'video':\n            raise ExtractorError('Webpage type is \"%s\": only video extraction is supported for Slideshare' % info['slideshow']['type'], expected=True)\n\n        doc = info['doc']\n        bucket = info['jsplayer']['video_bucket']\n        ext = info['jsplayer']['video_extension']\n        video_url = compat_urlparse.urljoin(bucket, doc + '-SD.' + ext)\n        description = self._html_search_regex(\n            r'<p class=\"description.*?\"[^>]*>(.*?)</p>', webpage, 'description')\n\n        return {\n            '_type': 'video',\n            'id': info['slideshow']['id'],\n            'title': info['slideshow']['title'],\n            'ext': ext,\n            'url': video_url,\n            'thumbnail': info['slideshow']['pin_image_url'],\n            'description': description,\n        }",
        "begin_line": 26,
        "end_line": 52,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.ustream.UstreamIE._real_extract#26",
        "src_path": "youtube_dl/extractor/ustream.py",
        "class_name": "youtube_dl.extractor.ustream.UstreamIE",
        "signature": "youtube_dl.extractor.ustream.UstreamIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('videoID')\n\n        video_url = 'http://tcdn.ustream.tv/video/%s' % video_id\n        webpage = self._download_webpage(url, video_id)\n\n        self.report_extraction(video_id)\n\n        video_title = self._html_search_regex(r'data-title=\"(?P<title>.+)\"',\n            webpage, 'title')\n\n        uploader = self._html_search_regex(r'data-content-type=\"channel\".*?>(?P<uploader>.*?)</a>',\n            webpage, 'uploader', fatal=False, flags=re.DOTALL)\n\n        thumbnail = self._html_search_regex(r'<link rel=\"image_src\" href=\"(?P<thumb>.*?)\"',\n            webpage, 'thumbnail', fatal=False)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'ext': 'flv',\n            'title': video_title,\n            'uploader': uploader,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 26,
        "end_line": 51,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.ustream.UstreamChannelIE._real_extract#58",
        "src_path": "youtube_dl/extractor/ustream.py",
        "class_name": "youtube_dl.extractor.ustream.UstreamChannelIE",
        "signature": "youtube_dl.extractor.ustream.UstreamChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        slug = m.group('slug')\n        webpage = self._download_webpage(url, slug)\n        channel_id = get_meta_content('ustream:channel_id', webpage)\n\n        BASE = 'http://www.ustream.tv'\n        next_url = '/ajax/socialstream/videos/%s/1.json' % channel_id\n        video_ids = []\n        while next_url:\n            reply = json.loads(self._download_webpage(compat_urlparse.urljoin(BASE, next_url), channel_id))\n            video_ids.extend(re.findall(r'data-content-id=\"(\\d.*)\"', reply['data']))\n            next_url = reply['nextUrl']\n\n        urls = ['http://www.ustream.tv/recorded/' + vid for vid in video_ids]\n        url_entries = [self.url_result(eurl, 'Ustream') for eurl in urls]\n        return self.playlist_result(url_entries, channel_id)",
        "begin_line": 58,
        "end_line": 74,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.breakcom.BreakIE._real_extract#21",
        "src_path": "youtube_dl/extractor/breakcom.py",
        "class_name": "youtube_dl.extractor.breakcom.BreakIE",
        "signature": "youtube_dl.extractor.breakcom.BreakIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group(1).split(\"-\")[-1]\n        embed_url = 'http://www.break.com/embed/%s' % video_id\n        webpage = self._download_webpage(embed_url, video_id)\n        info_json = self._search_regex(r'var embedVars = ({.*})\\s*?</script>',\n            webpage, 'info json', flags=re.DOTALL)\n        info = json.loads(info_json)\n        video_url = info['videoUri']\n        m_youtube = re.search(r'(https?://www\\.youtube\\.com/watch\\?v=.*)', video_url)\n        if m_youtube is not None:\n            return self.url_result(m_youtube.group(1), 'Youtube')\n        final_url = video_url + '?' + info['AuthToken']\n        return {\n            'id': video_id,\n            'url': final_url,\n            'title': info['contentName'],\n            'thumbnail': info['thumbUri'],\n        }",
        "begin_line": 21,
        "end_line": 39,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.ign.IGNIE._find_video_id#58",
        "src_path": "youtube_dl/extractor/ign.py",
        "class_name": "youtube_dl.extractor.ign.IGNIE",
        "signature": "youtube_dl.extractor.ign.IGNIE._find_video_id(self, webpage)",
        "snippet": "    def _find_video_id(self, webpage):\n        res_id = [r'data-video-id=\"(.+?)\"',\n                  r'<object id=\"vid_(.+?)\"',\n                  r'<meta name=\"og:image\" content=\".*/(.+?)-(.+?)/.+.jpg\"',\n                  ]\n        return self._search_regex(res_id, webpage, 'video id')",
        "begin_line": 58,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.ign.IGNIE._real_extract#65",
        "src_path": "youtube_dl/extractor/ign.py",
        "class_name": "youtube_dl.extractor.ign.IGNIE",
        "signature": "youtube_dl.extractor.ign.IGNIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        name_or_id = mobj.group('name_or_id')\n        page_type = mobj.group('type')\n        webpage = self._download_webpage(url, name_or_id)\n        if page_type == 'articles':\n            video_url = self._search_regex(r'var videoUrl = \"(.+?)\"', webpage, u'video url')\n            return self.url_result(video_url, ie='IGN')\n        elif page_type != 'video':\n            multiple_urls = re.findall(\n                '<param name=\"flashvars\" value=\"[^\"]*?url=(https?://www\\.ign\\.com/videos/.*?)[\"&]',\n                webpage)\n            if multiple_urls:\n                return [self.url_result(u, ie='IGN') for u in multiple_urls]\n\n        video_id = self._find_video_id(webpage)\n        result = self._get_video_info(video_id)\n        description = self._html_search_regex(self._DESCRIPTION_RE,\n                                              webpage, 'video description',\n                                              flags=re.DOTALL)\n        result['description'] = description\n        return result",
        "begin_line": 65,
        "end_line": 86,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.ign.IGNIE._get_video_info#88",
        "src_path": "youtube_dl/extractor/ign.py",
        "class_name": "youtube_dl.extractor.ign.IGNIE",
        "signature": "youtube_dl.extractor.ign.IGNIE._get_video_info(self, video_id)",
        "snippet": "    def _get_video_info(self, video_id):\n        config_url = self._CONFIG_URL_TEMPLATE % video_id\n        config = json.loads(self._download_webpage(config_url, video_id,\n                            u'Downloading video info'))\n        media = config['playlist']['media']\n        video_url = media['url']\n\n        return {'id': media['metadata']['videoId'],\n                'url': video_url,\n                'ext': determine_ext(video_url),\n                'title': media['metadata']['title'],\n                'thumbnail': media['poster'][0]['url'].replace('{size}', 'grande'),\n                }",
        "begin_line": 88,
        "end_line": 100,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.ign.OneUPIE._real_extract#124",
        "src_path": "youtube_dl/extractor/ign.py",
        "class_name": "youtube_dl.extractor.ign.OneUPIE",
        "signature": "youtube_dl.extractor.ign.OneUPIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        id = mobj.group('name_or_id')\n        result = super(OneUPIE, self)._real_extract(url)\n        result['id'] = id\n        return result",
        "begin_line": 124,
        "end_line": 129,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.teamcoco.TeamcocoIE._real_extract#23",
        "src_path": "youtube_dl/extractor/teamcoco.py",
        "class_name": "youtube_dl.extractor.teamcoco.TeamcocoIE",
        "signature": "youtube_dl.extractor.teamcoco.TeamcocoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        if mobj is None:\n            raise ExtractorError('Invalid URL: %s' % url)\n        url_title = mobj.group('url_title')\n        webpage = self._download_webpage(url, url_title)\n\n        video_id = self._html_search_regex(\n            r'<article class=\"video\" data-id=\"(\\d+?)\"',\n            webpage, 'video id')\n\n        self.report_extraction(video_id)\n\n        data_url = 'http://teamcoco.com/cvp/2.0/%s.xml' % video_id\n        data = self._download_xml(data_url, video_id, 'Downloading data webpage')\n\n        qualities = ['500k', '480p', '1000k', '720p', '1080p']\n        formats = []\n        for filed in data.findall('files/file'):\n            if filed.attrib.get('playmode') == 'all':\n                # it just duplicates one of the entries\n                break\n            file_url = filed.text\n            m_format = re.search(r'(\\d+(k|p))\\.mp4', file_url)\n            if m_format is not None:\n                format_id = m_format.group(1)\n            else:\n                format_id = filed.attrib['bitrate']\n            tbr = (\n                int(filed.attrib['bitrate'])\n                if filed.attrib['bitrate'].isdigit()\n                else None)\n\n            try:\n                quality = qualities.index(format_id)\n            except ValueError:\n                quality = -1\n            formats.append({\n                'url': file_url,\n                'ext': 'mp4',\n                'tbr': tbr,\n                'format_id': format_id,\n                'quality': quality,\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': self._og_search_title(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'description': self._og_search_description(webpage),\n        }",
        "begin_line": 23,
        "end_line": 76,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.stanfordoc.StanfordOpenClassroomIE._real_extract#24",
        "src_path": "youtube_dl/extractor/stanfordoc.py",
        "class_name": "youtube_dl.extractor.stanfordoc.StanfordOpenClassroomIE",
        "signature": "youtube_dl.extractor.stanfordoc.StanfordOpenClassroomIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        if mobj is None:\n            raise ExtractorError(u'Invalid URL: %s' % url)\n\n        if mobj.group('course') and mobj.group('video'): # A specific video\n            course = mobj.group('course')\n            video = mobj.group('video')\n            info = {\n                'id': course + '_' + video,\n                'uploader': None,\n                'upload_date': None,\n            }\n\n            self.report_extraction(info['id'])\n            baseUrl = 'http://openclassroom.stanford.edu/MainFolder/courses/' + course + '/videos/'\n            xmlUrl = baseUrl + video + '.xml'\n            mdoc = self._download_xml(xmlUrl, info['id'])\n            try:\n                info['title'] = mdoc.findall('./title')[0].text\n                info['url'] = baseUrl + mdoc.findall('./videoFile')[0].text\n            except IndexError:\n                raise ExtractorError(u'Invalid metadata XML file')\n            info['ext'] = info['url'].rpartition('.')[2]\n            return [info]\n        elif mobj.group('course'): # A course page\n            course = mobj.group('course')\n            info = {\n                'id': course,\n                'type': 'playlist',\n                'uploader': None,\n                'upload_date': None,\n            }\n\n            coursepage = self._download_webpage(url, info['id'],\n                                        note='Downloading course info page',\n                                        errnote='Unable to download course info page')\n\n            info['title'] = self._html_search_regex('<h1>([^<]+)</h1>', coursepage, 'title', default=info['id'])\n\n            info['description'] = self._html_search_regex('<description>([^<]+)</description>',\n                coursepage, u'description', fatal=False)\n\n            links = orderedSet(re.findall('<a href=\"(VideoPage.php\\?[^\"]+)\">', coursepage))\n            info['list'] = [\n                {\n                    'type': 'reference',\n                    'url': 'http://openclassroom.stanford.edu/MainFolder/' + unescapeHTML(vpage),\n                }\n                    for vpage in links]\n            results = []\n            for entry in info['list']:\n                assert entry['type'] == 'reference'\n                results += self.extract(entry['url'])\n            return results\n        else: # Root page\n            info = {\n                'id': 'Stanford OpenClassroom',\n                'type': 'playlist',\n                'uploader': None,\n                'upload_date': None,\n            }\n\n            rootURL = 'http://openclassroom.stanford.edu/MainFolder/HomePage.php'\n            rootpage = self._download_webpage(rootURL, info['id'],\n                errnote=u'Unable to download course info page')\n\n            info['title'] = info['id']\n\n            links = orderedSet(re.findall('<a href=\"(CoursePage.php\\?[^\"]+)\">', rootpage))\n            info['list'] = [\n                {\n                    'type': 'reference',\n                    'url': 'http://openclassroom.stanford.edu/MainFolder/' + unescapeHTML(cpage),\n                }\n                    for cpage in links]\n\n            results = []\n            for entry in info['list']:\n                assert entry['type'] == 'reference'\n                results += self.extract(entry['url'])\n            return results",
        "begin_line": 24,
        "end_line": 105,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.gdcvault.GDCVaultIE._parse_mp4#36",
        "src_path": "youtube_dl/extractor/gdcvault.py",
        "class_name": "youtube_dl.extractor.gdcvault.GDCVaultIE",
        "signature": "youtube_dl.extractor.gdcvault.GDCVaultIE._parse_mp4(self, xml_description)",
        "snippet": "    def _parse_mp4(self, xml_description):\n        video_formats = []\n        mp4_video = xml_description.find('./metadata/mp4video')\n        if mp4_video is None:\n            return None\n\n        mobj = re.match(r'(?P<root>https?://.*?/).*', mp4_video.text)\n        video_root = mobj.group('root')\n        formats = xml_description.findall('./metadata/MBRVideos/MBRVideo')\n        for format in formats:\n            mobj = re.match(r'mp4\\:(?P<path>.*)', format.find('streamName').text)\n            url = video_root + mobj.group('path')\n            vbr = format.find('bitrate').text\n            video_formats.append({\n                'url': url,\n                'vbr': int(vbr),\n            })\n        return video_formats",
        "begin_line": 36,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.gdcvault.GDCVaultIE._parse_flv#55",
        "src_path": "youtube_dl/extractor/gdcvault.py",
        "class_name": "youtube_dl.extractor.gdcvault.GDCVaultIE",
        "signature": "youtube_dl.extractor.gdcvault.GDCVaultIE._parse_flv(self, xml_description)",
        "snippet": "    def _parse_flv(self, xml_description):\n        video_formats = []\n        akami_url = xml_description.find('./metadata/akamaiHost').text\n        slide_video_path = xml_description.find('./metadata/slideVideo').text\n        video_formats.append({\n            'url': 'rtmp://' + akami_url + '/' + slide_video_path,\n            'format_note': 'slide deck video',\n            'quality': -2,\n            'preference': -2,\n            'format_id': 'slides',\n        })\n        speaker_video_path = xml_description.find('./metadata/speakerVideo').text\n        video_formats.append({\n            'url': 'rtmp://' + akami_url + '/' + speaker_video_path,\n            'format_note': 'speaker video',\n            'quality': -1,\n            'preference': -1,\n            'format_id': 'speaker',\n        })\n        return video_formats",
        "begin_line": 55,
        "end_line": 74,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.gdcvault.GDCVaultIE._login#76",
        "src_path": "youtube_dl/extractor/gdcvault.py",
        "class_name": "youtube_dl.extractor.gdcvault.GDCVaultIE",
        "signature": "youtube_dl.extractor.gdcvault.GDCVaultIE._login(self, webpage_url, video_id)",
        "snippet": "    def _login(self, webpage_url, video_id):\n        (username, password) = self._get_login_info()\n        if username is None or password is None:\n            self.report_warning('It looks like ' + webpage_url + ' requires a login. Try specifying a username and password and try again.')\n            return None\n\n        mobj = re.match(r'(?P<root_url>https?://.*?/).*', webpage_url)\n        login_url = mobj.group('root_url') + 'api/login.php'\n        logout_url = mobj.group('root_url') + 'logout'\n\n        login_form = {\n            'email': username,\n            'password': password,\n        }\n\n        request = compat_urllib_request.Request(login_url, compat_urllib_parse.urlencode(login_form))\n        request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        self._download_webpage(request, video_id, 'Logging in')\n        start_page = self._download_webpage(webpage_url, video_id, 'Getting authenticated video page')\n        self._download_webpage(logout_url, video_id, 'Logging out')\n\n        return start_page",
        "begin_line": 76,
        "end_line": 97,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.gdcvault.GDCVaultIE._real_extract#99",
        "src_path": "youtube_dl/extractor/gdcvault.py",
        "class_name": "youtube_dl.extractor.gdcvault.GDCVaultIE",
        "signature": "youtube_dl.extractor.gdcvault.GDCVaultIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n        webpage_url = 'http://www.gdcvault.com/play/' + video_id\n        start_page = self._download_webpage(webpage_url, video_id)\n\n        xml_root = self._html_search_regex(r'<iframe src=\"(?P<xml_root>.*?)player.html.*?\".*?</iframe>', start_page, 'xml root', None, False)\n\n        if xml_root is None:\n            # Probably need to authenticate\n            start_page = self._login(webpage_url, video_id)\n            if start_page is None:\n                self.report_warning('Could not login.')\n            else:\n                # Grab the url from the authenticated page\n                xml_root = self._html_search_regex(r'<iframe src=\"(?P<xml_root>.*?)player.html.*?\".*?</iframe>', start_page, 'xml root')\n\n        xml_name = self._html_search_regex(r'<iframe src=\".*?\\?xml=(?P<xml_file>.+?\\.xml).*?\".*?</iframe>', start_page, 'xml filename', None, False)\n        if xml_name is None:\n            # Fallback to the older format\n            xml_name = self._html_search_regex(r'<iframe src=\".*?\\?xmlURL=xml/(?P<xml_file>.+?\\.xml).*?\".*?</iframe>', start_page, 'xml filename')\n\n        xml_decription_url = xml_root + 'xml/' + xml_name\n        xml_description = self._download_xml(xml_decription_url, video_id)\n\n        video_title = xml_description.find('./metadata/title').text\n        video_formats = self._parse_mp4(xml_description)\n        if video_formats is None:\n            video_formats = self._parse_flv(xml_description)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'formats': video_formats,\n        }",
        "begin_line": 99,
        "end_line": 134,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.myvideo.MyVideoIE.__rc4crypt#35",
        "src_path": "youtube_dl/extractor/myvideo.py",
        "class_name": "youtube_dl.extractor.myvideo.MyVideoIE",
        "signature": "youtube_dl.extractor.myvideo.MyVideoIE.__rc4crypt(self, data, key)",
        "snippet": "    def __rc4crypt(self,data, key):\n        x = 0\n        box = list(range(256))\n        for i in list(range(256)):\n            x = (x + box[i] + compat_ord(key[i % len(key)])) % 256\n            box[i], box[x] = box[x], box[i]\n        x = 0\n        y = 0\n        out = ''\n        for char in data:\n            x = (x + 1) % 256\n            y = (y + box[x]) % 256\n            box[x], box[y] = box[y], box[x]\n            out += chr(compat_ord(char) ^ box[(box[x] + box[y]) % 256])\n        return out",
        "begin_line": 35,
        "end_line": 49,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.myvideo.MyVideoIE.__md5#51",
        "src_path": "youtube_dl/extractor/myvideo.py",
        "class_name": "youtube_dl.extractor.myvideo.MyVideoIE",
        "signature": "youtube_dl.extractor.myvideo.MyVideoIE.__md5(self, s)",
        "snippet": "    def __md5(self,s):\n        return hashlib.md5(s).hexdigest().encode()",
        "begin_line": 51,
        "end_line": 52,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.myvideo.MyVideoIE._real_extract#54",
        "src_path": "youtube_dl/extractor/myvideo.py",
        "class_name": "youtube_dl.extractor.myvideo.MyVideoIE",
        "signature": "youtube_dl.extractor.myvideo.MyVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self,url):\n        mobj = re.match(self._VALID_URL, url)\n        if mobj is None:\n            raise ExtractorError(u'invalid URL: %s' % url)\n\n        video_id = mobj.group(1)\n\n        GK = (\n          b'WXpnME1EZGhNRGhpTTJNM01XVmhOREU0WldNNVpHTTJOakpt'\n          b'TW1FMU5tVTBNR05pWkRaa05XRXhNVFJoWVRVd1ptSXhaVEV3'\n          b'TnpsbA0KTVRkbU1tSTRNdz09'\n        )\n\n        # Get video webpage\n        webpage_url = 'http://www.myvideo.de/watch/%s' % video_id\n        webpage = self._download_webpage(webpage_url, video_id)\n\n        mobj = re.search('source src=\\'(.+?)[.]([^.]+)\\'', webpage)\n        if mobj is not None:\n            self.report_extraction(video_id)\n            video_url = mobj.group(1) + '.flv'\n\n            video_title = self._html_search_regex('<title>([^<]+)</title>',\n                webpage, u'title')\n\n            video_ext = self._search_regex('[.](.+?)$', video_url, u'extension')\n\n            return [{\n                'id':       video_id,\n                'url':      video_url,\n                'uploader': None,\n                'upload_date':  None,\n                'title':    video_title,\n                'ext':      video_ext,\n            }]\n\n        mobj = re.search(r'data-video-service=\"/service/data/video/%s/config' % video_id, webpage)\n        if mobj is not None:\n            request = compat_urllib_request.Request('http://www.myvideo.de/service/data/video/%s/config' % video_id, '')\n            response = self._download_webpage(request, video_id,\n                                              u'Downloading video info')\n            info = json.loads(base64.b64decode(response).decode('utf-8'))\n            return {'id': video_id,\n                    'title': info['title'],\n                    'url': info['streaming_url'].replace('rtmpe', 'rtmpt'),\n                    'play_path': info['filename'],\n                    'ext': 'flv',\n                    'thumbnail': info['thumbnail'][0]['url'],\n                    }\n\n        # try encxml\n        mobj = re.search('var flashvars={(.+?)}', webpage)\n        if mobj is None:\n            raise ExtractorError(u'Unable to extract video')\n\n        params = {}\n        encxml = ''\n        sec = mobj.group(1)\n        for (a, b) in re.findall('(.+?):\\'(.+?)\\',?', sec):\n            if not a == '_encxml':\n                params[a] = b\n            else:\n                encxml = compat_urllib_parse.unquote(b)\n        if not params.get('domain'):\n            params['domain'] = 'www.myvideo.de'\n        xmldata_url = '%s?%s' % (encxml, compat_urllib_parse.urlencode(params))\n        if 'flash_playertype=MTV' in xmldata_url:\n            self._downloader.report_warning(u'avoiding MTV player')\n            xmldata_url = (\n                'http://www.myvideo.de/dynamic/get_player_video_xml.php'\n                '?flash_playertype=D&ID=%s&_countlimit=4&autorun=yes'\n            ) % video_id\n\n        # get enc data\n        enc_data = self._download_webpage(xmldata_url, video_id).split('=')[1]\n        enc_data_b = binascii.unhexlify(enc_data)\n        sk = self.__md5(\n            base64.b64decode(base64.b64decode(GK)) +\n            self.__md5(\n                str(video_id).encode('utf-8')\n            )\n        )\n        dec_data = self.__rc4crypt(enc_data_b, sk)\n\n        # extracting infos\n        self.report_extraction(video_id)\n\n        video_url = None\n        mobj = re.search('connectionurl=\\'(.*?)\\'', dec_data)\n        if mobj:\n            video_url = compat_urllib_parse.unquote(mobj.group(1))\n            if 'myvideo2flash' in video_url:\n                self.report_warning(\n                    u'Rewriting URL to use unencrypted rtmp:// ...',\n                    video_id)\n                video_url = video_url.replace('rtmpe://', 'rtmp://')\n\n        if not video_url:\n            # extract non rtmp videos\n            mobj = re.search('path=\\'(http.*?)\\' source=\\'(.*?)\\'', dec_data)\n            if mobj is None:\n                raise ExtractorError(u'unable to extract url')\n            video_url = compat_urllib_parse.unquote(mobj.group(1)) + compat_urllib_parse.unquote(mobj.group(2))\n\n        video_file = self._search_regex('source=\\'(.*?)\\'', dec_data, u'video file')\n        video_file = compat_urllib_parse.unquote(video_file)\n\n        if not video_file.endswith('f4m'):\n            ppath, prefix = video_file.split('.')\n            video_playpath = '%s:%s' % (prefix, ppath)\n            video_hls_playlist = ''\n        else:\n            video_playpath = ''\n            video_hls_playlist = (\n                video_file\n            ).replace('.f4m', '.m3u8')\n\n        video_swfobj = self._search_regex('swfobject.embedSWF\\(\\'(.+?)\\'', webpage, u'swfobj')\n        video_swfobj = compat_urllib_parse.unquote(video_swfobj)\n\n        video_title = self._html_search_regex(\"<h1(?: class='globalHd')?>(.*?)</h1>\",\n            webpage, u'title')\n\n        return [{\n            'id':                 video_id,\n            'url':                video_url,\n            'tc_url':             video_url,\n            'uploader':           None,\n            'upload_date':        None,\n            'title':              video_title,\n            'ext':                u'flv',\n            'play_path':          video_playpath,\n            'video_file':         video_file,\n            'video_hls_playlist': video_hls_playlist,\n            'player_url':         video_swfobj,\n        }]",
        "begin_line": 54,
        "end_line": 189,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.collegehumor.CollegeHumorIE._real_extract#55",
        "src_path": "youtube_dl/extractor/collegehumor.py",
        "class_name": "youtube_dl.extractor.collegehumor.CollegeHumorIE",
        "signature": "youtube_dl.extractor.collegehumor.CollegeHumorIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n\n        jsonUrl = 'http://www.collegehumor.com/moogaloop/video/' + video_id + '.json'\n        data = json.loads(self._download_webpage(\n            jsonUrl, video_id, 'Downloading info JSON'))\n        vdata = data['video']\n        if vdata.get('youtubeId') is not None:\n            return {\n                '_type': 'url',\n                'url': vdata['youtubeId'],\n                'ie_key': 'Youtube',\n            }\n\n        AGE_LIMITS = {'nc17': 18, 'r': 18, 'pg13': 13, 'pg': 10, 'g': 0}\n        rating = vdata.get('rating')\n        if rating:\n            age_limit = AGE_LIMITS.get(rating.lower())\n        else:\n            age_limit = None  # None = No idea\n\n        PREFS = {'high_quality': 2, 'low_quality': 0}\n        formats = []\n        for format_key in ('mp4', 'webm'):\n            for qname, qurl in vdata.get(format_key, {}).items():\n                formats.append({\n                    'format_id': format_key + '_' + qname,\n                    'url': qurl,\n                    'format': format_key,\n                    'preference': PREFS.get(qname),\n                })\n        self._sort_formats(formats)\n\n        duration = int_or_none(vdata.get('duration'), 1000)\n\n        return {\n            'id': video_id,\n            'title': vdata['title'],\n            'description': vdata.get('description'),\n            'thumbnail': vdata.get('thumbnail'),\n            'formats': formats,\n            'age_limit': age_limit,\n            'duration': duration,\n        }",
        "begin_line": 55,
        "end_line": 99,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.sina.SinaIE.suitable#43",
        "src_path": "youtube_dl/extractor/sina.py",
        "class_name": "youtube_dl.extractor.sina.SinaIE",
        "signature": "youtube_dl.extractor.sina.SinaIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        return re.match(cls._VALID_URL, url, flags=re.VERBOSE) is not None",
        "begin_line": 43,
        "end_line": 44,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0001584786053882726,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.sina.SinaIE._extract_video#46",
        "src_path": "youtube_dl/extractor/sina.py",
        "class_name": "youtube_dl.extractor.sina.SinaIE",
        "signature": "youtube_dl.extractor.sina.SinaIE._extract_video(self, video_id)",
        "snippet": "    def _extract_video(self, video_id):\n        data = compat_urllib_parse.urlencode({'vid': video_id})\n        url_doc = self._download_xml('http://v.iask.com/v_play.php?%s' % data,\n            video_id, 'Downloading video url')\n        image_page = self._download_webpage(\n            'http://interface.video.sina.com.cn/interface/common/getVideoImage.php?%s' % data,\n            video_id, 'Downloading thumbnail info')\n\n        return {'id': video_id,\n                'url': url_doc.find('./durl/url').text,\n                'ext': 'flv',\n                'title': url_doc.find('./vname').text,\n                'thumbnail': image_page.split('=')[1],\n                }",
        "begin_line": 46,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.sina.SinaIE._real_extract#61",
        "src_path": "youtube_dl/extractor/sina.py",
        "class_name": "youtube_dl.extractor.sina.SinaIE",
        "signature": "youtube_dl.extractor.sina.SinaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url, flags=re.VERBOSE)\n        video_id = mobj.group('id')\n        if mobj.group('token') is not None:\n            # The video id is in the redirected url\n            self.to_screen('Getting video id')\n            request = compat_urllib_request.Request(url)\n            request.get_method = lambda: 'HEAD'\n            (_, urlh) = self._download_webpage_handle(request, 'NA', False)\n            return self._real_extract(urlh.geturl())\n        elif video_id is None:\n            pseudo_id = mobj.group('pseudo_id')\n            webpage = self._download_webpage(url, pseudo_id)\n            video_id = self._search_regex(r'vid:\\'(\\d+?)\\'', webpage, 'video id')\n\n        return self._extract_video(video_id)",
        "begin_line": 61,
        "end_line": 76,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.dreisat.DreiSatIE._real_extract#27",
        "src_path": "youtube_dl/extractor/dreisat.py",
        "class_name": "youtube_dl.extractor.dreisat.DreiSatIE",
        "signature": "youtube_dl.extractor.dreisat.DreiSatIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        details_url = 'http://www.3sat.de/mediathek/xmlservice/web/beitragsDetails?ak=web&id=%s' % video_id\n        details_doc = self._download_xml(details_url, video_id, note=u'Downloading video details')\n\n        thumbnail_els = details_doc.findall('.//teaserimage')\n        thumbnails = [{\n            'width': te.attrib['key'].partition('x')[0],\n            'height': te.attrib['key'].partition('x')[2],\n            'url': te.text,\n        } for te in thumbnail_els]\n\n        information_el = details_doc.find('.//information')\n        video_title = information_el.find('./title').text\n        video_description = information_el.find('./detail').text\n\n        details_el = details_doc.find('.//details')\n        video_uploader = details_el.find('./channel').text\n        upload_date = unified_strdate(details_el.find('./airtime').text)\n\n        format_els = details_doc.findall('.//formitaet')\n        formats = [{\n            'format_id': fe.attrib['basetype'],\n            'width': int(fe.find('./width').text),\n            'height': int(fe.find('./height').text),\n            'url': fe.find('./url').text,\n            'filesize': int(fe.find('./filesize').text),\n            'video_bitrate': int(fe.find('./videoBitrate').text),\n        } for fe in format_els\n            if not fe.find('./url').text.startswith('http://www.metafilegenerator.de/')]\n\n        self._sort_formats(formats)\n\n        return {\n            '_type': 'video',\n            'id': video_id,\n            'title': video_title,\n            'formats': formats,\n            'description': video_description,\n            'thumbnails': thumbnails,\n            'thumbnail': thumbnails[-1]['url'],\n            'uploader': video_uploader,\n            'upload_date': upload_date,\n        }",
        "begin_line": 27,
        "end_line": 71,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.anitube.AnitubeIE._real_extract#22",
        "src_path": "youtube_dl/extractor/anitube.py",
        "class_name": "youtube_dl.extractor.anitube.AnitubeIE",
        "signature": "youtube_dl.extractor.anitube.AnitubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        key = self._html_search_regex(r'http://www\\.anitube\\.se/embed/([A-Za-z0-9_-]*)',\n                                      webpage, u'key')\n\n        config_xml = self._download_xml('http://www.anitube.se/nuevo/econfig.php?key=%s' % key,\n                                                key)\n\n        video_title = config_xml.find('title').text\n\n        formats = []\n        video_url = config_xml.find('file')\n        if video_url is not None:\n            formats.append({\n                'format_id': 'sd',\n                'url': video_url.text,\n            })\n        video_url = config_xml.find('filehd')\n        if video_url is not None:\n            formats.append({\n                'format_id': 'hd',\n                'url': video_url.text,\n            })\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'formats': formats\n        }",
        "begin_line": 22,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.bandcamp.BandcampIE._real_extract#27",
        "src_path": "youtube_dl/extractor/bandcamp.py",
        "class_name": "youtube_dl.extractor.bandcamp.BandcampIE",
        "signature": "youtube_dl.extractor.bandcamp.BandcampIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        title = mobj.group('title')\n        webpage = self._download_webpage(url, title)\n        # We get the link to the free download page\n        m_download = re.search(r'freeDownloadPage: \"(.*?)\"', webpage)\n        if m_download is None:\n            m_trackinfo = re.search(r'trackinfo: (.+),\\s*?\\n', webpage)\n            if m_trackinfo:\n                json_code = m_trackinfo.group(1)\n                data = json.loads(json_code)\n                d = data[0]\n\n                duration = int(round(d['duration']))\n                formats = []\n                for format_id, format_url in d['file'].items():\n                    ext, _, abr_str = format_id.partition('-')\n\n                    formats.append({\n                        'format_id': format_id,\n                        'url': format_url,\n                        'ext': format_id.partition('-')[0],\n                        'vcodec': 'none',\n                        'acodec': format_id.partition('-')[0],\n                        'abr': int(format_id.partition('-')[2]),\n                    })\n\n                self._sort_formats(formats)\n\n                return {\n                    'id': compat_str(d['id']),\n                    'title': d['title'],\n                    'formats': formats,\n                    'duration': duration,\n                }\n            else:\n                raise ExtractorError('No free songs found')\n\n        download_link = m_download.group(1)\n        video_id = re.search(\n            r'var TralbumData = {(.*?)id: (?P<id>\\d*?)$',\n            webpage, re.MULTILINE | re.DOTALL).group('id')\n\n        download_webpage = self._download_webpage(download_link, video_id,\n                                                  'Downloading free downloads page')\n        # We get the dictionary of the track from some javascrip code\n        info = re.search(r'items: (.*?),$',\n                         download_webpage, re.MULTILINE).group(1)\n        info = json.loads(info)[0]\n        # We pick mp3-320 for now, until format selection can be easily implemented.\n        mp3_info = info['downloads']['mp3-320']\n        # If we try to use this url it says the link has expired\n        initial_url = mp3_info['url']\n        re_url = r'(?P<server>http://(.*?)\\.bandcamp\\.com)/download/track\\?enc=mp3-320&fsig=(?P<fsig>.*?)&id=(?P<id>.*?)&ts=(?P<ts>.*)$'\n        m_url = re.match(re_url, initial_url)\n        #We build the url we will use to get the final track url\n        # This url is build in Bandcamp in the script download_bunde_*.js\n        request_url = '%s/statdownload/track?enc=mp3-320&fsig=%s&id=%s&ts=%s&.rand=665028774616&.vrs=1' % (m_url.group('server'), m_url.group('fsig'), video_id, m_url.group('ts'))\n        final_url_webpage = self._download_webpage(request_url, video_id, 'Requesting download url')\n        # If we could correctly generate the .rand field the url would be\n        #in the \"download_url\" key\n        final_url = re.search(r'\"retry_url\":\"(.*?)\"', final_url_webpage).group(1)\n\n        return {\n            'id': video_id,\n            'title': info['title'],\n            'ext': 'mp3',\n            'vcodec': 'none',\n            'url': final_url,\n            'thumbnail': info.get('thumb_url'),\n            'uploader': info.get('artist'),\n        }",
        "begin_line": 27,
        "end_line": 98,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.bandcamp.BandcampAlbumIE._real_extract#129",
        "src_path": "youtube_dl/extractor/bandcamp.py",
        "class_name": "youtube_dl.extractor.bandcamp.BandcampAlbumIE",
        "signature": "youtube_dl.extractor.bandcamp.BandcampAlbumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        title = mobj.group('title')\n        webpage = self._download_webpage(url, title)\n        tracks_paths = re.findall(r'<a href=\"(.*?)\" itemprop=\"url\">', webpage)\n        if not tracks_paths:\n            raise ExtractorError('The page doesn\\'t contain any tracks')\n        entries = [\n            self.url_result(compat_urlparse.urljoin(url, t_path), ie=BandcampIE.ie_key())\n            for t_path in tracks_paths]\n        title = self._search_regex(r'album_title : \"(.*?)\"', webpage, 'title')\n        return {\n            '_type': 'playlist',\n            'title': title,\n            'entries': entries,\n        }",
        "begin_line": 129,
        "end_line": 144,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.metacritic.MetacriticIE._real_extract#24",
        "src_path": "youtube_dl/extractor/metacritic.py",
        "class_name": "youtube_dl.extractor.metacritic.MetacriticIE",
        "signature": "youtube_dl.extractor.metacritic.MetacriticIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        # The xml is not well formatted, there are raw '&'\n        info = self._download_xml('http://www.metacritic.com/video_data?video=' + video_id,\n            video_id, 'Downloading info xml', transform_source=fix_xml_ampersands)\n\n        clip = next(c for c in info.findall('playList/clip') if c.find('id').text == video_id)\n        formats = []\n        for videoFile in clip.findall('httpURI/videoFile'):\n            rate_str = videoFile.find('rate').text\n            video_url = videoFile.find('filePath').text\n            formats.append({\n                'url': video_url,\n                'ext': 'mp4',\n                'format_id': rate_str,\n                'tbr': int(rate_str),\n            })\n        self._sort_formats(formats)\n\n        description = self._html_search_regex(r'<b>Description:</b>(.*?)</p>',\n            webpage, 'description', flags=re.DOTALL)\n\n        return {\n            'id': video_id,\n            'title': clip.find('title').text,\n            'formats': formats,\n            'description': description,\n            'duration': int(clip.find('duration').text),\n        }",
        "begin_line": 24,
        "end_line": 54,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.ninegag.NineGagIE._real_extract#23",
        "src_path": "youtube_dl/extractor/ninegag.py",
        "class_name": "youtube_dl.extractor.ninegag.NineGagIE",
        "signature": "youtube_dl.extractor.ninegag.NineGagIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        data_json = self._html_search_regex(r'''(?x)\n            <div\\s*id=\"tv-video\"\\s*data-video-source=\"youtube\"\\s*\n                data-video-meta=\"([^\"]+)\"''', webpage, 'video metadata')\n\n        data = json.loads(data_json)\n\n        return {\n            '_type': 'url_transparent',\n            'url': data['youtubeVideoId'],\n            'ie_key': 'Youtube',\n            'id': video_id,\n            'title': data['title'],\n            'description': data['description'],\n            'view_count': int(data['view_count']),\n            'like_count': int(data['statistic']['like']),\n            'dislike_count': int(data['statistic']['dislike']),\n            'thumbnail': data['thumbnail_url'],\n        }",
        "begin_line": 23,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.fourtube.FourTubeIE._real_extract#33",
        "src_path": "youtube_dl/extractor/fourtube.py",
        "class_name": "youtube_dl.extractor.fourtube.FourTubeIE",
        "signature": "youtube_dl.extractor.fourtube.FourTubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n        webpage_url = 'http://www.4tube.com/videos/' + video_id\n        webpage = self._download_webpage(webpage_url, video_id)\n\n        self.report_extraction(video_id)\n\n        playlist_json = self._html_search_regex(r'var playerConfigPlaylist\\s+=\\s+([^;]+)', webpage, 'Playlist')\n        media_id = self._search_regex(r'idMedia:\\s*(\\d+)', playlist_json, 'Media Id')\n        sources = self._search_regex(r'sources:\\s*\\[([^\\]]*)\\]', playlist_json, 'Sources').split(',')\n        title = self._search_regex(r'title:\\s*\"([^\"]*)', playlist_json, 'Title')\n        thumbnail_url = self._search_regex(r'image:\\s*\"([^\"]*)', playlist_json, 'Thumbnail', fatal=False)\n\n        uploader_str = self._search_regex(r'<span>Uploaded by</span>(.*?)<span>', webpage, 'uploader', fatal=False)\n        mobj = re.search(r'<a href=\"/sites/(?P<id>[^\"]+)\"><strong>(?P<name>[^<]+)</strong></a>', uploader_str)\n        (uploader, uploader_id) = (mobj.group('name'), mobj.group('id')) if mobj else (clean_html(uploader_str), None)\n\n        upload_date = None\n        view_count = None\n        duration = None\n        description = self._html_search_meta('description', webpage, 'description')\n        if description:\n            upload_date = self._search_regex(r'Published Date: (\\d{2} [a-zA-Z]{3} \\d{4})', description, 'upload date',\n                fatal=False)\n            if upload_date:\n                upload_date = unified_strdate(upload_date)\n            view_count = self._search_regex(r'Views: ([\\d,\\.]+)', description, 'view count', fatal=False)\n            if view_count:\n                view_count = str_to_int(view_count)\n            duration = parse_duration(self._search_regex(r'Length: (\\d+m\\d+s)', description, 'duration', fatal=False))\n\n        token_url = \"http://tkn.4tube.com/{0}/desktop/{1}\".format(media_id, \"+\".join(sources))\n        headers = {\n                b'Content-Type': b'application/x-www-form-urlencoded',\n                b'Origin': b'http://www.4tube.com',\n                }\n        token_req = compat_urllib_request.Request(token_url, b'{}', headers)\n        tokens = self._download_json(token_req, video_id)\n\n        formats = [{\n            'url': tokens[format]['token'],\n            'format_id': format + 'p',\n            'resolution': format + 'p',\n            'quality': int(format),\n            } for format in sources]\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'thumbnail': thumbnail_url,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'upload_date': upload_date,\n            'view_count': view_count,\n            'duration': duration,\n            'age_limit': 18,\n            'webpage_url': webpage_url,\n        }",
        "begin_line": 33,
        "end_line": 95,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.liveleak.LiveLeakIE._real_extract#47",
        "src_path": "youtube_dl/extractor/liveleak.py",
        "class_name": "youtube_dl.extractor.liveleak.LiveLeakIE",
        "signature": "youtube_dl.extractor.liveleak.LiveLeakIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('video_id')\n        webpage = self._download_webpage(url, video_id)\n\n        video_title = self._og_search_title(webpage).replace('LiveLeak.com -', '').strip()\n        video_description = self._og_search_description(webpage)\n        video_uploader = self._html_search_regex(\n            r'By:.*?(\\w+)</a>', webpage, 'uploader', fatal=False)\n        age_limit = int_or_none(self._search_regex(\n            r'you confirm that you are ([0-9]+) years and over.',\n            webpage, 'age limit', default=None))\n\n        sources_raw = self._search_regex(\n            r'(?s)sources:\\s*(\\[.*?\\]),', webpage, 'video URLs', default=None)\n        if sources_raw is None:\n            alt_source = self._search_regex(\n                r'(file: \".*?\"),', webpage, 'video URL', default=None)\n            if alt_source:\n                sources_raw = '[{ %s}]' % alt_source\n            else:\n                # Maybe an embed?\n                embed_url = self._search_regex(\n                    r'<iframe[^>]+src=\"(http://www.prochan.com/embed\\?[^\"]+)\"',\n                    webpage, 'embed URL')\n                return {\n                    '_type': 'url_transparent',\n                    'url': embed_url,\n                    'id': video_id,\n                    'title': video_title,\n                    'description': video_description,\n                    'uploader': video_uploader,\n                    'age_limit': age_limit,\n                }\n\n        sources_json = re.sub(r'\\s([a-z]+):\\s', r'\"\\1\": ', sources_raw)\n        sources = json.loads(sources_json)\n\n        formats = [{\n            'format_note': s.get('label'),\n            'url': s['file'],\n        } for s in sources]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'description': video_description,\n            'uploader': video_uploader,\n            'formats': formats,\n            'age_limit': age_limit,\n        }",
        "begin_line": 47,
        "end_line": 98,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.googlesearch.GoogleSearchIE._get_n_results#18",
        "src_path": "youtube_dl/extractor/googlesearch.py",
        "class_name": "youtube_dl.extractor.googlesearch.GoogleSearchIE",
        "signature": "youtube_dl.extractor.googlesearch.GoogleSearchIE._get_n_results(self, query, n)",
        "snippet": "    def _get_n_results(self, query, n):\n        \"\"\"Get a specified number of results for a query\"\"\"\n\n        entries = []\n        res = {\n            '_type': 'playlist',\n            'id': query,\n            'title': query,\n        }\n\n        for pagenum in itertools.count():\n            result_url = (\n                'http://www.google.com/search?tbm=vid&q=%s&start=%s&hl=en'\n                % (compat_urllib_parse.quote_plus(query), pagenum * 10))\n\n            webpage = self._download_webpage(\n                result_url, 'gvsearch:' + query,\n                note='Downloading result page ' + str(pagenum + 1))\n\n            for hit_idx, mobj in enumerate(re.finditer(\n                    r'<h3 class=\"r\"><a href=\"([^\"]+)\"', webpage)):\n\n                # Skip playlists\n                if not re.search(r'id=\"vidthumb%d\"' % (hit_idx + 1), webpage):\n                    continue\n\n                entries.append({\n                    '_type': 'url',\n                    'url': mobj.group(1)\n                })\n\n            if (len(entries) >= n) or not re.search(r'class=\"pn\" id=\"pnnext\"', webpage):\n                res['entries'] = entries[:n]\n                return res",
        "begin_line": 18,
        "end_line": 51,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.defense.DefenseGouvFrIE._real_extract#23",
        "src_path": "youtube_dl/extractor/defense.py",
        "class_name": "youtube_dl.extractor.defense.DefenseGouvFrIE",
        "signature": "youtube_dl.extractor.defense.DefenseGouvFrIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        title = re.match(self._VALID_URL, url).group(1)\n        webpage = self._download_webpage(url, title)\n        video_id = self._search_regex(\n            r\"flashvars.pvg_id=\\\"(\\d+)\\\";\",\n            webpage, 'ID')\n        \n        json_url = ('http://static.videos.gouv.fr/brightcovehub/export/json/'\n            + video_id)\n        info = self._download_webpage(json_url, title,\n                                                  'Downloading JSON config')\n        video_url = json.loads(info)['renditions'][0]['url']\n        \n        return {'id': video_id,\n                'ext': 'mp4',\n                'url': video_url,\n                'title': title,\n                }",
        "begin_line": 23,
        "end_line": 40,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.macgamestore.MacGameStoreIE._real_extract#23",
        "src_path": "youtube_dl/extractor/macgamestore.py",
        "class_name": "youtube_dl.extractor.macgamestore.MacGameStoreIE",
        "signature": "youtube_dl.extractor.macgamestore.MacGameStoreIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id, 'Downloading trailer page')\n\n        if re.search(r'>Missing Media<', webpage) is not None:\n            raise ExtractorError('Trailer %s does not exist' % video_id, expected=True)\n\n        video_title = self._html_search_regex(\n            r'<title>MacGameStore: (.*?) Trailer</title>', webpage, 'title')\n\n        video_url = self._html_search_regex(\n            r'(?s)<div\\s+id=\"video-player\".*?href=\"([^\"]+)\"\\s*>',\n            webpage, 'video URL')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': video_title\n        }",
        "begin_line": 23,
        "end_line": 43,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.mpora.MporaIE._real_extract#27",
        "src_path": "youtube_dl/extractor/mpora.py",
        "class_name": "youtube_dl.extractor.mpora.MporaIE",
        "signature": "youtube_dl.extractor.mpora.MporaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        data_json = self._search_regex(\n            r\"new FM\\.Player\\('[^']+',\\s*(\\{.*?)\\);\\n\", webpage, 'json')\n\n        data = json.loads(data_json)\n\n        uploader = data['info_overlay'].get('username')\n        duration = data['video']['duration'] // 1000\n        thumbnail = data['video']['encodings']['sd']['poster']\n        title = data['info_overlay']['title']\n\n        formats = []\n        for encoding_id, edata in data['video']['encodings'].items():\n            for src in edata['sources']:\n                width_str = self._search_regex(\n                    r'_([0-9]+)\\.[a-zA-Z0-9]+$', src['src'],\n                    False, default=None)\n                vcodec = src['type'].partition('/')[2]\n                \n                formats.append({\n                    'format_id': encoding_id + '-' + vcodec,\n                    'url': src['src'],\n                    'vcodec': vcodec,\n                    'width': int_or_none(width_str),\n                })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'uploader': uploader,\n            'duration': duration,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 27,
        "end_line": 66,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.syfy.SyfyIE._real_extract#23",
        "src_path": "youtube_dl/extractor/syfy.py",
        "class_name": "youtube_dl.extractor.syfy.SyfyIE",
        "signature": "youtube_dl.extractor.syfy.SyfyIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        return self.url_result(self._og_search_video_url(webpage))",
        "begin_line": 23,
        "end_line": 27,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.radiofrance.RadioFranceIE._real_extract#22",
        "src_path": "youtube_dl/extractor/radiofrance.py",
        "class_name": "youtube_dl.extractor.radiofrance.RadioFranceIE",
        "signature": "youtube_dl.extractor.radiofrance.RadioFranceIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        title = self._html_search_regex(r'<h1>(.*?)</h1>', webpage, u'title')\n        description = self._html_search_regex(\n            r'<div class=\"bloc_page_wrapper\"><div class=\"text\">(.*?)</div>',\n            webpage, u'description', fatal=False)\n        uploader = self._html_search_regex(\n            r'<div class=\"credit\">&nbsp;&nbsp;&copy;&nbsp;(.*?)</div>',\n            webpage, u'uploader', fatal=False)\n\n        formats_str = self._html_search_regex(\n            r'class=\"jp-jplayer[^\"]*\" data-source=\"([^\"]+)\">',\n            webpage, u'audio URLs')\n        formats = [\n            {\n                'format_id': fm[0],\n                'url': fm[1],\n                'vcodec': 'none',\n            }\n            for fm in\n            re.findall(r\"([a-z0-9]+)\\s*:\\s*'([^']+)'\", formats_str)\n        ]\n        # No sorting, we don't know any more about these formats\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'description': description,\n            'uploader': uploader,\n        }",
        "begin_line": 22,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.jeuxvideo.JeuxVideoIE._real_extract#25",
        "src_path": "youtube_dl/extractor/jeuxvideo.py",
        "class_name": "youtube_dl.extractor.jeuxvideo.JeuxVideoIE",
        "signature": "youtube_dl.extractor.jeuxvideo.JeuxVideoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        title = mobj.group(1)\n        webpage = self._download_webpage(url, title)\n        xml_link = self._html_search_regex(\n            r'<param name=\"flashvars\" value=\"config=(.*?)\" />',\n            webpage, 'config URL')\n        \n        video_id = self._search_regex(\n            r'http://www\\.jeuxvideo\\.com/config/\\w+/\\d+/(.*?)/\\d+_player\\.xml',\n            xml_link, 'video ID')\n\n        config = self._download_xml(\n            xml_link, title, 'Downloading XML config')\n        info_json = config.find('format.json').text\n        info = json.loads(info_json)['versions'][0]\n        \n        video_url = 'http://video720.jeuxvideo.com/' + info['file']\n\n        return {\n            'id': video_id,\n            'title': config.find('titre_video').text,\n            'ext': 'mp4',\n            'url': video_url,\n            'description': self._og_search_description(webpage),\n            'thumbnail': config.find('image').text,\n        }",
        "begin_line": 25,
        "end_line": 51,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.streamcloud.StreamcloudIE._real_extract#27",
        "src_path": "youtube_dl/extractor/streamcloud.py",
        "class_name": "youtube_dl.extractor.streamcloud.StreamcloudIE",
        "signature": "youtube_dl.extractor.streamcloud.StreamcloudIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        orig_webpage = self._download_webpage(url, video_id)\n\n        fields = re.findall(r'''(?x)<input\\s+\n            type=\"(?:hidden|submit)\"\\s+\n            name=\"([^\"]+)\"\\s+\n            (?:id=\"[^\"]+\"\\s+)?\n            value=\"([^\"]*)\"\n            ''', orig_webpage)\n        post = compat_urllib_parse.urlencode(fields)\n\n        self.to_screen('%s: Waiting for timeout' % video_id)\n        time.sleep(12)\n        headers = {\n            b'Content-Type': b'application/x-www-form-urlencoded',\n        }\n        req = compat_urllib_request.Request(url, post, headers)\n\n        webpage = self._download_webpage(\n            req, video_id, note=u'Downloading video page ...')\n        title = self._html_search_regex(\n            r'<h1[^>]*>([^<]+)<', webpage, u'title')\n        video_url = self._search_regex(\n            r'file:\\s*\"([^\"]+)\"', webpage, u'video URL')\n        duration_str = self._search_regex(\n            r'duration:\\s*\"?([0-9]+)\"?', webpage, u'duration', fatal=False)\n        duration = None if duration_str is None else int(duration_str)\n        thumbnail = self._search_regex(\n            r'image:\\s*\"([^\"]+)\"', webpage, u'thumbnail URL', fatal=False)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'duration': duration,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 27,
        "end_line": 66,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.lifenews.LifeNewsIE._real_extract#32",
        "src_path": "youtube_dl/extractor/lifenews.py",
        "class_name": "youtube_dl.extractor.lifenews.LifeNewsIE",
        "signature": "youtube_dl.extractor.lifenews.LifeNewsIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage('http://lifenews.ru/news/%s' % video_id, video_id, 'Downloading page')\n\n        videos = re.findall(r'<video.*?poster=\"(?P<poster>[^\"]+)\".*?src=\"(?P<video>[^\"]+)\".*?></video>', webpage)\n        if not videos:\n            raise ExtractorError('No media links available for %s' % video_id)\n\n        title = self._og_search_title(webpage)\n        TITLE_SUFFIX = ' - \u041f\u0435\u0440\u0432\u044b\u0439 \u043f\u043e \u0441\u0440\u043e\u0447\u043d\u044b\u043c \u043d\u043e\u0432\u043e\u0441\u0442\u044f\u043c \u2014 LIFE | NEWS'\n        if title.endswith(TITLE_SUFFIX):\n            title = title[:-len(TITLE_SUFFIX)]\n\n        description = self._og_search_description(webpage)\n\n        view_count = self._html_search_regex(\n            r'<div class=\\'views\\'>(\\d+)</div>', webpage, 'view count', fatal=False)\n        comment_count = self._html_search_regex(\n            r'<div class=\\'comments\\'>\\s*<span class=\\'counter\\'>(\\d+)</span>', webpage, 'comment count', fatal=False)\n\n        upload_date = self._html_search_regex(\n            r'<time datetime=\\'([^\\']+)\\'>', webpage, 'upload date',fatal=False)\n        if upload_date is not None:\n            upload_date = unified_strdate(upload_date)\n\n        def make_entry(video_id, media, video_number=None):\n            return {\n                'id': video_id,\n                'url': media[1],\n                'thumbnail': media[0],\n                'title': title if video_number is None else '%s-video%s' % (title, video_number),\n                'description': description,\n                'view_count': int_or_none(view_count),\n                'comment_count': int_or_none(comment_count),\n                'upload_date': upload_date,\n            }\n\n        if len(videos) == 1:\n            return make_entry(video_id, videos[0])\n        else:\n            return [make_entry(video_id, media, video_number+1) for video_number, media in enumerate(videos)]",
        "begin_line": 32,
        "end_line": 74,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.trutube.TruTubeIE._real_extract#21",
        "src_path": "youtube_dl/extractor/trutube.py",
        "class_name": "youtube_dl.extractor.trutube.TruTubeIE",
        "signature": "youtube_dl.extractor.trutube.TruTubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        video_title = self._og_search_title(webpage).strip()\n        thumbnail = self._search_regex(\n            r\"var splash_img = '([^']+)';\", webpage, 'thumbnail', fatal=False)\n\n        all_formats = re.finditer(\n            r\"var (?P<key>[a-z]+)_video_file\\s*=\\s*'(?P<url>[^']+)';\", webpage)\n        formats = [{\n            'format_id': m.group('key'),\n            'quality': -i,\n            'url': m.group('url'),\n        } for i, m in enumerate(all_formats)]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'formats': formats,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 21,
        "end_line": 44,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.everyonesmixtape.EveryonesMixtapeIE._real_extract#30",
        "src_path": "youtube_dl/extractor/everyonesmixtape.py",
        "class_name": "youtube_dl.extractor.everyonesmixtape.EveryonesMixtapeIE",
        "signature": "youtube_dl.extractor.everyonesmixtape.EveryonesMixtapeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('id')\n\n        pllist_url = 'http://everyonesmixtape.com/mixtape.php?a=getMixes&u=-1&linked=%s&explore=' % playlist_id\n        pllist_req = compat_urllib_request.Request(pllist_url)\n        pllist_req.add_header('X-Requested-With', 'XMLHttpRequest')\n\n        playlist_list = self._download_json(\n            pllist_req, playlist_id, note='Downloading playlist metadata')\n        try:\n            playlist_no = next(playlist['id']\n                               for playlist in playlist_list\n                               if playlist['code'] == playlist_id)\n        except StopIteration:\n            raise ExtractorError('Playlist id not found')\n\n        pl_url = 'http://everyonesmixtape.com/mixtape.php?a=getMix&id=%s&userId=null&code=' % playlist_no\n        pl_req = compat_urllib_request.Request(pl_url)\n        pl_req.add_header('X-Requested-With', 'XMLHttpRequest')\n        playlist = self._download_json(\n            pl_req, playlist_id, note='Downloading playlist info')\n\n        entries = [{\n            '_type': 'url',\n            'url': t['url'],\n            'title': t['title'],\n        } for t in playlist['tracks']]\n\n        if mobj.group('songnr'):\n            songnr = int(mobj.group('songnr')) - 1\n            return entries[songnr]\n\n        playlist_title = playlist['mixData']['name']\n        return {\n            '_type': 'playlist',\n            'id': playlist_id,\n            'title': playlist_title,\n            'entries': entries,\n        }",
        "begin_line": 30,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youporn.YouPornIE._real_extract#34",
        "src_path": "youtube_dl/extractor/youporn.py",
        "class_name": "youtube_dl.extractor.youporn.YouPornIE",
        "signature": "youtube_dl.extractor.youporn.YouPornIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n        url = 'http://www.' + mobj.group('url')\n\n        req = compat_urllib_request.Request(url)\n        req.add_header('Cookie', 'age_verified=1')\n        webpage = self._download_webpage(req, video_id)\n        age_limit = self._rta_search(webpage)\n\n        # Get JSON parameters\n        json_params = self._search_regex(r'var currentVideo = new Video\\((.*)\\);', webpage, u'JSON parameters')\n        try:\n            params = json.loads(json_params)\n        except:\n            raise ExtractorError(u'Invalid JSON')\n\n        self.report_extraction(video_id)\n        try:\n            video_title = params['title']\n            upload_date = unified_strdate(params['release_date_f'])\n            video_description = params['description']\n            video_uploader = params['submitted_by']\n            thumbnail = params['thumbnails'][0]['image']\n        except KeyError:\n            raise ExtractorError('Missing JSON parameter: ' + sys.exc_info()[1])\n\n        # Get all of the links from the page\n        DOWNLOAD_LIST_RE = r'(?s)<ul class=\"downloadList\">(?P<download_list>.*?)</ul>'\n        download_list_html = self._search_regex(DOWNLOAD_LIST_RE,\n            webpage, u'download list').strip()\n        LINK_RE = r'<a href=\"([^\"]+)\">'\n        links = re.findall(LINK_RE, download_list_html)\n\n        # Get all encrypted links\n        encrypted_links = re.findall(r'var encryptedQuality[0-9]{3}URL = \\'([a-zA-Z0-9+/]+={0,2})\\';', webpage)\n        for encrypted_link in encrypted_links:\n            link = aes_decrypt_text(encrypted_link, video_title, 32).decode('utf-8')\n            links.append(link)\n        \n        formats = []\n        for link in links:\n            # A link looks like this:\n            # http://cdn1.download.youporn.phncdn.com/201210/31/8004515/480p_370k_8004515/YouPorn%20-%20Nubile%20Films%20The%20Pillow%20Fight.mp4?nvb=20121113051249&nva=20121114051249&ir=1200&sr=1200&hash=014b882080310e95fb6a0\n            # A path looks like this:\n            # /201210/31/8004515/480p_370k_8004515/YouPorn%20-%20Nubile%20Films%20The%20Pillow%20Fight.mp4\n            video_url = unescapeHTML(link)\n            path = compat_urllib_parse_urlparse(video_url).path\n            format_parts = path.split('/')[4].split('_')[:2]\n\n            dn = compat_urllib_parse_urlparse(video_url).netloc.partition('.')[0]\n\n            resolution = format_parts[0]\n            height = int(resolution[:-len('p')])\n            bitrate = int(format_parts[1][:-len('k')])\n            format = u'-'.join(format_parts) + u'-' + dn\n\n            formats.append({\n                'url': video_url,\n                'format': format,\n                'format_id': format,\n                'height': height,\n                'tbr': bitrate,\n                'resolution': resolution,\n            })\n\n        self._sort_formats(formats)\n\n        if not formats:\n            raise ExtractorError(u'ERROR: no known formats available for video')\n        \n        return {\n            'id': video_id,\n            'uploader': video_uploader,\n            'upload_date': upload_date,\n            'title': video_title,\n            'thumbnail': thumbnail,\n            'description': video_description,\n            'age_limit': age_limit,\n            'formats': formats,\n        }",
        "begin_line": 34,
        "end_line": 114,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.FileDownloader.FileDownloader._do_download#8",
        "src_path": "youtube_dl/FileDownloader.py",
        "class_name": "youtube_dl.FileDownloader.FileDownloader",
        "signature": "youtube_dl.FileDownloader.FileDownloader._do_download(self, filename, info_dict)",
        "snippet": "    def _do_download(self, filename, info_dict):\n        real_fd = get_suitable_downloader(info_dict)(self.ydl, self.params)\n        for ph in self._progress_hooks:\n            real_fd.add_progress_hook(ph)\n        return real_fd.download(filename, info_dict)",
        "begin_line": 8,
        "end_line": 12,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.unistra.UnistraIE._real_extract#18",
        "src_path": "youtube_dl/extractor/unistra.py",
        "class_name": "youtube_dl.extractor.unistra.UnistraIE",
        "signature": "youtube_dl.extractor.unistra.UnistraIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        id = re.match(self._VALID_URL, url).group(1)\n        webpage = self._download_webpage(url, id)\n        file = re.search(r'file: \"(.*?)\",', webpage).group(1)\n        title = self._html_search_regex(r'<title>UTV - (.*?)</', webpage, u'title')\n\n        video_url = 'http://vod-flash.u-strasbg.fr:8080/' + file\n\n        return {'id': id,\n                'title': title,\n                'ext': 'mp4',\n                'url': video_url,\n                'description': self._html_search_regex(r'<meta name=\"Description\" content=\"(.*?)\"', webpage, u'description', flags=re.DOTALL),\n                'thumbnail': self._search_regex(r'image: \"(.*?)\"', webpage, u'thumbnail'),\n                }",
        "begin_line": 18,
        "end_line": 32,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.vevo.VevoIE._formats_from_json#68",
        "src_path": "youtube_dl/extractor/vevo.py",
        "class_name": "youtube_dl.extractor.vevo.VevoIE",
        "signature": "youtube_dl.extractor.vevo.VevoIE._formats_from_json(self, video_info)",
        "snippet": "    def _formats_from_json(self, video_info):\n        last_version = {'version': -1}\n        for version in video_info['videoVersions']:\n            # These are the HTTP downloads, other types are for different manifests\n            if version['sourceType'] == 2:\n                if version['version'] > last_version['version']:\n                    last_version = version\n        if last_version['version'] == -1:\n            raise ExtractorError('Unable to extract last version of the video')\n\n        renditions = xml.etree.ElementTree.fromstring(last_version['data'])\n        formats = []\n        # Already sorted from worst to best quality\n        for rend in renditions.findall('rendition'):\n            attr = rend.attrib\n            format_note = '%(videoCodec)s@%(videoBitrate)4sk, %(audioCodec)s@%(audioBitrate)3sk' % attr\n            formats.append({\n                'url': attr['url'],\n                'format_id': attr['name'],\n                'format_note': format_note,\n                'height': int(attr['frameheight']),\n                'width': int(attr['frameWidth']),\n            })\n        return formats",
        "begin_line": 68,
        "end_line": 91,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.vevo.VevoIE._formats_from_smil#93",
        "src_path": "youtube_dl/extractor/vevo.py",
        "class_name": "youtube_dl.extractor.vevo.VevoIE",
        "signature": "youtube_dl.extractor.vevo.VevoIE._formats_from_smil(self, smil_xml)",
        "snippet": "    def _formats_from_smil(self, smil_xml):\n        formats = []\n        smil_doc = xml.etree.ElementTree.fromstring(smil_xml.encode('utf-8'))\n        els = smil_doc.findall('.//{http://www.w3.org/2001/SMIL20/Language}video')\n        for el in els:\n            src = el.attrib['src']\n            m = re.match(r'''(?xi)\n                (?P<ext>[a-z0-9]+):\n                (?P<path>\n                    [/a-z0-9]+     # The directory and main part of the URL\n                    _(?P<cbr>[0-9]+)k\n                    _(?P<width>[0-9]+)x(?P<height>[0-9]+)\n                    _(?P<vcodec>[a-z0-9]+)\n                    _(?P<vbr>[0-9]+)\n                    _(?P<acodec>[a-z0-9]+)\n                    _(?P<abr>[0-9]+)\n                    \\.[a-z0-9]+  # File extension\n                )''', src)\n            if not m:\n                continue\n\n            format_url = self._SMIL_BASE_URL + m.group('path')\n            formats.append({\n                'url': format_url,\n                'format_id': 'SMIL_' + m.group('cbr'),\n                'vcodec': m.group('vcodec'),\n                'acodec': m.group('acodec'),\n                'vbr': int(m.group('vbr')),\n                'abr': int(m.group('abr')),\n                'ext': m.group('ext'),\n                'width': int(m.group('width')),\n                'height': int(m.group('height')),\n            })\n        return formats",
        "begin_line": 93,
        "end_line": 126,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.vevo.VevoIE._real_extract#128",
        "src_path": "youtube_dl/extractor/vevo.py",
        "class_name": "youtube_dl.extractor.vevo.VevoIE",
        "signature": "youtube_dl.extractor.vevo.VevoIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        json_url = 'http://videoplayer.vevo.com/VideoService/AuthenticateVideo?isrc=%s' % video_id\n        video_info = self._download_json(json_url, video_id)['video']\n\n        formats = self._formats_from_json(video_info)\n\n        is_explicit = video_info.get('isExplicit')\n        if is_explicit is True:\n            age_limit = 18\n        elif is_explicit is False:\n            age_limit = 0\n        else:\n            age_limit = None\n\n        # Download SMIL\n        smil_blocks = sorted((\n            f for f in video_info['videoVersions']\n            if f['sourceType'] == 13),\n            key=lambda f: f['version'])\n\n        smil_url = '%s/Video/V2/VFILE/%s/%sr.smil' % (\n            self._SMIL_BASE_URL, video_id, video_id.lower())\n        if smil_blocks:\n            smil_url_m = self._search_regex(\n                r'url=\"([^\"]+)\"', smil_blocks[-1]['data'], 'SMIL URL',\n                fatal=False)\n            if smil_url_m is not None:\n                smil_url = smil_url_m\n\n        try:\n            smil_xml = self._download_webpage(smil_url, video_id,\n                                              'Downloading SMIL info')\n            formats.extend(self._formats_from_smil(smil_xml))\n        except ExtractorError as ee:\n            if not isinstance(ee.cause, compat_HTTPError):\n                raise\n            self._downloader.report_warning(\n                'Cannot download SMIL information, falling back to JSON ..')\n\n        timestamp_ms = int(self._search_regex(\n            r'/Date\\((\\d+)\\)/', video_info['launchDate'], 'launch date'))\n        upload_date = datetime.datetime.fromtimestamp(timestamp_ms // 1000)\n        return {\n            'id': video_id,\n            'title': video_info['title'],\n            'formats': formats,\n            'thumbnail': video_info['imageUrl'],\n            'upload_date': upload_date.strftime('%Y%m%d'),\n            'uploader': video_info['mainArtists'][0]['artistName'],\n            'duration': video_info['duration'],\n            'age_limit': age_limit,\n        }",
        "begin_line": 128,
        "end_line": 182,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.canalc2.Canalc2IE._real_extract#23",
        "src_path": "youtube_dl/extractor/canalc2.py",
        "class_name": "youtube_dl.extractor.canalc2.Canalc2IE",
        "signature": "youtube_dl.extractor.canalc2.Canalc2IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        video_id = re.match(self._VALID_URL, url).group('id')\n        # We need to set the voir field for getting the file name\n        url = 'http://www.canalc2.tv/video.asp?idVideo=%s&voir=oui' % video_id\n        webpage = self._download_webpage(url, video_id)\n        file_name = self._search_regex(\n            r\"so\\.addVariable\\('file','(.*?)'\\);\",\n            webpage, 'file name')\n        video_url = 'http://vod-flash.u-strasbg.fr:8080/' + file_name\n\n        title = self._html_search_regex(\n            r'class=\"evenement8\">(.*?)</a>', webpage, 'title')\n\n        return {\n            'id': video_id,\n            'ext': 'mp4',\n            'url': video_url,\n            'title': title,\n        }",
        "begin_line": 23,
        "end_line": 41,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.vube.VubeIE._real_extract#30",
        "src_path": "youtube_dl/extractor/vube.py",
        "class_name": "youtube_dl.extractor.vube.VubeIE",
        "signature": "youtube_dl.extractor.vube.VubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        video = self._download_json('http://vube.com/api/v2/video/%s' % video_id,\n            video_id, 'Downloading video JSON')\n\n        public_id = video['public_id']\n\n        formats = [{'url': 'http://video.thestaticvube.com/video/%s/%s.mp4' % (fmt['media_resolution_id'], public_id),\n                   'height': int(fmt['height']),\n                   'abr': int(fmt['audio_bitrate']),\n                   'vbr': int(fmt['video_bitrate']),\n                   'format_id': fmt['media_resolution_id']\n                   } for fmt in video['mtm'] if fmt['transcoding_status'] == 'processed']\n\n        self._sort_formats(formats)\n\n        title = video['title']\n        description = video.get('description')\n        thumbnail = video['thumbnail_src']\n        if thumbnail.startswith('//'):\n            thumbnail = 'http:' + thumbnail\n        uploader = video['user_alias']\n        uploader_id = video['user_url_id']\n        upload_date = datetime.datetime.fromtimestamp(int(video['upload_time'])).strftime('%Y%m%d')\n        duration = video['duration']\n        view_count = video['raw_view_count']\n        like_count = video['total_likes']\n        dislike_count= video['total_hates']\n\n        comment = self._download_json('http://vube.com/api/video/%s/comment' % video_id,\n            video_id, 'Downloading video comment JSON')\n\n        comment_count = comment['total']\n\n        return {\n            'id': video_id,\n            'formats': formats,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'upload_date': upload_date,\n            'duration': duration,\n            'view_count': view_count,\n            'like_count': like_count,\n            'dislike_count': dislike_count,\n            'comment_count': comment_count,\n        }",
        "begin_line": 30,
        "end_line": 80,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.kankan.KankanIE._real_extract#24",
        "src_path": "youtube_dl/extractor/kankan.py",
        "class_name": "youtube_dl.extractor.kankan.KankanIE",
        "signature": "youtube_dl.extractor.kankan.KankanIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._search_regex(r'(?:G_TITLE=|G_MOVIE_TITLE = )[\\'\"](.+?)[\\'\"]', webpage, 'video title')\n        surls = re.search(r'surls:\\[\\'.+?\\'\\]|lurl:\\'.+?\\.flv\\'', webpage).group(0)\n        gcids = re.findall(r\"http://.+?/.+?/(.+?)/\", surls)\n        gcid = gcids[-1]\n\n        info_url = 'http://p2s.cl.kankan.com/getCdnresource_flv?gcid=%s' % gcid\n        video_info_page = self._download_webpage(\n            info_url, video_id, 'Downloading video url info')\n        ip = self._search_regex(r'ip:\"(.+?)\"', video_info_page, 'video url ip')\n        path = self._search_regex(r'path:\"(.+?)\"', video_info_page, 'video url path')\n        param1 = self._search_regex(r'param1:(\\d+)', video_info_page, 'param1')\n        param2 = self._search_regex(r'param2:(\\d+)', video_info_page, 'param2')\n        key = _md5('xl_mp43651' + param1 + param2)\n        video_url = 'http://%s%s?key=%s&key1=%s' % (ip, path, key, param2)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n        }",
        "begin_line": 24,
        "end_line": 48,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.veehd.VeeHDIE._real_extract#27",
        "src_path": "youtube_dl/extractor/veehd.py",
        "class_name": "youtube_dl.extractor.veehd.VeeHDIE",
        "signature": "youtube_dl.extractor.veehd.VeeHDIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        # VeeHD seems to send garbage on the first request.\n        # See https://github.com/rg3/youtube-dl/issues/2102\n        self._download_webpage(url, video_id, 'Requesting webpage')\n        webpage = self._download_webpage(url, video_id)\n        player_path = self._search_regex(\n            r'\\$\\(\"#playeriframe\"\\).attr\\({src : \"(.+?)\"',\n            webpage, 'player path')\n        player_url = compat_urlparse.urljoin(url, player_path)\n\n        self._download_webpage(player_url, video_id, 'Requesting player page')\n        player_page = self._download_webpage(\n            player_url, video_id, 'Downloading player page')\n        config_json = self._search_regex(\n            r'value=\\'config=({.+?})\\'', player_page, 'config json')\n        config = json.loads(config_json)\n\n        video_url = compat_urlparse.unquote(config['clip']['url'])\n        title = clean_html(get_element_by_id('videoName', webpage).rpartition('|')[0])\n        uploader_id = self._html_search_regex(r'<a href=\"/profile/\\d+\">(.+?)</a>',\n            webpage, 'uploader')\n        thumbnail = self._search_regex(r'<img id=\"veehdpreview\" src=\"(.+?)\"',\n            webpage, 'thumbnail')\n        description = self._html_search_regex(r'<td class=\"infodropdown\".*?<div>(.*?)<ul',\n            webpage, 'description', flags=re.DOTALL)\n\n        return {\n            '_type': 'video',\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'ext': 'mp4',\n            'uploader_id': uploader_id,\n            'thumbnail': thumbnail,\n            'description': description,\n        }",
        "begin_line": 27,
        "end_line": 65,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_unsigned_long_long#29",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_unsigned_long_long(self)",
        "snippet": "    def read_unsigned_long_long(self):\n        return struct_unpack('!Q', self.read(8))[0]",
        "begin_line": 29,
        "end_line": 30,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_unsigned_int#32",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_unsigned_int(self)",
        "snippet": "    def read_unsigned_int(self):\n        return struct_unpack('!I', self.read(4))[0]",
        "begin_line": 32,
        "end_line": 33,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_unsigned_char#35",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_unsigned_char(self)",
        "snippet": "    def read_unsigned_char(self):\n        return struct_unpack('!B', self.read(1))[0]",
        "begin_line": 35,
        "end_line": 36,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_string#38",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_string(self)",
        "snippet": "    def read_string(self):\n        res = b''\n        while True:\n            char = self.read(1)\n            if char == b'\\x00':\n                break\n            res += char\n        return res",
        "begin_line": 38,
        "end_line": 45,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_box_info#47",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_box_info(self)",
        "snippet": "    def read_box_info(self):\n        \"\"\"\n        Read a box and return the info as a tuple: (box_size, box_type, box_data)\n        \"\"\"\n        real_size = size = self.read_unsigned_int()\n        box_type = self.read(4)\n        header_end = 8\n        if size == 1:\n            real_size = self.read_unsigned_long_long()\n            header_end = 16\n        return real_size, box_type, self.read(real_size-header_end)",
        "begin_line": 47,
        "end_line": 57,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_asrt#59",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_asrt(self)",
        "snippet": "    def read_asrt(self):\n        # version\n        self.read_unsigned_char()\n        # flags\n        self.read(3)\n        quality_entry_count = self.read_unsigned_char()\n        # QualityEntryCount\n        for i in range(quality_entry_count):\n            self.read_string()\n\n        segment_run_count = self.read_unsigned_int()\n        segments = []\n        for i in range(segment_run_count):\n            first_segment = self.read_unsigned_int()\n            fragments_per_segment = self.read_unsigned_int()\n            segments.append((first_segment, fragments_per_segment))\n\n        return {\n            'segment_run': segments,\n        }",
        "begin_line": 59,
        "end_line": 78,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_afrt#80",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_afrt(self)",
        "snippet": "    def read_afrt(self):\n        # version\n        self.read_unsigned_char()\n        # flags\n        self.read(3)\n        # time scale\n        self.read_unsigned_int()\n\n        quality_entry_count = self.read_unsigned_char()\n        # QualitySegmentUrlModifiers\n        for i in range(quality_entry_count):\n            self.read_string()\n\n        fragments_count = self.read_unsigned_int()\n        fragments = []\n        for i in range(fragments_count):\n            first = self.read_unsigned_int()\n            first_ts = self.read_unsigned_long_long()\n            duration = self.read_unsigned_int()\n            if duration == 0:\n                discontinuity_indicator = self.read_unsigned_char()\n            else:\n                discontinuity_indicator = None\n            fragments.append({\n                'first': first,\n                'ts': first_ts,\n                'duration': duration,\n                'discontinuity_indicator': discontinuity_indicator,\n            })\n\n        return {\n            'fragments': fragments,\n        }",
        "begin_line": 80,
        "end_line": 112,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_abst#114",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_abst(self)",
        "snippet": "    def read_abst(self):\n        # version\n        self.read_unsigned_char()\n        # flags\n        self.read(3)\n\n        self.read_unsigned_int()  # BootstrapinfoVersion\n        # Profile,Live,Update,Reserved\n        self.read(1)\n        # time scale\n        self.read_unsigned_int()\n        # CurrentMediaTime\n        self.read_unsigned_long_long()\n        # SmpteTimeCodeOffset\n        self.read_unsigned_long_long()\n\n        self.read_string()  # MovieIdentifier\n        server_count = self.read_unsigned_char()\n        # ServerEntryTable\n        for i in range(server_count):\n            self.read_string()\n        quality_count = self.read_unsigned_char()\n        # QualityEntryTable\n        for i in range(quality_count):\n            self.read_string()\n        # DrmData\n        self.read_string()\n        # MetaData\n        self.read_string()\n\n        segments_count = self.read_unsigned_char()\n        segments = []\n        for i in range(segments_count):\n            box_size, box_type, box_data = self.read_box_info()\n            assert box_type == b'asrt'\n            segment = FlvReader(box_data).read_asrt()\n            segments.append(segment)\n        fragments_run_count = self.read_unsigned_char()\n        fragments = []\n        for i in range(fragments_run_count):\n            box_size, box_type, box_data = self.read_box_info()\n            assert box_type == b'afrt'\n            fragments.append(FlvReader(box_data).read_afrt())\n\n        return {\n            'segments': segments,\n            'fragments': fragments,\n        }",
        "begin_line": 114,
        "end_line": 161,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.FlvReader.read_bootstrap_info#163",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.FlvReader",
        "signature": "youtube_dl.downloader.f4m.FlvReader.read_bootstrap_info(self)",
        "snippet": "    def read_bootstrap_info(self):\n        total_size, box_type, box_data = self.read_box_info()\n        assert box_type == b'abst'\n        return FlvReader(box_data).read_abst()",
        "begin_line": 163,
        "end_line": 166,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.read_bootstrap_info#169",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m",
        "signature": "youtube_dl.downloader.f4m.read_bootstrap_info(bootstrap_bytes)",
        "snippet": "def read_bootstrap_info(bootstrap_bytes):\n    return FlvReader(bootstrap_bytes).read_bootstrap_info()",
        "begin_line": 169,
        "end_line": 170,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.build_fragments_list#173",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m",
        "signature": "youtube_dl.downloader.f4m.build_fragments_list(boot_info)",
        "snippet": "def build_fragments_list(boot_info):\n    \"\"\" Return a list of (segment, fragment) for each fragment in the video \"\"\"\n    res = []\n    segment_run_table = boot_info['segments'][0]\n    # I've only found videos with one segment\n    segment_run_entry = segment_run_table['segment_run'][0]\n    n_frags = segment_run_entry[1]\n    fragment_run_entry_table = boot_info['fragments'][0]['fragments']\n    first_frag_number = fragment_run_entry_table[0]['first']\n    for (i, frag_number) in zip(range(1, n_frags+1), itertools.count(first_frag_number)):\n        res.append((1, frag_number))\n    return res",
        "begin_line": 173,
        "end_line": 184,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.write_flv_header#187",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m",
        "signature": "youtube_dl.downloader.f4m.write_flv_header(stream, metadata)",
        "snippet": "def write_flv_header(stream, metadata):\n    \"\"\"Writes the FLV header and the metadata to stream\"\"\"\n    # FLV header\n    stream.write(b'FLV\\x01')\n    stream.write(b'\\x05')\n    stream.write(b'\\x00\\x00\\x00\\x09')\n    # FLV File body\n    stream.write(b'\\x00\\x00\\x00\\x00')\n    # FLVTAG\n    # Script data\n    stream.write(b'\\x12')\n    # Size of the metadata with 3 bytes\n    stream.write(struct_pack('!L', len(metadata))[1:])\n    stream.write(b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00')\n    stream.write(metadata)\n    # Magic numbers extracted from the output files produced by AdobeHDS.php\n    #(https://github.com/K-S-V/Scripts)\n    stream.write(b'\\x00\\x00\\x01\\x73')",
        "begin_line": 187,
        "end_line": 204,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.f4m._add_ns#207",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m",
        "signature": "youtube_dl.downloader.f4m._add_ns(prop)",
        "snippet": "def _add_ns(prop):\n    return '{http://ns.adobe.com/f4m/1.0}%s' % prop",
        "begin_line": 207,
        "end_line": 208,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.HttpQuietDownloader.to_screen#212",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.HttpQuietDownloader",
        "signature": "youtube_dl.downloader.f4m.HttpQuietDownloader.to_screen(self, *args, **kargs)",
        "snippet": "    def to_screen(self, *args, **kargs):\n        pass",
        "begin_line": 212,
        "end_line": 213,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.f4m.F4mFD.real_download#221",
        "src_path": "youtube_dl/downloader/f4m.py",
        "class_name": "youtube_dl.downloader.f4m.F4mFD",
        "signature": "youtube_dl.downloader.f4m.F4mFD.real_download(self, filename, info_dict)",
        "snippet": "    def real_download(self, filename, info_dict):\n        man_url = info_dict['url']\n        self.to_screen('[download] Downloading f4m manifest')\n        manifest = self.ydl.urlopen(man_url).read()\n        self.report_destination(filename)\n        http_dl = HttpQuietDownloader(self.ydl,\n            {\n                'continuedl': True,\n                'quiet': True,\n                'noprogress': True,\n                'test': self.params.get('test', False),\n            })\n\n        doc = etree.fromstring(manifest)\n        formats = [(int(f.attrib.get('bitrate', -1)), f) for f in doc.findall(_add_ns('media'))]\n        formats = sorted(formats, key=lambda f: f[0])\n        rate, media = formats[-1]\n        base_url = compat_urlparse.urljoin(man_url, media.attrib['url'])\n        bootstrap = base64.b64decode(doc.find(_add_ns('bootstrapInfo')).text)\n        metadata = base64.b64decode(media.find(_add_ns('metadata')).text)\n        boot_info = read_bootstrap_info(bootstrap)\n        fragments_list = build_fragments_list(boot_info)\n        if self.params.get('test', False):\n            # We only download the first fragment\n            fragments_list = fragments_list[:1]\n        total_frags = len(fragments_list)\n\n        tmpfilename = self.temp_name(filename)\n        (dest_stream, tmpfilename) = sanitize_open(tmpfilename, 'wb')\n        write_flv_header(dest_stream, metadata)\n\n        # This dict stores the download progress, it's updated by the progress\n        # hook\n        state = {\n            'downloaded_bytes': 0,\n            'frag_counter': 0,\n        }\n        start = time.time()\n\n        def frag_progress_hook(status):\n            frag_total_bytes = status.get('total_bytes', 0)\n            estimated_size = (state['downloaded_bytes'] +\n                (total_frags - state['frag_counter']) * frag_total_bytes)\n            if status['status'] == 'finished':\n                state['downloaded_bytes'] += frag_total_bytes\n                state['frag_counter'] += 1\n                progress = self.calc_percent(state['frag_counter'], total_frags)\n                byte_counter = state['downloaded_bytes']\n            else:\n                frag_downloaded_bytes = status['downloaded_bytes']\n                byte_counter = state['downloaded_bytes'] + frag_downloaded_bytes\n                frag_progress = self.calc_percent(frag_downloaded_bytes,\n                    frag_total_bytes)\n                progress = self.calc_percent(state['frag_counter'], total_frags)\n                progress += frag_progress / float(total_frags)\n\n            eta = self.calc_eta(start, time.time(), estimated_size, byte_counter)\n            self.report_progress(progress, format_bytes(estimated_size),\n                status.get('speed'), eta)\n        http_dl.add_progress_hook(frag_progress_hook)\n\n        frags_filenames = []\n        for (seg_i, frag_i) in fragments_list:\n            name = 'Seg%d-Frag%d' % (seg_i, frag_i)\n            url = base_url + name\n            frag_filename = '%s-%s' % (tmpfilename, name)\n            success = http_dl.download(frag_filename, {'url': url})\n            if not success:\n                return False\n            with open(frag_filename, 'rb') as down:\n                down_data = down.read()\n                reader = FlvReader(down_data)\n                while True:\n                    _, box_type, box_data = reader.read_box_info()\n                    if box_type == b'mdat':\n                        dest_stream.write(box_data)\n                        break\n            frags_filenames.append(frag_filename)\n\n        self.report_finish(format_bytes(state['downloaded_bytes']), time.time() - start)\n\n        self.try_rename(tmpfilename, filename)\n        for frag_file in frags_filenames:\n            os.remove(frag_file)\n\n        fsize = os.path.getsize(encodeFilename(filename))\n        self._hook_progress({\n            'downloaded_bytes': fsize,\n            'total_bytes': fsize,\n            'filename': filename,\n            'status': 'finished',\n        })\n\n        return True",
        "begin_line": 221,
        "end_line": 314,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.clipsyndicate.ClipsyndicateIE._real_extract#24",
        "src_path": "youtube_dl/extractor/clipsyndicate.py",
        "class_name": "youtube_dl.extractor.clipsyndicate.ClipsyndicateIE",
        "signature": "youtube_dl.extractor.clipsyndicate.ClipsyndicateIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        js_player = self._download_webpage(\n            'http://eplayer.clipsyndicate.com/embed/player.js?va_id=%s' % video_id,\n            video_id, u'Downlaoding player')\n        # it includes a required token\n        flvars = self._search_regex(r'flvars: \"(.*?)\"', js_player, u'flvars')\n\n        pdoc = self._download_xml(\n            'http://eplayer.clipsyndicate.com/osmf/playlist?%s' % flvars,\n            video_id, u'Downloading video info',\n            transform_source=fix_xml_ampersands)\n\n        track_doc = pdoc.find('trackList/track')\n        def find_param(name):\n            node = find_xpath_attr(track_doc, './/param', 'name', name)\n            if node is not None:\n                return node.attrib['value']\n\n        return {\n            'id': video_id,\n            'title': find_param('title'),\n            'url': track_doc.find('location').text,\n            'thumbnail': find_param('thumbnail'),\n            'duration': int(find_param('duration')),\n        }",
        "begin_line": 24,
        "end_line": 50,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.la7.LA7IE._real_extract#33",
        "src_path": "youtube_dl/extractor/la7.py",
        "class_name": "youtube_dl.extractor.la7.LA7IE",
        "signature": "youtube_dl.extractor.la7.LA7IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        xml_url = 'http://www.la7.tv/repliche/content/index.php?contentId=%s' % video_id\n        doc = self._download_xml(xml_url, video_id)\n\n        video_title = doc.find('title').text\n        description = doc.find('description').text\n        duration = parse_duration(doc.find('duration').text)\n        thumbnail = doc.find('img').text\n        view_count = int(doc.find('views').text)\n\n        prefix = doc.find('.//fqdn').text.strip().replace('auto:', 'http:')\n\n        formats = [{\n            'format': vnode.find('quality').text,\n            'tbr': int(vnode.find('quality').text),\n            'url': vnode.find('fms').text.strip().replace('mp4:', prefix),\n        } for vnode in doc.findall('.//videos/video')]\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'formats': formats,\n            'view_count': view_count,\n        }",
        "begin_line": 33,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.hotnewhiphop.HotNewHipHopIE._real_extract#26",
        "src_path": "youtube_dl/extractor/hotnewhiphop.py",
        "class_name": "youtube_dl.extractor.hotnewhiphop.HotNewHipHopIE",
        "signature": "youtube_dl.extractor.hotnewhiphop.HotNewHipHopIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('id')\n\n        webpage_src = self._download_webpage(url, video_id)\n\n        video_url_base64 = self._search_regex(\n            r'data-path=\"(.*?)\"', webpage_src, u'video URL', fatal=False)\n\n        if video_url_base64 is None:\n            video_url = self._search_regex(\n                r'\"contentUrl\" content=\"(.*?)\"', webpage_src, u'video URL')\n            return self.url_result(video_url, ie='Youtube')\n\n        reqdata = compat_urllib_parse.urlencode([\n            ('mediaType', 's'),\n            ('mediaId', video_id),\n        ])\n        r = compat_urllib_request.Request(\n            'http://www.hotnewhiphop.com/ajax/media/getActions/', data=reqdata)\n        r.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        mkd = self._download_json(\n            r, video_id, note='Requesting media key',\n            errnote='Could not download media key')\n        if 'mediaKey' not in mkd:\n            raise ExtractorError('Did not get a media key')\n\n        redirect_url = base64.b64decode(video_url_base64).decode('utf-8')\n        redirect_req = HEADRequest(redirect_url)\n        req = self._request_webpage(\n            redirect_req, video_id,\n            note='Resolving final URL', errnote='Could not resolve final URL')\n        video_url = req.geturl()\n        if video_url.endswith('.html'):\n            raise ExtractorError('Redirect failed')\n\n        video_title = self._og_search_title(webpage_src).strip()\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': video_title,\n            'thumbnail': self._og_search_thumbnail(webpage_src),\n        }",
        "begin_line": 26,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.ndtv.NDTVIE._real_extract#23",
        "src_path": "youtube_dl/extractor/ndtv.py",
        "class_name": "youtube_dl.extractor.ndtv.NDTVIE",
        "signature": "youtube_dl.extractor.ndtv.NDTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        filename = self._search_regex(\n            r\"__filename='([^']+)'\", webpage, u'video filename')\n        video_url = (u'http://bitcast-b.bitgravity.com/ndtvod/23372/ndtv/%s' %\n                     filename)\n\n        duration_str = filename = self._search_regex(\n            r\"__duration='([^']+)'\", webpage, u'duration', fatal=False)\n        duration = None if duration_str is None else int(duration_str)\n\n        date_m = re.search(r'''(?x)\n            <p\\s+class=\"vod_dateline\">\\s*\n                Published\\s+On:\\s*\n                (?P<monthname>[A-Za-z]+)\\s+(?P<day>[0-9]+),\\s*(?P<year>[0-9]+)\n            ''', webpage)\n        upload_date = None\n        assert date_m\n        if date_m is not None:\n            month = month_by_name(date_m.group('monthname'))\n            if month is not None:\n                upload_date = '%s%02d%02d' % (\n                    date_m.group('year'), month, int(date_m.group('day')))\n\n        description = self._og_search_description(webpage)\n        READ_MORE = u' (Read more)'\n        if description.endswith(READ_MORE):\n            description = description[:-len(READ_MORE)]\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': self._og_search_title(webpage),\n            'description': description,\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'duration': duration,\n            'upload_date': upload_date,\n        }",
        "begin_line": 23,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.freespeech.FreespeechIE._real_extract#26",
        "src_path": "youtube_dl/extractor/freespeech.py",
        "class_name": "youtube_dl.extractor.freespeech.FreespeechIE",
        "signature": "youtube_dl.extractor.freespeech.FreespeechIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        title = mobj.group('title')\n        webpage = self._download_webpage(url, title)\n        info_json = self._search_regex(r'jQuery.extend\\(Drupal.settings, ({.*?})\\);', webpage, 'info')\n        info = json.loads(info_json)\n\n        return {\n            '_type': 'url',\n            'url': info['jw_player']['basic_video_node_player']['file'],\n            'ie_key': 'Youtube',\n        }",
        "begin_line": 26,
        "end_line": 37,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.jukebox.JukeboxIE._real_extract#17",
        "src_path": "youtube_dl/extractor/jukebox.py",
        "class_name": "youtube_dl.extractor.jukebox.JukeboxIE",
        "signature": "youtube_dl.extractor.jukebox.JukeboxIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('video_id')\n\n        html = self._download_webpage(url, video_id)\n\n        mobj = re.search(self._IFRAME, html)\n        if mobj is None:\n            raise ExtractorError(u'Cannot extract iframe url')\n        iframe_url = unescapeHTML(mobj.group('iframe'))\n\n        iframe_html = self._download_webpage(iframe_url, video_id, 'Downloading iframe')\n        mobj = re.search(r'class=\"jkb_waiting\"', iframe_html)\n        if mobj is not None:\n            raise ExtractorError(u'Video is not available(in your country?)!')\n\n        self.report_extraction(video_id)\n\n        mobj = re.search(self._VIDEO_URL, iframe_html)\n        if mobj is None:\n            mobj = re.search(self._IS_YOUTUBE, iframe_html)\n            if mobj is None:\n                raise ExtractorError(u'Cannot extract video url')\n            youtube_url = unescapeHTML(mobj.group('youtube_url')).replace('\\/','/')\n            self.to_screen(u'Youtube video detected')\n            return self.url_result(youtube_url,ie='Youtube')\n        video_url = unescapeHTML(mobj.group('video_url')).replace('\\/','/')\n        video_ext = unescapeHTML(mobj.group('video_ext'))\n\n        mobj = re.search(self._TITLE, html)\n        if mobj is None:\n            raise ExtractorError(u'Cannot extract title')\n        title = unescapeHTML(mobj.group('title'))\n        artist = unescapeHTML(mobj.group('artist'))\n\n        return [{'id': video_id,\n                 'url': video_url,\n                 'title': artist + '-' + title,\n                 'ext': video_ext\n                 }]",
        "begin_line": 17,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.wistia.WistiaIE._real_extract#19",
        "src_path": "youtube_dl/extractor/wistia.py",
        "class_name": "youtube_dl.extractor.wistia.WistiaIE",
        "signature": "youtube_dl.extractor.wistia.WistiaIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        data_json = self._html_search_regex(\n            r'Wistia.iframeInit\\((.*?), {}\\);', webpage, u'video data')\n\n        data = json.loads(data_json)\n\n        formats = []\n        thumbnails = []\n        for atype, a in data['assets'].items():\n            if atype == 'still':\n                thumbnails.append({\n                    'url': a['url'],\n                    'resolution': '%dx%d' % (a['width'], a['height']),\n                })\n                continue\n            if atype == 'preview':\n                continue\n            formats.append({\n                'format_id': atype,\n                'url': a['url'],\n                'width': a['width'],\n                'height': a['height'],\n                'filesize': a['size'],\n                'ext': a['ext'],\n                'preference': 1 if atype == 'original' else None,\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': data['name'],\n            'formats': formats,\n            'thumbnails': thumbnails,\n        }",
        "begin_line": 19,
        "end_line": 57,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.spiegel.SpiegelIE._real_extract#27",
        "src_path": "youtube_dl/extractor/spiegel.py",
        "class_name": "youtube_dl.extractor.spiegel.SpiegelIE",
        "signature": "youtube_dl.extractor.spiegel.SpiegelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('videoID')\n\n        webpage = self._download_webpage(url, video_id)\n\n        video_title = self._html_search_regex(\n            r'<div class=\"module-title\">(.*?)</div>', webpage, 'title')\n\n        xml_url = 'http://video2.spiegel.de/flash/' + video_id + '.xml'\n        idoc = self._download_xml(\n            xml_url, video_id,\n            note='Downloading XML', errnote='Failed to download XML')\n\n        formats = [\n            {\n                'format_id': n.tag.rpartition('type')[2],\n                'url': 'http://video2.spiegel.de/flash/' + n.find('./filename').text,\n                'width': int(n.find('./width').text),\n                'height': int(n.find('./height').text),\n                'abr': int(n.find('./audiobitrate').text),\n                'vbr': int(n.find('./videobitrate').text),\n                'vcodec': n.find('./codec').text,\n                'acodec': 'MP4A',\n            }\n            for n in list(idoc)\n            # Blacklist type 6, it's extremely LQ and not available on the same server\n            if n.tag.startswith('type') and n.tag != 'type6'\n        ]\n        duration = float(idoc[0].findall('./duration')[0].text)\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 27,
        "end_line": 65,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.photobucket.PhotobucketIE._real_extract#30",
        "src_path": "youtube_dl/extractor/photobucket.py",
        "class_name": "youtube_dl.extractor.photobucket.PhotobucketIE",
        "signature": "youtube_dl.extractor.photobucket.PhotobucketIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        # Extract id from URL\n        mobj = re.match(self._VALID_URL, url)\n        if mobj is None:\n            raise ExtractorError(u'Invalid URL: %s' % url)\n\n        video_id = mobj.group('id')\n\n        video_extension = mobj.group('ext')\n\n        # Retrieve video webpage to extract further information\n        webpage = self._download_webpage(url, video_id)\n\n        # Extract URL, uploader, and title from webpage\n        self.report_extraction(video_id)\n        # We try first by looking the javascript code:\n        mobj = re.search(r'Pb\\.Data\\.Shared\\.put\\(Pb\\.Data\\.Shared\\.MEDIA, (?P<json>.*?)\\);', webpage)\n        if mobj is not None:\n            info = json.loads(mobj.group('json'))\n            return [{\n                'id':       video_id,\n                'url':      info[u'downloadUrl'],\n                'uploader': info[u'username'],\n                'upload_date':  datetime.date.fromtimestamp(info[u'creationDate']).strftime('%Y%m%d'),\n                'title':    info[u'title'],\n                'ext':      video_extension,\n                'thumbnail': info[u'thumbUrl'],\n            }]\n\n        # We try looking in other parts of the webpage\n        video_url = self._search_regex(r'<link rel=\"video_src\" href=\".*\\?file=([^\"]+)\" />',\n            webpage, u'video URL')\n\n        mobj = re.search(r'<title>(.*) video by (.*) - Photobucket</title>', webpage)\n        if mobj is None:\n            raise ExtractorError(u'Unable to extract title')\n        video_title = mobj.group(1).decode('utf-8')\n        video_uploader = mobj.group(2).decode('utf-8')\n\n        return [{\n            'id':       video_id.decode('utf-8'),\n            'url':      video_url.decode('utf-8'),\n            'uploader': video_uploader,\n            'upload_date':  None,\n            'title':    video_title,\n            'ext':      video_extension.decode('utf-8'),\n        }]",
        "begin_line": 30,
        "end_line": 76,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor._list_available_subtitles#15",
        "src_path": "youtube_dl/extractor/subtitles.py",
        "class_name": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor",
        "signature": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor._list_available_subtitles(self, video_id, webpage)",
        "snippet": "    def _list_available_subtitles(self, video_id, webpage):\n        \"\"\" outputs the available subtitles for the video \"\"\"\n        sub_lang_list = self._get_available_subtitles(video_id, webpage)\n        auto_captions_list = self._get_available_automatic_caption(video_id, webpage)\n        sub_lang = \",\".join(list(sub_lang_list.keys()))\n        self.to_screen(u'%s: Available subtitles for video: %s' %\n                       (video_id, sub_lang))\n        auto_lang = \",\".join(auto_captions_list.keys())\n        self.to_screen(u'%s: Available automatic captions for video: %s' %\n                       (video_id, auto_lang))",
        "begin_line": 15,
        "end_line": 24,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor.extract_subtitles#26",
        "src_path": "youtube_dl/extractor/subtitles.py",
        "class_name": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor",
        "signature": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor.extract_subtitles(self, video_id, webpage)",
        "snippet": "    def extract_subtitles(self, video_id, webpage):\n        \"\"\"\n        returns {sub_lang: sub} ,{} if subtitles not found or None if the\n        subtitles aren't requested.\n        \"\"\"\n        if not self._have_to_download_any_subtitles:\n            return None\n        available_subs_list = {}\n        if self._downloader.params.get('writeautomaticsub', False):\n            available_subs_list.update(self._get_available_automatic_caption(video_id, webpage))\n        if self._downloader.params.get('writesubtitles', False):\n            available_subs_list.update(self._get_available_subtitles(video_id, webpage))\n\n        if not available_subs_list:  # error, it didn't get the available subtitles\n            return {}\n        if self._downloader.params.get('allsubtitles', False):\n            sub_lang_list = available_subs_list\n        else:\n            if self._downloader.params.get('subtitleslangs', False):\n                requested_langs = self._downloader.params.get('subtitleslangs')\n            elif 'en' in available_subs_list:\n                requested_langs = ['en']\n            else:\n                requested_langs = [list(available_subs_list.keys())[0]]\n\n            sub_lang_list = {}\n            for sub_lang in requested_langs:\n                if not sub_lang in available_subs_list:\n                    self._downloader.report_warning(u'no closed captions found in the specified language \"%s\"' % sub_lang)\n                    continue\n                sub_lang_list[sub_lang] = available_subs_list[sub_lang]\n\n        subtitles = {}\n        for sub_lang, url in sub_lang_list.items():\n            subtitle = self._request_subtitle_url(sub_lang, url)\n            if subtitle:\n                subtitles[sub_lang] = subtitle\n        return subtitles",
        "begin_line": 26,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor._download_subtitle_url#65",
        "src_path": "youtube_dl/extractor/subtitles.py",
        "class_name": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor",
        "signature": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor._download_subtitle_url(self, sub_lang, url)",
        "snippet": "    def _download_subtitle_url(self, sub_lang, url):\n        return self._download_webpage(url, None, note=False)",
        "begin_line": 65,
        "end_line": 66,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor._request_subtitle_url#68",
        "src_path": "youtube_dl/extractor/subtitles.py",
        "class_name": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor",
        "signature": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor._request_subtitle_url(self, sub_lang, url)",
        "snippet": "    def _request_subtitle_url(self, sub_lang, url):\n        \"\"\" makes the http request for the subtitle \"\"\"\n        try:\n            sub = self._download_subtitle_url(sub_lang, url)\n        except ExtractorError as err:\n            self._downloader.report_warning(u'unable to download video subtitles for %s: %s' % (sub_lang, compat_str(err)))\n            return\n        if not sub:\n            self._downloader.report_warning(u'Did not fetch video subtitles')\n            return\n        return sub",
        "begin_line": 68,
        "end_line": 78,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor._get_available_subtitles#80",
        "src_path": "youtube_dl/extractor/subtitles.py",
        "class_name": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor",
        "signature": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor._get_available_subtitles(self, video_id, webpage)",
        "snippet": "    def _get_available_subtitles(self, video_id, webpage):\n        \"\"\"\n        returns {sub_lang: url} or {} if not available\n        Must be redefined by the subclasses\n        \"\"\"\n\n        # By default, allow implementations to simply pass in the result\n        assert isinstance(webpage, dict), \\\n            '_get_available_subtitles not implemented'\n        return webpage",
        "begin_line": 80,
        "end_line": 89,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor._get_available_automatic_caption#91",
        "src_path": "youtube_dl/extractor/subtitles.py",
        "class_name": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor",
        "signature": "youtube_dl.extractor.subtitles.SubtitlesInfoExtractor._get_available_automatic_caption(self, video_id, webpage)",
        "snippet": "    def _get_available_automatic_caption(self, video_id, webpage):\n        \"\"\"\n        returns {sub_lang: url} or {} if not available\n        Must be redefined by the subclasses that support automatic captions,\n        otherwise it will return {}\n        \"\"\"\n        self._downloader.report_warning(u'Automatic Captions not supported by this server')\n        return {}",
        "begin_line": 91,
        "end_line": 98,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.tudou.TudouIE._url_for_id#30",
        "src_path": "youtube_dl/extractor/tudou.py",
        "class_name": "youtube_dl.extractor.tudou.TudouIE",
        "signature": "youtube_dl.extractor.tudou.TudouIE._url_for_id(self, id, quality=None)",
        "snippet": "    def _url_for_id(self, id, quality = None):\n        info_url = \"http://v2.tudou.com/f?id=\"+str(id)\n        if quality:\n            info_url += '&hd' + quality\n        webpage = self._download_webpage(info_url, id, \"Opening the info webpage\")\n        final_url = self._html_search_regex('>(.+?)</f>',webpage, 'video url')\n        return final_url",
        "begin_line": 30,
        "end_line": 36,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.tudou.TudouIE._real_extract#38",
        "src_path": "youtube_dl/extractor/tudou.py",
        "class_name": "youtube_dl.extractor.tudou.TudouIE",
        "signature": "youtube_dl.extractor.tudou.TudouIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group(2)\n        webpage = self._download_webpage(url, video_id)\n\n        m = re.search(r'vcode:\\s*[\\'\"](.+?)[\\'\"]', webpage)\n        if m and m.group(1):\n            return {\n                '_type': 'url',\n                'url': u'youku:' + m.group(1),\n                'ie_key': 'Youku'\n            }\n\n        title = self._search_regex(\n            r\",kw:\\s*['\\\"](.+?)[\\\"']\", webpage, u'title')\n        thumbnail_url = self._search_regex(\n            r\",pic:\\s*[\\\"'](.+?)[\\\"']\", webpage, u'thumbnail URL', fatal=False)\n\n        segs_json = self._search_regex(r'segs: \\'(.*)\\'', webpage, 'segments')\n        segments = json.loads(segs_json)\n        # It looks like the keys are the arguments that have to be passed as\n        # the hd field in the request url, we pick the higher\n        quality = sorted(segments.keys())[-1]\n        parts = segments[quality]\n        result = []\n        len_parts = len(parts)\n        if len_parts > 1:\n            self.to_screen(u'%s: found %s parts' % (video_id, len_parts))\n        for part in parts:\n            part_id = part['k']\n            final_url = self._url_for_id(part_id, quality)\n            ext = (final_url.split('?')[0]).split('.')[-1]\n            part_info = {'id': part_id,\n                          'url': final_url,\n                          'ext': ext,\n                          'title': title,\n                          'thumbnail': thumbnail_url,\n                          }\n            result.append(part_info)\n\n        return result",
        "begin_line": 38,
        "end_line": 78,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.xtube.XTubeIE._real_extract#31",
        "src_path": "youtube_dl/extractor/xtube.py",
        "class_name": "youtube_dl.extractor.xtube.XTubeIE",
        "signature": "youtube_dl.extractor.xtube.XTubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n        url = 'http://www.' + mobj.group('url')\n\n        req = compat_urllib_request.Request(url)\n        req.add_header('Cookie', 'age_verified=1')\n        webpage = self._download_webpage(req, video_id)\n\n        video_title = self._html_search_regex(r'<p class=\"title\">([^<]+)', webpage, 'title')\n        video_uploader = self._html_search_regex(\n            r'so_s\\.addVariable\\(\"owner_u\", \"([^\"]+)', webpage, 'uploader', fatal=False)\n        video_description = self._html_search_regex(\n            r'<p class=\"fieldsDesc\">([^<]+)', webpage, 'description', fatal=False)\n        video_url = self._html_search_regex(r'var videoMp4 = \"([^\"]+)', webpage, 'video_url').replace('\\\\/', '/')\n        duration = parse_duration(self._html_search_regex(\n            r'<span class=\"bold\">Runtime:</span> ([^<]+)</p>', webpage, 'duration', fatal=False))\n        view_count = self._html_search_regex(\n            r'<span class=\"bold\">Views:</span> ([\\d,\\.]+)</p>', webpage, 'view count', fatal=False)\n        if view_count:\n            view_count = str_to_int(view_count)\n        comment_count = self._html_search_regex(\n            r'<div id=\"commentBar\">([\\d,\\.]+) Comments</div>', webpage, 'comment count', fatal=False)\n        if comment_count:\n            comment_count = str_to_int(comment_count)\n\n        path = compat_urllib_parse_urlparse(video_url).path\n        extension = os.path.splitext(path)[1][1:]\n        format = path.split('/')[5].split('_')[:2]\n        format[0] += 'p'\n        format[1] += 'k'\n        format = \"-\".join(format)\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'uploader': video_uploader,\n            'description': video_description,\n            'duration': duration,\n            'view_count': view_count,\n            'comment_count': comment_count,\n            'url': video_url,\n            'ext': extension,\n            'format': format,\n            'format_id': format,\n            'age_limit': 18,\n        }",
        "begin_line": 31,
        "end_line": 77,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.daum.DaumIE._real_extract#26",
        "src_path": "youtube_dl/extractor/daum.py",
        "class_name": "youtube_dl.extractor.daum.DaumIE",
        "signature": "youtube_dl.extractor.daum.DaumIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group(1)\n        canonical_url = 'http://tvpot.daum.net/v/%s' % video_id\n        webpage = self._download_webpage(canonical_url, video_id)\n        full_id = self._search_regex(\n            r'<iframe src=\"http://videofarm.daum.net/controller/video/viewer/Video.html\\?.*?vid=(.+?)[&\"]',\n            webpage, u'full id')\n        query = compat_urllib_parse.urlencode({'vid': full_id})\n        info = self._download_xml(\n            'http://tvpot.daum.net/clip/ClipInfoXml.do?' + query, video_id,\n            u'Downloading video info')\n        urls = self._download_xml(\n            'http://videofarm.daum.net/controller/api/open/v1_2/MovieData.apixml?' + query,\n            video_id, u'Downloading video formats info')\n\n        self.to_screen(u'%s: Getting video urls' % video_id)\n        formats = []\n        for format_el in urls.findall('result/output_list/output_list'):\n            profile = format_el.attrib['profile']\n            format_query = compat_urllib_parse.urlencode({\n                'vid': full_id,\n                'profile': profile,\n            })\n            url_doc = self._download_xml(\n                'http://videofarm.daum.net/controller/api/open/v1_2/MovieLocation.apixml?' + format_query,\n                video_id, note=False)\n            format_url = url_doc.find('result/url').text\n            formats.append({\n                'url': format_url,\n                'ext': determine_ext(format_url),\n                'format_id': profile,\n            })\n\n        return {\n            'id': video_id,\n            'title': info.find('TITLE').text,\n            'formats': formats,\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'description': info.find('CONTENTS').text,\n            'duration': int(info.find('DURATION').text),\n            'upload_date': info.find('REGDTTM').text[:8],\n        }",
        "begin_line": 26,
        "end_line": 68,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.trilulilu.TriluliluIE._real_extract#22",
        "src_path": "youtube_dl/extractor/trilulilu.py",
        "class_name": "youtube_dl.extractor.trilulilu.TriluliluIE",
        "signature": "youtube_dl.extractor.trilulilu.TriluliluIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('video_id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        title = self._og_search_title(webpage)\n        thumbnail = self._og_search_thumbnail(webpage)\n        description = self._og_search_description(webpage)\n\n        log_str = self._search_regex(\n            r'block_flash_vars[ ]=[ ]({[^}]+})', webpage, u'log info')\n        log = json.loads(log_str)\n\n        format_url = (u'http://fs%(server)s.trilulilu.ro/%(hash)s/'\n                      u'video-formats2' % log)\n        format_doc = self._download_xml(\n            format_url, video_id,\n            note=u'Downloading formats',\n            errnote=u'Error while downloading formats')\n \n        video_url_template = (\n            u'http://fs%(server)s.trilulilu.ro/stream.php?type=video'\n            u'&source=site&hash=%(hash)s&username=%(userid)s&'\n            u'key=ministhebest&format=%%s&sig=&exp=' %\n            log)\n        formats = [\n            {\n                'format': fnode.text,\n                'url': video_url_template % fnode.text,\n                'ext': fnode.text.partition('-')[0]\n            }\n\n            for fnode in format_doc.findall('./formats/format')\n        ]\n\n        return {\n            '_type': 'video',\n            'id': video_id,\n            'formats': formats,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 22,
        "end_line": 65,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.xnxx.XNXXIE._real_extract#26",
        "src_path": "youtube_dl/extractor/xnxx.py",
        "class_name": "youtube_dl.extractor.xnxx.XNXXIE",
        "signature": "youtube_dl.extractor.xnxx.XNXXIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        if mobj is None:\n            raise ExtractorError(u'Invalid URL: %s' % url)\n        video_id = mobj.group(1)\n\n        # Get webpage content\n        webpage = self._download_webpage(url, video_id)\n\n        video_url = self._search_regex(self.VIDEO_URL_RE,\n            webpage, u'video URL')\n        video_url = compat_urllib_parse.unquote(video_url)\n\n        video_title = self._html_search_regex(self.VIDEO_TITLE_RE,\n            webpage, u'title')\n\n        video_thumbnail = self._search_regex(self.VIDEO_THUMB_RE,\n            webpage, u'thumbnail', fatal=False)\n\n        return [{\n            'id': video_id,\n            'url': video_url,\n            'uploader': None,\n            'upload_date': None,\n            'title': video_title,\n            'ext': 'flv',\n            'thumbnail': video_thumbnail,\n            'description': None,\n            'age_limit': 18,\n        }]",
        "begin_line": 26,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._set_language#48",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._set_language(self)",
        "snippet": "    def _set_language(self):\n        return bool(self._download_webpage(\n            self._LANG_URL, None,\n            note=u'Setting language', errnote='unable to set language',\n            fatal=False))",
        "begin_line": 48,
        "end_line": 52,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._login#54",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._login(self)",
        "snippet": "    def _login(self):\n        (username, password) = self._get_login_info()\n        # No authentication to be performed\n        if username is None:\n            if self._LOGIN_REQUIRED:\n                raise ExtractorError(u'No login info available, needed for using %s.' % self.IE_NAME, expected=True)\n            return False\n\n        login_page = self._download_webpage(\n            self._LOGIN_URL, None,\n            note=u'Downloading login page',\n            errnote=u'unable to fetch login page', fatal=False)\n        if login_page is False:\n            return\n\n        galx = self._search_regex(r'(?s)<input.+?name=\"GALX\".+?value=\"(.+?)\"',\n                                  login_page, u'Login GALX parameter')\n\n        # Log in\n        login_form_strs = {\n                u'continue': u'https://www.youtube.com/signin?action_handle_signin=true&feature=sign_in_button&hl=en_US&nomobiletemp=1',\n                u'Email': username,\n                u'GALX': galx,\n                u'Passwd': password,\n                u'PersistentCookie': u'yes',\n                u'_utf8': u'\u9731',\n                u'bgresponse': u'js_disabled',\n                u'checkConnection': u'',\n                u'checkedDomains': u'youtube',\n                u'dnConn': u'',\n                u'pstMsg': u'0',\n                u'rmShown': u'1',\n                u'secTok': u'',\n                u'signIn': u'Sign in',\n                u'timeStmp': u'',\n                u'service': u'youtube',\n                u'uilel': u'3',\n                u'hl': u'en_US',\n        }\n        # Convert to UTF-8 *before* urlencode because Python 2.x's urlencode\n        # chokes on unicode\n        login_form = dict((k.encode('utf-8'), v.encode('utf-8')) for k,v in login_form_strs.items())\n        login_data = compat_urllib_parse.urlencode(login_form).encode('ascii')\n\n        req = compat_urllib_request.Request(self._LOGIN_URL, login_data)\n        login_results = self._download_webpage(\n            req, None,\n            note=u'Logging in', errnote=u'unable to log in', fatal=False)\n        if login_results is False:\n            return False\n        if re.search(r'(?i)<form[^>]* id=\"gaia_loginform\"', login_results) is not None:\n            self._downloader.report_warning(u'unable to log in: bad username or password')\n            return False\n        return True",
        "begin_line": 54,
        "end_line": 107,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._confirm_age#109",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._confirm_age(self)",
        "snippet": "    def _confirm_age(self):\n        age_form = {\n            'next_url': '/',\n            'action_confirm': 'Confirm',\n        }\n        req = compat_urllib_request.Request(self._AGE_URL,\n            compat_urllib_parse.urlencode(age_form).encode('ascii'))\n\n        self._download_webpage(\n            req, None,\n            note=u'Confirming age', errnote=u'Unable to confirm age')\n        return True",
        "begin_line": 109,
        "end_line": 120,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._real_initialize#122",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeBaseInfoExtractor._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        if self._downloader is None:\n            return\n        if not self._set_language():\n            return\n        if not self._login():\n            return\n        self._confirm_age()",
        "begin_line": 122,
        "end_line": 129,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.suitable#320",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        \"\"\"Receives a URL and returns True if suitable for this IE.\"\"\"\n        if YoutubePlaylistIE.suitable(url): return False\n        return re.match(cls._VALID_URL, url) is not None",
        "begin_line": 320,
        "end_line": 323,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0001584786053882726,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.__init__#325",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.__init__(self, *args, **kwargs)",
        "snippet": "    def __init__(self, *args, **kwargs):\n        super(YoutubeIE, self).__init__(*args, **kwargs)\n        self._player_cache = {}",
        "begin_line": 325,
        "end_line": 327,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.017241379310344827,
            "pseudo_dstar_susp": 0.018867924528301886,
            "pseudo_tarantula_susp": 0.017241379310344827,
            "pseudo_op2_susp": 0.018867924528301886,
            "pseudo_barinel_susp": 0.017241379310344827
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.report_video_info_webpage_download#329",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.report_video_info_webpage_download(self, video_id)",
        "snippet": "    def report_video_info_webpage_download(self, video_id):\n        \"\"\"Report attempt to download video info webpage.\"\"\"\n        self.to_screen(u'%s: Downloading video info webpage' % video_id)",
        "begin_line": 329,
        "end_line": 331,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.report_information_extraction#333",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.report_information_extraction(self, video_id)",
        "snippet": "    def report_information_extraction(self, video_id):\n        \"\"\"Report attempt to extract video information.\"\"\"\n        self.to_screen(u'%s: Extracting video information' % video_id)",
        "begin_line": 333,
        "end_line": 335,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.report_unavailable_format#337",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.report_unavailable_format(self, video_id, format)",
        "snippet": "    def report_unavailable_format(self, video_id, format):\n        \"\"\"Report extracted video URL.\"\"\"\n        self.to_screen(u'%s: Format %s not available' % (video_id, format))",
        "begin_line": 337,
        "end_line": 339,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.report_rtmp_download#341",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.report_rtmp_download(self)",
        "snippet": "    def report_rtmp_download(self):\n        \"\"\"Indicate the download will use the RTMP protocol.\"\"\"\n        self.to_screen(u'RTMP download detected')",
        "begin_line": 341,
        "end_line": 343,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._extract_signature_function#345",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._extract_signature_function(self, video_id, player_url, slen)",
        "snippet": "    def _extract_signature_function(self, video_id, player_url, slen):\n        id_m = re.match(r'.*-(?P<id>[a-zA-Z0-9_-]+)\\.(?P<ext>[a-z]+)$',\n                        player_url)\n        player_type = id_m.group('ext')\n        player_id = id_m.group('id')\n\n        # Read from filesystem cache\n        func_id = '%s_%s_%d' % (player_type, player_id, slen)\n        assert os.path.basename(func_id) == func_id\n        cache_dir = get_cachedir(self._downloader.params)\n\n        cache_enabled = cache_dir is not None\n        if cache_enabled:\n            cache_fn = os.path.join(os.path.expanduser(cache_dir),\n                                    u'youtube-sigfuncs',\n                                    func_id + '.json')\n            try:\n                with io.open(cache_fn, 'r', encoding='utf-8') as cachef:\n                    cache_spec = json.load(cachef)\n                return lambda s: u''.join(s[i] for i in cache_spec)\n            except IOError:\n                pass  # No cache available\n\n        if player_type == 'js':\n            code = self._download_webpage(\n                player_url, video_id,\n                note=u'Downloading %s player %s' % (player_type, player_id),\n                errnote=u'Download of %s failed' % player_url)\n            res = self._parse_sig_js(code)\n        elif player_type == 'swf':\n            urlh = self._request_webpage(\n                player_url, video_id,\n                note=u'Downloading %s player %s' % (player_type, player_id),\n                errnote=u'Download of %s failed' % player_url)\n            code = urlh.read()\n            res = self._parse_sig_swf(code)\n        else:\n            assert False, 'Invalid player type %r' % player_type\n\n        if cache_enabled:\n            try:\n                test_string = u''.join(map(compat_chr, range(slen)))\n                cache_res = res(test_string)\n                cache_spec = [ord(c) for c in cache_res]\n                try:\n                    os.makedirs(os.path.dirname(cache_fn))\n                except OSError as ose:\n                    if ose.errno != errno.EEXIST:\n                        raise\n                write_json_file(cache_spec, cache_fn)\n            except Exception:\n                tb = traceback.format_exc()\n                self._downloader.report_warning(\n                    u'Writing cache to %r failed: %s' % (cache_fn, tb))\n\n        return res",
        "begin_line": 345,
        "end_line": 400,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._print_sig_code#402",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._print_sig_code(self, func, slen)",
        "snippet": "    def _print_sig_code(self, func, slen):\n        def gen_sig_code(idxs):\n            def _genslice(start, end, step):\n                starts = u'' if start == 0 else str(start)\n                ends = (u':%d' % (end+step)) if end + step >= 0 else u':'\n                steps = u'' if step == 1 else (u':%d' % step)\n                return u's[%s%s%s]' % (starts, ends, steps)\n\n            step = None\n            start = '(Never used)'  # Quelch pyflakes warnings - start will be\n                                    # set as soon as step is set\n            for i, prev in zip(idxs[1:], idxs[:-1]):\n                if step is not None:\n                    if i - prev == step:\n                        continue\n                    yield _genslice(start, prev, step)\n                    step = None\n                    continue\n                if i - prev in [-1, 1]:\n                    step = i - prev\n                    start = prev\n                    continue\n                else:\n                    yield u's[%d]' % prev\n            if step is None:\n                yield u's[%d]' % i\n            else:\n                yield _genslice(start, i, step)\n\n        test_string = u''.join(map(compat_chr, range(slen)))\n        cache_res = func(test_string)\n        cache_spec = [ord(c) for c in cache_res]\n        expr_code = u' + '.join(gen_sig_code(cache_spec))\n        code = u'if len(s) == %d:\\n    return %s\\n' % (slen, expr_code)\n        self.to_screen(u'Extracted signature function:\\n' + code)",
        "begin_line": 402,
        "end_line": 436,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._parse_sig_js#438",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._parse_sig_js(self, jscode)",
        "snippet": "    def _parse_sig_js(self, jscode):\n        funcname = self._search_regex(\n            r'signature=([a-zA-Z]+)', jscode,\n            u'Initial JS player signature function name')\n\n        functions = {}\n\n        def argidx(varname):\n            return string.lowercase.index(varname)\n\n        def interpret_statement(stmt, local_vars, allow_recursion=20):\n            if allow_recursion < 0:\n                raise ExtractorError(u'Recursion limit reached')\n\n            if stmt.startswith(u'var '):\n                stmt = stmt[len(u'var '):]\n            ass_m = re.match(r'^(?P<out>[a-z]+)(?:\\[(?P<index>[^\\]]+)\\])?' +\n                             r'=(?P<expr>.*)$', stmt)\n            if ass_m:\n                if ass_m.groupdict().get('index'):\n                    def assign(val):\n                        lvar = local_vars[ass_m.group('out')]\n                        idx = interpret_expression(ass_m.group('index'),\n                                                   local_vars, allow_recursion)\n                        assert isinstance(idx, int)\n                        lvar[idx] = val\n                        return val\n                    expr = ass_m.group('expr')\n                else:\n                    def assign(val):\n                        local_vars[ass_m.group('out')] = val\n                        return val\n                    expr = ass_m.group('expr')\n            elif stmt.startswith(u'return '):\n                assign = lambda v: v\n                expr = stmt[len(u'return '):]\n            else:\n                raise ExtractorError(\n                    u'Cannot determine left side of statement in %r' % stmt)\n\n            v = interpret_expression(expr, local_vars, allow_recursion)\n            return assign(v)\n\n        def interpret_expression(expr, local_vars, allow_recursion):\n            if expr.isdigit():\n                return int(expr)\n\n            if expr.isalpha():\n                return local_vars[expr]\n\n            m = re.match(r'^(?P<in>[a-z]+)\\.(?P<member>.*)$', expr)\n            if m:\n                member = m.group('member')\n                val = local_vars[m.group('in')]\n                if member == 'split(\"\")':\n                    return list(val)\n                if member == 'join(\"\")':\n                    return u''.join(val)\n                if member == 'length':\n                    return len(val)\n                if member == 'reverse()':\n                    return val[::-1]\n                slice_m = re.match(r'slice\\((?P<idx>.*)\\)', member)\n                if slice_m:\n                    idx = interpret_expression(\n                        slice_m.group('idx'), local_vars, allow_recursion-1)\n                    return val[idx:]\n\n            m = re.match(\n                r'^(?P<in>[a-z]+)\\[(?P<idx>.+)\\]$', expr)\n            if m:\n                val = local_vars[m.group('in')]\n                idx = interpret_expression(m.group('idx'), local_vars,\n                                           allow_recursion-1)\n                return val[idx]\n\n            m = re.match(r'^(?P<a>.+?)(?P<op>[%])(?P<b>.+?)$', expr)\n            if m:\n                a = interpret_expression(m.group('a'),\n                                         local_vars, allow_recursion)\n                b = interpret_expression(m.group('b'),\n                                         local_vars, allow_recursion)\n                return a % b\n\n            m = re.match(\n                r'^(?P<func>[a-zA-Z$]+)\\((?P<args>[a-z0-9,]+)\\)$', expr)\n            if m:\n                fname = m.group('func')\n                if fname not in functions:\n                    functions[fname] = extract_function(fname)\n                argvals = [int(v) if v.isdigit() else local_vars[v]\n                           for v in m.group('args').split(',')]\n                return functions[fname](argvals)\n            raise ExtractorError(u'Unsupported JS expression %r' % expr)\n\n        def extract_function(funcname):\n            func_m = re.search(\n                r'function ' + re.escape(funcname) +\n                r'\\((?P<args>[a-z,]+)\\){(?P<code>[^}]+)}',\n                jscode)\n            argnames = func_m.group('args').split(',')\n\n            def resf(args):\n                local_vars = dict(zip(argnames, args))\n                for stmt in func_m.group('code').split(';'):\n                    res = interpret_statement(stmt, local_vars)\n                return res\n            return resf\n\n        initial_function = extract_function(funcname)\n        return lambda s: initial_function([s])",
        "begin_line": 438,
        "end_line": 548,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.argidx#445",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.argidx(varname)",
        "snippet": "        def argidx(varname):\n            return string.lowercase.index(varname)",
        "begin_line": 445,
        "end_line": 446,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.interpret_statement#448",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.interpret_statement(stmt, local_vars, allow_recursion=20)",
        "snippet": "        def interpret_statement(stmt, local_vars, allow_recursion=20):\n            if allow_recursion < 0:\n                raise ExtractorError(u'Recursion limit reached')\n\n            if stmt.startswith(u'var '):\n                stmt = stmt[len(u'var '):]\n            ass_m = re.match(r'^(?P<out>[a-z]+)(?:\\[(?P<index>[^\\]]+)\\])?' +\n                             r'=(?P<expr>.*)$', stmt)\n            if ass_m:\n                if ass_m.groupdict().get('index'):\n                    def assign(val):\n                        lvar = local_vars[ass_m.group('out')]\n                        idx = interpret_expression(ass_m.group('index'),\n                                                   local_vars, allow_recursion)\n                        assert isinstance(idx, int)\n                        lvar[idx] = val\n                        return val\n                    expr = ass_m.group('expr')\n                else:\n                    def assign(val):\n                        local_vars[ass_m.group('out')] = val\n                        return val\n                    expr = ass_m.group('expr')\n            elif stmt.startswith(u'return '):\n                assign = lambda v: v\n                expr = stmt[len(u'return '):]\n            else:\n                raise ExtractorError(\n                    u'Cannot determine left side of statement in %r' % stmt)\n\n            v = interpret_expression(expr, local_vars, allow_recursion)\n            return assign(v)",
        "begin_line": 448,
        "end_line": 479,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.assign#458",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.assign(val)",
        "snippet": "                    def assign(val):\n                        lvar = local_vars[ass_m.group('out')]\n                        idx = interpret_expression(ass_m.group('index'),\n                                                   local_vars, allow_recursion)\n                        assert isinstance(idx, int)\n                        lvar[idx] = val\n                        return val",
        "begin_line": 458,
        "end_line": 464,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.assign#467",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.assign(val)",
        "snippet": "                    def assign(val):\n                        local_vars[ass_m.group('out')] = val\n                        return val",
        "begin_line": 467,
        "end_line": 469,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.interpret_expression#481",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.interpret_expression(expr, local_vars, allow_recursion)",
        "snippet": "        def interpret_expression(expr, local_vars, allow_recursion):\n            if expr.isdigit():\n                return int(expr)\n\n            if expr.isalpha():\n                return local_vars[expr]\n\n            m = re.match(r'^(?P<in>[a-z]+)\\.(?P<member>.*)$', expr)\n            if m:\n                member = m.group('member')\n                val = local_vars[m.group('in')]\n                if member == 'split(\"\")':\n                    return list(val)\n                if member == 'join(\"\")':\n                    return u''.join(val)\n                if member == 'length':\n                    return len(val)\n                if member == 'reverse()':\n                    return val[::-1]\n                slice_m = re.match(r'slice\\((?P<idx>.*)\\)', member)\n                if slice_m:\n                    idx = interpret_expression(\n                        slice_m.group('idx'), local_vars, allow_recursion-1)\n                    return val[idx:]\n\n            m = re.match(\n                r'^(?P<in>[a-z]+)\\[(?P<idx>.+)\\]$', expr)\n            if m:\n                val = local_vars[m.group('in')]\n                idx = interpret_expression(m.group('idx'), local_vars,\n                                           allow_recursion-1)\n                return val[idx]\n\n            m = re.match(r'^(?P<a>.+?)(?P<op>[%])(?P<b>.+?)$', expr)\n            if m:\n                a = interpret_expression(m.group('a'),\n                                         local_vars, allow_recursion)\n                b = interpret_expression(m.group('b'),\n                                         local_vars, allow_recursion)\n                return a % b\n\n            m = re.match(\n                r'^(?P<func>[a-zA-Z$]+)\\((?P<args>[a-z0-9,]+)\\)$', expr)\n            if m:\n                fname = m.group('func')\n                if fname not in functions:\n                    functions[fname] = extract_function(fname)\n                argvals = [int(v) if v.isdigit() else local_vars[v]\n                           for v in m.group('args').split(',')]\n                return functions[fname](argvals)\n            raise ExtractorError(u'Unsupported JS expression %r' % expr)",
        "begin_line": 481,
        "end_line": 531,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.extract_function#533",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.extract_function(funcname)",
        "snippet": "        def extract_function(funcname):\n            func_m = re.search(\n                r'function ' + re.escape(funcname) +\n                r'\\((?P<args>[a-z,]+)\\){(?P<code>[^}]+)}',\n                jscode)\n            argnames = func_m.group('args').split(',')\n\n            def resf(args):\n                local_vars = dict(zip(argnames, args))\n                for stmt in func_m.group('code').split(';'):\n                    res = interpret_statement(stmt, local_vars)\n                return res\n            return resf",
        "begin_line": 533,
        "end_line": 545,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.resf#540",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.resf(args)",
        "snippet": "            def resf(args):\n                local_vars = dict(zip(argnames, args))\n                for stmt in func_m.group('code').split(';'):\n                    res = interpret_statement(stmt, local_vars)\n                return res",
        "begin_line": 540,
        "end_line": 544,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._parse_sig_swf#550",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._parse_sig_swf(self, file_contents)",
        "snippet": "    def _parse_sig_swf(self, file_contents):\n        if file_contents[1:3] != b'WS':\n            raise ExtractorError(\n                u'Not an SWF file; header is %r' % file_contents[:3])\n        if file_contents[:1] == b'C':\n            content = zlib.decompress(file_contents[8:])\n        else:\n            raise NotImplementedError(u'Unsupported compression format %r' %\n                                      file_contents[:1])\n\n        def extract_tags(content):\n            pos = 0\n            while pos < len(content):\n                header16 = struct.unpack('<H', content[pos:pos+2])[0]\n                pos += 2\n                tag_code = header16 >> 6\n                tag_len = header16 & 0x3f\n                if tag_len == 0x3f:\n                    tag_len = struct.unpack('<I', content[pos:pos+4])[0]\n                    pos += 4\n                assert pos+tag_len <= len(content)\n                yield (tag_code, content[pos:pos+tag_len])\n                pos += tag_len\n\n        code_tag = next(tag\n                        for tag_code, tag in extract_tags(content)\n                        if tag_code == 82)\n        p = code_tag.index(b'\\0', 4) + 1\n        code_reader = io.BytesIO(code_tag[p:])\n\n        # Parse ABC (AVM2 ByteCode)\n        def read_int(reader=None):\n            if reader is None:\n                reader = code_reader\n            res = 0\n            shift = 0\n            for _ in range(5):\n                buf = reader.read(1)\n                assert len(buf) == 1\n                b = struct.unpack('<B', buf)[0]\n                res = res | ((b & 0x7f) << shift)\n                if b & 0x80 == 0:\n                    break\n                shift += 7\n            return res\n\n        def u30(reader=None):\n            res = read_int(reader)\n            assert res & 0xf0000000 == 0\n            return res\n        u32 = read_int\n\n        def s32(reader=None):\n            v = read_int(reader)\n            if v & 0x80000000 != 0:\n                v = - ((v ^ 0xffffffff) + 1)\n            return v\n\n        def read_string(reader=None):\n            if reader is None:\n                reader = code_reader\n            slen = u30(reader)\n            resb = reader.read(slen)\n            assert len(resb) == slen\n            return resb.decode('utf-8')\n\n        def read_bytes(count, reader=None):\n            if reader is None:\n                reader = code_reader\n            resb = reader.read(count)\n            assert len(resb) == count\n            return resb\n\n        def read_byte(reader=None):\n            resb = read_bytes(1, reader=reader)\n            res = struct.unpack('<B', resb)[0]\n            return res\n\n        # minor_version + major_version\n        read_bytes(2 + 2)\n\n        # Constant pool\n        int_count = u30()\n        for _c in range(1, int_count):\n            s32()\n        uint_count = u30()\n        for _c in range(1, uint_count):\n            u32()\n        double_count = u30()\n        read_bytes((double_count-1) * 8)\n        string_count = u30()\n        constant_strings = [u'']\n        for _c in range(1, string_count):\n            s = read_string()\n            constant_strings.append(s)\n        namespace_count = u30()\n        for _c in range(1, namespace_count):\n            read_bytes(1)  # kind\n            u30()  # name\n        ns_set_count = u30()\n        for _c in range(1, ns_set_count):\n            count = u30()\n            for _c2 in range(count):\n                u30()\n        multiname_count = u30()\n        MULTINAME_SIZES = {\n            0x07: 2,  # QName\n            0x0d: 2,  # QNameA\n            0x0f: 1,  # RTQName\n            0x10: 1,  # RTQNameA\n            0x11: 0,  # RTQNameL\n            0x12: 0,  # RTQNameLA\n            0x09: 2,  # Multiname\n            0x0e: 2,  # MultinameA\n            0x1b: 1,  # MultinameL\n            0x1c: 1,  # MultinameLA\n        }\n        multinames = [u'']\n        for _c in range(1, multiname_count):\n            kind = u30()\n            assert kind in MULTINAME_SIZES, u'Invalid multiname kind %r' % kind\n            if kind == 0x07:\n                u30()  # namespace_idx\n                name_idx = u30()\n                multinames.append(constant_strings[name_idx])\n            else:\n                multinames.append('[MULTINAME kind: %d]' % kind)\n                for _c2 in range(MULTINAME_SIZES[kind]):\n                    u30()\n\n        # Methods\n        method_count = u30()\n        MethodInfo = collections.namedtuple(\n            'MethodInfo',\n            ['NEED_ARGUMENTS', 'NEED_REST'])\n        method_infos = []\n        for method_id in range(method_count):\n            param_count = u30()\n            u30()  # return type\n            for _ in range(param_count):\n                u30()  # param type\n            u30()  # name index (always 0 for youtube)\n            flags = read_byte()\n            if flags & 0x08 != 0:\n                # Options present\n                option_count = u30()\n                for c in range(option_count):\n                    u30()  # val\n                    read_bytes(1)  # kind\n            if flags & 0x80 != 0:\n                # Param names present\n                for _ in range(param_count):\n                    u30()  # param name\n            mi = MethodInfo(flags & 0x01 != 0, flags & 0x04 != 0)\n            method_infos.append(mi)\n\n        # Metadata\n        metadata_count = u30()\n        for _c in range(metadata_count):\n            u30()  # name\n            item_count = u30()\n            for _c2 in range(item_count):\n                u30()  # key\n                u30()  # value\n\n        def parse_traits_info():\n            trait_name_idx = u30()\n            kind_full = read_byte()\n            kind = kind_full & 0x0f\n            attrs = kind_full >> 4\n            methods = {}\n            if kind in [0x00, 0x06]:  # Slot or Const\n                u30()  # Slot id\n                u30()  # type_name_idx\n                vindex = u30()\n                if vindex != 0:\n                    read_byte()  # vkind\n            elif kind in [0x01, 0x02, 0x03]:  # Method / Getter / Setter\n                u30()  # disp_id\n                method_idx = u30()\n                methods[multinames[trait_name_idx]] = method_idx\n            elif kind == 0x04:  # Class\n                u30()  # slot_id\n                u30()  # classi\n            elif kind == 0x05:  # Function\n                u30()  # slot_id\n                function_idx = u30()\n                methods[function_idx] = multinames[trait_name_idx]\n            else:\n                raise ExtractorError(u'Unsupported trait kind %d' % kind)\n\n            if attrs & 0x4 != 0:  # Metadata present\n                metadata_count = u30()\n                for _c3 in range(metadata_count):\n                    u30()  # metadata index\n\n            return methods\n\n        # Classes\n        TARGET_CLASSNAME = u'SignatureDecipher'\n        searched_idx = multinames.index(TARGET_CLASSNAME)\n        searched_class_id = None\n        class_count = u30()\n        for class_id in range(class_count):\n            name_idx = u30()\n            if name_idx == searched_idx:\n                # We found the class we're looking for!\n                searched_class_id = class_id\n            u30()  # super_name idx\n            flags = read_byte()\n            if flags & 0x08 != 0:  # Protected namespace is present\n                u30()  # protected_ns_idx\n            intrf_count = u30()\n            for _c2 in range(intrf_count):\n                u30()\n            u30()  # iinit\n            trait_count = u30()\n            for _c2 in range(trait_count):\n                parse_traits_info()\n\n        if searched_class_id is None:\n            raise ExtractorError(u'Target class %r not found' %\n                                 TARGET_CLASSNAME)\n\n        method_names = {}\n        method_idxs = {}\n        for class_id in range(class_count):\n            u30()  # cinit\n            trait_count = u30()\n            for _c2 in range(trait_count):\n                trait_methods = parse_traits_info()\n                if class_id == searched_class_id:\n                    method_names.update(trait_methods.items())\n                    method_idxs.update(dict(\n                        (idx, name)\n                        for name, idx in trait_methods.items()))\n\n        # Scripts\n        script_count = u30()\n        for _c in range(script_count):\n            u30()  # init\n            trait_count = u30()\n            for _c2 in range(trait_count):\n                parse_traits_info()\n\n        # Method bodies\n        method_body_count = u30()\n        Method = collections.namedtuple('Method', ['code', 'local_count'])\n        methods = {}\n        for _c in range(method_body_count):\n            method_idx = u30()\n            u30()  # max_stack\n            local_count = u30()\n            u30()  # init_scope_depth\n            u30()  # max_scope_depth\n            code_length = u30()\n            code = read_bytes(code_length)\n            if method_idx in method_idxs:\n                m = Method(code, local_count)\n                methods[method_idxs[method_idx]] = m\n            exception_count = u30()\n            for _c2 in range(exception_count):\n                u30()  # from\n                u30()  # to\n                u30()  # target\n                u30()  # exc_type\n                u30()  # var_name\n            trait_count = u30()\n            for _c2 in range(trait_count):\n                parse_traits_info()\n\n        assert p + code_reader.tell() == len(code_tag)\n        assert len(methods) == len(method_idxs)\n\n        method_pyfunctions = {}\n\n        def extract_function(func_name):\n            if func_name in method_pyfunctions:\n                return method_pyfunctions[func_name]\n            if func_name not in methods:\n                raise ExtractorError(u'Cannot find function %r' % func_name)\n            m = methods[func_name]\n\n            def resfunc(args):\n                registers = ['(this)'] + list(args) + [None] * m.local_count\n                stack = []\n                coder = io.BytesIO(m.code)\n                while True:\n                    opcode = struct.unpack('!B', coder.read(1))[0]\n                    if opcode == 36:  # pushbyte\n                        v = struct.unpack('!B', coder.read(1))[0]\n                        stack.append(v)\n                    elif opcode == 44:  # pushstring\n                        idx = u30(coder)\n                        stack.append(constant_strings[idx])\n                    elif opcode == 48:  # pushscope\n                        # We don't implement the scope register, so we'll just\n                        # ignore the popped value\n                        stack.pop()\n                    elif opcode == 70:  # callproperty\n                        index = u30(coder)\n                        mname = multinames[index]\n                        arg_count = u30(coder)\n                        args = list(reversed(\n                            [stack.pop() for _ in range(arg_count)]))\n                        obj = stack.pop()\n                        if mname == u'split':\n                            assert len(args) == 1\n                            assert isinstance(args[0], compat_str)\n                            assert isinstance(obj, compat_str)\n                            if args[0] == u'':\n                                res = list(obj)\n                            else:\n                                res = obj.split(args[0])\n                            stack.append(res)\n                        elif mname == u'slice':\n                            assert len(args) == 1\n                            assert isinstance(args[0], int)\n                            assert isinstance(obj, list)\n                            res = obj[args[0]:]\n                            stack.append(res)\n                        elif mname == u'join':\n                            assert len(args) == 1\n                            assert isinstance(args[0], compat_str)\n                            assert isinstance(obj, list)\n                            res = args[0].join(obj)\n                            stack.append(res)\n                        elif mname in method_pyfunctions:\n                            stack.append(method_pyfunctions[mname](args))\n                        else:\n                            raise NotImplementedError(\n                                u'Unsupported property %r on %r'\n                                % (mname, obj))\n                    elif opcode == 72:  # returnvalue\n                        res = stack.pop()\n                        return res\n                    elif opcode == 79:  # callpropvoid\n                        index = u30(coder)\n                        mname = multinames[index]\n                        arg_count = u30(coder)\n                        args = list(reversed(\n                            [stack.pop() for _ in range(arg_count)]))\n                        obj = stack.pop()\n                        if mname == u'reverse':\n                            assert isinstance(obj, list)\n                            obj.reverse()\n                        else:\n                            raise NotImplementedError(\n                                u'Unsupported (void) property %r on %r'\n                                % (mname, obj))\n                    elif opcode == 93:  # findpropstrict\n                        index = u30(coder)\n                        mname = multinames[index]\n                        res = extract_function(mname)\n                        stack.append(res)\n                    elif opcode == 97:  # setproperty\n                        index = u30(coder)\n                        value = stack.pop()\n                        idx = stack.pop()\n                        obj = stack.pop()\n                        assert isinstance(obj, list)\n                        assert isinstance(idx, int)\n                        obj[idx] = value\n                    elif opcode == 98:  # getlocal\n                        index = u30(coder)\n                        stack.append(registers[index])\n                    elif opcode == 99:  # setlocal\n                        index = u30(coder)\n                        value = stack.pop()\n                        registers[index] = value\n                    elif opcode == 102:  # getproperty\n                        index = u30(coder)\n                        pname = multinames[index]\n                        if pname == u'length':\n                            obj = stack.pop()\n                            assert isinstance(obj, list)\n                            stack.append(len(obj))\n                        else:  # Assume attribute access\n                            idx = stack.pop()\n                            assert isinstance(idx, int)\n                            obj = stack.pop()\n                            assert isinstance(obj, list)\n                            stack.append(obj[idx])\n                    elif opcode == 128:  # coerce\n                        u30(coder)\n                    elif opcode == 133:  # coerce_s\n                        assert isinstance(stack[-1], (type(None), compat_str))\n                    elif opcode == 164:  # modulo\n                        value2 = stack.pop()\n                        value1 = stack.pop()\n                        res = value1 % value2\n                        stack.append(res)\n                    elif opcode == 208:  # getlocal_0\n                        stack.append(registers[0])\n                    elif opcode == 209:  # getlocal_1\n                        stack.append(registers[1])\n                    elif opcode == 210:  # getlocal_2\n                        stack.append(registers[2])\n                    elif opcode == 211:  # getlocal_3\n                        stack.append(registers[3])\n                    elif opcode == 214:  # setlocal_2\n                        registers[2] = stack.pop()\n                    elif opcode == 215:  # setlocal_3\n                        registers[3] = stack.pop()\n                    else:\n                        raise NotImplementedError(\n                            u'Unsupported opcode %d' % opcode)\n\n            method_pyfunctions[func_name] = resfunc\n            return resfunc\n\n        initial_function = extract_function(u'decipher')\n        return lambda s: initial_function([s])",
        "begin_line": 550,
        "end_line": 962,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._decrypt_signature#964",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._decrypt_signature(self, s, video_id, player_url, age_gate=False)",
        "snippet": "    def _decrypt_signature(self, s, video_id, player_url, age_gate=False):\n        \"\"\"Turn the encrypted s field into a working signature\"\"\"\n\n        if player_url is not None:\n            if player_url.startswith(u'//'):\n                player_url = u'https:' + player_url\n            try:\n                player_id = (player_url, len(s))\n                if player_id not in self._player_cache:\n                    func = self._extract_signature_function(\n                        video_id, player_url, len(s)\n                    )\n                    self._player_cache[player_id] = func\n                func = self._player_cache[player_id]\n                if self._downloader.params.get('youtube_print_sig_code'):\n                    self._print_sig_code(func, len(s))\n                return func(s)\n            except Exception:\n                tb = traceback.format_exc()\n                self._downloader.report_warning(\n                    u'Automatic signature extraction failed: ' + tb)\n\n            self._downloader.report_warning(\n                u'Warning: Falling back to static signature algorithm')\n\n        return self._static_decrypt_signature(\n            s, video_id, player_url, age_gate)",
        "begin_line": 964,
        "end_line": 990,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._static_decrypt_signature#992",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._static_decrypt_signature(self, s, video_id, player_url, age_gate)",
        "snippet": "    def _static_decrypt_signature(self, s, video_id, player_url, age_gate):\n        if age_gate:\n            # The videos with age protection use another player, so the\n            # algorithms can be different.\n            if len(s) == 86:\n                return s[2:63] + s[82] + s[64:82] + s[63]\n\n        if len(s) == 93:\n            return s[86:29:-1] + s[88] + s[28:5:-1]\n        elif len(s) == 92:\n            return s[25] + s[3:25] + s[0] + s[26:42] + s[79] + s[43:79] + s[91] + s[80:83]\n        elif len(s) == 91:\n            return s[84:27:-1] + s[86] + s[26:5:-1]\n        elif len(s) == 90:\n            return s[25] + s[3:25] + s[2] + s[26:40] + s[77] + s[41:77] + s[89] + s[78:81]\n        elif len(s) == 89:\n            return s[84:78:-1] + s[87] + s[77:60:-1] + s[0] + s[59:3:-1]\n        elif len(s) == 88:\n            return s[7:28] + s[87] + s[29:45] + s[55] + s[46:55] + s[2] + s[56:87] + s[28]\n        elif len(s) == 87:\n            return s[6:27] + s[4] + s[28:39] + s[27] + s[40:59] + s[2] + s[60:]\n        elif len(s) == 86:\n            return s[80:72:-1] + s[16] + s[71:39:-1] + s[72] + s[38:16:-1] + s[82] + s[15::-1]\n        elif len(s) == 85:\n            return s[3:11] + s[0] + s[12:55] + s[84] + s[56:84]\n        elif len(s) == 84:\n            return s[78:70:-1] + s[14] + s[69:37:-1] + s[70] + s[36:14:-1] + s[80] + s[:14][::-1]\n        elif len(s) == 83:\n            return s[80:63:-1] + s[0] + s[62:0:-1] + s[63]\n        elif len(s) == 82:\n            return s[80:37:-1] + s[7] + s[36:7:-1] + s[0] + s[6:0:-1] + s[37]\n        elif len(s) == 81:\n            return s[56] + s[79:56:-1] + s[41] + s[55:41:-1] + s[80] + s[40:34:-1] + s[0] + s[33:29:-1] + s[34] + s[28:9:-1] + s[29] + s[8:0:-1] + s[9]\n        elif len(s) == 80:\n            return s[1:19] + s[0] + s[20:68] + s[19] + s[69:80]\n        elif len(s) == 79:\n            return s[54] + s[77:54:-1] + s[39] + s[53:39:-1] + s[78] + s[38:34:-1] + s[0] + s[33:29:-1] + s[34] + s[28:9:-1] + s[29] + s[8:0:-1] + s[9]\n\n        else:\n            raise ExtractorError(u'Unable to decrypt signature, key length %d not supported; retrying might work' % (len(s)))",
        "begin_line": 992,
        "end_line": 1031,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._get_available_subtitles#1033",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._get_available_subtitles(self, video_id, webpage)",
        "snippet": "    def _get_available_subtitles(self, video_id, webpage):\n        try:\n            sub_list = self._download_webpage(\n                'https://video.google.com/timedtext?hl=en&type=list&v=%s' % video_id,\n                video_id, note=False)\n        except ExtractorError as err:\n            self._downloader.report_warning(u'unable to download video subtitles: %s' % compat_str(err))\n            return {}\n        lang_list = re.findall(r'name=\"([^\"]*)\"[^>]+lang_code=\"([\\w\\-]+)\"', sub_list)\n\n        sub_lang_list = {}\n        for l in lang_list:\n            lang = l[1]\n            params = compat_urllib_parse.urlencode({\n                'lang': lang,\n                'v': video_id,\n                'fmt': self._downloader.params.get('subtitlesformat', 'srt'),\n                'name': unescapeHTML(l[0]).encode('utf-8'),\n            })\n            url = u'https://www.youtube.com/api/timedtext?' + params\n            sub_lang_list[lang] = url\n        if not sub_lang_list:\n            self._downloader.report_warning(u'video doesn\\'t have subtitles')\n            return {}\n        return sub_lang_list",
        "begin_line": 1033,
        "end_line": 1057,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._get_available_automatic_caption#1059",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._get_available_automatic_caption(self, video_id, webpage)",
        "snippet": "    def _get_available_automatic_caption(self, video_id, webpage):\n        \"\"\"We need the webpage for getting the captions url, pass it as an\n           argument to speed up the process.\"\"\"\n        sub_format = self._downloader.params.get('subtitlesformat', 'srt')\n        self.to_screen(u'%s: Looking for automatic captions' % video_id)\n        mobj = re.search(r';ytplayer.config = ({.*?});', webpage)\n        err_msg = u'Couldn\\'t find automatic captions for %s' % video_id\n        if mobj is None:\n            self._downloader.report_warning(err_msg)\n            return {}\n        player_config = json.loads(mobj.group(1))\n        try:\n            args = player_config[u'args']\n            caption_url = args[u'ttsurl']\n            timestamp = args[u'timestamp']\n            # We get the available subtitles\n            list_params = compat_urllib_parse.urlencode({\n                'type': 'list',\n                'tlangs': 1,\n                'asrs': 1,\n            })\n            list_url = caption_url + '&' + list_params\n            caption_list = self._download_xml(list_url, video_id)\n            original_lang_node = caption_list.find('track')\n            if original_lang_node is None or original_lang_node.attrib.get('kind') != 'asr' :\n                self._downloader.report_warning(u'Video doesn\\'t have automatic captions')\n                return {}\n            original_lang = original_lang_node.attrib['lang_code']\n\n            sub_lang_list = {}\n            for lang_node in caption_list.findall('target'):\n                sub_lang = lang_node.attrib['lang_code']\n                params = compat_urllib_parse.urlencode({\n                    'lang': original_lang,\n                    'tlang': sub_lang,\n                    'fmt': sub_format,\n                    'ts': timestamp,\n                    'kind': 'asr',\n                })\n                sub_lang_list[sub_lang] = caption_url + '&' + params\n            return sub_lang_list\n        # An extractor error can be raise by the download process if there are\n        # no automatic captions but there are subtitles\n        except (KeyError, ExtractorError):\n            self._downloader.report_warning(err_msg)\n            return {}",
        "begin_line": 1059,
        "end_line": 1104,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE.extract_id#1107",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE.extract_id(cls, url)",
        "snippet": "    def extract_id(cls, url):\n        mobj = re.match(cls._VALID_URL, url, re.VERBOSE)\n        if mobj is None:\n            raise ExtractorError(u'Invalid URL: %s' % url)\n        video_id = mobj.group(2)\n        return video_id",
        "begin_line": 1107,
        "end_line": 1112,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.006711409395973154,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._extract_from_m3u8#1114",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._extract_from_m3u8(self, manifest_url, video_id)",
        "snippet": "    def _extract_from_m3u8(self, manifest_url, video_id):\n        url_map = {}\n        def _get_urls(_manifest):\n            lines = _manifest.split('\\n')\n            urls = filter(lambda l: l and not l.startswith('#'),\n                            lines)\n            return urls\n        manifest = self._download_webpage(manifest_url, video_id, u'Downloading formats manifest')\n        formats_urls = _get_urls(manifest)\n        for format_url in formats_urls:\n            itag = self._search_regex(r'itag/(\\d+?)/', format_url, 'itag')\n            url_map[itag] = format_url\n        return url_map",
        "begin_line": 1114,
        "end_line": 1126,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._extract_annotations#1128",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._extract_annotations(self, video_id)",
        "snippet": "    def _extract_annotations(self, video_id):\n        url = 'https://www.youtube.com/annotations_invideo?features=1&legacy=1&video_id=%s' % video_id\n        return self._download_webpage(url, video_id, note=u'Searching for annotations.', errnote=u'Unable to download video annotations.')",
        "begin_line": 1128,
        "end_line": 1130,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeIE._real_extract#1132",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        # Extract original video URL from URL with redirection, like age verification, using next_url parameter\n        mobj = re.search(self._NEXT_URL_RE, url)\n        if mobj:\n            url = 'https://www.youtube.com/' + compat_urllib_parse.unquote(mobj.group(1)).lstrip('/')\n        video_id = self.extract_id(url)\n\n        # Get video webpage\n        url = 'https://www.youtube.com/watch?v=%s&gl=US&hl=en&has_verified=1' % video_id\n        video_webpage = self._download_webpage(url, video_id)\n\n        # Attempt to extract SWF player URL\n        mobj = re.search(r'swfConfig.*?\"(https?:\\\\/\\\\/.*?watch.*?-.*?\\.swf)\"', video_webpage)\n        if mobj is not None:\n            player_url = re.sub(r'\\\\(.)', r'\\1', mobj.group(1))\n        else:\n            player_url = None\n\n        # Get video info\n        self.report_video_info_webpage_download(video_id)\n        if re.search(r'player-age-gate-content\">', video_webpage) is not None:\n            self.report_age_confirmation()\n            age_gate = True\n            # We simulate the access to the video from www.youtube.com/v/{video_id}\n            # this can be viewed without login into Youtube\n            data = compat_urllib_parse.urlencode({'video_id': video_id,\n                                                  'el': 'player_embedded',\n                                                  'gl': 'US',\n                                                  'hl': 'en',\n                                                  'eurl': 'https://youtube.googleapis.com/v/' + video_id,\n                                                  'asv': 3,\n                                                  'sts':'1588',\n                                                  })\n            video_info_url = 'https://www.youtube.com/get_video_info?' + data\n            video_info_webpage = self._download_webpage(video_info_url, video_id,\n                                    note=False,\n                                    errnote='unable to download video info webpage')\n            video_info = compat_parse_qs(video_info_webpage)\n        else:\n            age_gate = False\n            for el_type in ['&el=embedded', '&el=detailpage', '&el=vevo', '']:\n                video_info_url = ('https://www.youtube.com/get_video_info?&video_id=%s%s&ps=default&eurl=&gl=US&hl=en'\n                        % (video_id, el_type))\n                video_info_webpage = self._download_webpage(video_info_url, video_id,\n                                        note=False,\n                                        errnote='unable to download video info webpage')\n                video_info = compat_parse_qs(video_info_webpage)\n                if 'token' in video_info:\n                    break\n        if 'token' not in video_info:\n            if 'reason' in video_info:\n                raise ExtractorError(u'YouTube said: %s' % video_info['reason'][0], expected=True)\n            else:\n                raise ExtractorError(u'\"token\" parameter not in video info for unknown reason')\n\n        if 'view_count' in video_info:\n            view_count = int(video_info['view_count'][0])\n        else:\n            view_count = None\n\n        # Check for \"rental\" videos\n        if 'ypc_video_rental_bar_text' in video_info and 'author' not in video_info:\n            raise ExtractorError(u'\"rental\" videos not supported')\n\n        # Start extracting information\n        self.report_information_extraction(video_id)\n\n        # uploader\n        if 'author' not in video_info:\n            raise ExtractorError(u'Unable to extract uploader name')\n        video_uploader = compat_urllib_parse.unquote_plus(video_info['author'][0])\n\n        # uploader_id\n        video_uploader_id = None\n        mobj = re.search(r'<link itemprop=\"url\" href=\"http://www.youtube.com/(?:user|channel)/([^\"]+)\">', video_webpage)\n        if mobj is not None:\n            video_uploader_id = mobj.group(1)\n        else:\n            self._downloader.report_warning(u'unable to extract uploader nickname')\n\n        # title\n        if 'title' in video_info:\n            video_title = compat_urllib_parse.unquote_plus(video_info['title'][0])\n        else:\n            self._downloader.report_warning(u'Unable to extract video title')\n            video_title = u'_'\n\n        # thumbnail image\n        # We try first to get a high quality image:\n        m_thumb = re.search(r'<span itemprop=\"thumbnail\".*?href=\"(.*?)\">',\n                            video_webpage, re.DOTALL)\n        if m_thumb is not None:\n            video_thumbnail = m_thumb.group(1)\n        elif 'thumbnail_url' not in video_info:\n            self._downloader.report_warning(u'unable to extract video thumbnail')\n            video_thumbnail = None\n        else:   # don't panic if we can't find it\n            video_thumbnail = compat_urllib_parse.unquote_plus(video_info['thumbnail_url'][0])\n\n        # upload date\n        upload_date = None\n        mobj = re.search(r'id=\"eow-date.*?>(.*?)</span>', video_webpage, re.DOTALL)\n        if mobj is not None:\n            upload_date = ' '.join(re.sub(r'[/,-]', r' ', mobj.group(1)).split())\n            upload_date = unified_strdate(upload_date)\n\n        # description\n        video_description = get_element_by_id(\"eow-description\", video_webpage)\n        if video_description:\n            video_description = re.sub(r'''(?x)\n                <a\\s+\n                    (?:[a-zA-Z-]+=\"[^\"]+\"\\s+)*?\n                    title=\"([^\"]+)\"\\s+\n                    (?:[a-zA-Z-]+=\"[^\"]+\"\\s+)*?\n                    class=\"yt-uix-redirect-link\"\\s*>\n                [^<]+\n                </a>\n            ''', r'\\1', video_description)\n            video_description = clean_html(video_description)\n        else:\n            fd_mobj = re.search(r'<meta name=\"description\" content=\"([^\"]+)\"', video_webpage)\n            if fd_mobj:\n                video_description = unescapeHTML(fd_mobj.group(1))\n            else:\n                video_description = u''\n\n        def _extract_count(klass):\n            count = self._search_regex(\n                r'class=\"%s\">([\\d,]+)</span>' % re.escape(klass),\n                video_webpage, klass, default=None)\n            if count is not None:\n                return int(count.replace(',', ''))\n            return None\n        like_count = _extract_count(u'likes-count')\n        dislike_count = _extract_count(u'dislikes-count')\n\n        # subtitles\n        video_subtitles = self.extract_subtitles(video_id, video_webpage)\n\n        if self._downloader.params.get('listsubtitles', False):\n            self._list_available_subtitles(video_id, video_webpage)\n            return\n\n        if 'length_seconds' not in video_info:\n            self._downloader.report_warning(u'unable to extract video duration')\n            video_duration = None\n        else:\n            video_duration = int(compat_urllib_parse.unquote_plus(video_info['length_seconds'][0]))\n\n        # annotations\n        video_annotations = None\n        if self._downloader.params.get('writeannotations', False):\n                video_annotations = self._extract_annotations(video_id)\n\n        # Decide which formats to download\n        try:\n            mobj = re.search(r';ytplayer.config = ({.*?});', video_webpage)\n            if not mobj:\n                raise ValueError('Could not find vevo ID')\n            ytplayer_config = json.loads(mobj.group(1))\n            args = ytplayer_config['args']\n            # Easy way to know if the 's' value is in url_encoded_fmt_stream_map\n            # this signatures are encrypted\n            if 'url_encoded_fmt_stream_map' not in args:\n                raise ValueError(u'No stream_map present')  # caught below\n            re_signature = re.compile(r'[&,]s=')\n            m_s = re_signature.search(args['url_encoded_fmt_stream_map'])\n            if m_s is not None:\n                self.to_screen(u'%s: Encrypted signatures detected.' % video_id)\n                video_info['url_encoded_fmt_stream_map'] = [args['url_encoded_fmt_stream_map']]\n            m_s = re_signature.search(args.get('adaptive_fmts', u''))\n            if m_s is not None:\n                if 'adaptive_fmts' in video_info:\n                    video_info['adaptive_fmts'][0] += ',' + args['adaptive_fmts']\n                else:\n                    video_info['adaptive_fmts'] = [args['adaptive_fmts']]\n        except ValueError:\n            pass\n\n        def _map_to_format_list(urlmap):\n            formats = []\n            for itag, video_real_url in urlmap.items():\n                dct = {\n                    'format_id': itag,\n                    'url': video_real_url,\n                    'player_url': player_url,\n                }\n                if itag in self._formats:\n                    dct.update(self._formats[itag])\n                formats.append(dct)\n            return formats\n\n        if 'conn' in video_info and video_info['conn'][0].startswith('rtmp'):\n            self.report_rtmp_download()\n            formats = [{\n                'format_id': '_rtmp',\n                'protocol': 'rtmp',\n                'url': video_info['conn'][0],\n                'player_url': player_url,\n            }]\n        elif len(video_info.get('url_encoded_fmt_stream_map', [])) >= 1 or len(video_info.get('adaptive_fmts', [])) >= 1:\n            encoded_url_map = video_info.get('url_encoded_fmt_stream_map', [''])[0] + ',' + video_info.get('adaptive_fmts',[''])[0]\n            if 'rtmpe%3Dyes' in encoded_url_map:\n                raise ExtractorError('rtmpe downloads are not supported, see https://github.com/rg3/youtube-dl/issues/343 for more information.', expected=True)\n            url_map = {}\n            for url_data_str in encoded_url_map.split(','):\n                url_data = compat_parse_qs(url_data_str)\n                if 'itag' in url_data and 'url' in url_data:\n                    url = url_data['url'][0]\n                    if 'sig' in url_data:\n                        url += '&signature=' + url_data['sig'][0]\n                    elif 's' in url_data:\n                        encrypted_sig = url_data['s'][0]\n                        if self._downloader.params.get('verbose'):\n                            if age_gate:\n                                if player_url is None:\n                                    player_version = 'unknown'\n                                else:\n                                    player_version = self._search_regex(\n                                        r'-(.+)\\.swf$', player_url,\n                                        u'flash player', fatal=False)\n                                player_desc = 'flash player %s' % player_version\n                            else:\n                                player_version = self._search_regex(\n                                    r'html5player-(.+?)\\.js', video_webpage,\n                                    'html5 player', fatal=False)\n                                player_desc = u'html5 player %s' % player_version\n\n                            parts_sizes = u'.'.join(compat_str(len(part)) for part in encrypted_sig.split('.'))\n                            self.to_screen(u'encrypted signature length %d (%s), itag %s, %s' %\n                                (len(encrypted_sig), parts_sizes, url_data['itag'][0], player_desc))\n\n                        if not age_gate:\n                            jsplayer_url_json = self._search_regex(\n                                r'\"assets\":.+?\"js\":\\s*(\"[^\"]+\")',\n                                video_webpage, u'JS player URL')\n                            player_url = json.loads(jsplayer_url_json)\n\n                        signature = self._decrypt_signature(\n                            encrypted_sig, video_id, player_url, age_gate)\n                        url += '&signature=' + signature\n                    if 'ratebypass' not in url:\n                        url += '&ratebypass=yes'\n                    url_map[url_data['itag'][0]] = url\n            formats = _map_to_format_list(url_map)\n        elif video_info.get('hlsvp'):\n            manifest_url = video_info['hlsvp'][0]\n            url_map = self._extract_from_m3u8(manifest_url, video_id)\n            formats = _map_to_format_list(url_map)\n        else:\n            raise ExtractorError(u'no conn, hlsvp or url_encoded_fmt_stream_map information found in video info')\n\n        # Look for the DASH manifest\n        if (self._downloader.params.get('youtube_include_dash_manifest', False)):\n            try:\n                # The DASH manifest used needs to be the one from the original video_webpage.\n                # The one found in get_video_info seems to be using different signatures.\n                # However, in the case of an age restriction there won't be any embedded dashmpd in the video_webpage.\n                # Luckily, it seems, this case uses some kind of default signature (len == 86), so the\n                # combination of get_video_info and the _static_decrypt_signature() decryption fallback will work here.\n                if age_gate:\n                    dash_manifest_url = video_info.get('dashmpd')[0]\n                else:\n                    dash_manifest_url = ytplayer_config['args']['dashmpd']\n                def decrypt_sig(mobj):\n                    s = mobj.group(1)\n                    dec_s = self._decrypt_signature(s, video_id, player_url, age_gate)\n                    return '/signature/%s' % dec_s\n                dash_manifest_url = re.sub(r'/s/([\\w\\.]+)', decrypt_sig, dash_manifest_url)\n                dash_doc = self._download_xml(\n                    dash_manifest_url, video_id,\n                    note=u'Downloading DASH manifest',\n                    errnote=u'Could not download DASH manifest')\n                for r in dash_doc.findall(u'.//{urn:mpeg:DASH:schema:MPD:2011}Representation'):\n                    url_el = r.find('{urn:mpeg:DASH:schema:MPD:2011}BaseURL')\n                    if url_el is None:\n                        continue\n                    format_id = r.attrib['id']\n                    video_url = url_el.text\n                    filesize = int_or_none(url_el.attrib.get('{http://youtube.com/yt/2012/10/10}contentLength'))\n                    f = {\n                        'format_id': format_id,\n                        'url': video_url,\n                        'width': int_or_none(r.attrib.get('width')),\n                        'tbr': int_or_none(r.attrib.get('bandwidth'), 1000),\n                        'asr': int_or_none(r.attrib.get('audioSamplingRate')),\n                        'filesize': filesize,\n                    }\n                    try:\n                        existing_format = next(\n                            fo for fo in formats\n                            if fo['format_id'] == format_id)\n                    except StopIteration:\n                        f.update(self._formats.get(format_id, {}))\n                        formats.append(f)\n                    else:\n                        existing_format.update(f)\n\n            except (ExtractorError, KeyError) as e:\n                self.report_warning(u'Skipping DASH manifest: %s' % e, video_id)\n\n        self._sort_formats(formats)\n\n        return {\n            'id':           video_id,\n            'uploader':     video_uploader,\n            'uploader_id':  video_uploader_id,\n            'upload_date':  upload_date,\n            'title':        video_title,\n            'thumbnail':    video_thumbnail,\n            'description':  video_description,\n            'subtitles':    video_subtitles,\n            'duration':     video_duration,\n            'age_limit':    18 if age_gate else 0,\n            'annotations':  video_annotations,\n            'webpage_url': 'https://www.youtube.com/watch?v=%s' % video_id,\n            'view_count':   view_count,\n            'like_count': like_count,\n            'dislike_count': dislike_count,\n            'formats':      formats,\n        }",
        "begin_line": 1132,
        "end_line": 1452,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubePlaylistIE._real_initialize#1479",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubePlaylistIE",
        "signature": "youtube_dl.extractor.youtube.YoutubePlaylistIE._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 1479,
        "end_line": 1480,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubePlaylistIE._ids_to_results#1482",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubePlaylistIE",
        "signature": "youtube_dl.extractor.youtube.YoutubePlaylistIE._ids_to_results(self, ids)",
        "snippet": "    def _ids_to_results(self, ids):\n        return [self.url_result(vid_id, 'Youtube', video_id=vid_id)\n                       for vid_id in ids]",
        "begin_line": 1482,
        "end_line": 1484,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubePlaylistIE._extract_mix#1486",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubePlaylistIE",
        "signature": "youtube_dl.extractor.youtube.YoutubePlaylistIE._extract_mix(self, playlist_id)",
        "snippet": "    def _extract_mix(self, playlist_id):\n        # The mixes are generated from a a single video\n        # the id of the playlist is just 'RD' + video_id\n        url = 'https://youtube.com/watch?v=%s&list=%s' % (playlist_id[-11:], playlist_id)\n        webpage = self._download_webpage(url, playlist_id, u'Downloading Youtube mix')\n        search_title = lambda class_name: get_element_by_attribute('class', class_name, webpage)\n        title_span = (search_title('playlist-title') or\n            search_title('title long-title') or search_title('title'))\n        title = clean_html(title_span)\n        video_re = r'''(?x)data-video-username=\"(.*?)\".*?\n                       href=\"/watch\\?v=([0-9A-Za-z_-]{11})&amp;[^\"]*?list=%s''' % re.escape(playlist_id)\n        matches = orderedSet(re.findall(video_re, webpage, flags=re.DOTALL))\n        # Some of the videos may have been deleted, their username field is empty\n        ids = [video_id for (username, video_id) in matches if username]\n        url_results = self._ids_to_results(ids)\n\n        return self.playlist_result(url_results, playlist_id, title)",
        "begin_line": 1486,
        "end_line": 1502,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubePlaylistIE._real_extract#1504",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubePlaylistIE",
        "signature": "youtube_dl.extractor.youtube.YoutubePlaylistIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        # Extract playlist id\n        mobj = re.match(self._VALID_URL, url)\n        if mobj is None:\n            raise ExtractorError(u'Invalid URL: %s' % url)\n        playlist_id = mobj.group(1) or mobj.group(2)\n\n        # Check if it's a video-specific URL\n        query_dict = compat_urlparse.parse_qs(compat_urlparse.urlparse(url).query)\n        if 'v' in query_dict:\n            video_id = query_dict['v'][0]\n            if self._downloader.params.get('noplaylist'):\n                self.to_screen(u'Downloading just video %s because of --no-playlist' % video_id)\n                return self.url_result(video_id, 'Youtube', video_id=video_id)\n            else:\n                self.to_screen(u'Downloading playlist PL%s - add --no-playlist to just download video %s' % (playlist_id, video_id))\n\n        if playlist_id.startswith('RD'):\n            # Mixes require a custom extraction process\n            return self._extract_mix(playlist_id)\n        if playlist_id.startswith('TL'):\n            raise ExtractorError(u'For downloading YouTube.com top lists, use '\n                u'the \"yttoplist\" keyword, for example \"youtube-dl \\'yttoplist:music:Top Tracks\\'\"', expected=True)\n\n        url = self._TEMPLATE_URL % playlist_id\n        page = self._download_webpage(url, playlist_id)\n        more_widget_html = content_html = page\n\n        # Extract the video ids from the playlist pages\n        ids = []\n\n        for page_num in itertools.count(1):\n            matches = re.finditer(self._VIDEO_RE, content_html)\n            # We remove the duplicates and the link with index 0\n            # (it's not the first video of the playlist)\n            new_ids = orderedSet(m.group('id') for m in matches if m.group('index') != '0')\n            ids.extend(new_ids)\n\n            mobj = re.search(r'data-uix-load-more-href=\"/?(?P<more>[^\"]+)\"', more_widget_html)\n            if not mobj:\n                break\n\n            more = self._download_json(\n                'https://youtube.com/%s' % mobj.group('more'), playlist_id, 'Downloading page #%s' % page_num)\n            content_html = more['content_html']\n            more_widget_html = more['load_more_widget_html']\n\n        playlist_title = self._html_search_regex(\n                r'<h1 class=\"pl-header-title\">\\s*(.*?)\\s*</h1>', page, u'title')\n\n        url_results = self._ids_to_results(ids)\n        return self.playlist_result(url_results, playlist_id, playlist_title)",
        "begin_line": 1504,
        "end_line": 1555,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeTopListIE._real_extract#1564",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeTopListIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeTopListIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        channel = mobj.group('chann')\n        title = mobj.group('title')\n        query = compat_urllib_parse.urlencode({'title': title})\n        playlist_re = 'href=\"([^\"]+?%s.*?)\"' % re.escape(query)\n        channel_page = self._download_webpage('https://www.youtube.com/%s' % channel, title)\n        link = self._html_search_regex(playlist_re, channel_page, u'list')\n        url = compat_urlparse.urljoin('https://www.youtube.com/', link)\n        \n        video_re = r'data-index=\"\\d+\".*?data-video-id=\"([0-9A-Za-z_-]{11})\"'\n        ids = []\n        # sometimes the webpage doesn't contain the videos\n        # retry until we get them\n        for i in itertools.count(0):\n            msg = u'Downloading Youtube mix'\n            if i > 0:\n                msg += ', retry #%d' % i\n            webpage = self._download_webpage(url, title, msg)\n            ids = orderedSet(re.findall(video_re, webpage))\n            if ids:\n                break\n        url_results = self._ids_to_results(ids)\n        return self.playlist_result(url_results, playlist_title=title)",
        "begin_line": 1564,
        "end_line": 1587,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeChannelIE.extract_videos_from_page#1597",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeChannelIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeChannelIE.extract_videos_from_page(self, page)",
        "snippet": "    def extract_videos_from_page(self, page):\n        ids_in_page = []\n        for mobj in re.finditer(r'href=\"/watch\\?v=([0-9A-Za-z_-]+)&?', page):\n            if mobj.group(1) not in ids_in_page:\n                ids_in_page.append(mobj.group(1))\n        return ids_in_page",
        "begin_line": 1597,
        "end_line": 1602,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeChannelIE._real_extract#1604",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeChannelIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        # Extract channel id\n        mobj = re.match(self._VALID_URL, url)\n        if mobj is None:\n            raise ExtractorError(u'Invalid URL: %s' % url)\n\n        # Download channel page\n        channel_id = mobj.group(1)\n        video_ids = []\n        url = 'https://www.youtube.com/channel/%s/videos' % channel_id\n        channel_page = self._download_webpage(url, channel_id)\n        autogenerated = re.search(r'''(?x)\n                class=\"[^\"]*?(?:\n                    channel-header-autogenerated-label|\n                    yt-channel-title-autogenerated\n                )[^\"]*\"''', channel_page) is not None\n\n        if autogenerated:\n            # The videos are contained in a single page\n            # the ajax pages can't be used, they are empty\n            video_ids = self.extract_videos_from_page(channel_page)\n        else:\n            # Download all channel pages using the json-based channel_ajax query\n            for pagenum in itertools.count(1):\n                url = self._MORE_PAGES_URL % (pagenum, channel_id)\n                page = self._download_json(\n                    url, channel_id, note=u'Downloading page #%s' % pagenum,\n                    transform_source=uppercase_escape)\n\n                ids_in_page = self.extract_videos_from_page(page['content_html'])\n                video_ids.extend(ids_in_page)\n    \n                if self._MORE_PAGES_INDICATOR not in page['load_more_widget_html']:\n                    break\n\n        self._downloader.to_screen(u'[youtube] Channel %s: Found %i videos' % (channel_id, len(video_ids)))\n\n        url_entries = [self.url_result(video_id, 'Youtube', video_id=video_id)\n                       for video_id in video_ids]\n        return self.playlist_result(url_entries, channel_id)",
        "begin_line": 1604,
        "end_line": 1643,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeUserIE.suitable#1655",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeUserIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeUserIE.suitable(cls, url)",
        "snippet": "    def suitable(cls, url):\n        # Don't return True if the url can be extracted with other youtube\n        # extractor, the regex would is too permissive and it would match.\n        other_ies = iter(klass for (name, klass) in globals().items() if name.endswith('IE') and klass is not cls)\n        if any(ie.suitable(url) for ie in other_ies): return False\n        else: return super(YoutubeUserIE, cls).suitable(url)",
        "begin_line": 1655,
        "end_line": 1660,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.00015862944162436547,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeUserIE._real_extract#1662",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeUserIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        # Extract username\n        mobj = re.match(self._VALID_URL, url)\n        if mobj is None:\n            raise ExtractorError(u'Invalid URL: %s' % url)\n\n        username = mobj.group(1)\n\n        # Download video ids using YouTube Data API. Result size per\n        # query is limited (currently to 50 videos) so we need to query\n        # page by page until there are no video ids - it means we got\n        # all of them.\n\n        def download_page(pagenum):\n            start_index = pagenum * self._GDATA_PAGE_SIZE + 1\n\n            gdata_url = self._GDATA_URL % (username, self._GDATA_PAGE_SIZE, start_index)\n            page = self._download_webpage(\n                gdata_url, username,\n                u'Downloading video ids from %d to %d' % (\n                    start_index, start_index + self._GDATA_PAGE_SIZE))\n\n            try:\n                response = json.loads(page)\n            except ValueError as err:\n                raise ExtractorError(u'Invalid JSON in API response: ' + compat_str(err))\n            if 'entry' not in response['feed']:\n                return\n\n            # Extract video identifiers\n            entries = response['feed']['entry']\n            for entry in entries:\n                title = entry['title']['$t']\n                video_id = entry['id']['$t'].split('/')[-1]\n                yield {\n                    '_type': 'url',\n                    'url': video_id,\n                    'ie_key': 'Youtube',\n                    'id': video_id,\n                    'title': title,\n                }\n        url_results = PagedList(download_page, self._GDATA_PAGE_SIZE)\n\n        return self.playlist_result(url_results, playlist_title=username)",
        "begin_line": 1662,
        "end_line": 1705,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeSearchIE._get_n_results#1715",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeSearchIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeSearchIE._get_n_results(self, query, n)",
        "snippet": "    def _get_n_results(self, query, n):\n        \"\"\"Get a specified number of results for a query\"\"\"\n\n        video_ids = []\n        pagenum = 0\n        limit = n\n\n        while (50 * pagenum) < limit:\n            result_url = self._API_URL % (compat_urllib_parse.quote_plus(query), (50*pagenum)+1)\n            data_json = self._download_webpage(\n                result_url, video_id=u'query \"%s\"' % query,\n                note=u'Downloading page %s' % (pagenum + 1),\n                errnote=u'Unable to download API page')\n            data = json.loads(data_json)\n            api_response = data['data']\n\n            if 'items' not in api_response:\n                raise ExtractorError(\n                    u'[youtube] No video results', expected=True)\n\n            new_ids = list(video['id'] for video in api_response['items'])\n            video_ids += new_ids\n\n            limit = min(n, api_response['totalItems'])\n            pagenum += 1\n\n        if len(video_ids) > n:\n            video_ids = video_ids[:n]\n        videos = [self.url_result(video_id, 'Youtube', video_id=video_id)\n                  for video_id in video_ids]\n        return self.playlist_result(videos, query)",
        "begin_line": 1715,
        "end_line": 1745,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeSearchURLIE._real_extract#1760",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeSearchURLIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeSearchURLIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        query = compat_urllib_parse.unquote_plus(mobj.group('query'))\n\n        webpage = self._download_webpage(url, query)\n        result_code = self._search_regex(\n            r'(?s)<ol id=\"search-results\"(.*?)</ol>', webpage, u'result HTML')\n\n        part_codes = re.findall(\n            r'(?s)<h3 class=\"yt-lockup-title\">(.*?)</h3>', result_code)\n        entries = []\n        for part_code in part_codes:\n            part_title = self._html_search_regex(\n                r'(?s)title=\"([^\"]+)\"', part_code, 'item title', fatal=False)\n            part_url_snippet = self._html_search_regex(\n                r'(?s)href=\"([^\"]+)\"', part_code, 'item URL')\n            part_url = compat_urlparse.urljoin(\n                'https://www.youtube.com/', part_url_snippet)\n            entries.append({\n                '_type': 'url',\n                'url': part_url,\n                'title': part_title,\n            })\n\n        return {\n            '_type': 'playlist',\n            'entries': entries,\n            'title': query,\n        }",
        "begin_line": 1760,
        "end_line": 1788,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeShowIE._real_extract#1796",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeShowIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeShowIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        show_name = mobj.group(1)\n        webpage = self._download_webpage(url, show_name, u'Downloading show webpage')\n        # There's one playlist for each season of the show\n        m_seasons = list(re.finditer(r'href=\"(/playlist\\?list=.*?)\"', webpage))\n        self.to_screen(u'%s: Found %s seasons' % (show_name, len(m_seasons)))\n        return [self.url_result('https://www.youtube.com' + season.group(1), 'YoutubePlaylist') for season in m_seasons]",
        "begin_line": 1796,
        "end_line": 1803,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor.IE_NAME#1824",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor.IE_NAME(self)",
        "snippet": "    def IE_NAME(self):\n        return u'youtube:%s' % self._FEED_NAME",
        "begin_line": 1824,
        "end_line": 1825,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.002369668246445498,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor._real_initialize#1827",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor._real_initialize(self)",
        "snippet": "    def _real_initialize(self):\n        self._login()",
        "begin_line": 1827,
        "end_line": 1828,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor._real_extract#1830",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor",
        "signature": "youtube_dl.extractor.youtube.YoutubeFeedsInfoExtractor._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        feed_entries = []\n        paging = 0\n        for i in itertools.count(1):\n            info = self._download_webpage(self._FEED_TEMPLATE % paging,\n                                          u'%s feed' % self._FEED_NAME,\n                                          u'Downloading page %s' % i)\n            info = json.loads(info)\n            feed_html = info['feed_html']\n            m_ids = re.finditer(r'\"/watch\\?v=(.*?)[\"&]', feed_html)\n            ids = orderedSet(m.group(1) for m in m_ids)\n            feed_entries.extend(\n                self.url_result(video_id, 'Youtube', video_id=video_id)\n                for video_id in ids)\n            if info['paging'] is None:\n                break\n            paging = info['paging']\n        return self.playlist_result(feed_entries, playlist_title=self._PLAYLIST_TITLE)",
        "begin_line": 1830,
        "end_line": 1847,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeFavouritesIE._real_extract#1881",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeFavouritesIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeFavouritesIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        webpage = self._download_webpage('https://www.youtube.com/my_favorites', 'Youtube Favourites videos')\n        playlist_id = self._search_regex(r'list=(.+?)[\"&]', webpage, u'favourites playlist id')\n        return self.url_result(playlist_id, 'YoutubePlaylist')",
        "begin_line": 1881,
        "end_line": 1884,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.youtube.YoutubeTruncatedURLIE._real_extract#1895",
        "src_path": "youtube_dl/extractor/youtube.py",
        "class_name": "youtube_dl.extractor.youtube.YoutubeTruncatedURLIE",
        "signature": "youtube_dl.extractor.youtube.YoutubeTruncatedURLIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        raise ExtractorError(\n            u'Did you forget to quote the URL? Remember that & is a meta '\n            u'character in most shells, so you want to put the URL in quotes, '\n            u'like  youtube-dl '\n            u'\"http://www.youtube.com/watch?feature=foo&v=BaW_jenozKc\" '\n            u' or simply  youtube-dl BaW_jenozKc  .',\n            expected=True)",
        "begin_line": 1895,
        "end_line": 1902,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.videobam.VideoBamIE._real_extract#36",
        "src_path": "youtube_dl/extractor/videobam.py",
        "class_name": "youtube_dl.extractor.videobam.VideoBamIE",
        "signature": "youtube_dl.extractor.videobam.VideoBamIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        page = self._download_webpage('http://videobam.com/%s' % video_id, video_id, 'Downloading page')\n\n        formats = []\n\n        for preference, format_id in enumerate(['low', 'high']):\n            mobj = re.search(r\"%s: '(?P<url>[^']+)'\" % format_id, page)\n            if not mobj:\n                continue\n            formats.append({\n                'url': mobj.group('url'),\n                'ext': 'mp4',\n                'format_id': format_id,\n                'preference': preference,\n            })\n\n        if not formats:\n            player_config = json.loads(self._html_search_regex(r'var player_config = ({.+?});', page, 'player config'))\n            formats = [{\n                'url': item['url'],\n                'ext': 'mp4',\n            } for item in player_config['playlist'] if 'autoPlay' in item]\n\n        self._sort_formats(formats)\n\n        title = self._og_search_title(page, default='VideoBam', fatal=False)\n        description = self._og_search_description(page, default=None)\n        thumbnail = self._og_search_thumbnail(page)\n        uploader = self._html_search_regex(r'Upload by ([^<]+)</a>', page, 'uploader', fatal=False, default=None)\n        view_count = int_or_none(\n            self._html_search_regex(r'<strong>Views:</strong> (\\d+) ', page, 'view count', fatal=False))\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'uploader': uploader,\n            'view_count': view_count,\n            'formats': formats,\n            'age_limit': 18,\n        }",
        "begin_line": 36,
        "end_line": 80,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.muzu.MuzuTVIE._real_extract#26",
        "src_path": "youtube_dl/extractor/muzu.py",
        "class_name": "youtube_dl.extractor.muzu.MuzuTVIE",
        "signature": "youtube_dl.extractor.muzu.MuzuTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        info_data = compat_urllib_parse.urlencode({'format': 'json',\n                                                   'url': url,\n                                                   })\n        video_info_page = self._download_webpage('http://www.muzu.tv/api/oembed/?%s' % info_data,\n                                                 video_id, u'Downloading video info')\n        info = json.loads(video_info_page)\n\n        player_info_page = self._download_webpage('http://player.muzu.tv/player/playerInit?ai=%s' % video_id,\n                                                  video_id, u'Downloading player info')\n        video_info = json.loads(player_info_page)['videos'][0]\n        for quality in ['1080' , '720', '480', '360']:\n            if video_info.get('v%s' % quality):\n                break\n\n        data = compat_urllib_parse.urlencode({'ai': video_id,\n                                              # Even if each time you watch a video the hash changes,\n                                              # it seems to work for different videos, and it will work\n                                              # even if you use any non empty string as a hash\n                                              'viewhash': 'VBNff6djeV4HV5TRPW5kOHub2k',\n                                              'device': 'web',\n                                              'qv': quality,\n                                              })\n        video_url_page = self._download_webpage('http://player.muzu.tv/player/requestVideo?%s' % data,\n                                                video_id, u'Downloading video url')\n        video_url_info = json.loads(video_url_page)\n        video_url = video_url_info['url']\n\n        return {'id': video_id,\n                'title': info['title'],\n                'url': video_url,\n                'ext': determine_ext(video_url),\n                'thumbnail': info['thumbnail_url'],\n                'description': info['description'],\n                'uploader': info['author_name'],\n                }",
        "begin_line": 26,
        "end_line": 64,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.bambuser.BambuserIE._real_extract#37",
        "src_path": "youtube_dl/extractor/bambuser.py",
        "class_name": "youtube_dl.extractor.bambuser.BambuserIE",
        "signature": "youtube_dl.extractor.bambuser.BambuserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        info_url = ('http://player-c.api.bambuser.com/getVideo.json?'\n            '&api_key=%s&vid=%s' % (self._API_KEY, video_id))\n        info_json = self._download_webpage(info_url, video_id)\n        info = json.loads(info_json)['result']\n\n        return {\n            'id': video_id,\n            'title': info['title'],\n            'url': info['url'],\n            'thumbnail': info.get('preview'),\n            'duration': int(info['length']),\n            'view_count': int(info['views_total']),\n            'uploader': info['username'],\n            'uploader_id': info['uid'],\n        }",
        "begin_line": 37,
        "end_line": 54,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.bambuser.BambuserChannelIE._real_extract#63",
        "src_path": "youtube_dl/extractor/bambuser.py",
        "class_name": "youtube_dl.extractor.bambuser.BambuserChannelIE",
        "signature": "youtube_dl.extractor.bambuser.BambuserChannelIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        user = mobj.group('user')\n        urls = []\n        last_id = ''\n        for i in itertools.count(1):\n            req_url = ('http://bambuser.com/xhr-api/index.php?username={user}'\n                '&sort=created&access_mode=0%2C1%2C2&limit={count}'\n                '&method=broadcast&format=json&vid_older_than={last}'\n                ).format(user=user, count=self._STEP, last=last_id)\n            req = compat_urllib_request.Request(req_url)\n            # Without setting this header, we wouldn't get any result\n            req.add_header('Referer', 'http://bambuser.com/channel/%s' % user)\n            info_json = self._download_webpage(req, user,\n                'Downloading page %d' % i)\n            results = json.loads(info_json)['result']\n            if len(results) == 0:\n                break\n            last_id = results[-1]['vid']\n            urls.extend(self.url_result(v['page'], 'Bambuser') for v in results)\n\n        return {\n            '_type': 'playlist',\n            'title': user,\n            'entries': urls,\n        }",
        "begin_line": 63,
        "end_line": 88,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.hls.HlsFD.real_download#11",
        "src_path": "youtube_dl/downloader/hls.py",
        "class_name": "youtube_dl.downloader.hls.HlsFD",
        "signature": "youtube_dl.downloader.hls.HlsFD.real_download(self, filename, info_dict)",
        "snippet": "    def real_download(self, filename, info_dict):\n        url = info_dict['url']\n        self.report_destination(filename)\n        tmpfilename = self.temp_name(filename)\n\n        args = ['-y', '-i', url, '-f', 'mp4', '-c', 'copy',\n            '-bsf:a', 'aac_adtstoasc', tmpfilename]\n\n        for program in ['avconv', 'ffmpeg']:\n            try:\n                subprocess.call([program, '-version'], stdout=(open(os.path.devnull, 'w')), stderr=subprocess.STDOUT)\n                break\n            except (OSError, IOError):\n                pass\n        else:\n            self.report_error(u'm3u8 download detected but ffmpeg or avconv could not be found')\n        cmd = [program] + args\n\n        retval = subprocess.call(cmd)\n        if retval == 0:\n            fsize = os.path.getsize(encodeFilename(tmpfilename))\n            self.to_screen(u'\\r[%s] %s bytes' % (cmd[0], fsize))\n            self.try_rename(tmpfilename, filename)\n            self._hook_progress({\n                'downloaded_bytes': fsize,\n                'total_bytes': fsize,\n                'filename': filename,\n                'status': 'finished',\n            })\n            return True\n        else:\n            self.to_stderr(u\"\\n\")\n            self.report_error(u'ffmpeg exited with code %d' % retval)\n            return False",
        "begin_line": 11,
        "end_line": 44,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.dotsub.DotsubIE._real_extract#25",
        "src_path": "youtube_dl/extractor/dotsub.py",
        "class_name": "youtube_dl.extractor.dotsub.DotsubIE",
        "signature": "youtube_dl.extractor.dotsub.DotsubIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        info_url = \"https://dotsub.com/api/media/%s/metadata\" % video_id\n        info = self._download_json(info_url, video_id)\n        date = time.gmtime(info['dateCreated']/1000) # The timestamp is in miliseconds\n\n        return {\n            'id': video_id,\n            'url': info['mediaURI'],\n            'ext': 'flv',\n            'title': info['title'],\n            'thumbnail': info['screenshotURI'],\n            'description': info['description'],\n            'uploader': info['user'],\n            'view_count': info['numberOfViews'],\n            'upload_date': '%04i%02i%02i' % (date.tm_year, date.tm_mon, date.tm_mday),\n        }",
        "begin_line": 25,
        "end_line": 42,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.bloomberg.BloombergIE._real_extract#23",
        "src_path": "youtube_dl/extractor/bloomberg.py",
        "class_name": "youtube_dl.extractor.bloomberg.BloombergIE",
        "signature": "youtube_dl.extractor.bloomberg.BloombergIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        name = mobj.group('name')\n        webpage = self._download_webpage(url, name)\n        embed_code = self._search_regex(\n            r'<source src=\"https?://[^/]+/[^/]+/[^/]+/([^/]+)', webpage,\n            'embed code')\n        return OoyalaIE._build_url_result(embed_code)",
        "begin_line": 23,
        "end_line": 30,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.statigram.StatigramIE._real_extract#21",
        "src_path": "youtube_dl/extractor/statigram.py",
        "class_name": "youtube_dl.extractor.statigram.StatigramIE",
        "signature": "youtube_dl.extractor.statigram.StatigramIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        html_title = self._html_search_regex(\n            r'<title>(.+?)</title>',\n            webpage, 'title')\n        title = re.sub(r'(?: *\\(Videos?\\))? \\| Statigram$', '', html_title)\n        uploader_id = self._html_search_regex(\n            r'@([^ ]+)', title, 'uploader name', fatal=False)\n\n        return {\n            'id': video_id,\n            'url': self._og_search_video_url(webpage),\n            'title': title,\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'uploader_id': uploader_id\n        }",
        "begin_line": 21,
        "end_line": 38,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.mit.TechTVMITIE._real_extract#31",
        "src_path": "youtube_dl/extractor/mit.py",
        "class_name": "youtube_dl.extractor.mit.TechTVMITIE",
        "signature": "youtube_dl.extractor.mit.TechTVMITIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        raw_page = self._download_webpage(\n            'http://techtv.mit.edu/videos/%s' % video_id, video_id)\n        clean_page = re.compile(r'<!--.*?-->', re.S).sub('', raw_page)\n\n        base_url = self._search_regex(\n            r'ipadUrl: \\'(.+?cloudfront.net/)', raw_page, 'base url')\n        formats_json = self._search_regex(\n            r'bitrates: (\\[.+?\\])', raw_page, 'video formats')\n        formats_mit = json.loads(formats_json)\n        formats = [\n            {\n                'format_id': f['label'],\n                'url': base_url + f['url'].partition(':')[2],\n                'ext': f['url'].partition(':')[0],\n                'format': f['label'],\n                'width': f['width'],\n                'vbr': f['bitrate'],\n            }\n            for f in formats_mit\n        ]\n\n        title = get_element_by_id('edit-title', clean_page)\n        description = clean_html(get_element_by_id('edit-description', clean_page))\n        thumbnail = self._search_regex(\n            r'playlist:.*?url: \\'(.+?)\\'',\n            raw_page, 'thumbnail', flags=re.DOTALL)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'formats': formats,\n            'description': description,\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 31,
        "end_line": 67,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.mit.MITIE._real_extract#85",
        "src_path": "youtube_dl/extractor/mit.py",
        "class_name": "youtube_dl.extractor.mit.MITIE",
        "signature": "youtube_dl.extractor.mit.MITIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        page_title = mobj.group('title')\n        webpage = self._download_webpage(url, page_title)\n        embed_url = self._search_regex(\n            r'<iframe .*?src=\"(.+?)\"', webpage, 'embed url')\n        return self.url_result(embed_url, ie='TechTVMIT')",
        "begin_line": 85,
        "end_line": 91,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.mit.OCWMITIE._real_extract#122",
        "src_path": "youtube_dl/extractor/mit.py",
        "class_name": "youtube_dl.extractor.mit.OCWMITIE",
        "signature": "youtube_dl.extractor.mit.OCWMITIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        topic = mobj.group('topic')\n\n        webpage = self._download_webpage(url, topic)\n        title = self._html_search_meta('WT.cg_s', webpage)\n        description = self._html_search_meta('Description', webpage)\n\n        # search for call to ocw_embed_chapter_media(container_id, media_url, provider, page_url, image_url, start, stop, captions_file)\n        embed_chapter_media = re.search(r'ocw_embed_chapter_media\\((.+?)\\)', webpage)\n        if embed_chapter_media:\n            metadata = re.sub(r'[\\'\"]', '', embed_chapter_media.group(1))\n            metadata = re.split(r', ?', metadata)\n            yt = metadata[1]\n            subs = compat_urlparse.urljoin(self._BASE_URL, metadata[7])\n        else:\n            # search for call to ocw_embed_chapter_media(container_id, media_url, provider, page_url, image_url, captions_file)\n            embed_media = re.search(r'ocw_embed_media\\((.+?)\\)', webpage)\n            if embed_media:\n                metadata = re.sub(r'[\\'\"]', '', embed_media.group(1))\n                metadata = re.split(r', ?', metadata)\n                yt = metadata[1]\n                subs = compat_urlparse.urljoin(self._BASE_URL, metadata[5])\n            else:\n                raise ExtractorError('Unable to find embedded YouTube video.')\n        video_id = YoutubeIE.extract_id(yt)\n\n        return {\n            '_type': 'url_transparent',\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'url': yt,\n            'url_transparent'\n            'subtitles': subs,\n            'ie_key': 'Youtube',\n        }",
        "begin_line": 122,
        "end_line": 158,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.ringtv.RingTVIE._real_extract#20",
        "src_path": "youtube_dl/extractor/ringtv.py",
        "class_name": "youtube_dl.extractor.ringtv.RingTVIE",
        "signature": "youtube_dl.extractor.ringtv.RingTVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id').split('-')[0]\n        webpage = self._download_webpage(url, video_id)\n\n        if mobj.group('type') == 'news':\n            video_id = self._search_regex(\n                r'''(?x)<iframe[^>]+src=\"http://cms\\.springboardplatform\\.com/\n                        embed_iframe/[0-9]+/video/([0-9]+)/''',\n                webpage, 'real video ID')\n        title = self._og_search_title(webpage)\n        description = self._html_search_regex(\n            r'addthis:description=\"([^\"]+)\"',\n            webpage, 'description', fatal=False)\n        final_url = \"http://ringtv.craveonline.springboardplatform.com/storage/ringtv.craveonline.com/conversion/%s.mp4\" % video_id\n        thumbnail_url = \"http://ringtv.craveonline.springboardplatform.com/storage/ringtv.craveonline.com/snapshots/%s.jpg\" % video_id\n\n        return {\n            'id': video_id,\n            'url': final_url,\n            'title': title,\n            'thumbnail': thumbnail_url,\n            'description': description,\n        }",
        "begin_line": 20,
        "end_line": 43,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.videofyme.VideofyMeIE._real_extract#26",
        "src_path": "youtube_dl/extractor/videofyme.py",
        "class_name": "youtube_dl.extractor.videofyme.VideofyMeIE",
        "signature": "youtube_dl.extractor.videofyme.VideofyMeIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        config = self._download_xml('http://sunshine.videofy.me/?videoId=%s' % video_id,\n                                            video_id)\n        video = config.find('video')\n        sources = video.find('sources')\n        url_node = next(node for node in [find_xpath_attr(sources, 'source', 'id', 'HQ %s' % key) \n            for key in ['on', 'av', 'off']] if node is not None)\n        video_url = url_node.find('url').text\n\n        return {'id': video_id,\n                'title': video.find('title').text,\n                'url': video_url,\n                'ext': determine_ext(video_url),\n                'thumbnail': video.find('thumb').text,\n                'description': video.find('description').text,\n                'uploader': config.find('blog/name').text,\n                'uploader_id': video.find('identifier').text,\n                'view_count': re.search(r'\\d+', video.find('views').text).group(),\n                }",
        "begin_line": 26,
        "end_line": 46,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.eitb.EitbIE._real_extract#27",
        "src_path": "youtube_dl/extractor/eitb.py",
        "class_name": "youtube_dl.extractor.eitb.EitbIE",
        "signature": "youtube_dl.extractor.eitb.EitbIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        chapter_id = mobj.group('chapter_id')\n        webpage = self._download_webpage(url, chapter_id)\n        bc_url = BrightcoveIE._extract_brightcove_url(webpage)\n        if bc_url is None:\n            raise ExtractorError(u'Could not extract the Brightcove url')\n        # The BrightcoveExperience object doesn't contain the video id, we set\n        # it manually\n        bc_url += '&%40videoPlayer={0}'.format(chapter_id)\n        return self.url_result(bc_url, BrightcoveIE.ie_key())",
        "begin_line": 27,
        "end_line": 37,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.googleplus.GooglePlusIE._real_extract#28",
        "src_path": "youtube_dl/extractor/googleplus.py",
        "class_name": "youtube_dl.extractor.googleplus.GooglePlusIE",
        "signature": "youtube_dl.extractor.googleplus.GooglePlusIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        # Extract id from URL\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n\n        # Step 1, Retrieve post webpage to extract further information\n        webpage = self._download_webpage(url, video_id, 'Downloading entry webpage')\n\n        self.report_extraction(video_id)\n\n        # Extract update date\n        upload_date = self._html_search_regex(\n            r'''(?x)<a.+?class=\"o-U-s\\s[^\"]+\"\\s+style=\"display:\\s*none\"\\s*>\n                    ([0-9]{4}-[0-9]{2}-[0-9]{2})</a>''',\n            webpage, 'upload date', fatal=False, flags=re.VERBOSE)\n        if upload_date:\n            # Convert timestring to a format suitable for filename\n            upload_date = datetime.datetime.strptime(upload_date, \"%Y-%m-%d\")\n            upload_date = upload_date.strftime('%Y%m%d')\n\n        # Extract uploader\n        uploader = self._html_search_regex(r'rel\\=\"author\".*?>(.*?)</a>',\n            webpage, 'uploader', fatal=False)\n\n        # Extract title\n        # Get the first line for title\n        video_title = self._html_search_regex(r'<meta name\\=\\\"Description\\\" content\\=\\\"(.*?)[\\n<\"]',\n            webpage, 'title', default='NA')\n\n        # Step 2, Simulate clicking the image box to launch video\n        DOMAIN = 'https://plus.google.com/'\n        video_page = self._search_regex(r'<a href=\"((?:%s)?photos/.*?)\"' % re.escape(DOMAIN),\n            webpage, 'video page URL')\n        if not video_page.startswith(DOMAIN):\n            video_page = DOMAIN + video_page\n\n        webpage = self._download_webpage(video_page, video_id, 'Downloading video page')\n\n        # Extract video links all sizes\n        pattern = r'\\d+,\\d+,(\\d+),\"(http\\://redirector\\.googlevideo\\.com.*?)\"'\n        mobj = re.findall(pattern, webpage)\n        if len(mobj) == 0:\n            raise ExtractorError('Unable to extract video links')\n\n        # Sort in resolution\n        links = sorted(mobj)\n\n        # Choose the lowest of the sort, i.e. highest resolution\n        video_url = links[-1]\n        # Only get the url. The resolution part in the tuple has no use anymore\n        video_url = video_url[-1]\n        # Treat escaped \\u0026 style hex\n        try:\n            video_url = video_url.decode(\"unicode_escape\")\n        except AttributeError: # Python 3\n            video_url = bytes(video_url, 'ascii').decode('unicode-escape')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'uploader': uploader,\n            'upload_date': upload_date,\n            'title': video_title,\n            'ext': 'flv',\n        }",
        "begin_line": 28,
        "end_line": 93,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.kickstarter.KickStarterIE._real_extract#17",
        "src_path": "youtube_dl/extractor/kickstarter.py",
        "class_name": "youtube_dl.extractor.kickstarter.KickStarterIE",
        "signature": "youtube_dl.extractor.kickstarter.KickStarterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('id')\n        webpage_src = self._download_webpage(url, video_id)\n\n        video_url = self._search_regex(r'data-video=\"(.*?)\">',\n            webpage_src, u'video URL')\n        if 'mp4' in video_url:\n            ext = 'mp4'\n        else:\n            ext = 'flv'\n        video_title = self._html_search_regex(r\"<title>(.*?)</title>\",\n            webpage_src, u'title').rpartition(u'\\u2014 Kickstarter')[0].strip()\n\n        results = [{\n                    'id': video_id,\n                    'url': video_url,\n                    'title': video_title,\n                    'ext': ext,\n                    }]\n        return results",
        "begin_line": 17,
        "end_line": 37,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.__init__.parseOpts#100",
        "src_path": "youtube_dl/__init__.py",
        "class_name": "youtube_dl.__init__",
        "signature": "youtube_dl.__init__.parseOpts(overrideArguments=None)",
        "snippet": "def parseOpts(overrideArguments=None):\n    def _readOptions(filename_bytes, default=[]):\n        try:\n            optionf = open(filename_bytes)\n        except IOError:\n            return default  # silently skip if file is not present\n        try:\n            res = []\n            for l in optionf:\n                res += shlex.split(l, comments=True)\n        finally:\n            optionf.close()\n        return res\n\n    def _readUserConf():\n        xdg_config_home = os.environ.get('XDG_CONFIG_HOME')\n        if xdg_config_home:\n            userConfFile = os.path.join(xdg_config_home, 'youtube-dl', 'config')\n            if not os.path.isfile(userConfFile):\n                userConfFile = os.path.join(xdg_config_home, 'youtube-dl.conf')\n        else:\n            userConfFile = os.path.join(os.path.expanduser('~'), '.config', 'youtube-dl', 'config')\n            if not os.path.isfile(userConfFile):\n                userConfFile = os.path.join(os.path.expanduser('~'), '.config', 'youtube-dl.conf')\n        userConf = _readOptions(userConfFile, None)\n\n        if userConf is None:\n            appdata_dir = os.environ.get('appdata')\n            if appdata_dir:\n                userConf = _readOptions(\n                    os.path.join(appdata_dir, 'youtube-dl', 'config'),\n                    default=None)\n                if userConf is None:\n                    userConf = _readOptions(\n                        os.path.join(appdata_dir, 'youtube-dl', 'config.txt'),\n                        default=None)\n\n        if userConf is None:\n            userConf = _readOptions(\n                os.path.join(os.path.expanduser('~'), 'youtube-dl.conf'),\n                default=None)\n        if userConf is None:\n            userConf = _readOptions(\n                os.path.join(os.path.expanduser('~'), 'youtube-dl.conf.txt'),\n                default=None)\n\n        if userConf is None:\n            userConf = []\n\n        return userConf\n\n    def _format_option_string(option):\n        ''' ('-o', '--option') -> -o, --format METAVAR'''\n\n        opts = []\n\n        if option._short_opts:\n            opts.append(option._short_opts[0])\n        if option._long_opts:\n            opts.append(option._long_opts[0])\n        if len(opts) > 1:\n            opts.insert(1, ', ')\n\n        if option.takes_value(): opts.append(' %s' % option.metavar)\n\n        return \"\".join(opts)\n\n    def _comma_separated_values_options_callback(option, opt_str, value, parser):\n        setattr(parser.values, option.dest, value.split(','))\n\n    def _hide_login_info(opts):\n        opts = list(opts)\n        for private_opt in ['-p', '--password', '-u', '--username', '--video-password']:\n            try:\n                i = opts.index(private_opt)\n                opts[i+1] = '<PRIVATE>'\n            except ValueError:\n                pass\n        return opts\n\n    max_width = 80\n    max_help_position = 80\n\n    # No need to wrap help messages if we're on a wide console\n    columns = get_term_width()\n    if columns: max_width = columns\n\n    fmt = optparse.IndentedHelpFormatter(width=max_width, max_help_position=max_help_position)\n    fmt.format_option_strings = _format_option_string\n\n    kw = {\n        'version'   : __version__,\n        'formatter' : fmt,\n        'usage' : '%prog [options] url [url...]',\n        'conflict_handler' : 'resolve',\n    }\n\n    parser = optparse.OptionParser(**kw)\n\n    # option groups\n    general        = optparse.OptionGroup(parser, 'General Options')\n    selection      = optparse.OptionGroup(parser, 'Video Selection')\n    authentication = optparse.OptionGroup(parser, 'Authentication Options')\n    video_format   = optparse.OptionGroup(parser, 'Video Format Options')\n    subtitles      = optparse.OptionGroup(parser, 'Subtitle Options')\n    downloader     = optparse.OptionGroup(parser, 'Download Options')\n    postproc       = optparse.OptionGroup(parser, 'Post-processing Options')\n    filesystem     = optparse.OptionGroup(parser, 'Filesystem Options')\n    verbosity      = optparse.OptionGroup(parser, 'Verbosity / Simulation Options')\n\n    general.add_option('-h', '--help',\n            action='help', help='print this help text and exit')\n    general.add_option('-v', '--version',\n            action='version', help='print program version and exit')\n    general.add_option('-U', '--update',\n            action='store_true', dest='update_self', help='update this program to latest version. Make sure that you have sufficient permissions (run with sudo if needed)')\n    general.add_option('-i', '--ignore-errors',\n            action='store_true', dest='ignoreerrors', help='continue on download errors, for example to skip unavailable videos in a playlist', default=False)\n    general.add_option('--abort-on-error',\n            action='store_false', dest='ignoreerrors',\n            help='Abort downloading of further videos (in the playlist or the command line) if an error occurs')\n    general.add_option('--dump-user-agent',\n            action='store_true', dest='dump_user_agent',\n            help='display the current browser identification', default=False)\n    general.add_option('--user-agent',\n            dest='user_agent', help='specify a custom user agent', metavar='UA')\n    general.add_option('--referer',\n            dest='referer', help='specify a custom referer, use if the video access is restricted to one domain',\n            metavar='REF', default=None)\n    general.add_option('--list-extractors',\n            action='store_true', dest='list_extractors',\n            help='List all supported extractors and the URLs they would handle', default=False)\n    general.add_option('--extractor-descriptions',\n            action='store_true', dest='list_extractor_descriptions',\n            help='Output descriptions of all supported extractors', default=False)\n    general.add_option(\n        '--proxy', dest='proxy', default=None, metavar='URL',\n        help='Use the specified HTTP/HTTPS proxy. Pass in an empty string (--proxy \"\") for direct connection')\n    general.add_option('--no-check-certificate', action='store_true', dest='no_check_certificate', default=False, help='Suppress HTTPS certificate validation.')\n    general.add_option(\n        '--cache-dir', dest='cachedir', default=get_cachedir(), metavar='DIR',\n        help='Location in the filesystem where youtube-dl can store some downloaded information permanently. By default $XDG_CACHE_HOME/youtube-dl or ~/.cache/youtube-dl . At the moment, only YouTube player files (for videos with obfuscated signatures) are cached, but that may change.')\n    general.add_option(\n        '--no-cache-dir', action='store_const', const=None, dest='cachedir',\n        help='Disable filesystem caching')\n    general.add_option(\n        '--socket-timeout', dest='socket_timeout',\n        type=float, default=None, help=u'Time to wait before giving up, in seconds')\n    general.add_option(\n        '--bidi-workaround', dest='bidi_workaround', action='store_true',\n        help=u'Work around terminals that lack bidirectional text support. Requires bidiv or fribidi executable in PATH')\n    general.add_option('--default-search',\n            dest='default_search', metavar='PREFIX',\n            help='Use this prefix for unqualified URLs. For example \"gvsearch2:\" downloads two videos from google videos for  youtube-dl \"large apple\". By default (with value \"auto\") youtube-dl guesses.')\n    general.add_option(\n        '--ignore-config',\n        action='store_true',\n        help='Do not read configuration files. When given in the global configuration file /etc/youtube-dl.conf: do not read the user configuration in ~/.config/youtube-dl.conf (%APPDATA%/youtube-dl/config.txt on Windows)')\n\n\n    selection.add_option(\n        '--playlist-start',\n        dest='playliststart', metavar='NUMBER', default=1, type=int,\n        help='playlist video to start at (default is %default)')\n    selection.add_option(\n        '--playlist-end',\n        dest='playlistend', metavar='NUMBER', default=None, type=int,\n        help='playlist video to end at (default is last)')\n    selection.add_option('--match-title', dest='matchtitle', metavar='REGEX',help='download only matching titles (regex or caseless sub-string)')\n    selection.add_option('--reject-title', dest='rejecttitle', metavar='REGEX',help='skip download for matching titles (regex or caseless sub-string)')\n    selection.add_option('--max-downloads', metavar='NUMBER',\n                         dest='max_downloads', type=int, default=None,\n                         help='Abort after downloading NUMBER files')\n    selection.add_option('--min-filesize', metavar='SIZE', dest='min_filesize', help=\"Do not download any videos smaller than SIZE (e.g. 50k or 44.6m)\", default=None)\n    selection.add_option('--max-filesize', metavar='SIZE', dest='max_filesize', help=\"Do not download any videos larger than SIZE (e.g. 50k or 44.6m)\", default=None)\n    selection.add_option('--date', metavar='DATE', dest='date', help='download only videos uploaded in this date', default=None)\n    selection.add_option(\n        '--datebefore', metavar='DATE', dest='datebefore', default=None,\n        help='download only videos uploaded on or before this date (i.e. inclusive)')\n    selection.add_option(\n        '--dateafter', metavar='DATE', dest='dateafter', default=None,\n        help='download only videos uploaded on or after this date (i.e. inclusive)')\n    selection.add_option(\n        '--min-views', metavar='COUNT', dest='min_views',\n        default=None, type=int,\n        help=\"Do not download any videos with less than COUNT views\",)\n    selection.add_option(\n        '--max-views', metavar='COUNT', dest='max_views',\n        default=None, type=int,\n        help=\"Do not download any videos with more than COUNT views\",)\n    selection.add_option('--no-playlist', action='store_true', dest='noplaylist', help='download only the currently playing video', default=False)\n    selection.add_option('--age-limit', metavar='YEARS', dest='age_limit',\n                         help='download only videos suitable for the given age',\n                         default=None, type=int)\n    selection.add_option('--download-archive', metavar='FILE',\n                         dest='download_archive',\n                         help='Download only videos not listed in the archive file. Record the IDs of all downloaded videos in it.')\n    selection.add_option(\n        '--include-ads', dest='include_ads',\n        action='store_true',\n        help='Download advertisements as well (experimental)')\n    selection.add_option(\n        '--youtube-include-dash-manifest', action='store_true',\n        dest='youtube_include_dash_manifest', default=False,\n        help='Try to download the DASH manifest on YouTube videos (experimental)')\n\n    authentication.add_option('-u', '--username',\n            dest='username', metavar='USERNAME', help='account username')\n    authentication.add_option('-p', '--password',\n            dest='password', metavar='PASSWORD', help='account password')\n    authentication.add_option('-n', '--netrc',\n            action='store_true', dest='usenetrc', help='use .netrc authentication data', default=False)\n    authentication.add_option('--video-password',\n            dest='videopassword', metavar='PASSWORD', help='video password (vimeo, smotri)')\n\n\n    video_format.add_option('-f', '--format',\n            action='store', dest='format', metavar='FORMAT', default=None,\n            help='video format code, specify the order of preference using slashes: \"-f 22/17/18\". \"-f mp4\" and \"-f flv\" are also supported. You can also use the special names \"best\", \"bestaudio\", \"worst\", and \"worstaudio\". By default, youtube-dl will pick the best quality.')\n    video_format.add_option('--all-formats',\n            action='store_const', dest='format', help='download all available video formats', const='all')\n    video_format.add_option('--prefer-free-formats',\n            action='store_true', dest='prefer_free_formats', default=False, help='prefer free video formats unless a specific one is requested')\n    video_format.add_option('--max-quality',\n            action='store', dest='format_limit', metavar='FORMAT', help='highest quality format to download')\n    video_format.add_option('-F', '--list-formats',\n            action='store_true', dest='listformats', help='list all available formats')\n\n    subtitles.add_option('--write-sub', '--write-srt',\n            action='store_true', dest='writesubtitles',\n            help='write subtitle file', default=False)\n    subtitles.add_option('--write-auto-sub', '--write-automatic-sub',\n            action='store_true', dest='writeautomaticsub',\n            help='write automatic subtitle file (youtube only)', default=False)\n    subtitles.add_option('--all-subs',\n            action='store_true', dest='allsubtitles',\n            help='downloads all the available subtitles of the video', default=False)\n    subtitles.add_option('--list-subs',\n            action='store_true', dest='listsubtitles',\n            help='lists all available subtitles for the video', default=False)\n    subtitles.add_option('--sub-format',\n            action='store', dest='subtitlesformat', metavar='FORMAT',\n            help='subtitle format (default=srt) ([sbv/vtt] youtube only)', default='srt')\n    subtitles.add_option('--sub-lang', '--sub-langs', '--srt-lang',\n            action='callback', dest='subtitleslangs', metavar='LANGS', type='str',\n            default=[], callback=_comma_separated_values_options_callback,\n            help='languages of the subtitles to download (optional) separated by commas, use IETF language tags like \\'en,pt\\'')\n\n    downloader.add_option('-r', '--rate-limit',\n            dest='ratelimit', metavar='LIMIT', help='maximum download rate in bytes per second (e.g. 50K or 4.2M)')\n    downloader.add_option('-R', '--retries',\n            dest='retries', metavar='RETRIES', help='number of retries (default is %default)', default=10)\n    downloader.add_option('--buffer-size',\n            dest='buffersize', metavar='SIZE', help='size of download buffer (e.g. 1024 or 16K) (default is %default)', default=\"1024\")\n    downloader.add_option('--no-resize-buffer',\n            action='store_true', dest='noresizebuffer',\n            help='do not automatically adjust the buffer size. By default, the buffer size is automatically resized from an initial value of SIZE.', default=False)\n    downloader.add_option('--test', action='store_true', dest='test', default=False, help=optparse.SUPPRESS_HELP)\n\n    verbosity.add_option('-q', '--quiet',\n            action='store_true', dest='quiet', help='activates quiet mode', default=False)\n    verbosity.add_option('-s', '--simulate',\n            action='store_true', dest='simulate', help='do not download the video and do not write anything to disk', default=False)\n    verbosity.add_option('--skip-download',\n            action='store_true', dest='skip_download', help='do not download the video', default=False)\n    verbosity.add_option('-g', '--get-url',\n            action='store_true', dest='geturl', help='simulate, quiet but print URL', default=False)\n    verbosity.add_option('-e', '--get-title',\n            action='store_true', dest='gettitle', help='simulate, quiet but print title', default=False)\n    verbosity.add_option('--get-id',\n            action='store_true', dest='getid', help='simulate, quiet but print id', default=False)\n    verbosity.add_option('--get-thumbnail',\n            action='store_true', dest='getthumbnail',\n            help='simulate, quiet but print thumbnail URL', default=False)\n    verbosity.add_option('--get-description',\n            action='store_true', dest='getdescription',\n            help='simulate, quiet but print video description', default=False)\n    verbosity.add_option('--get-duration',\n            action='store_true', dest='getduration',\n            help='simulate, quiet but print video length', default=False)\n    verbosity.add_option('--get-filename',\n            action='store_true', dest='getfilename',\n            help='simulate, quiet but print output filename', default=False)\n    verbosity.add_option('--get-format',\n            action='store_true', dest='getformat',\n            help='simulate, quiet but print output format', default=False)\n    verbosity.add_option('-j', '--dump-json',\n            action='store_true', dest='dumpjson',\n            help='simulate, quiet but print JSON information', default=False)\n    verbosity.add_option('--newline',\n            action='store_true', dest='progress_with_newline', help='output progress bar as new lines', default=False)\n    verbosity.add_option('--no-progress',\n            action='store_true', dest='noprogress', help='do not print progress bar', default=False)\n    verbosity.add_option('--console-title',\n            action='store_true', dest='consoletitle',\n            help='display progress in console titlebar', default=False)\n    verbosity.add_option('-v', '--verbose',\n            action='store_true', dest='verbose', help='print various debugging information', default=False)\n    verbosity.add_option('--dump-intermediate-pages',\n            action='store_true', dest='dump_intermediate_pages', default=False,\n            help='print downloaded pages to debug problems (very verbose)')\n    verbosity.add_option('--write-pages',\n            action='store_true', dest='write_pages', default=False,\n            help='Write downloaded intermediary pages to files in the current directory to debug problems')\n    verbosity.add_option('--youtube-print-sig-code',\n            action='store_true', dest='youtube_print_sig_code', default=False,\n            help=optparse.SUPPRESS_HELP)\n    verbosity.add_option('--print-traffic',\n            dest='debug_printtraffic', action='store_true', default=False,\n            help='Display sent and read HTTP traffic')\n\n\n    filesystem.add_option('-t', '--title',\n            action='store_true', dest='usetitle', help='use title in file name (default)', default=False)\n    filesystem.add_option('--id',\n            action='store_true', dest='useid', help='use only video ID in file name', default=False)\n    filesystem.add_option('-l', '--literal',\n            action='store_true', dest='usetitle', help='[deprecated] alias of --title', default=False)\n    filesystem.add_option('-A', '--auto-number',\n            action='store_true', dest='autonumber',\n            help='number downloaded files starting from 00000', default=False)\n    filesystem.add_option('-o', '--output',\n            dest='outtmpl', metavar='TEMPLATE',\n            help=('output filename template. Use %(title)s to get the title, '\n                  '%(uploader)s for the uploader name, %(uploader_id)s for the uploader nickname if different, '\n                  '%(autonumber)s to get an automatically incremented number, '\n                  '%(ext)s for the filename extension, '\n                  '%(format)s for the format description (like \"22 - 1280x720\" or \"HD\"), '\n                  '%(format_id)s for the unique id of the format (like Youtube\\'s itags: \"137\"), '\n                  '%(upload_date)s for the upload date (YYYYMMDD), '\n                  '%(extractor)s for the provider (youtube, metacafe, etc), '\n                  '%(id)s for the video id, %(playlist)s for the playlist the video is in, '\n                  '%(playlist_index)s for the position in the playlist and %% for a literal percent. '\n                  '%(height)s and %(width)s for the width and height of the video format. '\n                  '%(resolution)s for a textual description of the resolution of the video format. '\n                  'Use - to output to stdout. Can also be used to download to a different directory, '\n                  'for example with -o \\'/my/downloads/%(uploader)s/%(title)s-%(id)s.%(ext)s\\' .'))\n    filesystem.add_option('--autonumber-size',\n            dest='autonumber_size', metavar='NUMBER',\n            help='Specifies the number of digits in %(autonumber)s when it is present in output filename template or --auto-number option is given')\n    filesystem.add_option('--restrict-filenames',\n            action='store_true', dest='restrictfilenames',\n            help='Restrict filenames to only ASCII characters, and avoid \"&\" and spaces in filenames', default=False)\n    filesystem.add_option('-a', '--batch-file',\n            dest='batchfile', metavar='FILE', help='file containing URLs to download (\\'-\\' for stdin)')\n    filesystem.add_option('--load-info',\n            dest='load_info_filename', metavar='FILE',\n            help='json file containing the video information (created with the \"--write-json\" option)')\n    filesystem.add_option('-w', '--no-overwrites',\n            action='store_true', dest='nooverwrites', help='do not overwrite files', default=False)\n    filesystem.add_option('-c', '--continue',\n            action='store_true', dest='continue_dl', help='force resume of partially downloaded files. By default, youtube-dl will resume downloads if possible.', default=True)\n    filesystem.add_option('--no-continue',\n            action='store_false', dest='continue_dl',\n            help='do not resume partially downloaded files (restart from beginning)')\n    filesystem.add_option('--cookies',\n            dest='cookiefile', metavar='FILE', help='file to read cookies from and dump cookie jar in')\n    filesystem.add_option('--no-part',\n            action='store_true', dest='nopart', help='do not use .part files', default=False)\n    filesystem.add_option('--no-mtime',\n            action='store_false', dest='updatetime',\n            help='do not use the Last-modified header to set the file modification time', default=True)\n    filesystem.add_option('--write-description',\n            action='store_true', dest='writedescription',\n            help='write video description to a .description file', default=False)\n    filesystem.add_option('--write-info-json',\n            action='store_true', dest='writeinfojson',\n            help='write video metadata to a .info.json file', default=False)\n    filesystem.add_option('--write-annotations',\n            action='store_true', dest='writeannotations',\n            help='write video annotations to a .annotation file', default=False)\n    filesystem.add_option('--write-thumbnail',\n            action='store_true', dest='writethumbnail',\n            help='write thumbnail image to disk', default=False)\n\n\n    postproc.add_option('-x', '--extract-audio', action='store_true', dest='extractaudio', default=False,\n            help='convert video files to audio-only files (requires ffmpeg or avconv and ffprobe or avprobe)')\n    postproc.add_option('--audio-format', metavar='FORMAT', dest='audioformat', default='best',\n            help='\"best\", \"aac\", \"vorbis\", \"mp3\", \"m4a\", \"opus\", or \"wav\"; best by default')\n    postproc.add_option('--audio-quality', metavar='QUALITY', dest='audioquality', default='5',\n            help='ffmpeg/avconv audio quality specification, insert a value between 0 (better) and 9 (worse) for VBR or a specific bitrate like 128K (default 5)')\n    postproc.add_option('--recode-video', metavar='FORMAT', dest='recodevideo', default=None,\n            help='Encode the video to another format if necessary (currently supported: mp4|flv|ogg|webm)')\n    postproc.add_option('-k', '--keep-video', action='store_true', dest='keepvideo', default=False,\n            help='keeps the video file on disk after the post-processing; the video is erased by default')\n    postproc.add_option('--no-post-overwrites', action='store_true', dest='nopostoverwrites', default=False,\n            help='do not overwrite post-processed files; the post-processed files are overwritten by default')\n    postproc.add_option('--embed-subs', action='store_true', dest='embedsubtitles', default=False,\n            help='embed subtitles in the video (only for mp4 videos)')\n    postproc.add_option('--add-metadata', action='store_true', dest='addmetadata', default=False,\n            help='write metadata to the video file')\n    postproc.add_option('--xattrs', action='store_true', dest='xattrs', default=False,\n            help='write metadata to the video file\\'s xattrs (using dublin core and xdg standards)')\n    postproc.add_option('--prefer-avconv', action='store_false', dest='prefer_ffmpeg',\n        help='Prefer avconv over ffmpeg for running the postprocessors (default)')\n    postproc.add_option('--prefer-ffmpeg', action='store_true', dest='prefer_ffmpeg',\n        help='Prefer ffmpeg over avconv for running the postprocessors')\n\n\n    parser.add_option_group(general)\n    parser.add_option_group(selection)\n    parser.add_option_group(downloader)\n    parser.add_option_group(filesystem)\n    parser.add_option_group(verbosity)\n    parser.add_option_group(video_format)\n    parser.add_option_group(subtitles)\n    parser.add_option_group(authentication)\n    parser.add_option_group(postproc)\n\n    if overrideArguments is not None:\n        opts, args = parser.parse_args(overrideArguments)\n        if opts.verbose:\n            write_string(u'[debug] Override config: ' + repr(overrideArguments) + '\\n')\n    else:\n        commandLineConf = sys.argv[1:]\n        if '--ignore-config' in commandLineConf:\n            systemConf = []\n            userConf = []\n        else:\n            systemConf = _readOptions('/etc/youtube-dl.conf')\n            if '--ignore-config' in systemConf:\n                userConf = []\n            else:\n                userConf = _readUserConf()\n        argv = systemConf + userConf + commandLineConf\n\n        opts, args = parser.parse_args(argv)\n        if opts.verbose:\n            write_string(u'[debug] System config: ' + repr(_hide_login_info(systemConf)) + '\\n')\n            write_string(u'[debug] User config: ' + repr(_hide_login_info(userConf)) + '\\n')\n            write_string(u'[debug] Command-line args: ' + repr(_hide_login_info(commandLineConf)) + '\\n')\n            write_string(u'[debug] Encodings: locale %r, fs %r, out %r, pref: %r\\n' %\n                         (locale.getpreferredencoding(), sys.getfilesystemencoding(), sys.stdout.encoding, preferredencoding()))\n\n    return parser, opts, args",
        "begin_line": 100,
        "end_line": 535,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.002369668246445498,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.__init__._readOptions#101",
        "src_path": "youtube_dl/__init__.py",
        "class_name": "youtube_dl.__init__",
        "signature": "youtube_dl.__init__._readOptions(filename_bytes, default=[])",
        "snippet": "    def _readOptions(filename_bytes, default=[]):\n        try:\n            optionf = open(filename_bytes)\n        except IOError:\n            return default  # silently skip if file is not present\n        try:\n            res = []\n            for l in optionf:\n                res += shlex.split(l, comments=True)\n        finally:\n            optionf.close()\n        return res",
        "begin_line": 101,
        "end_line": 112,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.002369668246445498,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.__init__._readUserConf#114",
        "src_path": "youtube_dl/__init__.py",
        "class_name": "youtube_dl.__init__",
        "signature": "youtube_dl.__init__._readUserConf()",
        "snippet": "    def _readUserConf():\n        xdg_config_home = os.environ.get('XDG_CONFIG_HOME')\n        if xdg_config_home:\n            userConfFile = os.path.join(xdg_config_home, 'youtube-dl', 'config')\n            if not os.path.isfile(userConfFile):\n                userConfFile = os.path.join(xdg_config_home, 'youtube-dl.conf')\n        else:\n            userConfFile = os.path.join(os.path.expanduser('~'), '.config', 'youtube-dl', 'config')\n            if not os.path.isfile(userConfFile):\n                userConfFile = os.path.join(os.path.expanduser('~'), '.config', 'youtube-dl.conf')\n        userConf = _readOptions(userConfFile, None)\n\n        if userConf is None:\n            appdata_dir = os.environ.get('appdata')\n            if appdata_dir:\n                userConf = _readOptions(\n                    os.path.join(appdata_dir, 'youtube-dl', 'config'),\n                    default=None)\n                if userConf is None:\n                    userConf = _readOptions(\n                        os.path.join(appdata_dir, 'youtube-dl', 'config.txt'),\n                        default=None)\n\n        if userConf is None:\n            userConf = _readOptions(\n                os.path.join(os.path.expanduser('~'), 'youtube-dl.conf'),\n                default=None)\n        if userConf is None:\n            userConf = _readOptions(\n                os.path.join(os.path.expanduser('~'), 'youtube-dl.conf.txt'),\n                default=None)\n\n        if userConf is None:\n            userConf = []\n\n        return userConf",
        "begin_line": 114,
        "end_line": 149,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.002369668246445498,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.__init__._format_option_string#151",
        "src_path": "youtube_dl/__init__.py",
        "class_name": "youtube_dl.__init__",
        "signature": "youtube_dl.__init__._format_option_string(option)",
        "snippet": "    def _format_option_string(option):\n        ''' ('-o', '--option') -> -o, --format METAVAR'''\n\n        opts = []\n\n        if option._short_opts:\n            opts.append(option._short_opts[0])\n        if option._long_opts:\n            opts.append(option._long_opts[0])\n        if len(opts) > 1:\n            opts.insert(1, ', ')\n\n        if option.takes_value(): opts.append(' %s' % option.metavar)\n\n        return \"\".join(opts)",
        "begin_line": 151,
        "end_line": 165,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.002369668246445498,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.__init__._comma_separated_values_options_callback#167",
        "src_path": "youtube_dl/__init__.py",
        "class_name": "youtube_dl.__init__",
        "signature": "youtube_dl.__init__._comma_separated_values_options_callback(option, opt_str, value, parser)",
        "snippet": "    def _comma_separated_values_options_callback(option, opt_str, value, parser):\n        setattr(parser.values, option.dest, value.split(','))",
        "begin_line": 167,
        "end_line": 168,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.002369668246445498,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.__init__._hide_login_info#170",
        "src_path": "youtube_dl/__init__.py",
        "class_name": "youtube_dl.__init__",
        "signature": "youtube_dl.__init__._hide_login_info(opts)",
        "snippet": "    def _hide_login_info(opts):\n        opts = list(opts)\n        for private_opt in ['-p', '--password', '-u', '--username', '--video-password']:\n            try:\n                i = opts.index(private_opt)\n                opts[i+1] = '<PRIVATE>'\n            except ValueError:\n                pass\n        return opts",
        "begin_line": 170,
        "end_line": 178,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.002369668246445498,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.__init__._real_main#538",
        "src_path": "youtube_dl/__init__.py",
        "class_name": "youtube_dl.__init__",
        "signature": "youtube_dl.__init__._real_main(argv=None)",
        "snippet": "def _real_main(argv=None):\n    # Compatibility fixes for Windows\n    if sys.platform == 'win32':\n        # https://github.com/rg3/youtube-dl/issues/820\n        codecs.register(lambda name: codecs.lookup('utf-8') if name == 'cp65001' else None)\n\n    setproctitle(u'youtube-dl')\n\n    parser, opts, args = parseOpts(argv)\n\n    # Set user agent\n    if opts.user_agent is not None:\n        std_headers['User-Agent'] = opts.user_agent\n\n    # Set referer\n    if opts.referer is not None:\n        std_headers['Referer'] = opts.referer\n\n    # Dump user agent\n    if opts.dump_user_agent:\n        compat_print(std_headers['User-Agent'])\n        sys.exit(0)\n\n    # Batch file verification\n    batch_urls = []\n    if opts.batchfile is not None:\n        try:\n            if opts.batchfile == '-':\n                batchfd = sys.stdin\n            else:\n                batchfd = io.open(opts.batchfile, 'r', encoding='utf-8', errors='ignore')\n            batch_urls = read_batch_urls(batchfd)\n            if opts.verbose:\n                write_string(u'[debug] Batch file urls: ' + repr(batch_urls) + u'\\n')\n        except IOError:\n            sys.exit(u'ERROR: batch file could not be read')\n    all_urls = batch_urls + args\n    all_urls = [url.strip() for url in all_urls]\n    _enc = preferredencoding()\n    all_urls = [url.decode(_enc, 'ignore') if isinstance(url, bytes) else url for url in all_urls]\n\n    extractors = gen_extractors()\n\n    if opts.list_extractors:\n        for ie in sorted(extractors, key=lambda ie: ie.IE_NAME.lower()):\n            compat_print(ie.IE_NAME + (' (CURRENTLY BROKEN)' if not ie._WORKING else ''))\n            matchedUrls = [url for url in all_urls if ie.suitable(url)]\n            for mu in matchedUrls:\n                compat_print(u'  ' + mu)\n        sys.exit(0)\n    if opts.list_extractor_descriptions:\n        for ie in sorted(extractors, key=lambda ie: ie.IE_NAME.lower()):\n            if not ie._WORKING:\n                continue\n            desc = getattr(ie, 'IE_DESC', ie.IE_NAME)\n            if desc is False:\n                continue\n            if hasattr(ie, 'SEARCH_KEY'):\n                _SEARCHES = (u'cute kittens', u'slithering pythons', u'falling cat', u'angry poodle', u'purple fish', u'running tortoise')\n                _COUNTS = (u'', u'5', u'10', u'all')\n                desc += u' (Example: \"%s%s:%s\" )' % (ie.SEARCH_KEY, random.choice(_COUNTS), random.choice(_SEARCHES))\n            compat_print(desc)\n        sys.exit(0)\n\n\n    # Conflicting, missing and erroneous options\n    if opts.usenetrc and (opts.username is not None or opts.password is not None):\n        parser.error(u'using .netrc conflicts with giving username/password')\n    if opts.password is not None and opts.username is None:\n        parser.error(u'account username missing\\n')\n    if opts.outtmpl is not None and (opts.usetitle or opts.autonumber or opts.useid):\n        parser.error(u'using output template conflicts with using title, video ID or auto number')\n    if opts.usetitle and opts.useid:\n        parser.error(u'using title conflicts with using video ID')\n    if opts.username is not None and opts.password is None:\n        opts.password = getpass.getpass(u'Type account password and press return:')\n    if opts.ratelimit is not None:\n        numeric_limit = FileDownloader.parse_bytes(opts.ratelimit)\n        if numeric_limit is None:\n            parser.error(u'invalid rate limit specified')\n        opts.ratelimit = numeric_limit\n    if opts.min_filesize is not None:\n        numeric_limit = FileDownloader.parse_bytes(opts.min_filesize)\n        if numeric_limit is None:\n            parser.error(u'invalid min_filesize specified')\n        opts.min_filesize = numeric_limit\n    if opts.max_filesize is not None:\n        numeric_limit = FileDownloader.parse_bytes(opts.max_filesize)\n        if numeric_limit is None:\n            parser.error(u'invalid max_filesize specified')\n        opts.max_filesize = numeric_limit\n    if opts.retries is not None:\n        try:\n            opts.retries = int(opts.retries)\n        except (TypeError, ValueError):\n            parser.error(u'invalid retry count specified')\n    if opts.buffersize is not None:\n        numeric_buffersize = FileDownloader.parse_bytes(opts.buffersize)\n        if numeric_buffersize is None:\n            parser.error(u'invalid buffer size specified')\n        opts.buffersize = numeric_buffersize\n    if opts.playliststart <= 0:\n        raise ValueError(u'Playlist start must be positive')\n    if opts.playlistend not in (-1, None) and opts.playlistend < opts.playliststart:\n        raise ValueError(u'Playlist end must be greater than playlist start')\n    if opts.extractaudio:\n        if opts.audioformat not in ['best', 'aac', 'mp3', 'm4a', 'opus', 'vorbis', 'wav']:\n            parser.error(u'invalid audio format specified')\n    if opts.audioquality:\n        opts.audioquality = opts.audioquality.strip('k').strip('K')\n        if not opts.audioquality.isdigit():\n            parser.error(u'invalid audio quality specified')\n    if opts.recodevideo is not None:\n        if opts.recodevideo not in ['mp4', 'flv', 'webm', 'ogg']:\n            parser.error(u'invalid video recode format specified')\n    if opts.date is not None:\n        date = DateRange.day(opts.date)\n    else:\n        date = DateRange(opts.dateafter, opts.datebefore)\n    if opts.default_search not in ('auto', None) and ':' not in opts.default_search:\n        parser.error(u'--default-search invalid; did you forget a colon (:) at the end?')\n\n    # Do not download videos when there are audio-only formats\n    if opts.extractaudio and not opts.keepvideo and opts.format is None:\n        opts.format = 'bestaudio/best'\n\n    # --all-sub automatically sets --write-sub if --write-auto-sub is not given\n    # this was the old behaviour if only --all-sub was given.\n    if opts.allsubtitles and (opts.writeautomaticsub == False):\n        opts.writesubtitles = True\n\n    if sys.version_info < (3,):\n        # In Python 2, sys.argv is a bytestring (also note http://bugs.python.org/issue2128 for Windows systems)\n        if opts.outtmpl is not None:\n            opts.outtmpl = opts.outtmpl.decode(preferredencoding())\n    outtmpl =((opts.outtmpl is not None and opts.outtmpl)\n            or (opts.format == '-1' and opts.usetitle and u'%(title)s-%(id)s-%(format)s.%(ext)s')\n            or (opts.format == '-1' and u'%(id)s-%(format)s.%(ext)s')\n            or (opts.usetitle and opts.autonumber and u'%(autonumber)s-%(title)s-%(id)s.%(ext)s')\n            or (opts.usetitle and u'%(title)s-%(id)s.%(ext)s')\n            or (opts.useid and u'%(id)s.%(ext)s')\n            or (opts.autonumber and u'%(autonumber)s-%(id)s.%(ext)s')\n            or u'%(title)s-%(id)s.%(ext)s')\n    if not os.path.splitext(outtmpl)[1] and opts.extractaudio:\n        parser.error(u'Cannot download a video and extract audio into the same'\n                     u' file! Use \"{0}.%(ext)s\" instead of \"{0}\" as the output'\n                     u' template'.format(outtmpl))\n\n    any_printing = opts.geturl or opts.gettitle or opts.getid or opts.getthumbnail or opts.getdescription or opts.getfilename or opts.getformat or opts.getduration or opts.dumpjson\n    download_archive_fn = os.path.expanduser(opts.download_archive) if opts.download_archive is not None else opts.download_archive\n\n    ydl_opts = {\n        'usenetrc': opts.usenetrc,\n        'username': opts.username,\n        'password': opts.password,\n        'videopassword': opts.videopassword,\n        'quiet': (opts.quiet or any_printing),\n        'forceurl': opts.geturl,\n        'forcetitle': opts.gettitle,\n        'forceid': opts.getid,\n        'forcethumbnail': opts.getthumbnail,\n        'forcedescription': opts.getdescription,\n        'forceduration': opts.getduration,\n        'forcefilename': opts.getfilename,\n        'forceformat': opts.getformat,\n        'forcejson': opts.dumpjson,\n        'simulate': opts.simulate,\n        'skip_download': (opts.skip_download or opts.simulate or any_printing),\n        'format': opts.format,\n        'format_limit': opts.format_limit,\n        'listformats': opts.listformats,\n        'outtmpl': outtmpl,\n        'autonumber_size': opts.autonumber_size,\n        'restrictfilenames': opts.restrictfilenames,\n        'ignoreerrors': opts.ignoreerrors,\n        'ratelimit': opts.ratelimit,\n        'nooverwrites': opts.nooverwrites,\n        'retries': opts.retries,\n        'buffersize': opts.buffersize,\n        'noresizebuffer': opts.noresizebuffer,\n        'continuedl': opts.continue_dl,\n        'noprogress': opts.noprogress,\n        'progress_with_newline': opts.progress_with_newline,\n        'playliststart': opts.playliststart,\n        'playlistend': opts.playlistend,\n        'noplaylist': opts.noplaylist,\n        'logtostderr': opts.outtmpl == '-',\n        'consoletitle': opts.consoletitle,\n        'nopart': opts.nopart,\n        'updatetime': opts.updatetime,\n        'writedescription': opts.writedescription,\n        'writeannotations': opts.writeannotations,\n        'writeinfojson': opts.writeinfojson,\n        'writethumbnail': opts.writethumbnail,\n        'writesubtitles': opts.writesubtitles,\n        'writeautomaticsub': opts.writeautomaticsub,\n        'allsubtitles': opts.allsubtitles,\n        'listsubtitles': opts.listsubtitles,\n        'subtitlesformat': opts.subtitlesformat,\n        'subtitleslangs': opts.subtitleslangs,\n        'matchtitle': decodeOption(opts.matchtitle),\n        'rejecttitle': decodeOption(opts.rejecttitle),\n        'max_downloads': opts.max_downloads,\n        'prefer_free_formats': opts.prefer_free_formats,\n        'verbose': opts.verbose,\n        'dump_intermediate_pages': opts.dump_intermediate_pages,\n        'write_pages': opts.write_pages,\n        'test': opts.test,\n        'keepvideo': opts.keepvideo,\n        'min_filesize': opts.min_filesize,\n        'max_filesize': opts.max_filesize,\n        'min_views': opts.min_views,\n        'max_views': opts.max_views,\n        'daterange': date,\n        'cachedir': opts.cachedir,\n        'youtube_print_sig_code': opts.youtube_print_sig_code,\n        'age_limit': opts.age_limit,\n        'download_archive': download_archive_fn,\n        'cookiefile': opts.cookiefile,\n        'nocheckcertificate': opts.no_check_certificate,\n        'proxy': opts.proxy,\n        'socket_timeout': opts.socket_timeout,\n        'bidi_workaround': opts.bidi_workaround,\n        'debug_printtraffic': opts.debug_printtraffic,\n        'prefer_ffmpeg': opts.prefer_ffmpeg,\n        'include_ads': opts.include_ads,\n        'default_search': opts.default_search,\n        'youtube_include_dash_manifest': opts.youtube_include_dash_manifest,\n    }\n\n    with YoutubeDL(ydl_opts) as ydl:\n        ydl.print_debug_header()\n        ydl.add_default_info_extractors()\n\n        # PostProcessors\n        # Add the metadata pp first, the other pps will copy it\n        if opts.addmetadata:\n            ydl.add_post_processor(FFmpegMetadataPP())\n        if opts.extractaudio:\n            ydl.add_post_processor(FFmpegExtractAudioPP(preferredcodec=opts.audioformat, preferredquality=opts.audioquality, nopostoverwrites=opts.nopostoverwrites))\n        if opts.recodevideo:\n            ydl.add_post_processor(FFmpegVideoConvertor(preferedformat=opts.recodevideo))\n        if opts.embedsubtitles:\n            ydl.add_post_processor(FFmpegEmbedSubtitlePP(subtitlesformat=opts.subtitlesformat))\n        if opts.xattrs:\n            ydl.add_post_processor(XAttrMetadataPP())\n\n        # Update version\n        if opts.update_self:\n            update_self(ydl.to_screen, opts.verbose)\n\n        # Maybe do nothing\n        if (len(all_urls) < 1) and (opts.load_info_filename is None):\n            if not opts.update_self:\n                parser.error(u'you must provide at least one URL')\n            else:\n                sys.exit()\n\n        try:\n            if opts.load_info_filename is not None:\n                retcode = ydl.download_with_info_file(opts.load_info_filename)\n            else:\n                retcode = ydl.download(all_urls)\n        except MaxDownloadsReached:\n            ydl.to_screen(u'--max-download limit reached, aborting.')\n            retcode = 101\n\n    sys.exit(retcode)",
        "begin_line": 538,
        "end_line": 805,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.002369668246445498,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.__init__.main#808",
        "src_path": "youtube_dl/__init__.py",
        "class_name": "youtube_dl.__init__",
        "signature": "youtube_dl.__init__.main(argv=None)",
        "snippet": "def main(argv=None):\n    try:\n        _real_main(argv)\n    except DownloadError:\n        sys.exit(1)\n    except SameFileError:\n        sys.exit(u'ERROR: fixed output name but more than one file to download')\n    except KeyboardInterrupt:\n        sys.exit(u'\\nERROR: Interrupted by user')",
        "begin_line": 808,
        "end_line": 816,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.002369668246445498,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.rtlnow.RTLnowIE._real_extract#108",
        "src_path": "youtube_dl/extractor/rtlnow.py",
        "class_name": "youtube_dl.extractor.rtlnow.RTLnowIE",
        "signature": "youtube_dl.extractor.rtlnow.RTLnowIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_page_url = 'http://%s/' % mobj.group('domain')\n        video_id = mobj.group('video_id')\n\n        webpage = self._download_webpage('http://' + mobj.group('url'), video_id)\n\n        mobj = re.search(r'(?s)<div style=\"margin-left: 20px; font-size: 13px;\">(.*?)<div id=\"playerteaser\">', webpage)\n        if mobj:\n            raise ExtractorError(clean_html(mobj.group(1)), expected=True)\n\n        title = self._og_search_title(webpage)\n        description = self._og_search_description(webpage)\n        thumbnail = self._og_search_thumbnail(webpage, default=None)\n\n        upload_date = unified_strdate(self._html_search_meta('uploadDate', webpage, 'upload date'))\n\n        mobj = re.search(r'<meta itemprop=\"duration\" content=\"PT(?P<seconds>\\d+)S\" />', webpage)\n        duration = int(mobj.group('seconds')) if mobj else None\n\n        playerdata_url = self._html_search_regex(\n            r\"'playerdata': '(?P<playerdata_url>[^']+)'\", webpage, 'playerdata_url')\n\n        playerdata = self._download_xml(playerdata_url, video_id, 'Downloading player data XML')\n\n        videoinfo = playerdata.find('./playlist/videoinfo')\n        \n        formats = []\n        for filename in videoinfo.findall('filename'):\n            mobj = re.search(r'(?P<url>rtmpe://(?:[^/]+/){2})(?P<play_path>.+)', filename.text)\n            if mobj:\n                fmt = {\n                    'url': mobj.group('url'),\n                    'play_path': 'mp4:' + mobj.group('play_path'),\n                    'page_url': video_page_url,\n                    'player_url': video_page_url + 'includes/vodplayer.swf',\n                }\n            else:\n                fmt = {\n                    'url': filename.text,\n                }\n            fmt.update({\n                'width': int_or_none(filename.get('width')),\n                'height': int_or_none(filename.get('height')),\n                'vbr': int_or_none(filename.get('bitrate')),\n                'ext': 'flv',\n            })\n            formats.append(fmt)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n            'duration': duration,\n            'formats': formats,\n        }",
        "begin_line": 108,
        "end_line": 165,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.jadorecettepub.JadoreCettePubIE._real_extract#25",
        "src_path": "youtube_dl/extractor/jadorecettepub.py",
        "class_name": "youtube_dl.extractor.jadorecettepub.JadoreCettePubIE",
        "signature": "youtube_dl.extractor.jadorecettepub.JadoreCettePubIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        display_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, display_id)\n\n        title = self._html_search_regex(\n            r'<span style=\"font-size: x-large;\"><b>(.*?)</b></span>',\n            webpage, 'title')\n        description = self._html_search_regex(\n            r'(?s)<div id=\"fb-root\">(.*?)<script>', webpage, 'description',\n            fatal=False)\n        real_url = self._search_regex(\n            r'\\[/postlink\\](.*)endofvid', webpage, 'video URL')\n        video_id = YoutubeIE.extract_id(real_url)\n\n        return {\n            '_type': 'url_transparent',\n            'url': real_url,\n            'id': video_id,\n            'title': title,\n            'description': description,\n        }",
        "begin_line": 25,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.smotri.SmotriIE._search_meta#96",
        "src_path": "youtube_dl/extractor/smotri.py",
        "class_name": "youtube_dl.extractor.smotri.SmotriIE",
        "signature": "youtube_dl.extractor.smotri.SmotriIE._search_meta(self, name, html, display_name=None)",
        "snippet": "    def _search_meta(self, name, html, display_name=None):\n        if display_name is None:\n            display_name = name\n        return self._html_search_regex(\n            r'<meta itemprop=\"%s\" content=\"([^\"]+)\" />' % re.escape(name),\n            html, display_name, fatal=False)\n        return self._html_search_meta(name, html, display_name)",
        "begin_line": 96,
        "end_line": 102,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.smotri.SmotriIE._real_extract#104",
        "src_path": "youtube_dl/extractor/smotri.py",
        "class_name": "youtube_dl.extractor.smotri.SmotriIE",
        "signature": "youtube_dl.extractor.smotri.SmotriIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n        real_video_id = mobj.group('realvideoid')\n\n        # Download video JSON data\n        video_json_url = 'http://smotri.com/vt.php?id=%s' % real_video_id\n        video_json_page = self._download_webpage(video_json_url, video_id, 'Downloading video JSON')\n        video_json = json.loads(video_json_page)\n\n        status = video_json['status']\n        if status == self._VIDEO_NOT_FOUND:\n            raise ExtractorError('Video %s does not exist' % video_id, expected=True)\n        elif status == self._PASSWORD_DETECTED: # The video is protected by a password, retry with\n                                                # video-password set\n            video_password = self._downloader.params.get('videopassword', None)\n            if not video_password:\n                raise ExtractorError('This video is protected by a password, use the --video-password option', expected=True)\n            video_json_url += '&md5pass=%s' % hashlib.md5(video_password.encode('utf-8')).hexdigest()\n            video_json_page = self._download_webpage(video_json_url, video_id, 'Downloading video JSON (video-password set)')\n            video_json = json.loads(video_json_page)\n            status = video_json['status']\n            if status == self._PASSWORD_NOT_VERIFIED:\n                raise ExtractorError('Video password is invalid', expected=True)\n\n        if status != self._SUCCESS:\n            raise ExtractorError('Unexpected status value %s' % status)\n\n        # Extract the URL of the video\n        video_url = video_json['file_data']\n\n        # Video JSON does not provide enough meta data\n        # We will extract some from the video web page instead\n        video_page_url = 'http://' + mobj.group('url')\n        video_page = self._download_webpage(video_page_url, video_id, 'Downloading video page')\n\n        # Warning if video is unavailable\n        warning = self._html_search_regex(\n            r'<div class=\"videoUnModer\">(.*?)</div>', video_page,\n            'warning message', default=None)\n        if warning is not None:\n            self._downloader.report_warning(\n                'Video %s may not be available; smotri said: %s ' %\n                (video_id, warning))\n\n        # Adult content\n        if re.search('EroConfirmText\">', video_page) is not None:\n            self.report_age_confirmation()\n            confirm_string = self._html_search_regex(\n                r'<a href=\"/video/view/\\?id=%s&confirm=([^\"]+)\" title=\"[^\"]+\">' % video_id,\n                video_page, 'confirm string')\n            confirm_url = video_page_url + '&confirm=%s' % confirm_string\n            video_page = self._download_webpage(confirm_url, video_id, 'Downloading video page (age confirmed)')\n            adult_content = True\n        else:\n            adult_content = False\n\n        # Extract the rest of meta data\n        video_title = self._search_meta('name', video_page, 'title')\n        if not video_title:\n            video_title = os.path.splitext(url_basename(video_url))[0]\n\n        video_description = self._search_meta('description', video_page)\n        END_TEXT = ' \u043d\u0430 \u0441\u0430\u0439\u0442\u0435 Smotri.com'\n        if video_description and video_description.endswith(END_TEXT):\n            video_description = video_description[:-len(END_TEXT)]\n        START_TEXT = '\u0421\u043c\u043e\u0442\u0440\u0435\u0442\u044c \u043e\u043d\u043b\u0430\u0439\u043d \u0440\u043e\u043b\u0438\u043a '\n        if video_description and video_description.startswith(START_TEXT):\n            video_description = video_description[len(START_TEXT):]\n        video_thumbnail = self._search_meta('thumbnail', video_page)\n\n        upload_date_str = self._search_meta('uploadDate', video_page, 'upload date')\n        if upload_date_str:\n            upload_date_m = re.search(r'(?P<year>\\d{4})\\.(?P<month>\\d{2})\\.(?P<day>\\d{2})T', upload_date_str)\n            video_upload_date = (\n                (\n                    upload_date_m.group('year') +\n                    upload_date_m.group('month') +\n                    upload_date_m.group('day')\n                )\n                if upload_date_m else None\n            )\n        else:\n            video_upload_date = None\n\n        duration_str = self._search_meta('duration', video_page)\n        if duration_str:\n            duration_m = re.search(r'T(?P<hours>[0-9]{2})H(?P<minutes>[0-9]{2})M(?P<seconds>[0-9]{2})S', duration_str)\n            video_duration = (\n                (\n                    (int(duration_m.group('hours')) * 60 * 60) +\n                    (int(duration_m.group('minutes')) * 60) +\n                    int(duration_m.group('seconds'))\n                )\n                if duration_m else None\n            )\n        else:\n            video_duration = None\n\n        video_uploader = self._html_search_regex(\n            '<div class=\"DescrUser\"><div>\u0410\u0432\u0442\u043e\u0440.*?onmouseover=\"popup_user_info[^\"]+\">(.*?)</a>',\n            video_page, 'uploader', fatal=False, flags=re.MULTILINE|re.DOTALL)\n\n        video_uploader_id = self._html_search_regex(\n            '<div class=\"DescrUser\"><div>\u0410\u0432\u0442\u043e\u0440.*?onmouseover=\"popup_user_info\\\\(.*?\\'([^\\']+)\\'\\\\);\">',\n            video_page, 'uploader id', fatal=False, flags=re.MULTILINE|re.DOTALL)\n\n        video_view_count = self._html_search_regex(\n            '\u041e\u0431\u0449\u0435\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0440\u043e\u0441\u043c\u043e\u0442\u0440\u043e\u0432.*?<span class=\"Number\">(\\\\d+)</span>',\n            video_page, 'view count', fatal=False, flags=re.MULTILINE|re.DOTALL)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': video_title,\n            'thumbnail': video_thumbnail,\n            'description': video_description,\n            'uploader': video_uploader,\n            'upload_date': video_upload_date,\n            'uploader_id': video_uploader_id,\n            'duration': video_duration,\n            'view_count': video_view_count,\n            'age_limit': 18 if adult_content else 0,\n            'video_page_url': video_page_url\n        }",
        "begin_line": 104,
        "end_line": 228,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.smotri.SmotriCommunityIE._real_extract#236",
        "src_path": "youtube_dl/extractor/smotri.py",
        "class_name": "youtube_dl.extractor.smotri.SmotriCommunityIE",
        "signature": "youtube_dl.extractor.smotri.SmotriCommunityIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        community_id = mobj.group('communityid')\n\n        url = 'http://smotri.com/export/rss/video/by/community/-/%s/video.xml' % community_id\n        rss = self._download_xml(url, community_id, 'Downloading community RSS')\n\n        entries = [self.url_result(video_url.text, 'Smotri')\n                   for video_url in rss.findall('./channel/item/link')]\n\n        description_text = rss.find('./channel/description').text\n        community_title = self._html_search_regex(\n            '^\u0412\u0438\u0434\u0435\u043e \u0441\u043e\u043e\u0431\u0449\u0435\u0441\u0442\u0432\u0430 \"([^\"]+)\"$', description_text, 'community title')\n\n        return self.playlist_result(entries, community_id, community_title)",
        "begin_line": 236,
        "end_line": 250,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.smotri.SmotriUserIE._real_extract#258",
        "src_path": "youtube_dl/extractor/smotri.py",
        "class_name": "youtube_dl.extractor.smotri.SmotriUserIE",
        "signature": "youtube_dl.extractor.smotri.SmotriUserIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        user_id = mobj.group('userid')\n\n        url = 'http://smotri.com/export/rss/user/video/-/%s/video.xml' % user_id\n        rss = self._download_xml(url, user_id, 'Downloading user RSS')\n\n        entries = [self.url_result(video_url.text, 'Smotri')\n                   for video_url in rss.findall('./channel/item/link')]\n\n        description_text = rss.find('./channel/description').text\n        user_nickname = self._html_search_regex(\n            '^\u0412\u0438\u0434\u0435\u043e \u0440\u0435\u0436\u0438\u0441\u0441\u0435\u0440\u0430 (.*)$', description_text,\n            'user nickname')\n\n        return self.playlist_result(entries, user_id, user_nickname)",
        "begin_line": 258,
        "end_line": 273,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.smotri.SmotriBroadcastIE._real_extract#281",
        "src_path": "youtube_dl/extractor/smotri.py",
        "class_name": "youtube_dl.extractor.smotri.SmotriBroadcastIE",
        "signature": "youtube_dl.extractor.smotri.SmotriBroadcastIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        broadcast_id = mobj.group('broadcastid')\n\n        broadcast_url = 'http://' + mobj.group('url')\n        broadcast_page = self._download_webpage(broadcast_url, broadcast_id, 'Downloading broadcast page')\n\n        if re.search('>\u0420\u0435\u0436\u0438\u0441\u0441\u0435\u0440 \u0441 \u043b\u043e\u0433\u0438\u043d\u043e\u043c <br/>\"%s\"<br/> <span>\u043d\u0435 \u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0443\u0435\u0442<' % broadcast_id, broadcast_page) is not None:\n            raise ExtractorError('Broadcast %s does not exist' % broadcast_id, expected=True)\n\n        # Adult content\n        if re.search('EroConfirmText\">', broadcast_page) is not None:\n\n            (username, password) = self._get_login_info()\n            if username is None:\n                raise ExtractorError('Erotic broadcasts allowed only for registered users, '\n                    'use --username and --password options to provide account credentials.', expected=True)\n\n            login_form = {\n                'login-hint53': '1',\n                'confirm_erotic': '1',\n                'login': username,\n                'password': password,\n            }\n\n            request = compat_urllib_request.Request(broadcast_url + '/?no_redirect=1', compat_urllib_parse.urlencode(login_form))\n            request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n            broadcast_page = self._download_webpage(request, broadcast_id, 'Logging in and confirming age')\n\n            if re.search('>\u041d\u0435\u0432\u0435\u0440\u043d\u044b\u0439 \u043b\u043e\u0433\u0438\u043d \u0438\u043b\u0438 \u043f\u0430\u0440\u043e\u043b\u044c<', broadcast_page) is not None:\n                raise ExtractorError('Unable to log in: bad username or password', expected=True)\n\n            adult_content = True\n        else:\n            adult_content = False\n\n        ticket = self._html_search_regex(\n            'window\\.broadcast_control\\.addFlashVar\\\\(\\'file\\', \\'([^\\']+)\\'\\\\);',\n            broadcast_page, 'broadcast ticket')\n\n        url = 'http://smotri.com/broadcast/view/url/?ticket=%s' % ticket\n\n        broadcast_password = self._downloader.params.get('videopassword', None)\n        if broadcast_password:\n            url += '&pass=%s' % hashlib.md5(broadcast_password.encode('utf-8')).hexdigest()\n\n        broadcast_json_page = self._download_webpage(url, broadcast_id, 'Downloading broadcast JSON')\n\n        try:\n            broadcast_json = json.loads(broadcast_json_page)\n\n            protected_broadcast = broadcast_json['_pass_protected'] == 1\n            if protected_broadcast and not broadcast_password:\n                raise ExtractorError('This broadcast is protected by a password, use the --video-password option', expected=True)\n\n            broadcast_offline = broadcast_json['is_play'] == 0\n            if broadcast_offline:\n                raise ExtractorError('Broadcast %s is offline' % broadcast_id, expected=True)\n\n            rtmp_url = broadcast_json['_server']\n            if not rtmp_url.startswith('rtmp://'):\n                raise ExtractorError('Unexpected broadcast rtmp URL')\n\n            broadcast_playpath = broadcast_json['_streamName']\n            broadcast_thumbnail = broadcast_json['_imgURL']\n            broadcast_title = broadcast_json['title']\n            broadcast_description = broadcast_json['description']\n            broadcaster_nick = broadcast_json['nick']\n            broadcaster_login = broadcast_json['login']\n            rtmp_conn = 'S:%s' % uuid.uuid4().hex\n        except KeyError:\n            if protected_broadcast:\n                raise ExtractorError('Bad broadcast password', expected=True)\n            raise ExtractorError('Unexpected broadcast JSON')\n\n        return {\n            'id': broadcast_id,\n            'url': rtmp_url,\n            'title': broadcast_title,\n            'thumbnail': broadcast_thumbnail,\n            'description': broadcast_description,\n            'uploader': broadcaster_nick,\n            'uploader_id': broadcaster_login,\n            'age_limit': 18 if adult_content else 0,\n            'ext': 'flv',\n            'play_path': broadcast_playpath,\n            'rtmp_live': True,\n            'rtmp_conn': rtmp_conn\n        }",
        "begin_line": 281,
        "end_line": 369,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.theplatform.ThePlatformIE._get_info#35",
        "src_path": "youtube_dl/extractor/theplatform.py",
        "class_name": "youtube_dl.extractor.theplatform.ThePlatformIE",
        "signature": "youtube_dl.extractor.theplatform.ThePlatformIE._get_info(self, video_id, smil_url)",
        "snippet": "    def _get_info(self, video_id, smil_url):\n        meta = self._download_xml(smil_url, video_id)\n\n        try:\n            error_msg = next(\n                n.attrib['abstract']\n                for n in meta.findall(_x('.//smil:ref'))\n                if n.attrib.get('title') == u'Geographic Restriction')\n        except StopIteration:\n            pass\n        else:\n            raise ExtractorError(error_msg, expected=True)\n\n        info_url = 'http://link.theplatform.com/s/dJ5BDC/{0}?format=preview'.format(video_id)\n        info_json = self._download_webpage(info_url, video_id)\n        info = json.loads(info_json)\n\n        head = meta.find(_x('smil:head'))\n        body = meta.find(_x('smil:body'))\n\n        f4m_node = body.find(_x('smil:seq/smil:video'))\n        if f4m_node is not None:\n            f4m_url = f4m_node.attrib['src']\n            if 'manifest.f4m?' not in f4m_url:\n                f4m_url += '?'\n            # the parameters are from syfy.com, other sites may use others,\n            # they also work for nbc.com\n            f4m_url += '&g=UXWGVKRWHFSP&hdcore=3.0.3'\n            formats = [{\n                'ext': 'flv',\n                'url': f4m_url,\n            }]\n        else:\n            base_url = head.find(_x('smil:meta')).attrib['base']\n            switch = body.find(_x('smil:switch'))\n            formats = []\n            for f in switch.findall(_x('smil:video')):\n                attr = f.attrib\n                width = int(attr['width'])\n                height = int(attr['height'])\n                vbr = int(attr['system-bitrate']) // 1000\n                format_id = '%dx%d_%dk' % (width, height, vbr)\n                formats.append({\n                    'format_id': format_id,\n                    'url': base_url,\n                    'play_path': 'mp4:' + attr['src'],\n                    'ext': 'flv',\n                    'width': width,\n                    'height': height,\n                    'vbr': vbr,\n                })\n            self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': info['title'],\n            'formats': formats,\n            'description': info['description'],\n            'thumbnail': info['defaultThumbnailUrl'],\n            'duration': info['duration']//1000,\n        }",
        "begin_line": 35,
        "end_line": 95,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.theplatform.ThePlatformIE._real_extract#97",
        "src_path": "youtube_dl/extractor/theplatform.py",
        "class_name": "youtube_dl.extractor.theplatform.ThePlatformIE",
        "signature": "youtube_dl.extractor.theplatform.ThePlatformIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        if mobj.group('config'):\n            config_url = url+ '&form=json'\n            config_url = config_url.replace('swf/', 'config/')\n            config_url = config_url.replace('onsite/', 'onsite/config/')\n            config_json = self._download_webpage(config_url, video_id, u'Downloading config')\n            config = json.loads(config_json)\n            smil_url = config['releaseUrl'] + '&format=SMIL&formats=MPEG4&manifest=f4m'\n        else:\n            smil_url = ('http://link.theplatform.com/s/dJ5BDC/{0}/meta.smil?'\n                'format=smil&mbr=true'.format(video_id))\n        return self._get_info(video_id, smil_url)",
        "begin_line": 97,
        "end_line": 110,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.__init__.gen_extractors#314",
        "src_path": "youtube_dl/extractor/__init__.py",
        "class_name": "youtube_dl.extractor.__init__",
        "signature": "youtube_dl.extractor.__init__.gen_extractors()",
        "snippet": "def gen_extractors():\n    \"\"\" Return a list of an instance of every supported extractor.\n    The order does matter; the first extractor matched is the one handling the URL.\n    \"\"\"\n    return [klass() for klass in _ALL_CLASSES]",
        "begin_line": 314,
        "end_line": 318,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.000157952930026852,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.__init__.get_info_extractor#321",
        "src_path": "youtube_dl/extractor/__init__.py",
        "class_name": "youtube_dl.extractor.__init__",
        "signature": "youtube_dl.extractor.__init__.get_info_extractor(ie_name)",
        "snippet": "def get_info_extractor(ie_name):\n    \"\"\"Returns the info extractor class with the given ie_name\"\"\"\n    return globals()[ie_name+'IE']",
        "begin_line": 321,
        "end_line": 323,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.023255813953488372,
            "pseudo_dstar_susp": 0.023255813953488372,
            "pseudo_tarantula_susp": 0.019230769230769232,
            "pseudo_op2_susp": 0.023255813953488372,
            "pseudo_barinel_susp": 0.019230769230769232
        }
    },
    {
        "name": "youtube_dl.extractor.servingsys.ServingSysIE._real_extract#43",
        "src_path": "youtube_dl/extractor/servingsys.py",
        "class_name": "youtube_dl.extractor.servingsys.ServingSysIE",
        "signature": "youtube_dl.extractor.servingsys.ServingSysIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        pl_id = mobj.group('id')\n\n        vast_doc = self._download_xml(url, pl_id)\n        title = vast_doc.find('.//AdTitle').text\n        media = vast_doc.find('.//MediaFile').text\n        info_url = self._search_regex(r'&adData=([^&]+)&', media, 'info URL')\n\n        doc = self._download_xml(info_url, pl_id, 'Downloading video info')\n        entries = [{\n            '_type': 'video',\n            'id': a.attrib['id'],\n            'title': '%s (%s)' % (title, a.attrib['assetID']),\n            'url': a.attrib['URL'],\n            'duration': int_or_none(a.attrib.get('length')),\n            'tbr': int_or_none(a.attrib.get('bitrate')),\n            'height': int_or_none(a.attrib.get('height')),\n            'width': int_or_none(a.attrib.get('width')),\n        } for a in doc.findall('.//AdditionalAssets/asset')]\n\n        return {\n            '_type': 'playlist',\n            'id': pl_id,\n            'title': title,\n            'entries': entries,\n        }",
        "begin_line": 43,
        "end_line": 69,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.imdb.ImdbIE._real_extract#29",
        "src_path": "youtube_dl/extractor/imdb.py",
        "class_name": "youtube_dl.extractor.imdb.ImdbIE",
        "signature": "youtube_dl.extractor.imdb.ImdbIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage('http://www.imdb.com/video/imdb/vi%s' % video_id, video_id)\n        descr = get_element_by_attribute('itemprop', 'description', webpage)\n        available_formats = re.findall(\n            r'case \\'(?P<f_id>.*?)\\' :$\\s+url = \\'(?P<path>.*?)\\'', webpage,\n            flags=re.MULTILINE)\n        formats = []\n        for f_id, f_path in available_formats:\n            f_path = f_path.strip()\n            format_page = self._download_webpage(\n                compat_urlparse.urljoin(url, f_path),\n                'Downloading info for %s format' % f_id)\n            json_data = self._search_regex(\n                r'<script[^>]+class=\"imdb-player-data\"[^>]*?>(.*?)</script>',\n                format_page, 'json data', flags=re.DOTALL)\n            info = json.loads(json_data)\n            format_info = info['videoPlayerObject']['video']\n            formats.append({\n                'format_id': f_id,\n                'url': format_info['url'],\n            })\n\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage),\n            'formats': formats,\n            'description': descr,\n            'thumbnail': format_info['slate'],\n        }",
        "begin_line": 29,
        "end_line": 59,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.imdb.ImdbListIE._real_extract#67",
        "src_path": "youtube_dl/extractor/imdb.py",
        "class_name": "youtube_dl.extractor.imdb.ImdbListIE",
        "signature": "youtube_dl.extractor.imdb.ImdbListIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        list_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, list_id)\n        entries = [\n            self.url_result('http://www.imdb.com' + m, 'Imdb')\n            for m in re.findall(r'href=\"(/video/imdb/vi[^\"]+)\"\\s+data-type=\"playlist\"', webpage)]\n\n        list_title = self._html_search_regex(\n            r'<h1 class=\"header\">(.*?)</h1>', webpage, 'list title')\n\n        return self.playlist_result(entries, list_id, list_title)",
        "begin_line": 67,
        "end_line": 79,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.aparat.AparatIE._real_extract#25",
        "src_path": "youtube_dl/extractor/aparat.py",
        "class_name": "youtube_dl.extractor.aparat.AparatIE",
        "signature": "youtube_dl.extractor.aparat.AparatIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('id')\n\n        # Note: There is an easier-to-parse configuration at\n        # http://www.aparat.com/video/video/config/videohash/%video_id\n        # but the URL in there does not work\n        embed_url = (u'http://www.aparat.com/video/video/embed/videohash/' +\n                     video_id + u'/vt/frame')\n        webpage = self._download_webpage(embed_url, video_id)\n\n        video_urls = re.findall(r'fileList\\[[0-9]+\\]\\s*=\\s*\"([^\"]+)\"', webpage)\n        for i, video_url in enumerate(video_urls):\n            req = HEADRequest(video_url)\n            res = self._request_webpage(\n                req, video_id, note=u'Testing video URL %d' % i, errnote=False)\n            if res:\n                break\n        else:\n            raise ExtractorError(u'No working video URLs found')\n\n        title = self._search_regex(r'\\s+title:\\s*\"([^\"]+)\"', webpage, u'title')\n        thumbnail = self._search_regex(\n            r'\\s+image:\\s*\"([^\"]+)\"', webpage, u'thumbnail', fatal=False)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'url': video_url,\n            'ext': 'mp4',\n            'thumbnail': thumbnail,\n        }",
        "begin_line": 25,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.postprocessor.xattrpp.XAttrMetadataPP.run#25",
        "src_path": "youtube_dl/postprocessor/xattrpp.py",
        "class_name": "youtube_dl.postprocessor.xattrpp.XAttrMetadataPP",
        "signature": "youtube_dl.postprocessor.xattrpp.XAttrMetadataPP.run(self, info)",
        "snippet": "    def run(self, info):\n        \"\"\" Set extended attributes on downloaded file (if xattr support is found). \"\"\"\n\n        # This mess below finds the best xattr tool for the job and creates a\n        # \"write_xattr\" function.\n        try:\n            # try the pyxattr module...\n            import xattr\n\n            def write_xattr(path, key, value):\n                return xattr.setxattr(path, key, value)\n\n        except ImportError:\n            if os.name == 'nt':\n                # Write xattrs to NTFS Alternate Data Streams:\n                # http://en.wikipedia.org/wiki/NTFS#Alternate_data_streams_.28ADS.29\n                def write_xattr(path, key, value):\n                    assert ':' not in key\n                    assert os.path.exists(path)\n\n                    ads_fn = path + \":\" + key\n                    with open(ads_fn, \"wb\") as f:\n                        f.write(value)\n            else:\n                user_has_setfattr = check_executable(\"setfattr\", ['--version'])\n                user_has_xattr = check_executable(\"xattr\", ['-h'])\n\n                if user_has_setfattr or user_has_xattr:\n\n                    def write_xattr(path, key, value):\n                        if user_has_setfattr:\n                            cmd = ['setfattr', '-n', key, '-v', value, path]\n                        elif user_has_xattr:\n                            cmd = ['xattr', '-w', key, value, path]\n\n                        subprocess.check_output(cmd)\n\n                else:\n                    # On Unix, and can't find pyxattr, setfattr, or xattr.\n                    if sys.platform.startswith('linux'):\n                        self._downloader.report_error(\n                            \"Couldn't find a tool to set the xattrs. \"\n                            \"Install either the python 'pyxattr' or 'xattr' \"\n                            \"modules, or the GNU 'attr' package \"\n                            \"(which contains the 'setfattr' tool).\")\n                    else:\n                        self._downloader.report_error(\n                            \"Couldn't find a tool to set the xattrs. \"\n                            \"Install either the python 'xattr' module, \"\n                            \"or the 'xattr' binary.\")\n\n        # Write the metadata to the file's xattrs\n        self._downloader.to_screen('[metadata] Writing metadata to file\\'s xattrs')\n\n        filename = info['filepath']\n\n        try:\n            xattr_mapping = {\n                'user.xdg.referrer.url': 'webpage_url',\n                # 'user.xdg.comment':            'description',\n                'user.dublincore.title': 'title',\n                'user.dublincore.date': 'upload_date',\n                'user.dublincore.description': 'description',\n                'user.dublincore.contributor': 'uploader',\n                'user.dublincore.format': 'format',\n            }\n\n            for xattrname, infoname in xattr_mapping.items():\n\n                value = info.get(infoname)\n\n                if value:\n                    if infoname == \"upload_date\":\n                        value = hyphenate_date(value)\n\n                    byte_value = value.encode('utf-8')\n                    write_xattr(filename, xattrname, byte_value)\n\n            return True, info\n\n        except (subprocess.CalledProcessError, OSError):\n            self._downloader.report_error(\"This filesystem doesn't support extended attributes. (You may have to enable them in your /etc/fstab)\")\n            return False, info",
        "begin_line": 25,
        "end_line": 107,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.tf1.TF1IE._real_extract#22",
        "src_path": "youtube_dl/extractor/tf1.py",
        "class_name": "youtube_dl.extractor.tf1.TF1IE",
        "signature": "youtube_dl.extractor.tf1.TF1IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        id = mobj.group(1)\n        webpage = self._download_webpage(url, id)\n        embed_url = self._html_search_regex(r'\"(https://www.wat.tv/embedframe/.*?)\"',\n                                webpage, 'embed url')\n        embed_page = self._download_webpage(embed_url, id, u'Downloading embed player page')\n        wat_id = self._search_regex(r'UVID=(.*?)&', embed_page, 'wat id')\n        wat_info = self._download_webpage('http://www.wat.tv/interface/contentv3/%s' % wat_id, id, u'Downloading Wat info')\n        wat_info = json.loads(wat_info)['media']\n        wat_url = wat_info['url']\n        return self.url_result(wat_url, 'Wat')",
        "begin_line": 22,
        "end_line": 33,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.canalplus.CanalplusIE._real_extract#26",
        "src_path": "youtube_dl/extractor/canalplus.py",
        "class_name": "youtube_dl.extractor.canalplus.CanalplusIE",
        "signature": "youtube_dl.extractor.canalplus.CanalplusIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.groupdict().get('id')\n        if video_id is None:\n            webpage = self._download_webpage(url, mobj.group('path'))\n            video_id = self._search_regex(r'videoId = \"(\\d+)\";', webpage, u'video id')\n        info_url = self._VIDEO_INFO_TEMPLATE % video_id\n        doc = self._download_xml(info_url,video_id, \n                                           u'Downloading video info')\n\n        self.report_extraction(video_id)\n        video_info = [video for video in doc if video.find('ID').text == video_id][0]\n        infos = video_info.find('INFOS')\n        media = video_info.find('MEDIA')\n        formats = [media.find('VIDEOS/%s' % format)\n            for format in ['BAS_DEBIT', 'HAUT_DEBIT', 'HD']]\n        video_url = [format.text for format in formats if format is not None][-1]\n\n        return {'id': video_id,\n                'title': u'%s - %s' % (infos.find('TITRAGE/TITRE').text,\n                                       infos.find('TITRAGE/SOUS_TITRE').text),\n                'url': video_url,\n                'ext': 'flv',\n                'upload_date': unified_strdate(infos.find('PUBLICATION/DATE').text),\n                'thumbnail': media.find('IMAGES/GRAND').text,\n                'description': infos.find('DESCRIPTION').text,\n                'view_count': int(infos.find('NB_VUES').text),\n                }",
        "begin_line": 26,
        "end_line": 53,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.firstpost.FirstpostIE._real_extract#23",
        "src_path": "youtube_dl/extractor/firstpost.py",
        "class_name": "youtube_dl.extractor.firstpost.FirstpostIE",
        "signature": "youtube_dl.extractor.firstpost.FirstpostIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n        video_url = self._html_search_regex(\n            r'<div.*?name=\"div_video\".*?flashvars=\"([^\"]+)\">',\n            webpage, 'video URL')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': self._og_search_title(webpage),\n            'description': self._og_search_description(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n        }",
        "begin_line": 23,
        "end_line": 38,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.bbccouk.BBCCoUkIE._extract_asx_playlist#61",
        "src_path": "youtube_dl/extractor/bbccouk.py",
        "class_name": "youtube_dl.extractor.bbccouk.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbccouk.BBCCoUkIE._extract_asx_playlist(self, connection, programme_id)",
        "snippet": "    def _extract_asx_playlist(self, connection, programme_id):\n        asx = self._download_xml(connection.get('href'), programme_id, 'Downloading ASX playlist')\n        return [ref.get('href') for ref in asx.findall('./Entry/ref')]",
        "begin_line": 61,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.bbccouk.BBCCoUkIE._extract_connection#65",
        "src_path": "youtube_dl/extractor/bbccouk.py",
        "class_name": "youtube_dl.extractor.bbccouk.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbccouk.BBCCoUkIE._extract_connection(self, connection, programme_id)",
        "snippet": "    def _extract_connection(self, connection, programme_id):\n        formats = []\n        protocol = connection.get('protocol')\n        supplier = connection.get('supplier')\n        if protocol == 'http':\n            href = connection.get('href')\n            # ASX playlist\n            if supplier == 'asx':\n                for i, ref in enumerate(self._extract_asx_playlist(connection, programme_id)):\n                    formats.append({\n                        'url': ref,\n                        'format_id': 'ref%s_%s' % (i, supplier),\n                    })\n            # Direct link\n            else:\n                formats.append({\n                    'url': href,\n                    'format_id': supplier,\n                })\n        elif protocol == 'rtmp':\n            application = connection.get('application', 'ondemand')\n            auth_string = connection.get('authString')\n            identifier = connection.get('identifier')\n            server = connection.get('server')\n            formats.append({\n                'url': '%s://%s/%s?%s' % (protocol, server, application, auth_string),\n                'play_path': identifier,\n                'app': '%s?%s' % (application, auth_string),\n                'page_url': 'http://www.bbc.co.uk',\n                'player_url': 'http://www.bbc.co.uk/emp/releases/iplayer/revisions/617463_618125_4/617463_618125_4_emp.swf',\n                'rtmp_live': False,\n                'ext': 'flv',\n                'format_id': supplier,\n            })\n        return formats",
        "begin_line": 65,
        "end_line": 99,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.bbccouk.BBCCoUkIE._extract_items#101",
        "src_path": "youtube_dl/extractor/bbccouk.py",
        "class_name": "youtube_dl.extractor.bbccouk.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbccouk.BBCCoUkIE._extract_items(self, playlist)",
        "snippet": "    def _extract_items(self, playlist):\n        return playlist.findall('./{http://bbc.co.uk/2008/emp/playlist}item')",
        "begin_line": 101,
        "end_line": 102,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.bbccouk.BBCCoUkIE._extract_medias#104",
        "src_path": "youtube_dl/extractor/bbccouk.py",
        "class_name": "youtube_dl.extractor.bbccouk.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbccouk.BBCCoUkIE._extract_medias(self, media_selection)",
        "snippet": "    def _extract_medias(self, media_selection):\n        return media_selection.findall('./{http://bbc.co.uk/2008/mp/mediaselection}media')",
        "begin_line": 104,
        "end_line": 105,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.bbccouk.BBCCoUkIE._extract_connections#107",
        "src_path": "youtube_dl/extractor/bbccouk.py",
        "class_name": "youtube_dl.extractor.bbccouk.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbccouk.BBCCoUkIE._extract_connections(self, media)",
        "snippet": "    def _extract_connections(self, media):\n        return media.findall('./{http://bbc.co.uk/2008/mp/mediaselection}connection')",
        "begin_line": 107,
        "end_line": 108,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.bbccouk.BBCCoUkIE._extract_video#110",
        "src_path": "youtube_dl/extractor/bbccouk.py",
        "class_name": "youtube_dl.extractor.bbccouk.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbccouk.BBCCoUkIE._extract_video(self, media, programme_id)",
        "snippet": "    def _extract_video(self, media, programme_id):\n        formats = []\n        vbr = int(media.get('bitrate'))\n        vcodec = media.get('encoding')\n        service = media.get('service')\n        width = int(media.get('width'))\n        height = int(media.get('height'))\n        file_size = int(media.get('media_file_size'))\n        for connection in self._extract_connections(media):\n            conn_formats = self._extract_connection(connection, programme_id)\n            for format in conn_formats:\n                format.update({\n                    'format_id': '%s_%s' % (service, format['format_id']),\n                    'width': width,\n                    'height': height,\n                    'vbr': vbr,\n                    'vcodec': vcodec,\n                    'filesize': file_size,\n                })\n            formats.extend(conn_formats)\n        return formats",
        "begin_line": 110,
        "end_line": 130,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.bbccouk.BBCCoUkIE._extract_audio#132",
        "src_path": "youtube_dl/extractor/bbccouk.py",
        "class_name": "youtube_dl.extractor.bbccouk.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbccouk.BBCCoUkIE._extract_audio(self, media, programme_id)",
        "snippet": "    def _extract_audio(self, media, programme_id):\n        formats = []\n        abr = int(media.get('bitrate'))\n        acodec = media.get('encoding')\n        service = media.get('service')\n        for connection in self._extract_connections(media):\n            conn_formats = self._extract_connection(connection, programme_id)\n            for format in conn_formats:\n                format.update({\n                    'format_id': '%s_%s' % (service, format['format_id']),\n                    'abr': abr,\n                    'acodec': acodec,\n                })\n            formats.extend(conn_formats)\n        return formats",
        "begin_line": 132,
        "end_line": 146,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.bbccouk.BBCCoUkIE._extract_captions#148",
        "src_path": "youtube_dl/extractor/bbccouk.py",
        "class_name": "youtube_dl.extractor.bbccouk.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbccouk.BBCCoUkIE._extract_captions(self, media, programme_id)",
        "snippet": "    def _extract_captions(self, media, programme_id):\n        subtitles = {}\n        for connection in self._extract_connections(media):\n            captions = self._download_xml(connection.get('href'), programme_id, 'Downloading captions')\n            lang = captions.get('{http://www.w3.org/XML/1998/namespace}lang', 'en')\n            ps = captions.findall('./{0}body/{0}div/{0}p'.format('{http://www.w3.org/2006/10/ttaf1}'))\n            srt = ''\n            for pos, p in enumerate(ps):\n                srt += '%s\\r\\n%s --> %s\\r\\n%s\\r\\n\\r\\n' % (str(pos), p.get('begin'), p.get('end'),\n                                                          p.text.strip() if p.text is not None else '')\n            subtitles[lang] = srt\n        return subtitles",
        "begin_line": 148,
        "end_line": 159,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.bbccouk.BBCCoUkIE._real_extract#161",
        "src_path": "youtube_dl/extractor/bbccouk.py",
        "class_name": "youtube_dl.extractor.bbccouk.BBCCoUkIE",
        "signature": "youtube_dl.extractor.bbccouk.BBCCoUkIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        group_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, group_id, 'Downloading video page')\n        if re.search(r'id=\"emp-error\" class=\"notinuk\">', webpage):\n            raise ExtractorError('Currently BBC iPlayer TV programmes are available to play in the UK only',\n                expected=True)\n\n        playlist = self._download_xml('http://www.bbc.co.uk/iplayer/playlist/%s' % group_id, group_id,\n            'Downloading playlist XML')\n\n        no_items = playlist.find('./{http://bbc.co.uk/2008/emp/playlist}noItems')\n        if no_items is not None:\n            reason = no_items.get('reason')\n            if reason == 'preAvailability':\n                msg = 'Episode %s is not yet available' % group_id\n            elif reason == 'postAvailability':\n                msg = 'Episode %s is no longer available' % group_id\n            else:\n                msg = 'Episode %s is not available: %s' % (group_id, reason)\n            raise ExtractorError(msg, expected=True)\n\n        formats = []\n        subtitles = None\n\n        for item in self._extract_items(playlist):\n            kind = item.get('kind')\n            if kind != 'programme' and kind != 'radioProgramme':\n                continue\n            title = playlist.find('./{http://bbc.co.uk/2008/emp/playlist}title').text\n            description = playlist.find('./{http://bbc.co.uk/2008/emp/playlist}summary').text\n\n            programme_id = item.get('identifier')\n            duration = int(item.get('duration'))\n\n            media_selection = self._download_xml(\n                'http://open.live.bbc.co.uk/mediaselector/5/select/version/2.0/mediaset/pc/vpid/%s'  % programme_id,\n                programme_id, 'Downloading media selection XML')\n\n            for media in self._extract_medias(media_selection):\n                kind = media.get('kind')\n                if kind == 'audio':\n                    formats.extend(self._extract_audio(media, programme_id))\n                elif kind == 'video':\n                    formats.extend(self._extract_video(media, programme_id))\n                elif kind == 'captions':\n                    subtitles = self._extract_captions(media, programme_id)\n\n        if self._downloader.params.get('listsubtitles', False):\n            self._list_available_subtitles(programme_id, subtitles)\n            return\n\n        self._sort_formats(formats)\n\n        return {\n            'id': programme_id,\n            'title': title,\n            'description': description,\n            'duration': duration,\n            'formats': formats,\n            'subtitles': subtitles,\n        }",
        "begin_line": 161,
        "end_line": 223,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.http.HttpFD.real_download#17",
        "src_path": "youtube_dl/downloader/http.py",
        "class_name": "youtube_dl.downloader.http.HttpFD",
        "signature": "youtube_dl.downloader.http.HttpFD.real_download(self, filename, info_dict)",
        "snippet": "    def real_download(self, filename, info_dict):\n        url = info_dict['url']\n        tmpfilename = self.temp_name(filename)\n        stream = None\n\n        # Do not include the Accept-Encoding header\n        headers = {'Youtubedl-no-compression': 'True'}\n        if 'user_agent' in info_dict:\n            headers['Youtubedl-user-agent'] = info_dict['user_agent']\n        basic_request = compat_urllib_request.Request(url, None, headers)\n        request = compat_urllib_request.Request(url, None, headers)\n\n        if self.params.get('test', False):\n            request.add_header('Range', 'bytes=0-10240')\n\n        # Establish possible resume length\n        if os.path.isfile(encodeFilename(tmpfilename)):\n            resume_len = os.path.getsize(encodeFilename(tmpfilename))\n        else:\n            resume_len = 0\n\n        open_mode = 'wb'\n        if resume_len != 0:\n            if self.params.get('continuedl', False):\n                self.report_resuming_byte(resume_len)\n                request.add_header('Range', 'bytes=%d-' % resume_len)\n                open_mode = 'ab'\n            else:\n                resume_len = 0\n\n        count = 0\n        retries = self.params.get('retries', 0)\n        while count <= retries:\n            # Establish connection\n            try:\n                data = compat_urllib_request.urlopen(request)\n                break\n            except (compat_urllib_error.HTTPError, ) as err:\n                if (err.code < 500 or err.code >= 600) and err.code != 416:\n                    # Unexpected HTTP error\n                    raise\n                elif err.code == 416:\n                    # Unable to resume (requested range not satisfiable)\n                    try:\n                        # Open the connection again without the range header\n                        data = compat_urllib_request.urlopen(basic_request)\n                        content_length = data.info()['Content-Length']\n                    except (compat_urllib_error.HTTPError, ) as err:\n                        if err.code < 500 or err.code >= 600:\n                            raise\n                    else:\n                        # Examine the reported length\n                        if (content_length is not None and\n                                (resume_len - 100 < int(content_length) < resume_len + 100)):\n                            # The file had already been fully downloaded.\n                            # Explanation to the above condition: in issue #175 it was revealed that\n                            # YouTube sometimes adds or removes a few bytes from the end of the file,\n                            # changing the file size slightly and causing problems for some users. So\n                            # I decided to implement a suggested change and consider the file\n                            # completely downloaded if the file size differs less than 100 bytes from\n                            # the one in the hard drive.\n                            self.report_file_already_downloaded(filename)\n                            self.try_rename(tmpfilename, filename)\n                            self._hook_progress({\n                                'filename': filename,\n                                'status': 'finished',\n                            })\n                            return True\n                        else:\n                            # The length does not match, we start the download over\n                            self.report_unable_to_resume()\n                            resume_len = 0\n                            open_mode = 'wb'\n                            break\n            # Retry\n            count += 1\n            if count <= retries:\n                self.report_retry(count, retries)\n\n        if count > retries:\n            self.report_error(u'giving up after %s retries' % retries)\n            return False\n\n        data_len = data.info().get('Content-length', None)\n        if data_len is not None:\n            data_len = int(data_len) + resume_len\n            min_data_len = self.params.get(\"min_filesize\", None)\n            max_data_len = self.params.get(\"max_filesize\", None)\n            if min_data_len is not None and data_len < min_data_len:\n                self.to_screen(u'\\r[download] File is smaller than min-filesize (%s bytes < %s bytes). Aborting.' % (data_len, min_data_len))\n                return False\n            if max_data_len is not None and data_len > max_data_len:\n                self.to_screen(u'\\r[download] File is larger than max-filesize (%s bytes > %s bytes). Aborting.' % (data_len, max_data_len))\n                return False\n\n        data_len_str = format_bytes(data_len)\n        byte_counter = 0 + resume_len\n        block_size = self.params.get('buffersize', 1024)\n        start = time.time()\n        while True:\n            # Download and write\n            before = time.time()\n            data_block = data.read(block_size)\n            after = time.time()\n            if len(data_block) == 0:\n                break\n            byte_counter += len(data_block)\n\n            # Open file just in time\n            if stream is None:\n                try:\n                    (stream, tmpfilename) = sanitize_open(tmpfilename, open_mode)\n                    assert stream is not None\n                    filename = self.undo_temp_name(tmpfilename)\n                    self.report_destination(filename)\n                except (OSError, IOError) as err:\n                    self.report_error(u'unable to open for writing: %s' % str(err))\n                    return False\n            try:\n                stream.write(data_block)\n            except (IOError, OSError) as err:\n                self.to_stderr(u\"\\n\")\n                self.report_error(u'unable to write data: %s' % str(err))\n                return False\n            if not self.params.get('noresizebuffer', False):\n                block_size = self.best_block_size(after - before, len(data_block))\n\n            # Progress message\n            speed = self.calc_speed(start, time.time(), byte_counter - resume_len)\n            if data_len is None:\n                eta = percent = None\n            else:\n                percent = self.calc_percent(byte_counter, data_len)\n                eta = self.calc_eta(start, time.time(), data_len - resume_len, byte_counter - resume_len)\n            self.report_progress(percent, data_len_str, speed, eta)\n\n            self._hook_progress({\n                'downloaded_bytes': byte_counter,\n                'total_bytes': data_len,\n                'tmpfilename': tmpfilename,\n                'filename': filename,\n                'status': 'downloading',\n                'eta': eta,\n                'speed': speed,\n            })\n\n            # Apply rate limit\n            self.slow_down(start, byte_counter - resume_len)\n\n        if stream is None:\n            self.to_stderr(u\"\\n\")\n            self.report_error(u'Did not get any data blocks')\n            return False\n        stream.close()\n        self.report_finish(data_len_str, (time.time() - start))\n        if data_len is not None and byte_counter != data_len:\n            raise ContentTooShortError(byte_counter, int(data_len))\n        self.try_rename(tmpfilename, filename)\n\n        # Update file modification time\n        if self.params.get('updatetime', True):\n            info_dict['filetime'] = self.try_utime(filename, data.info().get('last-modified', None))\n\n        self._hook_progress({\n            'downloaded_bytes': byte_counter,\n            'total_bytes': byte_counter,\n            'filename': filename,\n            'status': 'finished',\n        })\n\n        return True",
        "begin_line": 17,
        "end_line": 187,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.downloader.mplayer.MplayerFD.real_download#11",
        "src_path": "youtube_dl/downloader/mplayer.py",
        "class_name": "youtube_dl.downloader.mplayer.MplayerFD",
        "signature": "youtube_dl.downloader.mplayer.MplayerFD.real_download(self, filename, info_dict)",
        "snippet": "    def real_download(self, filename, info_dict):\n        url = info_dict['url']\n        self.report_destination(filename)\n        tmpfilename = self.temp_name(filename)\n\n        args = ['mplayer', '-really-quiet', '-vo', 'null', '-vc', 'dummy', '-dumpstream', '-dumpfile', tmpfilename, url]\n        # Check for mplayer first\n        try:\n            subprocess.call(['mplayer', '-h'], stdout=(open(os.path.devnull, 'w')), stderr=subprocess.STDOUT)\n        except (OSError, IOError):\n            self.report_error(u'MMS or RTSP download detected but \"%s\" could not be run' % args[0])\n            return False\n\n        # Download using mplayer.\n        retval = subprocess.call(args)\n        if retval == 0:\n            fsize = os.path.getsize(encodeFilename(tmpfilename))\n            self.to_screen(u'\\r[%s] %s bytes' % (args[0], fsize))\n            self.try_rename(tmpfilename, filename)\n            self._hook_progress({\n                'downloaded_bytes': fsize,\n                'total_bytes': fsize,\n                'filename': filename,\n                'status': 'finished',\n            })\n            return True\n        else:\n            self.to_stderr(u\"\\n\")\n            self.report_error(u'mplayer exited with code %d' % retval)\n            return False",
        "begin_line": 11,
        "end_line": 40,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.nfb.NFBIE._real_extract#34",
        "src_path": "youtube_dl/extractor/nfb.py",
        "class_name": "youtube_dl.extractor.nfb.NFBIE",
        "signature": "youtube_dl.extractor.nfb.NFBIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        page = self._download_webpage('https://www.nfb.ca/film/%s' % video_id, video_id, 'Downloading film page')\n\n        uploader_id = self._html_search_regex(r'<a class=\"director-link\" href=\"/explore-all-directors/([^/]+)/\"',\n            page, 'director id', fatal=False)\n        uploader = self._html_search_regex(r'<em class=\"director-name\" itemprop=\"name\">([^<]+)</em>',\n            page, 'director name', fatal=False)\n\n        request = compat_urllib_request.Request('https://www.nfb.ca/film/%s/player_config' % video_id,\n            compat_urllib_parse.urlencode({'getConfig': 'true'}).encode('ascii'))\n        request.add_header('Content-Type', 'application/x-www-form-urlencoded')\n        request.add_header('X-NFB-Referer', 'http://www.nfb.ca/medias/flash/NFBVideoPlayer.swf')\n\n        config = self._download_xml(request, video_id, 'Downloading player config XML')\n\n        title = None\n        description = None\n        thumbnail = None\n        duration = None\n        formats = []\n\n        def extract_thumbnail(media):\n            thumbnails = {}\n            for asset in media.findall('assets/asset'):\n                thumbnails[asset.get('quality')] = asset.find('default/url').text\n            if not thumbnails:\n                return None\n            if 'high' in thumbnails:\n                return thumbnails['high']\n            return list(thumbnails.values())[0]\n\n        for media in config.findall('./player/stream/media'):\n            if media.get('type') == 'posterImage':\n                thumbnail = extract_thumbnail(media)\n            elif media.get('type') == 'video':\n                duration = int(media.get('duration'))\n                title = media.find('title').text\n                description = media.find('description').text\n                # It seems assets always go from lower to better quality, so no need to sort\n                formats = [{\n                    'url': x.find('default/streamerURI').text,\n                    'app': x.find('default/streamerURI').text.split('/', 3)[3],\n                    'play_path': x.find('default/url').text,\n                    'rtmp_live': False,\n                    'ext': 'mp4',\n                    'format_id': x.get('quality'),\n                } for x in media.findall('assets/asset')]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'description': description,\n            'thumbnail': thumbnail,\n            'duration': duration,\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'formats': formats,\n        }",
        "begin_line": 34,
        "end_line": 94,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.helsinki.HelsinkiIE._real_extract#26",
        "src_path": "youtube_dl/extractor/helsinki.py",
        "class_name": "youtube_dl.extractor.helsinki.HelsinkiIE",
        "signature": "youtube_dl.extractor.helsinki.HelsinkiIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        formats = []\n\n        mobj = re.search(r'file=((\\w+):[^&]+)', webpage)\n        if mobj:\n            formats.append({\n                'ext': mobj.group(2),\n                'play_path': mobj.group(1),\n                'url': 'rtmp://flashvideo.it.helsinki.fi/vod/',\n                'player_url': 'http://video.helsinki.fi/player.swf',\n                'format_note': 'sd',\n                'quality': 0,\n            })\n\n        mobj = re.search(r'hd\\.file=((\\w+):[^&]+)', webpage)\n        if mobj:\n            formats.append({\n                'ext': mobj.group(2),\n                'play_path': mobj.group(1),\n                'url': 'rtmp://flashvideo.it.helsinki.fi/vod/',\n                'player_url': 'http://video.helsinki.fi/player.swf',\n                'format_note': 'hd',\n                'quality': 1,\n            })\n\n        self._sort_formats(formats)\n\n        return {\n            'id': video_id,\n            'title': self._og_search_title(webpage).replace('Video: ', ''),\n            'description': self._og_search_description(webpage),\n            'thumbnail': self._og_search_thumbnail(webpage),\n            'formats': formats,\n        }",
        "begin_line": 26,
        "end_line": 62,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.cliphunter.CliphunterIE._real_extract#32",
        "src_path": "youtube_dl/extractor/cliphunter.py",
        "class_name": "youtube_dl.extractor.cliphunter.CliphunterIE",
        "signature": "youtube_dl.extractor.cliphunter.CliphunterIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        pl_fiji = self._search_regex(\n            r'pl_fiji = \\'([^\\']+)\\'', webpage, 'video data')\n        pl_c_qual = self._search_regex(\n            r'pl_c_qual = \"(.)\"', webpage, 'video quality')\n        video_title = self._search_regex(\n            r'mediaTitle = \"([^\"]+)\"', webpage, 'title')\n\n        video_url = ''.join(translation_table.get(c, c) for c in pl_fiji)\n\n        formats = [{\n            'url': video_url,\n            'format_id': pl_c_qual,\n        }]\n\n        return {\n            'id': video_id,\n            'title': video_title,\n            'formats': formats,\n        }",
        "begin_line": 32,
        "end_line": 56,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.podomatic.PodomaticIE._real_extract#26",
        "src_path": "youtube_dl/extractor/podomatic.py",
        "class_name": "youtube_dl.extractor.podomatic.PodomaticIE",
        "signature": "youtube_dl.extractor.podomatic.PodomaticIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n        channel = mobj.group('channel')\n\n        json_url = (('%s://%s.podomatic.com/entry/embed_params/%s' +\n                     '?permalink=true&rtmp=0') %\n                    (mobj.group('proto'), channel, video_id))\n        data_json = self._download_webpage(\n            json_url, video_id, note=u'Downloading video info')\n        data = json.loads(data_json)\n\n        video_url = data['downloadLink']\n        uploader = data['podcast']\n        title = data['title']\n        thumbnail = data['imageLocation']\n        duration = int_or_none(data.get('length'), 1000)\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'uploader': uploader,\n            'uploader_id': channel,\n            'thumbnail': thumbnail,\n            'duration': duration,\n        }",
        "begin_line": 26,
        "end_line": 52,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.thisav.ThisAVIE._real_extract#24",
        "src_path": "youtube_dl/extractor/thisav.py",
        "class_name": "youtube_dl.extractor.thisav.ThisAVIE",
        "signature": "youtube_dl.extractor.thisav.ThisAVIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n\n        video_id = mobj.group('id')\n        webpage = self._download_webpage(url, video_id)\n        title = self._html_search_regex(r'<h1>([^<]*)</h1>', webpage, 'title')\n        video_url = self._html_search_regex(\n            r\"addVariable\\('file','([^']+)'\\);\", webpage, 'video url')\n        uploader = self._html_search_regex(\n            r': <a href=\"http://www.thisav.com/user/[0-9]+/(?:[^\"]+)\">([^<]+)</a>',\n            webpage, 'uploader name', fatal=False)\n        uploader_id = self._html_search_regex(\n            r': <a href=\"http://www.thisav.com/user/[0-9]+/([^\"]+)\">(?:[^<]+)</a>',\n            webpage, 'uploader id', fatal=False)\n        ext = determine_ext(video_url)\n        \n        return {\n            'id':          video_id,\n            'url':         video_url,\n            'uploader':    uploader,\n            'uploader_id': uploader_id,\n            'title':       title,\n            'ext':         ext,\n        }",
        "begin_line": 24,
        "end_line": 47,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.infoq.InfoQIE._real_extract#27",
        "src_path": "youtube_dl/extractor/infoq.py",
        "class_name": "youtube_dl.extractor.infoq.InfoQIE",
        "signature": "youtube_dl.extractor.infoq.InfoQIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        # Extract video URL\n        encoded_id = self._search_regex(r\"jsclassref ?= ?'([^']*)'\", webpage, 'encoded id')\n        real_id = compat_urllib_parse.unquote(base64.b64decode(encoded_id.encode('ascii')).decode('utf-8'))\n        video_url = 'rtmpe://video.infoq.com/cfx/st/' + real_id\n\n        # Extract title\n        video_title = self._search_regex(r'contentTitle = \"(.*?)\";',\n            webpage, 'title')\n\n        # Extract description\n        video_description = self._html_search_regex(r'<meta name=\"description\" content=\"(.*)\"(?:\\s*/)?>',\n            webpage, 'description', fatal=False)\n\n        video_filename = video_url.split('/')[-1]\n        video_id, extension = video_filename.split('.')\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': video_title,\n            'ext': extension,  # Extension is always(?) mp4, but seems to be flv\n            'description': video_description,\n        }",
        "begin_line": 27,
        "end_line": 55,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.elpais.ElPaisIE._real_extract#26",
        "src_path": "youtube_dl/extractor/elpais.py",
        "class_name": "youtube_dl.extractor.elpais.ElPaisIE",
        "signature": "youtube_dl.extractor.elpais.ElPaisIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('id')\n\n        webpage = self._download_webpage(url, video_id)\n\n        prefix = self._html_search_regex(\n            r'var url_cache = \"([^\"]+)\";', webpage, 'URL prefix')\n        video_suffix = self._search_regex(\n            r\"URLMediaFile = url_cache \\+ '([^']+)'\", webpage, 'video URL')\n        video_url = prefix + video_suffix\n        thumbnail_suffix = self._search_regex(\n            r\"URLMediaStill = url_cache \\+ '([^']+)'\", webpage, 'thumbnail URL',\n            fatal=False)\n        thumbnail = (\n            None if thumbnail_suffix is None\n            else prefix + thumbnail_suffix)\n        title = self._html_search_regex(\n            '<h2 class=\"entry-header entry-title.*?>(.*?)</h2>',\n            webpage, 'title')\n        date_str = self._search_regex(\n            r'<p class=\"date-header date-int updated\"\\s+title=\"([^\"]+)\">',\n            webpage, 'upload date', fatal=False)\n        upload_date = (None if date_str is None else unified_strdate(date_str))\n\n        return {\n            'id': video_id,\n            'url': video_url,\n            'title': title,\n            'description': self._og_search_description(webpage),\n            'thumbnail': thumbnail,\n            'upload_date': upload_date,\n        }",
        "begin_line": 26,
        "end_line": 58,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.worldstarhiphop.WorldStarHipHopIE._real_extract#18",
        "src_path": "youtube_dl/extractor/worldstarhiphop.py",
        "class_name": "youtube_dl.extractor.worldstarhiphop.WorldStarHipHopIE",
        "signature": "youtube_dl.extractor.worldstarhiphop.WorldStarHipHopIE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        m = re.match(self._VALID_URL, url)\n        video_id = m.group('id')\n\n        webpage_src = self._download_webpage(url, video_id)\n\n        m_vevo_id = re.search(r'videoId=(.*?)&amp?',\n                              webpage_src)\n\n        if m_vevo_id is not None:\n            self.to_screen(u'Vevo video detected:')\n            return self.url_result('vevo:%s' % m_vevo_id.group(1), ie='Vevo')\n\n        video_url = self._search_regex(r'so\\.addVariable\\(\"file\",\"(.*?)\"\\)',\n            webpage_src, u'video URL')\n\n        if 'youtube' in video_url:\n            self.to_screen(u'Youtube video detected:')\n            return self.url_result(video_url, ie='Youtube')\n\n        if 'mp4' in video_url:\n            ext = 'mp4'\n        else:\n            ext = 'flv'\n\n        video_title = self._html_search_regex(r\"<title>(.*)</title>\",\n            webpage_src, u'title')\n\n        # Getting thumbnail and if not thumbnail sets correct title for WSHH candy video.\n        thumbnail = self._html_search_regex(r'rel=\"image_src\" href=\"(.*)\" />',\n            webpage_src, u'thumbnail', fatal=False)\n\n        if not thumbnail:\n            _title = r\"\"\"candytitles.*>(.*)</span>\"\"\"\n            mobj = re.search(_title, webpage_src)\n            if mobj is not None:\n                video_title = mobj.group(1)\n\n        results = [{\n                    'id': video_id,\n                    'url' : video_url,\n                    'title' : video_title,\n                    'thumbnail' : thumbnail,\n                    'ext' : ext,\n                    }]\n        return results",
        "begin_line": 18,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    },
    {
        "name": "youtube_dl.extractor.tube8.Tube8IE._real_extract#27",
        "src_path": "youtube_dl/extractor/tube8.py",
        "class_name": "youtube_dl.extractor.tube8.Tube8IE",
        "signature": "youtube_dl.extractor.tube8.Tube8IE._real_extract(self, url)",
        "snippet": "    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        video_id = mobj.group('videoid')\n        url = 'http://www.' + mobj.group('url')\n\n        req = compat_urllib_request.Request(url)\n        req.add_header('Cookie', 'age_verified=1')\n        webpage = self._download_webpage(req, video_id)\n\n        video_title = self._html_search_regex(r'videotitle\t=\"([^\"]+)', webpage, u'title')\n        video_description = self._html_search_regex(r'>Description:</strong>(.+?)<', webpage, u'description', fatal=False)\n        video_uploader = self._html_search_regex(r'>Submitted by:</strong>(?:\\s|<[^>]*>)*(.+?)<', webpage, u'uploader', fatal=False)\n        thumbnail = self._html_search_regex(r'\"image_url\":\"([^\"]+)', webpage, u'thumbnail', fatal=False)\n        if thumbnail:\n            thumbnail = thumbnail.replace('\\\\/', '/')\n\n        video_url = self._html_search_regex(r'\"video_url\":\"([^\"]+)', webpage, u'video_url')\n        if webpage.find('\"encrypted\":true')!=-1:\n            password = self._html_search_regex(r'\"video_title\":\"([^\"]+)', webpage, u'password')\n            video_url = aes_decrypt_text(video_url, password, 32).decode('utf-8')\n        path = compat_urllib_parse_urlparse(video_url).path\n        extension = os.path.splitext(path)[1][1:]\n        format = path.split('/')[4].split('_')[:2]\n        format = \"-\".join(format)\n\n        return {\n            'id': video_id,\n            'uploader': video_uploader,\n            'title': video_title,\n            'thumbnail': thumbnail,\n            'description': video_description,\n            'url': video_url,\n            'ext': extension,\n            'format': format,\n            'format_id': format,\n            'age_limit': 18,\n        }",
        "begin_line": 27,
        "end_line": 63,
        "comment": "",
        "is_bug": false,
        "susp": {
            "pseudo_ochiai_susp": 0.00031259768677711783,
            "pseudo_dstar_susp": 0.00031259768677711783,
            "pseudo_tarantula_susp": 0.00031259768677711783,
            "pseudo_op2_susp": 0.0003181673560292714,
            "pseudo_barinel_susp": 0.00031259768677711783
        }
    }
]